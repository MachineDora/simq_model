id,clarification_question
1424,"by 'such event' do you mean exactly 3 aces , or at least 3 aces ?"
2909,how accurate do you need it ?
2915,should this be cw as it is asking for a collection of resources ?
1853,multivariate or univariate ?
2072,can you clarify what you mean by irregular ?
2335,could you be more precise about what you mean by cross-tabulating the ors ?
2377,do you require that the standard deviation remain constant with this transformation as well ?
2988,do you expect some dropouts during follow-up ?
3368,what do you mean by ` i have 3 time series' ?
3446,"i confess to being mystified by this , despite struggling several times to make sense of it : is there a question here ?"
4155,do you mean arima rather than x-12-arima ?
4465,roughly what proportion of the individuals died by the end of the experiment ?
4816,"if you define the deltas to be complementary incomplete gamma functions , you obtain exact equalities . obviously these are the sharpest possible bounds ! i guess the point of this question is that your calculator doesn't compute incomplete gammas and you're looking for an approximation , but that still omits essential information : how can we answer this question until we know just what your calculator * can * compute ?"
5443,"if x1 . 5 and x2 . 1 , then y = "" b "" . is that the intended behaviour ?"
146169,how large is your sample ?
230120,"i see , sorry for the confusion , maybe url answers your question ?"
4856,may i ask what kind of data do you want to model and for what usage you want to do it ?
5004,doesn't url answer this question ?
10171,"do you mean something like , e . g . , where the entries of a single column of the design matrix are permuted , holding the response and other covariates fixed ?"
12546,cardinal how would you recast this as a linear program ?
13953,"i suggest you think in very precise terms about what you mean by "" control "" in this context . within one multiple regression , control would mean to see how x1 relates to y while partialling out or holding constant x2 . what does control mean with respect to your situation involving a second y ?"
14113,"did you select x and y * before * looking at the dataset or in response to what you're seeing in the data ( such as focusing on the highest or lowest frequencies , for instance ) ?"
111100,is the green table only a subset of a full table that includes all the predictors also found in the blue table ?
307203,"most of the methods for comparing means would probably be robust against small departures from normality so as maartenbuis wisely remarks , why bother ?"
6562,why haven't you tried it yourself ?
6736,"what is this "" given purpose "" ?"
7153,"onestop , marco , cw ?"
7605,how do you measure the increase in goodness-of-fit ?
8126,"in what way are you using * * optim * * ( with what options , with or without supplying a gradient function , etc ) ?"
8160,"when you say "" will best take into account "" , what do you mean by "" best "" ?"
9416,n / w = network ?
9776,in order to use a kalman filter you should have the model of your dynamical system ( i . e . a system of differential equations ) plus the measurements equations . are they available ?
9926,"$ f $ is a pdf , right ?"
10008,exactly what do you plan to do with this correlation once you compute it ?
10059,you mean like clustering on a sample to quickly get good starting centroids for the 'full' pass ?
10532,"would you mind clarifying what you mean by "" simulation of experimental design data "" ?"
10656,"of course you * can * : ) are you asking how to do it in the software , or whether you can draw a particular conclusion , etc ?"
11108,"your title says "" change of mean "" , but the boxplots don't show the means . maybe it won't make much difference , but do you mean a change in the median ?"
11273,can you indicate where you encountered this term ?
11329,i'm confused . did you mean to write $ q_r ( d ) = r $ instead of $ = d $ ?
11414,can we get an example of the query ?
11444,homework ?
11516,is your main research q more about length of time until cancer or about the causes of the three different outcomes ?
12068,can you please elaborate ?
12205,if you have a representative sample why do you need corrections ?
12443,do you have any information about the joint distribution of the five variables or are you trying to estimate it ?
12484,cardinal good answer ! ( maybe you could post it as a reply ?
12610,is it for hypothesis testing ?
12661,can you please define * noisy * ?
12860,why has no one mentioned theoretical properties of information theory and entropy yet ?
13162,could you clarify one thing ?
13430,"sander : perhaps an example for illustration would make your question clearer ( for example , a sample of * a method * ) ?"
13468,are the sites fare enough from one another so that the measurements can be considered independent across sites ?
13693,i'm assuming the $ * $ is to indicate simple multiplication ?
13848,higher than what ?
13857,"so you are trying to predict x , based on var1-var3000 ?"
13849,"could you perhaps say a little more about the purpose of doing pca in this case and why that leads you to think some kind of "" adjustment "" for gender bias might be needed ?"
14064,what is cpk and ppk ?
14237,"peter flom , data collected over time need not be time dependent , and even if it is , it may not make that much difference to your results . it depends on the situation and on what information you have . moominpappa - just wondering , * why * do you think the variables need to be normalised ?"
14247,can you clarify the clustering goal ?
14269,why would you want to do that ?
14636,"what is theta , and what is the distance measured from ?"
14761,"wait , is the output 1500 unique values ?"
14951,can you provide more information ?
14974,"sanity check : in your question , class and group are equivalent , right ?"
15001,it would be useful if you could include plots of the distributions you're comparing . but i suspect that the statistic ( for comparing the distributions ) won't be as big of a problem as the null distribution of the statistic . do you have just the one network ?
15084,did you get homogenous subsets ?
15157,could you please be a bit more detailed ?
15309,are there different dependent variables in the two models ?
15343,what is the hypothesis you want to test ?
15950,plot it how ?
15976,"could you clarify or provide an example of what you mean by "" items in a strong association rule "" ?"
16224,can you qualify huge ?
7088,could you elaborate more on what you mean by format ?
16764,what happens when you do the logistic regression with just the dichotomous predictor ?
27607,"could you explain what you mean by "" ratio and group information "" ?"
43499,does the answer [ here ] ( url ) help ?
81967,what are you trying to do ?
136513,do you mean estimators of the true effects of the variables ?
189239,what are $ x_1 $ and $ x_2 $ and how do they differ from $ x_1 $ and $ x_2 $ ?
272655,what is $ u ( t ) $ ?
15841,are you only concerned with testing differences in means ?
325222,i cannot understand the actual question . could you perhaps rephrase it a bit ?
13427,"i doubt it . . . loess is built-in in most statistical programs , thus there is no practical need to do that . what precisely do you want to alter inside ?"
7799,are you interested in univariate multiple regression ( one predicted variable ) or multivariate multiple regression ( many predicted variables analyzed simultaneously ) ?
9213,"did you want to write p ( e l , t ) = 1 . 0 instead of the second p ( e l , t ) = 1 . 0 ?"
11829,"what do you mean by "" the independant variable is with log link "" ?"
14763,what do you mean by structural breaks ?
17708,the answer should be data dependent . are you asking how to determine them ?
21630,"the answer to your question is "" no "" , unless your daily demands are all the same . irishstat , below , lists a bunch of things that can affect time series . also , when you say , "" can i forecast just for one period "" , what kind of method are you using to forecast ?"
23832,to what does that last sentence refer ?
27900,"you mention the lme package on the title , and nlme on your question . which is the correct package ?"
30075,"could you add details to your quite reserved question . examples . and do you consider here both stages of lda - extraction and classification , - or classification only ?"
243153,"it might depend on context . can you offer an explicit example , in context , with a proper reference ?"
12676,"can you add a proper citation , or better an on-line version of the paper ?"
17293,how do you know there is overdispersion without first doing the poisson regression ?
17417,weren't the bayesians before the frequentists ?
18184,can the blocks overlap ?
18279,are these actually * negative * log posteriors ?
18604,"some clarification might be helpful . you say want to build a 'predictive model' , what is it you want to predict ?"
18606,"i'm not sure what you mean by "" strong , linear , growing correlation "" . can you show the plot ?"
18848,"terminology like "" gender affects the relationship "" may be confusing you . with very few exceptions , people do not change their gender ( and when they do , i doubt it affects their research-purchasing patterns ) . what you seem to want to know is "" how does the relationship between x and y differ by gender ?"
19014,can you also keep count of the number of copies of each unique value in the sample ?
19158,"are these lists of * words , * of * phrases , * * sentences , * * paragraphs , * * entire documents , * or something else ?"
19216,very similar question here : url is there any more you're looking for ?
19427,how many rows of data are we talking about here ?
19629,could you elaborate on why you think the lower bound must be $ 0 $ for $ x times y $ ?
19873,"( 1 ) when you speak of pcs , am i right in assuming it is related to classical pca and not factor analytic methods ?"
20101,"is the question oen about the difference between the functions prcomp and princomp in r or about the difference between "" q-mode "" and "" r-mode pca "" ?"
20130,sufficient for what parameter ( s ) ?
20196,what is your definition ( because there are so many ! ) of convergent vs . discriminant validity ?
20469,do you have any reference or any measure on true votes ?
20545,"can we assume that the states are in a random order , and that the fitness of a particular state is independent of where it falls in the sequence ?"
20568,have you seen this ?
20638,"the answer will depend on 1 ) the distribution you expect for the concentration of each sample ( if you sample from a slightly heterogeneous solution ) , and on 2 ) the distribution of the errors of the analysis method . i assume there are usual hypothesis for this , like for 2 ) centered gaussian error , are you aware of this ?"
21109,what do you mean by significantly different ?
21115,how are your data represented ?
21214,what part of your question is not answered by [ this page ] ( url ) ?
21439,what do you suppose is the relationship between this player's probability and the probability for each of the other 1000 players ?
21484,i do not understand the question . see [ what is the difference between a population and a sample ?
21668,are you aware of r ?
21736,i'm confused with your terminology . could you give a specific example ?
21949,1 ) what are you stratifying on ?
22069,"hi there , when you say time series analysis do you mean an analysis like ` arima ` or do you mean something like a regression with a lag factor ?"
22200,how many times do you plan on doing this ?
22189,have you tried adding skip-layer connections ?
22239,"are you interested in all methods of data mining , or just one method in particular ?"
22619,what software do you wish to use for this ?
22840,what did you try so far ?
22896,"you need to explain more , with a full example ; ` mvpart ( ) ` is a complex function doing all sorts of things . what do you mean by "" tree output "" ?"
22916,"are you treating your categorical variables as categorical , or are you regressing them as if their numeric encodings were mere numbers ?"
23024,"are you desiring a closed-form solution , or would you be willing to use mcmc techniques to generate a ( large ) sample from the posterior distribution ?"
23038,why would you want to use use kernel density estimation when all the values are the same ?
23076,"to clarify , by 'distribution of random effects estimator' do you mean the distribution of the variance of the random effects ?"
23090,"is your question answered by this other question , [ is there a good reason for the name missing at random ?"
23369,"to clarify , is this text data , or audio data ?"
23808,"could you clarify "" highly skewed along some of the dummy variables "" ?"
23856,"could you explain what you mean by successes being "" in a specific order "" ?"
23873,"gschneider you asked for the jt test , didn't you ?"
24033,"could you please explain why you cannot use the "" usual approaches "" ?"
24263,"when you say "" multiple cross-validation "" , do you mean that you run $ m $ times a $ k $ -fold cross-validation ?"
24284,"hi bonnie , could you provide more details about your design ?"
24367,"the second document provides three changepoint methods : ` cpt . mean ` to detect changes in mean , ` cpt . var ` to detect changes in variances , and ` cpt . meanvar ` to detect changes in both ( with "" three distributional choices "" ) . does that not answer the question ?"
24437,in what context ?
24559,i agree with epigrad's answer . i am wondering where this term cropped up in your situation - did someone publish a paper on the test using this term ?
24680,"hi there , welcome to the site . could you post the ` lm ` code that you are using - both sets ?"
24894,we already answered that in your other post url . you just have to check inequality ( * ) . what is the deal of doing that ?
24919,why can't you use logistic regression ?
24944,"it's easy to come up with many different ways of quantifying "" similar "" in this context . it's hard to choose among them without knowing anything about * why * you seek to measure similarity , * what * you will conclude from the result , and what the possible consequences of an incorrect conclusion might be . it would also help immensely to have some kind of model , either physical or statistical , describing * how * differences between the matrices can arise . could you perhaps share some of that kind of information with us ?"
25016,. . . have you tried it ?
25190,what is the outcome you want to classify ?
25334,"just to clarify , is this the type of data : ( a ) of 1000 supermarket trips on which tide was purchased , crest was purchased on 139 . ( b ) of 300 supermarket trips on which crest was purchased , tide was purchased on 60 . if so , do you have other information ( e . g . to establish whether this is a higher than lower than normal rate ) ?"
25372,"i don't see a $ chi ^ 2 $ statistic or distribution here . the expression in the first formula is a sum of weighted squared residuals . it is not a $ chi ^ 2 $ statistic , nor will it generally have a $ chi ^ 2 $ distribution , nor does it test goodness of fit . ( if you were to replace $ sigma_i ^ 2 $ by $ f ( x_i , beta ) $ you would have something like a $ chi ^ 2 $ statistic . ) accordingly , the question as stated does not seem to make sense . perhaps you could tell us what kind of data you have and what you are trying to accomplish ?"
25603,for clarification - are the two significant relationships also significant in study t ?
25690,can you explain further what you mean ?
26236,"if you type ` help . zelig ( "" models "" ) ` you can see a list of the models that are supported by ` zelig ( ) ` . it looks like beta regression models are not supported at this time , but you might be better off asking on the ` zelig ` mailing list ( url ) . they'll be able to tell you with certainty if it is or isn't supported ( and if it isn't , what the likelihood that it eventually will be ) . is there a reason you can't do beta regression directly ?"
26261,are you seeking an authoritative answer or a collection of different opinions ?
26438,"although a section begins "" my question is , "" i cannot discern any question there . what do you need to know ?"
26712,how about [ this post ] ( url ) ?
26720,do you mean to say these x values are character representations of numbers ?
26722,what is this matrix supposed to represent ?
26841,"i'm confused about several aspects of this question . first , presumably your "" $ f ( theta ; x ) $ "" is an abuse of notation to mean $ f ( x ; theta ) $ ( for otherwise you have merely switched the names of the variables ) . but why can you call $ f ( x ; theta ) $ * qua * function of $ theta $ a "" distribution "" when it is usually not normalized ( and sometimes not even integrable ) ?"
27313,""" how do i accept an answer on this website ?"
27651,what kind of background do the audience have ?
27677,"as i do not have the access to the article at the moment , i would say that the difference is in the assumptions . if you run regression with instrumental variables you assume that some of your variables are endogenous , i . e . they correlate with the regression disturbances . if they truly are , running the fixed effects regression will not solve this , hence your estimates will be inconsistent and biased . are you looking for such type of explanation ?"
27817,"first , the margin of error given in the wiki article was based on a binary outcome with a 50 / 50 chance of success , which would have the maximal margin of error - so the margin of error is at most 0 . 049 - this same logic applies for any binary outcome , not just poll results . second , are you asking that if you sampled 400 people and the algorithm worked for all 400 people , can you conclude that the algorithm would work for 100 % of the population ?"
27831,"maybe if one estimates the link function , it could be seen as semi-parametric . also , could it be that "" the people "" mean generalized additive models ?"
27833,by two groups do you mean groups defined by their binary response ?
28165,what kind of model ?
28571,what exactly do you mean by selecting the weight ?
28605,what does it mean when you say that * * probabilities aren't correlated ?
28665,how big is your corpus ?
28921,"how is "" finding the best model parameters "" different from "" training the model "" ?"
28988,"i'm unclear what "" covariance type "" means here - what are the options ?"
29158,i'd be curious to have some more context -- why do you care ?
28715,is it time series data ?
29262,is this homework ?
29438,"the answer varies according to your reason for considering the transformation : whether it is for exploratory or confirmatory purposes , whether it is a dependent or independent variable in a regression , and so on . could you perhaps share some of that relevant information with us so we can give you appropriate , focused answers ?"
29477,are there 100 or 1000 ?
29544,"what do you precisely mean by "" bias "" ?"
29697,"do the events of type $ a $ , $ b $ , $ c $ occur before the start of the follow-up period , or during it ?"
29705,how is what you're wanting to do different from a goodness-of-fit test that your data come from the uniform measure on the $ s ^ { p-1 } $ sphere ?
29713,"also of interest : "" [ how would you explain covariance to someone who understands only the mean ?"
29756,why not transform your data ?
29932,"link is broken . can you update it , please ?"
29977,could you give the full reference of flurry 1988 ?
30087,"for clarity , is it the case that your experiment is 2 ( before vs . after ) x 2 ( condition a vs . condition b ) , eg ?"
30620,how do you get bivariate correlation for a sample vs a mean vector ?
30982,interesting question . are you considering independent entries ?
31141,"because the question is probably sufficiently challenging that there isn't an obvious standard methodology . rather than "" i want to use well-known statistical procedure x , is it implemented in r / how do i go about using it ?"
31510,have you thought of using squared correlations ?
65280,"is it fair to say that by "" relevelling "" you mean you are changing the base category for the factors ?"
69840,what's a nonparametric distribution ?
97512,"what do you mean by "" determine joint and marginal distribution "" ?"
110807,"is that the same thing as a variance-covariance matrix , also called a parameter covariance matrix ?"
197920,"as far as i know , it's still not possible . what kind of model are you fitting that nlme isn't suitable ?"
233324,couldn't you try a symbolic mathematical computation program ?
69974,"did you make sure that , when spss generates its own dummy codes with by , the reference category is the same category as the one with a value of 0 on your own dummy codes ?"
33043,does any underlying theory predict the interaction ought to be there ?
273573,something is incorrectly stated . if 12 sides pay 11 to 1 and the other 20 to 1 how can you lose ?
274853,this looks like a fairly routine textbook-style question . is this work for some subject ?
276085,could you post some code and / or the output ?
283918,why aren't you including a constant term in the model ?
20680,you want to run the model again in spss ?
22912,you just wrote down the estimator of $ beta $ . what else do you want to know ?
23313,"i'm curious even about the two-variable case . what exactly is "" shared variance "" when the covariance is * negative * ?"
25802,"pca is probably not the best method to deal with a mix of continuous and categorical predictors . are you interested in performing a separate or prior [ feature selection ] ( url ) , or are you looking after modeling strategies with some form of penalization that allow to cope with large number of predictors ?"
25785,"i guess i don't understand the dilemma . $ e ( c ) = c $ for any constant , $ c $ . multiply through by $ -1 $ and you have $ -e ( c ) = -c $ . were you asking anything else ?"
32106,the tails of the lognormal and log-t are going to be different independently of the sample . what is the goal of your comparison ?
33010,"are $ x_1 , x_2 $ correlated ?"
33499,""" best "" in what sense ?"
46325,are a and b always going to be integers ?
52318,"you are using somewhat confusing terminology , since "" test "" and "" assume "" have their own meaning in the statistics world . do you want to investigate if there are more "" 1 "" s in the left column ?"
109732,how far into the future are you planning on forecasting ?
128812,it looks correct to me ( what did you get for the endpoints ?
31495,"so the two factors in your anova are pre / post and treatment , for a 2 x 3 design ?"
31577,can you include the code you used to produce this error ?
31813,the most important question to answer is whether or not when you sampled from each stratum did you do it at random ?
31922,"since you want to find the effect of the predictors - $ x_1 , . . . , x_n $ on a univariate response $ y $ , this seems like a classical _multiple_ regression modeling problem ( not _multivariate_ , which would imply you have multiple dependent variables ) . is there any reason multiple regression doesn't do what you need ?"
32243,"david , can you explain to me please what's the difference between full matching and 1-to-1 matching ?"
32323,do you mean different approaches _to classification_ in lda for two groups ?
32432,do you have a preference for a particular software ?
32528,do you have any data / theory as to what points are outliers ?
32666,"so , just to clarify , each $ ( x_i , y_i ) sim f_i times g_i $ pair has a different distribution and you want to consider a convex combination $ h = sum_i w_i ( f_i times g_i ) $ ?"
33048,do the $ t $ 's represent times ?
33384,are you trying to predict improvements / declines based upon past performance or just determine at a given point whether there has been improvement ?
33656,could you confirm that $ z = u $ ?
33676,is this homework ?
33721,what do you mean that you have nested data as a result of having replicates ?
33778,"is a = 0 , b = 1 , c = 10 a valid coding ?"
33852,maybe a duplicate of [ is it problematic if one predictor in a set accounts for almost all the prediction ?
34065,"on the face of it , this question ought to have a routine answer in the sas manuals and help files . is there something in those references that you need help with ?"
34272,what sort of regression do mean ?
34330,does this happen for all cases of one variable ?
34354,hmm can we consider bridges that are pinned to non-zero locations ?
34479,can you explain your situation a bit more ?
35019,just a quick check : do any of the independent variables have missing values ?
35274,do you know what the conditioning event is * a priori * ( up to the values of the parameters ) ?
35299,is there a particular language you would * like * it in ?
35393,are these observations independent ?
35732,what is the point of a var in this case ?
35766,which part is unclear ?
35811,what does saturates mean ?
35999,where have you found that terminology ?
36266,what do you mean by rescore ?
37628,"well , for your data , the harmonic mean is not defined ! why do you want to use an harmonic mean ?"
38755,"welcome to the site ! to get a better answer , you might want to be more specific : what is did specification ?"
38839,did you find [ this ] ( url ) ?
38922,"pardon me for asking , but what exactly do you mean with non-negative lasso ?"
38952,are $ x_1 $ and $ x_2- mu_1 $ _standard_ normal random variables ?
38973,"what is the "" x = 55 "" in the first paragraph ?"
39268,"just interested , where can i read about why red noise is the same as ar ( 1 ) stationary gaussian process with a positive correlation at unit lag ?"
40348,"you'll need to provide more information on your dataset to get helpful answers . in particular , what do these percentages represent ?"
40515,"you say you want to compute "" the probability of this grouping being correct "" . by "" correct "" do you mean that it will naturally be separated from the rest of the data in an unsupervised sense ( i . e . it will be a cluster ) ?"
40646,"this really depends on what you are trying to get with the rankings and the nature of the artist rankings . i am assuming that there are known "" artist ranks "" , but are these 1 , 2 , 3 . . . . ( and who's number 1 ?"
40697,why not set h = 365 292 7 ?
40698,what exactly is your question here ?
40768,"do you know what k1 and k2 are , and can you calculate them ?"
40884,can you say which cv question you are referring to ?
40961,"do you mean inter-rater reliability , or are you asking whether the rater was consistent within themself based on having done the tracing more than once ?"
41023,can you clarify what you meant by writing $ y-x beta_ { neg } $ ?
41141,welcome to the site . is this homework ?
41210,are you * only * interested in packages for this in r ?
41276,can you not just calculate the r ^ 2 on each test fold ?
41368,""" ranking "" per [ everitt ] ( url ) ( at least , an earlier edition ) just means "" the process of sorting a set of variables into ascending or descending order "" . so , what do you mean by ranking ?"
41549,what does this plot do ?
41678,"beside possible lack of power ( but power / sample size should have been determined beforehand ) , what else would you like to say ?"
41714,have you looked at our [ tag : books ] list ?
41876,"could you provide more information , including what is exactly the _balance score_ ?"
43140,is this homework ?
43197,is your restricted model nested within your unrestricted model ?
43571,could you indicate what size this matrix has and what form of pca you need to do ?
43629,is that $ y_1 lt -x_1 $ or $ y_1 leftarrow x_1 $ or possibly the r code ` y1 - x1 ` ?
43955,is it atmospheric data ?
44003,have you searched the site ?
44099,* * hint * * : what the independence assumption implies on the expectation of the product ?
44133,"so if you are given i . i . d . observations $ ( x_1 , y_1 ) , ( x_2 , y_2 ) , ldots , ( x_n , y_n ) $ , can't you just form a likilihood function $ l ^ n ( lambda ) $ and then solve the optimization problem : $ max_ { lambda big lambda leq 1 } l ^ n ( lambda ) $ ?"
44256,are you confounding observations and variables ?
44385,"i think you're going to need more information to do this . eg , how often will the units be measured , once per year ?"
44461,what kind of bayesian survival analysis are you talking about ?
44469,you may find [ how to ask a statistics question ] ( url ) helpful . what are you trying to find out ?
44536,what loss function ( s ) do you have in mind ?
44748,does ` r ` know wealth quintile is a factor ?
44794,"since you have used the ` normal-distribution ` tag , which part of the problem do _you_ think involves the normal distribution ?"
45033,what distribution do you want to test against & why ?
45188,do i understand correctly that you want the confidence interval for the prediction of _one_ case ?
45466,who is the audience / what is the goal for the picture ?
45630,is this a homework assignment ?
45866,curious why you would model all of your effects as random ?
45910,"what does "" ff "" mean ?"
45979,i don't quite follow the premise of your question . are you asking how to know if your time-series data are stationary ?
45988,what makes your outliers outliers ?
46422,looks like this should be tagged ` homework ` . what have you tried ?
46502,"by $ x $ & $ y $ in the roc curve , i gather you mean the * false positive rate * & the * true positive rate * , right ?"
47115,i don't see how the sediments are important here . aren't you counting the marbles ?
47209,what are your results ?
47251,looking at the source of sm : : hsj the function looks pretty easy to rewrite in java . . . is there any reason you are not doing it ?
47353,stable = stationary ?
47429,"do you mean "" or $ h_a : mu geq mu_0 $ "" ?"
47462,"you say that you have 8 measurements per individual , but list 6 measurement occasions , can you clarify this ?"
47521,is this homework ?
47707,is this a homework problem ?
47863,you are right that the prior becomes irrelevant when you have large $ n $ . what is the sample size here ?
47902,what does it mean that f is a replicate of d ?
48042,is this homework ?
48076,many of * which * articles ?
48224,what is your current model ?
48234,as in . . . x contributed to the model ?
25724,"well , you could write you own code . . . what exactly are you asking ?"
48518,"it's good you're having trouble , because the conclusion is false unless $ k $ has some special values . what do you know about $ k $ ?"
48749,"perhaps your notation is confusing you , so let's write the decomposition as $ p' lambda d lambda'p = ll' $ . now isn't it obvious that $ l = p' lambda sqrt { d } $ where the square root is applied to the diagonal elements of $ d $ ?"
48813,what is it that you want to find out ?
48817,"what constitutes a "" good approximation "" in this context ?"
28170,"speaking about those 2 categorical variables you in effect described them as ordinal . now , what's about the rest 2 "" ordinal "" variables ?"
49125,"it sounds like you have * * multiple * * outcome measures , do i have that right ?"
49166,what area are you in ?
49391,""" . . . so i have been attempting to use qvalue r package to relax the fdr and therefore gain a greater number of significant p-values . "" * danger , will robinson ! * what is the point of gaining a greater number of significant $ p $ -values here ?"
49557,'efficiency' has a different meaning in statistics . did you mean 'computational complexity' ?
49632,"this sounds like a ( speculative , unmotivated ) answer in search of a question . what problem are you trying to solve here ?"
49867,"when you say "" multivariate "" are you referring to * multiple ( ordinal ) response variables * , or just multiple explanatory / predictor variables ?"
49871,are the group information of the observations known ?
50081,by cumulative sum do you mean rolling some with a period of k ( eg the sum of the last 20 flights late times ) ?
50129,"is the data published as a data set or did you "" scrape "" it off the site ?"
50447,"why do you call it "" linear "" if you are using a polynomial ?"
50663,is the definition given in [ wikipedia ] ( url ) sufficient for your purposes ?
50677,you want to test for serial correlation ?
50920,can you show us the data ( using graphs ) ?
50926,"could you expand what "" rct "" means ?"
51070,by q-values are you referring to benjamini-hochberg adjusted p-value or to local fdr ?
51107,is this homework ?
51453,what is _a_ in the expression ?
51501,"what do you mean by "" new observations "" ?"
51624,"if your fixed effects fit isn't ols , how did you fit it ?"
51802,"this seems rather close to your [ earlier question ] ( url ) . is this the same question worded a different way , or an actually different issue ?"
52081,"it is not obvious to me what fit2 is . for example , what do you get when you regress 30 values of y on the factor x having 30 levels ?"
55555,"it's probably best to * avoid * going about it . if that doesn't make sense / you want to understand why , it may help to read my answer here : [ algorithms-for-automatic-model-selection ] ( url ) . why are you opposed to regularization ?"
62593,do you know how each measure is calculated ?
63565,have you tried logistic regression with a lasso penalty ?
71523,they should be the same . can you post the full question ?
74367,"you should post on one site . if there is no response , delete your question then post on another . read "" is it acceptable to post on multiple sites ?"
85508,"what do you mean by "" finding which parameters of the model are likely "" ?"
87729,"would this be something like time to first , second and third infection / time to failure of three different parts of a machine / time to different disease stages ?"
131089,do you really need to apply any correction to your p values ?
210366,are you saying that you are trying to predict y and you train a linear model with log ( y ) as the output and an svm model with y as the output ?
213417,what else do you know about the coins ?
224896,do you have data that includes weather catastrophes ?
68100,"online documentation indicates the degrees of freedom will be $ a b-2 , $ where $ a $ is sample size of numerator and $ b $ is sample size of denominator . why do you think it should be 1 degree of freedom ?"
276553,"that could be a reasonable interpretation , but it would be case-specific . would you expect the stores to be all ( or mostly ) competitors ?"
284603,"what do you mean by "" true type i error rate "" ?"
287473,can you define the columns / attributes in your dataset before and after the aggregation ?
300343,you cannot say beforehand what the best model is . this also depends on the goal you want to achieve . are you only interested in accuracy ?
47815,i'm afraid i don't understand the question . could you restate it or elaborate it ?
48527,can you be more specific ?
158410,"when you say "" we "" who are you including ?"
32431,what do you mean under ` nonlinear regression . . . with the help of genetic programming ` ?
32552,can you describe your data a little more ?
38578,what software are you using ?
43867,"it looks like this is part of a chapter on discrimination between sets . in your first pair of graphs , the one on the left clearly doesn't distinguish well between the three sets of points . does that answer your question ?"
46594,welcome to the site . do you mean that you actually have 120 questions ?
48495,what is the dimension of said variable ?
51153,did your variable fulfill the assumptions of t-test ?
61612,this is easy to answer for thresholds $ t le n $ --you're just computing volumes of hyperspheres--but more difficult to work out for $ t gt n $ . are you in either of those situations ?
53340,could you be more precise ?
53333,"couple of books that you might be interested in "" what if there were no significance tests ?"
50825,are you at all familiar with prior distributions and posterior distributions ?
59100,"i'm not sure what you mean here , what k = 1 means ?"
60216,it's certainly * possible * ; the questions are more 'how' and 'does it have the properties you want' ?
68799,please clarify this question : what setting do you have in mind where we cannot estimate a population variance ?
71330,do you have the source of that statement ?
71976,"if you were given just the formulas for these functions and not told that they were cdfs or pdfs ( in fact , suppose that you had no knowledge whatsoever of probability and / or statistics ) , could you find the partial derivatives using standard calculus techniques such as the chain rule ?"
73173,"who considers the first order statistic to be a good initial estimate of a location parameter , & in what context ?"
74358,having read the snippet provided i'm not sure what algorithm you mean . are you referring to the calculation of $ inst ( h ) $ given in equation ( 2 ) ?
74743,"what do you mean by "" important "" ?"
76635,what is sbc ?
81251,how are these graphics supposed to work ?
52721,it is important to hear _why_ you see such data problematic for you . something made you to post the question . what was that ?
52935,"because there are many ways to "" make a nonlinear fit , "" please provide some details of what you are doing , including what program you are using . ( doesn't the program's documentation explain its output ?"
53033,how many survey responses do you have ?
53377,""" ceptrum "" = [ "" cepstrum "" ] ( url ) ?"
55321,what is the end goal here ?
55772,"you say that the questions have been marked as right or wrong , but are there multiple questions ?"
55862,nsc10 where exactly did you get stuck ?
56042,1 ) uniform on what ?
33928,i wonder if ( multiple ) correspondence analysis would allow you to do ( 1 ) and ( 2 ) ?
56156,why would you look at the entire genome when you have a control for the region that you know you are interested in ?
56226,maybe you're thinking of ` plm ` ?
56442,is this homework ?
56481,are the seasons the same length ?
57165,did you try to email the authors and ask ?
57258,"how is "" a curve "" defined ?"
57307,"welcome to the site . i have tidied up your question a little . please check the faq , especially the later part of the section relating to [ asking questions ] ( url ) , where it relates to homework . please add the ` self-study ` tag and read the [ self-study tag wiki ] ( url ) . with those pieces of information in mind . . . what do you understand about the pivotal method and what have you tried ?"
57684,"the question asks about alpha , the final line about lambda . i might be missing something , but is this a typo ?"
57938,"to what "" bulging rules "" are you referring ?"
58096,have you tried ` tseries ` or ` tsa ` packages ?
58121,is the range always the same ?
58136,i gather your response is binary ( positive vs . negative ) . what is the status of your explanatory variables ?
58371,are these paired measurements or not ?
41441,do you have any basis at all to convert poll results to probabilities ?
58406,did you mean to say $ f ( 0 ) = 0 $ instead of $ f ( 0 ) = 1 $ ?
58479,did you learn russian ?
59046,welcome to cv . i don't recognize the upshot of your question . why couldn't you just use standard regression ?
59134,how do you pre-process your datas ?
59359,where is your model with random effects ?
59421,"excuse me , why did you delete the plot i went to the trouble of including for illustration ?"
59631,"when you add a constant to all values , that changes * only * the mean and not the sd . when you rescale all values , that changes all moments but in a predictable way . in particular , it will not change the mean if the mean is already zero . so , why not ( a ) shift the variable to make the mean zero , then ( b ) rescale it to make the sd equal to 10 ( leaving the mean equal to zero ) , then ( c ) shift the mean to 5 ?"
59755,have you read this [ documentation for the changepoint package ] ( url ) ?
59823,have you had a look at rpois ( ) ?
60004,how are the $ x_i $ ( cor ) related ?
60024,do you get any error messages or warnings ?
60037,"to my eye you seem to be conflating different things , but it might just be a difference in terminology ( different areas often use terms puzzling to others ) . can you point to an example of a "" gaussian process "" itself being called a "" smoother "" , rather than say a computation applied to the output of a gaussian process ?"
60246,"i get the impression from some of your responses under my answer that you're in communication with a third party , perhaps a supervisor or some such , relaying answers and responses to them . is this the case ?"
60260,"woudldn't the best threshold depend on the data . if you have only univariate data , then gini will say "" cut all but the information-holding variable "" . if your variables are all equally informative , wouldn't gini say "" keep them all "" ?"
60376,"are you talking about doing a meta-analysis on a series of experiments , or testing if several groups differ from each other where you have a series of observations w / i each group ?"
60355,not sure to understand . does that mean that $ n_3 ( t ) equiv 0 $ when $ v_1 geq c $ ?
60418,are you talking about classification or regression ?
60537,"can you not have something like "" if value = = missing then value = mean ( feature ) "" ?"
60549,do you mean $ e [ x mid x ] $ ?
61400,the first call to mva . pairs is conventional . we compare each array to a reference array ( synthetic in some versions ) . the difference between each array and this reference should not depend on avg expression . i am not familiar with the second version . you have computed a fold-change based on a phenotype . is there any expectation that this should not relate to avg expression ?
61582,can you be more specific about the nature of the data and especially the intention of the mapping ( a visualization ) ?
61649,"you may already know this , but maps with zip codes are going to be odd . there are some zip codes that are a single building and that have no residents . the largest zip code , 89049 is over 800 square miles . what is the purpose of this map ?"
61682,$ ( mu- frac { delta ^ 2 } { 2 } ) t $ correct ?
61742,"because it's unlikely any such transformation can be found , may i ask instead why it even matters ?"
61918,do you have a single website that you are changing / manipulating yourself or are you testing a collection of real websites ?
61932,what specifically do you want to measure ?
61944,have you tried _anything_ at all to find the answers ?
62059,what do you want to do with the model ?
62127,where can we find the ` matcor ` function ?
62220,are you saying that you have an n of about 5 ?
62227,is this a question ?
62337,what were the numbers ?
63010,$ x_j $ is the same for all $ i $ ?
63221,"if you take the log of the dependent variable , then you lose all observations with zero , i . e . , 50 % . i wouldn't do that . what is the ratio exactly ?"
63472,"what are "" x and y wind speeds "" ?"
63537,what is it that you actually need help with ?
63698,what package / function do you use to fit the gee in ` r ` ?
63764,thanks for the explanations . a few comments : 1 ) why do ` y1_real ` and ` y2_real ` not have indices when calculating ` y3_real ` ?
61907,"who is "" field "" and where is this said ?"
63941,"regarding the cfa , might your problem be solved by dropping a problematic item ?"
64335,"your question seems pretty broad ( i . e . , how do you analyse data ?"
64437,are you asking if there's an analog of ( say ) cohen's kappa for interrater reliability when you have only one rater ?
64666,` gower's similarity coefficient is generally not compatible with ward's method ` you might have also read that it is not comatible with k-means as well . because k-means and ward are relatives . won't you prefer k-medoids in place of k-means ?
64694,"ss of deviations ( "" error "" ) from _what_ ?"
64738,why are you doing median splits ?
64953,"in your actual problem , is the thing you want to predict cyclical ( like time ?"
65017,what software are you using ?
65252,what hypothesis do you mean to test with the t-test ?
65578,what type of sequences are we talking about ( continuous variable or discrete ?
66051,"ttnphns testing and estimation are different concepts : parameters can be estimated without any test being performed ( * e . g . * , many opinion polls provide only parameter estimates and no tests ) and not all hypothesis tests require anything to be estimated ( * e . g . * , what is the kolmogorov-smirnov test estimating ?"
66110,"what does "" cte "" mean ?"
66191,what are your performance criteria ?
67047,"did you mean "" the best curve [ . . . ] is _not_ a horizontal line "" ?"
67058,did you have a population measure of association in mind that you want the new sample to have ( presumably one like the sample measure on the target sample ) ?
67198,"are you asking if it makes statistical sense to do this , or how to write the code to do it ?"
67371,"isn't this result immediate , given that the output of $ f $ is a weighted average ( i . e . , a * mixture * ) of identical distributions ?"
67017,"what does "" unreliable "" mean here ?"
67430,sounds like a case of [ simpson's paradox ] ( url ) ( - see the diagram in particular ) . what are these subsamples ?
67661,something like ` mmps ` in package ` car ` ?
67671,reference for your statement ?
68377,"babakp perhaps the user was referring to the change of sign in the second derivatives , which is also referred to as curvature ( imprecisely ) ?"
68562,why not take it at face value ?
68792,is this with unknown scale and location ?
68803,"do you mean literally you will say "" the die is biased "" or will you provide an explicit prior distribution for your belief ?"
69251,"i'm pretty new to pca myself , but do you think it could have anything to do with the fact that there's a second component ?"
69257,it's not particularly clear from your discussion what you're really aiming to capture there . the difficulty is one could sit here making a hundred guesses about what you want ; i think you need to be able to articulate its properties more completely . what underlying problem does this solve ?
69498,"a proof is a sequence of statements each of which is deduced logically from its predecessor . to start a proof you therefore must have a set of * assumptions * and definitions . what , then , are you assuming as the start of your proof ?"
69599,what can you tell us about your population ?
69947,so each item has one correct answer and 4 incorrect ones ?
70166,"i'm guessing that something bayesian would be appropriate . without any data on the hypothetical unobserved sides , you might have to inject some kind of prior belief . can you clarify what are at least two of your possible candidate models ?"
70830,"what does "" tanking "" mean here please ?"
70909,"what do you mean by "" adjusting model likelihood by aic "" ?"
71106,what is the cost in your case ?
71141,how did you derive a ratio when there is only one case ?
71328,"what do you mean by "" p-values "" ?"
71413,do you have interaction terms ?
71439,how long are your time series ?
71535,"just to clarify , are you talking about single items with 4 and 7 response options respective or scales that are the result of taking the sum or mean of a set of items where each item happens to have 4 or 7 response options ?"
71681,is this the exact question ?
71799,"repeated measures anova makes strong assumptions , especially sphericity , that are unlikely to be met in longitudinal data . have you considered a multi-level model ?"
72046,are those pairs of coordinates indexed by time ?
72173,"what do you want to obtain from "" regression "" ?"
72217,hypothesis testing and calculating distances is not quite the same . so i wonder if you could be more precise ?
72511,"are you after a basic but general discussion of mcmc overall , a description of a specific kind of mcmc , or a specific discussion of it in relation to your problem ?"
72529,what are you trying to do - perform a test or estimate something with an associated confidence interval ?
72554,$ int f ( x ) ^ 2 dx $ is also $ mathbb { e } [ f ( x ) ] $ where the expectation is with respect to $ x sim f ( x ) $ . does this help ?
72686,what do you mean by apply to real life ?
73052,"with this sort of question it is important to consider whether balls are replaced after drawing . would you a ) replace each ball before drawing the next one , or b ) for approach 2 , replace the balls after each sample of 50 , or c ) not replace at all ?"
73159,"just out of curiosity , why are you constrained not to use stirling's formula ?"
73253,consider any $ t infty $ . is $ text { var } ( y_ { t 1 } ) = text { var } ( y_t ) $ ?
73378,what happens to the polynomial and its roots when you plug in $ 1 / u $ for $ lambda $ ?
73460,is $ sigma ^ 2 $ assumed to be known ?
73566,"could you please be more specific about the "" files "" and what you mean by "" whether files are different "" . e . g . , in each file do you have a univariate time series and you'd like to know whether the trend of each of these time series is different or something similar ?"
73743,"ladislav in your answer it would be helpful to compare your recommendations with standard methods of spatial analysis such as the [ ripley cross-k function ] ( url ) . confeco , the approach you should take depends on the nature of the data : are they an exhaustive census of a region or are they samples ?"
73896,notes for what ?
73899,"how do you propose using numerical integration , given non-numerical $ a , b , c $ and $ d $ ?"
74312,does $ d-c $ equal $ b-a $ ?
74385,"what exactly do you mean by "" mapping "" ?"
74600,"which assumptions are faulty , and why are they less faulty if you use the census ?"
74788,it depends on the purpose : why do you need a single scale ?
74833,this reads like standard bookwork for a basic subject on distributions . is this for some subject ?
74993,the peremptory tone of this question suggests it is [ tag : homework ] . what steps have you taken towards an answer ?
76086,what is ` clusterg ` ?
76290,have you checked the data that you are inputting ?
76440,"you could just draw the densities - you don't need simulated values . try the following and check the various arguments ( and examples , where relevant ) - ` ?"
76487,there are numerous threads here on likert data . did you look at any of them ?
76543,ttnphns have you got a good example ?
76557,"if you are asking for a way to get the information then i think your question is off topic . if you want a way to * analyze * information that you already have , then it is clearly on topic . can you clarify ?"
76583,what are you actually trying to do ?
76657,"hmm , how did you find the distribution of $ dfrac { 1 } { hat { beta_0 } } $ ?"
76721,have you considered effect of end-points on forecasting accuracy using emd ?
76783,300000x300000 matrix ?
77035,what technique ( s ) are you using for feature selection and classification ?
77173,"you are approaching this the wrong way . a graphical representation is not always the best way to look at things . variance is just the square of the standard deviation , which you already understand . a better question is : why is the square interesting enough that it has its own name ?"
77253,how would you answer the same question in a linear regression without complex survey design ?
77343,will this be a cox proportional hazards model ?
77694,what tests would you do for the comparison of just two ?
77647,is this homework or self-study ?
78007,are you adding fixed effects terms to an existing ols regression ?
78030,can we assume that the support of $ d $ is always included in $ mathbb r ^ { ge 0 } $ ?
78372,"do you actually have access to raw data , or are you trying to make this inference just based on the given figure ?"
78422,this is very broad . . . . perhaps too broad . can you narrow it down ?
79695,you're asking about estimating odds ratios in 2x2 contingency tables ?
79959,question that is a hint : how many standard deviations does a 95 % ci of a standard bell curve ( aka a normal distribution ) cover ?
80159,is $ a = 1 $ a requirement ?
80500,are all the observations statistically independent ?
80738,"probability that when they die , it will be their birthday ?"
83272,what are n and p ?
85622,can you be more specific ?
85994,can you spell out sols ?
86156,do you know that $ e [ ( a-bx ) ^ 2 ] = a ^ 2 -2abe [ x ] b ^ 2e [ x ^ 2 ] = a ^ 2 -2ab mu b ^ 2 ( sigma ^ 2 mu ^ 2 ) $ ?
86422,wouldn't it be the variance of the binomial distribution ?
90424,"does "" millions of those "" refer to the number of observations , or the number of predictors ?"
92777,just to clarify - you have data collected every 4 seconds over 3 days ?
96060,for 1 . -- in what way ?
121713,what do you mean by k-d ?
256905,what other studies do you mean ?
285909,statsstudent can you elaborate on it ?
287048,what for do you need it ?
313560,do you know anything about the shape of the distribution aside from what you can infer from those 3 values ?
68856,what kind of process produces your data ?
69532,i'd say yes . but can you give some context ?
80167,where did you encounter this term ?
63442,"nah , i'm just working on a 38 x 500000 ( 500k ) data set , pca and even more complex methods work beautifully . what do you want to test with your anova ?"
64877,usually $ -2 . 615 times 10 ^ { 5 } $ . see e . g . url ( p . s . did you copy this exactly ?
66733,"i guess that bi visualization means "" business intelligence visualization "" . is this correct ?"
77689,"how do you define "" important / dominant "" ?"
78918,"i'm assuming a and b are random variables , correct ?"
79560,"knowing sample sizes doesn't help here . statistical theory tells you that , other things being equal , bigger sample sizes are better , but you can't put a number on how much without knowing the variability . furthermore , are the costs and revenues associated with each click independent of each other ?"
79625,"could you please provide a reference to that "" somewhere "" for those who are struggling to understand exactly what it might have said ?"
89481,you don't mean b2-b1 ?
89523,which assumptions specifically do you believe are violated and what are you attempting to accomplish with this regression ?
89718,what's the problem with such a situation ?
90727,why can't you use dummy categories ?
90869,are you after something like a ( binomial ) [ confidence interval for a proportion ] ( url ) ?
92225,how many participants ?
92442,what have you tried so far ?
101066,then you'll slide the window one month and do it again with the last as test ?
93812,how were the estimates obtained ?
104714,"if the real question's "" should i exclude those values ?"
107616,[ spearman's correlation ] ( url ) seems appropriate ?
109712,"i'm not sure i undestood your question . do you want to know the calculations that yield the residuals from an arima ( 0 , 0 , 1 ) model ?"
114034,see here - url for how to do the calculation . reference each cell that respectively gets you ` a / b / c / d ` - ` ?
114153,why do you want to * classify * with an unsupervised algorithm ?
115780,"what do you mean by "" 10 runs "" ?"
125398,just to clarify : are rows your samples ( not features ) ?
125493,have you considered [ kernel density estimation ] ( url ) ?
139675,that's an interesting comment . could you perhaps say a few words about what the two different interpretations would be ?
18430,biplot ?
24767,what is * c * ?
35040,"mark , could you please clarify an important distinction ?"
78469,it sounds like you have unbalanced traning data set . can you provide frequency of the miss and hit classes in training data ?
78472,shouldn't it be the sum of $ 1 / x_i $ ?
78935,"what are "" eps "" ?"
79110,can you elaborate further ?
79217,"the right method ( a ) matches your ideas of what you are estimating and ( b ) works well with your data to the extent allowed . ( not all samples have well-defined modes ; no white magic will extract a worthwhile estimate in those cases . ) that may seem a worthless answer , but you haven't given enough information to allow guidance . why do different methods exist , any way ?"
79277,what you mean by svd ?
79353,please try to give a more formal definition of what you want to achieve . you want to order a list by two rankings : are these rankings consistent ?
79403,you're doing one sample t-tests on data that can only take three values ?
79426,is the null that the population proportion of hits is the same for the two groups ?
79475,why does the fact that the survival curves never go below 80 % mean they aren't informative ?
79477,perhaps he / she means 9 % ?
79582,i think you mean $ frac { 1 } { n } cdot sum_ { i = 1 } ^ { n } ( r_i-c ) $ for * income * ?
79584,what do you mean by 'best' here ?
79864,what's an ma ( 2 ) model ?
79848,why not ?
79971,welcome to cross validated . what exactly are you stuck on and what work have you done so far to solve the problem ?
79972,where is $ q $ in your code ?
79980,[ baum-welch ] ( url ) is capable of estimating the initial probabilities along with the transition and emission matrices . but i guess you opted not to use it . is there a specific reason why the initial probabilities are important ?
80036,do you know any info on counts ( eg total sample size ) ?
80110,i do not understand what kind of association could be there in bootstrapping and effect-size weighing ?
80212,in what form are your cdfs represented ?
80608,how is the rank calculated ?
80809,( i ) why is 'algorithms' one of the tags ?
81019,not sure that i understand . do you mean the cross-correlation function ?
81017,"if there is a formula it is certainly not simple . furthermore mape is a very bad fit statistic for $ delta log ( y_t ) $ , since you should have a sizeable amount of values close to zero , which should make mape large . also do you claim that mape is normal , or $ delta log ( y_t ) $ is normal ?"
80995,how would you start ?
81316,"when you say you 'standardized the scores of a variable' do you mean you standardized the components before adding them , or you standardized the result after adding them ?"
81069,"the posterior is the proportional to the prior times the likelihood . now , think of a multidimensional prior and likelihood . do you think it will be in general tractable ?"
81478,so what is the question ?
81542,so are you estimating the parameters with ml or mc ?
81556,you need to say something about the nature of your data and the domain of your problem . is there some source of heterogeneity you haven't accounted for ?
81705,is this a [ tag : self-study ] question by any chance ?
81794,have you had a look at [ gibb's inequality ] ( url ) ?
82014,sounds like you know exactly what you want to do . what's stopping you for building the model ?
82513,is it a balanced design ?
82601,how are these values from the 'theoretical' distributions obtained ?
82690,"by inefficiency equation , are you referring to the rule of thumb which one estimates through regression relating efficiency of , say , extracting critical information through torture ?"
82930,are your ivs binary or just integer valued ?
83494,you seem to be asking for an algorithm to compute sums of squares of distances . is that really your question ?
83618,"it sounds like mathematica might do what you want . do you mean * open source * software "" that would solve complicated matrix expressions "" ?"
83663,research papers in statistics or allied disciplines ?
83804,lifereg is not the name of a model . don't think of sas as life . are the predictors such that they should have a constant effect over time ?
84026,"are you perhaps thinking of maxdiff , i . e . , best-worst scaling ?"
84357,what was the point of turing movies' income into a 5-level ordinal ranking ?
85721,can you tell me in what book or paper you saw this formula ?
85755,"what is "" c4 . 5 "" ?"
86004,what broad area of economics do you work in ?
86161,can you show your work on a and b ?
86300,what exactly is your question ?
86347,"it sounds like you're "" correcting "" your independent variable . if so , * why * ?"
86504,is your twelve dimensional data or some transformation thereof approximately multivariate normal ?
86569,"welcome to the site . i removed your signature , as it is automatically added . what is it you are trying to do ?"
86612,do you have linkages ?
86844,wouldn't you want $ c ^ 2 $ to appear in the expressions in the denominator rather than $ c $ ?
87293,"i'm not completely sure i understand your description , but it sounds like you're trying to construct some kind of interval for a poisson mean for some unobserved time period based on a sample for some other time period . is that correct ?"
87294,""" does this affect the validity of the parameters it has come back with ?"
87353,"following the links through [ tag : conditional-expectation ] provides plenty of useful information , such as the linearity relationship at url something looks not quite right about your last line : how did the condition on $ x = x $ magically disappear ?"
87494,do we know the messages are equally frequent ?
87714,"to what "" time "" do you refer ?"
87762,"welcome to the site , jay . did you probably mean permutation test ?"
87909,why is age not in the model ?
87986,"if it isn't stationary , have you considered first differencing the time series and checking again for stationarity ?"
88291,what is the dimension of $ beta $ ?
88507,how many groups are you trying to classify the data into ?
88902,i don't find the wording clear here . are you testing for normality but want your test to be robust in the face of non-normality ?
89515,"what do you mean by "" $ x_1 $ is the main effect "" ?"
89697,could you tell us what you've tried so far and where you get stuck ?
89725,"the best way to graph this will depend on what assumptions you are willing to make . in particular , are you willing to assume that sales are not seasonal ?"
90100,do you have any other siblings ?
90340,instead of the knn predicting a class you want it to predict an array of probabilities for each class ?
90339,do you expect what happens under each condition to be independent of what happens under every other condition ?
90441,"my apologies , i'm new here and it doesn't allow new users to comment unless you have 50 reputation so i'll try to answer your question but if it's not clear , please let me know . it seems that you want to find out the time you have to leave the house to get to work on time . is it correct ?"
90532,"so your dependent variable ( defect density ) is right skew , right ?"
90563,what's the difference between the case and the control ?
90822,"that depends on what property of the groups you wish to investigate , and you said nothing about that other than that you wanted to "" compare "" them . specifically , do you want to test something like $ h_0 : p_1 = p_2 = p_3 $ versus $ h_a : exists , i ne j ; s . t . ; p_i ne p_j $ ?"
90999,"( 1 ) this sounds a lot like [ routine bookwork ] ( url ) , as might be set for an assignment . ( how does this question arise ?"
91050,"do you have a specific method in mind for measuring similarity between two sets of gene targets , or is that part of the question ?"
91220,is it accurate to describe your data as essentially a 6-row by 3 column contingency table ?
91143,please explain the sense in which you are modifying sample sizes . are you trying to compare p-values for two independent experiments of different things or are you instead perhaps contemplating the possibility of augmenting a sample of size $ 45 $ by collecting $ 120-45 $ additional independent observations ?
91351,what is the mean of a categorical variable ?
91689,could you define more mathematically this markov chain ?
91762,"better to search for "" anova "" than "" anovar "" . does this help ?"
91803,why would you want to do such a thing ?
92014,( 1 ) what are the units in which each coefficient is measured ?
92234,maybe you are using wrong sample sizes ?
92419,what do you mean by themes ?
92429,"if you mean that you correlated the price of a stock ( level ) w / another variable & the percent change in the price of a stock w / the other variable , & got different results , that is to be expected , b / c they are different questions . can you clarify ?"
92750,the help for the function ( ` ?
92796,what books are you reading ?
92872,"how exactly do you define probabilities "" $ p $ "" in terms of integrals in the first place ?"
92902,"what method ( s ) would you use to "" just analyze this as ordinal "" ?"
92999,what do you mean by ` original kmeans ` ?
93330,"i've had a look at the expectation expression , and i fail to get it equal to $ int_0 ^ { infty } e ^ { -x ^ 2 } text { d } x $ . could you possibly demonstrate the working for that so that we can check it ?"
93383,"why not just calculate this directly from the normal equation , then plot the resulting function ?"
93444,would you be so kind us to provide us the r code you've been using ?
93529,which chow test do you mean ?
93564,"what do you mean "" test "" here ?"
93718,would regularizing the problem and attempting to enforce sparsity help ?
93773,"show your code , maybe ?"
93777,did you see researchers including all three in the models ?
93779,do you mean using the new ` simplan ` procedure ?
93849,"you mean , knowing _only_ $ beta_1 $ and not the other coefficients related to the other regressors ?"
93900,your question seems to end mid sentence . did you lose part of it ?
94109,"picking up on whuber's comment and deathkill14's answer , you have not given us enough information to answer properly . it's important to know how the errors in measuring $ x , y , z $ "" work . "" for example , if the error measuring $ x $ was positive at 3 seconds , it it more / less likely to be positive at 4 seconds---i . e . is there serial correlation ?"
94317,"think about this , what values can $ x $ take on ?"
94320,what is your response variable ?
94379,do you have a measure for how latent they are ?
94583,". . . ctd for example , are you trying to estimate an average ?"
94648,"i suppose your problem is not related with $ o ( n * k ) $ directly , but with the fact that this time is multiplied with the the time of a distance computation ( which is usually expensive ) . there are to general solutions since the problem is hard . thought some heuristics might be applied . to give a proper answer * to your specific problem * , give some further details , please . how big is $ k $ , how big is $ n $ , what kind of distance do you use ?"
95032,"where did you read that "" glmm's won't perform well like that "" ?"
95112,i am wondering if your question was ( a ) why does eigenvalue decomposition of a covariance matrix maximizes variance ( i . e . why do we use eigendecomposition for pca ?
95281,which bias are you referring to ?
95290,two questions - what is the first plot showing ?
95846,"please be aware that p-values and statistical significance differ greatly from classification accuracy . see , for instance , url so , your cross-validation accuracy is 81 % . whether that's "" good "" or "" bad "" depends on your application and your objectives , about which you have told us little . your question therefore does not seem to be answerable--and even if it were , it would likely come down to a matter of opinion . could you edit it to clarify these points ?"
95918,"could you do a plot of your data , perhaps ?"
96618,is each judge treating just one applicant ?
97240,is this homework ?
97290,( 1 ) what exactly would your data look like ?
23006,how large a data set do you have ?
97445,what model are you fitting ?
97668,are you referring to ehler's supersmoother ?
97760,forgive my confusion ; what level of significance are you looking for if not the $ p $ value itself ?
97850,what is the likelihood of your data ?
97877,do you have reason to believe that the matrix has low rank ?
97902,is this a statistical problem ?
99206,what exactly do you want to use this measure to do ?
99461,"you observe the n largest samples , but do you know how many samples q were drawn in the first place ?"
99759,"what does "" true variability "" mean ?"
99782,how would a mixture model deal with the problem illustrated by [ simpson's paradox ] ( url ) -- essentially a consequence of omitted variable bias ?
99911,what do you hope to accomplish with this ?
100001,i am not sure what you want here . you have 30 people with a rare disease . each has 20 features . fine . what is it you are trying to find out ?
100306,"you must define your terms ! what do "" evidence "" mean for you ?"
100414,"are you wondering how such correlations are calculated ( ie , how to arrive at the number ) , how they are tested ( ie , if they could have come from a population w / o any correlation ) , or what they mean ?"
100873,""" probably normal distributed "" - plot them ?"
101110,what is the sample size you are working with ?
101329,sorry but i don't see why for each $ j $ we must have that $ sum_i theta_ { ij } = 1 $ ?
101499,see [ does a huge difference in the number of observations in a dummy variable influence its regression result ?
102856,what is cem ?
103091,what exactly did you test for ?
103115,so you know the chunks of points you want to test for straightness ahead of time ?
103167,"when stata fails to converge , does it tell you anything about what went wrong ?"
103260,"that seems fine , what is your question ?"
103361,"when you say "" these values are different from one another "" my immediate reaction is : "" is the units place the same ?"
103783,what is the aim of this compsite score that two different ranks of the data you have do not solve ?
103821,is this a homework problem ?
103946,"you have chosen an interesting way to index agreement . do you see an advantage of your approach over percent choosing a , b , or c for each cx ?"
104103,"in order to draw a random sample you need to specify the distribution from which these samples need to be drawn , e . g . a normal distribution , gamma distribution , laplace distribution , . . . so , which distribution do you want to use ?"
104239,"what are the possible values of $ k $ and $ n $ and how should we interpret "" best "" in a quantitative way ?"
104260,"you want to communicate the false positive rate , or the positive / negative predictive values ?"
104277,any chance you could upload the plot ?
104336,can you show that $ hat beta $ is normal ?
104497,how is functionally independence between random variables defined ?
104563,what's $ sigma ( x_i ) $ ?
104721,what do you mean by hac / hc1 ?
104788,you are trying to predict category ( 1 or -1 ) from ratings and words ( called documents ) . you seem to be stuck on how to use the ratings to predict category . have you considered plotting the data to see if there is any apparent relationship between rating and category ?
104815,metropolis-hastings can sample using proposals for a conditional . are you referring to a particular * kind * of mh ?
104899,your question is unclear . can you give more detail about what your data consist of ?
104915,could you please edit your question to include your comment ?
105189,"could you use a survey sampling approach , like in polling where the researchers don't have access to the entire population ?"
105669,so to clarify : are you interested in the distribution of artist counts ?
106003,how far below $ 0 $ could $ x $ go ?
106172,"how can variance be "" less than -1 "" ?"
106310,& $ pr ( x_i 0 ) = $ ?
107503,how about performing pca on the pattern dataset and then projecting each pattern onto pc space ?
107852,is this a lagrangean optimization ?
107876,"i'd say find a model of an economy with no banking system and build off of that . out of curiosity , would you mind saying what game ?"
108281,what are the types of the variables ?
108311,what is the purpose of the normalization ?
108258,what do you edge weights represent ?
108329,"yes , and it's easily calculated . but since this is [ routine bookwork ] ( url ) , i have to wonder if this is for a class or something similar . how does this question arise ?"
108391,"added some latex , see if it says what you want it to . your second equation seems incorrect ; combining it with your first equation it says that $ x ( t ) = x ( t ) -x ( t-1 ) $ , is that really what you mean ?"
108649,what are you trying to achieve ?
108700,are you sure that the peak you see in figure 2 an error ?
108735,"i don't really follow your question , can you say more ?"
108949,"maximum likelihood may be possible . however , ml estimators are not unbiased in general . you have some data that is called right-censored . do you know anything about the distributional form of your time-to-event data ?"
109149,may be this is biological question in addition to statistical question ?
109214,"at a fixed sample size , this would be a matter of comparing statistics that measure deviation from normality ( whether shapiro-wilk , anderson-darling , or whatever you feel captures what you want to capture ) . it would be difficult to compare across different sample sizes without a much more careful identification of what you're trying to achieve , which * might * help you identify a suitable metric . why is it important to compare how normal they are ?"
109471,"what do you mean by "" [ . . . ] predict the * * collectability of debts of a given debtor * * "" ?"
109666,why not storing your processed training data in a database ?
109798,did this help you get the desired behavior ?
109813,are you trying to test the association between the two variables or are you trying to see how this association evolves over time ?
109824,possibly of interest : [ is it possible to have a pair of gaussian random variables for which the joint distribution is not gaussian ?
109859,what does ` nonlineartest ` do in splus ?
109875,"when you say "" restore "" , what do you actually mean ?"
110443,"trouble with this question is that without any limitation of its scope the answers are endless - stock controller , biochemist , quality engineer , archaeologist , & c . what's the point of it ?"
110469,why would you do such a thing ?
110530,"when you said "" known "" , do you intend that the means and variances are known realizations of random variables , or that they are not random ?"
110557,is this a self-study question ?
110617,can you provide a citation of the use of $ sigma $ you want to understand better ?
110618,what do you want ?
110901,"what is your definition of "" session length "" and how is that related to visits per minute ?"
110904,i'm not sure i understand the question . you want spss to impute any possible values except 8 ( not applicable ) ?
111106,"please explain what you mean by "" upper and lower bounds . "" are you perhaps seeking a confidence interval for the cv based on a random sample ?"
111397,do you have time series / panel data ?
111555,"you say that you "" do not manage to get a result using r language . "" what function have you been using ?"
111941,are familiar with utility from economics ?
111986,"at least one of your variables is ordered ; you may get more power if you account for ordering . what do you mean by "" which one "" ?"
112222,what do you mean by indices ?
112383,do you mean how to construct roc's when there are 2 * * models * * ?
112459,will the correlation between the new sample and all the other samples be given ?
112532,how does this relate to k-means ?
112659,are you sure that the waiting room holds only $ 2 $ persons ?
112694,"please provide us a context to understand this question ! what are "" a "" and "" b "" and how are these quantities related to "" growth rates "" ?"
112723,is there a particular algorithm you inquire about ?
112772,is your goal prediction or description ?
112790,why do you want to combine them ?
112804,cross-validation ?
112876,"yeah , there exist many statistical tests / coefficients identicies . every advanced statistician has tended to invent or "" invent "" his own . quede test ?"
112992,presumably you'd want some kind of model for the daily data ( are mondays different from thursdays ?
113284,define what is considered a noisy label . instance duplicates with different labels ?
113432,do the rates look normally distributed ?
113436,do you have a rough idea of the size of the proportion $ y $ ?
113464,you say widely varying p-values but are they all non-significant ?
113472,"when you say "" proc autoreg "" are you talking about sas ?"
113510,how is this related with roc ?
113518,"you have three variables ( year , output , capital ) . are you interested in the relationship between output and capital , or is it their individual behaviour over time you care about -- or something else ?"
113554,that's odd . when a variable is discrete it is impossible for it to be gaussian or to be transformed to have a gaussian distribution . any why not use statistical methods that are dedicated to ordinal data ?
113556,what fraction of observations have complete data ?
113594,why didn't you include the intercept ?
113599,do you think you could explain your data set a little bit more . how does before and after relate to believes ?
113624,"when you say "" such as in spss "" do you really mean "" in spss "" or do you mean ( as it appears to ask ) "" in some statistics package , of which spss is an example "" ?"
113799,what are the values themselves ?
113839,internally or externally studentized ?
114103,"i don't understand the statement , "" the diagnosis codes may be different for some of the billed amounts "" . can you clarify what that means ?"
114193,is your question only about why the code is behaving this way ?
114249,"` a greater than b greater than c greater than d ` so , the categories are ordinal , not nominal , aren't they ?"
114304,when you mention a function it's best to state which package it's from . do you mean the ` survdiff ` function from ` survival ` ?
114337,"i'm trying to clarify . you have x ~ normal ( 0 , y ) where y ~ gamma ( 1 , 1 ) ?"
114376,what is the support of $ x $ ?
114396,"is the range you have restricted relative to the population , or relative to the possible range ?"
114614,"since $ h $ and $ s $ are dependent , the assertion that their joint distribution is also normal is an _additional_ assumption . do you make this additional assumption ?"
114742,"if your interest is in the intercepts themselves , you may want to use fixed effects . w / random effects you can't get estimates of the paramters , only predictions . are you wanting to test the variances ?"
114763,is there a preview section / sample chapter of your book available somewhere ?
114926,the question is indeed unclear . are you _generating_ random clusters or doing _cluster analysis_ of existing data ?
115410,have you considered [ singular value decomposition ] ( url ) ?
115494,is this for a class exercise or other self-study ?
115537,"( -1 ) yes , principal component analysis ( or factor analysis ) is probably what you need . but your questions : is it reliable ?"
115538,"the trees in random forests are not pruned , so will you get a probability from each classifier ?"
115702,"be aware that asking for code is off-topic . questions about simulating survival data can be on-topic , though . you will have to say a lot more for this question to be answerable . what distributions are you considering ?"
115708,i think it's reasonable to think that the participants in the first survey that answered disagree or slightly disagree would answer tend to disagree if they were given the second survey . any reason you don't just want to collapse the 6-scale into the 4-scale like that ?
115715,how do you intend to measure whether it correlates ?
115745,maybe topic modeling is better suited than clustering ?
115754,is a ( two-tailed ?
116561,what is the data / information that is being used to make the inference ?
129392,what are the group sizes and variances ?
147160,i'm a bit confused because you seem to understand why the intercept isn't estimable ( i . e . any estimate would fit the data as well as any other ) - what would you do with it ?
162582,what is your question ?
162876,"this is hard to follow . are the resilience & anxiety scores originally continuous variables , which , in coding them into high & low , are dichotomized & entered as 0 / 1 variables ?"
175731,"what do you mean "" after n times "" ?"
184989,would a simulation do ?
199965,do you want to test all one-hundred and one thousand and twenty-seven ( 101027 ) possible combinations of the $ 17 $ variables ?
212111,"this is hard to follow . what are "" dma's "" ?"
270537,i can guess where this is from ( em algo ?
83514,i'm a little confused . how does that formula guarantee that the result is between 0 and 100 ?
5191,could you supply a reference for this definition of order of a kernel ?
274624,"are you being "" asked "" as course work , or is the from actual research work ?"
279498,could you elaborate or quote some sources ?
286298,the definition of an ar ( 1 ) process could be clarified : is this a general first order markov as written in the title or a 1-st order markov with a specific form of transition ?
317691,"what does "" $ p $ "" mean ?"
81828,you are indeed correct * under certain assumptions . * the answer depends on ( a ) how the moving average is started and ( b ) the coefficients in the average . what can you tell us about them ?
81840,how many dimensions do you have ?
82193,in order to have a classifier you have to have some input variables and some out variables . which would be your input / output variables in this case ?
83593,why do you see the occurence of a bug as a random thing ?
88725,can you please provide a citation and link to the resource which uses this term ?
96596,"standard normals $ n ( 0 , 1 ) $ or general normals $ n ( mu , sigma ^ 2 ) $ ?"
97520,what do you observe ( measure ) ?
99263,valid for what exactly ?
108227,train on the training set and predict on the validation set ?
162314,how is the range related to the data ?
78432,this is a very broad question . which assumptions are you most concerned with ?
79005,can you explain why you expect a bias ( as opposed to random error / variance ) ?
79590,"lucas , would you be so kind as to spell out in your question what you mean by "" gbm "" ?"
80510,"welcome to the site . "" in the good "" = ?"
85793,"are the variables quantitative , qualitative ?"
86490,"when you say it follows 'a power-law distribution' , do you mean a pareto distribution ?"
96987,"can you explain what you mean by bias , and / or how you calculated it ?"
105670,"what do you mean that the "" models have different y axes "" ?"
108591,"also , could you please be more specific ?"
109652,"i'd guess it depends on the size of your model , i . e . the number of latent factors . can you comment on that ?"
110564,are you asking the psychological question of why people like smoothness or the statistical question of why smooth functions are better statistically ?
111824,could you elaborate please ?
111946,"as a starter , don't you think it's a bit unclever to estimate the means with $ bar { x } $ and $ bar { y } $ when in fact we know that they are 0 and 0 ?"
241354,this is how i understand it . . . could you provide reference for it and / or full quote describing it ?
258430,"welcome to the site . ` self-study ` questions should be tagged as such , and you should read its wiki to see the etiquette on asking self-study questions on this site , which includes showing you have made a 'good faith' attempt at solving the problem yourself . we also do not answer self-study questions for you , rather , we will point you in the right direction . now , given that this is for a class exam , is there nothing in your class notes or textbook that discusses this ?"
116262,is there a typo in the problem statement ?
117151,"i'm not sure what you're after . do you mean "" what does 'not independent' mean "" or something else ?"
117935,"given additional information ( such as a prior distribution for $ rho $ or a restriction of the sign of $ rho $ ) estimation would be possible , but otherwise $ rho $ is not identifiable because ( since $ pm ( x , -y ) sim n left ( pmatrix { 0 0 } , pmatrix { 1 & - rho - rho & 1 } right ) $ ) the likelihood for $ - rho $ is exactly the likelihood for $ rho $ . what sort of information do you have of this nature ?"
121228,how about drawing something like a decision tree with class probabilities at the leafs ?
114105,how many data points do you have ?
124584,wouldn't this just be what is called analysis of residuals ?
130488,""" the data contains a lot of zeros "" . . . and so would be unsuitable for the procedures you're using - they both assume continuous data , at least in their original versions ( does your software handle the heavy level of ties properly ?"
131015,why do you feel you need to normalize the prices at all ?
127612,"since $ x = mu sigma z $ , with $ z sim text { n } ( 0 , 1 ) $ , you can simplify the problem into $ mu = 0 $ and $ sigma = 1 $ . from there , you should first consider solving $ y le y $ in terms of constraints on $ x $ towards deriving the pdf of $ y $ , but i am unsure there exists an analytical solution . maybe start with a second degree polynomial ?"
87613,possible duplicate [ here ] ( url ) ?
138148,do you mean the largest root of a noncentral wishart matrix ?
138562,do you know whether the problem is i ) that the posteriors of your model are more narrow than you want or ii ) that your mcmc algorithm outputs too narrow posteriors compared to the true posteriors of your model ?
141084,have you thought about running a logistic regression ?
142229,a ( possibly ) simpler way of phrasing this is as the expectation of a gaussian random variable conditioned on $ x cdot theta 0 $ . can we assume identity covariance ?
143308,does [ this answer ] ( url ) give you what you need ?
143709,is there some reason why you want to code obese versus non-obese when you have actual bmi values ?
143778,hint : can you split it into parts that are independent and perfectly dependent ?
145328,"then - if age is a continuous variable - it is unclear what you mean saying "" adjust for age "" . please clarify that . may it be about a regression issue ?"
145639,should the generated numbers be different from the original ones ?
149688,are you given the black line initially ?
154830,do you remember where you read that ?
155979,how much is notably better ?
156432,time-dependent data can be modeled with a wide range of models . could you provide us more information on what kind of models are you interested ?
157825,"so there should be a baseline group , right ?"
160514,the question is unclear as asked . what do you mean by compare ?
162829,"so the predictor variable can have a series of values , which can be set in order , but it makes no sense to calculate differences ( like kindergarten , primary school , high school , college ) and the predicted variable is a continuous variable , varying within a range , right ?"
164123,could you explain what a comparison of standard deviations of any kind of * normalized * values would mean ?
19823,could you give an example ?
172908,i take it you are specifically interested in the effects of year / month / week ?
256477,"under the null hypothesis $ mu_1 - mu_2 = 3 $ , what's the expectation of $ bar { x } _1 - bar { x } _2 - 3 $ ( where $ bar { x } _j $ is the mean of the $ j $ th sample ) ?"
285967,welcome to the site . which book or thteads you are you reading ?
40543,"the way the cross-classification occurs is important , nonetheless , since some tests assume that one or both marginal totals are fixed . why a fisher's test in this instance ?"
108977,"can you clarify what the "" certain task "" is that you want the svm to do ?"
116278,can you explain where 5 . 95 comes from ?
116322,the coefficient of what ?
116593,` how i can split a class into two or more classes such that each of the resulting classes have a higher average silhouette ` why not just take that class and do cluster analysis of it ?
116674,"the argument in the first expression is $ 1 / h ^ 2 = 1 / a $ times the argument in the second expression . if $ h $ were a constant , then your final remark would apply , so evidently $ h $ is supposed to be a random variable , right ?"
116771,did you try using dummies for the holidays ?
116827,"what do you mean by "" sample of size k , weighted by a function f ( x ) "" ?"
117412,"do you have any thoughts or information about the mechanisms behind , or the statistical nature of , those deviations ?"
117420,"bob , when you mean "" pattern "" are you referring to unsupervised learning / clustering or supervised learning ?"
117553,you're trying to minimize $ hat y $ ?
117677,try ` ?
117889,what happens if $ a = 0 $ ?
117920,"i think you described "" the * concept * of building a new model with the residuals from a previous model as the response variable "" quite well . what is it you are seeking ?"
118093,"this question seems to come down to a misunderstanding of densities , which is addressed at url does that solve your problem ?"
118209,"a confidence interval for * what * , exactly ?"
118218,"how is the "" outcome "" related to these subsets ?"
118368,why would you not get probabilities for the negative binomial using ` dnbinom ` ?
118444,"i don't really understand your question . you state that the "" parameter distribution is given as distribution of theta "" & then ask if there is "" a way [ you ] can infer on the parameter distribution "" . can you make your question clearer & more concrete ?"
119740,how was this data set constructed ?
120014,is this for a course ?
120029,"do you mean you've fit a model to 20000 _variables_ using the lasso , or 20000 _models_ ?"
119913,"under the standard assumptions , error terms * are * normally distributed . what assumptions , then , do you have in mind ?"
120238,"are you aware that adding a constant $ mu $ to a normal $ ( 0 , sigma ^ 2 ) $ variable gives a normal $ ( mu , sigma ^ 2 ) $ variable ?"
120475,""" what is the principle behind this ?"
120479,"it is difficult to guess what you are asking . "" the same conceptual meaning "" as * what * ?"
120486,have you searched our site for related questions ?
120585,by more important you mean the most significant or have the highest effect ?
120613,it is unclear how you are comparing them . are you using multiple data sets / cross-validation / . . . ?
120809,what exactly is your response variable ?
120825,have you tried the optim ( ) function ?
121096,does it have to be over integer values ?
121116,"since asymptotic unbiasedness is proved using more general properties of the mle , what would "" verify "" mean here ?"
121180,can you explain to us what is ep ?
121260,why do you think you should use the chi-squared distribution here ?
122030,""" layman's terms "" could mean almost anything . what does it mean here ?"
122343,"your question doesn't make sense - priors for a parameter don't generally come from examining the density of the model for the data . are you asking about a particular kind of prior , like a jeffreys' prior , or maybe just about conjugate priors , where you would look at the form of the probability function ?"
123013,umm . . couldn't you just subtract $ 10 $ at the end ?
123021,what time series model ?
123036,"auc is unclear if you don't specify the curve . do you mean area under the roc curve , area under the pr curve , . . . ?"
123161,i'm assuming the conditions are completely disjoint and the frequency of each condition is known in advance ?
123167,"hints : since $ x , y , z $ are independent and identically distributed ( prove this if it is not immediately obvious ! ) , all $ 3 ! = 6 $ orderings of $ ( x , y , z ) $ are equally likely . for the second part , observe that the set $ { x = y } $ is a superset of $ { x = y z } $ . what is the probability of the former event ?"
123549,there are paired tests that do not assume the same scale ( eg rank-based ) ; you could also re-scale / standardize the data . but - can't they experience both ( could these categories be non-independent - and this might be what you are indirectly referring to ) ?
123727,"you need to supply more information . what exactly do you mean by a "" combination "" ?"
123803,have you tried barnard's test ?
123850,what would your formula say for random variables of zero expectation ?
124157,no . does bishop have a proof ?
124208,which paper are you looking at ?
124374,"if you do not know the boundaries , how can you use a truncated guassian mixture ?"
124401,could you articulate the basis of your confusion and indicate what kind of guidance you are seeking ?
124426,"to which "" two rules "" are you referring ?"
124427,"what does "" $ f_ { v_5 } $ "" mean ?"
124488,you need to provide more details . why do you want to increase the number of data points ?
124536,"what do you mean by "" experiment "" ?"
124735,what about adding a column for each p-value ?
124881,what definitions of these two terms are you using ?
125210,week is usually considered cyclic data . is it alright to treat it as linear ( just ask - i don't know your situation ) ?
125383,the question is unclear as stated : do you ask what is the mean standard deviation value ?
125559,"is $ y $ certain if $ x $ is , or is it still random ?"
125556,for what purpose is the visualization ?
125611,"what is "" categorical with date "" ?"
125652,generally the only reason to combine classes is because your expected counts are very low ( 5 ) . do you have low data or are you just trying to 'find significance' ?
125730,"is there are a particular context you've seen $ p ( beta , mu y ) $ in ?"
125838,what makes you think it is over fit ?
125996,"my comment was about explaining the regression method of computing factor scores , it does not answer your question . the thing is what is $ mathbb { e } [ mathbf { z } ] $ . expected mean value for a factor ?"
126079,you can do cbca with [ rologit ] ( url ) in stata . can you clarify what you mean by no-choice option ?
125991,"are you asking for matlab code , or are you asking how the jacobian is calculated for a neural network ?"
126248,please explain what the table is actually showing . what is the value 247 ?
126412,an ber-mixing markov chain ?
126513,why are incorrect and i don't know coded the same ?
126772,can you clarify the polynomial terms you are referring to ?
127166,can you provide a little more context ?
127370,is this question related to a course assignment ?
128622,what have you done so far ?
128647,"as far as i'm aware there's no one way to sample a graph because the idea of sampling a graph isn't well-defined . do you sample nodes and let edges "" fall off "" ?"
128892,is $ y $ a scalar or a vector ?
128968,"have you tried searching the internet with phrases like "" statistics compare to a known value ?"
129157,out of curiosity : how there can be negative rainfall . . ?
129158,is your dependent uptake per year or cumulated uptake ?
129208,what is $ f ( . ) $ ?
129290,"for future reference and for the sas-impaired , it would be nice to describe what ` toep ( x ) ` and ` sp ( pow ) ` statements actually do ( i'm guessing a toeplitz structure and some kind of spatial power autocorrelation function ) ?"
129339,""" the probability distribution of this plant flowering may be uniform between 1200 and 3000 . "" does this mean that , if at a given moment in time a plant accumulates 2100 energy points , then the plant has a 50 % probability of flowering ?"
129554,"welcome to cv ! for clarity , is it correct that you have a set of balls , all with known sizes ?"
129626,( 1 ) derivative with respect to which variable ( s ) ?
129658,is this for a course ?
129784,you'll need to provide a lot more information for this to be answerable . what book by bishop ?
129834,"have you considered penalized regression techniques such as ridge , lasso or lars ?"
130204,what are the explained variances of pca components ?
130503,could you provide the link to the stackexchange question for assessing the potential duplication ?
130544,could you perhaps do some training on a ( relatively small ) subsample of your data ( the * training * set ) ?
130594,"sorry for this off-center comment , but i would be surprised if the language you are using ( which is what language ?"
130926,can you add some details / context here ?
131034,"when you say "" model two time series "" -- you should be more explicit . are you trying to predict one from the other ( which from which ?"
131086,"rather than asking people to check other entries , could you write a summary of the method and of your difficulties with it ?"
131182,what is your goal in fitting the model ?
131181,"are you assuming that a , b and h matrices are known ?"
131219,is this a home work ?
131369,"do you want linear correlation , or some more general association ?"
131471,"you lost me at the first line , for several reasons . ( 1 ) a sample cannot have a gaussian distribution ( but it can approximately have one ) . ( 2 ) one characteristic of * all * gaussian distributions ( and therefore of approximations to them ) is * symmetry * . you have contradicted yourself . by describing your data in your own terms , rather than statistical jargon , you will better communicate what you have . could you also explain , in as plain a manner as possible , what you really want to accomplish with your data ?"
131484,why not give a ( perhaps weighted ) average of the corresponding standarad deviations ?
132594,"i found a doi on zhe chen's researchgate profile ( 10 . 1080 / 02331880309257 ) but it doesn't resolve to anything . dois are supposed to be opaque , but it does * look * like the other dois from * statistics * circa 2003 . weird , eh ?"
132635,just to clarify : are you trying to _simulate_ or _estimate_ the model ?
132689,"did you try integrating using $ ( x , x ^ 2 , x ^ 3 ) $ ?"
132806,it's not clear to me why you think there's a problem . what makes you thinks there's anything wrong here ?
132976,""" projecting the data to where there is huge variance "" isn't quite right . it sounds like a mistranslation of "" projecting the data to where there is greatest variance . "" are you a spanish speaker by chance ?"
133019,"are some additional conditions assumed , such as $ w_i ge 0 $ $ forall i $ and $ sum_ { i = 1 } ^ n = 1 $ ?"
133172,did you check confidence intervals on both errors ?
133196,"keeping in mind the guidelines at the self-study [ tag wiki ] ( url ) , what's your thinking on this ?"
133295,"what is "" spams "" ?"
133482,what is the meaning of the relationship between the sets of variables ?
133564,"if your code is not [ returning a beta $ ( k 1 , n-k 1 ) $ distribution ] ( url ) for $ k $ successes in $ n $ trials , then what is it doing ?"
133593,it all depends on what you compare : if you have two sets of weights $ ( x_i ) $ and $ ( y_i ) $ how are they produced ?
133832,is this a homework question ?
133894,i don't follow your description . can you please show the first few rows of your data table with column headings ?
134030,"derivating $ h $ yields $ h $ , where do you encounter a difficulty ?"
134262,with what goal ?
134351,can you be more specific about what you want to achieve with pca ?
134472,what kind of proportional data ( is this continuous proportions ?
134476,what is a confidence interval for $ x_i $ ?
134790,what did you try ?
134816,"suppose x = y , what happens then ?"
134879,if this is a homework question could you please add the self-study tag ?
134908,"what exactly does "" representativeness "" mean for you here ?"
135106,"the search for "" independent space analysis "" [ yields only 7 results on google scholar ] ( url ) and these look mostly irrelevant ; are you sure this term really exists ?"
135133,maybe try aic / bic ?
135250,isn't this a form of [ expectation-maximization ( em ) ] ( url ) ?
135567,can you explain more clearly what you mean ?
135547,"the formula in the code for ` e ( x ) ` is not recognizable as being a normal approximation to binomial probabilities . could you tell us precisely what you think the formula for the "" laplace approximation "" is ?"
135775,_best_ in what sense ?
135796,those counts are awfully small . 1 approach is to simulate the distribution of your test statistic . i have ` r ` code ( which hopefully is self-explanatory & easy to adapt to python ) in my answer here : [ how to simulate effectiveness of treatment in r ?
135789,"did each * pair * of observations take place in a different city ( eg , both obs in row 1 in the same city ) ?"
136007,have you looked at similar questions on the [ gis . se ] site ?
136143,hint : this integral is ( almost ) the expected value of $ { sqrt x over sqrt { x 1 } } times exp left ( x ^ 2 right ) $ for a well-chosen random variable . which one ?
136192,"when you say "" multiplied the size "" do you mean they simply used a different $ n $ in the calculations to the $ n $ that was actually sampled ?"
136203,"do you mean given some variables , scale them to ( 0 , 1 ) range . use those transformed variables for regression ?"
136319,is this under self-study ?
136145,"there are some troubling inconsistencies in your statement . first , your distributions appear to be * univariate * rather than "" bivariate . "" are you perhaps using "" bivariate "" in the sense of "" takes on two distinct values "" ?"
136638,"mahalanobis distance , like euclidean distance , is for isotropic space , that is , the variables defining the space must be on the same scale . if logarithm is enough for you to think the scales are now "" same "" then it is all right . you say you need the distance to track down outliers . then you say the distance is large for some not outlier points . so it appears that you know your outliers in advance ?"
136967,"perhaps you could clarify what you mean by "" distinguish "" . what do you actually want to do ?"
137141,what is the context of that conversation ?
137192,is this question from a course or a textbook ?
137086,what do you know ?
137264,"do you know that the series was sampled at time $ t $ , even if observations were not conserved ?"
46559,"i am afraid you did lose me . suppose the process has a nonzero ( albeit small ) chance of producing any five-tuple , so that after a sufficiently large number of observations , * every * five-tuple will occur in your dataset . what would you do then ?"
137631,"why are you plotting components 3 and 4 , rather than 1 and 2 ?"
137803,can you describe a bit more the problem ?
138020,you could use analogue data / product to capture seasonality . is this retail industry ?
138266,how about a regression model with the use of contrast statements ?
138431,this seems much closer to a viable question now . can you rephrase / reframe it so that it has to do w / different variants of decision tree models instead of something that's weka specific ?
138436,suppose you add another line with 1 view and 1 click for a ctr of 100 % . what is the new average of ctr ?
138430,why would you want to test these two data sets if the values are constant ?
138572,i think you can . isn't this what irf is supposed to be used for ?
138633,if you consider $ $ p ( x-s ge t x ge s ) = p ( x ge t ) $ $ what does this tell you ?
138669,luca why shouldn't they ?
138848,what do you mean by the frequency of schizophrenia if all the subjects have chronic schizophrenia ?
138877,do you mean with distance matrix the matrix of dissimilarities used as input or the distance matrix that is fitted to the dissimilarities ?
138980,could you elaborate on the motivation for fitting a regression ?
139013,"if your goal is to select a given amount of pixels with highest scores , why can't you just simply do it ?"
139096,what mode of convergence ?
139702,"why can't you cluster 1d data "" by hand "" ?"
139879,"hint : white noise is about absence - rather than presence - of regularities . also , your estimated ma process is non-invertible and thus would produce explosive behaviour into the future ; does that make sense for the data you are studying ?"
140048,what inference do you want to do exactly ?
140189,what do you mean by 'just 1 mean' ?
140612,do you have any additional variables rather then number of crimes and population size ?
140621,what kind of documents do you have and how long are they ?
140695,the question is not clear . the r function ` poly ( ) ` does create orthogonal polynomials . in what sense do you need something different ?
140724,"have you searched "" asymptotic variance "" ?"
140847,does it ?
140902,could you be more specific what you want to ask ?
140996,what kind of code are you using ?
141077,are you asking for the formula that gives you the probability of 2 successes out of 4 trials when the underlying probability of success differs by trial ?
141207,"what time ( calender time , age ) is used for the analysis , and how is the follow-up time of the two groups distributed on that time scale ?"
141212,do you have the original data that the means were calculated from ?
141250,"it isn't immediately clear to me what "" good arrangement "" vs . "" bad arrangement "" means here . are you asking about [ wide vs . long form ] ( url ) ?"
141525,in what way does it matter to you ?
141572,"by replicates , do you mean replicated centre points ?"
141685,"to be clear , the notation { 0 , 20 } means a set with just two elements , 0 and 20 . is that what you mean ?"
141709,"are you only interested in the bivariate situation , so one x and one y , or in a multiple x situation ?"
141768,you need to give a clearer context for the circumstances near the start of your question . how are the $ x_i $ distributed ?
141799,is your output space continuous ?
142433,"if you mean "" given the correct model is one of these two , which has a greater probability of having generated the data ?"
142442,trying to understand at which step you are having a difficulty . . . are you able to do that for other models rather than what ` mumin ` returns ( so that it is ` mumin ` that is the trouble ) ?
142493,how many data points are there ?
141227,is this a homework problem ?
142884,"if you say that the random variable has an unknown distribution on $ [ 0 , 1 ] $ , is it ok for you to take the uniform distribution over $ [ 0 , 1 ] $ ?"
142971,are you ( implicitly ) assuming some * fixed * number of components $ k leq ( n 1 ) / 3 $ ?
143049,so your question is how to write code for constructing this matrix ?
143554,why would you want to do this ?
144128,"taking the simplest case of vectors of length $ 1 $ , are you asking whether $ e [ xy ] 0 $ implies that $ p { xy 0 } leq p { mu_x y 0 } $ ?"
144201,are you asking specifically about r ?
144406,"first off matching algorithms are notorious for computational inefficiency , have you considered other semi-parametric techniques such as inverse probability weighting and double-robust regression ?"
144474,can you further explain about your dataset ?
144636,can you clarify what you want ?
144630,slef-study ?
144752,can you clarify your question ?
144836,why are you testing normality ?
145288,are there any covariates ?
145326,do you have individual data on your dependent variable or not ?
145340,"what do you want to know about rngs , specifically ?"
145409,"what is the obstacle to using actual "" real life data "" ?"
145580,"the nans come from attempts to divide by 0 . on that line follow through : estimate = 0 , se = 0 , so t = estimate / se = ?"
145852,"well 0 . 3 percent sounds like a trivial difference to me , but i'd not in your field . does it sound like a meaningful difference to you ?"
145752,"i wonder about the motivation behind this question , because i understand that standardized betas tell us about the relationship between the $ x_i $ and the * response * variable , whereas the partial r's tell us about the relationships between the $ x_i $ themselves . given these are such different things , what would be the reason to suppose there must be such a strict inequality ?"
145938,something like [ this ] ( url ) ?
145966,have you considered naive bayes ?
146035,so the training data is raw data and the test data has been averaged across multiple runs ?
146292,'less important for the detection' of what ?
146640,"do you mean a general _field_ ( e . g . finance , meteorology , . . . ) where these models work well or a _specific data set_ ?"
146946,is it a homework problem ?
147104,are subject common between placebo and supplement groups ?
147114,are you saying that a heuristic is what we cannot formally explain how we define it ?
147140,how were these features generated ?
147698,"what exactly do you mean that the "" maximum length "" is $ 30 $ ?"
147880,the answer to your question is in the circumstance that - as it follows from your posing your task - you don't need the covariance matrix of the columns for itself . you only wanted it as a path to obtain pcs . right ?
147931,"are there only the three personality types ( introvert , moderate , and extrovert ) ?"
147987,how will the joint distribution be described ?
148423,what does your book say about these things ?
148461,"am i right that i'm understanding you as that you want just to compute pc scores for the new , incoming data points ?"
148468,do you have any ideas why there is nothing above 38 . 3 degrees ?
148491,how small is small ?
148673,are the varieties planted at the plots in a random way ?
148697,what additional data do you have ?
148721,did you also try the breslow approximation along with the exact method ?
148725,"are the groups related in some ordinal sense ( eg , high-school students , college-students , grad-students ) , or are they unrelated categories ( eg , architects , engineers , truck drivers ) ?"
148776,"in 3 . , do you mean $ f_x $ ?"
148811,"what do you mean by "" a forecast with 2 or more factors "" ?"
149065,"can you please provide source of your terms filtering , wrapper and embedded ?"
149662,"are you talking about a linear svm , or rbf kernel , or . . . ?"
150935,that's how you calculate confidence intervals for a correlation . what do you get if you don't convert confidence intervals ?
151548,have you checked the following answers ?
151791,is the positive event always an upwards peak ?
151848,what is the underlying equation describing your phenomenon ?
152603,which programming language do you use ?
152696,"what do those $ pm $ figures represent , exactly ?"
152780,can you provide some context regarding where you have recently seen this ?
152892,"by repeated measures fully randomized , do you mean each subject saw all levels of the independent variables ?"
153170,is there a good reason why you do not the actual data ?
153244,"you may have additional information that is relevant and valuable . these sound like * time series * data where observations are taken sequentially over time and , perhaps , nearby observations are correlated with one another . that would have a profound effect on the correct estimate of uncertainty . could you add to your post to fill us in on the situation ?"
153245,"wouldn't the "" ideal "" method be the "" best method "" ?"
153433,can you be more specific in how your variable is censored ?
153487,"which "" pitman book "" is this ?"
153500,"quick note : if present-oriented and future-oriented are dichotomous states , such that everyone is in either one category or the other , then your two hypotheses are the same ?"
153570,maybe you didn't normalize your input and target data ?
153632,"when you say "" which factors are causing problems "" what are you after ?"
153723,welcome to cross validated ! data reduction is clearly a sensible approach to model fitting here - you've only 43 cases ! i think you need to add a little more context about what you're trying to achieve & clarify what you're asking - how to combine them ?
153820,"such a model would almost certainly yield nonsense predictions ( percentages outside of [ 0 , 100 ] ) when given years far in the future . does that matter for your application ?"
154221,what do you want to do ?
154264,"* any covariate can shown significant effect in the model . thats why i think them "" equal "" . * isn't this true for linear regression as well ?"
154351,how is the model classifying into buckets based on the probabilities ?
154452,"by "" experiments "" , do you simply mean how much data do you need ?"
154513,"welcome to our site , megan . what are the "" two dimensions "" ?"
154571,what image size must be ?
154568,could you give some context to help readers understand * why * you are comparing monthly variances ?
154981,for what reason do you want to select regressors in the first place ?
155483,"what do you mean by "" best n-gram "" ?"
155781,do the test statistics match while the p-values do not match ?
155810,'baseline' means an individual outcome measurement that is taken before the beginning of the experiment ?
155876,is this a self-study question ?
155973,do some variables have missing values for some of your units in the most recent year ?
156258,"i assume they vary from month to month . why would peak flow be the same in january and july , or march and september ?"
156371,why not try a one-way anova ?
156396,"can you say more about your situation , your data , & the analysis / model ?"
156504,how do you compute the statistical significance for smoothed ratios ?
156696,why do you want to go back to the original 10 variables ?
156797,do you mean that your response variable is an ordered categorical variable ?
156837,could you please edit your post to make clearer which is your independent and which your dependent variable ?
157025,"what do you mean "" detect a difference of 1ppt "" ?"
157057,is there an 'exact' ( and trivial ) connection for sure ?
157148,could he be doing the task at * a * and also be watching for the bus ?
157158,"these are two very different questions , you should ask them separately . the first one also isn't a programming question , you should ask on stats . stackexchange , not here . as to the second question , have you tried ?"
157598,are you just asking how to * use * the bootstrap to test a hypothesis ?
157724,"although time is an essential part of any survival analysis , "" status "" is not . would you mind clarifying for us what you mean by "" status variable "" ?"
157960,have you tried applying the definition of conditional probability ?
158076,"do you * need * to use pcr , or is the question about what else you can try instead ?"
158155,what is a woe transformation ?
158185,could you please clarify what you want to know ?
158389,"did you transform the data before fitting the model ( e . g . by taking logs ) , or equivalently were the data so transformed before you got them ?"
158556,what about using the cumulative distribution function of a gaussian whose mean is $ ( p1 p2 ) / 2 $ and standard deviation $ ( p2-p1 ) / 2 $ ?
158850,have you considered quantile regression ?
158920,"isn''t the median of $ { 1 , 2 , 3 , 4 } $ $ 2 . 14159265 dots $ because 50 % of the sample is $ leq 2 . 14159265 dots $ and 50 % of the sample is $ geq 2 . 14159265 dots $ ?"
158952,this is way too unclear and broad . have you actually run the test ?
159067,"so , $ x sim dir ( alpha ) $ , and $ y $ is what , a multinomial distribution or something else ?"
159235,what exactly is the outcome variable here ?
159369,"the simplest way i have ever encountered ( at least among the ways that make quantitative use of the data ) is to compare the last value to the first . for some purposes and some data it works just fine . for most purposes it's inferior . but that raises the question , inferior in what sense ?"
159496,"to clarify , the idea is to determine if the proportion of ` positive_reads ` ( given the number of ` total_reads ` ) differs by ` population ` , is that right ?"
159509,"what is a "" synthetic control "" ?"
159510,i presumed the 5 categories are not ordered but independent . is that right ?
159531,why can you not just calculate the probability the same way you did $ p ( a_n mid b_n ) $ ?
159729,"are you solving for $ b $ , and $ a $ is fixed ?"
159749,do you have the outcomes for each individual in each trial ( in each group ) ?
159665,"you haven't specified how this fitting is to be achieved ; are you using ml , say , or at the least can we guarantee we're using a consistent estimator ?"
159790,"if the regressions are truly independent , then what use is this ?"
159838,"granger tests operate over a number of lags , w / only 6 time points available , how many lags did you want to include ?"
160014,why is the data missing ?
160091,when you open the arff file with a text editor do they have the same header ?
160182,"would you be able to build 6 models ( one where a predicts b , one where a predicts c , . . . ) and combine the results ?"
49820,have you seen [ this ] ( url ) question ?
160388,i think $ d = frac { bar { x_1 } - bar { x_2 } } { s } $ is the formula for cohen's d . where is the second fromula from ?
160662,"not the answer you're looking for , but the ` multinom ` function in the ` nnet ` is superb . uses the exact same functionality as any ` glm ` object ( which technically speaking , it is ) . aside from preference , what do you need form ` rms ` ?"
160559,why would you expect it to change ?
160677,"it's not clear what scope you intend to include in "" is this normal ?"
160847,what is gp ?
161009,are your n observations drawn at random from the population ?
161234,"are you running a classification model at all , or is this linear regression the only modeling you've done ?"
161264,have you tried to check it yourself ?
161298,maybe you can add some more details . how do you use the mean and std ?
161409,what's the purpose of this prediction ?
161435,is this regarding a specific data analysis that you are doing ?
161490,have you searched our site for [ likert and regression ] ( url ) yet ?
161703,can you share your code and data ?
161993,what do you mean by sum-code ?
162063,what do you mean with the ` / ` in $ c / x $ ?
162135,is it possible to go from state 1 - 3 or 4 ( i . e . bypassing state 2 ?
162172,""" motivate theoretical work "" in which sense ?"
162238,what is your data ( is it continuous or discrete ) ?
162494,what differences are you interested in knowing about ?
162532,this depends on what you are trying to achieve with dimensionality reduction . why are you doing it ?
162781,is your response variable the sum of spoken words of a pair ?
162670,"if your question is how to build a testing or validation set , you can simulate the future by splitting the data based on time , rather than taking a random subset . is there something else to your question ?"
163132,data visualisation or data validation ?
163210,i am not very familiar with this package but isn't the transform ( ) call doing just this ?
163327,the package does not compute confidence intervals . but note that you can access the underlying ssa dataset if you wish : ` genderdata : : ssa_national ` and see ` ?
163387,do you want o test each advisor against each other ?
163528,"it is unclear what you are asking since you mention "" nonlinear "" forecasting in the title while you give an example of linear regression in your question . what do you mean by "" nonlinear forecasting "" ?"
163529,what is your hypothesis ?
163696,are the power . t . test or power . anova . test what you are looking for ?
163718,"it is not very clear what you are asking for . when you say "" i want to find a suitable statistical test can help me to illustrate the difference "" , what difference do you mean ?"
163914,what is it you'd like to know about these data ?
164054,"i tend to agree with you . from the context of that sentence , it should be as you wrote . btw , did you get any interesting results with slow feature analysis ?"
164162,"even if full data matrix does not fit into memory , it can very well be that either covariance or the gram matrix fits into memory . those are enough to perform pca . what size of the input data matrix are you thinking about ?"
164340,two questions : 1 ) what was the size measure ?
164520,what's your question exactly ?
164615,"just curious , why not plot ?"
164676,"do you expect results from different days to be correlated in some way ( visually , it seems like maybe ) , or are you willing to treat them as iid ?"
164867,this looks like routine bookwork ( and so would likely fall under the ` self-study ` tag [ q . v . ] ( url ) ) . is this for a class ?
164997,"please review my edit of your question , will it be all right for you ?"
166272,i don't follow this . can you say more about your situation & your data ?
166431,who or what are dudley and brighton & hove ?
166490,can you clarify this ?
166660,by kpca you mean kernel pca ?
168265,how are you converting the predicted probabilities into predicted classes ?
169741,what are you trying to do ?
175325,do you have reproducible code ?
188399,""" success_rate "" cannot be a probability * per se * ( because probabilities are unobservable theoretical constructs ) : most likely it is a ratio of two counts . exactly what is it counting ?"
190008,so is x a binary categorical variable ?
191502,what do you want to do ?
216331,would you like to add the constraint that the process is stationary in the wide-sense ?
218688,what do you want to do ?
221753,"this baseball batting average "" paradox "" url can be explained based on differing numbers of at bats ( divisor for batting average ) in the seasons . i don't consider number of at bats to be a "" confounding "" variable ( but maybe other people do ?"
230521,how exactly are you estimating $ beta $ and $ sigma ^ 2 $ ?
244702,"could you explain what "" explodes "" means in this context . the word evokes a good visual , but does not exactly say what happens numerically . what does happen numerically , please ?"
248588,could you spell out dqn ?
154746,"is there any reason that you can't use a generic non-linear curve fitting function , like ` nls ` in r ?"
257624,"chris , the sample covariance matrix is always positive semi-definite . ( it is the covariance of the empirical distribution , * qed * . ) are you perhaps computing a matrix of * pairwise * covariances when some of the data are missing ?"
280337,"can you clarify what you mean by "" percentage difference "" in this context ?"
283483,"are "" option a "" and "" option b "" two different answers to the same question or are they corresponding responses to two different questions ?"
319727,"what is meant by "" non one hot output "" ?"
326048,do you have a reason to suspect there is a trend in the final product quality independent from your input variables ?
348798,where did you find the reference to $ h1 $ regularization ?
127253,"oh noes , where are the units ?"
134919,is this a homework or test problem ?
135307,is it a self-study question ?
138935,what if $ b = a ^ c $ ?
139721,what do you mean saying ` if covariance matrix were different things ` ?
143887,"interesting question . do you have an example when this could be relevant , or is it just a theoretical problem ?"
145406,"out of interest , do you have an application in mind ?"
146936,is age the only predictor in your model ?
151682,"since $ mathbb { e } [ x y = y ] = rho y $ , what about integrating $ rho y $ over the positive half-line ?"
154651,why do you want to do an f test for a group with identical values ?
161633,"you need to assume $ { d_i } $ and $ { x_t } $ are independent , right ?"
326330,what type of bootstrap ci did you use ?
117765,what is fisher's combined probability test ?
118403,"usually "" $ p $ "" denotes a ( usually unknown ) _constant_ ( which does not have a variance , and so neither does any function of it ) . so i suspect that here "" $ p $ "" actually stands for $ hat p $ , a random variable that estimates the true $ p $ . is that so ?"
118593,are the timesteps smaller ( i . e . faster sampling over an equivalent time period ) or are they the same ( i . e same sampling rate over a longer period ) ?
121335,"when you say "" method in bayesian statistics "" , do you mean an inference algorithm , like a specific kind of sampler ?"
133673,you might want to provide more information on the data you have . how was effort measured ?
134227,"what is a "" laplace multiplier "" ?"
136392,can you please add the definition of [ the spectral norm of a matrix ] ( url ) to make the question more readable ?
137067,"your "" almost forgot to mention "" is crucial here . whenever values cannot be negative , working on log scale is usually the answer . you can use generalised linear models with logarithmic link to get the best of both worlds , as it were fitting on logarithmic scale but predicting on the original scale . important detail : can values ever be zero ?"
138076,do you really have a sample size of 20000 ?
143489,if eigenvalues ( which are the variances of the principal components ) differ only little and so their variance is small then it means that the multivariate cloud is [ rather spherical ] ( url ) than ellipsoid . in this circumstance the data cannot be summarized well by just few first components . many components are needed . is there any sense to do pca ( apart from for orthogonalization only ) then ?
144947,are the values missing at random or you have blocks of missing data ?
147203,what is the training error ?
147953,what is your dependent variable of interest ?
152323,do you mean a plot ?
152597,"if this is for homework or assignment purposes , could you please add the [ self-study ] tag ?"
153422,"several aspects of this situation are still unclear . presumably the $ x_i $ are independent , right ?"
153661,can you give some more detail about the exact problem setup here ?
153854,why is your fitted model not a straight line ?
154515,"the crucial element missing from this post is the value of "" what i should expect . "" what is it ?"
155276,could you tell more about your covariates ?
156393,what is your aim in using latent dirichlet allocation ?
157389,you mean like the [ ising model ] ( url ) ?
160391,"can you provide a definition for "" global outliers "" vs "" local outliers "" ?"
160579,"note that transformations are performed on the original variable , so what do the plots of $ y $ vs $ x_i $ look like ?"
160927,how did you get a gmm w / o the mixing proportions ?
163414,"calibration means that you find the parameters ( weights or parameters in some theoretical model for an economy ) such that the outcomes ( weighted means , or outcomes of that theoretical economy ) correspond to some known to be true values ( from e . g . census data ) . is that the answer you are looking for , or is there something else ?"
190052,there are several k-means algorithms . can you define the canopy algorithm you are referring to & what's wrong with it ?
218939,"do i understand correctly that you don't yet know * which * subsets of features the samples should have a linear correlation in , but want to derive this during the process ?"
166713,"if you really only have two samples per group , could you analyse the differences from each group ?"
167050,are you asking why it's a curve instead of a single point ?
168817,how much subjects to you have access to in order to build your sample list ?
168865,do you have access to the underlying y variables ?
169893,it's hard to say . can you provide more context ?
166767,have you considered the eric-wan diagrammatic jacobian with the delta rule ?
176591,could you add a reference to the theorem and / or explain the theorem in the question ?
180823,what do you mean by the derivative of the gp ?
181197,what is your actual goal ?
183150,you mean as predictors ?
189542,which distribution does the t-distribution approach as the degrees of freedom increase ?
189756,why not decide yourself ?
189962,why not generate cauchy variates directly ?
189062,what makes you see that as a contradiction ?
192122,"what do you mean by "" accept an estimate "" ?"
192388,"are there any other assumptions here , e . g . distributional ?"
194529,what kind of data are you trying to recognize ?
195124,"excellent question . just a quick clarification . would you like to predict these events , or , once they happen , adjust the model predictions given your new information ?"
195199,does the function output residuals ?
196920,"is there supposed to be a relationship between the "" imps "" and "" conv "" variables ?"
197638,could you add a reference ?
198785,have you removed punctuation and stop words from your corpus ?
202040,why did you subtract p-values ?
202334,can you paste an example of possible dataset ?
206540,is this a homework exercise ?
206788,"can you say more about your situation , your data , your analyses & your goals here ?"
208089,can you also provide the definition of set estimator you are using ?
210691,"possibly . this seems a little abstract to me , & removed from my typical scenario . can you say more about your actual situation , & post the plot in question ?"
210765,is this a question from a course or textbook ?
211908,parseltongue is tot the same thing as atet ?
212121,it would help if you could provide some example data for people to work with . do you just want to see how the quantitative variables are related ?
215548,what does the manual say about the difference between the two functions ?
217715,"if you have a * single * dataset , you could [ use cross-validation after choosing a loss function ] ( url ) . i'm a bit unclear what you want to achieve by comparing different models * fitted to different data * . could you elaborate ?"
216181,[ ordinal logistic ] ( url ) models are often used when $ y $ is ordered - proportional odds being the most common assumption . but why don't you think a multinomial model would be a good choice ?
218714,"because this is not how testing works , could you explain in non-statistical words what you are attempting to accomplish ?"
220325,is the p-value -0 . 86 ?
221899,there's some obvious things to be said here . first -- where do these numbers come from ?
224068,did you do an stl decomposition on the remainder that you obtained from stl decomposition ?
228370,do you mean actual population rate parameters ( $ mu_i $ ) or * estimates * of rate parameters ( $ hat { mu } _i $ ) ?
194,"maybe you are asking a bit to much to statistic : you said "" patterns that you extract out from the data are indeed true patterns , not statistical fluke "" and then you ask if there is a statistical procedure to answer the question . . . can i send that to xkcd : ) ?"
1256,i assume that 'without multicore' means without parallelism at all ?
26870,do you mean to call p a proportion rather than a probability ?
155717,can you add a summary of your argument for why the maximum converges to $ 1 $ ?
157073,what is your scientific goal ?
163512,did i get this right : you want a handful of methodological options to add them to your decision tree and then choose one of them later-on ?
166582,"why would you treat the other study as it were a population , when it , too is based on a sample ?"
166994,is it not true that when $ lambda = 0 $ then $ x ^ * = a ^ y $ ?
167029,why not just do a correlation matrix ?
112664,"i take it these are all within subjects or repeated measures studies . and if so , are you more interested in individual condition variances or effect variances ?"
167507,can you provide details on what kind of censoring is happening ?
167577,that does not seem to make a lot of sense . why don't you use the original data and fit a model with fewer variables ?
167532,can you add some context ?
167592,"if $ y_k $ is close to $ pm pi / 2 $ , then $ n_i $ will be very large in absolute value , and infinite if $ y_k = pm pi / 2 $ . could you clarify why you want to transform the variables in the first place ?"
167757,what do you mean by marginal effects ?
167921,""" better "" for what purpose ?"
168118,"i'm not sure what you're asking for . . are you asking "" how do i compute an average for values in a table ?"
168255,"for clarity , the "" two methods "" you are referring to are ( 1 ) including a lagged y value as an additional covariate , & ( 2 ) using clustered se's , is that correct ?"
168503,"if you're generating a series of random numbers , . . . how is that not in some fashion "" monte carlo "" ?"
168558,do you have a random sample from a weibull distribution or data that suggests the same shape as a weibull distribution ?
168623,why not just look at the count of how many were handled ?
168777,is it too problematic for you to model it as two separate binomial models instead ?
169023,i'm not too savvy at reading sas code ( so maybe the answer to this question is embedded in there ) but what are the truncation limits for finish ?
169169,why wouldn't it work ?
169209,have you thought about converting the ` ca . jo ` object to a ` varest ` object using the function ` vec2var ` and applying the function on it ?
169196,"it's unclear to me what you are trying to ask . on the face of it , understanding "" $ n $ "" as referring to sample size , the formula explicitly shows it depends on $ z $ , $ p $ , $ e $ , and $ n $ . since this is so obvious , i have to assume you are trying to get at something more meaningful--but what is it ?"
169216,are you decreasing the learning rate as you are training ?
169245,"do you mean "" interpolation "" ?"
169497,could you describe your data ?
169678,why can't you check for normality with 294 values ?
171200,"i don't quite understand . if you don't want to maximize the variance , what is it exactly that you're trying to do ?"
171379,throw the model away because it is garbage ?
171442,what do you know about the data ?
167922,to clarify : are you simply trying to split the users into k classes ?
171592,what is f1 in your plot ?
171831,"is this a statistical question , or just a question about ecology ?"
171919,what effect size estimates are you pooling ?
172564,* * which * * normalized euclidean distance ?
172815,your training data set is different than tweets dataset ?
172748,is the $ leq $ pairwise ?
172920,what do you mean by any particular distribution ?
172935,"you might want to provide more specifics ( including if relevant the software package you want to implement this in ) to increase the chances of getting the kind of response you want . for example , if you want to generate an autoregressive series ( at discrete time intervals - or do you want time being continuous ?"
173082,"choosing some values , plotting the cdf , and see if it falls within the band ?"
173308,we'd need to know a little more about your data before anyone could give a sensible answer . can you describe your independent and dependent variables some more as well as the goals of your study ?
173414,in what sense would the sample be representative ?
173418,"for each machine , do you have data on how long it ran ?"
173654,are you imposing some extra assumptions about $ mathbf { a } $ or $ mathbf { x } $ ?
173699,are they nested models ?
173970,"when you say "" train a model "" , which algorithm ( s ) are you using ?"
174113,is $ f $ monotonic ?
174117,have you looked here ?
174266,"can you post some example data , and the results you're getting ?"
174331,"i would say , you need to specify your problem in more details . do you want to marginalize the other factors or account for them ?"
174364,"besides the fact that the 'idea behind' it is completely different , do you mean that it is simpler to minimize $ sum_ { i = 1 } ^ n left ( y_i - frac { 1 } { 1 e ^ { - ( beta_0 sum_ { k = 1 } ^ p beta_k x_k ) } } right ) ^ 2 $ , did you set up the system of equations to find the solution that minimises it ?"
174368,how did you come to the idea that using information gain ( or other uncertainty measure ) _requires_ discretization of continuous features ?
174507,how does this problem arise ?
174835,"are you asking about r , python , or something else ?"
175112,do you have the daily # of occurances over a period of time ( say a decade ) ?
175224,you don't just want to divide by 1000 ?
175512,re your penultimate comment : the equation obviously * is * correct . perhaps you are confusing distribution functions with random variables ?
175730,what is the vcv ?
175822,tb stands for tuberculosis ?
175617,could you please provide a link to where you found the function ?
175846,"first , $ beta_3xz $ ?"
175942,do you want to know how they are associated individually or together ?
176003,"did you search ` install . packages ( "" sos "" , dep = true ) ; findfn ( "" partial structural break "" ) ` ?"
176024,this depends heavily on the data that you have ! how many covariates do you have and how many observations do you have ?
176054,did you find a good approach for this ?
176293,are they all positive ?
176352,doesn't caret use cv as it's default for model selection ?
176437,"i'm having some difficulty understanding your problem . . . what is your dependent variable in this case , i . e . what are you trying to predict ?"
176470,"if they have the same number of parameters , wouldn't sum of squared residuals be one indicator of closer fit ?"
176504,"hi , sampassmore i have recently encountered with the same problem ?"
176955,ecdf meets uniform distribution ?
176970,have you thought about using the inverse hyperbolic sine $ ln { x ( x ^ 2 1 ) ^ { 1 / 2 } } $ transformation ?
177427,"lsdv . . . . = "" least squares dummy variable "" as in econometrics ?"
177720,can we safely assume $ k 0 $ or must we deal with the possibility that the denominator can have nonzero density at $ 0 $ ?
177811,the _ [ particle filter ] ( url ) _ ?
177866,what are $ p_0 $ and $ p_1 $ ?
177913,"if that were the case , why would we have lasso or ridge ?"
178186,"your example of ( 1 / 2 , 1 / 2 , 0 , 0 , 0 , 0 , 0 ) and ( 1 / 2 , 0 , 0 , 1 / 2 , 0 , 0 , 0 ) are non-uniform in the same way , so it should not matter if you are only interested in testing for non-uniformity . so maybe you want to test something more that was not stated explicitly in your question ?"
178217,do you really need the interface ?
178334,"if you write $ lag $ , do you mean logarithm $ log $ ?"
178522,the linearity of the classifier refers to its decision boundary . is it a hyperplane or not ?
178775,what can you say about the independence ( or lack thereof ) of uncorrelated bivariate normal variables ?
178859,are you familiar with the [ characteristic function ] ( url ) ?
178898,where are the individual staff ratings coming from ?
178978,"brainupgraded one consideration would be to leverage a hierarchical approach which would nest individuals within cities . this would have the advantage of shrinking estimates of your coefficients relative to the standard glm form assumed with your current design . another question concerns the scaling of your dependent variable . you suggest that it's yes / no "" did the respondent eat at a fast food restaurant . "" but is that 0 , 1 response based on collapsing * counts * of the number of times a respondent did this ?"
178899,could you tell us in which context you did encounter this formula ?
178900,n . deaths & observation . years are sufficient statistics for the exponential distribution . more interesting : what to do regarding missing observation years for some subjects ?
179110,do you have a question ?
179365,is $ e $ a constant ?
179565,what exactly do you impute ?
179644,how do you compute the score ?
179794,what software are you using ?
179846,a histogram is a plot . what is a chi-squared distance ?
179874,how exactly is the loss function defined ?
179889,"i don't know what feature extraction is , but iv is a method for causal inference . it is not unbiased , but rather consistent as n gets very large . are you interested in prediction , or causality ?"
180043,"that will very much depend on your specific problem . pca , logistic regression and cross validation are very different techniques used to answer very different questions , after all . "" zero heavy data "" could refer to "" many "" zeros in either your independent or your dependent variable . perhaps you could be a little more specific in your question ?"
180086,"you haven't said what data you're fitting . specifically , are you predicting something about customers , or about some other data for which the associated customer is a feature ?"
180391,"could it be an extreme event , or a few of them , causing these autocorrelations ?"
180437,"the question is unclear : what is a "" posterior probability of gaussian distributions "" ?"
180539,have you tried just pushing it through the formula ?
181291,have you tried it . . . ?
181351,"what do you mean by "" pair-wise analysis "" if you have different ns ( 60 vs 4200 ) ?"
181353,could you explain what connection this question has with statistics ?
181373,i don't understand your question . could elaborate with some more context ?
181417,unclear what you're asking . what are your specific concerns ?
181692,what's the exact definition of your distortion metric $ d $ ?
181761,you need to describe what this plot represents . it certainly isn't the graph of a copula ! what exactly is it ?
181941,"what's "" bio stay "" ?"
182171,` e . g . components not orthogonal any more ` why ?
182199,"yuri , do you have descriptive information about the employees and can you compare it to your sample ?"
182444,just to confirm : it sounds as if you are using a pretest / posttest within subjects study design . is that correct ?
182492,what is your reference for a second shape parameter ?
182541,can you provider more informations about the items in this recommendation system ?
182933,"if there was no differencing , would you be able to do the task ?"
182934,"what do you mean by "" create "" ?"
141072,you'll need to provide us with much more information about your problem . what are you studying ?
183090,at least 10 heads out of 10 000 tosses ?
183129,"accounting for skewness would seem to entail subject-matter considerations . as none are sketched here , it is hard to see what you expect . is the variable bounded above , e . g . by 100 , or could it take any value in principle ?"
183164,what would you say your mathematical maturity is ?
183229,is your problem that you want to do this with a limited number of calls to the api ?
183234,"do you need a * proof * of this , or do you want a conceptual explanation that will make this fact intuitive ?"
183332,why is the chi-square the wrong choice ?
183408,"i think i can guess most of it , but could you please describe x , e , $ sigma $ , and $ sigma $ ?"
183438,"a senone is a speech recognition term . is that the definition you're looking for , or clarification of how they're modeled in that paper ?"
183538,how many attributes did you sample on ?
183556,could you explain a little what sort of tests you had in mind ?
183655,your question is not clear which two variables's $ rho $ you want to calculate ?
183813,""" * even though the estimator is asymptotically normal , its distribution is far from normal distribution in a realistic sample size . * "" --- what is the basis for this claim ?"
183858,welcome to cv . you will need to describe your question in more detail if you hope to get an answer . what is the objective of your project ?
184051,"yes , $ p ( x_ { 12 } leq 73731 ) = 1 $ . but what about $ p ( x_ { 10 ^ 6 } leq 73731 $ ?"
184061,"do you just have two random variables or several consisting of the complete histories of more than one bus engine with the values of $ x_1 , x_2 , . . . , x_t $ ?"
184211,""" * the me is calculated generally at the mean of x * "" -- sure , when the effect is linear , but since the effect changes with $ x $ , does that really make sense ?"
184317,can you clarify your situation & your data here ?
184540,which formulas specifically are you asking about ?
184608,is this data on a dense regular grid or not ?
184656,have you considered euclidean distance ?
184838,why do you think factor analysis cannot be used ?
184841,"can you think of the zones as ordered ( ie , one end of the tank , the middle , the other end ) ?"
185071,i don't see any reason why they can't be negative . is there a particular reason / observation that you have in mind ?
185103,"this is a very a broad question , what are you trying to do ?"
185110,are you interested in meta-analysis ?
185192,""" i know that this should equal "" . . . . no , it shouldn't , actually . imagine $ x = 1 $ , so it effectively disappears from the equations . why do you think $ text { e } hat { beta } $ should equal $ hat { beta } $ ?"
185397,"by time series , do you mean $ y = y ( t ) $ and $ x_i = x_i ( t ) $ ?"
185513,"if the transformation is pca , then the $ z $ values will be independent , that might be a solution ?"
185770,"for fixed $ x $ , what are the possible values for $ y $ ?"
185783,"you'll have to roll your own $ sqrt { n } $ -consistent initial estimator $ tilde beta $ for $ beta $ , but once you have that , can't you just multiply the design matrix in each group ( possibly after orthonormalizing ) by $ lvert tilde beta rvert_2 ^ { - gamma } $ and then apply an algorithm for the group lasso with a general weight ?"
185976,are the features categorical or quantitative ?
186084,"why would you need both "" 1 "" terms there ?"
186130,"i'm not familiar with soms , but since you bring up k-means , a common approach is to train them until weights to see if they're within a particular tolerance . does this fit your interest ?"
186125,how many individuals / counts do you have ?
186169,"what do you mean by "" where the true negatives hits peak is exactly where the true negatives hit a trough "" ?"
186276,"since [ covariances are variances of linear combinations ] ( url ) , this question can also be understood as asking either ( a ) why linear combinations of variables are useful or ( b ) why variances are useful . which of these aspects are you concerned about ?"
186621,"when you say "" independent "" do you mean to say that $ x_i $ and $ y_i $ are independently distributed ?"
186654,you are right - have you asked the person who gave you the question ?
186821,can you say more about your situation and your data ?
186893,"you say logic suggests it would decrease . why then are you trying to figure out "" why it would increase "" ?"
186901,would a step by step derivation of a vanilla neural network help you ?
186950,this seems rather like a textbook-style exercise . is this for some class ?
186986,how are the three quantiles and the mean obtained ?
187053,doesn't ` cv . glmnet ` support poisson regression directly ?
187111,"your source seems to be using "" precision "" in a sense similar to "" bias , "" which is often interpreted as * accuracy * . are you sure you have interpreted this source correctly ?"
187394,do you know the true categories ?
187276,"can you clarify ( in an edit to your question ) what your question is asking that is distinct from what's there , or explicitly identify what aspect of your question is not addressed there ?"
187521,certainly those are acceptable from a statistical point of view . is that what you're asking ?
187526,have you had a look at the [ barrier function approach ] ( url ) ?
187787,how did you choose those five months ?
187914,which test are you using to get a p-value for the odds ratio ?
188037,"what do you mean by "" median odds ratio "" ?"
188148,"could you elaborate on what you mean by "" focus the analysis "" ?"
188183,"have you tried using the jacobian method for determining the joint density resulting from the transformation of $ ( u_1 , u_2 ) $ into $ ( z_0 , z_1 ) $ ?"
188186,could you please explain how you obtain the value of $ 2 times ( 2 ^ n ) $ ?
188215,"interesting question , could you please link one of these sources ?"
188355,"it depends , how many categories do you have ?"
188362,"presumably , these are 0's out of some possible total ( eg , 0 patients out of 10 have a heart attack ) . what are the denominators ?"
188369,are there outliers in your data ?
188444,"what is "" a stronger statistic "" ?"
188530,does it need to be a parametric function ?
188594,welcome to cs . se ! 1 . what's a svc ?
188637,"could you elaborate on what you mean by "" write "" ?"
188747,have you looked into the area under an roc curve ?
189000,""" it is said "" . . . by whom , where , in what context ?"
189139,"you say "" it doesn't happen with a shuffle split cross-validation "" but then write "" but even the shuffled k-fold yields the same results . "" how are both of these statements true ?"
189391,i guess i'm confused . under what circumstances would you have an empirical distribution available to perform such a calculation ?
189418,do you have a measure of overall project success ?
189443,these two papers may be useful : 1 ) is object localization for free ?
189491,"where exactly have you seen the "" autocorrelated probability distribution "" term ?"
189610,""" 90 / 10 "" means that you have only 100 observations ?"
189638,do you have the underlying data ?
189727,"what do you mean by "" dag "" ?"
189867,are they all biallelic snps ?
189944,"peter , i believe your question was already answered here : url does this help to answer your question ?"
190018,are you comparing questions ?
190201,"_exactly_ one red ball , or at _least_ one red ball ?"
190252,can you provide some context ?
190358,the information in this question appears to be incomplete . how many hotels are there ?
190303,can you say more about where you are confused and what you need to understand ?
190529,your post is a bit confusing . how does an extreme value distribution enter into this ?
190611,why are you only conditioning u on x and v on y ?
190745,"what do you mean "" the two sample sizes "" ?"
190807,"i think you may need to be much more precise about your analysis to get better advice . using regression just is too broad a description : is this panel data , etc . ?"
190916,this seems a little unusual . can you provide a simple example ?
191111,"the conditional mean , variance and probably other moments of a time series may be changing over time , hence the in-sample correlation may not have a counterpart in population . what are you going to do with the correlation if you find it ?"
191208,couldn't you just take the estimated values for the latent predictors and use these as predictors with a logistic regression approach ?
191579,surely $ np $ is the expected value not the mean ?
191623,"so for each of the 200 images , you compute area % for 7 phases . and for each of the 7 phases , you compute an average over the 200 images ?"
191652,did you mean to share your chart ?
191661,what is your observable ?
192040,"i am confused by two things . first , i don't understand precisely what you mean by "" pivoting . . . a variable "" : could you explain what procedure that is ?"
181421,"i think you're making an analogy to the normal equations in ols , right ?"
192132,is it * eunuch * . . . huh ?
192148,what test do you suppose the minimal p-value corresponds to ?
192423,the computation of the mean is straightforward as explained in the answer . but are you sure euclidean distance as the crow flies is the most relevant metric of distance within cities ?
192492,"are you looking for an informal "" this is probably worth it "" , or some kind of formalized hypothesis test ?"
192629,can you clarify your question ?
192756,"depending on how the confidence intervals are computed , the answer may be easy indeed . but i am curious about the application : what do you suppose this point would tell you ?"
192772,is this by any chance self-study ?
192809,when $ x_ { t-2 } $ has direct causal effects on both $ x_ { t-1 } $ and $ x_ { t } $ ?
192963,are you using sas ?
192915,"hold on a second , are you looking for mvue or the umvue ?"
193122,has it ever gone to 0 ?
193126,are you comparing groups or controlling for covariates ?
193181,is the context linear models with polynomial basis functions ?
193258,this is hard to understand . can you provide more context for this ?
193405,"i agree with peter that this is different . at the same time , i'd ask yliu95 to think through and clarify the question . for example , "" will the . . . significance level of the coefficients be different "" : that's exactly why you would transform in the first place : the transformation would make the relationship more realistic ( linear ?"
193408,what is the nature of x here ?
193561,what aspects of it make it unsuitable or what would you seek in another text that would make it understandable to scientists ?
193728,using both at the same time ?
193855,the example's a little odd as you * know * all the coefficients anyway - why do a regression ?
193873,"because the expression "" $ e ( xu ) ne 0 $ "" does not contain "" $ beta $ "" anywhere , could you please explain the connection you see between the two ?"
194251,can you give us an in context quote where this is used ?
194259,"i edited your equation to include the time subscript for $ delta gdp $ and the error term . i hope it is correct , or should the time subscript be $ _ { t-1 } $ ?"
194405,"are the message categories a , b , c ordered ?"
194438,"do you have just 3 counts , or do you have 3 * sets * of multiple counts ?"
194459,can you tell us a little more ?
194463,is this a homework question ?
194578,"sorry i'm confused -- if your results are significant either way you run the test , what's your concern ?"
194603,"if you know that beta regression is appropriate for your problem , why are you looking for alternatives ?"
194817,when you say uniform do you actually mean uniform ( over some range ) or do you mean you have an improper prior that's flat ?
195152,"what do you mean by "" check "" ?"
195329,what about a 2 sample test for proportions ?
195473,what are these terms you are talking about ?
196621,what is the difference between $ x $ and $ x $ in the term $ x-e [ x ] $ ?
196669,"apart from that , do you want matrix t to be a rotation matrix , or not necessarily ?"
196676,i can't really follow this at present . are you just asking how least squares maximizes $ r ^ 2 $ ?
196718,"it isn't clear what you're asking . if you are asking for r code for double integrals , that would be off topic here . can you clarify this ?"
196747,"when you take log of the * number * of likes , how are you dealing with zero likes ?"
196840,how many samples ?
197053,what is the question ?
197156,are all your data occurring at equally-spaced discrete points in time ?
197370,""" the only dataset i have is the total population of the district . "" you mean a single number ?"
197433,what kind of nonparametric do you mean ?
198118,what is the standard behavior genetic model ?
198190,"can you clarify what "" i want to generate a sample of random variates choosing 5 out of 7 days of week such that the aggregate counts resemble a given day-of-week profile "" means ?"
198274,when did the process start ?
198288,"ideally , you would want to know the sizes of the samples used to compute each correlation--or , at a minimum , you would want to be sure those sizes were either ( a ) close to the same or ( b ) all very large . so : what do you know about the sample sizes ?"
198355,you really need to provide more details for anyone to be able to answer this . what technique did you use ?
198424,( 1 ) do you need a one-sided or two-sided interval ?
192877,in 1 . are you asking if it's possible to have a reference prior that's not a jeffreys' prior ?
198512,"it seems this is more of a practical than a statistical question . how many words would someone have to know before you consider it "" too much ?"
198545,can you supply the output ?
198549,"given the w matrix and a fixed value of n , surely the p by n matrix is not unique . do you wish to find a ( non-unique ) such p by n matrix corresponding to w ?"
198573,"please elaborate , why ?"
198626,"this is going to be hard to answer because it is so sparse . can you say more about your situation , your data , & your goals ?"
198795,have you tried to post your question somewhere on russian-speaking data analysis forums ?
198891,have you checked in the literature ?
199126,what has the question got to do with the title ?
199173,are you looking for way to validate your model or are you looking for important research questions in machine learning in general ?
199232,"just to clarify , your data set has multiple records for each customer ( each time a voucher is sent ) , and also multiple customers ?"
199250,dsaxton why are they both zero ?
198917,does $ p $ depend on anything when this function is called ?
199590,"i am re-reading your question . you are past the idea that $ text { or } = e ^ { beta } $ , am i right ?"
199669,"re "" why isn't the answer zero "" - why do you expect it to be ?"
200114,"many examples can be found by searching our site for [ delta method ] ( url ) . the "" follow-up "" is really a second , separate question . which one do you want answered ?"
200195,see [ what do statisticians do that can't be automated ?
200268,"exactly how you are doing "" robust regression "" is relevant , because many forms of this use a specific loss function which would be natural to use to assess the quality . could you edit your question to provide this information ?"
200320,"by the way , should you have contemporaneous $ delta y_t $ and $ delta z_t $ on the right hand side ( as you do now ) ?"
200816,"wouldn't it depend on what the distribution looks like ( or hypothetically would look like , at least ) ?"
201016,i'm unsure what you are referring to : different definitions of what ?
201062,"could you please explain what you mean by "" give the same coefficients "" and why you believe this is true ?"
201614,what exactly is your goal ?
201855,"using just the definition , it's straightforward to write down an expression for the pdf--but whether you consider that "" analytical , "" or even useful , is another matter . if you want more than such a generality , could you indicate what the distribution function of $ ( x_1 , x_2 ) $ is ?"
201913,in what sense would any of the 200 values be paired with a particular value from the 100 non-convective values ?
202005,"i don't quite see what "" crossover "" means in this context . it is true that your 2 examples have the same values at relatively similar times , but what is the point of that ?"
202016,this makes no sense . you aren't getting any new information by duplicating existing observations . what is the problem w / her existing n ?
201773,in what sense is this * multivariate * ?
202108,what do you mean by 'linear transformation' ?
202294,"what does "" dominant "" mean here ?"
202320,"the use of "" optimal "" suggests you have a specific intended use for your rating system--but what is it ?"
202330,"it's not clear what you are presuming here and there are no sources : "" i have read "" doesn't identify what you looked at , so please give a specific url . there is , naturally , no sense in which any kruskal-wallis test knows about any other you are conducting . how many tests are you conducting ?"
202335,what measure is repeated ?
202361,can you expand on why you think you cannot do this ?
202368,this isn't possible in general . you can't for instance reach a correlation higher than what you'd get when the data are perfectly sorted . maybe you can include some constraints in your question ?
202353,"yes , you can calculate conditional probability from this data -- what do you mean by asking if it is going to "" work "" ?"
202463,"when the first experimentalist worked , did he fix or measure the value of $ y $ ?"
202567,"what makes "" peakedness "" * good * ?"
202606,"do you mean $ x_i ( x_ { i-1 } = x_ { i-1 } ) sim n ( alpha x_ { i-1 } , sigma ^ 2 ) $ ( mind the parentheses ) ?"
202785,"it would be good to know the end use of the matching . such as what sort of data you are searching , pure user input or authoritative data source ?"
202851,how do you know that it's important if it doesn't improve the model ?
202873,why would you like to compare them ?
202958,"could you illustrate what "" a more complicated var model "" is -- and what you intend to use it for ( do a wald test in order to . . . , what else ) ?"
203120,"did you hypothesize that a is preferred a-priori , or are you wondering that now because of the strong preference in the data ?"
203212,"it should be $ omega = $ critical region , no ?"
203374,"you do realize that there are a total of 9 kolmogorov equations , one for each $ p_ { ij } $ ?"
203761,"can the integers go to infinity , or just to 2 ?"
203766,"can you please define "" burstiness "" ?"
203881,could $ sigma_ { it } $ simple be the absolute value of $ sigma_ { it } $ ( since $ sigma_ { it } $ can be negative ) ?
204035,what would you want from this analysis ?
204255,"your question doesn't seem specific to r at all , so don't mention that in the title . more crucially it is quite unclear . do you mean that some variables have been imported in a way that surprises you ?"
204393,"would it be correct to assume $ a $ takes on the values $ 0 $ and $ 1 $ and expressions like "" $ p ( a b = t ) $ "" really mean $ p ( a = 1 b = t ) $ ?"
204933,"the answer to this depends a lot on what you are trying to do , i . e . what kind of analysis are you interested in ?"
205369,why did you include the ` var ` tag ?
205620,are you getting this accuracy on your training set or on a separate set of data ?
205668,"to clarify : do you mean that the data comes from a binomial distribution where the probability parameter is constant across all observations , or that the probability parameter varies from observation to observation in accordance with an ( assumed ) beta distribution ?"
205882,is this a question from a course or textbook ?
205879,what part of the documentation are you having trouble understanding ?
206156,can you describe little bit more the model and especially the variables ?
206186,how do you know you have a normally distributed variable ?
206201,is r square in percentage ?
206294,can you make a factor variable for the grouping and then do plots ?
206306,if each stage is independent and results in a p value then there does not seem to be any bar to using one of the methods for combining p values . can you expand further on the problem as you see it ?
205028,improvement in which sense ?
206460,what kind of effect size measure are you referring to ?
206488,you're asking how to do significance-hunting ( data dredging ) ?
206561,"it's not clear what , exactly "" no correlation ( not necessarily linear ) "" encompasses . do you intend independence or something weaker than independence ?"
207144,do both groups show the same long tail ?
207319,how many respondents ?
207595,this reads like a routine textbook-style question . is this work for some class ?
207643,"welcome to the site . can you clarify why you would "" need to find a non-linear relationship to predict how log ( x variable ) will affect log ( y variable ) ?"
207779,have you tried to use the search function ?
207852,"what constitutes "" fully described "" ?"
207856,please explain what parts of the definition you follow . do you understand what $ theta $ is ?
208029,"it depends on what regressors you use . if any linear combination of them exhibits periodicity of the same period , then you might not need any additional variables . it is strange that you introduce a new variable "" $ t $ "" in a regression that does not involve $ t $ at all : are you perhaps thinking of [ tag : time-series ] ?"
208093,"what exactly do you mean by the "" invertibility of the schur complement $ ( c . . . ) $ "" ?"
208159,statama do you want to test that the effect on child's education of father's education and mother's education is the same ?
208182,"by variance here do you mean covariance matrix , as $ x $ is d-dimensional ?"
208214,"i'm just guessing here , but have you tried standardizing your variables ?"
49837,"welcome to the site . can you provide full links to ( i ) the paper , ( ii ) the r package , please ?"
208589,are the 3 variables response ( y ) variables ?
209068,is ` n ` the sample size here or some other constant that needs to be estimated ?
209096,maybe you should have multi-class or multi-label modeling ?
209299,1 . what is the underlying question of interest ?
209349,what is the sample size ?
209404,is the the book you're using agresti * an introduction to categorical data analysis * ?
209405,"do you only have access to those observations in the larger set for which you can get a fuzzy match , or are you able to randomly select records from the larger dataset ?"
209591,are you just asking for r code ?
209844,could you explain why you think your first formula is correct ?
209939,"i would not create two dummy variables , since r automatically creates dummies from non-ordered factors . simply set the reference category to "" medium "" ( using ` relevel ` e . g . ) . then , you were talking about repeated measures , but i don't see a time variable included in your model ?"
210025,can you give a link to such a code ?
210185,if i read you correctly you are asking how the coefficients change if you add a constant value to all the observations of one of the variables in multiple regression . is that correct ?
210234,spss has nothing to do with this . are the sizes roughly normal within each sex ?
210230,is this a question from a course or textbook ?
210250,"plot a graph for what , exactly ?"
210290,do you have the original measurements or just the summary statistics ?
210818,you've been * un * stuck ?
210953,"what do you mean by "" pg . 35-29 "" ?"
211065,a lot more information is needed here . why do you suspect the data are normal ?
211092,is $ y $ a random variable ?
211336,are you using r ?
211511,could you link to some examples ?
211554,could you explain what you are referring to ?
211687,is your outcome binary or continuous ?
211696,there is no one size that fits all . could you try splitting the independent variable into bins and see the relationship with the dependent variable ?
211708,"what do you mean by "" beta regression "" ?"
211736,are you familiar with the story of the boy who cried wolf ?
212107,in what sense ?
212129,"by "" already have the model parameters "" do you mean that you already have the state vector at time $ t $ ?"
212202,"hi ravi , welcome to crossvalidated . have you tried with reading the documentation first ?"
212882,do you know the distributions ?
212897,gung really ?
212989,"i don't think your formula can be right , for several reasons . perhaps context would help clarify things - such as giving assumptions , and presumably explicitly stating this is intended to be an approximation of some kind , and perhaps explaining why it has the variable where i'd expect to see ( say ) an expectation . where does it come from ?"
212982,does each of the providers make single or multiple forecasts ( e . g . you have $ i $ -th providers' forecast for $ j $ -th turbine $ x_ { ij } $ with multiple values per turbine and per provider ) ?
213272,why do you find it surprising that both are significant ?
213398,"typo , should it be $ e ( y z ) = frac { gamma } { 1 - beta } e ( x mid z ) $ ?"
213460,are you taking taking the mean of each of the 100 $ n $ -dimensional vectors ?
213693,"could you explain what "" bayes formula without summation in the denominator "" is intended to do ?"
213862,"to reduce potential ambiguity , which particular wiki * pedia * page were you looking at ?"
213917,why is there no need to consider insignificant factors in further experiments ?
214065,what is mape ?
214127,what is your question . . ?
214202,what's wrong with ` qqplot ( scale ( x ) ) ` . . . ?
214356,"it's going to be impossible for us to say , given this information . can you post the data ?"
214659,"can you clarify this question , you have some data $ x $ and you are going to take a laplace transform of some distribution $ f $ . i assume $ f $ is from an "" empirical distribution , "" can you clarify what you mean by that ?"
214671,"you describe $ y $ as the * outcome * , so presumably it's a random variable . one does not estimate random variables--they are random , after all ! moreover , since you state the values of $ p_k $ are * known * , it would appear there is nothing more that can possibly be learned . what exactly are you trying to estimate , then ?"
214719,are there reasons for not using numerical integration ?
214802,i'm really interested in your thoughts on this . this is a really exciting problem ! what are your thoughts on this question ?
214855,there are important details missing . what variables are observed and which are not ?
215480,what would sensitivity & specificity mean in a survival analysis context ?
215581,"can you clarify the "" weight "" ?"
215588,at the moment your different criteria all have different weights ( if you just add them ) . is that what you want ?
215589,"it is not always the case that both coefficients will be large or even of opposite signs , so are you asking about the near * lack of identifiability * , about the * multicollinearity * , or about this specific behavior of large opposite signs in the coefficient estimates ?"
215694,i think what you want is a monthplot url missing data usually refers to a time series that is non-contiguous . this is not your case . how is that a problem for a month plot ?
215721,can you give a reference ?
215828,"do you have the situation that for some expert ratings , you have more than one user rating ?"
207306,i often find that 20 events per predictor are required . but this is oversimplified because you need at least 96 observations just to estimate the intercept . i don't understand why you think a proportion of 0 . 37 for $ y = 1 $ could be a problem . and isn't healthy aging a continuous concept ?
216042,"this question is both very broad and rather unclear . it would be difficult for anybody to advise on what might be the "" best "" clustering technique for data they have not seen any part of , nor the structure of , and only the sparsest of details ( what does "" probability scores resulted from choice experiment "" actually mean ?"
216146,what is you $ h_1 $ . . ?
216276,hyperparameters of what model ?
216299,please paste in whatever context is necessary to understand & answer your question . we want this thread to remain valuable even if the link goes dead . can you provide a complete citation ?
217537,"could you expand on exactly what "" proportions "" you have ?"
217575,why should $ gamma_2 $ ( a coefficient of $ z $ ) have anything at all to do with $ alpha_2 $ ( a coefficient of $ x $ ) ?
217606,can you provide more context ?
217622,"since there can be no more than three stages , the tree would be particularly simple and small . what's the matter with that approach ?"
217774,"why do you consider these "" outliers "" ?"
217826,""" is it possible "" ?"
217847,can you be a little more specific about your data ?
217881,"if you want a * similarity function * , do you require that $ f ( a , b ) = f ( b , a ) $ and that $ f geq 0 $ ?"
218096,"if you have only 1 country then your country variables do not vary within that country , right ?"
218427,so you want to see if particular running groups exhibit particular motivations ?
218556,what exactly is unclear for you ?
218602,"for each original ( step 1 ) experiment $ i $ , define $ x_i $ as the fraction of subsequent ( step 2 ) results that produce findings within the original result's confidence interval . you want to compute the empirical distribution of $ x $ ?"
218852,is the action binary ?
218910,"at the moment this question is quite unclear . what does "" i don't know how to do the labeling "" mean ?"
218757,"yes , i really don't get what you're trying to achieve . there are two problems you seem to be confusing : 1 ) system identification to find your model parameters , and 2 ) kalman prediction ( $ k $ step look ahead ) . can you please explain a bit more about your application ?"
219135,"feels like it could be shown by giving a way to construct such a sample - easy along one dimension , perhaps not much more difficult with more dimensions ?"
219309,are you asking about how to program this ?
219411,did you get cut off trying to type your question ?
219800,how will arima know about seasonality ?
219829,is this a homework question ?
219833,how do you plan to estimate ?
220044,what specifically is the part you do not understand ?
220084,is this a question from a course or textbook ?
220198,did you try at least training your model and evaluate it ?
220274,"given that this question is not asking for r code & states , "" does anyone have practical advice on how i can conduct my imputation for this variable ?"
220357,is this related to your other question ?
220413,"1 . you mean "" intend "" not "" pretend "" right ?"
220422,"well , formally there could be . for example , you can present / model each common factor as a function or several meta-factors . but what's the use of it ?"
220651,this looks like another textbook question . have you checked out the self-study tag as suggested in the comments to the previous question ?
220766,are the error independent of one another ?
220845,what is your goal ?
220878,"i don't understand where the latent representation would come from . it sounds like the output of the network is a prediction / reconstruction of the data , but what are the inputs ?"
220993,you mean prevalence ?
221051,what exactly are you trying to predict ?
221078,"what is it you want to know , just if the means differ ?"
221350,"what are "" free parameters "" ?"
221546,what happens to your problem after you [ complete the square ] ( url ) ?
221873,could you explain why they need to have opposite signs ?
221987,are you sure about what you're asking ?
222235,"stephankolassa , why not develop that into an answer ?"
222297,"please tell us what "" good "" and "" bad "" means . are you referring to data quality , to the data themselves , or even perhaps to some personal feelings about them ?"
222617,"welcome to cv . by "" human survival times , "" are you referring to mortality tables ?"
222802,"i am not saying this is "" the "" correct term , but how about "" non-credible region ( s ) "" ?"
222813,"do you mean that 30 % of the value range from 0 . 0 to 1 . 0 defines a red event versus 80 % of the range that is blue , and that you do not know the probability distribution of those values across the range of numbers ?"
223185,can you just confirm you mean mathematical graphs not statistical graphs ?
223197,is your choice of $ xi_k $ a pragmatic one or is this threshold of particular interest ?
223361,"if i understand correctly , you have 1 . ) age at beginning of study 2 . ) age at end of study 3 . ) indicator of whether subjected died withing the study and 4 . ) if they died , the time of death . is that correct ?"
223426,"a ) i assume injuries are not ordered ( e . g . by location , type , or so ) - so a patient with injury4 will always also have injury1-3 too ?"
223636,how do you split your train and test set ?
224050,why do you say running imputation on this dataset takes forever ?
224129,"suppose i am located one meter along a road from its start and you are a thousand meters down the road . although our distance is 999 meters , our * normalized * vectors are identical . when you normalize a nonzero vector you throw away all information about its length . how could that * not * affect distance calculations ?"
224236,"what do you mean by "" duplicating "" it ?"
224478,does the answer here url help ?
224498,how are you looking to compare the two distributions ?
224715,"okay , and another couple of questions : 1 ) are these measures your independent or dependent variables , and 2 ) do you expect the right and left measures to be related ( and if so , how ) ?"
224964,do you already understand standard ( single-agent ) reinforcement learning reasonably well ?
225016,"for the population total you need the population size , right ?"
225229,"it depends on the purpose of your study ; do you want to analyse how good your model fits the data , or do you want to analyse the 'impact' of an independent variable on the dependent variable ?"
225332,"would it be possible to model company size as a continuous variable ( e . g . , number of employees , annual sales , or some such ) rather than as a 3-level categorical variable ?"
225632,"do you want to fit a gaussian curve , or determine whether the data was drawn from a gaussian probability distribution ?"
225682,what do the minus signs mean in the first one ?
225688,does this help ?
225638,please clarify . are c and d counts of number of words ?
225961,why do you want to use sem ?
226101,how much lines per person will you have in your sheet ?
226104,what is the basis for your preliminary assertion ?
226143,do you mean running a logistic regression ?
226006,newbie is treatment random ?
226185,"why do you want to find a saddlepoint , and what is its higher-level use ?"
226292,do you have any negative values or noninteger values ?
226364,is this related to probability or statistics ?
226371,have you factored the data frame ?
226399,bayesians assume $ theta $ is random . frequentists assume $ theta $ is non-random . which framework are you using ?
226419,you might want to say a bit more as this is a huge topic . do you want it to also include glms ?
226025,how many months of data do you have ?
226465,what is the denominator here ?
226504,"what is the form of the density which you have , which you know ( or assume ( ?"
226523,would you be willing to share some more details about the variables ?
226703,"how many is "" very few "" ?"
226778,is it the question from before ( that i put back in the text ) ?
226967,gdppc means gdp per capita ?
226986,does it . . ?
227090,what do you understand a residual to be ?
228206,maybe gaussian mixture models ?
228558,welcome to our site ! is this a question from a course or textbook ?
228644,what is the distribution of x ?
228907,are you willing to assume the scores to be independent ?
228924,can you give more details about the model you are using and the data-set ?
229249,"what exactly is a "" blocking variable "" in this case ?"
229265,do you have already annotated example for each information type you want to extract ?
229445,where did the defaults come from ?
229459,different in what sense ?
229534,"if you are trying to predict the future based on factors a , b and c , you must have some type of model that takes in these three arguments and spits out a prediction . why not make year one of the factors in your model ?"
229545,have you tried forming a recursion for $ p $ ?
229279,"when you say you want to "" add and multiply them "" what is being added or multiplied ?"
229837,does [ this answer ] ( url ) help ( the update part ) ?
229882,""" i can't really see it "" suggests you seek intuition rather than proof . which do you want ?"
229908,could you indicate how you think stratified sampling might be applied ?
230028,have you thought of venn diagrams ( also called euler's circles ) ?
230160,"when you say "" corresponding "" do you mean are the two sets of measurements measuring the same thing , perhaps with some level of discrepancy , or do you mean measuring two different things that should be similar in their behavior ?"
230187,"whether they measure the same on average , & which is most meaningful are different questions . how many measures will you have from each subject from each device ?"
230333,"do you mean that they are zero-mean independent terms of any distribution , or in particular normal variates ?"
230363,is this for a homework or self-study problem ?
230372,can you say a little more about the initial model ?
230483,do you just want to show whether men are different from women overall or do you want to do it question by question ?
230384,i don't understand what you are asking about . can you make this clearer ?
230493,why do you want to randomly select non-attack days ?
230499,"what do you mean that they are "" all different "" ?"
230534,can you confirm that the propensity score will be used to balance treatment assignment and that you have more than two treatments ?
230540,( 1 ) where did this null hypothesis come from ?
230563,are these 110 panelists a sample of a larger group in which you are interested ?
230639,"dear keerthi , maybe you can explain why you think the fact that the coefficient of variation is low is a problem ?"
230758,what is your question ?
231027,what is the relationship between the two samples ?
231034,by 500 data sets do you mean 500 rows if no then can you tell us what these 500 data sets are ?
231068,what of some of the variables have no effect alone but have effect when taken together with others ?
231082,how many different pages do you have ?
231127,what is the prevalence of the outcome you are predicting and how many predictors do you have in the model ?
231158,weak exogeneity is what you've written there and for ols that will be sufficient for consistency . but i don't think the constant not being there matters ?
231288,have you tried searching through the page : url . . ?
231318,"wouldn't the prediction mov = winning_tm_pts - losing_tm_pts work perfectly , without any need for statistical analysis ?"
231471,"please spell out your acronyms . what is "" ntlk "" ?"
231532,how would you resample with 4 observations only ?
231545,what values can $ i $ and $ t $ take on ?
231534,"there is a * beta distribution * and it has a * cumulative distribution function * ( cdf ) . the sense of * mean of the distribution * is clear , but what in what sense do you refer to "" mean of the cdf "" ?"
231639,could you narrow down the topic ?
231685,why not extract the residual df from the object ?
231692,svd itself isn't a clustering algorithm at all . do you mean by it some clustering algo using svd ( there exist some ) ?
231746,"do you mean that , for example , you want to know if subject-object is less common than object-subject ?"
204254,"if you give exactly 180 potatoes to pigs , then all the possible combinations will sum up to 180 -- or am i missing something . . ?"
232152,"did you happen to look at the documentation url , and see a parameter called 'weights' ?"
232221,how are these several million aucs related ?
232271,"ind . oneway . second ( m , sd , n , unbiased = true , contr = null , sig . level = 0 . 05 , digits = 3 ) why not specify n ?"
232399,what's an xyz file ?
232400,do you mean $ y = e ^ { ax } epsilon $ and $ log ( y ) $ vs . $ x $ ?
232447,can you explain the context in which you encountered the two terms ?
232773,"note that there really is no cox survival curve , the cox model estimates hazard ratios and the survival curve itself needs to be estimated by other means . depending on your goals , the risk scores and coefficients from a cox model might be enough . what exactly are you trying to learn from your analysis ?"
237839,maybe ( ?
254795,why did you think balancing your data would imporve performance ?
256111,isn't optimization ( maximizing i assume ?
264833,do you know about the inverse gamma family of distributions ?
265168,"although it is a question about a statistical analysis procedure , it seems to be more mathematical than statistical . it is not about the algebra of cca algoritm ( such as outlined [ here ] ( url ) and in other threads here ) , but rather is about linear algebra . maybe ( perhaps ) it is better to move the question to a math site ?"
268904,"if you can included nonseasonal dummies , can you not slip in seasonal dummies in their place ?"
223369,what type of classification scheme are you using that has no hyper-parameters to tune ?
280143,aren't you just comparing behavior to one factor ( whether the group size is three or five ) ?
284024,is this an answer to your question ?
284655,was treatment assignment by randomization or up to the treating physician ?
284688,can you write $ hat y $ as a function of $ x $ in each case and see what happens ?
285386,the question is confusing . do you mean that you want to show that x is also a good predictor of z ?
285976,could you please explain how do you get to that expression and tell what $ theta_ { y } $ is ?
286475,before solving this we need a bit more information . do we assume the coin is fair ?
286720,did you tried to shuffle observations in training / test set and measure performance again ?
298531,you provided half information . can you provide more context of the data model ?
302021,do you have survey data or anything else ?
302401,do you want to analyse each task completion time separately ?
305637,presumably $ p ( ) $ denotes a density . is that correct ?
313095,"if the dependent variables were not correlated with any independent variables ( or any of their linear combinations ) , why would you even be attempting regression in the first place ?"
160725,the inequality needs quantifiers . do you mean * for all * $ a $ and $ b $ or * there can exist * $ a $ and $ b $ ?
330824,is this cross sectional data ?
337259,logistic regression is for binary data . is your count variable a covariate or the outcome ?
169426,what's a study variable ?
174797,"by "" window "" , do you mean how much past data to use ?"
180304,have you tried brockwell and davis ?
183197,"you should define the size of the data ( big can be 10 000 , 1 million , more ?"
160935,"hi . i cannot believe your question still exists , for over five years and there is no answer . i have got the same problem . have you found anything instructive on that ?"
190195,are you doing these on the same dataset ?
193979,"have you thought of using the representation of a wishart matrix $ x sim mathfrak { w } ( v , n ) $ as a sum of $ n $ matrices $ y_iy_i ^ text { t } $ when the $ y_i $ are iid $ mathfrak { n } ( 0 , v ) $ ?"
196589,"in what sense do you mean that brownian motion "" exists "" ?"
202830,do the models have different amounts of data ?
210456,do you have either of the group means ?
213170,"just to clarify , if ` sim ( a , b ) thres ` and ` sim ( b , c ) thres ` but ` sim ( a , c ) thres ` , the partition can be either ` { a , b } { c } ` or ` { a } { b , c } ` , right ?"
215759,which linkage methods are you using ?
219488,please specify what type of non-stationarity you have in mind . unit roots ?
221139,how is an answer for this different for a nn than for another alg ?
221353,"could you explain why quantifying the "" dimensionality "" might matter in your situation ?"
228729,"can you please define "" best "" ?"
169250,"i am a bit confused by the wording of your issue . you have data in a column , but can that column only contain 3 unique values ?"
171406,"could you give some more detail , like what is your goal ?"
177324,sorry to be thick but $ k $ ( i assume to be the truncation level ) is unknown ?
177448,can you paste in the actual question ?
178563,could you provide the full quote from the textbook and the reference ?
179933,the first thing you mention is a null ; presumably you mean against an alternative of at least one not being 0 . is the second thing mean to be an alternative hypothesis rather than a null ?
181871,"is the x_i2 in the second model also an exponent , or just a multiplication ?"
186536,"please explain what role this might have in "" nonlinear regression . "" could you clarify why you are calling a method of generating * normal * random variables an "" exponential transformation "" ?"
186983,do you have any other information ?
187463,hi ann : can you clarify which path ( s ) in your mediation model you are trying to meta-analyze ?
189573,"if you know the variable isn't a count , why do you want to use a count model ?"
195059,are you just asking for code ?
195068,do you assume that the new observation comes from the same population as the ones you used for training ?
199373,sometimes . the answer depends on if the data was collected under identical / similar circumstances and your goals . can you provide additional details ?
200684,this isn't clear to me . are you asking how to use regression to count the number of rows in a table ?
206388,how does it follow ?
207626,[ here ] ( url ) ?
209498,you want to take a sample of your data & have it still be distributed as a pareto ?
211749,can you add more context and make your question more concrete ?
213339,could you give some information about what you are trying to model ?
214398,"they are totally different things , so could you clarify what makes you consider them "" essentially the same "" ?"
218261,how many amplitude-radius pairs per set ?
219823,"do you need the concepts and formulas , or are you just looking for ` r ` code ?"
220315,can you highlight the * statistical * nature of your question ?
220243,"you have stated you are confused , but what is your question ?"
222342,where did you get that formula ?
223159,what exactly is your scientific question ?
224182,related : [ how small a quantity should be added to x to avoid taking the log of zero ?
226522,do you see colored images in the first link ?
228400,"are we seeking to maximize the entropy ( of the sum ) over all possible joint distributions of $ x_1 , ldots , x_m $ with the condition that the marginals need to be $ bern ( 0 . 5 ) $ ?"
230114,should formula be $ ( w ^ t x_i b ) _ $ which is hinge loss ?
234054,"perhaps "" hidden units "" data ?"
249296,when you say beta do you mean the standardised values which spss reports ?
233025,in which context ?
231955,""" however , in my understanding , random forest is using the mode of these trees to classify new items . how can i access this , and perhaps display a final decision tree ?"
234177,"the correlation measures the degree of linear dependency , it's does not by it self indicate that a linear relationship exists . why not try both a linear and non linear method and see which work better ?"
235389,can you give an example of your data set ?
239616,"could you explain what you mean by "" proceed "" ?"
240778,do you expect to see at most one anomaly or might you have several ?
243668,"what does "" optimal "" mean ?"
250088,can you provide more context about the data ?
250860,"hint : what is the covariance matrix of $ ( hat { beta } _1 , hat { beta } _2 , hat { beta } _3 ) $ ?"
251511,your hypothesis should be about the populations from which the groups were drawn . are you proposing to test the hypothesis that they have the same mean against the alternative that the means differ ?
253453,"the answer is "" yes "" . however , before giving more details , can i ask if this is a [ tag : self-study ] question ?"
253982,""" the . . . bar graph of means "" suggests that you have a specific design in mind . is showing a set of different means by different bars sufficient ?"
254092,is this an exercise for some class ?
254299,"could you please elaborate on exactly how these variables "" allow me to split a cohort into two "" ?"
254712,could you provide an example dataset ( possibly toy example ) ?
254961,"there can be no general answer to the question as you stated it , because it will depend on the correlation of the predictors $ a_ { 1 : n } $ with * * each other * * . do you have training data ?"
255830,"please explain your problem some more . what does "" i'm having a linear model "" mean ?"
256005,what aspect of the pattern are you intrigued by ?
256979,are you familiar with [ units analysis ] ( url ) ?
259068,"in the case of ( 1 ) , are linear combinations of $ x $ and $ y $ normally distributed ?"
262659,what do you want to do with these coefficients ?
263608,are you talking about error on training or test set ?
266442,from where is the second formula ?
266465,what is your strategy for deciding when to re-roll ?
269476,"could you clarify what "" i had negative values so i transformed the data "" means ?"
270218,what ?
270328,"you should consider the literature on pairwise comparisons . i am puzzled by the numbers and the "" na "" symbol . where do you show the individual players' game scores ?"
273916,what have you done towards finding the answer ?
210585,by $ exp ( x ) $ do you mean the componentwise $ exp $ ?
280208,"how is the duration of the incidents modelled , perhaps a normally distributed duration ?"
247818,do you want to use all your predictor variables simultaneously or do you want separate models for each ?
283413,or you used age group as continue covariate ?
283823,could you give an example of your data and the glmer output you are talking about ?
286049,"a cost function relates the cost of a type i error to the cost of a type ii error or the cost of incorrectly estimating the cost of a parameter location . for example , what is the cost to you , a consumer , to be told you have cancer when you do not ?"
285708,what software are you trying to use ?
288053,did you notice that $ ( 20 . 7 ) $ and $ ( 20 . 12 ) $ are different probabilities ?
289378,"there's an "" increase "" at time 2 relative to what ?"
298637,"please clarify your situation : is each $ x $ obtained by drawing $ p $ and then drawing from bin $ ( n , p ) $ or is the sequence obtained by drawing $ p $ once and for all and then drawing an iid sequence from bin $ ( n , p ) $ ?"
301581,what does indefinite mean ?
121894,two questions : 1 ) is ` n_components ` stands for the number of components / factors you extract ?
302690,do you have a specific r-code question ?
302956,fisher's iris data ?
324574,why are you choosing the wilcox test ?
18287,is the mean a known value or is it to be estimated from the sample ?
171924,are you using the response to discard the irrelevant features before removing outliers ?
232911,is the noise contamination for the $ n_i $ independent from $ n_j $ ?
232921,"offset doesn't work , e . g . url ?"
232922,"just curious , what does it mean a test for a variance within a group ?"
202276,"by "" stacked "" do you mean for example "" character-level token-level "" ?"
233119,it seems you are translating from another language ; are you sure that you have translated the text correctly into english ?
233275,what is 0 . 29 measuring ?
233284,what was the actual skewness value ?
233344,1 . is it definitely the mean of the distribution of differences you wish to test ( rather than a more general kind of location-difference ) ?
233443,significant differences in _what_ ?
233712,just to be clear -- protein level ( as recorded in the original data set ) is ordered-categorical ?
233762,"is this different from your recent post [ "" show that , for a constant vector a , $ cov ( a ^ tx , e_i ^ t ( x-  ) ) = _i a ^ te_i $ ?"
233834,aksakal points to an important issue : exactly how do you intend to use ` normaldist ` in your algorithm ?
233856,you mean something like url ?
234198,is there an experimental design to go along with the data ?
234255,""" for instance the factors "" default "" and "" marital status "" have different levels "" - what do you mean ?"
234280,where would lasso and elastic net fall into ?
234443,"we're going to need more information here . what do you mean by "" best author "" ?"
234570,do you mean each study reports the or or rr for a number of cut-offs ?
234585,"whuber how can it be not about statistics , machine learning ?"
234732,could you precise your question ?
234736,is your question about a conjoint analysis or 'linear mixed model with repeated measures' ?
234859,"$ z_n = 0 $ with probability $ 1 / n $ , z = 1 else . what happens to z as n goes to infinity ?"
235007,"you should be interested in accuracy or parameters at least a little . otherwise , why bother classifying at all ?"
235118,"can you explain us what is fpr , tpr ?"
235565,"when you say subject to random effects , are you referring to mixed models or are you referring more broadly to data generating mechanisms ?"
235643,context ?
235648,"welcome to crossvalidated . notice i edited your post to highlight code formatting . when you say it's "" taking too much time "" , how much is too much ?"
235903,"pca minimizes l2 norm . are you asking why it does not * also * minimize the l1 norm ( meaning that you think that it's equivalent ) , or are you asking why pca was developed with l2 and not l1 minimization ?"
235755,this is pretty counterintuitive . it sounds like a kind of proxy for double centering but double centering has never given good results for anybody i know of . what are these four values ?
236066,"would you see a use for ` sim ` as in $ sim n ( e vert0 , beta ^ { -1 } ) $ ?"
236139,"you do not seem to mention any target distribution that you want to sample from , so why metropolis algorithm . . ?"
236167,could you tell us what this variables really is ?
236184,have you tried running an individual regression model and inspecting for any violations of assumptions ( i . e . non-normal studentized residuals ) ?
236235,are you looking to apply the definition of expectation to this case or for a method of numerical calculation ?
236382,have you taken a look at generalized additive models ?
236395,have you made an attempt to look up any references to solve this issue ?
236403,there is not enough information here to calculate the probability that you win . can you clarify ?
236463,are you testing equality ( all parameters equal ) against the alternative of any inequality ?
236470,"can you give an example of such a table , and maybe an example of the context it would appear in ?"
236556,"when you talk about "" a board "" , does that board occupy the whole of $ mathbb { r } ^ 2 $ ?"
236625,"hmm , i've once implemented a cc-algorithm , based on a proposal of s . mulaik in his monography on factor analysis and had never seen such problems . don't know whether there is something interesting for you in this ?"
236692,"by standardize , i assume you mean , mean center and divided by standard deviation ( or something similar ) . why not do that before cross validation ?"
236774,what is the basis for your assertions about the units in your question ?
236801,are you about rm-anova ?
236803,"i * think * what you're asking is that since all combinations of $ 100 $ outcomes are equally likely for a fair coin , why should observing 90 heads be any more evidence against the hypothesis of fairness than observing 50 , 51 , or even 100 heads ?"
236970,"it's somewhat unclear what you're asking here . are you basically asking "" is it okay to have to draw each boxplot on different scales "" ?"
237012,"because "" significant "" has a well-known technical meaning in statistics , but is not applicable here , i have to ask : what do * you * mean by "" significance "" ?"
237018,what do mean by handling the t-test ?
237042,not sure i understand your question . $ f $ and $ g $ are unknown but you want to sample from $ fg $ * exactly * ?
237217,because the formulas were very clear and easy i suppose your question amounts to how one does matrix algebra in r . i hope a kind r user will help you . but does ` mass ` package not outputting those coefficients ?
237428,are you doing hamiltonian monte carlo ?
237447,hint : $ x ( t_1 ) $ and $ x ( t_2 ) $ are _jointly_ gaussian random variables . what does that suggest about the distribution of the increment $ x ( t_2 ) -x ( t_1 ) $ ?
237761,please keep adding clarification to main question only : ) . what is meant by attributes ( is there additional data eg location ) ?
237784,can you give more details about what you are trying to achieve ?
237876,better than what ?
238020,do you know in advance which groups are likely to be similar ?
238025,it is not quite clear what you mean by different more than 0 . 3 from a mean . can you try to re-express it ?
238154,"in comparison with the 1 dimensional case , are you only looking for a hypothesis test like the shapiro wilk test or are you looking for something like a qq plot to demonstrate approximate gaussianity ?"
238161,why not use the central limit theorem ?
238166,"can you explain why $ int_0 ^ 1 c ( u , v ) du = 1 $ ?"
238144,can you clarify what you are asking ?
238280,is this a homework problem ?
238382,"when you say "" generate labels , "" do you mean generate meaningful labels without manual labeling , or predict future documents from a labelled training set ?"
238407,why don't you call it ' difference in standard deviation' ?
238420,if anova is nsig the ( rare occasional ) sig pairwise subtest should not be honoured . ( else why do anova at all ?
238493,why would you integrate $ xf ( x ) $ ?
238529,are you assuming equal variances for $ x $ and $ y $ ?
238533,are you fitting the distribution to * the same * dataset ?
238757,"i flagged this as too broad . i read this question as effectively saying "" i have some data which may , or may not , have a wide range of different errors . what steps might i take to deal with these errors ?"
238769,what do you mean by variables that don't have units . . . ?
238944,error bar = $ delta y $ = $ sqrt { y } $ ?
239126,what is the model ?
239295,what kind of white noise . . ?
239348,do i understand correctly that the issue here is that the state is ( somewhat ) high-dimensional but each observation depends only on a low-dimensional subspace ?
239538,"can you give some context ( quote , reference ) where did you've seen the terms used like this ?"
239540,"it depends on what one intends by "" informative "" which is not clear . are you asking about something someone else has said ?"
239766,what parameters did you use for calling smote ?
239809,what is your background ?
239864,"could you explain what "" n "" refers to specifically ?"
240058,are all followed for the same time ( i . e . no censoring ) ?
240081,"please explain what a monday and wednesday "" frequency "" means : your usage here does not appear consistent with the usual meaning of "" frequency . "" do you mean observations are made every monday and wednesday only ?"
240215,your question is not fully clear : you have a scalar 2d function ?
240296,can you post your data ( or a small sample of them ) for people to work with ?
240327,"if you're trying to detect non-linearity , why don't you perform linearity tests ?"
240494,can you expand on what the terms in your formula stand for ?
240558,banach spaces in layman terms ?
240563,"for "" in general "" you mean a multivariate possibly multimodal joint density with unbounded domain and no pre-specified parametric form ?"
240573,why shouldn't it work ?
240659,"standardized return data is well known to be non-normal , so why would it lie on a 45 degree line ?"
240679,can you provide a reference / link to this method ?
240772,why have you integrated over the whole domain ?
240823,"can you observe $ ( x_t , z_t , y_t ) $ ?"
241148,"this is very unclear , at least for somebody who is not familiar with your research topic . can you describe your data in more details ?"
241323,why do you want to group those values ?
241459,what is your scientific hypothesis ?
241196,"this is rather broad , & may be hard for people to answer . can you provide some context , perhaps where you've seen these terms used together ?"
241823,why would a high regression coefficient indicate overfitting ?
241867,"answering the question probably requires expertise on self-driving cars rather than statistics , so i am not sure this is on topic here . or did i misunderstand you ?"
241892,"what kind of "" average "" do you refer to ?"
241882,can you provide some context for your question or elaborate this somehow ?
242110,"to notice . i'm not sure if your data is binary ( dichotomous ) , but for [ binary data ] ( url ) bc distance = 1-dice , which is in turn 2a / ( 2a b c ) - not far from jaccard a / ( a b c ) . given that nmds reacts only to monotonic relationships in dissimilarities , i wouldn't wonder if someone gets identical results ( at least sometimes ?"
242152,"could you clarify on what "" points "" are ?"
240834,( 1 ) can you clearly state your question ?
242621,do you mean to only ask about cases where there's one observation per x-value ( as in your example ) or not ?
242675,our sister site [ gis ] ( url ) is devoted to all such platforms and their use . i don't recommend migrating your question there because it would likely be considered too broad and lacking in research . why not investigate that site for a few minutes to see what options are out there ?
242798,perhaps it would be clearer if you said what variables you think you would need in your ancova ?
242875,hint : what happens to your situation when you interchange $ a $ and $ b $ ?
242950,"what do you mean by "" the classes are about 70 / 30 biased towards the positive class . "" ?"
243226,( 1 ) what distribution are you assuming for $ x $ ?
243330,so you are assuming at the same time that $ mu $ is a random variable and that it has zero variance ?
243394,are you asking about confidence intervals ( of what ?
243437,what led you to believe that it is all zeros on the diagonal ?
243615,"what does it mean to say that a student "" has "" a number out of 10 ?"
243777,"machine learning algorithms , as the name suggests , are used to * learn * something from the data , not to simulate it . what kind of data do you want to simulate ?"
243906,show us your code and if possible post ` dput ( yourdata ) ` . what problem domain are you working in ?
243908,"i think you question should be modified a little . "" best "" - there is not answer for that . ask something like "" what are some good methods "" to do tuning ?"
244004,what's importance here ?
244069,could you give us the number of variables you've got ?
244137,are you sure this question is stated as intended ?
244380,could you explain what information the line segments might be providing in addition to the points ?
244409,what are you trying to estimate ?
244400,"could you explain what you mean by "" the data below "" ?"
244493,` i'm very much clear about biplot but here i'm confused with the given plots ` sounds strange . isn't the 1st one a biplot ( with possibly some centering of the data and some form of scaling - the authors should have informed which ) ?
244544,just a minor correction : could it be $ p ( d b ) $ instead of $ p ( d a ) $ ?
244682,you want to test for a difference between teaching & non-teaching hospitals with respect to what ?
244696,"did you notice that the ` [ statistical ] ` tag says "" this tag is deprecated . do not use it . "" ?"
244804,"to normalize price $ x $ to a value from 0 to 1 use the formula $ frac { x-x_ { minimum } } { x_ { maximum } -x_ { minimum } } $ . i presume that you did this already , what is the problem you're having with it ?"
244811,"when you say nonlinear do you mean the predictors enter nonlinearly or do you mean you are predicting the outcome through a log , logit , or other link ?"
244920,[ lindley's paradox ] ( url ) relies on the fact that the $ t $ statistic that appears in both the frequentist and the bayesian answers is kept fixed . why would this statistic remain fixed for all $ n $ ?
245016,was each context tested with different speakers ?
245262,is p a number ?
245282,can you provide any context for this ?
245598,what are you asking exactly ?
245756,what are these data ?
245865,""" before testing this i would like to know if there is a proper answer to that ?"
245861,can you give us a bit more detail about your thoughts so far ?
246164,have you tried igraph or networkx ?
246168,"what is "" incompatible "" about your results ?"
246591,"i don't think 10 features is a lot . . what are your features , scalars ?"
246650,can you indicate which kinds of true nominal variables could be under influence of a latent factor ?
247057,"since it looks that you do not care too much about the meaning of your data , why did you not generate those kind of datasets ?"
247133,could you possibly provide a ( very small ) toy example to illustrate your question ?
247211,is this a question from a course or textbook ?
247219,why not show us your code ?
247301,in what respect to you think they are the same ?
247571,"what do you mean by "" intrinsically non-linear "" ?"
247639,how would you call $ e ( z x ) = x beta $ where $ z = ln y $ . . ?
247875,do you absolutely need a plot ?
248203,"please explain what "" most appropriate "" would be . how would one measure "" appropriateness "" ?"
248611,isn't the click-through rate ( ctr ) defined as clicks divided by impressions ?
248823,would it not be more informative to present a confidence interval for $ rho $ ?
248825,"clarification : in your own code , after you reduced the dimensionality to 3 , what is the size of your data matrix ?"
164048,"user777 you mean , you're reading "" explain "" as "" obtain "" or something like that ?"
248952,why not run a manova ?
249094,is this a question from a course or textbook ?
249283,you need a bit more information . how did you tune the regularization parameter in lasso ?
249317,why don't trying to do it yourself ?
249493,"is it better to wear shoes that are too big , or too small ?"
249521,"you seem to be using the word "" residuals "" to mean the * errors * in the model . ( residuals depend on a particular fit whereas the errors are hypothetical random variables . ) is this right ?"
249538,why not use [ beta regression ] ( url ) ?
249545,"this is an r programming question and if so it is off-topic here . see url however , can't you define function which does the part "" c [ [ i ] ] - which ( a [ i , ] = = b [ i ] ) "" and then feed it to apply ?"
249607,why do you need these variables to be normal ?
249645,what does it mean when the gradient of any function is 0 ?
249702,"what do you mean by "" valid kernel "" ?"
249778,what is a formula of your first approach ?
250004,did you try svd and then do out-of-sample extension to get your $ u $ points mapped in that latent space ?
250037,"have you noticed this 5 % improvement on more than one run , and how do you select the epoch for which you report the result on the development set ?"
250058,"it's not clear what kind of explanation you're seeking . do you need an explanation of what likelihood is ( by which "" more likely "" should be interpreted ) ?"
250171,are you trying to evaluate the point forecasts or the volatility forecasts ?
250437,maybe they just mean the empirical mean ?
250497,is this either homework or self study ?
250675,have you heard of the xor problem ?
250720,how does knowing this help you solve the problem in the last sentence ?
250791,"what , in your opinion , is a lax definition of the hazard rate , and what is a strict definition ?"
251275,"i forget . when you write $ 5 pm1 $ , does that mean the correct measurement is between 4 and 6 95 % of the time ?"
251300,"truncated below , truncated above , or both ?"
251456,two time points of the same individuals with one measure ?
251457,do you want it to handle a time series of arbitrary length ?
251643,what do you mean by rda ?
251672,is this self-study ?
251745,"to me , wu-hausman is a test for endogeneity . how do you use it to test for weak instruments ?"
251159,can you include plots of the learning curves you're seeing ?
251917,are you using a specific library ?
251787,can you post more of your code ?
251911,it is difficult to comment on this . if the proportions are based on independent identically distributed bernoulli trials then you could be testing the difference between two binomial proportions . because of the central limit theorem in large samples a two sample z-test could be used as an approximation . i don't see how a chi-square test is a generalization of a z-test . your notation for the null and alternative is confusing . does mean = ?
251961,can you expand on what you mean by the two models not showing much difference ?
252101,"could you elaborate on what the cryptic phrase "" sigma ^ 2 for b__2 being x__i "" might mean ?"
252262,what distribution is e ( 0 . 5 ) ?
252333,how have you identified the right structure for the x matrix . since this is time series there may be lags needed and potential delays . there may be anomalous values in y or any of the x's . there may be changes in the model's parameters over time . have you resolved these issues analytically ?
252436,what meaning is there in the sum of the ordinal / ranking scores ?
252587,welcome to cross-validated and thank you for your question . are you specifically interested in published measures or would you be happy with some impromptu translation of he betweenness to your task ?
252688,"have you looked for the answer in a time series textbook , e . g . hamilton "" time series analysis "" ?"
252703,"by model combination , do you mean model stacking ?"
252735,how high is the correlation between the two variables ?
252910,this is rather opaque . can you make this clearer & more concrete ?
253030,is this a time series ?
253031,"do you want continuous data , or discrete data ?"
253022,"this question would not be a duplicate if the question was , "" why have deeper neural networks risen in popularity ?"
253217,""" in the xor network , there are 3 neurons excluding the inputs . therefore 3 decision boundaries should be drawn . "" why do you think this is so ?"
253480,what is the purpose of study ?
253518,does this help : url ?
253922,what does pdl stand for ?
253975,"who says it "" is sensitive to unequal variances "" ?"
254056,did you read about how your weight update was derived ?
254167,what parameter optimization algorithm do you use ?
254319,"what's the problem with it being "" skewed "" ?"
254367,i am facing a similar problem while training a neural network . . did you find an answer ?
254385,where is the time index in your model ?
254604,have you tried applying the definitions ?
254617,there are methods which weight the $ p $ -values so you could consider down-weighting the correlated values . would that help ?
254845,are these really zeros ( = events at time 0 ) ?
254884,can you summarise what was written in the methodology you linked ?
254958,is your data discrete or continuous ?
255479,what are you trying to achieve in comparing these curves ?
255559,wouldn't equal variances violate the first premise ?
255793,is this homework ?
255890,"medicine , when taken to include every caring parent , naturopath , chiropractor , shaman , nutritionalist , * etc . * also is a "" world of never ending confusion . "" simply consult the internet for abundant evidence ! nevertheless , there are scientific principles to medicine and modern healthcare is remarkably effective in many ways . should we complain because people who do not have medical training may be so confused ?"
255996,are the $ x_i $ independent ?
256064,did you get a warning when you did the anova ?
256165,can you tell us more about the data and the problem ?
256226,what questions are you trying to answer ?
256258,what do you mean by * outperform * ?
256323,why do you want to estimate the variance ?
256387,have you tried to fix your random seed ?
256904,"what is "" $ bar y $ "" ?"
256965,what you mean by _positive_ or _negative_ class ?
255835,can you clarify whether or not you'll know when forecasting when these price change 'events' will occur in the future ?
257151,what are the bounds on the x variables supposed to be ?
257259,"are you talking about a correlation between consecutive samples of the same parameter , or between concurrent samples of different parameters ?"
257288,what happened in 2014 and first half 2015 ?
57232,did you have a look at the suggestion laid on in the [ r-sig-mixed-models faq draft ] ( url ) ?
257342,are you interested in the number of events in an interval of time or the time between events ?
257386,can you quote what you read ?
257536,presumably $ a ^ prime v a $ is invertible . multiply everything by its inverse : what do you get ?
257778,"imagine someone asks you "" which two numbers add to 11 ?"
257955,"these questions are premised on conflating a definition with a characterization . the poisson distribution is * defined * in terms of its mathematical properties . it often * applies * to counts within time intervals--but that certainly does not limit its scope of application ! this conflation has given rise to a jumble of interrelated questions about when this distribution might be applicable , about glms , about other distributions , about wins , webpage visits , and so on . that looks like it will be too broad to answer on this site . could you narrow your question ?"
258049,"to clarify : when you say that you're calculating a cross-validation error for the degree , do you mean that you are trying out many different degrees ( 1 , 2 , 3 , etc . ) and calculating the cross-validation error for each degree that you try ?"
258179,it depends on what you know - have you used gamma functions before ?
258235,"this isn't an r help site . for the rest of us , what does ` glht ` do , please ?"
258231,""" what i plan to do is to simulate user email generation process in order to predict future behavior . "" this is not sufficient information . how do you plan to predict ?"
258421,this sure smells like a homework assignment . are you expecting so to do your homework for you ?
258466,do you mean the gini coefficient that is usually used as a measure of income inequality ?
253362,"what exactly would "" $ hat eta_ { text { min } } $ "" and "" $ hat eta_ { text { max } } $ "" refer to ?"
258589,what do u mean by known parameters ?
258784,what exactly does not apply in your opinion . . ?
258839,"whuber , should we close this as a duplicate , then ?"
258947,"questions about how to use software ( eg , python ) are generally off topic here . a software-neutral text mining question about how to handle stemming issues when you want to preserve other details ( what ?"
259008,how is there a difference between can reject and have to reject ?
259096,"yes , i got that from your question , but context matters . what kind of study are we talking about ?"
149559,it seems to me that the prediction value will come from the mechanism that you use to build your model . am i understanding this correctly ?
259132,you mean the * explained variance * proportion ?
259026,what is rbf ?
260017,huh ?
260061,what types of model are they ?
260119,can you clarify your question ?
260270,"first , n = 368 is not a large sample . second , what do you mean by saying that "" sample is dependent in nature "" ?"
260297,why can't you use an interaction ?
260366,"welcome ! i think you might want to edit your question to remove the "" multivariate analysis "" tag . . . implies more than one dependent variable . i think you are simply asking about multiple regression ( i . e . multiple predictors ) ?"
260582,maximum likelihood method uses optimization to estimate the model parameters . what algorithms are used for the optimization ?
260587,"could you expand on what you mean by "" sample . . . using the marginals "" ?"
260761,"since $ f $ is a * scalar * , don't you mean to write "" $ n ( 0 , 1 ) $ "" instead of "" $ n ( 0 , i ) $ "" ?"
260766,"by definition , "" low power "" means "" tends to have large p-values even for large effect sizes . "" i would expect that whatever definition you might know could be translated directly into those terms . if not , then what definition are you actually using ?"
260916,do you have access to the underlying source code ?
261101,i think you need to expand on some of this . for instance what do you mean by varying success numbers ?
261123,where did you hear about it ?
261158,i did not understand whether you have time series or not ?
261169,"if you are asking for software , this is off topic . or are you asking what kind of optimization algorithm ( independent of software ) works best for garch models ( converges fastest , does not get stuck ) ?"
261231,what for ?
261459,"your reference to "" marginals "" suggests you have a multivariate distribution , but only a single univariate distribution is in evidence here . please verify the question you have posted is the one you really want to ask . please also tell us why you want to "" find a suitable distribution "" : what are you hoping to do with the answer ?"
261488,hint : what are the predicted sales when the value of ` tv ` is zero ?
261506,could you explain what your graphic is showing and why it does not seem reasonable ?
261521,can you give a reference ?
261560,why not sample * from * the gamma distribution ( ` rgamma ` ) if you assume that your sample comes from the gamma distribution ?
261771,why do you care about the distribution of your data ?
261963,so are you saying you saw this somewhere & are wondering what they did ?
262098,are $ epsilon_t $ and $ epsilon_ { t-1 } $ independent ?
97077,what's the difference between the two samples ?
262185,sampling properties of pca estimators ?
262823,why do you want to select only one sensor ?
262838,"it depends on what you mean by "" ok "" and on the nature of the data . for instance , what would you do if any $ y_j x_i $ were zero ?"
263110,is it one choice test ?
263217,got any answer on it ?
263231,could you explain the connection of this question with statistics or machine learning ?
263238,"( 1 ) i see results for four methods , not three . ( 2 ) how could removing evidence of the prediction capabilities possibly improve the methods ?"
263372,what test is that ?
235933,you mean integers ?
263576,what's a bullwhip effect ?
263688,"maybe you have some simila , historic data you can use to guess standard deviations ?"
263828,is the variance of the difference between two random variables the difference of their variances ?
264126,"what do you mean by "" non-event "" ?"
264261,could you please provide details of your analysis ?
264580,why would you do that ?
264593,i am assuming that $ var ( x ) $ is the identical variance of any of the $ x_i $ ?
264601,"could you please tell us what these "" normality assumptions for linear modeling "" might be ?"
264640,how is death measured in each experiment ?
265047,does $ e ( x_n ) $ help in proving convergence ?
265076,the y variable is obscure . is it categorical nominal or ordinal or count or ( discrete ) metric ?
265260,is a $ 1 / 2 $ factor missing in the exponential or not ?
265320,it depends : what analysis do you wish ultimately to carry out ?
265576,can you provide some context for where you've encountered this terminology ?
265606,if y is continuous how can it only have values 0 or 1 ?
265660,can you edit your post to clarify whether this is a group identified from theory or by fishing in the data ?
265943,$ ( 1-x ) / x = frac { 1 } { x } -1 $ is not exponential . it's a branch of a hyperbola . in what context did you see this ?
266030,have you tried feature selection ?
266146,"constant , as opposed to variable , maybe ?"
111074,"what is the "" conclusion "" to which the title refers ?"
266474,looks like you are trying to exhaust all the downsampling methods . does this wikipedia page help ?
266584,can you model it with high standard deviation ?
266750,"could you clarify what you mean by an "" equally expressive model "" ?"
266783,what model do you use ?
266842,"it's not recommended because those regression could give you out-of-bound results . if you want to do that , why not just ordinal regression ?"
267060,[ why ?
267485,what is a normal answer ?
267695,"rather than giving us a putative answer and asking what the associated question might be , why don't you explain the problem you actually have and ask a specific question about it ?"
267908,"all the eigen values of ` sample_corr ` are positive , so the matrix is positive definite . can you show the code of ` is . positive . semi . definite ` ?"
268001,can you share a reference to this off-policy version of sarsa you're curious about ?
268243,yes . but what exactly are you asking for ?
268354,how much data do you have ?
268420,what is gmm ?
33507,have you read about how w is computed ?
268572,what statistic are you calculating ?
268652,i'm curious how you get a dog to respond to a likert item ; - ) . are you saying you have both before & after measures for each dog in 2 groups & want to compare the groups ?
268916,"could you please tell us what you mean by "" the variance "" of an eight-dimensional variable ?"
269034,do you know how to calculate an roc curve ?
269127,do you know the difference between error and residual ?
269137,"you're already familiar with interpreting the cdf as the area under the distribution's pdf ( "" bell curve "" in the normal case ) , yes ?"
269358,hint : exactly what would be the equation of the line based only on average price per square meter ?
269378,"there seems to be no assurance that your objective function is even defined--it looks entirely possible for it to attempt to take logs of negative values . the parameterization looks unstable , too . are you sure this is actually a log likelihood ?"
269438,"alex is your response ordered categories ( e . g . high , medium , low ) or nominal categories ( red , blue , yellow ) ?"
269452,"are you comfortable with linear algebra , matrix algebra ?"
269611,"is there a distinction between an "" a "" and a "" 2a "" ?"
269651,can you be a little more specific / give a more concrete example ?
269615,can you provide some kind of figure ?
269863,is this question from a course or homework ?
270437,could you indicate why the trial lengths vary ?
270514,the question seems to be quite vague . are you asking if you can fit an interaction term like : $ imr_i = beta_0 beta_1democracy beta_2gdp beta_3democracy : gdp epsilon_i $ ?
270807,"why do you think that 3 is the "" mean satisfaction level "" ?"
270955,"i do not see any clusters there , do you ?"
271408,shouldn't this matrix be symmetric ?
271455,"can you please give some relevant reference for "" one of the talks "" , the speaker and / or some relevant publication ?"
271631,"i'm a little confused by the question . it may be that you need to provide more detail . for instance , in designing this study , how did you intend to use the * control * group ?"
271830,probably sf insures against zero denominator ?
271865,do you know how the ci was computed ?
271980,"i take it you want to compare interpretation-1's tool1 measure and interpretation-2's tool1 measure , and these measures are both counts ( i . e . , ratio scales ) ?"
272296,is this a pca function you wrote ?
272499,you can probably answer this question yourself simply by considering how you would use the predicted response . exactly how do you intend to interpret or use it ?
272705,"would "" club "" perhaps be intended to mean "" clump "" or "" combine "" ?"
273177,are you saying that because the fourth row is ' one minus sum of other three rows' that means the matrix can't have full rank ?
273403,"once you've found the hyperparameters , when you say "" test set "" , you mean some hold out data that you haven't used for cv ?"
273423,what characteristic do you have to distinguish new users from old ?
273619,did you exclude the prediction column from your dataset ?
273675,i am not familiar with sap hana but am very interested in solution . could you describe your data please ?
273769,"are we to understand that the "" income gap "" will be the dependent variable in these $ 30 $ cross-sectional regressions ?"
273776,"a properly applied $ chi ^ 2 $ test will demonstrate that there are preferences . ( the null hypothesis of * no preference * is not the same as * no difference in patterns * among the species , and has different expected values . ) but why do that ?"
273826,"kevinkim you have to clarify how this data matrix is used . i presume the columns are your predictors that feed into a model to explain some response , correct ?"
274079,do you expect covariance in the measurement error ?
274255,are you asking the general theoretical question about applying this kind of penalty in a flexible manner or are you looking for explicit python solutions ?
274442,"i tend to view "" dimensionality reduction "" as pertaining to variables ( or features or vectors ) , and silhouette scores as pertaining to clustered objects ( or cases or observations ) . am i wrong ?"
274497,what are the * rules * you are talking about ?
274512,"it's not unambiguously clear what you intend there by "" $ x sim b ( alpha , beta ) , space x k $ "" . do you mean a [ truncated ] ( url ) beta distribution ( truncated on the left at $ k $ ) ?"
274721,"i always think of this as a large markov graph where subpart of the "" journey "" is a transition between the different states . then you just don't want the transition matrix to become unwieldy . perhaps you can aggregate similar pages into one state ?"
274725,why do you want bootstrap standard error estimates for cox regression covariates ?
274804,so your question is : how to determine the values of weight penalties ?
274860,exactly what kinds of comparisons are you looking for ?
275046,where did you see this terminology used ?
275164,is $ sigma_f $ a parameter or a function of the data ?
275373,"intuitively , is 5 out of 20 really "" much more "" then 3 out of 20 ?"
275605,"correct me if i've misunderstood something . . . you have m matrices , and m associated ( leading ) eigenvalues . and you are asking whether it is equivalent to jackknife over the matrices and then calculate the eigenvalues , versus jackknife over the eigenvalues ?"
275755,is there just one or one for each item ?
275806,it would be very helpful to understand what the ultimate goal is . why do you need the normalization ?
275982,the squared deviations from the median ?
276239,"just to be sure , can you clarify what you mean by "" the method of fa would be pca "" ?"
276320,"how do you define the $ sigma $ -algebra on $ mathcal { v } $ , necessary to define $ p ( v in b ) $ where $ b $ any events of this $ sigma $ -algebra ?"
276518,are your data naturally ordered or would breaking them into subsets of equal weight do ?
276573,why no correction for multiple testing ?
276837,how do you know that the ma ( 1 ) model is best whether or not you include an intercept ?
276901,what is correlation of the genes . . ?
277075,you define it in terms of a probability distribution . does a probability distribution need to integrate to 1 . . ?
277385,what exactly is your question ?
277596,what do the axes represent ?
277664,what is given ?
277686,do you have series of realized variances ( and perhaps realized covariance ) or just the vix and xau / usd themselves ?
277767,"i suppose $ mu $ is the fixed effect , which should be the same for $ t = 1 , ldots , t $ . do you do that ?"
278014,what is the model ?
278026,"need to specify what parameter or function of parameters you try to estimate by $ hat p_1 $ . in addition , you have $ e ( x ) $ , and could not find $ e ( frac { x 2 } { n 4 } ) $ ?"
278093,since attitudes to recycling is an ordered categorical variable why not use ordered logistic regression ?
278161,how does $ u_t $ enter into the regression model ?
278209,did you find the answer below satisfactory ?
278247,what is the independent variable ?
278346,which paper are you referencing ?
278357,why do you have a problem with question 1 ?
278358,stationarity is a form of dependence ?
278821,could you give an example ?
279069,are you looking for patterns in the sequence ?
279264,this is an outer product so you have a random matrix ?
279361,you put raw in quotes . . . is really only the d' available or is also available the proportion correct ?
279385,can you please provide one ( or some ) of the references you have already used so your question and a potentially answer as better contextualised ?
279445,i suspect this might have been discussed before on cross validated . have you gone through similar threads thoroughly ?
90985,how many independent variables do you have ?
279648,why do the p-values matter in your question ?
279769,when you say you are required to do you mean this is a self-study question ?
279891,can you post your data ?
280014,"suppose you're on a site where old people stay for hours and hours , but young people leave right away . ( maybe it follows step function at age 18 . ) obviously , age affects your predictions . am i mis-understanding your question ?"
280125,the first question is why you are considering a goodness of fit test at all ?
280318,how much training data is that ?
280376,could you show in more detail how that logarithm arises ?
280466,1 ) why shouldn't it ?
280499,what purpose do you have in mind ?
280500,"there are a number of strange issues here . you claim that 8571 stayed , but really the split is telling you that 8571 have a satisfaction level of $ = 0 . 46 $ . so why is the "" stayed "" part in the data set equal to this ?"
280681,we need more information . what is the goal of doing the t-tests ?
280745,"after getting the image of every player , can you use k-means clustering with k = 3 on the pixels to get the 3 different color groups ?"
280980,how would you deal with a subscriber who arrives to find the carpark already filled ?
281309,i don't really follow your situation . what would be the point of running a pca ?
281362,could you be more specific on what you mean by scale ?
281473,in my experience when r gives me this warning it means i have done something truly stupid . it is a bit like : did you really mean . . . ?
281526,"tell me if im thinking about this correctly : your dependent variable is , say , the temperature , and we have a bunch of other independent variables like cloud coverage and wind speed ?"
281633,could you post the ` head ( ) ` of your data ?
281664,it's sometimes said ( and i've even read it in books ) that you should use nonparametric methods when you have small sample sizes . i've no idea what the justification is for this . perhaps you can ask the recommender ?
281698,welcome to cv . what is icc ?
281878,where have you seen people mention supervised dimension reduction ?
281931,signal / noise ?
282070,what does linear distribution look like ?
282386,did the methods you explored not work for you ?
282461,what are you doing it for ?
282513,i don't understand : has $ b_1 $ occured or not ?
282762,"perhaps it is too late to ask your instructor . this kind of question really makes me wonder why they were not identified and addressed in class . moreover , are these problems genuine barriers to using such models , which could prove quite useful ?"
282835,if you have no prior belief why bother with the bayesian approach ?
282950,"it looks like $ f $ , $ b $ , $ c $ and $ n $ are irrelevant and potentially distracting . ignoring the constant coefficients in $ z $ , which affect the variance in simple obvious ways , aren't you just asking what the variance is of the logistic transformation $ e ^ y / ( 1 e ^ y ) = 1-1 / ( 1 e ^ y ) $ of a normal random variable $ y $ ?"
283034,"if i understand , you have two dependent variables . do you have any independent variables ?"
283116,"are your independent variable data concurrent , or are you trying to forecast future sales based on current iv data ?"
283117,"so you have 3 measurements per worker , is that right ?"
283157,question your basis . can you have negative population ?
283248,$ f_i = ?
283339,what makes you think anova is only for paired data ?
283549,"hmm , the index does seem to mean something , doesn't it ?"
283624,are you asking that if you use the probability integral transform to generate data from a normal distribution and only take values from . 5 . to 1 from the uniform distribution if the resulting data would also follow a normal distribution ?
283798,did the lecturer provide any reference ?
284112,is your main hypothesis the four-way interaction ?
284197,under what distributional assumptions ?
284287,could you explain what you're trying to do in more detail ?
284299,"there seems to be some confusion expressed here . in particular , ` sd ` simply computes an ( adjusted ) standard deviation . it has nothing to do with any assumptions of normality . you might therefore want to rephrase your question in a way that distinguishes basic statistics , like the sd , from your * objectives * . in particular , what are you actually trying to find out about these data ?"
284351,are you assuming that the distribution ( s ) are gaussian ?
284453,did everyone in your study have cardiovascular disease ?
284513,do you know the n in each mean ?
284541,"you seem to be on the threshold of rediscovering analysis of variance : - ) . for some intuition , consider what would happen if the data for person # 5 were 103 , 102 . could you interpret the two versions of the se in that case ?"
83619,"hint : based on your last formula , it looks like the only way in which the data enter into the likelihood is via the expression $ sum log x_i $ . how is that related to the geometric mean ?"
284031,why are you * convolving * those two things ?
284945,how does your confusion matrix look like ?
285129,"do you mean to ask whether you can have , for example , both age and sex as independent variables ?"
285246,"they're * binary * variables , not bernoulli . bernoulli relates to a probability distribution , while these needn't be random . what are you trying to find out ?"
285326,using categorical variables to explain the response is very common in multivariate regression . what exactly are you not getting ?
285331,"how could distribution "" retain time index "" ?"
285346,why not fit a poisson-based time series model ?
285384,by test set do you mean the predictions you'll have to make when your model gets deployed into production and has to make live predictions ?
285506,how does the initial ranking of features work ?
285956,where did you hear / read that one of the assumptions of logistic regression is that you must have continuous predictors ?
286082,can you be more specific about what bothers you about it ?
286087,are you sure your title correctly reflects the question ?
286092,what sort of analysis do you want to do of the subset ?
286114,can you provide reference for those formulas ?
286222,"it's not clear to me why that's a problem . q : "" which model has better accuracy ?"
286225,"is your concern about some source of error ( is this implementation right / sufficiently accurate ) , or is it in relation to the possibility getting a sample ( or samples ) that are by chance far from what you'd usually see ?"
286302,why do you say that having one case and multiple controls is unusual ?
286379,you have sum every days of the same hour ?
286427,"ive never seen anyone evaluate the performance of a model based on the training time . perhaps you are reading about deep learning in particular , which are expensive to train ?"
286441,can you provide more information about your data ?
286519,what is rsm ?
286911,to what do you add the noise ?
287178,is $ sigma $ the variance or the standard deviation ?
287283,are you trying to construct an interval for the proportion that choose lemon ?
287301,$ p_2 - p_1 $ is an effect size . do you have a particular effect size type you want to estimate ?
287329,do you need to add a self-study tag to this question ?
287480,"i think this might be an unsolved problem . the code you link to is * ad hoc * and unsupported by any assessment of its performance or correctness , and therefore it shouldn't be relied on without extensive testing and analysis . do you need the absolute best solution or will a decent approximation be ok ; and if so , how close should the approximation be ?"
287536,does this require the self-study tag ?
287557,what do the rows and columns of the matrix represent ?
287645,it is somewhat unclear as to what you are asking . there seems to be two questions here : ( a ) how to know if ` x1 ` or ` x2 ` is better at predicting ` y ` . this could be done in a number of ways . but you also are asking ( b ) how to compare non-nested models . are you asking which model tests your hypothesis best ?
287705,is non-pair important ?
288060,why not just do the math ?
288163,is there any possibility that the $ p $ -values are being restricted by the characteristics of the test you are using to generate them ?
288452,users might be able to help better if you provide more information . is this a software question ?
288555,"if you know you have 10 classes , why are you doing cluster analysis rather than some form of classification ?"
288583,how exactly would you even get started ?
288601,"what if c and a occur , but b does not occur ?"
288770,could you clarify question 1 ?
288774,"obviously you need * some * estimate of $ sigma $ . thus , is your question about * which * estimator $ hat sigma $ to use or is it about why the confidence interval takes this particular form ?"
290789,if you look at the correlation matrix does that show very high correlations ?
290847,how large is your sample ?
291067,if it is rct already why you use propensity score ?
291202,"are they photographs taken by hand that needs not have the box perfectly head-on , or are they perfect reproductions of the fronts of the boxes ?"
291280,could you give more details about what statistical steps you've taken on the data and what the context / expected result of this should be ?
291377,are you saying the trees themselves are attempting to minimize the exponential loss greedily ?
291398,"can you clarify the part about "" at what value of the continuous variable would we get a desired probability "" ?"
291522,what are the axes in your figure ?
291695,"please share some of your code , this will allow others to help you better . what kind of functions are you using for your analysis ?"
291945,"can you assume a unique mapping from p & q to your new distribution , let's call it u , i . e . ( p , q ) maps to u ?"
291982,"see url for answers to the question "" what is a random variable ?"
292047,"lipsey and wilson ( 2001 ) give the standard error of the _logit_ transformed proportion ( log odds ) . also , when you write "" many studies provide the standard error "" , then the standard error of _what_ ?"
292199,"i assume that in your second paragraph you mean "" . . . incurring bias can lead to lower losses "" instead of "" . . . higher losses "" ?"
292222,do you want to regress $ c $ on $ b $ or $ b $ on $ c $ ?
292289,can you make this more concrete & focused on a narrow question ?
292440,what properties do you want your control limits to have ?
292519,why not just compare the proportions ?
292600,are you asking ( a ) if it is * possible * to do inverse-variance weighting with reml in the ` metafor ` package or ( b ) does the reml estimator do this by default ?
292616,how do you know it isn't stationary ?
292634,"what is the "" conventional "" estimation method in this case ?"
293838,what programming language or software package would you prefer to use ?
293843,"no , it doesn't mean that . it means that , under the assumption that the true value of that parameter is zero , and a slew of model assumptions are fulfilled , that the probability you would observe data giving you a parameter estimate equally or more extreme than what you actually observed is smaller than your presumed threshold . what does that have to do with predictive power ?"
293894,how is it possible to have n k ?
294021,""" slope "" ?"
294108,how did you select your tuning parameter ?
294153,what is your research question ?
294175,the standard definition of error is different . ( see tag ) . what is absolute difference ?
294216,"since the two functions are essentially the same , what exactly are you trying to ask ?"
294315,( 1 ) makes no sense at all . what are you trying to assert ?
294422,why don't you get ( b-a ) ( b a ) = b $ ^ 2 $ -a $ ^ 2 $ ?
294429,what will happen in pca without normalization if you switch a feature from being measured in meters to being measured in millimeters ?
294467,i think you might need to give some more information and an example . what are these subsamples ?
294571,can you define what you mean undersampled ?
294610,what is the response ?
294632,"could you describe what an "" example "" would consist of ?"
294646,the title is unclear . sufficient for what ?
294756,what's fminunc ?
294989,what are you trying to compute ( average number of banks per country ) ?
295108,"first , refine your target : are you trying to predict whether they will relocate in the next 365 days ?"
295149,are there two heavy tails or one ?
295598,the answer to this would almost amount to a complete introductory statistics course . can you narrow it down a bit to a specific scientific analysis where you are in doubt what to do ?
291703,can you clarify what your mod function does ?
295719,what do you want to know about these data ?
296092,"are those performance measurements conducted on testing dataset ( one that was not used for training the model , e . g . via cross-validation ) . . ?"
296224,the presence of a picture is a binary variable which you could use in a correlation . but why not just estimate the difference between the means for the two groups with a confidence interval ?
296270,did they differ so that you ask it ?
296364,"the distribution is asymmetric ; the variance is not - it's just related to spread , and is agnostic with respect to skew . perhaps you are interested in calculating something like an upper 95 % quantile ?"
296869,what was your train / test split ?
296966,"i don't really understand the spirit of this question . mcc is a number ( a summary statistic ) , whereas roc is a curve . are you maybe asking why to use auc over mcc ?"
297141,you sure that it is $ 0 . 05x ^ 2 $ in the exponent and not $ 0 . 05x $ ?
297445,"because the grammar is warped and the question is so terse , it is difficult to understand . could you modify or expand it ?"
297458,how precise is the data ?
297595,"the goal of a cfa is generally to test the possibility that a latent variable or set of latent variables can reasonably account for the observed variances and covariances of your manifest variables . that being said , i am having a little difficulty understanding a research aim in which an investigator wants to use a cfa but include 0 latent variables . there are other extensions of structural equation models like measured variable path analyses . perhaps , this latter approach is more suitable for your aims ?"
297865,what's a caterpillar plot ?
297927,are you assuming that $ x $ and $ y $ are independent ?
298015,how do you get that hypothesized mean ?
297811,"it is difficult to understand what you are asking because you do not seem to have formulated a definite hypothesis and you appear to use technical terms , especially "" parameter , "" in a nonstandard way . could you provide some more background or explanation of what you are actually doing , what these "" parameters "" are , and how they are measured , determined , or estimated ?"
298175,these terms may be idiosyncratic to the text . what is this text and how does it describe or define them ?
298210,` does the above code somehow nest the random effects ?
298355,probability of what ?
298607,what is the first thing you've tried to answer the question yourself ?
298701,"this is the typical case , if all your nodes are pure you have overfit the data . see this ( slide when to stop splitting ?"
298822,"when you talk about correlation changing over time , do you mean the data generating process is changing ?"
298957,what's a blstm ?
298962,you need a distribution . do you have it ?
299529,does your network converge and overfit if you make the training set just one or a few datapoints ?
299593,"define "" find patterns "" . on random data , the predicted class will look random , so what ?"
299640,this is a very broad question and is not likely to get very useful answers . do you have a specific dataset or domain you are considering ?
299639,are you sure you have formulated your question as you intended ?
299816,what about using some weighed f score ?
300173,could you tell more about your use case ?
300661,why can't you use dunn's test ?
300814,that first p-value is $ 10 ^ { -497 } $ and the second is $ 10 ^ { -178 } $ . but why should such a result be a problem ?
300990,"what you have done is ( almost ) discovered that , when drawing independent observations from a population , the standard deviation of the sample mean is equal to the standard deviation of the population divided by the sample size . is this what you are interested in learning about ?"
301071,"what makes you say that the remainder has a "" cyclical "" setup ?"
301080,better in what sense ?
301201,how would you know that b and c do not intersect ?
301305,did you fit both models on the same data set ?
301334,what is the aim of your analysis ?
301547,does the sequence always have the same length ?
301622,what's $ phi $ in this case ?
301688,is your case somehow different from dozens of previous questions on order selection of arima models ?
301732,what makes you think that there are any outliers ( in the sense of erroneous extreme values ) ?
301802,( 1 ) in many practical cases it's impossible or meaningless to set $ x = 0 $ ( what if $ x $ is a person's height ?
301941,discriminant analysis controls for all the variables that are used to create the discriminant functions . perhaps you mean to stratify by some variable ?
302047,but did all of your patients get treated ?
228968,how many participants do you have ?
302333,roughly how many parameters do you have ?
302423,are you checking every observation ?
302437,"it's hard to study tensors from a mathematical perspective without also learning some differential topology or geometry at the same time , as that is where these objects are most important in mathematics . is that something you are interested in ?"
302640,why not use an offset rather than dividing ?
302744,that's called a problem of instability . does it happen with all algorithms ?
302945,write down the rejection rules for both proposed tests . are they going to always reject the same cases ?
302983,are the events the three probabilities refer to independent ?
303106,"welcome to cross validated , hwjang . your question leads me to suppose that you misunderstand the nature of a t-statistic . the magic 1 . 96 number is not relevant to the t-distribution unless the sample size is very large . perhaps start by searching for an explanation of a t-test on this site . if you want the most helpful answers you should provide more context than you have given . what is the table an output from ?"
303218,"these situations can be subtle and complex . for instance , how do you identify these groups of squares ?"
303249,"glen_b , would [ tukey's hsd ] ( url ) or similar not be appropriate here ?"
303276,where did you find your top formula ?
303317,it's hard to answer this question without a clear objective in mind . what application is this for ?
303466,is this from a [ tag : self-study ] question ?
303526,"the image is too small to read the subscript easily , can you edit it into your question as a formula ?"
303553,your demands are not articulated enough . 1 ) what if the object is farther from centroid than the threshold - what is its destiny then ?
303804,"your question is unclear ; you say you calculate the correlation matrix and ask a question on p-values , i assume that you compute a correlation matrix and then want to test some hypothesis , what is that hypothesis that you want to test ?"
303836,couldn't you find out any other reading on the training / validation / test dataset splitting on the internet ?
303916,"you are talking about of out of sample accuracy , right ?"
303939,could you give us ( possibly made-up ) example of your data so it is more clear what is the problem about in here ?
303990,regression splines have defined knots . are you referring to using some particular function in some package where you specify df and that function is placing the knots for you ?
304116,"what's even more , how does this model hope to produce actionable results at the student level ?"
304138,would it be possible to compare using information criteria such as dic or bayes factors ?
304173,to me the summary line on the first graph is tilted . is that an illusion ?
304204,how is depression measured ?
304155,from the deep learning book ?
251528,"i think this might qualify for a self-study tag since you seem to want some hints as to how to proceed , but not the final answer ?"
304481,"* why * do you want to "" add "" them . . ?"
304570,what does accuracy mean here ?
304907,so it doesn't have an optimum ?
305431,"i would begin by considering how the electric bill is given as data . do you have scanned images or the original computer representation created by the energy producer , for instance ?"
305800,"you can always use straightforward rejection sampling if you can find a constant $ c geq sup_x p ( x ) $ . however , the computational issue with having to perform a bivariate numerical integration for every proposal step seems pretty important no matter what . can you write out the three conditional densities and construct a gibbs sampler ?"
306227,"what does "" $ y $ "" represent in your formula for $ hat n $ ?"
306426,is it sufficient to just use the mean squared error ?
306656,"welcome to cv ! i have made some edits to your post for clarity ( let me know if i unintentionally changed the meaning ) . what do you mean by "" normalize ?"
306861,do you want to say that you want to measure an association between categories of p and categories of s ?
306875,?
306911,"well , you can just copy-paste , so what's there to confirm ?"
306920,"i like to use two nearly opposite , but still valid ways to get to the answer . will you accept an answer that isn't symbolic ?"
307071,please provide more information : are the events independent ?
307158,is not it the confusion matrix question ?
307207,your question at the end seems to imply that poisson noise can only be non-additive . why do you think that ?
307353,"rolling origin seems fine . what measures of model quality were you considering , and what are your doubts about this ?"
307436,[ rnn ] ( url ) ?
307447,"i have not heard of the hawkes process , but it sounds like something one might encounter with heavy tailed distributions . did you test for this ?"
307578,why do you believe a mape below 3 ( % ?
307616,"whether it is drift or "" trend "" , you want to supply ( v ) ar model with stationary or pseudo-stationary data . what if you take : a ) first differences , b ) first log differences of your vector and try to investigate the existence of : a ) autoregressive part , b ) seasonality ?"
307788,"i think you're right to be worried about seasonality . saying more about the phenomena of interest would give context : i am guessing at an ecological and / or environmental topic . so , why do you think an annual mean and sd is either needed or useful here ?"
308051,what exactly do you mean by * at run time * ?
308095,this reads like a routine textbook exercise . . . is this an exercise for some class ?
308168,how can i upvote your son for asking great probability questions ; - ) ?
308326,where did you here that definition ?
308795,are you talking about bootstrapping ?
308828,can you expand on the way how you think the data is paired ?
310142,is this a test question or a homework question ?
336611,"by "" football "" i assume you refer to what in the united states is called "" soccer "" ?"
240198,what do you mean by vc matrix of a model ?
241244,"i had a co-worker apply the 1 - cor_matrix method ( in python ) for a client we were consulting for who wanted to use k-means clustering on some click-bait feature for their social media data . it seemed to work fine for their purposes . i will ask though , what data are you trying to cluster and what are you trying to gain from the cluster analysis ?"
137630,is this just a question about how to use stata ?
249625,do you have a reference for that statement ?
249959,can you clarify what you mean by normalise ?
250096,"sorry , can you clarify the question a bit more ?"
255966,you could do almost anything you want but what is your motivation and what would be the statistical justification ?
267381,can you provide a little more context for this ?
277297,what exactly do you want to achieve ?
286651,"what's wrong with something "" mainstream "" ?"
288816,are you sure that it's paired ?
298817,are you familiar with the primal and dual statements of the svm optimization problem ?
310371,"logistic regression does not produce class assignments , only probabilities . so an important question is , how did you convert the class probabilities to class assignments , and why ?"
234271,what are about off-diagonal elements of ` c ` ?
235065,"yes can you add more information about the "" extrapolation "" ?"
236191,"why are you using gbm , vs say an arima ( p , d , q ) model ?"
237286,what you seem to be doing doesn't make sense to me . why are you comparing proportions for one subgroup with the combined data for both groups in the numerator but using a denominator for a subgroup-vs-subgroup comparison ?
238236,"if you have a constraint $ theta leq c $ , then this seems like [ map ] ( url ) estimation perhaps ?"
238606,what is the question you want to answer about the populations of interest ?
240582,so you want to mark a point for the mean and an interval indicating mean $ pm $ standard error ?
241111,how much data do you have ?
244938,perhaps if you share your thoughts others can help you find a way forward ?
248270,did you read the article in that post ?
249212,"what are 0 , 1 , 3 , lables or numbers ?"
252564,do you mean $ beta_1 - beta_2 $ ?
254007,"can you elaborate further on what you mean by a "" nonstatistical "" moment ?"
255278,do you want the lines to meet at k as you have drawn it or do you just want different slopes ?
255498,are the censoring levels constant or can they vary ?
256551,what is alpha ?
261314,what is a matthews correlation coefficient ?
261928,"what do you mean exactly by "" valid "" ?"
263945,i don't understand the question as formulated . could you at least try to produce a grammatically meaningful sentence ?
266034,is this a question from a course or textbook ?
272147,i think you may want to look at the mantel-haenzel method for stratifying odds ratios . out of curiosity is this regarding a heart operation ?
272858,"the description of this process is ambiguous , because it can include all gridded sampling procedures as well as adaptive procedures unrelated to grids : they differ in how the minimum distance criterion is implemented and enforced . do you have a specific problem or specific sampling procedure in mind ?"
274366,hint : could the distribution be multinormal if either of the marginals is * discrete * ?
277846,what are the units for error ?
282362,is it differentiable ?
282586,"to be clear about what you are asking , do you want to ( a ) test an individual who was singled out for such testing for some * a priori * reason unrelated to the data ; ( b ) test all individuals to identify * one * who is "" most outlying "" ; ( c ) test all individuals to identify * any * that appear to be outliers ; or ( d ) something else ?"
285348,"by "" one hot encoding "" do you mean * reference level * coding or * level means * coding ( see [ here ] ( url ) for examples ) or something else , in this case ?"
288603,what are we talking about here ?
290770,are $ a $ or $ q $ known ?
300103,would you kindly add the plot you are talking about to this question ?
300485,i am afraid that this may be too broad to be answerable . . . could you edit to add more details and make it more specific ?
302105,there are a number of questions on this site tagged [ tag : sensitivity-analysis ] . perhaps you could review them again and then clarify what you do not understand ?
302717,is your model linear in all your predictors ?
1507,"why would you calculate the probability of exactly 39 in case 1 , but 39 or higher in case 2 ?"
2423,cw perhaps ?
3136,"skarab maybe i'm totally off , but wouldn't you expect that the frequency of any word will be inversely proportional to its rank in the frequency table of words , according to zipf's law ( url ) ?"
3383,can you distinguish what pre-treatment weight is assigned to each different treatment group ?
3616,"what do you mean by "" different "" ?"
3646,"it's unclear how "" regression "" could be invoked in a * univariate * dataset . also , exactly what distinction are you suggesting between the two bulleted methods ?"
3715,as i understand the [ agresti-coull ] ( url ) procedure is used to generate approximate confidence intervals for the binomial proportion confidence interval . i am not sure i see the relationship to bayes theorem . could you provide some context and your goals within the context to understand how the bayes arises in the context of the agresti-coull method ?
3924,i'm missing something : you have your dataset so you compute its mean * m * and standard deviation * s * . the value at * z * standard deviations from the mean therefore equals m z * s for any * z * you like . where is the problem ?
4918,calculate in what sense ?
5508,really 21st century 2000 and onward ?
5680,could you link to some of those threads ?
6753,i really wonder how an equal frequency histogram might look like . i have the intuition that it is really flat . can you give an example ?
6841,"teucer , what do you mean by simulate ?"
7285,"a very interesting problem . do you have a sample of "" typical population of email addresses "" at hand ?"
7326,"mortimer , good question , can you tell us what you want to do with this sample ?"
8662,"mbaitoff : your comments to the answer of schenectady indicate , that you are less interested in getting the name of the distribution but in finding out why the values are distributed this way . is this correct ?"
8771,"b the answer is that you're asking a different question . you're not trying to decide whether there are significant differences among different options ; you simply need to make the best decision possible , based on these data , concerning which is the best . suppose you had to answer to the head of advertising , who wants your decision : which is "" the best performing ad ?"
8984,"just to make sure , you calculate cv for the sample only from the two measurements ?"
9228,is this a case-control study ?
9299,what do you mean by a gaussian with a variance * and * scale parameter ?
7982,some questions : how many datapoints do you have ( i smell a prototypical overfitting problem ) ?
9581,what kind of clustering method would you like to use ?
9625,do you have a specific alternative hypothesis in mind ?
9607,"sorry , can you clarify what you're trying to do ?"
9817,"what do you mean by "" number of free parameters of g "" ?"
10407,with large ` n ` the independent poisson approximation is probably fine . did you try simulation studies of how well the formula is working ?
11243,josh you added the tag ` ridge-regression ` . does it mean that you have a large number of predictors and / or that you suspect that it has something to do with the observed difference in prediction accuracy ?
11800,are you familiar with the bradley-terry model ?
11899,"jms given that the nominal data would have to be represented as dummy indicators , doesn't that point us right back to the question about [ factor analysis of dyadic data ] ( url ) ?"
11967,can you give a counterexample of what you mean ?
6656,but what is the question precisely ?
12706,isn't it possible that your independent variable that obtains negative coefficient in multiple-prediction circumstances serves as a suppressor variable ?
12648,do i understand you right in that you ask how to classify new objects to the k clusters given that you have the k cluster means ?
12878,"tu what exactly do you mean by a "" risk difference "" ?"
13052,"this seems to have several subproblems . first , you need to find and extract the periods of inactivity for each fish . a person can do it by just looking , but if you have a lot of data , maybe you want to do it automatically . second , you need to combine them for all the fish in one group . third , you need to compare them across groups . which of these do you need help with ?"
13102,"let me see if i'm getting this right : you have two input parameters , one with two levels and one with four , for a total of 8 combinations . for each combination , you ran a simulation with 4 learning agents which cooperated ( ?"
13182,"just out of curiousity , do the two methods lead to a much different ordering ?"
10800,what exactly are you trying to accomplish ?
13922,"the answer obviously has to depend on the text itself . for instance , after shredding a sequence of 100k 'a's , a single copy of the shredded text will suffice . the answer also depends on the actual distribution of the piece lengths , not just their mean $ x $ . it is also clear that some strong simplifying assumptions have to be made , such as that certain locations should not be heavily favored as break points in the shredding process . ( e . g . , if there exists one location that is certain to break , you can never be sure of the reconstruction . ) do all these assumptions leave a realistic question ?"
13961,"maybe you should explain what you are trying to do in terms that are not technical . do you expect to see the same event at different places at the same time , or the same pattern of events at different places at different times , or what ?"
13983,"user it's unfair to speculate about the questioner . let's address the question , shall we ?"
14069,to clarify : are you asking if there are statistical tests that address whether or not two samples are from the same distribution ?
14177,"when you say the "" average expected ratio "" do you mean the proportion in the population that votes for a ?"
14088,is this just a smaller example then ?
14220,"the question "" is there a function to compute the p-value for cor = 0 . 75 ?"
14410,"your question is very sincere , but you're essentially asking "" hey , i have this large device in my basement that has a big tank of gasoline or something connected to it , and there's this big red button on it i want to push . what will it do ?"
14457,what's your model ?
14719,$ n $ has no distribution unless you assume one or unless you have some kind of stopping rule for a sequential experiment . what's your situation ?
14774,"this is can be done via simple binomial testing & macro has a good answer . however , one issue is with the samples themselves : is there anything that could affect your decision to take route a or route b ?"
15585,"b seven - if your validation set gets tainted ( i assume by fitting models to it ) then perhaps dividing your data into a training , test and validation set may be more appropriate ?"
15689,why would you average them ?
15912,did i understand correctly that you intend to use the pseudo- random number generator ( prng ) for generating the random needed for monte carlo ?
16413,"this is politics . do you really think they took the time to conduct a poll , much less an accurate poll ?"
16928,can you describe the actual data you have a little bit more ?
17189,could you recommend me some good sources to learn about rna-seq data and statistical challenges in this field ?
17424,does it have to be a paper ?
17576,"it all depends on what you mean by "" trade area , "" which usually comes down to how you intend to use the result of the analysis . could you elaborate on this ?"
17919,are the $ z_i $ also independent complex gaussian random variables ?
17866,why do you want to do this ?
18023,can you please add the formulas for your model ?
18323,"by "" detailed development "" , what do you mean ?"
18580,"what operational distinction are you making about "" fake "" * versus * "" true "" growth ?"
18781,"what kinds of models ( logistic , presumably ) and which lr tests do you have in mind specifically ?"
18518,"can you give examples how your "" species x year "" matrices look like ?"
19226,do you have way to measure the distance between a pair of sequences ?
19490,could you post all the code ?
19731,where does function ` process ( ) ` come from and what is it doing ?
19470,"( 1 ) are you applying the jb test to ( a ) an dependent variable , ( b ) an independent variable , or ( c ) residuals in a regression ?"
19955,( 1 ) from what data have you estimated $ beta_1 mu beta_0 $ ?
20189,correlations by themselves don't tell us a lot about multicollinearity ; hypothesis tests about correlations tell us nothing at all . what is the [ condition number ] ( url ) of the matrix ?
20295,model consistency is a different concept than asymptotic consistency of the parameter estimates . are you aware of ( familiar with ) this difference ?
20315,what kind of loss function are you interested in ?
20534,are the trials assumed independent ?
20565,possible duplicate of [ what is the distribution of the sum of non i . i . d . gaussian variates ?
20666,have you tried deriving it from the definition of the student t distribution ?
21040,whuber : why a trio of dummies ?
19912,"1 whuber . xboxrob : aren't you , by fitting a curve , already making assumptions about what might be an outlier ?"
21195,"i do not get it . what do you mean by "" theoretically , the number of samples in each group will remain fixed . "" ?"
21426,are you wanting to do an analysis of number of sales ( i . e count data ) or value of sales ?
21578,hi . could you please describe what you mean by the reliability of the expert . is a reliable expert one who ( 1 ) consistently provides similar ratings across wines of similar quality or ( 2 ) is more experienced and you believe their ratings are more accurate ?
21638,i'm fairly sure that there are infinite possible distributions fitting those criteria . generating one that satisfies * all * of them is likely to be hard though . are you trying to find a theoretical distribution that fits a dataset ?
22027,online fitting of * what * ?
22662,"hi there , how many categories do you have for each of your 3 stratification variables ?"
22291,how large is the training set ?
5962,"re disappointment : you wouldn't expect each problem to have the same parameters , so why * would * you expect the problems to share good values for the hyperparameters ( log gamma and c ) ?"
22737,are you treating these ordinal results as categorical or continuous in your main analysis ?
22766,"do you mean convention for naming in a program only , or will there be a meta-data document as well ?"
23044,"if you require that there be no possibility of deviations from this correlated behavior , then these variables cannot be multivariate normal unless they all are linear combinations of a constant and one ( univariate ) normal . but perhaps your restriction is not as severe as this ?"
23690,you need to better describe your data . for example are all your values positive ?
23668,why do you expect the mle to be more accurate than this ?
24170,"if you don't want to discard the rows with nas , and you don't want to impute missing values , what else is there to do ?"
24073,"yes , mike , this one is exactly to solve your question of constrained optimization with non-negative coefficients . on the other hand , just curious why stacked regression or not now popular and commonly used lasso or lars methods ?"
24388,if red and green have a wider variety of items than purple ( rather than just more inventory of the same items ) wouldn't this be as expected ?
24911,are the samples paired ?
25029,"although this question looks focused , it really is extremely broad due to the huge disparate collection of solutions available . so that the question can be narrowed and made effectively answerable , could you please indicate what the * immediate * problem is that you are attempting to solve ?"
25151,"i'm a little confused here . bootstrap seeks to replace an unknown distribution with its empirical distribution , and then some analytic results can be shown when the true distribution is assumed known . however , if you already * know * that your data are coming from a uniform , why wouldn't you just use monte carlo to get samples from that analytic uniform distribution ?"
25358,whuber : can you clarify / expand briefly ?
25723,do you mean [ canonical correlation analysis ] ( url ) ?
25653,why don't you select those features that optimize the value of your performance measure ?
25899,"naught , regarding the spatial aspect of your question , how are your regions defined ?"
25941,"well , the test statistics for each data set separately all have an ( asymptotic ) $ n ( 0 , 1 ) $ distribution . since the data set are presumably independent , why not take the average and treat it as a usual $ z $ -statistic ?"
26115,* oob * ?
26434,what is the minimum value in the dataset ?
26499,"* * hint * * : if $ y = a b ( x-c ) $ , and you know $ y , a , b $ , and $ c $ , can you solve for $ x $ ?"
26587,why aren't you using regular competing risks ?
17881,"you might wish to cast a broader net , because this is not necessarily a time series question . indeed , perhaps the most fundamental question here concerns the best or at least correct way to quantify a treatment "" endpoint "" : is it mean growth in a population after a certain time , average growth rates over time , etc ?"
26958,so is your question how you can obtain a correlation matrix given a covariance matrix ?
26965,do you mean that for each binary response you have ~ 1500 explanatory variables ?
26951,can you describe the data a little more ?
27175,which clustering algorithms have you tried so far ?
27177,does this help ?
27377,"also , don't you have three stocks , not two ?"
27479,whuber that's very well-put . why not make it an answer ?
27741,are you looking into learning about instrumental variables ?
27846,"in order to be most consistent with the question you want answered , should you maybe change your wording from "" i would like to calculate the probability of him touching the table "" to "" i would like to calculate the fraction of contacts that are with the table "" ?"
27863,"what do you mean by "" performance "" ?"
27961,"pca is one of the mainstream methods for dimensionality reduction . however , i don't know if you understand what pca actually does , can you provide your background ?"
19592,you are going to have to provide more information . what do you want to analyze ?
28262,"* * hint * * : $ y_n = x_n - x_ { n-1 } $ so $ y_n $ has zero mean . so , what's $ mathbb e y_n y_ { n-1 } $ ?"
28177,rolando2 : what os is that ?
28540,what is your problem ?
28538,"the key is that var ( ax b ) = a ^ 2 var ( x ) . so you just need to make sure a ^ 2 = 1 . we all have given good answers , but everyone did it as a comment only . are we to refrain from making an answer if the question seems trivial ?"
28761,"if the "" noise "" doesn't have a strong temporal correlation , then the integral consists of the signal plus a random walk , implying its error is ( a ) strongly autocorrelated and ( b ) strongly heteroscedastic ( its variance increases over time ) . moreover , ( c ) the underlying response should be monotonically increasing . this can indeed be accurately fit , but it's a good idea to use specialized techniques adapted to that model and error structure . this leads me to inquire , * what fitting procedures are you comparing ?"
28887,i didn't try to follow your original financial question but i do think i understand your voting analogy . to make sure you hit all the countries you can stratify . take a stratified random sample preferably sampling proportional to size . smaller countries should have small weight because they have less total votes . in the end what are you estimating ?
29016,is there a particular point you are stuck on ?
29176,you're right on all three points : 1 ) it doesn't seem like there's much of a point to the power analysis if there's nothing you can do about it . what is the logic behind this ?
29583,are you sure you have included fs / ms in your cv loop ?
29611,"1 ) why is regression "" hard "" ?"
29638,"exactly what "" median column "" were you looking at ?"
30072,"this question suggests you may have different ideas of what "" representative "" means . the use of t-tests implies you just want the sample to have a comparable mean to the population . the reference to correlation implies you are looking at a second-order comparison between the sample and the population . a chi-squared test examines the full distribution of the sample in comparing it to the population . so , the first thing you could do is reflect on what precisely you mean by "" representative , "" then come back here and share that with us . could you also say * why * you're checking "" representativeness "" ?"
30173,"the issue being , that something like the dow jones index is just an average of some sort of various stock prices , so it is by definition "" true "" for that particular average of stock prices . what is the underlying concept you want the index to be a valid sign of ?"
30236,"so , after that long introductory comment , which situation are you in , alexx ?"
30390,significance of what ?
30448,"michaelchernick , i think there may be a bit more to it though . for example , when you stratify by year , should you also let the random effect variances change from year to year ?"
30414,what is the error message ?
30526,are you asking how to generate non-independent correlated binary data ?
30540,"what do you mean by "" high regression "" ?"
30684,have you tried integrating in mathematica ?
30704,are we assuming the foul occurrences are uniformly distributed throughout the game ?
30781,"what do you mean by "" composite $ z $ -score "" ?"
30699,can you explain this a little more clearly ?
30706,"if you fit a mixed effects model then how have you not "" accounted for repeated measures "" ?"
30919,univariate or multivariate sample ?
31088,"wouldn't the argument in my , now deleted , answer still hold ?"
31519,"momo 1 for a good quip , but aren't you implying there's no difference between statistics , machine learning , or data mining ?"
31280,"which "" many methods "" did you see that in ?"
31538,could you clarify what the response variable is for one channel on one subject in one trial ?
31858,"i don't understand your points . x , x $ ^ 2 $ and x $ ^ 3 $ are not orthogonal . hence they are correlated and the regression parameters could be unstable , but it is not automatically the case that they are unreliable . conversion to orthognonal polynomials may be more reliable . but what makes the coefficient of the original powers of x any more interpretable than the coefficients of the orthogonal polynomials ?"
32295,see ` ?
32377,"michael , i do not understand why your statement is true . a p-value less than . 05 will occur under the null hypothesis 5 % of the time * regardless * of sample size . so how can it be possible that larger sample sizes will solve this problem ?"
32719,"i am both puzzled and curious as to why you would be interested in solving such a problem . i think the term "" largest sample "" is not what you mean . don't you mean that you want to estimate the noncentrality parameter of the maximum of the fs ?"
32725,what do you call a variance covariance matrix of a matrix ?
32820,"if there are $ 0 $ s and $ 1 $ s in your sample , then there is evidence against a beta distribution because this is a continuous distribution . do you know how are they generated ?"
33173,"when making a statistical comparison you usually need some idea about the spread of the measured quantities . are you able to extract the run times from each repetition , so that the spread can be investigated ?"
33474,"are you referring to a question of * experimental design , * where ( for example ) you could choose $ 2n $ $ x $ values and you might elect to take $ n $ at one value of $ x $ and another $ n $ at a second value of $ x $ , as opposed to spreading all $ 2n $ $ x $ values out ?"
33879,"gisol : have you tried ` anova ( g1 , g2 , g3 , g4 , g5 ) ` ?"
33981,why bare you so set on double exponential smoothing to forecast ?
33948,i think we need to hear more about why you can't just resample with replacement for the main statistic of interest . why is it possible to do this with subsets but not the original dataset ?
34006,what aspects are you interested in being able to reproduce ?
34148,might this be related to the [ german tank problem ] ( url ) ?
34262,"by constructing confidence intervals , you implicitly assume the survey is a * simple random sample * of a population . what population ?"
34439,"do you have many discreet design variables with small # of modality smaller than , say , 6 ?"
34826,why specify more indices than what you are going to use ?
35028,you are looking for advice on what exactly ?
34848,can you give more detail about the state space of the mcmc chain ?
35324,"just curious , why do you want to initialize the model with a different time series ?"
29616,so f0 is known and fixed . but is f known or from a parametric family or are doing this in a nonparametric framework with all you know about f coming from your sample ?
35644,"what is the stumbling block there for you , i can't get ?"
35861,hint : what are the implications of the characteristic roots being non-negative ?
35967,suppose you are updating $ p_j $ to $ p_j ^ { textrm { new } } $ . how about just setting $ p_i ^ { textrm { new } } = frac { p_i } { p_j ^ { textrm { new } } sum_ { k neq j } p_k } $ ?
36164,"are you wondering about the underlying mathematics , or code for how to implement this in practice ?"
37743,can you tell us the condition number of your covariance matrix using ` cond ( a ) ` ?
37762,"this question is too broad to be answerable : it covers a great deal of all of the theory and practice of simulation . to narrow it , could you describe in more detail precisely what distribution you are trying to simulate ?"
37796,presumably you are correct in assuming that they are doing this for a normal population but they don't even let you specify the variance . so maybe they assume it is 1 as you suggest in your question . what parameter are they trying to estimate with the confidence interval ?
37920,i don't follow from very early on . how is generating posterior data standard bayesian stuff ?
37999,"michaelchernick : i know your edit was very well-meaning and i appreciate it . however , editing out a potential factual error can drastically change the question meaning and interpretation . my experience is that these errors are often highly correlated with the questioner's actual question and misunderstanding . i believe that may be the case here , hence caution is advised . see also : [ should i edit a factual error ?"
38290,"right , except shouldn't you say "" without replacement , "" as peter does below ?"
38210,if you are looking at proportions why do you have to bootstrap to get confidence intervals ?
38255,"for a start , it sounds like you do * not * have discrete distributions , but only discrete summaries of variables that probably should be modeled with continuous distributions . but what is your analytical objective : are you , for instance , trying to determine which of the theories provides the best fit for the data ?"
38250,have you tried integrating to find the log-normalizer ?
38452,"ok , then could you please clarify what do you mean by * independence of the sample itself * ?"
38616,( 1 ) epigrad : why are you concerned about the ci ( i . e . about the standard error ) of the predictions from the fixed-effect part of your model ?
38436,"what do you mean by more "" interpretable "" ?"
24586,can you confirm the accuracy rate of the classifier ?
38719,"it depends on what you want to express . the absolute strength of linear relationship would better be expressed with your first approach ( absolute correlation coefficient ) than with that suggested by roman , as with his approach a strong negative correlation ( near -1 ) tends towards 0 after transformation , and a strong positive correlation tends towards 1 . is this what you want ?"
39018,"just a general comment on unsupervised learning : in general it is very difficult to compare methods in this field , since you have to define what you mean by a "" good clustering "" . this is a problem because not only can you define this in multiple ways , but this often implies some assumption on the distribution that generated the data ( e . g . gaussian ) , which is generally a bad thing . what most people do is compare either by using one of these definitions ( the one that gives the best results for their algorithm ?"
39080,are you using anova for binary data ?
39077,your colors are given in the rgb coding ?
39266,"did you mean to write "" . . . then $ v_ theta ( r_2 ) $ is probably * * small * * . . . "" ?"
40383,do i understand correctly that you have data on your outcomes for the same participants before & after the intervention ?
40581,what are you talking about ?
40799,are the $ x_i $ and $ y_i $ independent ?
41218,are you asking for the meaning of mutually independent random variables or for a computer-based technique for generating them ?
41473,"you can't find the expected value of the mle ( hence , you can't correct the bias ) without knowing the distribution of the mle . it is related to order statistics as suggested below , but you don't need to be familiar with order statistics to solve this problem . if $ y = textrm { max } left { x_1 , x_2 , ldots , x_n right } $ , what is the cdf of $ y $ , $ f_y ( y ) = p ( y leq y ) $ ?"
13497,does it has discrete or continuous values ?
43256,could you please describe the data ?
43434,what is the level of your class ?
41900,what positioning systems are the ships using ?
30729,"this appears to be a good question , but the question could be more useful ( to non-experts ) if it were revised for clarity . for example , the terms "" ergodic "" and "" invariant "" are not clear ; "" ergodic "" is not mentioned in [ gelman et al bda ] ( url ) although it appears frequently in the more recent [ handbook of mcmc ] ( url ) . could you provide a definition and perhaps a visual example or description of how you would identify or test for an ergodic chain or invariant distribution ?"
44199,"i find it interesting that you have $ alpha $ in front of both terms . is that correct , or should the first term have $ alpha ^ 2 $ ?"
44322,"why don't you show them as-is , using two different vertical axes to put the two series on the same graph ?"
44359,"maybe i'm missing something , but could you explain why you choose multinomial regression to model the dependent variable "" memory score "" ?"
44489,could you address which of the concepts is tripping you up instead of just posing the question directly ?
44615,"welcome to the site , joshhansen . do you see this q primarily as a programming question or a statistics question ?"
44563,can you explain why you think that entry order is important ?
44445,what's the graph ?
44783,"could you please tell us what you mean by "" divisive "" ?"
45032,almost certainly . can you give more information about what your 'points' consist of that you want to find correlations between ?
45381,kernel for * what * ?
45807,are you serious ?
45780,what do i know about how the unknown entries of the $ k ^ { th } $ observation are chosen ?
45907,what is the sample size ?
3795,"out of interest , what did you find was the problem with graphviz ?"
46201,"no , i can't think of a situation where it makes sense to average p-values . how are you randomly generating distances ?"
46264,why is this a problem to begin with talbot ?
46185,"what kind of data are you analyzing , and why do you want to remove a covariate , $ e ^ { x_1t } $ , from your model . also , is there a reason you are removing the intercept ?"
46797,i'm curious about it too . but can't you drop the number of features by using dimension reduction like pca and then try to do some classification ?
47250,"what would it mean here to "" make a conclusion about the male / female general interest "" ?"
47299,could you tell us how exactly the adjustments don't work ?
47408,there may be better approaches . how are these rates measured ?
47597,"peter , could you expand on why logistic regression is a bad option ?"
47719,"why not just transform your data so that it is normal , i . e . take the log of your data ?"
47189,"it would be helpful to have more detail on your outcome / dependent variable , especially whether it is a continuous or categorical variable . my other question is why are you calculating z-scores ?"
47885,any chance the numbers are too large ?
48139,"is your text one of those that emphasizes that it makes no sense to talk about a chance of the null hypothesis being true , or is it one that views all probabilities as conditional and focuses on bayesian inference ?"
48325,"your headline and your text ask different questions . if you "" know "" that your original data is normally distributed then you can derive that several operations like summing up , multiplying by constants and so on preserve normality . when you say in the text of the question that you take the integral , what do you do ?"
48689,what parameter are we computing the confidence interval for ?
48747,ttnphns : could you please elaborate a little on ordinal dichotomous vs nominal dichotomous ?
48902,is the third group tested once or twice ?
48994,could you clarify your question ?
49936,what was the basis for breaking the regressions at 1980 ?
50073,$ y ( m ) $ takes on values $ 1 $ and $ -1 $ with equal probability and so $ e [ y ( m ) ] = 0 $ . what does _linearity of expectation_ tell you about $ e [ z ( n ) ] = e left [ sum_ { m = 1 } ^ n y ( m ) right ] $ ?
50215,"welcome to the site . why do you particularly want to use quantile regression rather than other techniques such as some form of generalized linear model ( including straightforward traditional "" regression "" ) ?"
49935,are you asking about an explanation of matrix notation ?
50816,"are you using "" correlation "" in its conventional sense as a measure of linear association between two paired sets of data ?"
51056,can you define what 'accuracy' you'd like to optimize ?
50786,can't you use poisson regression ?
51353,to what extent do you need the groups to be well described by the information you have on the people ?
51408,"is your discrete signal periodic , or is it an aperiodic a sampling of a periodic signal ?"
51671,"there are a lot of ways to aggregate that data , can you talk about how they were aggregated ?"
51908,can't you run knn on any distance matrix ?
51898,why is the normal approximation bad to teach ?
51974,( i think all your readers will appreciate the motivation for learning and the benefits of writing your own code for comparison to the state of the art . ) but then what is your question ?
52005,"to begin understanding why the answer is in the negative , you might consider what happens to the histogram as you vary the * start point * of the bins , which is not specified by this rule of thumb . but why narrow your question so much ?"
52161,this is a broad question . do you have a specific dataset or situation in mind that will make it concrete and answerable without requiring a treatise on data analysis and data mining ?
52133,what options do you have in mind ?
52163,could you explain how a theory about * time series * would be applied to a * singular event * like an accident ?
49987,"john , are you asking about works discussing , say , which * models * may have multiple local maxima or is your question about * optimization methods * and the risk that they might return maxima that are global but not local ?"
52672,"frankly , i still do not understand what is going on regarding questions 1 and 3 . what does for example "" there are parameters of the model which has captured a very wide range - say , 10 % to 90 % . it does not give me comfort , rather , it may show that the expert panel inputs missed out on the clear range "" mean ?"
52803,"you might want to clarify : you have five items , with three ( count ) measurements taken over time ?"
53140,"before anyone can answer , you have to make your question more precise . what is the chance of * what * happening ?"
54764,why would one not simply use all the data ?
54785,can you be a little more specific about what you are trying to do with the algorithm ?
54986,"if this is discrete time , you must have a lot of ties , right ?"
55027,""" * have been told that this method is not appropriate * "" - on what basis ?"
55210,"not sure what you mean by "" non-standard "" in this context ; can you edit the question to include the expressions ?"
55350,"wait , you're assuming time - a continuous variable - is * poisson distributed * - that is , distributed as a discrete variable ?"
55551,personally i think it looks ugly . is there a good reason to use it ?
55695,"but there's a direct sense in which 'biased coin' is akin to that meaning - the bias of a coin would be $ pi - 0 . 5 $ , if $ pi = p ( textrm { head } ) , $ , say , and similarly with a die . if someone says 'what's the bias of this die' , my first instinct would be to think they mean $ e ( x ) - 3 . 5 $ - again , the amount that the expectation deviates from the 'fair' value . as such , the question 'which is more biased ?"
55539,"since you say that there is a curved relationship between the predictor and the response , have you considered a quadratic term in your regression model ?"
55801,this looks like it's for some subject . could you please add the self-study tag ?
55784,1 just for the barfed line . lol . have you looked into sparse matrix formats in r ?
49568,i just know how to specify two crossed factors with lme ( ) . could it help ?
55943,is this frequency weighting or some other kind of weighting ?
56167,what's 1-d in your 1st paragraph ?
56429,possible duplicate of [ how to calculate the p-value of parameters for arima model in r ?
56605,"this might seem to be not very revealing , but there's already software available to do the check : conduct a chi-squared test ( in the five-way table ) and check that the chi-squared statistic is exactly zero . incidentally , aren't there really just four variables here ?"
56398,ttnphns this sounds like the more of an answer than mine - maybe flesh it out below ?
56926,how about using some smoother ?
56971,what happens if you do the anova despite the unequal variance ?
57025,how are you assessing correlation ?
56899,"sashkello : are you saying that a test stopped at 490 samples because one subject is shown to be outperforming the other by 20 % somehow reports a value that is less credible than one that collected 1 , 961 samples and also showed the same 20 % performance improvement ?"
56544,"i'd be tempted to build a model from the data in order to simulate this to answer these questions . it also facilitates what-if analysis ( "" what if average rainfall decreased 10 % because of climate change ?"
57565,what books / sources did you actually use to find out about the techniques and implement them ?
57849,"if you have measurements of the entire population in question , why do you need inference ?"
58446,""" and only one robust regression gives a sensible result . "" a better way to say that is that only one of the robust functions was designed to work with the 'confint ( ) ' interval . . . "" is it a correct way to produce a confidence interval for the robust regression model ?"
58425,how many levels do you have for each of your 2 ivs ?
58651,i'm not sure what you are asking ?
58921,what percentage of rows are marked ?
59014,"in certain cases , subject to mathematical limitations , that is possible . could you explain what you mean by "" predictive validity "" ?"
38979,"have you noticed that $ x y sim n ( mu_1 mu_2 , 3 ) $ and $ x-y sim n ( mu_1- mu_2 , 1 ) $ are uncorrelated and jointly normal , whence they are independent ?"
55825,"could you clarify how time comes into the experiment - you say you expected differences "" to become larger as blocks advanced "" - what does this mean ?"
58244,glen : can you help me understand why not ?
59311,"maybe do it a few times with a 20k subset , and look how frequently each feature gets selected ?"
59517,what is your research question ?
59558,"your answer seems a little conflated . in the sample space , you can measure the distance between two data points using any of a family of norms like the euclidian norm : $ d ( x_1 , x_2 ) = sum ( x_1 - x_2 ) ^ 2 $ . in the functional space , you can measure the distance between their probability functions using kl or bhatta distances $ d ( f_ { x_1 } , f_ { x_2 } ) = int_ { omega_x } hat { mathbb { f } } _ { x_1 } - hat { mathbb { f } } _ { x_2 } $ . the functional metrics in statistics use the sample to estimate their cdfs and then calculate their distance . can you re-explain exactly what you're trying to do ?"
59620,"given that kurtosis usually refers to properties of the fourth moment and bivariate distributions have not one but * five * distinct fourth moments , could you more precisely explain what you mean by "" platykurtic "" or "" leptokurtic "" in the bivariate case ?"
59661,evan : are you sure ?
59805,"if you add the already * correctly classified * examples in the training set , this won't improve your performance ( often the model will not change ) . what classification algorithm are you using ?"
60166,"i am unfamiliar with your programming language , is it c ?"
56964,"jojo , could you say a bit more about your particular situation ?"
60231,"can you define what you mean by "" extraneous "" ?"
44435,where are the features coming from ?
60764,"what is the "" cell "" chi-squared test ?"
60743,"could you clarify what you mean by "" this set of data is different from that set of data ?"
61217,hi zglaa1 and welcome . why do you think that you have to transform the variables ?
61431,"it still seems to me that is precisely the question addressed by the thread i linked to . if it is not , could you explain how they differ ?"
61858,"it depends on which kinds of alternatives you want to give the most power to . for example , are the 256 possibilities regarded as just 256 separate categories , with no particular ordering , or are they 'ordered' in the sense that a value of '37' is regarded as * closer * to '36' than it is to '93' ( i'm writing the byte values as decimal values ) ?"
61531,"can you supply the formulae , and / or r / stata code to exemplify your thinking ?"
61961,"you'll be doing anova on the means for each subject , not on each data point . are the means skewed ?"
62132,what do you mean saying ` the clustering process entails a violation of assumptions . . . ` ?
62238,"( 1 ) copying a comment for clarification from the [ mo version ] ( url ) : just a small point of clarification : as i read it , $ ( alpha_1 , alpha_2 , alpha_3 ) = ( 1 , 2 , 3 ) $ qualifies under your null hypothesis , but $ ( 1 , 2 , 2 ) $ and $ ( 1 , 1 , 1 ) $ do not ( regardless of $ beta $ ) . is that what you intended ?"
62647,what do you mean by significant ?
62748,"tell us this : ( 1 ) is it possible that $ f_ { x , y } ( 1 , 0 ) ne 0 $ ?"
63054,"* why * do you need to "" enforce normality "" ?"
63260,is $ m $ specified * before * you draw values from the generator or is it somehow computed from the values you have drawn ?
63254,i think there are a couple of threads on cv that might help you ; take a look at these : [ why does a 95 % ci not imply a 95 % chance of containing the mean ?
63684,is this a homework problem ?
63835,is it perishable or durable ?
61474,is there no way to load the data into another application and compute the log there ?
44319,"yes it is tangential , but let us move on : do you have some other information about the distribution , so as its range / continuos / discrete . . . ?"
64054,that is not enough information to give any useful advice . how exactly are the values not correct ?
64400,could you please explain your notation ?
64449,what do you mean ?
64608,are the errors iid and normally distributed ?
64672,why would a * cost * function be linear ?
64815,why are you comparing the models ?
64869,"justcurious , i personally find no sin in doing pca on binary data , - if you wish to know my [ opinion ] ( url ) . what do you mean saying ` i need the data in a clustering friendly form ` , how is this connected with pca ?"
65001,"to add just a detail to the answer and comment you already have : from your description , it seems possible that you don't need either of them . it seems you simply want a regular multiple regression , possibly comparing several nested models ( why did you decide you needed several steps ?"
65384,what do you mean with cumulative probabilities ?
65577,"it is not clear what you mean when you say "" the nature of this relationship "" . are you referring to the within group or between group relationships ?"
65757,"i would think it is best to ignore this . but it would help to have an exact definition of "" threshold "" . is it just an intercept estimate ?"
66365,do you mean that the expected value is $ np $ ?
66465,i am not sure i understood your problem correctly . formally you could do that but what this approach would achieve is testing if the proportion of elderly and young customers for each row is 50 / 50 . imagine that 70 % of your customers are elderly but that they are facing exactly the same problems than the younger ones ; all these proportions should be significantly different from 50 % ( i am ignoring some technical issues here ) but that's just because you have more elderly customers than young customers . would that result be of interest to you ?
66588,"i am not sure of what you mean by merge information from other , smaller data sets but generally speaking this seems some variant of the surprisingly common question why not just duplicate records to reach some desirable sample size ?"
66652,isn't the production function equal to the price function with a smaller intercept and a white noise error term ?
66404,have you tried two way ` anova ` ?
67349,"i have no idea what you're asking now . perhaps you should say what you think the bootstrap is . i highly recommend reading the book that the ` boot ` package goes with . are you confusing the terms 'observation' ( a data point for a single observational unit , like a person - possibly with observations on several variables ) with 'sample' ( a collection of such observations ) ?"
67530,"thank jake : that sounds like a good characterization . in this case i was seeking a clarification ( but ran out of room after explaining why clarification is desirable ) : justin , could you make more precise what * you * mean by "" bounds of the data , "" by "" valid "" predictions , and by "" articulating "" a region ?"
67579,what do you exactly want to model and why is this binomial distributed ?
67779,why would you transform your dv ?
67764,can you define what you mean by 'viable' ?
67938,"1 ) can you provide us with the categorical predictor of interest ( or a similar example ) so that we know what these "" hundreds of levels "" mean ?"
67871,you are grouping by year - is it the year of the first treatment ?
68270,"i don't see any recommendation on that math thread concerning 30 , cassandra . but what's so frustrating ?"
68555,"is one of them a "" null "" value ?"
66407,"stephen - i think of cis as inverted hypothesis tests : the $ 1- alpha $ ci is the set of values that would not be rejected by an $ alpha $ -level test . it's not obvious to me what your test is . if $ theta = theta_1 $ and we hypothesize $ theta = theta_0 $ , what is the rejection probability when $ theta_0 = theta_1 $ ?"
68752,real world independence ?
68996,"where are you having "" trouble "" ?"
69088,"hm , i see . why not try logistic regression with elastic net penalty than ?"
64749,how would using a static / compiled language save you from an api change ?
69096,you'll have to search the web for examples . maybe you could explain where exactly you're stuck ?
69317,"have you tried expliciting calculating $ $ text { cor } ( x , y ) = text { cor } ( a-b , c-b ) = . . . $ $ ?"
69409,note that histograms are * not * bar charts : bar charts represent quantities by length while histograms represent them by area . the difference therefore shows up when you construct a histogram using bins of unequal width . have you considered that option ?
69575,"references please . more importantly : 1 . there can't be a "" correct number "" here independently of the kind of distribution you are drawing from . 2 . these rules usually come from interest in short-cut methods of estimating the sd from the range . now we have computers . . . . do you want to do that and why ?"
29828,hint : do bookmakers really need to know probabilities in order to be profitable ?
69629,there's an infinite number of distributions that can be positive and negative and are both skew and have excess kurtosis . why do you need to fit a distribution at all ?
69597,did you mean to say that we assume the variance of $ x_i $ and $ y_i $ are known ?
69928,are you talking about a linear correlation or pearson correlation coefficient when you're mentioning correlation ?
69864,why do you believe that $ w ^ { 2 } = w ^ { t } w $ will be 1 ?
70073,"sure ! and , the $ k = 3 $ case is actually instructive . think about flipping coins in pairs ( repeatedly , as necessary ) . what are the possible outcomes ?"
70134,"can you please elaborate how exactly you wish to "" base the weights of features in k-nn on the total variance of said features "" . for k-nn you need a distance metric for determining the closest neighbor . do you intend to use some sort of weighted euclidean metric , using the weights for pca ?"
70375,"you've got two issues . ( 1 ) calculating the weights . ( 2 ) using the weights . do you need help with both of those , or just one ?"
70561,"is the event column "" exactly one event "" or "" at least one event "" ?"
70548,""" * so as the variance of the laplace distribution increases to 1 , you lose all moments including the mean * "" --- can you please explain why you think this follows ?"
70714,i'm not sure i understand correctly : how would you calculate a correlation between only one tupel ( two consecutive values ) ?
70900,your new values do have a standard deviation of $ 1 $ because after subtracting the mean from each of your original values you divided by $ 4 . 85 $ . where does the confusion arise ?
70709,"why don't you apply the change-of-variable formula that is presented in the wiki link of benjamin 's comment , and see where it leads you ?"
70956,is this homework ?
71019,can you say more about the structure of the situation ?
24903,"white and royston ( statist . med . , 2009 ) suggest to include in the imputation model the nelson-aalen estimate of the cumulative hazard ( ` h ( t ) ` ) * * instead of * * ` log ( t ) ` ( or ` t ` ) . what would you do in the case described by epigrad ?"
71197,"raxel , why is bias so important ?"
71353,why not just mean square error or mean absolute deviation ?
71735,"are you talking about a sample of $ x $ 's to which you're trying to find a local minimum of a density , or is this a set of observations of ( possibly noisy ) pairs , $ ( x , f ( x ) ) $ ?"
71857,"it sounds to me like there were two sets of paired t-tests that produced p-values . the first set was to make sure the covariates used for matching were balanced across treatment and control groups . you can imagine testing square footage , percentage affluent in trade area , and maybe pre-treatment outcomes , and so on in this way . the second test was a t-test on the equality of post-treatment outcome ( like profits and revenue ) . was that the case ?"
72032,"so , for $ p_2 $ someone just handed you a number , is that correct ?"
72036,why would you test the distribution of ivs ?
72247,"no , you can not say that dutch donate to charity twice as much . as i understand , your "" donors "" are poorly defined ( there is no difference if i give 1 euro or 1 000 euro ) . have you some other numbers instead of percents ?"
72514,alexb . what made you choose statistica ?
72535,"if you do not assume a prior distribution for ( mean , sd ) , then it is hard even to make sense of this question . ( what does it mean to be "" close "" ?"
60825,you have to ask yourself what would be your decision if the p-value is 0 . 051 ?
72557,why do you need a p-value more exact than . 0001 ?
72590,"( 1 ) i'm not sure you can necessarily compare a glm and a time series model via bic . ( 2 ) in any case which you used depends on what you want to do well at ; even when bic's are comparable , bic is no guarantee of out of sample performance . * why * do you want to optimize on one or the other ?"
72764,"as explained in comments at url there are trade-offs between computation time , storage , and programming complexity . what are your preferences concerning those ?"
72853,"my reply at url addresses the negative part of this question : namely , why $ r ^ 2 $ does not of itself tell you anything about linearity , especially when the independent variables in the data sets are different . although you did not ask it , this question begs for a positive response , too ( and perhaps you should mention this explicitly ) : given that your proposed methods don't do the job , what * does * work for assessing linearity ?"
72935,"the question as posed is nice and straightforward to read , but some other info it would be useful to add in at the end : 1 ) what kind of variables are l and d ?"
73425,it may help you to read my answer here : [ when to use fisher and neyman-pearson framework ?
73414,"this question needs more context / information to answer . are you interested in "" what's the probability that x is just a typo for y ?"
73522,"rv's are functions , as any other . so you have $ x = g ( z ) $ ( although one rarely knows the functional form of $ g ( z ) $ - it is _not_ the probability density function ) . now assume the domain of the rv is $ z in [ 1 , 2 ] $ . you can insert $ z = 1 . 5 $ into the r . v and you will get $ g ( 1 . 5 ) $ . you can insert $ z = 1 . 7 $ into the rv and you will get $ g ( 1 . 7 ) $ . but can you insert $ z = 1 . 5 $ and $ z = 1 . 7 $ _together_ ?"
73724,what do you want this statistic to do or represent ?
60274,how do you construct the indicator variable for membership of group a ?
73978,how large is large ?
74002,is this all you have ?
50459,"i think i follow , but "" i'll have an expected value and error in both x and y "" is tripping me up : are you saying that each datum $ ( x_i , y_i ) $ has a distribution with * known * expectation $ ( xi_i , eta_i ) $ and * known * covariance matrix $ sigma_i $ ?"
73856,i am slightly confused by the wording you use ( probably it's just me . ) do you by cross-sectional regression mean a simple linear regression without random effects ?
74145,"how can you "" see the answer "" if you can't compute the integral ?"
74402,values from each question were counted together ?
74578,have you noticed $ p ( x_ { ( 1 ) } - theta epsilon ) = p ( x_ { ( 1 ) } - theta epsilon ) $ ?
74751,why wouldn't cross validation be if not the best at least a better solution than a random one time split of the data ?
76123,"what is the null hypothesis of the dickey fuller test , and what are the critical values ?"
75050,what could it possibly mean for the area under the curve to be 'significant' ?
9085,"gsk3 - interesting question . i would have a guess that this "" programaphobe "" does not have to deal with the complicated spreadsheets ?"
76310,""" * i am not confortable with the idea of building an informative prior with an infinite variance density * "" -- why is that , exactly ?"
76373,"on the question * "" which pairs of numbers appear most often together "" , i'd start with cross-tabulations . $ quad , , , $ $ , $ * the 'question' is actually a host of somewhat different questions , depending on things like whether the pair ( num1 = 3 , num2 = 5 ) is considered the same as ( num1 = 5 , num2 = 3 ) ( does order matter ?"
76689,why don't you have the data ?
76629,would the -party- package version of cart work since it includes ordinal responses ?
76676,would you mind spelling out your acronyms the first time you use them for people who are not as familiar w / them ?
76927,"you assert normality right in your title and your opening sentence . if the minimum possible value is not $ - infty $ , then your assertion is false . ( i ) how do you know with such certainty that you have normality ?"
77026,how is the proportion calculated ?
77658,what do the subscripts $ i $ and $ j $ represent ?
66088,any information on $ x $ or $ beta $ ?
77892,"this kind of question is not of direct use in any application , so i presume it is a [ tag : self-study ] question for which guidance--rather than a direct answer--is sought . what sampling methods do you know of and which one of those do you suppose this is ?"
77998,""" optimal "" with respect to what criterion ?"
78203,what do you mean ?
77878,"what is lower-case "" $ m $ "" ?"
77245,what is the purpose of removing variable 17 ?
78442,what is a gene ?
78148,what results do you get when you perform pca on the * untransformed * data ?
78803,"this question can be interpreted two ways : if the true proportion is $ 100p % $ and your estimate is $ 100 hat { p } % $ , do you want the confidence limits to be within ( a ) $ 0 . 10 times 100 hat { p } % $ of $ 100 hat { p } % $ or ( b ) $ 10 % $ of $ 100 hat { p } % $ ?"
78900,if you're tying to compare preferences ( which seems to suggest some test of location ) why are you testing variance ?
78898,how about a permutation test ?
78982,why is this a problem ?
79051,"i am not familiar with the rugarch package , but are you interpreting this correctly ?"
72525,"i don't understand your "" but "" here . does "" non-multimodal "" mean anything but "" unimodal "" ?"
79108,"suppose there were * no * observations in one of the middle categories--say , in the interval $ ( 32 , 34 ] $ . that would be a glaring departure from a normal distribution , wouldn't it ?"
79240,do you have any information about people who read multiple magazines ?
79243,"are you assuming that the two "" correctnesses "" are independent of each other ?"
79245,will this method still be of use if you have shrunken estimates without standard errors ?
74451,do you know some other inequalities ?
79830,have you already thought of using akaike's information criterion ( aic ) or mallows' $ c_p $ ?
79189,i'm not sure i understand - doesn't centering remove the very effect you're testing for ?
80223,why do you think that the number of absent doctors on some day $ v $ would affect the number of deaths on some other day $ w $ ?
80315,"on the question : "" * is it possible to calculate the probability that two samples are drawn from the same distribution ?"
80496,can you provide a few examples of what you are referring to ?
80481,"what do you mean by "" not random "" ?"
80537,you need a simple example . have you learned about the [ binomial asset pricing model ] ( url ) ?
81071,"pearson's $ r $ ignores the order of repeated observations of any one variable ; it only preserves pairings between observations of separate variables . in your two time series , you have observations of two separate variables from each year , right ?"
81311,is this a homework assignment ?
81395,could you explain more explicitly how pca and regression are connected in your statement ?
81523,"just wondering , but did you try doing the anova anyway ?"
81674,"maybe you shouldn't be ! as whuber is implying , your quest for good predictions is much more complex than the matter of choosing the right model . you might want to spend a couple hours studying regression , if you haven't already . your second question is pretty basic , but the answer may not be . your information is all relevant to other , variably complex ( or simple ) issues that you may want to understand better . i can throw some jargon at you to help you narrow down the topics worth studying if you like , but this is just as likely to raise other questions as answer yours . does that sound good ?"
76970,the question is hard to understand . are the six categories mutually exclusive for a particular structure ?
82464,"how does a distinction between "" independent variable "" and "" controls "" arise here and how it can be pertinent to the merits of lpms ?"
82285,"( * previous comment deleted because it depends on this more fundamental issue * ) . . . . . are you trying to identify a criterion for choosing between a and b , or are you somehow able to trade off variability and mean and are looking for some optimum point on a frontier ?"
82686,the maturity corresponding to the highest yield ?
82978,is this an equivalent phrasing ?
82982,what's the problem with the sample mean ?
83223,what are you expecting to get ?
83073,would a 2-way repeated measures anova for each dv work ?
83193,or try this : let bill arrive at a particular time $ b $ . when can will arrive in order to meet him ?
83042,"define 'good' , for your purposes . what aspects or features of a model are important ?"
83513,we need more information than that : what are your variables ?
83876,"it also depends on what the records represent ( ie are they independent observations , or a sequence of events on independent units in time , or a sequence of events for a single unit ) and what kind of analysis ( summarize the data , compare two groups , regression an outcome on some covariates ) you plan to do . can you provide more details ?"
83893,remyf like what ?
84029,"if there's noise , why does your model have an equality there without a noise term ?"
84000,"although "" non-gaussianity "" does not mean "" non-existence of moments "" , but rather non-symmetry and / or skewness / excess kurtosis , you specifically mention the possibility of non-existence of first and second moments . does this come from theoretical considerations which tell you that the real-world situation under study would be well represented by such a distribution , for example a cauchy distribution ?"
84321,"i don't think normalizing the actual signal will help , although some classifiers have problem with different scales on the dimensions for the feature space . what are you using as features ?"
81751,what does the data looks like ?
85457,is this regression or time-series ( you have the time series tag ) ?
83966,"you can't "" cluster according to programming language "" . that is classification , not clustering . other than that , what have you tried yet ?"
85381,why not just subtract the mean effect from the coefficients ?
86125,the difficulty is having the equality in the alternative . how is one to find the distribution of the test statistic under the null ?
86418,could you tell us how you would compute the selection probabilities based on the advertising ?
86556,"you remain unclear on what the data are and how they were produced , making it difficult to advise you well . in my favourite software ( stata ) i can fit gamma and lognormal distributions directly to data in the form you have , just using the observed probabilities as weights ; there is no need for a mystic "" area factor "" . also , you appear to mean by "" normalized distribution "" that the probabilities sum to 1 ; nothing special about that , as it should always be true . the value in the highest bin is slightly puzzling : can you rule its including all the highest values ?"
86640,what are you having trouble with ?
86778,"because $ x $ and $ y $ are positive a . s . , the statement $ x gt y $ is algebraically equivalent to $ ( x / 1 ) / ( y / 10 ) gt 10 . $ does that help ?"
86756,"the online [ linest help page ] ( url ) explains how to extract this information ( and more ) . for instance , the standard error of the slope will be in row 2 , column 1 of the linest output . could you please edit your question to tell us * how * you want to "" take these into account "" ?"
86595,is the reference saying that the posterior distribution for the normal-normal problem is intractable or is it saying in general the problem is intractable ?
87032,"whuber : and they do ! i observed it many times myself , and have always assumed that for a random covariance ( i . e . positive semi-definite ) matrix the spectrum will show exponential decay ( maybe in the limit of large $ n $ ?"
87271,"there are an infinite number of ways in which a stream of numbers might be nonrandom . given your sample size looks rather small , can you be more precise about what kinds of non-randomness you want to detect ?"
87101,"how , exactly , are these being standardized ?"
87018,"that only means there is still real collinearity . not all collinearity is as evident as the presence of ones in the off-diagonal entries . anyway , what is your question ?"
87369,assessing goodness of fit with 12 observations is pretty low-power with the best of tests . using the chi-square to assess goodness of fit is * very * low-power . so . . . ( i ) why test goodness of fit ?
35697,"i don't really follow your question . can you say more about your situation , your data & your goals ?"
87681,"so , you have a big square matrix of distances between the points you want to cluster . ( btw what distance ?"
87798,what makes you to consider your time scale after the clustering ordinal ?
87720,can you supply the ` formula ` object you wrote to fit this model ?
87866,"please tell us what elm means . it looks like you are asking for help solving a lagrange multiplier problem , right ?"
87834,why do you think the aic and bic don't agree ?
38141,i know a lot about classification but i have never heard the term recall . could you give a definition ?
88103,what do you want to find out from this comparison ?
88147,thank you . would you mind explaining how the seat allocation could affect the results ?
88074,"what was the error message , and what version of r is installed ?"
88411,charles : can you explain why you don't like the question ?
82704,"maximum likelihood estimation must involve a data set and a parametric family of probability distributions , right ?"
89624,a dummy variable takes values of either 0 or 1 . how might it exhibit a non-linear relation to the response ?
89570,what do you want to find out ?
89560,"what , precisely , do you mean by "" their statistical errors "" ?"
89944,maybe you'd prefer to model change over consecutive days in the frequency of positive differences in the participants' treated eyes ?
89753,this would only make sense if your two sets of species have the same size ; this sounds a bit weird to me in the context of your research problem -- why would they ( if not only by chance ) ?
90068,"needs a bit more explanation . so you have a model price = a b * age with a and b known with some known uncertainty and want to determine which car is cheaper , right ?"
90101,it is unclear what you are trying to achieve . what is the goal of the transformation ?
89769,"( when you say you can't use libraries , what exactly do you mean ?"
90232,are you sampling randomly and separately from $ d $ and $ d_2 $ ?
90336,are you saying you're on a machine with * no * graphical capability at all ?
90436,what do you mean by stacking up ?
90986,a cdf is increasing ; it's graph can never look like that for any distribution . do you mean that the graph should match that of a pdf ?
91230,"( 1 ) have you looked at the residuals , done a lag1 test ( durbin-watson ) , white-noise test ( portmanteu ) or looked at auto-correlation plots ?"
91334,"( 1 ) how do you know wage * is * lognormal , rather than some similar distribution ?"
91157,"given that $ x y = 1 , $ then $ y = 1-x $ , whence your question reduces to "" how to estimate the error in $ ax / ( ax b ( 1-x ) ) = 1 / b - 1 / ( b ( a-b ) x ) $ given the error in $ x $ ?"
91123,could you clarify what you mean by a false zero ?
91444,"( 1 ) don't beg for help from people in comments . if whuber has useful help to offer and the time to do it in , you'll have it . if he doesn't , you're just harassing him . better to use your time to make your question as clear and well laid-out as you can . ( 2 ) can you describe the situation ?"
91838,what would the parameters be ?
91323,"use of a 2-tailed test when the direction of an effect isn't pre-specified is "" penalization "" enough . what "" multitude of tests "" are you thinking about ?"
92140,what mode of neuron firing are you trying to fit ?
92227,"you're not classifying data as outliers on that basis alone , are you ?"
92602,can you tell me why we normally prefer to use an adj- $ r ^ 2 $ rather than the $ r ^ 2 $ ?
92569,how does one achieve a ci that is a multiple of 20 ?
91958,why does it matter what the distribution is ?
92858,i'm not entirely clear on what you are asking . why should the * minimum * of your sample carry much information about the * expected value * ?
93176,"machine 1 has worse accuracy than machine 2 , yet it's used to calibrate the latter ?"
91462,"to clarify the underlying nature of this question ( since it has been bouncing back & forth b / t cv & so ) , i wonder if we might edit the title , rob . how about 'why doesn't there seem to be a package for lasso standard errors , are they difficult to compute ?"
93579,"you use "" should "" several times in your opening paragraph , as if those calculations were the only way to deal with the issues . is there a justification for this use of 'should' rather than 'can' ?"
93577,lucidnonsense - you don't make it clear where your difficulty lies ; which part of the formula is giving you implementation problems ?
93704,"i think the idea of "" probability of accordance to normality "" has flaws . no distribution is perfectly normal , so , what exactly does this probability mean ?"
93752,how did you determine this conditional probability must be zero ?
92854,"i like the following 2 books : an introduction to statistical learning : with applications in r ( james , witten , hastie and tibshirani ) . the elements of statistical learning : data mining , inference , and prediction ( hastie , tibshirani , friedman ) . i also find that epidemiologists prefer parametric regression models ( the glm type models you mention ) for estimation and inference compared to modern semi / non-parametric regression models . i suppose because much of their work focuses on discovery / explanation of risk / protective factors , rather than generating flexible regression fits ( for prediction ) ?"
94285,is there a non-linearity issue here ?
85451,"i don't see a ` spatstat ` function in r . there's a * package * called "" spatstat "" . it seems to have a function called ` ppp ` ( ` spatstat : : ppp ` ) , though ( and a class called * ppp * ) . what other functions are you calling ?"
94110,"in addition to statistical methods , i would urge you to look at the substantive meaning : which clustering is more useful to you ?"
94385,"you say : "" i have a correct estimate of the mean of $ y $ "" , / / / do you actually intend to say that you "" _have a correct estimate of the mean_ "" : i . e . $ e [ y ] $ , or that you have an unbiased estimator of the mean of $ y $ ?"
94218,what is the standard deviation of each value ?
95024,two questions . do you have any idea about highly correlated your other variables are with year of birth ?
94770,why would you use a measure such as error rate that is inconsistent with maximum likelihood estimation ?
95374,"do you mean is 11 . 0 % significantly different from 6 . 4 % , 12 . 7 % etc ?"
48462,do you want to calculate the derivatives on the log likelihood ?
95883,"i'd say , yes , you can discard the other components . you retain 91 % of the information , with 10 % of the complexity . your variables are highly correlated , but also appear to be skewed . what's the aim of your analysis ?"
95868,"( a ) is ambiguous / misleadingly phrased at best , since what it ( i hope ! ) really seeks is a conditional probability , not an unconditional one . what would the distribution of $ sum d_i ^ 2 / sigma_i ^ 2 $ be * if the given model were the correct one * ?"
95820,"if [ this ] ( url ) is the paper , the first reference to $ phi $ in your quote above references $ x $ without a subscript ; might $ x_i $ reference a row or column vector within a matrix $ x $ ?"
95998,is there a reason you are using the magnitudes of the misperceptions and ignoring their signs ?
95226,are all the observations independent ?
95317,"* * of the six sources for names that you mention * * - individual teachers - schools - universities - gov secretaries - labor unions - event organizers how many of the original 7 , 000 names came from each ?"
96186,what distributions do you think it looks similar to ?
96222,can you show us what you have tried so far ?
96087,what is non-linear here ?
96831,"there are only $ 2 ^ { 10 } = 1024 $ possible results when the coin is tossed $ 10 $ times , and so it is not at all surprising that one of $ 1000 $ people did call all ten flips correctly . do a fake experiment . don't flip a coin at all but _pretend_ that you flipped $ 10 $ times and got $ 10 $ heads in a row . will the $ 1000 $ -th person get that sequence right ?"
210068,"ok , we need more information about how you constructed these model but let's start with the obvious stuff : can you understand why for example the second plot is problematic ?"
244262,what's the difference between graph 1 and 2 ?
222375,"you would like to test for whether there is mean differences for series or not , right ?"
311217,"hi , do you have lots of important event flags , like hundreds , to be able to construct a labeled dataset ?"
311738,"are the subjects in * * t * * the exact same subjects in * * t 1 * * , with the only differences being the introduction of an intervention and the passing of time ?"
313174,have you ever come across [ karpathy's blog ] ( url ) ?
314769,just curious : is $ 12 $ the mean value $ y $ ?
316049,why do you think regression cannot handle a categorical variable ?
320265,""" acceptable "" to whom and for what purpose ?"
320712,do you not still count as a child even if you were not the first one born to a particular mother ?
321085,perhaps there is something about your data that is causing the very small value of f . are all your observations independent ?
321619,why not just read the original paper ?
322122,"welcome to cross validated . the lack of correlation indicates that the relation between x and y , if present , is nonlinear ( i assume the two are continuous variables ) . do you have any candidate model of the nonlinear relationship between x and y ?"
323502,"i have not played the game myself much , but aren't the current locations of the squares and the numbers on them dependent on your previous moves ?"
325043,"i'm not sure if it answers your question , but wouldn't the polynomial basis be a subset of the spline basis ?"
325639,do you wish to make this test separately for each individual or for the individuals as a group ?
330005,"have you ever heard of the phrase "" correlation does not imply causation "" ?"
329579,"what do you mean when you say that you "" want to set a null to ( y = 5 when x = 5 ) "" ?"
332897,did you scramble / randomly assign the order in which they tried the dictionaries ?
310709,what is * finite-sample population * and is it different from * population * ?
333453,"the answer clearly depends on the function and what you mean by "" smooth . "" for instance , is a function with continuous first derivative and discontinuous second smooth ?"
335818,"are they matched , e . g . pairs inside / outside on same day ?"
336278,"please remove "" correlation "" from the title . please give examples ( more than one ) of the data you have and what you want to figure out . also , "" effects "" seems causal - do you have an experiment with randomization ?"
338356,"i'm mot saying this is the best way , but how about reversing the order of the time series and forecasting into the future of the reversed time series ?"
340526,you would have to specify your question a bit more to get a more precise and in depth explanation . it is a bit general . maybe you are looking for a book / chapter / article / introduction on the topic ?
295999,nice question ! i'm really curious if you actually came across this ( if so please post the full data and analysis ) or a clever [ gedankenexperiment ] ( url ) ?
342095,do you know the $ sigma_i ^ 2 $ or not ?
341997,"of course it loses information . and that information is often significant , in the sense that adding that information could easily be the difference between and algorithm working versus not working . why throw it away then ?"
342447,"acf means auto-correlation function , and auto means "" self "" . what would your version of a plot consist of ?"
342748,"it's difficult to see how you could accomplish that in anything but an arbitrary way . note , however , that your $ k $ samples uniquely determine a subspace $ v $ of dimension no larger than $ k-1 lt m . $ why not stop there ?"
344070,are there observations that have negative or zero income ?
344489,"but what do you mean by "" more noisy "" ?"
345074,the question is not very clear . what do you mean by similarity / ies ?
517,"first , two lines from wiki : "" in computer science , semi-supervised learning is a class of machine learning techniques that make use of both labeled and unlabeled data for training - typically a small amount of labeled data with a large amount of unlabeled data . semi-supervised learning falls between unsupervised learning ( without any labeled training data ) and supervised learning ( with completely labeled training data ) . "" does that help ?"
660,"what do you mean by * types * of "" textual "" content ?"
1274,correlated with what ?
1874,you mean a a good 3d image reconstruction algorithm ?
2181,"to what extent do you want : ( a ) mathematical rigour ; ( b ) applications in particular software ( e . g . , r , spss , sas , etc . ) ; ( c ) domain-specific applications ?"
2348,"perhaps , cw ?"
2892,"do you have in mind any particular application , that is do you seek for general advices about how many evs we need to consider apart from any application ( i . e . on a pure mathematical side ) or should it apply to a specific context ( e . g . factor analysis , pca , etc . ) ?"
3165,"in your q2 , do you mean ` cex . lab ` instead of ` cex . axis ` ?"
3260,zenna : do you have a set of pre-identified break points ?
3463,are the time series both stationnary ?
3672,"a bit more details could be helpful ; how they are obtained , are branches weighted ?"
3708,what are the geographic units and do you expect them to have any geographic dependency ( i . e . spatial autocorrelation ?
3820,"stephan i understand the question as referring to an univariate distribution , hence one variable with multiple observations . am i missing something ?"
3885,don't these become unbiased only in conjunction with additional distributional assumptions ?
4062,what is the advantage of a polar representation ( aside from saving space ) ?
4120,does the y column give the means ?
4196,what kind of inference are you making ?
4356,what do you precisely mean by multivariate split ?
4513,is that the statistical query model of kearns ( 1998 ) url ?
5013,"out of curiosity , is the misspelling of "" theoretical "" in the plot built into the matplotlib and scipy . stats packages ?"
5058,might you be able to remember * where * you 'read a few days back' ?
5167,1 ) do you mean wishart or inverse wishart ?
5387,isn't it software dependent ?
5563,"what would be the use of such a function , i . e . do you want to make symbolic calculus in r ?"
5887,how did you divide the data ?
6253,"i interpreted "" 10 % bonus "" as an additional 10 % towards your return mark . for example , 30 % goes to 40 % with this bonus . however , it could be that your return mark is increased by 10 % ( 30 % goes to 33 % ) . would you clarify ?"
6462,what does 'fcm' stand for ?
6481,would you still be interested in knowing how ordinal logistic regression work ?
6525,"the legend in your graph does not correspond to the graph of function $ y = 10 ^ 6 / x $ , is this intentional ?"
6702,"did you read the accompagnying vignette , [ estimation of multinomial logit models in r : the mlogit packages ] ( url ) ?"
7022,"you should mention java environment in the title of your question this will maximize the chance to get an answer . also is there a tag "" java "" ?"
7096,and ` spline ` does not work why ?
7159,"do you mean you're running two nested bootstraps , i . e . a bootstrap procedure within a bootstrap procedure ?"
7318,"in what way is the data "" non-normal "" ?"
7412,"a question when you say "" network "" - that word means many things . do you mean anything that might be defined as a network ( for example , the social contacts of an entire city ) or do you mean a network of computers ?"
7512,you may need to provide more information . what do you mean by correlate ?
7581,"whuber , can i say the model parameters estimates are the estimator ?"
7664,all probability measures assign measure one to the entire sample space ( by definition ) . is that what you're looking for ?
7730,for what size of dataset ?
7897,"what do you mean by "" many more "" 100 ?"
8201,"charles . y . zheng , i don't think the replication idea is appropriate . your function $ f $ is a function of the "" order statistics "" of your input $ x_i $ . so , why not sort the coordinates of $ x_i $ and fit your $ f $ that way ?"
8225,"the commas in the result data frame mean something special , or is it just the decimal point ?"
8281,$ d ^ { } $ and $ d ^ { - } $ are common names for the one-sided statistics ( cf url ) . in what context does your $ d' $ appear ?
8290,what assumptions can you make ?
8514,"some of the maps packages for r have built-in colour codes that prevent this kind of issue , but is that what you were asking about ?"
8777,"before asking these questions , did you search this site for "" pca "" or explore the "" pca "" tag ?"
8797,"your [ confidence interval ] ( url ) ( i assume it is for the mean ) looks strange because it must be an interval , not a single value . isn't it [ 4 . 28 ; 4 . 92 ] instead ?"
9003,could you please tell more about the dependent variable ?
9023,is this for a homework or a test ?
9109,how do you mean difficult ?
9324,"just a quick check : ` female ` is supposed to be factor with several levels ( actually considered as your random effect ) , but i would have expected something like ` lmer ( size ~ ( 1 id ) , data = data , subset = gender = = "" female "" ) ` , where ` id ` is subject number , ` gender ` codes for the sex ( with two levels , ` male ` / ` female ` , the analysis being restricted here on females only ) . could you explain a little bit more the structure of your data , or just put the results of ` head ( data ) ` ?"
9329,my first thought was to wonder how what you are wanting to do differs from the variable importance of the training data ?
9748,"do you have two values for each week , ( 1 ) a continuous outcome measure and ( 2 ) a yes / no predictor ?"
9880,you're getting there . why don't you edit the question to reflect this refinement and see what responses you get ?
10223,"compared to the message posted on [ weka ml ] ( url ) ( notwithstanding the cross-post on [ metaoptimize ] ( url ) ) , do you mean you want to compare different regression models , or just to optimize a given model with e . g . , cross-validation ?"
10434,is your model linear or nonlinear ?
10478,are you aware of papers establishing consistency results for the lasso ?
10700,does the following link help ?
10867,do you have any reason to believe your values should be normally distributed ?
10963,depends on application . . . any more details ?
11246,what do you need the table for ?
11412,something doesn't compute . how can you have means or medians or cis with categorical data ?
10900,""" unskwed "" = "" unskewed "" ?"
11749,"what do you mean by "" the probability to add a question in a forum "" ?"
11940,so you get a ( random ?
12053,are you doing this using software ( and if so which software ) or are you trying to do the calculations by hand ?
12069,what are the tilde's representing ?
12119,what kind of fix do you want ?
12138,"if you take the data every day , don't you know the day of the week ?"
12412,"small , embarrassing question -- why ?"
12514,"i think your question needs some editing but i'd like to ask first : ( 1 ) "" because the dependent is bivariate "" , i think you meant "" binomial "" ( the outcome is treatment = yes or no , right ?"
12683,do you have the toxicity numbers ( true values ) ?
12828,"you mean "" discriminant analysis "" aka "" discriminant function analysis "" , don't you ?"
12843,"must be a coding mistake . i don't use r , so i can't say what the mistake is exactly -- but i just coded up your solution ( taking care to take the middle root of the cubic polynomial , which always lies between 0 and 1 ) , and i get good agreement between the samples and the expected distribution . could it be a problem with your root finder ?"
12935,could you provide a link to a book that states _the model for sampling * * with * * replacement is incomplete_ ?
13048,what is the size of your data set ?
13086,try logging it first ?
13130,"it seems to me that imputation of missing data only makes sense when framed into a specific statistical context ( regression , classification , scores reporting , etc . ) . could you specify what you have in mind here ?"
13136,"i think your question is phrased in a confusing fashion . you have a "" coin "" with a certain "" bias "" p . your standard mode of operation is to flip the coin until it comes up heads , and count the number of flips required to achieve this . is this what you consider to be one "" trial "" ?"
13236,what software are you using ?
13615,how do you measure accuracy of your current model ?
13666,"you was advised to do differencing , a general method to detrend series . did you try it ?"
13721,what other constraints do you want to put on this ?
13781,"the em algorithm is a general purpose tool for doing maximum likelihood estimation with missing data - can you be more specific about how it is a "" clustering algorithm "" ?"
13850,does model 2 also have the main effects from model 1 in it ?
13890,how many files do you have ?
13959,perhaps you can provide a link to the particular reference you are using . do you know what a [ sufficient statistic ] ( url ) is in general ?
13952,"since spearman correlation is based on ranks it will be the same on raw variables and on monotonically transformed variables ( such as z scores ) . but what do you mean under "" relate back to the raw data "" ?"
13989,"i think you need to be more precise . do you want to draw them by hand ( don't ) , or use a specific piece of software ( r , spss , . . . ) ?"
13995,can you describe the data in more detail ?
14076,"assume they give different results ( i mean in terms of p-value ) , how do you plan to interpret this ?"
14079,could you share how you decided to proceed to run stl decomposition on your weekly data ?
14122,which degrees of freedom do you want to increase ?
14332,what kind of efficiency are you looking for ?
14360,is this a discrete or continuous state markov chain ?
14401,what is your disciplinary background ?
14210,dmitrij that is a deep and insightful answer . why don't you elaborate on it in a reply ?
14505,"k-1 : the highest frequency is indeed linked to the total length of the time serie , whereas the smallest frequency is linked to the sampling frequency . no surprise here . about your second question , how do you define "" turbulent fluctuations "" ?"
14678,"if the dependent variables are that different , is it even reasonable to combine effect sizes in a meta-analysis ?"
14757,do you really need to do it using web application ?
14908,what do you mean by decode ?
14917,the picasa link seems to be broken ; can you fix it please ?
15021,"just to make sure , the correlation coefficients are between shopping habits and weight gain for three subpopulations ?"
15091,"without more information , it may be difficult to give a clear cut answer . is there any information about business failure in the area , ie : how is the failure of businesses distributed in the area ?"
15068,have you considered a hidden markov model ?
15201,1 for the aok reference . have you played on the zone ?
15266,is this homework ?
15299,"( 1 ) out of curiosity , what regression algorithm requires binning ?"
15413,it is probably asking you to indicate what you think the true correlation is . but let me ask you this : what is the purpose of this power calculation ?
15475,is $ t $ the total number of samples ?
15490,do you assume that the player always declares the joker to be of the suit for which she has the most cards ?
15703,"when you say "" compared to the others "" , do you mean "" compared to prosthesisa , prosthesisc and other "" , or "" compared to other "" ?"
15717,what do you mean by bayesian network program ?
15928,how * much * more important are the negative values ?
16046,important or relevant to what ?
4901,you could tell us a little bit about your data ?
16130,are you expressly looking for * free * data sets ?
16448,""" i would like to create a measure to find the clusters which discriminate a from b . "" obviously and plainly , it is the ratio between numbers of as and bs in a cluster . if as or bs prevail in a cluster then that cluster discriminates them well . your idea of ratio of mean similarity between as in a cluster to mean similarity of all points in the cluster is questionable . what if you have just 2 as ( very close to each other ) and 20 bs in a cluster . the ratio will be 1 . what does it tell you ?"
16458,"not an answer , but you could probably calculate the kalman filter steps analytically for this simple model , as it would only involve small matrices . and which "" kalman filter "" value are you comparing : the smoothed value , 1-step ahead prediction , . . ?"
16672,which version of ` caret ` are you using ?
16855,"out of curiosity , what package did you use for model-based clustering , ` mclust ` ?"
16877,why would there be bias introduced by matching with replacement ?
17016,""" one bayes classifier to rule them all "" and in the darkness bind them ?"
17151,what other option are you considering ?
17166,i find the question vague . are you talking about two unordered multisets of real numbers ?
17239,"neither your question nor your data is clear . . . i'm guessing your cases are individual people , that two methods of surveillance were applied to every person , sometimes succeeding and sometimes failing ?"
17256,"do you have any domain specific knowledge about how the "" five and more times "" category would be distributed across counts of 5 , 6 , 7 , etc . ?"
17431,"well , now i'm confused -- what do you mean by "" mathematical formula "" in this case ?"
17472,what are you trying to convey with the visualization ?
17488,could you elaborate on just how the before and after samples would be ( statistically ) * dependent * ?
17609,thanks for the answers . in fact for one parameters i well know the procedure but for two it is not clear . do you have an example like elastic net and prostate data ?
17635,"it could be just me , but i'm having trouble understanding the 2nd 1 / 2 of your post . could you edit a bit , maybe break down some of the statements into chunks so as to be plainer ?"
17774,how many years of records do you have ?
18270,are you looking for something more efficient than sorting the words by their frequencies ?
18363,i interpret the [ brief wikipedia article ] ( url ) as saying that this * is * done . have you looked at its references ?
18403,how is your outcome variable distributed ?
18451,can you mention what kind of things you'd like more depth on ?
18456,is the three variable model a sub-model of the five variable model ?
18661,it seems you know a model for how such a probability distribution would arise . can you use that to help you ?
18693,how is that a problem ?
18732,did you really maximize the * negative * log likelihood ?
18752,what are you quoting ?
18841,what software do you have available ?
18847,can you be more specific ?
18884,do you have some references where you've seen it used in an effective manner ?
19120,"to make any progress , carl , you need to quantify what you mean by "" good sense of . "" you also need to be more specific about what it would mean for the sample distribution to "" represent "" that of the full population . what kinds of discrepancies are ok , and how large can they be ?"
19151,"by variogram , you mean variogram * * model * * ?"
19281,can you say exactly which document contains this advice ?
19344,its not clear what you're asking . . . why are you transforming your outcome variable ?
19403,"do you really want just to * predict * y , or do you want to explain the mechanism by which one or more variables * explain * y ?"
19526,"what do you mean by "" coherent "" ?"
19538,what about network analysis ?
19739,you mean like --------------- : --------------- ?
20176,1 ) what is your data ?
20375,"have you searched the web for "" moment matching "" ?"
20570,what do you mean by 3d data ?
20669,"are the sections supposed to measure different constructs ( e . g . , linear algebra , real analysis , etc . ) or do you consider the total responses correct on all 25 items ?"
20733,"gesture recognition is rather a specific application ; if you can't find such using a search engine , you'll have to get lucky to get some here . also , c code samples for hmm will be rather lengthy . i'm sure this is what you'd like , ideally , but is there something less restrictive that would be useful to you ?"
20904,so which model is better ?
20673,"the question makes it sound like the only attribute of the georeferenced coordinates is the user , but that would be highly unusual : isn't each coordinate pair also identified by the object it purports to locate ?"
21241,"the likelihood is a function of just two parameters : what's "" unwieldy "" about that ?"
21283,the question has ancova in the title . . . is this in any way related to the problem ?
21345,"it's not quite clear what your problem is here . what are these "" other weights z "" ?"
21391,is this homework ?
21512,* why * are you thinking it might be more appropriate to compare the minimum values ?
21658,"can you explain what you mean by "" risk "" of oversampling ?"
21722,"could you please clarify what you mean by estimates . do you mean , for e . g . , that you want to test the overlap between height and weight for boys ?"
21738,how big were the training and validation sample sizes ?
21790,what software are you using ?
21927,"i can't parse your first sentence ; 11 and 7 are what , n's ?"
22310,could this relate to copula ?
22666,"could you add more detail to your question , such as what your dependent ( outcome ) variable is , what your independent ( predictor ) variables are , and what you want to know ?"
22849,"i'm curious about why a zero intercept is assumed as there is a base time in ms to react to a whether a stimulus ( word ) is present , regardless of length , so i would have thought that would be the intercept . the other question i have is whether the duration is linear , could it be curvilinear instead ?"
22954,when you say 'fatigue life distributions' do you mean [ the birnbaum saunders distribution ( also known as the fatigue life distribution ) ] ( url ) ?
22956,"this seems reasonable , isn't it the way that ar and ma terms are determined in an arima ?"
22135,would one of these help ?
23282,"hi , could you clarify a few things . which is your response variable ( on the vertical axis ) - perceived velocity or actual velocity ?"
23526,"hi there , is this homework ?"
23531,do you assume any underlying distribution of your variable -- like a normal distribution ?
23698,"to clarify , is the $ hat { m } $ in the first equation the same as $ hat { m } _1 $ in the second ?"
23703,homework tag too ?
23794,are you sure you don't want to consider replacing the 100 . 00 % too ?
23838,welcome to the website . confidence level / margin of error for which statistic ?
23939,"what do you mean by "" as bad or as good "" ?"
23966,"is there any randomness in here , or is $ t_i = 10 ( b_i - 0 . 9b_ { i-1 } ) $ exactly ?"
24125,"have you tried ` table ( classification . 1 , classification . 2 ) ` or ` xtable ` ?"
24178,"the paper does not appear to create a two-sigma limit : it refers to an * empirical * determination of a variance threshold used in a highly specialized application . the present question seems to generalize from this to "" a quantity's constant nature , "" but i see no intention in the paper to do so , nor can i imagine any statistical justification for such an unfounded statement . are you perhaps quoting something else ?"
24199,a random variable _has_ a distribution . are you talking about modeling some observed data as arising from unobserved random variables ?
24369,do you need a formula or would an ` r ` function do the trick ?
24405,what is the range or standard deviation of your other variables ?
24462,"do you mean that , at time $ t $ , $ y_t = 4- ( x_ { t-1 } x_ { t-2 } x_ { t-3 } x_ { t-4 } ) $ ?"
24484,why does spearman rank correlation seem 'kind of funny' to you ?
24490,what is the meaning of the numbers in the matrix ?
24508,"this is a simulation where you _begin_ with signals that are not jointly normal _by construction_ , and your statistical procedure seems to be showing that one can be reasonably confident that the signals _are_ in fact jointly normal . so , should you be checking whether ( a ) the statistical method was applicable , or correctly applied , or correctly interpreted , or ( b ) your signal generation method is leading to signals that _are_ in fact jointly normal even though a _prima facie_ case cannot be made for joint normality ( as would be the case if ` s1 = randn ( size ( x , 2 ) ) ; ; s2 = randn ( size ( x , 2 ) ) ; ` ?"
24595,"is this a repeated measures design such that each subject runs in all , or many , of the conditions ?"
24619,"do you mean in your last sentence "" or are these methods only suitable when the dataset is not that big ?"
24658,""" some "" ?"
24853,do you want the distribution to be unimodal or not ?
24956,you have to provide much more details . what does your effect size suppose to detect ?
24962,what package are you using ?
25000,16 day data comprise data about every day ?
25024,i presume you have considered using multinomial logistic regression ( i know you know about it as you have asked other questions on it ) . is there a reason why it is not helpful here ?
25049,"you mean a way of * calculating * hac robust standard error * estimates * , right ?"
25181,"a more interesting question might be "" is there a way to predict future change based on * no * data "" ?"
25353,sounds reasonable . wouldn't you want the comparison model to include gender as well as age though ?
25354,is this homework ?
25400,could you do a little bit of explaining what the code does in order to make it clearer to those of us who might be good at sas but not so much familiar with what the winbugs code is doing ?
25561,"do you take a fixed sample of size $ n $ from the underlying distribution and then throw away the bad observations or do you continue sampling until you get a fixed sample size of "" good "" observations ?"
25700,can you post some example data ?
25923,"re # 1 : in what sense is the estimate "" scaled "" ?"
26019,"i'm looking into the rss examinations myself , specifically the 5 exams needed for the graduate diploma . what's a bit off putting is the fact that the study books suggestions are pretty broad . do you have any experience with the exams to share a year and a half after you've asked this question ?"
26194,"there's something wrong . you should have $ sum_i y_i = sum_i hat { pi } _i $ . did you , perhaps , suppress the intercept ?"
26352,what does it mean that a vector is negative ?
26347,what is the dependent variable ?
26326,"the "" predict "" function may be what you're after ?"
26430,some people care about badges ?
26545,"are conditions different diseases or symptoms ( outcomes ) , or are they explanatory variables that interact with treatment ( like smoking would be in a study of alcohol consumption and cirrhosis ) ?"
26552,what concrete questions do you want to answer ?
26667,( 1 ) was your sample obtained with or without replacement ?
26629,and $ epsilon $ ?
18030,what is the size of the problem ?
27097,what does $ { rm mod } ( x ) $ mean in this context ?
27476,programmitically ?
27475,"what's a "" hit "" ?"
27480,"could you tell us what a "" phi measurement "" is and what "" moa "" might stand for ?"
27503,probabilities lie between 0 and 1 . are the figures you give percentages ?
27515,are these lotteries for money ?
27558,a post-hoc test for . . ?
27703,i am not quite sure what you mean by showing different behavior . if you mean that they look like different time series then why not fit something like an arima model to each and if the form of the two models are very different you can say that the behavior is different ?
4597,what do you mean by needs to implement ?
27766,where is the curve above ?
27785,kaplan-meier is sensible as long as the censoring is independent of the failure time . is it a problem with the dependence ?
28010,question for clarification ?
28040,what distribution were you thinking of fitting to the data after re-scaling ?
27942,do you simply want to calculate sse or also different types of measures for the cluster cohesion ?
28120,"i think [ genetics ] ( url ) , [ dynamical systems ] ( url ) among other areas present challenges in sampling from the posterior of the parameters . for this reason [ abc ] ( url ) is becoming popular . the posterior of the parameters of [ stable distributions ] ( url ) is another example of difficult posteriors to sample from as well . is this the sort of examples you are looking for ?"
28138,what sort of data you have ?
28311,"it would help if you'd define the terms in your equations . also , is $ widehat { { bf b } } $ a maximum likelihood estimator ( if so , under what assumptions ) or . . ?"
28363,"procrastinator : could you clarify what it means for the ks test to "" work in the heteroscedastic case "" given that this is a test on the equality of * distributions * from two iid samples ?"
28426,"what do you mean by "" type of probability "" ?"
28454,"just an idea , but how about create summary statistics for each group , and then use ?"
28461,"for two matrices $ a $ and $ b $ , $ a-b $ is usually interpreted as elementwise subtraction . see url . but what on earth is "" the mse between to matrices "" ?"
28670,"have you used the 80 % , 15 % , 5 % figures anywhere yet when determining these entries ?"
28683,i don't understand your question . you mention a model and simulating to estimate but don't mention data ?
28695,this is a pretty broad question that has been discussed on this site quite often - have you done a search of all questions that use the tag 'model-selection' ?
28801,"the likelihood is the joint density of the data , given a parameter value and the prior is the marginal distribution of the parameter . something tells me you're asking something more though-- can you elaborate ?"
28811,"just clarifying : do you mean that there is no error other than the uniform error , and you know the bounds on it ?"
28845,"there are a lot of posts on this site that ask , essentially , this same question . here is one example : possible duplicate of [ how can i get a significant overall anova but no significant pairwise differences with tukey's procedure ?"
28852,"you say that you want to predict the ctr instead of whether a single add has been clicked or not . how does the feature "" whether the user has seen this ad earlier "" fits then ?"
29151,"the icc is not , in itself , a parametric statistic . you can conceive of the icc regardless of the distribution of the data . what exactly do you mean by "" nonparametric icc "" ?"
29437,can you create an animated gif from the matlab plot at different angles ?
29599,what is the basis for using $ n-2 $ for the degrees of freedom ?
29642,what did you try so far ?
29661,what is your objective ?
29673,"re : "" i am not able to do regression due to less number of observations that i have 5 independent variables "" : does this mean you have more predictors than you have samples ?"
29712,"well , with regard to the research question - does distance matter , or does it only matter whether or not you can hit the bullseye ?"
29790,have you plotted interarrival time versus time itself ?
30002,"what properties do you want of a "" standard error "" ( of the mean , presumably ) that is a "" mad equivalent "" ?"
30025,"sorry , i don't think i got it : the first model is $ y_i = beta_i x_i epsilon $ ?"
30067,"are you saying that , in some of your models , you have sampling site as both part of the random term and as a fixed effect ?"
30128,are you aware of dynamic factor analysis ?
30319,the original lars paper has several illustrative figures of the procedure . have you also looked there ?
30301,"if there is a physical / biological / experimental way of improving the precision and reducing this natural variability , then it is possible . if not , then you have to deal with this . this is , depending on your goals , you have to include this characteristic in your statistical model . what are you planning to do with these data ?"
30329,is subtracting the values at t = 0 from your remaining conditions ( 4 time points x 2 conditions ) an option ?
30578,could you explain this plots to me and how you made them ?
30592,could you provide a reference to what you heard or elaborate on the context a little ?
30754,what is the textbook you are reading ?
30763,"do you have an estimate of uncertainty in the model output , or is it a point estimate ?"
30849,since tranforming to normality is not a good way to approach this problem why not look for a different method to approach the problem of classification ?
30895,"since the $ x $ s are vectors , how are you defining $ x ^ 2 $ exactly - element-wise or $ x'x $ , or . . . ?"
30989,"i think you answer your own question . the logic seems reasonable - for practical purposes , if you only need to run a computing task once , then the length of time is fairly irrelevant unless it's so long that it can't even be performed once . you may want to consider the possibility of tweaks to the classification tool , however . how quickly would you need to be able to respond to new topics appearing in the text ?"
31036,"have you looked at the very first figure in the wikipedia article on [ consistent estimators ] ( url ) , which specifically explains this distinction ?"
31092,this looks like you've fit two separate regression models with $ x $ as the predictor in one model and $ w $ as the predictor in the other . why not fit a single regression model with both $ x $ and $ w $ as predictors ?
31099,"what is $ im_ { t-1 } $ and what does $ d ( 1 , phi ^ { 2 } _ { t } ) $ denote ?"
31129,"the statistical part of this question is the last : how would "" geographical distance "" change the variogram ?"
31116,why do you want to do this ?
31496,are these from to separate mixed models or two slopes in one mixed model ?
31579,i know what classification error rates are and i know you can look to find the classifier with the lowest estimate average error rate but what does generalisation error mean ?
31718,"excuse me , what does this mean ` data is t1xn and t2xn ` ?"
31798,"i may be a bit off-topic , but why can you not accept a cluster that happens to land at the overall mean ?"
31910,if you introduce a random effect i would think it would be a variable that you would automatically be include or else why make it random ?
32043,or do you mean that a single datum can belong to more than one category ?
32088,how would you like to compute factor scores ?
32160,"i do not quite follow your question , do you just need the pair of observations with the largest difference ?"
32195,what does p ( c ) mean ?
32221,are your series stationary --i . e . is mean ( a ) constant over time ?
32277,"at first blush , bootstrapping should be an easy way to do get such a ci . do you need sample code to figure out how to do this in r ?"
32287,"i can't know what you might intend . you can see definition of "" factor analysis "" by pointing on the tag ( or read in wikipedia ) . does its meaning fit your case ?"
32292,"possible duplicate of [ how to estimate how many people attended an event ( say , a political rally ) ?"
32409,what kind of data- continuous ?
32546,why are you ` not sure if the test is a valid measure for my research ` ?
32560,are the data publicly available ?
32750,"once a person asked this to [ richard samworth ] ( url ) and he replied that if you use a large enough thinning period , then the dependence of the mcmc sample is not an issue as it is very small . i think you can prove that the approximation can be good for a large enough thinning . does this makes sense in your context ?"
32793,"what exactly does it mean that the "" deviations are hard in some cases "" ?"
32784,"could you elaborate on the threshold you are using , and the change in drift you expect ?"
32841,"the first formulation suggests your data have both "" male "" and "" female "" attributes and that individuals can be both or neither of those ! the second one does * exactly * what you ask ( provided "" unknown "" has been made the base level of the ` gender ` factor ) . i wonder therefore whether you are accurately communicating your question . could you perhaps tell us in words what these models mean to you ?"
32891,are $ e_1 $ and $ e_2 $ the same in each equation ?
33008,why is time a factor ?
32982,is this homework ?
33027,do you mean in [ this sense ] ( url ) ?
33062,did you notice how that wikipedia article actually quotes jaynes on the b-k paradox ?
33113,this question is too vague to answer as it stands . is there something you * do * want the statistic to be able to detect ?
33117,could it be that you were in a region with a local maximum and happened to move into a different region with a different local maximum ?
33465,yes it makes sense . the variance of the data approximates the variance of the theoretical distribution from which the data is generated ( if the data are i . i . d replicates of this distribution ) . but is it useful / relevant ?
33475,what research have you done in investigating this question ?
33519,did you check wikipedia ?
33601,"what do you mean when you say "" similar to some extent "" ?"
33788,what test would you use in order to reject or accept a null hypothesis ?
33919,would this information be available on a family level or just overall ?
33995,i tried your code . and the mean function for both models seems to be the same ?
34069,"welcome to the site brian . is this question * only * about how to get something done in r , or also about the statistical issues ?"
34073,do you mean the wilcoxon rank-sum test ?
34205,i've not seen results from hurdle models 'integrated' ; what does that look like ?
18241,"is the expected frequency zero because of some pre-existing constraint , or is it only due to some marginal probabilities being zero by chance ?"
34593,perhaps some sort of weighted moving average ?
34646,can you edit this to provide more information ?
34652,this question needs more information . what model are you fitting ?
34743,did you try using url ?
34817,y = f ( x ) ?
35013,are you putting additional predictors into the logistic regression model ?
35192,""" best "" equation for what purpose ?"
28676,have you asked this on the multilevel list ?
35424,"i would , in general , leave it as a single factor . but it depends ( as so many things do ) on context . what is the split from the root node ?"
35515,i am cleaning the ambiguous ` gmm ` tag . what does ` gmm ` stand for here ?
35557,are you asking why that formula comes from the gradient of the loss function $ l $ ?
35663,what kinds of analyses will you be performing with these data ?
35746,"can you say more about your situation , your data , your model & your goals ?"
35995,could you describe how the data you receive is related to the event ?
36064,what is the model you use in r ?
36159,you might also want to mention which parameters you're interested in . are we talking about some sort of shifted t-distribution ?
36325,the link doesn't give us the full paper and so we can't look at section 2 . 2 . can you give us the relevant part of the section that gives the derivation ?
37416,what is n . i . d . ?
37511,why have you normalised the real ones to add to 1 ?
37523,"incidentally , can you link to the article in question ?"
37566,a couple of questions : why do you think that quantiles are inappropriate for normally distributed data ?
37569,10th decile would be maximum income ?
37870,hmm . maybe it isn't different . but then why does it assume that the chain has to visit all states before move 12 ?
37923,i don't quite understand . what is the mean you are trying to measure - is it the average number of events per visit ( over the full time period ) for each treatment ?
38001,"you say , "" in my case these processes are robust "" . meaning what ?"
38029,without the binary data for the two proportions how could any form of regression be possible ?
38133,what is it that you need that you cannot get from a uniform random number generator ?
38273,"wait , pearson's correlation coefficient assumes normality ?"
38346,doesn't it just follow from slutsky ?
38423,it is impossible to tell with the information given . are other variables involved in the stock return model besides gdp growth ?
38495,"it's a little hard to understand the structure of your experiment and data . it sounds like both species and treatment were manipulated between experimental units ( i . e . , each unit is in only one "" tub "" ) , is that correct ?"
38507,did you use r and predict ( ) ?
38534,can you be more precise on how you plan to use coverage probability ?
38662,"perhaps you might tell us a bit more about your situation . for example , do you think the hits are all or mostly first time hits or do you think most or many of the hits are repeat hits ?"
38724,"i assume $ sum ( x , y ) = ( sum x , sum y ) $ . is there any assumptions ?"
38736,"it's a good question , but could you be a little more specific about what kind of information you are looking for ?"
38750,one of those links you reference shows how to deal with the fourth root . what part of it are you having trouble adapting to the reciprocal square root ?
38776,"it would help to draw useful answers if you could describe the ways in which you are controlling for this variable or using it as a moderator . in what sorts of procedures , and with what sorts of other variables ?"
38874,let me see if i get this : you get a performance increase for every data set . and then you use some test statistic that aggregates those performance increases ?
39013,by non parameteric do you mean that the clustering algorithm does not assume a distribution ?
39054,the $ p $ -value is always related to a hypothesis test . what is the null hypothesis ?
39128,do you recognize the formula for $ p ( x d ) $ as an * expectation * and the set of $ theta ^ { ( s ) } $ as an iid * sample * ?
40362,do you know some basics notions of the theory of empirical processes ?
40378,is your response variable a count ?
40454,"what are "" x1 transfers "" , "" x2 transfers "" etc . ?"
40479,what test would you use if he questions are independent ?
40624,"the data are still autocorrelated at lag 1 only . this wouldn't be the case if your data crossed zero though , would it ?"
40752,erogol : good question i will try to answer . do you have a link to that dataset ?
40778,i think there may be some confusion as to the labels for the lines in question . could you post an example of the chart ( s ) you're looking at ?
41004,could you please share why you are planning to put constraints on the cluster sizes ?
41027,"if you're running a poisson regression , what difference does it make if the residuals are normal ?"
41197,do you also know the size of each sample ?
41319,how many columns ?
41379,perhaps you want to give this question a shot yourself and people can chime in with additional insight ?
41442,why do you think that the researchers should have used logistic regression ?
41462,what does $ theta $ have to do with this question ?
41518,are you saying that the questions on your questionnaire are unrelated to your hypothesis ?
41539,does the opening line of the link that you posted not answer your question ?
41608,"how do you measure "" capacity to colonize "" ?"
41794,would r code that does a fully bayesian analysis for this be useful for you ?
41879,is this homework ?
43019,are you already a user of another statistical software ?
43012,"i don't follow how your $ net $ frequencies are related to the numbers listed & your dummies d0-7 . if you have counts , why not use them directly as your covariate ?"
43042,"nothing circumvents the multiple comparisons problem except not doing multiple comparisons . how * * much * * of a problem it is is a matter of some disagreement and has been discussed here . if you want to compare 3 groups on some continuous variable , the first thing to think of is a linear model ( anova / regression ) do you have a reason for rejecting those ?"
43149,"maybe i don't understand your question properly , but couldn't you just use a normal chi ^ 2 test ?"
43159,"when you say you know the means and variances of these groups , are they parameters or sample values ?"
43413,"why do you equate "" measure "" with "" estimator "" ?"
43421,how did you choose the polynomial and the regularisation parameter ?
43453,i think you can safely say what day it currently is with no uncertainty at all . can you elaborate on how you are using days in this experiment ?
43602,"could you please clarify what you mean by "" perturb "" ?"
43614,does $ x $ have any specific distribution ?
44102,"could you be a little more explicit as to what you mean by "" sparse "" in this context and how this differs from the box-jenkins approach ?"
44141,power will necessarily depend on what distributional assumptions you make for the processes . could you please give us some indication of what assumptions you can make in your application ?
44146,are you talking about loglinear models for proportions ( generally in tables ) or loglinear models for something else ?
44471,are you willing to impose symmetry as well ?
44484,"i bet your $ n $ is moderately large , right ?"
44542,"are you * assigning * patients to cases or control , or merely collecting those who happen to be cases and controls ?"
44559,"mark , you have received an answer that focuses on assessing the sampling distribution of the median , whereas in my previous comment i originally understood your question to ask about summarizing data . could you please indicate which interpretation you intended ?"
44604,what is your loss function ?
44727,isn't this a duplicate of [ classification table for logistic regression in r ] ( url ) ?
44735,[ gam ] ( url ) ?
44793,it would probably help to know a bit more about how your implementation differs from k-means ! does it just have to do with the constraints on cluster sizes ?
44867,"there's a lot of variation in terminology with the bootstrap ( where i have seen one thing called three different names , and i've seen the same name used for different things ) . can you point to where you saw it ?"
44272,"this sounds more like a matter of speculation best reserved for a discussion forum or chat room . is there a particular problem of statistics , data analysis , or machine learning this question might help solve ?"
44945,any chance you could post a link to some information about wizard neural networks ?
44949,how many covariates are in your model ?
45010,do you mind providing a reference for the calibrated p-value for those unfamiliar ?
45029,to give advice on a more appropriate technique we would need to know a bit more about what you are looking for . are you interested in whether groups have different overall levels ; different rates of change over time ; or something else ?
45074,"simone , it is unlikely you will obtain anything simpler than the summation used to define the expectation . what do you need the expectation for ?"
45168,"what does "" uncertainty "" mean in this context ?"
45192,"are you asking which test you will use when you have the data , or how to determine the sample size you will require to insure a specified level of power given a specified effect size ?"
45193,"no i don't get that . i also just get 1000 iteration in my plot , if the burn in period was also included . wouldn't the plot show 2000 iterations ?"
45228,do you need to generate according to a distribution whose mean is $ 100 $ or do you need the mean of the generated values to equal $ 100 $ ?
45357,how familiar are you with gibbs sampling in general ?
45371,to do gibbs sampling you must be able to evaluate the conditional posterior distribution of each variable conditioned on the other variables . are you able to do that ?
45431,"i don't think this question is necesarily about statistics--and even less about stat . sig . , or history . it seems to be about measurement and / or evaluation . you're looking for a good method by which to measure performance on a task , right ?"
45822,how are you planning to integrate friendship links into matrix factorization ?
46036,"bootstrap ( and jack-knife ) are typically techniques to estimate sampling distributions for parameters of interest . cross-validation is a bit different , which compares out of sample predictive accuracy . are you sure you don't mean "" leave one out "" cross-validation versus "" leave n out "" cross-validation ?"
46053,did you follow the links within the tag wiki ?
46074,it depends on what you want to generalize to . other servers ?
46052,why do you not choose to use all the variables in the original model ?
46145,can you clarify this a little bit ?
46167,"how much heteroskedasticity is there ( roughly , $ max sigma_i / min sigma_i $ as a guess ?"
46173,where exactly does this value of 1 . 04 come from ?
46334,have you considered making the lines semi-transparent by changing the alpha that's being used to plot them ?
46391,"what do you mean by "" the historic data will not be updated "" ?"
46500,ain't there a bunch of books on epidemiological statistics ?
46661,can you post the r code which raised this error ?
46683,what are $ x $ and $ y $ ?
46812,do you only have two leafs in total - one control and one treatment ?
46949,what makes your trials different ?
47003,what do you mean by 'unified distributions' ?
47089,can you cite the source ?
47149,"what quantitative information do you have about this "" data loss "" ?"
47162,"* * hint : * * $ f ( x , y ) = f ( y x ) cdot f ( x ) $ . now , for a fixed $ x $ , what must the conditional density $ f ( y x ) $ look like ?"
47270,doesn't my answer to [ your previous question ] ( url ) also address this one ?
47290,why don't you work through the simplest nontrivial case where $ u $ is a 2-vector and $ r = 1 $ ?
47233,is this homework ?
47470,"if $ theta 0 $ , then $ sqrt { bar { x } } $ is complex-valued with ( arbitrarily ) high probability as $ n $ increases , so in that sense , there * is * a problem . however , your intuition regarding the mle on the restricted parameter space is correct . how would you prove it ?"
47517,"what does "" optimizing parameters of a single kernel "" mean ?"
47556,is this homework ?
47615,"you could always just run autocorrelations on the raw response data , instead of the residuals . have you searched the site ?"
47624,do you really mean cdf ?
47656,do you want the distribution for * fixed * $ n $ or the asymptotic distribution ?
47739,"does "" l , m , h , l "" mean "" low , medium , high , low "" ?"
47889,maybe 'extremes' ?
48127,do you have a control group ?
48143,looks like a question on how to interpret the coefficients . is it useful to ` exp ` both sides ?
48202,"does that mean that the values of a1 , a2 , . . . an and of b1 , b2 , . . . bm are all binomial ?"
48205,do you have just * one * number ?
48255,why are you calculating sample size if you only have 45 students ?
48544,can you clarify what you mean by 'prognostic' . i assume that it means response to treatment ?
48654,have you tried doing a parallel analysis ?
48841,it's not clear what you are doing . you say the evaluations don't change over time at the test stage ?
48845,"saying "" dimensions "" , are you speaking of axes or of variables ?"
48959,can you get multiple measurements at each frequency ?
49017,what is your purpose in rolling it up into a larger time scale ?
49160,"you have to use $ p ( z_t s_t ) $ to calculate the weights in order to obtain a weighted sample from the filtering distribution $ p ( z_t s_ { 1 : t } ) $ . this is the "" update "" step of the sir particle filter . if you substitute $ p ( z_t s_t ) $ with another function you won't get a sample from the filtering distribution . why are you considering using something else ?"
49259,was this with the assumption of equal variance or was there some approximate adjustment for inequality such as welch-satterthwaite ?
49261,typo ?
49431,how large is your set ?
49462,what non-linear transformation are you referring to ?
49541,"what do you mean by "" what is the best possible way to get a better predictor ?"
49685,"the formula indicates $ int f_x ( x ) dx = mu_x = int x f_x ( x ) dx . $ by definition , $ f_x ( x ) = frac { d } { dx } f_x ( x ) $ , allowing us to write $ mu_x = int x d ( f_x ( x ) ) $ . doesn't that suggest integration by parts ?"
7172,could you tell us * where * you came by the concept ?
49857,i think i've just spotted the issue here - you want to know for the purposes of calculating the duan smear factor correct ?
50083,"unless $ x $ is orthogonal to the constant vector , the estimated coefficients will be correlated , in which case zero might not be a good choice . are you using sas ?"
50112,do you have any more information about the report ?
50145,"what do you mean by "" significance value "" - is it related to a statistical hypothesis test or is it something about materiality ?"
50148,the question as it stands is pretty broad . do you have any anticipated forms of potential dependence ?
50397,"what happens if the n ( 0 , 1 ) does not happen ?"
50454,i'm not sure what exactly is the question you're asking ?
50588,"what assumptions can you make about the distribution of the data across the nodes--for instance , would they be independently and randomly distributed ?"
50639,"that depends entirely on what you need , does it not ?"
50644,"there are some inconsistencies in the notation--for instance , what is "" c2 "" ?"
50948,i found [ this paper ] ( url ) through google . is it not what you want ?
50949,""" however , everything i tend to read warns against calculating the inverse / pseudoinverse of a covariance matrix "" can you add a reference ?"
51009,` so that i can apply it to new data points ?
51081,are you familiar with bayesian inference at all ?
51335,doesn't everybody maintain such a database on their pc ?
51370,could this be due to wald vs . other types of test ?
51521,"are you working from 3 different downloaded datasets , or do you have one dataset that lists income w / all of these factors ?"
51633,"what is the meaning that you are ascribing to the word "" random "" when you say "" the event occurrence is random "" ?"
51789,"l2 regularization has a bayesian interpretation under certain assumptions . is that what you mean by "" in the bayesian setting "" ?"
52319,"whoah , when did this all happen ?"
52387,what is your reasoning ?
52605,"nick , i would consider a binary logistic regression . your response variable would be binary - did they purchase or not ?"
52636,how are these values generated ?
52819,do you have any reason not to use anova ?
52821,"by "" $ h ( x ) $ "" do you perhaps mean $ h ( f , g ) $ ?"
52824,"could you tell me what you mean by "" argument "" and what it means to get hold of one ?"
52829,[ does this help ] ( url ) ?
52890,"it depends on your design , of which there aren't enough details . . . . e . g . was the order of the two surveys randomized ?"
52908,do you know the definition of $ i ( theta ) $ ?
53066,"what do you mean by "" similarity "" ?"
53154,"if this is for some subject , or even just for your own self-study purposes , would you mind adding the ` self-study ` tag ?"
53239,does this : url help ?
53241,"could you explain what this question has to do with $ x_2 , ldots , x_n $ ( and therefore why you have to drag in concerns about statistics , efficiency , etc ) ?"
53254,which package are you using ?
53355,"ah , perhaps i misunderstood . were all products presented simultaneously ?"
54463,"$ s $ , $ a ^ c $ , $ a_1 cup ldots cup a_n $ are subsets of $ s $ , don't you agree ?"
54695,the min and max will be more useful if you have the * count * of your data as well . is that available ?
54699,what specifically are you doing and what is going wrong ?
54912,is there an expectation that the two values will be positively correlated ?
54999,could you state your exact hypothesis ?
55031,"vaguely related : url may be this question can be kept by rewording it to something like "" software for managing statistical projects "" ( cw ) and hope that someone will submit an answer based on python ?"
55033,could you provide more details of the experimental design and your hypotheses ?
55136,do i understand correctly that you resample years ?
55243,do you mean something specific for c4 . 5 or are you asking a general question on binary trees ?
55335,please be more specific what you're trying to ask . are you trying to distinguish between the standard error of the mean versus the true standard deviation of the sample mean ?
55357,"just to clarify , you're saying that you have a lot of missing * labels * , correct ?"
55458,"you might have to explain a bit more about your model . also , do you mean that some coefficients _are_ significant whilst others not ?"
54746,"what distinction are you making between "" dependent variables "" and "" response "" ?"
55803,i'm puzzled by the whole tale . why on earth would he need age to be remotely normal in the first place ?
55854,is circle overlap allowed ?
56065,with what assumptions on the original scores ?
56556,"are these ts ar , arma , arima , etc ?"
57191,"when you say "" i'm trying to fit a discrete time model "" . . . what model do you want to fit ?"
57262,not directly aware of any . but there may be something that can be done . what do you need to do with it ?
57347,"would a monte carlo estimate be useful to you , or do you need the answer in a closed form ?"
57609,"could you please explain what you mean by a "" standard deviation of errors "" ?"
57668,i've never used this package . one troubleshooting approach is to make a temp data set with same structure and fill in all but one value ; run mi ; does it do what you expect ?
57730,how much data do you have ?
58031,"given you are are looking estimates for the same subject , why exclude it then ?"
58041,could you give us an idea as to the distribution of the measurements you have taken ?
58051,clrm : curiously labelled rebarbative model ?
58309,"have you ever noticed that $ x ^ 2 $ actually has a linear part , depending on how you look at it ?"
58392,""" sample volume "" : is this the sample size or the regression coefficient for the model ?"
58421,right : you checked all 133 results in the last 17 minutes . what's the matter with the duplicate ?
58498,"what distinction are you making between "" probability "" and "" likely "" ?"
58530,""" use estimated se "" . . . for what purpose ?"
58697,"possible duplicate of [ in linear regression , when is it appropriate to use the log of an independent variable instead of the actual values ?"
58757,what is your goal that you are using factor analysis to achieve ?
58922,"though i haven't checked every single step , the reasoning appears sound . that makes the question rather hard to answer with anything but "" yes "" . but i'll add a challenge ( hoping your course is not entirely theoretical ) : can you imagine a way of checking ( by using a computer ) whether your final answer , 3334 , is right , without advanced reasoning or maths ?"
59140,"some context would help here , because ordinarily "" error bars "" are not computed as percentiles . what is the meaning of the data in ` x ` and ` y ` and how do you intend the "" error bars "" to be interpreted ?"
59276,this looks too vague to be answerable . could you provide references and / or a specific question ?
59310,how is the tpr related to the question ?
59472,"just asking , but why are you sure that the blogger got the right answer ?"
59562,care to be more specific about the data ?
59654,have you drawn the q-q plot ?
59683,this is relevant : url * how small * do you imagine $ p $ can be ?
59709,"is the result you need something like : if $ p_i , q_i geq 0 $ and $ sum_ { i = 1 } ^ n p_i = sum_ { i = 1 } ^ n q_i = 1 $ are two different pmfs , then $ $ sum_ { i = 1 } ^ n p_i log p_i sum_ { i = 1 } ^ n p_i log q_i quad ?"
59731,i'm not sure i understand what the problem is . . . why do you want to take the ln of the values exactly ?
59881,could you provide some more context ?
60095,i suspect multicollinearity . the confidence interval of ` sexnull ` is also extremely wide . could you explain how ` sexnull ` and ` asa ` are related ?
60123,please tell us what you mean by $ sigma $ : is it a known standard deviation or an estimated standard deviation ?
60227,why the mode ?
60688,of what are you taking a mean ?
60703,"are you trying to model p ( object in image image , tags ) or just p ( object in image tags ) ?"
60888,"when you say 'feature' , what do you mean by it ?"
60934,can you give us a hint of the context of your question ?
61037,"( psychometric ) questionnaire validation is a complex area , discussed in a large literature and not really a well-defined statistical question that could be addressed by some spss procedure . what do you want to do with this validity ?"
61069,perhaps the marking scheme and examination questions are available somewhere . there may be some mix of right or wrong questions and some tougher ones . there may be a protocol to round reported marks for some reason ; otherwise why so many even marks ?
61086,"if you're formally trying to test them , maybe . if you're just saying 'where were the big ones ?"
61240,"hi joost , welcome to the site . if you have only two groups ( black and white ) , you could do a simple two-sample t-test to compare the mean vitamin d levels between black and white skin color . by the way : what software do you use ?"
61439,can you be more clear about where passers by are counted ?
61461,maybe integrate cpu-usage over the hour ?
61473,""" we covered at least 80 % of our population of interest "" i highly doubt this means what you think it means . do you actually mean to say , of the people approached 80 % were eligible or participated in the study or completed the survey ?"
61669,what steps have you taken to address this problem ?
61666,if you're comparing the performance of various classifiers wouldn't it be better to use something like the receiver operating characteristic ( roc ) curve ?
61784,that will not help you solve the specific problems you asked about but how can a domain be a measurable construct ?
61028,the p-value you mean ?
61859,"instead of jumping to technical terms like non-parametric statistics , you could perhaps give us a little more detail on what you want to learn . are make or categories of particular interest ?"
61912,it's not clear what data you have . do you have multiple time points ?
61991,clearly you have multiple students for each teacher . do you have multiple teachers for each student ?
62009,have you tried using various clustering algorithms ?
62017,"a google search identifies several candidates for the meaning , including [ an ar process with geometric marginals ] ( url ) and a [ generalization of a renewal process ] ( url ) . could you provide a reference and a context for this term ?"
62210,have you tried to see if you can use zero-inflated poisson ?
62246,i suggest you don't try to distribute fewer than 1 ball . what does negative balls mean in terms of the original problem ?
62399,do you mean columns that have the same number of 1's and 0's ?
62524,could you clarify why you can't include both predictors in the model ?
62512,"do you mean you want to estimate the expected number of visits per month of a user ; or do you just want the expected value of the "" days since last visit "" variable ?"
62643,it's not entirely clear to me what you are asking . do you want to know about other interpolation algorithms so you can see if yours works better or worse ?
62669,"just to be perfectly clear : would your dataset then consist of records that look like ( individual identifier , # tosses of coin 1 , proportion heads in coin 1 , # tosses of coin 2 , proportion heads in coin 2 ) ?"
62758,what are the possible answers to the questions ?
62859,what do you mean by less than robust ?
62887,you should look into survival analysis . there are many good books on this topic . what software are you using ?
62923,"what do you mean by "" bigger models "" ?"
62961,"just curious , which books have you been consulting ?"
63056,why would you consider 83 . 4 % cis ?
63099,most undergraduate texts on theoretical statistics or probability theory have a chapter on distribution theory that covers these questions . but how much mathematical background would you want to assume ?
63203,samples from heavy tailed distributions tend to have a huge range compared to the middle 50 % . what do you want to do about that ?
63217,"that appearance might be a consequence of the intervals that were chosen , or of something else . there's really very little to go on here . when you say "" my estimates "" you suggest the depicted estimates are yours , but your question earlier suggests the slides belong to someone else . are the estimates yours , and if not , why call them yours ?"
63231,"azeem asks : what do you mean by "" normalized frequency "" ?"
63415,given the problems with retrospective power ( see my answer ) i haven't given much thought to the aspects of the question pertaining interactions but i do have a question : do your factors represent experimental manipulations or measured / observed variables ?
58791,"what "" parametric test "" are you anticipating using ?"
63517,why are you looking at only the first principal component ?
63600,can you please rephrase your question or add some details ?
63750,i don't think that is possible . could you tell us more about your problem ?
63888,"( 1 ) does "" $ d $ "" stand for the probability mass function or for the cumulative distribution function ?"
63922,"is your question perhaps answered at url if not , how does it differ ?"
63924,why do you want the data to be normal ?
64157,ordinal or multinomial regression ?
64161,"( your nick is very appealing , i like it ) do i understand correctly that for you , "" subject "" is class , "" session "" is some condition or treatment ( what is it , by the way ?"
64162,can you give some more details as to the actual scenario ?
51296,can you define what you mean by precision and recall ?
64314,"you are focusing on the frequency of a specific word , and how its usage could predict events ?"
64429,"some questions : the idea here is that the sensor actually took a number of measurements , and calculated & returned their mean & sd , is that right ?"
64480,"if that inequality were not true , what would the correlation coefficient be ?"
64612,"welcome to the site , user28136 . i recognize that your title is informative , but it might be nice to add some context to your question in the body , rather than just paste output . what is it that's confusing you exactly ?"
64714,"this question should be able to stand on its own , or at least contain a link to other questions / answers upon which it depends . can you add information or links ?"
64720,what are the differences / link between daily_uv and reported_uv ?
64821,what is your sample size ?
64973,"the prior distribution is a specification for the parameter ( s ) of the model for the data . to specify a prior one needs to know what model you use for the data . so , what is it ?"
64962,[ what is the expectation maximization algorithm ?
64996,"you'll need to decide what you mean by "" significant change "" , and doing so should help determine the analytic approach too . for example , just by eyeballing the data it's obvious that person 1 now agrees with 35 more than they used to and disagrees with 11 more than they used to . if all you need is evidence that some people change their minds you've got it with that one data point . so how much difference is the threshold before you say it is material ?"
65055,"just to clarify some basics - firstly , do you have a univariate data set , with regular observations on a single variable that is "" river flow "" ?"
65216,hint : did the professor use a normal distribution function or a student t distribution function to compute the p-value ?
65437,can't you regress the variables to an intercept and work with the residuals ?
64614,stask any link without a paywall ?
65576,do the networks have different structures ?
65613,if the variables have a correlation of 0 . 95 almost all the information given by one of them is included in the information given by the other . why include both in the regression ?
65660,your interpretation of that sentence is correct : the author is saying that boosted models are not prone to overfitting . what else specifically do you need clarified ?
65708,do you mean transforming data from wide format to long format ?
65732,are you seeking a taxonomy of predictive modeling methods for univariate $ y $ ?
65738,couldn't you have chosen a slightly different title for your question ?
65838,"what distinction are you making between "" general linear model "" & "" multivariate linear regression model "" ?"
65841,are you treating the regressors as stochastic or as deterministic ?
65692,in what way cca generalizes pca ?
66002,you'd use a binary logit ( = logistic regression ) if the choices were mutually exclusive . is it possible that someone buys both shampoo and toothpaste ?
66273,what do you mean by 'very strict' there ?
66287,how many studies ?
66308,"i edited the question to clarify the meaning of "" ball "" as being all vectors of norm * less than or equal to * $ 1 $ rather than equal to $ 1 $ . is this what you intended ?"
66335,can you clarify what you mean here ?
66410,these models were generated on different samples from the same population of transactions ?
66449,"out of curiosity , where have you seen the phrase "" perfectly dependent "" ?"
66468,where did you see this term used ?
66579,"what does "" busy "" mean ?"
66641,your question is rather broad - it's hard to identify exactly what kind of assistance you need and therefore hard to make any suggestions . could you clarify your needs ?
66760,--ci 0 . 95 command could help ?
66771,"well , it's all about having the right tool for the job . your question is very vague : what are you trying to forecast ?"
66889,is there a reason why you've ruled out a-c a-priori ?
66898,what makes you think that the first sentence is true ?
66951,""" * 180 are system missing * "" --- this appears to be package-specific terminology . which package -- spss ?"
67054,are you looking for an algorithmic recommendation system ?
67123,"[ please add the 'self-study' tag ] it's like trying to check if your younger brother is really taller than you . you just compare the values ! if you * truly have the populations about which you wish to make some statements * about how the averages compare , you simply look at the two averages . is one less than the other ?"
67143,so what do you wanna test exactly ?
67328,"a little more precision in the main statement would help . where you write $ pr [ xy ] $ , what is that exactly ?"
66957,"can you say more about your situation , your data & your goals ?"
67536,are the data really that coarse ?
67659,"this sounds like a textbook type question . if this is for self-study , or for some subject , could you add the ` self-study ` tag ?"
67709,there's not enough information . were these coded as factors ?
67817,why is a difference being called a ratio ?
68140,is your continuous variable really continuous or discrete ?
68183,is your call to ` glm ` meant as pseudocode ?
68304,"i find this question confusing and suspect it might be because in statistics and data analysis "" sample "" has a particular meaning and you might be using it in a different way . even accounting for that , this question appears ill-defined : it seems you are asking for something ( to resample from a set of observations ?"
68313,how are the targets ( y variables ) related ?
68439,are the clicks also in the visits ( i . e . clicks / visits can never be greater than 1 ) ?
68440,what is your ultimate interest here ?
68573,are you using r ?
68597,"expressions like "" dum1 dum2 dum3 "" are not defined until you state how you are numerically encoding the dummies . how are * you * encoding them ?"
68662,do you have any matlab code example for using deep learning for forecasting ?
30411,can you give a reference to the paper ?
68876,are items in s similar to each other ?
69022,the intent of your question is not completely clear to me . you define the density of $ c $ over the same variable you're taking the integral over . did you mean to integrate the density with respect to $ dx $ ?
69094,"do you mean that the total number that reached level $ l $ is actually the value recorded there , * plus * all the values listed for the levels above $ l $ ?"
24400,"what is your interval between measurements , daily ?"
69192,can you give an example of what the data you gather would actually look like ?
69190,are you asking if their are any standard priors that incorporate a determinant ?
68870,"if i've understood correctly , you haven't developed the new questionnaire yet . what did you perform exploratory factor analysis on ?"
69516,a nice way to visualize three values summing to a constant is [ ternary scatter-plot ] ( url ) . but you have _four_ not three proportions adding up to 1 . this makes ternary plot not applicable . . . but who knows ?
69685,"you can always leave the very strong variable out of the initial random forest ( and reintroduce it later ) , but the rest of my input requires a few questions : after carrying out this random forest , are you hoping to build a regression model ?"
69727,questions pertaining to processing speed are not a great fit for cv . perhaps what you want to know is something along the lines of how many are required to ensure the stability of result ?
69874,"what do you mean by "" correcting "" ?"
70047,a small hint : what's $ hat beta_0 $ ?
70095,it kind of depends on what kind of information you would find relevant . # data dredging . how about apply zipf's law to estimate the total number of words in the mobile app vocabulary ( including the words not in your data ) ?
70125,what sort of text are you working with ?
70126,it is not clear to me what you meant by steps . is it an algorithm ?
70144,it's a good question but it seems pointless . what could be accomplished by such a separation that isn't already achieved by the mixture model estimates ?
70200,"just to make sure i understand , for every value of $ x in [ 1 , 1000 ] $ you have an associated probability ?"
70220,do you just want to delete class a ?
70282,how many cells are in the table ?
70543,"we're assuming $ a $ is a unitary transformation matrix , right ?"
70565,is that the * complete * dataset ?
70633,could you please tell us what you would have expected to see after running your code ?
70649,"what are you saying when you write "" . . . . means $ lambda_i $ and standard deviations respectively "" ?"
70744,"lots of things . the 1st answer would be sampling error , i suppose . can you say anything more specific ?"
70828,"the dependent variable , however , stays the same ?"
70746,is 'proving it' related to some subject ?
70893,user2676173 : what is the purpose of your analysis ?
70946,instead of averaging over daily batting averages why not calculate batting averages using the data from every day ?
70949,"you'll want to look into survival analysis methods taking into account right censoring . also , why do exactly half the observations not have a completion time ?"
71222,count you not just switch from the binomial confidence interval to the poisson ?
71327,are you speaking about [ friedman test ] ( url ) ?
71394,"do you know what the mean and variance of sums and differences of variables are , given their means , variances and covariances ?"
71390,what is your current knowledge about it from student point of view ?
71434,"what do you mean by the "" quantitative overlap "" of 2 species ?"
71475,i'm a little unclear on what you're asking . are you asking whether it's a problem if the practice effect of b on a is of a different magnitude than the practice effect of a on b ?
71493,"while i can't think of any that have known 'names' , it should be reasonably straightforward to derive closed-form solutions . are there any cases for $ y $ that you are particularly interested in ?"
71521,is the threshold the same ?
71623,have you considered the possibility of using both variables simultaneously to predict $ y $ ?
71829,"you are assuming familiarity here with very particular software , or so it seems . what is the specific question you are asking ?"
71887,"it would be nice if you define in your text what are $ d $ and $ k $ . also , why did you used tag ` bayesian ` ?"
71994,"how about building a joint dataset using your sets a , b , c by joining them on the variables in c ?"
72094,you mentioned each survey was already weighted . are they weighted using similar methods ?
72162,well i am not sure if i understand correctly what you are asking but i will give it a try . i understand that you have data and you split them in a and b . you want to know if you train with a what will happen if you test with b ?
72194,"what does "" c "" stand for in this context ?"
72205,"so , your task is to assess how much the clusters have reproduced the existent classes , yes ?"
72208,"i don't understand your question ( too much english for me , perhaps ) . do you want to display the variance on a picture ?"
72238,"` zeroinfl ( y ~ . , offset = log ( lambda ) , data = data , dist = "" poisson "" ) ` ?"
72253,are all $ 2m $ observations jointly independent ?
72256,suppose you were to address a collection of $ n $ instances of $ mathcal { p } $ and could choose either algorithm to do it . how would you compare the computational efforts then ?
72370,can you elaborate further ?
72375,"not for all models , only gaussian linear models . what is the model you use exactly ?"
72460,it is difficult to understand this description . could you perhaps post a simple example of your dataset ?
72669,the likelihood function of the sample is the joint density . here the variables are not independent . do you know how to apply the chain rule to decompose the joint density into conditional densities ?
72703,in what sense do you want a * proof * ?
72741,"possible duplicate of [ how to interpret and test for a significant difference between two correlations drawn from independent groups ( e . g . , males and females ) ?"
72756,what is the feedback ?
72762,"have you consulted the [ wikipedia article on "" statistical distance "" ] ( url ) , which points out there are * many * different distances ?"
72985,"you seem to state that you know the vectors $ ( a_k ) $ and $ ( b_k ) $ up to permutation . ( to maximize their inner product you put both sequences in ascending order ; to minimize their inner product you put one in ascending order and the other in descending order . ) but i'm not sure that's what you're saying , because if you * do * have this kind of information then you can easily compute both the means and the sds , yet you specifically remark that you have the means and yet cannot find the sds . could you please edit the question to clarify exactly what information you really have ?"
72981,don't you want . . . to determine which variable give the greatest segregation between the yes and no samples ?
73091,is this self-study or homework ?
73212,the question is not clear enough to give an answer . what is exactly your working hypothesis ?
73214,the statement for t 2 will only be true if the degrees of freedom are large enough . can you provide examples of papers that make a statement like that ?
73362,"first , a test can't show "" no significance "" - it gives a particular p value . second i don't understand exactly what you mean by "" subsetting on varx "" , nor exactly what you are bootstrapping . what is it you are trying to do ?"
73387,"please tell us what $ z , $ $ varepsilon , $ $ hat { varepsilon } , $ and $ sigma $ represent . in particular , what formulas do you know that express $ hat { varepsilon } $ in terms of $ varepsilon $ and $ z $ ?"
73410,"are you looking for an answer that dr . sheldon cooper might appreciate , or one that leonard or raj would be satisfied with ?"
73449,can you give us an idea of how many words or powerpoint slides you can use to get the idea across ?
73526,"hi , have you already solved this problem ?"
73529,are you after $ frac { partial hat { p } } { partial x } $ at $ x = bar x $ ?
73689,"without using any jargon ( and especially , without using the word 'significant' ) , what are you actually trying to achieve ?"
73742,"the actual estimators and models are not important to your metric , just the performance of the model based on 1000 random subsets ?"
73818,i've not heard of this operative effect size . there are equations using 1-r but i'm uncertain if you have the right one . do you have references for operative effect size and your 1-r including equation ?
73828,"welcome to the site , nikos . i don't think your question is answerable in its current form . can you tell us more about your data , your situation , & your goals ?"
74133,how can da validate the clusters ?
74172,could you please be more specific what it is that you want to know and in what context ?
74210,"hi rdittmer , welcome to the site ! as this is a self-study question , could you please add the ` self-study ` tag ?"
74270,"in your notation , what is $ p $ ?"
74322,do you correctly interprete the bootstrap distribution ?
74450,where exactly did you find those statistics ?
74452,( i ) please read the [ self-study tag wiki info ] ( url ) - what have you tried ?
74507,is the null that the distributions are identical apart from the possibility of a change in spread ?
74588,"your link is not to a paper by genest et al . . . the linked paper is by dobri and schmid . please fix , either by changing the link to the one you meant or changing the name to correspond to the actual authors listed ( and if you keep 'genest' in your question , please correct the spelling of that name at the same time ) . further , questions should as far as possible stand on their own ( for example , what happens to your question if the paper is moved ?"
74596,it it correct to assume that the complication will not happen anymore if you are able to predict it based on imaging ?
74595,"it is not clear what you are asking . "" should you . . . "" - for what purpose ?"
74701,what's lasso4j ?
74912,"this is a broad question , can you be more specific towards what you are looking for ?"
74945,"this sounds like a linear regression problem written in a slightly different-looking form . ( just out of curiosity , is $ x_1 $ a vector of $ 1 $ s ?"
75056,do you have a statistics package ?
76084,can you please be slightly more specific ?
76104,do you know mvrnorm ( ) from the mass library in r ( url ) ?
76195,is it a univariate or a multivariate gaussian you are trying to fit ?
76243,after taking the measurement the subject will no longer be in the study . is that correct ?
76423,this depends entirely on * your * objectives : why are you predicting ?
76586,is this ( 1 ) one survey sent to 33 individuals ?
76608,why does a square matrix not work ?
76673,"this is an incredibly broad question , and you haven't given many details . there are many other macroeconomic factors that go into the cpi than just e-commerce . can cpi be modeled ?"
76811,"what exactly do you mean by "" multivariate . . . regression "" ?"
76827,are you talking about the function ` glmnet ` in the * r * package ` glmnet ` ?
76893,why not ask your professor exactly what he meant ?
76950,what is your understanding of what a random variable is ?
76958,"if you are "" measuring their difference [ as ] $ c = a-b $ "" , what does it mean for there to be a "" case when $ x_a-x_b ne x_c $ "" ?"
76922,"as i have understood the question , the typos do not occur in labels ( response variable ) , but only in the predictor variable aka terms . is this correct ?"
77012,do you need to do this by hand or using statistical computing software ?
76997,welcome . is there any piece of data you can provide as a [ reproducible example ] ( url ) ?
77110,are you sure you need a derivative for your optimization ?
77115,how do you derive the jeffreys prior on the other parameter once you have given a prior to the other parameter ?
77146,"this question is a little unclear . . . why are you even trying to define states , instead of just using the measurement data itself ?"
77265,employ and gpd are absolute values or relative variations ?
77384,this sounds oddly familiar to your recent question [ here ] ( url ) . could you elaborate on how they differ ?
77440,"why do you want to do this via spherical coordinates instead of the more conventional way , as mentioned in your second link ?"
77635,what makes it difficult for you to calculate it as soon as you understood it ?
77876,"did you use the same parameters ( $ c $ , $ gamma $ ) before and after scaling ?"
77893,the paper you link to seems to answer your questions . perhaps you can rephrase your question to ask something specific in the paper that you did not understand ?
77895,"a minor but important clarification is needed : are all the values of $ a $ ( or $ c $ ) associated with each pair $ ( x_i , y_i ) $ the * same * or can they differ from one observation to the next ?"
78049,how can you know the variance without knowing the mean ?
78068,"to many people ( e . g . url ) , what you are asking to show is the very definition of a bootstrap sample ! it appears , then , that you are starting with a different definition . * what is it ?"
78144,what about [ integration by parts ] ( url ) ?
78521,"welcome to the list . are you asking for statistical help ( that is , what is the right way to find the association between these variables ?"
78761,"in what way is the data "" not good "" ?"
78722,which book has that first form ?
78878,( 1 ) why wouldn't you want to include a variable that directly calculates the independent variable ?
78896,have you read the corresponding [ wiki ] ( url ) ?
79018,"what constitutes being "" about the same thing "" ?"
79087,"i find the double negative in "" ( not ) never "" ambiguous . do you mean "" never "" or not ?"
76068,"what do you mean by "" validate "" ?"
79337,"i don't follow your overview . is it that 2 people mentioned customer service among their reasons & only 1 person mentioned speed , or something else ?"
79371,why is it necessary to omit data ?
79516,are you by any chance being asked to find the * observed * fisher information ?
79546,have you tried ` plot ( fittree ) ` to visualize your decision tree ?
79623,how are these data values measured ?
79653,what are these values ?
79655,why don't you try proving the asymptotic normality of the mle using this set of assumptions and see if you need any more ?
79970,"this appears to be a standard textbook-style question ; while such questions are welcome here , they are treated differently . please review the ` self-study ` [ tag wiki info ] ( url ) , and add the tag to your post . with the points in the tag wiki in mind , what have you tried ?"
79974,"please read the ` self-study ` [ tag wiki info ] ( url ) . you'll note that for this kind of question , more is expected of you than just posting the question . please address the points in the tag wiki . if you knew the population proportion was some particular value , could you do this sort of a question ?"
80002,is this homework ?
80014,"using 0 . 5 is a good "" default "" . however , if your two misclassifications have different costs or implications , another number might be better . what is the context ?"
80054,is that $ mu_ { t 1 } $ or $ epsilon_t $ ?
80059,"it is a good deal better , thank you . however , you do still leave a number of totally subjective things ( such as 'a better result' ) unspecified . better in what way ?"
80041,some more details might help here . what are your variables ?
80172,are you using ` anova ` from the stats package ?
80175,"are you asking in general , or are you asking specifically how to do this in r ?"
80209,it will also partly depend on the nature of the questionnaire and what you are trying to do and on the distributions of the other questions . is this an ability test ?
80282,"just to be clear , all the items are either 1 or 0 ?"
80283,do you just want the pairwise euclidean distances in pc scores for all languages ( based on the first two pcs ) ?
80484,what happens if $ mathbb e [ y_n ] infty $ and $ n rightarrow infty $ ?
80498,what are your null and alternative hypotheses ?
80532,"three properties , three things to check : which of these is causing you difficulties ?"
80640,"is your question about how to do this in ` spss ` or is it about whether this is permissible , statistically ?"
80794,"if you have 0's then , of course , a pure log transform will not work . are there any actual 0's ?"
81047,"when you say throwing away values is not an option , do you mean that there's some reason you can't throw * any * away , or that you can't throw as many away as a naive approach would suggest ?"
81061,"what kind of "" information "" do you wish to extract ?"
81068,categorical or continuous moderator ?
81161,random subsets of the test data ?
81184,"some clarifications are needed . with contr . poly ( 5 ) , are you interested in the linear up to quartic relationships across time ?"
81194,"some context is needed here : what kind of answer are you looking for where you ask "" which time series "" ?"
81227,( i ) if you're writing a distribution for predicted values it sounds like you're trying to use a bayesian framework . are you after a prediction interval for your predicted values ( or their sum ) instead ?
81288,* * hints : * * is the company trying to make decisions about the size-18 customers who have sent in their heights or about all future customers who order size 18 ?
81480,how are you measuring performance ?
81516,"what do you mean by "" why we get probability of x = 2 , 3 ?"
81753,do you mean the percentage of variance explained by each component ?
81893,your equations ( 1 ) and ( 2 ) are surprising . what kind of weird model do you have ?
81911,"did you set "" type of matrix "" = covariance ?"
81929,"in some contexts , with some interpretations of "" statistical significance , "" this question makes no sense at all ( as hinted by your quotation ) and in others it is fine but cannot be answered with the information given . what , then , do * you * mean by "" statistically significant "" ?"
82354,this has a flavour of : i get 42 as the result of a calculation with data i won't show you . did i do it right ?
82362,"it might help to know a bit more about your data , what is the response variable and what are the covariates ?"
82386,"if your data is different each time , why would you expect a number calculated from that data to be the same each time ?"
82478,is that matlab code ?
82709,your question is not quite clear . are you asking what was the first study ( historically ) to have used k-means clustering ?
82717,"try stepping back from the math a little . . . writing heuristically , how does $ t ( f ) $ change for a small change in a value of $ x f ^ { -1 } ( alpha ) $ ?"
82757,do you have any measure / estimate of the consequences of being out by a given amount in your forecast ?
82767,"( 1 ) do you have before & after measurements , or at least multiple measurements , for each store ?"
82852,what does the word 'represent' really mean in this context ?
82979,did you try these websites ?
82997,have you checked missing data ?
83061,"do you know that $ a , b , c $ are independent or uncorrelated ?"
83133,"so , if coefficients and ses are identical , what is the difference between the fits ( i . e . , the results not the r commands ) ?"
83159,what would you propose using to represent the distribution of the data instead of $ f_n $ ?
83509,"my question might be dumb , but is this even a statistics-related question ?"
83616,could you please describe the objective of the regression you are trying to create ?
83647,what is $ nu $ ?
83805,"this is one case where proving a generalization of the statement might be easier than proving a special case , as well as giving more insight : can you show that the conclusion is true when the normal distribution is replaced by * any * symmetric distribution ?"
83835,are you asking about mahalanobis distance ?
83967,i'm confused by this set up . what's $ i $ ?
84024,does the statement make sense for you if you put scalars there ?
84164,can you clarify why you want to use a generalized linear model ?
85385,"i need some clarification : when dividing data into 'folds' , the number of classes is irrelevant , unless you're actually saying that you have only two data points . why not randomly assign points to folds , without considering 'class' ?"
85432,a little more information please . how many subjects do you have ( irt models can require a large number of subjects ) ?
85476,so you're taking proportions because they're all going for the same prey ?
85572,do your offers expire ?
85659,are you scaling the out of sample test set in the same way ?
85754,i'm trying to understand the question . are you asking that how you can write down the likelihood of the bigger matrix when each of its rows is characterized by a separate gaussian mixture model ?
85759,have you seen [ this thread ] ( url ) ?
86184,"and to clarify , are you saying you've got the top $ k $ scores out of unknown $ n $ from a known family ( e . g . log-normal ) whose parameters ( e . g $ mu $ , $ sigma $ ) you want to estimate ?"
86220,this question leaves so scarce information so far . what clustering method do you conceive of ?
86377,are you sure you don't want $ a $ to be the event $ x- mu_x le k sigma_x $ and $ y- mu_y le k sigma_y $ ?
86411,what is the resolution of your temporal data ?
86831,"hi user40398 , welcome to cross validated . your question seems to be a little bit hard to understand the way it is written now . could you make it a little bit clearer ?"
86962,this looks like a [ routine textbook style question ] ( url ) . tell me ( you can work it out ) - what's the value of $ bar x $ ?
86975,"if the sample standard deviation was 0 , what would the sample look like ?"
86993,"do i understand you correctly , a = 0 iff b ! = 0 and vice versa ?"
87093,""" * isn't the equation derived using mle a regression ?"
87139,do you need exactly the given values or just reasonable approximations ?
87154,"why 15 , 5 and 2 ?"
87411,the linear situation is well understood : when you're * sure * the relationship is linear then the most precise fit is found by making half the observations at each extreme value of the independent variable ( 0 % and 25 % ) . the math is that of ordinary least squares . your question is more interesting due to the complication of needing to figure out the shape of the curve . good answers will capitalize on your * objectives * : presumably at some later point you will use this information to optimize a business objective ( like profit ) . how exactly will you use your study results in that optimization ?
87483,did you give them 4 yes / no questions ( one for each subject ) ?
87627,there's not enough information to say much of anything . how does the bartlett test work with time series - doesn't it work on grouped data and rely on independence ?
51384,what are you trying to do ?
87933,"what do you mean by "" influences ?"
87943,"i can't see that this is a stata question ; conversely , if it is , it is off-topic here . if the doubt is what to do , then much of any time series text or course includes material on ( e . g . ) removing trends and / or building models that include trends . as formulated , this question is too broad to be answered , as it is too close to what should i do with nonstationary data ?"
88109,"there are several different meanings of "" sampling weights "" ; for instance , stata natively supports three different ones . could you therefore explain what your weights mean ?"
88150,were there any time lapses between weeks ?
88182,"you seem to have overlooked the expectation operators in drawing your conclusions . here is a simple analogy : when the expectation of a random variable is positive , does that imply the variable cannot have any negative values ?"
88214,( just in case one of them turns out to be equivalent ) what were the model selection criteria that were included ?
88218,"just to make sure , "" skewed negative "" means the long tail pointing to left or right ?"
88253,"it's unclear what you're asking , or what you were asked to do . what was the assignment ?"
88255,welcome to the site . could you spell out ` lda ` ?
88320,the panel structure of the dataset would make for an odd interpretation of the output . you might get the same people in different clusters . maybe this is what you want ?
88456,"the general answer to "" how do i compute power for a complex situation "" ?"
88635,are you adding interaction terms when you add your dummies ?
88718,you don't know anything about z ?
89056,welcome to the site ! can you tell us some more about your data and the sorts of comparisons you'd like to make ?
89078,"if you are trying to compare boston with nyc , why not do a 2x2 chi-square ?"
89174,what are the uncertainties ?
89188,i'm guess you mean a $ threshold $ that maximizes your true negative rate while minimizing your false negative rate ?
89334,"hi bunya , welcome to cv . could you give a little bit more detail in your question ?"
89364,"how "" small "" is your dataset ?"
89437,is that community special in some sense ( other than the high proportion of missing data ) ?
89440,"where do the $ n = 60 , 000 $ people come from ?"
89489,"can you explain what is meant by : i ) you "" found one breakpoint ?"
89547,what type of model are we talking about here ?
89617,which form of the gamma are you discussing ( is $ beta $ the scale or the rate ?
89842,what do you mean and want by ` formally test ` ?
89921,"anything with the word "" analysis "" in it can't be a model , by definition . the goal is to "" explain "" reaction time by each of the medications . the goal of the model is to answer such questions like , "" what brand had the longest / shortest reaction time ?"
89923,have you considered bayes' theorem ?
89943,you have the same expectation for a binomial distribution with parameters $ n $ and $ p = frac { k } { n } $ . what happens when $ n $ increases while $ n $ and $ k $ do not ?
90010,"i believe to do this properly you will need to use time series analysis . perhaps , apply arima and look for a trend . how much data do you have ?"
90028,how severely unbalanced are the data ?
90079,does it require strictly positive data ?
90136,"unless there are id's that span states , then you can cluster on the nesting variable . i think there is a paper by colin cameron at uc davis that explains this . re : dummies : are they collinear ?"
90165,"is it i ) you draw a coin , toss , put the coin back and repeat for another 99 times , or ii ) you draw a coin , toss it 100 times ?"
90350,"if all you want to know is the mean and variance of the index over the last month , why do you think you need the distribution ?"
90395,this is a standard problem covered in statistics textbooks . did you try consulting them first ?
90451,` because i think that euclidean distance assumes that the dimensions are independent ` why do you think so ?
90463,"have you checked what , if anything , mostly harmless econometricians recommend ?"
90544,"are the random variables mapping a ( fair ) coin toss ` ( head - 0 , tails - 1 ) ` and ` ( head - 1 , tails - 0 ) ` identically distributed ?"
90586,"are you thinking of ( 1 ) experimental studies that demonstrate causation , or ( 2 ) observational studies that turned out on further investigation to have identified causal relationships , or ( 3 ) observational studies that in themselves provide strong evidence for causal relationships ( having included all plausible confounders , & c . ) - or something else ?"
90608,"i'd say no , and much though i love stata , that software is irrelevant here too . even if you got an excellent-looking result with one method , it could still be better with the other . in any case , what is "" better "" ?"
90782,you might be able to do an anova for part 1 and a grouped linear regression ( by distance ) for the other . is there a flow or current component to this ?
90799,how do you calculate rmse ?
91138,i've voted to leave the question open as there is a statistical question here . are you interested in measures of health service for * individuals * or are you interested in aggregating your survey up to make measures of health service * in areas * ?
91148,"if you're not sure what to compare them with that means you're not sure what question you're asking , so let's start there : what is your research question ?"
91196,is the total number of trials huge ?
91326,"can you state your hypothesis in plain english ( without using statistical jargon like "" significant "" -- which doesn't belong in a hypothesis ) ?"
91363,why did this get migrated to cv ?
91393,"you will need to be a bit more precise in what exactly you mean by "" similar "" . what level of dissimilarity should be detected as abnormal ?"
91466,"let's see : $ ( a , c ) - ( b , c ) - ( a , d ) ( b , d ) = ( 0 , 0 ) $ shows those four pairs are linearly dependent . can a set of linearly dependent random variables be independent ?"
91500,i don't really understand what question you are asking . your original problem is to find out the required sample size needed to answer what question ?
91510,"you have n x variables . are you saying how to correlate any particular one w / color ( eg , cor ( color , x_1 ) ) or the combination of all of them ?"
91585,what happens when the $ 2 $ comes from one group and the $ 3 $ comes from the other group you are comparing it to ?
91633,what are you trying to accomplish ?
91961,what if $ x_1 $ is the largest sample value ?
92199,"why not multiply everything by -1 , then proceed as usual ?"
92239,why sample mean rather than sample median ( which actually minimizes the sum of absolute deviations from the sample values ) ?
92249,do you have repeated observations of the same units across time ?
92266,"if it is a classification task , k-nn classifier or nearest centroid classifier ?"
92383,have you find an answer to this question ?
92388,it is possible in ` nlme ` . check the use of ` ?
92661,"usually , the mean is just an estimator for the expectation of a random variable . are you sure you don't have to prove the mean is an unbiased estimator of the expectation ?"
92670,"this says you are trying to predict something rare . my take would be that you don't have enough good predictors of the "" rare "" cases . if you did there would likely be more points in the 0-2 range . either that or there is a certain class of points that your model does poorly on . is your estimated intercept large in magnitude ?"
92826,did you look at ` ?
92851,i don't understand why it's important to say that your clusters are statistically significant ?
93001,is this for a class ?
93211,what was the basis of the claim that you could not ?
93386,"just to clarify : by "" first orthonormal component "" you mean the eigenvector $ psi_1 $ of the covariance matrix of ` x ` with the largest eigenvalue or the corresponding pc projection scores ( say $ f_ { 1 , j } $ ) ?"
93448,is this an exercise for some subject ?
93472,how large are the two sample sizes and the two variances ?
93603,are you allowed to keep tossing after you hit $ 0 ?
93633,what is the 'problem' you refer to ?
93636,what do you mean that this is for a paper ?
94111,"if it is a log-linear model , then the offset should be log ( length ) . also , how are you determining model quality ?"
94156,why don't you estimate the standard deviation directly from data ?
94204,welcome to our site ! could you edit your question to clarify some obscure points ?
94663,what are the column headers ?
94909,"your terminology is likely to confuse people : ordinarily "" controls "" and "" cases "" are * assigned by the experimenter . * if you have no cases , you haven't done the experiment yet and there is nothing to analyze . one might guess that "" controls "" and "" cases "" just distinguish two possible outcomes that can occur , but what exactly do "" a "" and "" b "" mean ?"
95083,50 % missing values for a crucial variable ?
95099,what's the sample size ?
95227,"( 1 ) moments , even when measured without sampling error , don't determine distributions particularly well ; sometimes even an infinite number of moments is insufficient . ( 2 ) why would the list of distributions in wikipedia happen to coincide with your data ?"
95257,do you have any other in-house rules ?
95424,"welcome to crossvalidated ! you are aware of aggregated and ensemble models , are you ?"
95431,can you please clarify what you mean by comparing for differences ?
95608,"are the 10 independent ordinal variables meant to measure the same latent construct , or different ones ?"
95620,what is opt-in ?
95621,"please say what you mean by "" relevant "" and "" agile . "" what is your research question ?"
95657,"the statistics are independent , i suppose ?"
95726,why not ask your professor ?
95913,can you give some context ?
95989,"what does "" the marbles are assumed to be normally distributed . "" mean here ?"
96301,"since this is a textbook question , you should add the ` self-study ` tag ( see url ) . also , would you be able to make your figure larger ?"
96396,what's the measure of your time component ?
96403,"this question is not clear . what do you mean by "" how regression tree is better than ols in terms of heterogeneity "" ?"
96592,when you say 'een' is that intended to be the dutch indefinite article ( 'a' in english ) ?
96767,"do you have a sample from each population , or do you actually know the total number of people in each population who like ice cream ?"
104544,which probabilities are given to start with ?
106405,possible duplicate of [ should covariates that are not statistically significant be 'kept in' when creating a model ?
111147,are you getting those values from somewhere ?
117633,what source did your supervisor recommend when you asked him ?
10450,"can you define what you mean by "" random "" ?"
124843,could you edit your question to give examples for methods described as long term or short term methods ?
124950,"does "" not more than 10 % different "" mean that max = 1 . 1min , or min = 0 . 9max , or ( max-min ) = 0 . 1 ( max min ) / 2 ?"
135004,have you read url how does your question differ ?
136147,"just to clarify , you mean that the independent variables have many 0s , not the dependent , correct ?"
136355,where is the 4 . 7 population mean coming from ?
136452,does your question include the restriction to exponential families ?
137728,this seems to be more of a comment than an answer . which book are you referencing ?
137997,how do you get from $ e [ x x y ] $ to $ int_ { x y } xf_ { x y } dx $ ?
139878,"i'm trying to grab the gist . you have measurements of several variables on several occassions ( t1 , t2 , t3 , . . . ) on the same group of people . you would like to predict somehow the progress of people , more specifically the progress from t1- t2 , t2- t3 , t3- . . is that correct ?"
143310,are you using linear regression ?
155811,are the two sets of yes / no answers paired ( given by the same subjects ) ?
168252,what do you mean by statistically relevant ?
172857,did you look at false discovery rate ?
178545,jasonstack do you have a reference to the paper ?
180010,why do you want your algorithm to predict some wrong value ?
180033,what do you mean by reliable ?
181825,"how did you conclude that you needed an * odds ratio * , especially since odds are typically estimated as a function of the presence or absence of a property or feature ?"
182278,do you use stratification or weighting ?
186619,you mean $ mathbb { p } ( left { omega : mathbb { 1 } _a ( omega ) = 1 right } ) = 1 $ ?
188919,"( 1 ) appears to have no bearing on the question . regardless , * both * calculations assume the chance of winning the second drawing of the lottery is $ 1 / 2 $ , no matter what happens in the first drawing . what more is there to say ?"
190566,"residuals are correlated by construction , do you perhaps mean the errors ?"
202856,"hierarchical agglomerative clustering ( hac ) stepwisely combines objects in greater and greater , wrt frequency inside , clusters . there arises question how a distance between clusters should be defined . between two single objects the distance is plain : it's the distance between them in the input distance matrix . but what is the distance between an object and a 2-object cluster ?"
222214,i'm not entirely clear what you are asking about . the point of cv lies in applying it to * different * models and * choosing * the model that has the lowest cv error . could you clarify ?
229391,"plot with errorbars is one way to report confidence intervals . do you want to test if effect for pop a differs from the same effect for pop b , and looking for suitable test / plot ?"
234705,what do you measure ?
239939,is the question how to apply rf to time series data ?
252869,did you retrain it after the swapping ?
255620,why is b not called a fair coin ?
256823,did you happen to come across [ this ] ( url ) ?
257395,are you treating this as a time series ?
263984,what is the objective of your study . which technique you intend to apply . panel data analysis ?
30878,"could you please clarify what you mean by "" separately both from other factors and other dates "" ?"
265580,isn't it true that the software has a menu you can use to obtain the required sample size ?
17933,"i am sorry , but this question makes no sense to me . normally one would group the scores in order to see how the teams are distributed across the scores . your grouping , as far as i understand you , is purely artificial . what shall this plot demonstrate ?"
268840,"so , you just want to convert a nominal variable to continous ?"
270544,"is this "" self study "" ?"
270613,are you explictly talking about normalization or do you mean scaling ?
76552,will all the separators always be approximately the same color ?
44130,"this is a good question , but does seem like it may be a better fit on the [ math se site ] ( url ) , are you only interested in the mathematical aspects of this , or are you also wondering about the substantive statistical meaning of changing $ w $ ( eg ) ?"
70526,are there any particular areas of ecology that you are interested in ?
51089,what about an odds ratio ?
26475,"could you elaborate a little bit more on the "" different categories of the classification "" ?"
142343,"by "" rate of something "" would you mean a count of events per unit time ?"
273539,how do you calculate a standard deviation beforehand ?
273550,"your question appears not to be about binning * per se * but rather on how you intend to introduce this as an explanatory variable into the regression . without binning , it costs you one degree of freedom : the assumption is that the logit of the response varies linearly with this variable . if you were to bin it ( into , say , five bins ) * and treat the bins as categories * , evidently that would cost you $ 5-1 = 4 $ degrees of freedom , in return for which you do not need a linear relationship . why not test this by formally comparing the two models ?"
273775,why are there two control groups in the first place ?
276608,"sorry if i'm being dense , but how do you know that x and x * y have the same mean ?"
277505,what do you mean events $ y_j $ ?
280341,why not welch-satterthwaite type anova ?
280715,"if you're just concerned with the individual variables , couldn't you simply perform a normality test on them separately ?"
15281,"* ad 1 . * your formula vaguely represents the variance of regression , and related indicators ( such as r ) are commonly used as quality criteria . * ad 2 . * why would you apply a * visual * method for parameter optimization ?"
285516,"let me make sure i understand the question : right now , variable 1 has five levels [ 1 , 2 , 3 , 4 , 5 ] . your professor thinks you can collapse levels 1 and 3 together , which would mean you have four levels [ 2 , 4 , 5 , 1 & 3 ] . your question is what test can tell you if you can collapse those levels into one ?"
286215,why don't you do a linear or logistic regression ?
287189,why did you average your hourly data to monthly ?
287511,what are you intending to illustrate ?
287780,what is your question ?
295827,have you considered this as a meta-analysis problem ?
296736,why the downvote ?
300566,"you are implicitly assuming that a and b are equally likely to occur , is this on purpose ?"
301949,"i don't understand , why don't you produce your averaged path by simply taking all ` lane deviation ` values at a certain ` distance ` and average them ?"
307178,are you trying to compare designs where each person sees one ad with designs where each person sees many ?
308818,"how do you calculate this "" anova "" statistic ?"
309197,what exactly would you like to prove ?
309221,did you use 0 . 298 for p or 0 . 25 ?
309247,"are you going to find your null hypothesis more plausible when your sample mean is * close * to the hypothesized mean , or when it's * very far * from the hypothesized mean ?"
309293,the short answer to your question is yes . why not try adding some non-linear term in age ?
309289,what kind of reason are you looking for ?
309430,why not just have a loss function only for temperature ?
309522,"would a "" root square "" transformation be the * square root * , $ x to x ^ { 1 / 2 } $ ?"
309532,why ( and how ) does a fixed effects regresson reduce the number of individuals ?
309609,is it clear what does the assumption $ l ^ * = 0 $ gives you ?
309617,are they at risk of the event ?
309640,are the non-zeroes counts ?
309677,"how many items , how many observations do you have ?"
309702,how would you fit a binary model in your first example ?
309962,can please tell what is t-sne ?
310102,are you talking about perfect separability like in logistic regression ( hauck-donner effect ) ?
310407,do you have an example of what this should look like ?
310440,why do you feel you can do anova but not glm ?
310572,"you could always just say no . you do not say who asked you , is it someone who has some power over you ?"
310623,is this a question from homework / a test ?
310735,how many observations do you have per level of the categorical predictor ?
310897,"have you already considered censored regression models , like the ` tobit ` model ?"
310947,what are your inputs ?
311095,"if you intend $ w_a $ to be a vector , then just what do you mean by "" $ w_a ^ 2 $ "" ?"
311216,this is unclear -- what exactly do you mean by 'input space ?
311234,"can you clarify the distinction between "" the optimal number of clusters for clustering "" , & "" the number of clusters my data has by its nature "" ?"
311273,are you sure you are reading correctly ?
311476,do you intend to use each question within each domain separately or do you intend to try to aggregate them in some way to form a scale ?
311570,"there are indeed some , mostly chi-square based tests . but doesn't the book consider them to some extent ?"
311694,what is berkson's error ?
311700,are these numeric measurements made at fixed intervals over time or space ?
311775,"you should be more specific as to what sort of comparison you want to do . do you want to do hypothesis testing with null hypothesis "" the population means of the distributions the three means were drawn from are the same "" ?"
311874,could you also link to the chapter later in the book in which they make the claim ?
311609,how can a constant be ergodic ?
312061,why doesn't the obvious construction work ?
312089,hard to guess because it's not defined the blog post . have you tried emailing the author ?
312303,"could you refer us to any authority that asserts t tests , anova , and kw tests are not applicable to small groups ?"
312505,why dirichlet when you state its a proportion of counts ?
312547,"mac wang , does the machine solve the problem well after the training ?"
312572,"the premise of this question is that it is good to do so , but what makes you think so ?"
312749,what quantity are you trying to obtain when you transform back ?
312752,in what way are some observations far more important than others ?
313100,"do you mean linear in some function of $ x $ , linear in some function of $ ( theta_1 , theta_2 , theta_3 ) $ , or both ?"
313272,"why not just define $ x_3 = min { x_1 , x_2 } $ and run the regression $ y = beta_0 beta_1 x_3 mu $ ?"
313287,i just want to make doubly sure : the thing you want demonstrated is that this $ - frac { 1 } { 3 } ( x_ { t 1 } -2x_t x_ { t-1 } ) $ equals this $ - frac { 1 } { 3 } delta ^ 2x_ { t 1 } $ ?
313297,"just for clarification - how many independent variables do you have , and what types are they ?"
313732,"if your data are counts , they really can't be gaussian . they might be something else , though . is there some kind of maximum possible count ( eg , count of heads , where number of coin flips is known ) ?"
313853,what makes you think that this is not the right answer ?
313996,how about that ?
314113,you want to always reject the null hypotheses ?
314112,what are gbc and rfe ?
314216,why do you have to assume any ( or a linear one specifically ) association between $ x_1 $ and $ x_2 $ ?
314410,is the categorical variable ordered or not ?
44664,does this help ?
314618,what is your goal here ?
314634,did you read about the roots of the characteristic polynomial ?
314775,is it a homework ?
314902,what kind of uniform distribution ?
314996,can you be more specific about the data ?
315096,what do those plots look like ?
315284,what is the purpose of such a representation ?
315338,are you looking for kind of weighted balance statistics for two populations ( eg for treated and controls ) ?
315439,"sure--but it's no different than , say , recording temperatures in degrees f and restating them in degrees c for analysis . besides , you're doing ml--why would you even care that the data are changed , provided the model works ?"
315634,have you considered l1 regularization ?
315721,if you have the underlying data why not re-analyse it using the same method for each study and get an effect size and standard error from each ?
315741,wat does the star mean ?
315771,did you look into box-cox transform ?
315927,"you don't understand what [ maximum likelihood ] ( url ) is , or how was it calculated for the markov chain ?"
316000,did you look into bootstrapping ?
316077,"for 1 , 000 , 000 dimensions , you must have a lot of time samples . how many time points do you have ?"
316255,statistics is a big field . can you narrow down what specifically you are interested in ?
316533,can you link a url or a text name for what you are reading ?
316538,are you asking about overfitting ?
316697,"what do you mean by "" profile "" in the second sentence ?"
316859,is there any reason why you want to avoid doing a meta-analysis ?
316943,"what does it mean for the acf plot to "" look bad "" ?"
317101,could you elaborate on what you're looking for ?
317104,you mean to regress the residuals on covariates ?
317311,what is the * expected * count for d-yes ?
317431,hint : what's the joint probability of two independent events ?
61104,see ` ?
317846,"have they run tests , observed "" non-significant results "" , and then decided they were unsatisfied with these tests ?"
318106,are they the same species and same geographic area ?
318266,"there are much better methods than that , so what do you really want to ask : how to optimize a procedure that appears to be inferior ( the one you describe ) or how to improve the predictions ?"
318296,this question is thin . can you add detail ?
318311,by * elbow * you mean the first meaningful statistical divergence from x = 0 ?
318459,couldn't you simply set all temperatures above 0 to exactly 0 ?
318495,"what this model fits * is * a continuous quantity : it's the ( log or logit of the ) poisson parameter . to that extent , any method that works for ordinary least squares models ought to work here , too . could you elaborate on what you mean by "" probing "" an interaction ?"
319116,"in general , it all depends on the loss function . for example posterior mean is the estimator when a quadraric loss function is used and the posterior mode when a 0-1 loss function is used . also one can take the absolute error loss which leads to the posterior median . is this helpful ?"
318703,"hi daniele , i'm having trouble replicating your work . the ` acf ( ) ` function in the ` stats : : ` package returns a plot ( unless the argument ` plot = false ` is supplied ) , not a single ( positive or negative ) value . what do you mean by "" negative autocorrelation "" ?"
319627,where did you encounter the definition you mention ?
319895,what exactly do you not understand ?
320124,"the standard normal distribution n ( 0 , 1 ) has a mean of zero and a standard deviation of one . url is that what you are asking or do you want every possible distribution to be standardized ?"
320567,can you please add the source of these derivations ?
320581,a typical first step if you have three continuous predictors and a binary outcome is logistic regression . have you considered logistic regression ?
320682,"most , if not all , of these questions are answered at url after reviewing that , could you edit your post to focus on any aspects of your questions that might not already have been answered ?"
320893,does each movie have at least 1 genre ?
321745,could you elaborate a bit more on which problem you want to apply the conjugate gradient method ?
322047,what are you taking as your definition of natural cubic splines ?
322080,are any of those values zero or negative ?
322128,you need to dig a little into r documentation enter ?
322439,is that count data ?
322870,"( 1 ) the first plot clearly is not linear , although it may be approximately so . ( 2 ) what does the second plot show ?"
323115,"if the state sequence ( including the starting state $ 1 $ ) is $ 1-2-2-3-3-3-4 $ , is the answer not $ 6 $ steps ?"
323264,is this in r ?
323556,please show us the details of ` y ` : how exactly are its levels encoded ?
323610,""" model selection "" is a big word that can include tons of things . can you talk more specific ?"
323731,-test reveals they're only 0 . 1 sigmas apart . what is sigma here ?
323779,"to give a concrete example , if you're comparing the performance of randomforest with max_features = 2 or max_features = 10 , are you asking if it would be in some sense better to start each test with the random number generator initialized to the same seed ?"
175429,why would it matter ?
323963,sounds like reverse causation ?
323974,"i see what you're getting at , but could you define your use of the work "" equivalent "" here ?"
324126,hint : when $ k = 1 $ and $ k = 2 $ what is $ ( k-1 ) ( k-2 ) $ ?
324129,can you give an example of your data set ?
324696,"could you clarify what you mean by a "" derivation "" ?"
325254,"by a "" column of bias "" do you mean you also estimated an intercept ?"
325280,stepwise multivariate regression ( analysis ) ?
325362,do you know of another gbm implementation that does this ?
325537,could you be more precise ?
325669,why not analyse each animal separately and then use meta-analysis to pool the effects ?
325777,"can you define what you mean by "" population "" ?"
325876,"url is clear about the definitions . as a hint , suppose $ x $ is any random variable and let $ mathcal x = ( ldots , x , x , x , ldots ) $ be a time series . ( thus , in any realization of this time series all values will be equal at all times . ) is this stationary ?"
325888,"no , why would it be ?"
325938,"these variables have no explicit connection , so what do you mean by "" correlation "" or "" association "" ?"
326030,could you clarify your question a bit ?
326087,where did you read that ?
326465,if this is self-study then perhaps add that tag and read its wiki ?
326503,"i understand that your "" treatment variable "" or explanatory variable is continuous , but what about your response variable ?"
326478,"it's not . in your block of three equations , look at line 2 carefully and compare it to your question . write out what $ a $ is and what $ b $ is . is $ ab / c $ really what's in line 2 ?"
326527,"in statistics , "" significant "" has meaning only with respect to testing a particular hypothesis . you seem to be using "" significant "" in a different sense , but what would that be ?"
326916,how are you proposing to evaluate reliability either in one or two groups ?
327097,what are f and g ?
327174,"what do you mean by "" visualizing the structure of the neural network given an output "" ?"
327219,are you asking for the sampling distribution of the mean of a binomial ?
327227,why would you expect the results to be different ?
327489,""" two or more cities with 10 sampled population each "" - what would that mean ?"
327528,"no ; that makes no sense within a chi-square test , although testing could make sense in other frameworks e . g . a model for the counts . . you might as well say : if there is a significant difference between frogs and toads , is it the frogs or the toads who are significantly different ?"
327895,"i wonder whether this might be a better fit at health se , if it asking for the biomedical implications ?"
328159,this sounds like a ` self-study ` question . can you explain where you have problem with using adam's law ?
328360,"are you trying to find one mdc ( e . g . mdc between measurement 1 and 7 ) or 6 mdcs ( mdc for 1 to 2 , 2 to 3 etc . ) ?"
328440,"perhaps you could expand on this question a little , and tell us what you understand and don't understand ?"
328477,did you add dropout ?
328547,when i do this 'iterated modelling' and i want to include the first prediction as a feature for the second one then i always end up not doing it because i simply wonder : what value should i put for the first prediction in the training set ?
328451,"i disagree with the closure of this question as a duplicate of "" how is the minimum of a set of random variables distributed ?"
328614,what is meant by $ omega sim $ spherical gaussian ?
328618,sounds like a good application of log-linear models . have you done regression ?
328664,are you able to print the output ?
328893,what do $ a $ and $ n $ represent ?
329411,looks like the problem arises with the first argument you pass to the interp function . is this the output you are looking for ?
329414,what is the ultimate goal ?
329462,perhaps 1 . 48 times as likely to be in a higher category ?
329609,what exactly do you mean by ` identifing danger zones in that city ` ?
329863,have you checked other questions tagged as [ tag : missing-data ] ?
330010,"did the above references answer your question , or are you still looking for an answer ?"
329821,is by any chance your dataset biased towards the ` 0 ` class ?
329914,"although i have closed this as a duplicate , i don't like the answer to the duplicate . it won't work correctly in many cases . the essence of the problem is revealed by considering extreme cases : they show how difficult it can be to combine medians into some overall estimator . but if you could be more specific about your situation , then we could focus on answers that might work specifically for you . e . g . , are these random samples ?"
330052,"inverting the corresponding characteristic function indicates the original is a "" generalized distribution "" rather than a legitimate probability distribution . how did you obtain this mgf ?"
330117,what is $ f $ . . . ?
330185,i'm not sure i understand your question . you've written the underlying closed-form equation and an implementation to produce the above plot . is there a more specific part that you don't understand ?
330337,what are you complaining about dilip sarwate ?
330360,"the wilcoxon signed rank test might be used for comparing two algorithms over many data sets $ ^ * $ , rather than many algorithms over two data sets . . . $ * $ ( at least , under certain assumptions about how the data sets relate to the notional population of sets that you wish to perform inference over . are there such assumptions that would make sense though ?"
330371,are you testing on these synthetic values ?
330507,what do you mean by * my implementation was not scaled in relation to the inputs * ?
330791,"there are two possible interpretations of your question : a ) if you would get another data point $ x $ from the same process , what is the probability that $ x geq 2 $ or b ) given the observed data , what is the probability that the mean value of all the data points is $ geq 2 $ - could you clarify which is correct ?"
330911,"could you explain what is "" weird "" looking about the plots ?"
331019,"please add the self-study tag . also , what is $ t $ ?"
331037,""" a = x , a = y , b = x , b = y "" i don't understand what you mean by this . are you referring to the cell frequencies generated under independence ?"
331076,"this was marked as off topic - but it seems to be exactly on topic , to me . why is it thought to be off topic ?"
331380,is this a question about r programming ?
331405,you seem to postulate an illogical model . share of expenditure depends on number of votes cast in favour of a specific candidate ?
332182,why would you want to run pca many times ?
332228,why are the metrics not satisfactory ?
332315,"you don't need to elaborate on your research , but you will need to pose your problem a bit more clearly . you say that $ y $ is normally distributed "" with respect to $ x $ "" . what do you mean exactly ?"
332436,do you mean that you see the same photo on * both * day 1 and day 2 ?
332486,performing a chi-squared test and determining a distribution are different activities . which do you need to do ?
332492,do those two statements appear near each other ?
332511,the gmms for a and f are bad and should be retrained ?
333090,"please make the question clear , what do you mean by "" multicollinearity may leads to small effects of some variables "" ?"
333152,do you scale the variances against the acceptance rates ?
134701,""" how can * a * random variable converge to * a * single number but * also * converge to * a * distribution ?"
333644,is cross-validation involved in any way ?
333690,why restrict the number of pairs of participants ?
333686,how were these values obtained ?
333943,do the variables follow a multivariate gaussian distribution ?
333952,what is the question literally ?
335074,would you please post a link to the data ?
335124,"what do you mean by "" $ x ( n ) = n $ and $ x ( n ) = 1 $ ?"
335410,the size of $ lambda $ should not be your concern . it is required that you scale your variables before penalizing to get correct results . second is the size of $ y $ comparable to the mse ?
335885,did you try any traditional time series forecasting methods ?
336150,did you lookup syllabi of similar courses in peer universities ?
336327,"when you refer to the "" censor distribution "" are you referring to censoring without failure ?"
336795,the question needs a bit more detail to understand your situation . did one type of video have several pauses and the other only one ?
336857,maybe add self-study tag ?
337069,what does $ x_j $ mean ?
337215,did you look at the vignette in the ` forecast ` package ?
337352,are you trying to compare population means in particular or is the hypothesis more general ?
337452,"why not use the standard , well-known , exceptionally widely used technique of [ tag : multiple-regression ] ?"
337521,"seems to me that in that scenario there is no sensible hypothesis that would say that the difference between male and female heights should be unaffected by age , so why do a test ?"
337549,"use of a running mean indicates that the sequencing of the variables have meaning , maybe time ?"
337591,you want to use 8 latent factors and 3 demographic variables as predictors in a regression . what exactly are you asking--for suggestions about narrowing down that set of predictors ?
337942,could you give us more details on what exactly are you doing ?
338086,do you have an even number of observations in the data ?
338179,how does a 1 hour change affect your data ?
338188,isn't the fisher information the [ expectation ] ( url ) of the logarithmic derivative of the density ?
338422,have you looked at ` stan_glmer ` . . . ?
338570,show the output if possible . how many studies ?
338658,"your question of "" what is a gradient "" is really broad . have you tried reading any tutorials or articles about it , such as [ this one ] ( url ) by khan academy ?"
338583,what is ks ?
338870,"normally the notation "" $ mathbb { e } _ theta $ "" means that $ theta $ is a random variable and you are taking expectation with respect to it . that doesn't appear to be the case here , but that makes your question ambiguous : just what are you taking the expectation with respect to ?"
338996,i guess if it is a sizable effect then it is worth reporting- i just wouldn't overstate it . but the question that comes to mind is why it not-significant . did you have enough power to detect an effect ?
339016,"a "" value between 0 and 1 "" tells us nothing whatsoever , because you are free to choose any unit of measurement you want . thus , your question comes down to "" i did a simulation to estimate an undefined quantity and my simulation gave me a finite number . why would that be ?"
339197,where does the 4 come from ?
339242,it's not clear what's the problem here . did you try to search the terms in internet ?
339464,are you creating matched pairs ?
339544,cross correlation ?
339647,how did you come to get two different p-values for one test ?
339681,why do you believe this to be true ?
339779,can you elaborate whether you are interested in a bayesian or frequentist example ?
339785,"what kind of statistical analysis are you planning on doing after "" normalizing "" the data ?"
339868,"are you referring to "" simple structure "" ?"
339870,"it sounds to me that you're talking about two versions of transfer learning . in one case , you keep the same architecture and freeze the weights at some depth -- could be at "" layer 0 "" so that you're adjusting all weights or could be deeper so you're not adjusting earlier weights . in the other case , you're chopping out entire layers and making new ones -- which might boil down to randomizing the weights of the transferred net . is this correct ?"
340903,"i highly welcome questions about exchangeability . but could you please provide a clear and simple practical example . it could look something like : exam a on matter b in school c sees 90 / 100 students pass , etc . what exactly are you after ?"
340973,are you talking about determining all the 1-dimensional marginals ?
341050,"what do you mean by "" accurate "" here ?"
341259,are the data paired at all ?
341268,what do the loss curves look like ?
341297,what is your question ?
341614,"it might be more revealing to invert your question : could you tell us why we should expect the probability of any particular number of successes to be so * high * , given that there are almost 70 million trials and therefore even more possibilities for the number of successes ?"
341706,why is the missing feature missing ?
341823,"well , it's math , based on calculating the expectation of $ x ^ 4 $ . are you asking for the derivation ?"
341868,"are you asking how dpg selects an action after you have trained it , or while training it ?"
341929,bootstrapping ?
342221,how many measures do you have in each group ?
342265,why do you need to choose n / 10 ?
342477,"could you please explain what "" se covariance "" is ?"
342489,"both statements are mathematically incorrect and evidently ambiguous . either one could be interpreted as meaning $ x = ( 100 44 . 6 ) / 100 times y . $ why don't you simply state the truth , such as "" $ x-y $ is $ 33 . 1 % $ "" ?"
342510,see here : url ?
342193,what effects size are you using ?
342856,"what do you mean by "" formative "" and "" reflective "" ?"
342989,""" log difference "" ?"
343077,isn't $ sigma $ $ ^ 2 $ = var ( $ s_n $ ) ?
343157,"how correlated are your 20 , 000 features ?"
343226,"your question is interesting , as repeated measures studies are generally more powered than non-repeated measures . for what specific parameter are you concerned about not being able to detect a difference ?"
343404,maybe we come from an intuitive point before goint into mathematics : a better fit reduces mean squared error ! is that clear or not yet ?
343417,"please clarify what you mean by "" regularize the data "" ?"
343513,why is time being treated as a dummy variable instead of a scalar ?
343540,"look carefully , is the first version a vector notation ?"
343606,"to "" deal with being a bayesian , "" have you considered joining a bayesian support group ?"
343808,why would you need this in layman terms ?
343825,what is $ n $ ?
343835,"as long as the cnn's had the same structure , one would be talking about the weights . it would make mathematical sense to average the weights . however , if i took two pictures of different people , would i expect superimposition to give a picture of a third person ?"
344022,this is in danger of being closed as you seem to be asking for code help although i think you have a statistical question here . are the zeroes all genuine zeroes or are they just below the threshold of your measuring device ?
344066,"are you interested in the example you state , or in a general formula ?"
344087,why do you want to normalize these data ?
344089,can you post a link with the pdf version of the paper ?
344221,important for what ?
344278,could you add more context on what your images are and what you're trying to detect ?
344362,itt is intention-to-treat ?
344525,what units would you like your answer to be in ?
344675,"for any penalty parameter , lasso will estimate $ m le m $ nonzero coefficients . are you asking about how the optimization works ?"
344768,the predictors should be correlated with the outcome ?
344996,possible duplicate of [ how can unsupervised learning be performed by connectionist ( neural network ) algorithms ?
344019,what do you think about my answer ?
344860,what do you mean by gmm ?
345247,what do you mean with correction on over-dispersion ?
345311,is your question about cluster analysis or about modeling in clustered / nested populations ?
345342,"do you mean in the example you give , or in general ?"
345427,hint : do you know any results for exponential families that make it easy to identify complete statistics ?
345508,what is the purpose of these scores ?
345624,do you mean you would like a ci for the coefficient of x1 in the regression model ?
345656,you're maybe the only one in the world still using fully connected nns for mnist . any specific reason why you did that ?
346155,"what do you mean by "" knowing p ( z ) "" ?"
346184,"can you pleas check this thread on "" [ what is baseline in precision recall curve ] ( url ) "" ?"
346233,what link function are you using for your poisson regression ?
346238,why are you shrinking variables involved in colinearity ?
346251,by beta do you mean the regression coefficients that is used for prediction ?
346039,"could you provide definitions of the various variables , different sources use different notation so it is important to provide rigorous and unambiguous definition to ensure that readers don't confuse concepts and to ensure their answers use the notation in the same way for optimal clarity . what do you mean by m = p for example ?"
346259,what's the p value for your auroc ?
346362,"i don't know what defn you are using , but it's really unusual for a to be invertible because a is nxp and unless n = p , an inverse can't exist ( should it be pxp , nxn or what ?"
346474,"well that's going to depend on what $ f $ * is * , isn't it ?"
346529,hi svendvn are you looking for a software package to do this or are you asking for an explanation on how the sequence simulation is carried out ?
346566,does this help you out ?
346852,"well , if there is * * exactly * * one observation per student , how do you discern between the student term and the error term ?"
346886,can you tell us more about your 4 responses ?
347178,"if you only worry about which test you should have used * after * you failed to reject , you're significance hunting ( if you rejected with the anova would you have asked about using the wrong test ?"
347460,what is then your software ?
347675,why not use the rsq ( ) and rsq . partial ( ) functions in the rsq package for this computation ?
347677,do you mean to ask if the alpha threshold ( for determining if p is significant ) should be updated ?
347681,how exactly would you do the pairing ?
348026,"the way you have written your first sentence , it appears that the entries of $ l $ are independent . is this the case ?"
348027,what makes you think it doesn't hold in all cases for which $ x $ depends only on $ theta $ ?
348064,what is the n for the least frequent class ?
348138,"this is a panel . but could you please elaborate on "" * i want to study each id as a whole * "" . what does that mean ?"
348196,is your question related to the concept of how to adjust for confounders or programming challenges ?
348224,who is complaining about the hessian ?
348238,what code did you use for the hosmer-lemeshow test ?
348285,"since applying a definition of a copula provides a ready answer to this question , could you tell us what you understand a "" copula "" to be ?"
348389,does e ( theta ) in 2 . refer to the prior mean ?
348398,"many methods assume relatively balanced number of instances per class . sampling like that is often called stratified . apart from that , i don't see why not random sample ?"
348412,this is how in principle google and any other service offering recommendations or personalized content should work . but i'm not sure how your question is related to statistics or ml ?
348492,"what does "" * better result * "" mean ?"
348498,"if you correct for multiple testing , is that not precisely what you have done ?"
348557,"what does it mean exactly , that you're "" running k-means on a weighted adjacency matrix "" ?"
348655,"your times given in the question are not intervals . there are several ways to express them as intervals though , which may make it more clear as to the type of data , and thus the most correct statistical method , to apply to the data . . . and what you you mean by "" and each one separated from its neighbour by the same meaningful interval . "" ?"
348717,if your outcome is a count is there any reason why you are avoiding poisson regression ?
348698,what are your two groups and how do they each have 1500 groups ?
348870,"perhaps you could word this a little better . are you asking $ p ( a = a , b = b subp = i ) $ for some $ i $ ?"
348864,which test of ovb did you use ?
348932,"what do you mean by "" standard coefficient "" ?"
349307,it's not clear what problem you're trying to solve . can you edit your question to say in more detail what you're trying to do ?
349409,"you need to tell them what to expect , right ?"
349487,why are you using a gamma distribution for a prior ?
349515,what's your problem ?
3564,could you tell us a little more about your problem ?
3999,"as a hypothetical example , suppose the categories are named "" a "" through "" e "" . could an object simultaneously have values of 10 for a . low , 20 for b . high , 50 for b . medium , 15 for b . low , and 5 for c . high ( and zeros in all other subcategories ) ?"
4337,"how many cinemas are there , roughly ?"
6444,any particular reason you chose 1 and n as the two variables ?
7054,what is the aim of the analysis ?
7952,what is the coloured table ?
9067,"in sas or r you need a few lines of code to remove empty columns , but how come it did not work in excel ?"
9810,do you want a global test for the three groups with the null hypothesis that the three medians are equal ?
2419,i agree with mbq . is there a very good reason why you have to do that in python ?
10320,"strangely enough , for imus , sometimes noise can * improve * your measurements and inferences ! ( * * think * * : dithering . ) can you give more details on the types of signals you're trying to measure , e . g . , sampling rate , frequencies of interest , etc . ?"
10464,can the reason that the 10 % are binned be ascribed to a random process or is there some underlying factor influencing the binning ?
10631,did you not answer your own question ?
10640,is your response binary as well ?
13981,is there any reason why some observations are dots and other crosses ?
14194,are you willing to assume that the historical data form a set of identically distributed and perhaps even independent curves ?
16042,i think this question is too vague and broad for anyone to supply useful advice . what is the structure of your data ?
16778,"precisely how do these matrices "" represent a distribution "" ?"
20619,"it sounds to me that what you have are the * steps * of a process that you want to test whether it is a * time-homogeneous * simple random walk ( possibly asymmetric ) . so , can the problem be reasonably codified as follows ?"
21742,"any metric will almost invariably depend on the final "" product "" one is interested in . what are your end goals ?"
23092,what rules do you know that might enable you to compute the expectation and variance of a sum of random variables or a constant multiple of a random variable ?
23194,what does it mean for parameters to be * uncorrelated * ?
23781,can you be a bit clearer ?
24259,"cost benefit analysis is not a trivial exercise , normally valuing the costs is not that easy , and the valuing of the benefits is extremely hard . also , a discount rate is used for out-year costs and benefits , although costs tend to be front-loaded . do you have any economists you can talk to ?"
24716,"out of curiosity , what is the statistical application ?"
24829,i gather from [ the wikipedia article for atwood's machine ] ( url ) that * a * is acceleration . how did you measure * a * ?
24900,"negative binomial models are often suggested for count data , when the data doesn't look poisson . but if you just want to do regression without specifying a particular mean-variance relationship , and have at least a moderate sample size , apply robust standard errors to e . g . poisson regression output . also , is this a homework question ?"
25200,how * would * you 'make up' a sample of data whose true mean you knew ?
26047,people actually use 5-grams ?
26252,do you have a 'ground truth' / answer key / etc ?
26465,"migrating d . w . comment from the duplicate : why do you believe the same dataset will be separated with $ k_1 ( x , y ) k_2 ( x , y ) $ ?"
26387,are you saying you'd delete all observations who responded with the the removed choices ?
26876,have you ever heard of finite mixture modeling ?
27315,could you please clarify : are there three or four variables ?
27418,"i posted an answer related to the informal ( underground ) economy . "" black market "" can be used to describe such an economy , or it can imply that the market is for trade which , if reported , would be illegal ( as opposed to trade which is only illegal because it is not reported / taxed ) . could you clarify which definition you intended ?"
27482,could you give some references ?
29264,"in both cases i think a good starting point is thinking through explicitly what your null hypothesis from the chi square test is , and how you would describe and interpret that null hypothesis . does it make sense ?"
29512,"are you sure you are using "" vertical "" correctly in every instance ?"
29615,"does your third point mean "" must not be gpl "" or does it mean "" need not to be gpl "" ?"
16758,( 1 ) are you sure there are not some qualifications that have gone unstated in your question ?
29873,are you doing capture -recapture ?
31024,"to help you clarify your thinking , please consider this : why do you consider $ e $ to be "" random "" ?"
31068,"it would be helpful if you could also say something about your goals for the model & subsequent simulations . eg , are you hoping to predict future use , or understand the conditions under which customers are more likely to use credit cards vs . cash ( etc ) ?"
31379,what sort of difference are you looking for ?
31630,are you familiar with the [ elo system ] ( url ) ?
31900,why did you merge categories ?
32139,"can you provide some more information about your situation , data , and these classifiers ?"
32662,what do you mean by $ p ( x ) $ and $ p ( y ) $ ?
32905,i'm not familiar with this package but this appears to be saying that there are too many ties in terms of which neighbor is nearest . this can happen when you have a very discrete variable ( i . e . it only takes on a few unique values ) you're trying to cluster on - is that the case here ?
33124,"this is terrible advice in general because at most locations air quality changes dramatically throughout the day . so , although you could compare the cdfs , the comparison would likely be meaningless or woefully misleading . special circumstances could rescue you , though , depending on how these sample times were chosen and how they compare between the two datasets . perhaps you could tell us more about that ?"
33449,would you mind posting a few references to some of the economics papers that you have in mind ?
33931,"if the five other homes are similar in size , lot , location , # of bedrooms , do you need a regression ?"
34552,it would help if we could have more context . could you provide an excerpt from the paper ?
34690,"as i understand that , the volatility of the process is not a stationary process itself . even the mean is not equal to zero . so applying arma for volatility is not correct . or maybe i misunderstood you ?"
35153,"why not rank the phones , and score accordingly ?"
35409,can you explain _why_ you expected that result ?
35438,what are you looking for ?
35564,so basically what you're saying is that your svm classifier is classifying all testing data-set as 0 . is your data-set balanced ( # of 1s is approximately equals to # of 0s ) ?
35891,your terminology is somewhat foreign to me . does this have something to do with probability and / or statistics ?
35954,this question is on-topic both here and math . se . it may receive slightly more attention on the math site . is $ mathcal s $ countable ?
37430,"what do you call "" output of a model "" ?"
37555,how do you intend to interpret the results ?
38086,i'm not sure to understand . is it the conditional distribution of the squared norm of the $ x_i $ 's conditional to the constraints ?
38245,can you provide a citation for the statement you read about spss's degrees of freedom being based on the listwise n ?
38262,how do you define best ?
38741,how do you calculate the p-values ?
38932,are you sure you care about the mean ?
38983,what is u in this context ?
40505,what criterion are you using ?
40554,"are you interested in the correlation between each variables / items or a composite score ( e . g . , sum or mean score ) derived from them ?"
43459,i don't get how the two different samples - treatment and control - work . is in fact your question of interest whether the treatment has an impact on learning effect ?
43913,"i think if anyone is to answer this , they're going to need a lot more information about the data . are you trying to determine the distribution of a data set from the raw data ?"
44226,can you tell more in the question about ` adversarial noise ` ?
45664,"another thought here , separate from shrinkage issues with stepwise regression as per frankharrell's answer -- how would you deal with things if your 10 imputed datasets return more than one "" solution "" in terms of the predictor set selected ?"
46223,can you add a screenshot or cut and past the results ?
48089,"for two vectors to be orthogonal you require their inner product x , y to be zero . is that what you want ?"
48160,"okay , i've thought about it some more , and i know how to make the argument for products over mixtures when the distributions being added or multiplied together are discrete , but i'm not sure how to apply it to the continuous case hinton is talking about in the paper you referenced . would you still like for me to give it a shot ?"
48546,"when you say that we only have estimates of x ( etc ) , are you talking about having finite samples to estimate the population parameter ( the standard statistical topic ) , or that your observations come w / measurement error , or something else ?"
48804,""" performs the best "" in what sense ?"
50116,what do you mean by 'all possible cases' ?
50597,why would you not put more weight on the means that are more certain ?
50831,"hi and welcome to the site . your question is fine etiquette wise , but as a general comment more specific questions are likely to get better answers . for example , you ask for downsides in general - do you have any specific concerns about the method ?"
50848,"there is a simple relationship for certain kinds of nonlinear models : they are the ones fit using ordinary least squares . with other fitting methods , such as maximum likelihood , if there is a relationship it usually is only an approximate asymptotic one . what exactly is your model ?"
41324,what's wrong with making a svm regression predicting position of the cutting point ?
51779,"this need more detail . what sort of distribution is it ( for instance , what does a histogram look like ) ?"
52235,are you asking how to compute the likelihood or are you asking whether it's sensible to select the bucket with the highest likelihood ?
52736,what do you do about data that is well below the average ?
53231,"( 1 ) "" significant "" says relatively little about * amount * of the effect . especially if your data are numerous , anova can declare utterly trivial amounts of collinearity to be "" significant . "" ( 2 ) why would you remove all continuous variables ?"
54655,are you saying there are 365 people and 804 variants ?
54908,what sort of statistical software do you or can you use ?
56645,how much data have you got ?
57937,what is $ s $ ?
58334,jensen inequality ?
59375,would levene's test and an independent groups t-test do what you want ?
60754,what steps have you taken towards the solution of this exercise ?
61456,"you can probably look at this problem differently ( as a regression problem , possibly with a multilevel model ) . what are you trying to find out ?"
62182,we could probably use more information ( how many items ?
63607,"do you think ( conditional on the trend ) the outcomes would be independent , or could there be time-dependence as well ?"
63689,possible duplicate of [ why is the bonferroni procedure applicable only when the effects to be investigated are identified in advance of the study ?
63830,"what kind of "" measurement errors "" ?"
64199,"i think you meant to say that the 'discrimination' parameter is analogous to the uniqueness parameter in fa , not the difficulty . also , if irt ( more specifically , the 2pl model ) is the categorical analogue for a single factor fa since logit ( p ) = a b * theta , then wouldn't mirt be the categorical analogue to exploratory and confirmatory fa since the logit transformation is still the same ; logit ( p ) = a b1 * theta1 b2 * theta2 ?"
66886,how do you work out the sampling distribution of a mean without knowing what the distribution of a sum is first ?
67258,"is it clear to you that 'pbinom ( n , 100 , prob ) ' returns $ pr [ x leq n ] $ with $ x sim text { bin } ( 100 , text { prob } ) $ ?"
67537,why aren't you just testing b vs . c ?
67704,"glen_b , why not make that an 'official' answer ?"
67907,"the answer is a qualified yes , but the exact procedure depends on how the initial segment of data is treated . if it is simply dropped , then you have effectively lost 15 pieces of data , leaving you with an undeterdetermined system of linear equations . the upshot is that there exist many valid answers in general , but you can still make some progress if either ( a ) shorter windows ( or some such procedure ) are used for the initial 15 moving averages or ( b ) you can specify additional constraints on the solution ( about 15 dimensions' worth of constraints . . . ) . what situation are you in ?"
69585,could you give us your definition of what is a degenerate random variable ?
70682,have you considered doing a simple regression on the problem ?
70712,have you thought about using the simple [ scipy . stats . curve_fit ] ( url ) method directly on your two polynormial model ?
71699,is the data quite biased ?
71588,"how about a uniform distribution over the interval [ 0 , 1 ] ?"
71770,"whuber - it seems to me that he's asking what that limit has to do with the expectation of the pareto when $ beta = 1 $ . i agree it's a little unclear , but . . . to the op : if what i've written is correct , it would improve your question considerably if you put an explicit statement to that effect in place of the "" . . . clarify my doubt ?"
72495,what's the treatment ?
72635,"two-way comparisons with paired samples are not restricted to matching . siblings , twins , pre / post measurement , or responses to a question asked to both wife and husband might all be tested using , e . g . , a t-test for paired samples . could you clarify what your situation actually look like ?"
73259,"regarding your link : note that there is a big difference between being * positively * correlated and * perfectly * correlated ! regarding identical betas , you might think about two simple cases : what if $ beta = 1 $ and what if $ beta = 0 $ ?"
74122,are these random variables discrete ?
74400,"that simulation shouldn't be slow unless either your initial generation of the geometric is unusually slow , or your adding of $ s $ is unusually slow . which is slow , . . . and if possible , * why * is it slow ?"
74705,what would make a name 'official' ?
74887,you may want to take a look at the [ elastic net ] ( url ) method ( see also this [ detailed handout ] ( url ) or tibshirani and coll [ jss paper ] ( url ) for one implementation in r ) . there's also [ when to use regularization methods for regression ?
74937,"by "" relevant tweets "" do you mean the tweets of that length that were spam ?"
76814,is cdiscrambling actually a continuous variable that you've made categorical ?
76946,how do you plan to set one d for all main effects and contrasts simultaneously ?
60011,it seems to me this question has been answered at url is there more that you need ?
77040,"this is more than possible ; if you construct a hierarchical model , this is common practice . are you able to share more information about the problem you are trying to solve ?"
77330,why does it have to be a single model ?
77871,is the confindence interval around the ols-estimate wide ?
80790,"how can a two parameter model on training data yield worse fit than a single parameter , unless it is corrupt ?"
18276,should this be cw ?
81162,what do you mean when you say that people are invited to use the program every 2 years ?
80914,have you tried to change your initial values when applying ` optim ` ?
81102,what do you mean by 'significantly' ?
81618,"laplace's law of succession is derived as a bayes estimator to the success probability , p , in the binomial distribution using a uniform prior on ( 0 , 1 ) . why do you want to use the law of succession ?"
52897,"i'm not familiar with tost , but are you looking for mann-whitney ?"
86239,what does the sd there measure ?
86391,"25 observations over 18 years is closer to 1 per year than it is to 2 per year - it's below 1 . 4 . there are methods for dealing with data at irregular time points , though having so many categories and some being so rare suggests you'll need some strong assumptions and external knowledge about things like period . what are you trying to find out from the data ?"
86589,"i think i'm missing something , because it looks like you are giving two different ways of constructing the series $ x_k $ ( and they lead to different results ) : the method before the "" and "" and the method after it . you cannot do both at the same time ! which one do you want to implement ?"
86898,are you able to measure or find the actual sunrise / sunset times with some degree of accuracy after they have occurred to test the predictions against some known / true values ?
86678,"$ s $ is indeed the variance-covariance matrix of the outcomes . however , what makes you think it is diagonal ?"
87145,"what in statistical theory gave you the idea that insignificant variables are harmful to a model , or that variable selection isn't anything more than a mirage ?"
87441,"by divergence , do you mean difference in performance ?"
88230,"shouldn't $ alpha_i $ be a single , known and fixed probability between 0 and 1 ( like 0 . 5 if you are modelling the median ) ?"
89227,please search for the * extensive * discussions about this on the site . why do you want nonparametric to not be the * first * option ?
89236,"the data are * not * normal : apart from the ages , they are * binomial * ( which is about as non-normal as one can get ) . any reasonable measure of binary results will be equivalent to the mean , so you don't really have any choice in that matter . what exactly do you mean by "" controls "" ?"
89271,"right now , i can't understand what your question is . what are the elements ?"
89151,what is the shape of the objects ?
89796,"if you generate correlated random variables with each having mean zero , then add a constant to each individual variable , what is the outcome ?"
89762,"would your dv then be one variable with 6 categorical levels , or six variables each continuous ?"
90628,"are you sure those are sd and not 95 % confidence intervals which might be more like 3 * sd . it looks like those sd are about the same size as the means . it's really hard to say what the sample size is as we don't know what effects were included in those errors or even what the statistic is . if it were just counting statistics , i . e . the poisson distribution , included the mean over the sd should be like 1 / sqrt ( n ) . however that would imply n = 1 ( or a few at most ) . can you give us more information about what these statistics are ?"
87272,what kind of data are you working with ?
90998,"instead of using fancy methods , have you tried just computing the _numerical_ values of the success rates of the four cases , that is , $ 9 / ( 9 4 ) , 8 / ( 8 4 ) , 4 / ( 4 3 ) , 12 / ( 12 7 ) $ to see if anything is glaringly obvious ?"
91078,"$ f ( x ) = x $ won't work if your data are $ mathcal u ( 0 , 1 ) $ . are your data uniform on ( -1 , 1 ) ?"
91386,this question appears to be off-topic because it is about data analysis methods -- migrate to crossvalidated ?
91479,"you should use the more modern implementations , in the robustbase package . that one will return a more complete output . for the two other questions , what do you mean by "" problem of non-normality of the dependent or independent variables "" ?"
92035,"it's hard to tell from the graphs , but are there a whole lot of 0s ?"
92409,"it depends on how the data for each $ r $ calculation are related . if they are not independent , then you need to account for that . more fundamentally , given that you have carried out regression calculations , why are you focusing on $ r $ ?"
92876,"one batch would be less than $ 10 ^ 5 $ values . a year's worth ( 25 batches ) would still be only a few million values , requiring perhaps 10 mb uncompressed storage . is there some kind of restriction on your storage or computing systems that precludes storing this many numbers at once ?"
94002,the ivs aren't assumed to be normal in regression . did they have any better reason than that ?
95682,"( 1 ) is "" 95 % / - 5 % "" just a way of saying "" at least 90 % "" ?"
96541,can you give more details about the null hypothesis ?
310670,"hope you formulate your question more carefully . for example , why standard error , instead of standard deviation ( or variance ) is asked ?"
311249,openseason without changing the results of the recurrence analysis ?
313090,"averaging might work for certain circumstances where the model is an excellent fit and sample sizes are large . but , since it's not hard to think of other circumstances where averaging would be a particularly poor procedure , why not just fit a single model to all the data ?"
320602,is this for homework ?
328430,what kind of epidemiological studies are you referring to ?
331688,your setup is weird . so you can't wait a few weeks to collect more data ?
204526,what is ftrl here ?
334002,"what is "" ssr "" ?"
333991,the variable you mean here is the number of observation or the dimension of the data ?
339895,why would you do this ?
344921,"negative binomial is unbounded at the high end , but maybe a zero-inflated binomial ?"
4396,i'm pretty confused by what you are asking to do . can you describe the format of your data and why using if statements won't accomplish what you are trying to do ?
5690,"could you pls give some indication about sample sizes , time frame , % survival , etc . so that we get a better idea of the design of your study ?"
11955,what format are your documents ?
13171,is $ mathbb { n } $ suppose to denote the standard normal distribution ?
16788,could you please provide a reference that indicates sa has actually been used for this purpose ?
18033,do you have several prices for a given date ?
18166,why do you think these beta values are not acceptable ?
18512,you say that there are two populations . are these two pre-existing populations from which you've drawn random samples or are these two hypothetical populations to which you've applied some treatment through random sampling ?
20035,what is your development environment ?
21548,"yes , the forecasts and errors are not independent , but it would be good to know why do you think this is important ?"
22346,specifically mer or you are asking for any linear model coefficients ?
22441,hi florian . why not use a permutation test on the difference between the chi squares ?
23142,where have you read about that ?
25926,how do you get ties if $ k $ is odd ?
26301,"for two-class lda , wouldn't y be just a scalar ( or , if you will , a one-dimensional vector ) ?"
27721,"just to clarify , are you talking about one-way anova or factorial anova ?"
29408,is this homework ?
30565,how large is your sample ?
31702,"do you want to take sampling schemes into account , or do you just want to understand the basic idea of a confidence interval for a binomial distribution ?"
32247,do you know the reorder points of the goods at the warehouse ?
32813,"i barely see any difference between categorical and qualitative variable , except one of terminology . anyway , that would be very difficult to compute anything like mean or sd on a nominal variable ( e . g . , hair color ) . maybe you are thinking of categorical variables with ordered levels ?"
32916,"this question in its current form appears to be unanswerable . could you tell us * what * detection algorithm is proposed and--more importantly--exactly what your challenger might mean by "" just doing some statistics "" ?"
37702,what makes the models different ?
43050,"could you tell us anything about the likely values of $ a $ , $ b $ , $ c $ , and $ x $ ?"
43324,i believe there are many forms of matrix factorization . what one do you mean ?
48086,"isn't this question simply "" what do these two papers say ?"
48366,"if you're looking for some black-box function to do this for you , please let us know so we can migrate your question to so . otherwise , if you're looking for a formula you can implement , this is the right place to post your question . could you clarify ?"
49889,"welcome to the site , kurt . i tried to edit your q for greater clarity . please make sure it's still asking what you want to know . in addition , i couldn't make sense of your 2nd paragraph ; did you mean "" if x is not * linearly independent * , what would the rank of x'x be "" ?"
55583,"what is this , a survey ?"
55602,"presumably $ x_n $ and $ x_n $ are sequences of random variables and you mean the * non * convergence of the harmonic series . but it needn't be that complicated . for instance , consider a discrete distribution $ f_n $ with $ pr_ { f_n } ( 0 ) = 1-1 / n $ and $ pr_ { f_n } ( n ^ 2 ) = 1 / n $ . if $ x_n sim f_n $ are iid , does $ x_n $ converge to $ 0 $ in the sense you intend ?"
60998,can you tell us a little about the data ?
61978,what on earth is $ n $ indexing here ?
62350,"what does "" at least a face is b "" mean ?"
62944,"can you provide some more information about your data . how many points might there be for "" a "" , "" b "" , etc ?"
64454,the answer depends on the distribution into these categories on the population . are they equiprobable ?
67311,"danielle , do you know what type of statistical test you are hoping to run with this sample ?"
67879,why the robust tag ?
68394,this sounds like straight coursework . can you explain the context in which it arises please ?
69336,it is rather striking that $ y_t = x_t - x_ { t-1 } $ = $ 1 / 2 ( x_ { t-1 } -x_ { t-2 } ) w_t $ = $ ( 1 / 2 ) y_ { t-1 } w_t $ . does that help ?
69472,what is your outcome of interest ?
70113,"the key point here is about "" similarity "" . do you have any ideas about what sort of similarity you want ?"
70377,is this a homework problem ?
70509,not sure what your question is . why not just look at the coefficient of the variable of interest ?
73309,"while you headed and tagged this question as related to propensity scores , your two questions look at odd to me : binary classifiers are one thing , the use of [ tag : propensity-scores ] with binary outcome is another topic . are you asking whether logistic regression is better than , say , neural networks in deriving pss ?"
73891,"please make more concrete the expression "" increases with dispersion "" : increases as variance increases ?"
74840,"please explain what you are trying to do . do you mean using windowing with spectral estimation , or with kernel smoothing , or something else ?"
76961,how do you define $ xy $ in $ var ( xy ) $ ?
78331,( 1 ) there is something wrong with your formula . what $ a_i $ might be and why both expressions end up at $ p $ ?
78466,have you first [ searched our site ] ( url ) for answers to this question ?
80022,how do the columns sum to 100 ?
81857,"calling $ y $ a "" mean "" may confuse many readers , because "" mean "" has a standard definition . it appears you are seeking a kind of * average * $ y $ , depending on the $ ( x_i ) $ , that minimizes the median of the $ ( x_i-y ) ^ 2 $ . ( note that $ y $ is unlikely to be unique . ) moreover , you do not seem to be * estimating * anything about a population or process that the data may represent : you want to * compute * $ y $ . are these interpretations correct ?"
86140,this phrase is understandable as soon as you apply definitions of conditional distributions and quantiles : would you like help with one of these in particular ?
86409,any ideas you've thought of ?
88383,"you could formulate it as either . should the input [ 34 , 23 , 34 ] always return 34 ?"
90412,"it may impact the kinds of answers that may be relevant -- what kind of approach would you tend to use to calculate $ i ( x ; y ) $ between the $ x $ and $ y $ observations in a sample of $ n $ observations on $ ( x , y ) $ ?"
93302,"multiple regression by ordinary-least squares assumes at most that the errors , & therefore ( approximately ) the residuals are independent normal random variables with zero mean & common variance . no assumptions are necessary about the distribution of the predictors , which indeed may be fixed at arbitrary values by an experimenter ; or , it follows , about that of the response . so are you worrying about nothing ?"
95535,"although i cannot reproduce the "" correct "" answer , i can get close ( $ 2 . 008 $ ) by using a student t distribution with $ 60-1 $ degrees of freedom instead of a normal distribution . is the student t also covered in this study material ?"
125660,better in what respect ?
233819,can you clarify the situation that lies behind your question ?
308723,url or did you have a more specific question ?
310551,what does $ perp $ sign mean : uncorrelated or independent ?
311660,"adding perfect multivariate data for your model should be easy and then you can just add noise to the dependent variable . however , you want the snr to be "" fixed "" . what do you mean by "" fixed "" . should it be any arbitrarily given number or fixed when you change something else ?"
324326,maybe this post can help ?
326605,what assumption are you making about where this student might score ?
327421,"um . . . you have given us the formula for $ hat beta $ , so what are you trying to ask ?"
331220,what data points are you referring to ?
337114,why do you think that either of your statements - the one about mle overfitting and map not overfitting in linear regression - is true ?
337216,do you know the exact distributions of your populations ?
342234,""" it helped my understanding to think of one-way anova and ancova using analogies in linear regression . "" -- so how do you understand this analogy ?"
345278,what is the population ?
96692,"perhaps you could try iterated expectations for $ e ( xy ) $ . if you think they are independent , then what would the covariance be in part a ?"
96928,presuming that the $ m_i $ are given nonnegative integers ( is this correct ?
97219,"the coefficient must change when you scale , or the fitted values wouldn't be the same . in what way would normalizing help ?"
97465,populations . . . of models ?
97826,why not try a joint test of significance ?
97769,what you ask is very much application dependent . can you tell us more on what you are trying to achieve ?
97761,do you have data or just this question of interest ?
97842,why not just leave it as continuous ?
97849,jackknife ?
98958,this thread can probably be helpful also : [ what would be an illustrative picture for linear mixed models ?
99065,"as far as i can see , the variable ` price ` is continuous in this dataset ( price in us dollars ) . this makes the use of poisson regression questionable . what was your reasoning when choosing poisson regression ?"
95815,is the dataset same for the two models ?
99122,the normal convention is to use $ beta $ for a true ( population ) coefficient and $ hat beta $ for its value as estimated by regression on sample data . do you mean $ hat beta $ ?
97736,more information is always better . your ordinal logit should work better than binary . why are you asking this question ?
99607,do you have a specific data set you're working with ?
99722,"given this evidence that on the average a * random * strategy performs better than yours , is there any need to consider your strategy further ?"
99803,the answer * strongly * depends on how the value of 26 . 05 % was obtained . is it a new value ?
100485,"you should give more data , like is it numeric ?"
100751,"what is the "" problem "" that does not arise in anova or linear regression ?"
100954,what happens when you just change ` m11 ` to a ` glmer ` instead of ` lme ` model ?
86168,take t = 1 . how do you calculate $ f ( x_1 varphi ) $ from $ f ( y_1 varphi ) $ ?
101181,why does this include the tags ` t-test ` and ` z-test ` ?
102691,"thank you for the reference : in reading it i see i overlooked the assumption that the limiting value of the density at zero is strictly positive : that's a crucial assumption . intuitively , it tells you that the distribution of the minimum of a very large number of independent variables will be controlled by the value of $ f $ near $ 0 $ . so one way to appreciate this problem would be to replace $ f $ by , say , a * uniform * distribution , which would have to be u $ ( 0 , 1 / lambda ) $ . you can compute the distribution of $ x_n $ exactly in this case : what is it and what is its limit as $ n to infty $ ?"
102756,"is your 'judge giving a different score' just an example , or is it the real question ?"
102703,what specific post-hoc comparisons do you want to make ?
2350,"just to be clear : are you applying rfs in an iterative manner , that is by selecting the top-ranked features ( according to gini index or decrease in mse ) from the whole input space ?"
102960,"poisson regression explicitly assumes poisson variation of the responses , so why would normality even be a consideration ?"
102991,perhaps you are referring to something else ?
103026,are you referring to the proof of theorem 4 . 3 . 3 ?
103062,"a mixture of gammas is continuous , not discrete . do you want the result to be continuous or discrete ?"
103332,a standard solution is the $ chi ^ 2 $ test . have you considered that and found it wanting for some reason ?
103393,"have you tried different values of "" dodge "" ?"
103654,related to [ this question ] ( url ) ?
103625,possible duplicate of [ this ] ( url ) ?
103688,"just to clarify , this is a panel dataset , correct ?"
103748,why did you log transform them in the first place ?
103844,it would be far better to begin with the data from which the contour line was generated . do you have those data ?
103879,"it depends on your application and what your data looks like . how small is a "" small "" p-value ?"
104082,what makes you say that large sample sizes in hypothesis testing lead to false positives ( i . e . type i errors ) ?
104998,are you trying to compare proportions ?
104937,i think this is practically impossible to answer the question as written because it depends on what the goal of the analysis is . what is it that you want to know by analyzing the purchasing path ?
104810,"it could be a huge amount of * data * , willem , as summarized with four statistics . so the amount of data isn't the issue . the keys to focus on in explaining your problem are ( 1 ) what is the purpose in fitting a distribution to these statistics and ( 2 ) what is the basis for assuming a lognormal distribution ?"
104060,"then , a solution could be to re-express the * estimates of uncertainty around the mean * in terms of empirical quantiles of the data . would that be acceptable in your application ?"
73255,"the population of 'coins in circulation' and 'coins that appear in my change' would need to be the same , at the right relative frequencies . why would this be the case ?"
103671,why should there be a problem ?
105550,"what do "" a "" , "" b "" , "" c "" , "" d "" mean ?"
105576,why do you want such an approximation ?
105737,i think it's a bad idea to use rsme as a model comparison metric - even if you didn't have the problem of missing observations or different sample sizes . i say this because you may get two values of rsme that are very close to each other . how do you know if the small difference is statistically significant ?
106042,how many features ( variables ) ?
106206,"your results will not change at all by standardizing the variables . the fact that they do implies you are not actually standardizing them . i suspect--assuming that "" $ logx $ "" means $ log ( x ) $ and "" $ mlogw $ "" means $ m times log ( w ) $ --that you might have standardized $ x $ and $ w $ . ( it is unclear whether $ m $ is a variable or a constant . ) that drastically changes the entire model . the variables you might wish to standardize ( although it will make no difference ) are $ log ( x ) $ and $ log ( w ) $ . what's the problem with large coefficients , anyway ?"
86089,"i am not sure what you are asking . do you mean you want to tell if the proportion saying "" true "" is the same as that saying "" false "" ?"
106049,the purpose of bagging and random forests and most other approaches is so that you don't need to divide the data again to run the algorithms . and you did not explain why classification is of special interest as opposed to predicting risk . what is the ultimate problem you are trying to solve ?
106191,do you know the definition of leverage ?
105608,are you evaluating your models using hold-out data or cross-validation / bootstrap ?
107422,"is there a particular field in which you want to apply your statistics knowledge ( other than "" statistics "" , of course ) ?"
89208,did you do the pca on the correlation or the covariance matrix ?
107532,"just to make sure , by cross-validation error you mean the error from nested cross validation ?"
107795,why are you simulating for imputation ?
108221,"if you read to the second part of my solution you will see that i reframed the question in a way that seems perfectly aligned with your formulation . don't you think "" balanced teams "" and "" teams of nearly equal strength "" are the same concept ?"
106371,what is ` uid ` and its significance in your analysis ?
108708,what is weka ?
108463,what do you data look like ?
108837,"is there any reason not to run four separate regressions , one for each response variable ?"
108866,"exactly how do you determine whether one rectangle is "" larger "" than another ?"
109412,"the residuals for real data won't ever be likely to be perfect white noise , but what makes you feel that the residuals * aren't * sufficiently near to white noise there ?"
109627,"which "" two formulas "" are you referring to ?"
109669,why would you want to change the skewness of an iv ?
103730,"yes , it doesn't make much sense . what do you mean by random effects ?"
109710,the meta-question : [ not-a-particular dataset request - still not kosher ?
110323,"i do not see how the concept of stationarity ( as a [ property of a stochastic process with infinite support ] ( url ) ) even applies to most regression models . what do you take stationarity to be , exactly ?"
110588,"it isn't , numbers that * look like * ` 0 . 640 ` are more likely to pop up than numbers that look like ` 0 . 001 ` . i'm not sure that i completely follow your question / the problem you're having . your top code should work fine . what language are you using ?"
110513,you've already asked this question here : url you created an entirely new account just so you could ask it again ?
110748,"p-values tend to go down as sample size goes up . with 682k sample size you are likely to see a lot of small p-values , even the detected difference or association is trivial . so , don't just look at p-values , also focus on the regression coefficients and their interpretation ; they surely are statistically different , but are they also practically meaningful ?"
110898,can you use an approximate ( and random ) solution ?
108186,what variance estimates did you supply to the power calculations ?
111185,how many variables do you actually have ?
111319,"a visual assessment of normality , such as the qq plot at your link , at least is looking at a measure of effect size ( how non-normal is it ?"
111214,"what do you mean by "" a standard distribution "" ?"
111176,i don't see how you can consider it a count . it won't have the properties of a count . do you know how the recoding was done ?
111545,"that depends on what you mean by "" compare them "" . what , precisely , is your question ?"
111809,"by 'randomly placed' do you mean 'with equal probability' , among those with space for at least one more ball ?"
111784,would it help you if you wrote it as $ ( x_ { ( 1 ) } / theta ) / ( x_ { ( n ) } / theta ) $ ?
111776,"is anyone worried about the effect of dependence here , or is that just me ?"
111992,"the joint distribution is a multivariate density -so the phrase "" the joint distribution of $ y_t $ "" makes no sense . do you mean "" the joint distribution of $ t $ $ y $ -random variables "" ?"
112014,the t-test is probably not ideal . how much data do you have ?
111970,"it's not clear what you mean . what do you intend by "" probability distribution "" ?"
111989,it seems you can reject the null hypothesis of no association based on fisher's exact test . why bother about power ?
112263,logistic regression ?
111978,is this a completeley specified distribution or are we estimating parameters ?
112294,( 1 ) do you mean 'rate' rather than 'rage' ?
112318,log values may be even more meaningful than linear values : [ scientific american ] ( url ) . what is your polynomial plot intended to show ?
112325,is there an apa style for path diagrams ?
112479,just to clarify - is $ p ( p ) $ your prior ?
112660,"to be clear , you have 1 value for each variable , right ?"
112686,does h refer to time ?
113021,""" * q = i . a i . s i . ec i . pr i . xx i . dd # i . ii * "" -- what is this ?"
113305,"what relationship to statistics , data visualization , etc , does this question have ?"
113299,first you should start of with some * * exploratory data analysis * * --that will give you the push you need . . . is the data available online in an easily accessible format ( such as * * . csv * * ) ?
7364,"gappy , there are several articles about the limit theory for factor models , but in [ econometrics context ] ( url ) . i dabbled myself in factor models but for me your formulation of the factor model is anything but standard . could you please provide a reference ?"
113474,why did you pick these specific tags ?
113439,have you examined the ols output after re-sorting your data ?
113706,which alternative will you compute it under ?
114004,what constitutes 'bell-shaped' exactly ?
114146,is this a case where you're testing for a standard normal ?
114012,""" test "" $ neq $ "" report "" ; do you mean "" test the coefficient for my variable "" ?"
114549,are you familiar with the family of [ student t distributions ] ( url ) ?
96482,"nathaniel : thank you , i posted my answer . i am wondering if it settles the question for you ?"
2925,what do you mean by 'verify' ?
114610,what is $ x $ ?
114855,what are you selecting a model for ?
115011,"is it possible that some "" $ $ "" signs in the text are being mis-rendered ( or misread ) as "" $ - $ "" signs ?"
115024,"cube root is often quite good for distributions near the gamma ( wilson-hilferty ) ; but in many situations you simply won't find a suitable transformation . more importantly , why do you need to make data normal ?"
115313,is this for a class ?
115333,"what are the forms of $ f ( x ) $ , $ g ( x ) $ and $ k ( x ) $ ?"
115823,"you might need to provide more information about the analytic approach that you intend to use after the bootstrap . sure you could bootstrap cells lower than 200 until they hit 200 , but the number of bootstrapped values you would need before you hit 200 would depend on the particular run of the bootstrap you stumbled into . how is that any better than simply inflating the number of deaths and the number of cases by ( $ 200 / n_ { obs } $ ) ?"
115695,"when you say "" every overlapping word of size $ n $ "" is that like ( for n = 3 ) splitting "" sesquipedelian "" into "" ses "" , "" esq "" , "" squ "" , "" qui "" and so forth ?"
116061,where do you find an assertion that ssr has just one df ?
116174,is there some reason that you care about the p-value itself ?
116652,have you tried logistic regression ?
116968,"your question is not clear enough . ( 1 ) do by "" centroid "" you mean what is usually meant by the word : the multivariate arithmetic mean ?"
20822,could it be helpful to rephrase this as a 'change in variance' rather than a 'change in amplitude' ?
117601,"1 . when you say "" average "" what do you actually mean ?"
117637,""" * 1 ) dependent variable has normal distribution ( shapiro-wilk test ) * "" . . . well , no . failure to reject doesn't mean it's normal . ( similarly for the other two items ) . beyond that , i find your question unclear . what do you mean by "" quality of the fit "" and what does "" the answer is no "" mean ?"
118060,you can supply precisely no context ?
118122,what do you mean by ` least predictive information ` ?
118250,"what does it mean to "" get these two standard deviations on an equivalent level "" ?"
119794,could you clarify the circumstances . . . why do you need this ( it may help to guide us to better answers ) ?
119843,do you have in mind any parctical situation leading to data of that kind ?
119881,are you asking for help w / code ?
119992,are you referring to the likelihood of $ tilde { y } $ given $ hat { x } $ ?
120061,something like this ?
120325,"this result may or may not be surprising . it is hard to say . can you provide more detail about your situation , your data & your goals ?"
120267,what do you mean by an invertible $ t $ ?
120798,"it would help to have better data . the results you show could be severely interdependent , depending on whether the same subgroups of players are showing up in tournaments and on the tournament structures themselves . couldn't you collect data about * individuals * , their styles , and their head-to-head results ?"
121056,"implicitly you seem to be talking about * sequences * of random values : that is , stochastic processes . moreover--although it is not perfectly clear--your references to "" head , "" "" tail , "" and "" mid "" appear to be contiguous subsets of those sequences . "" windowed , "" "" moving , "" and "" neighborhood "" are adjectives typically applied to such statistics in both a time series setting ( where the indexes are contiguous integers ) and a spatial setting ( where the indexes may be irregularly located within a euclidean space or riemannian manifold ) . is this perhaps what you are asking about ?"
121166,first you have to segment this into its original pieces . i don't know that a ga is going to work for that . next you must re-order candidates . any optimization requires a measure of goodness so how do you measure that the edges of two pieces go together ?
121315,that depends on what you think drives sales in particular months ( i . e . what are the predictors ?
121263,what is your goal ?
31658,"the assumption is that the residuals are normally distributed , what is the result of the shapiro-wilks test for the residuals ?"
122052,there's not enough information here to answer the question -- generated * how * ?
122148,which r package are you running ?
122029,for a non-negative variable only ?
122178,"you are implying in your last sentence that you will be deleting observations . this is not necessarily a scientific approach to the problem . but more to the point , what is your real hypothesis / goal ?"
122242,can you explain why 'noisy' implies mcmc is 'not the best option' ?
122231,"why don't you post your data , describe what it measures , and describe the test that you want to perform ?"
51396,can you make any assumptions about the distribution of $ x_i $ ?
122784,can you define what you mean by 'how gaussian-like' ?
123799,do you have a source for this extraordinary claim ?
123782,"just to clarify , i assume the probability of group membership depends upon which group it's in ?"
124150,where does the quote come from ?
122985,"i assume your second $ u_1 $ is meant to be $ u_2 $ . are you really asking for a reference that shows that ( given the information in your question ) $ u_1 = n_1n_2-u_2 $ , or are you asking for a reference for something else ?"
79386,what happens if you start the mcmc chain with 1 topic per document ?
124599,"what exactly are you trying to understand , what variables are related to the various racial compositions ?"
123193,"hmm , are there no examples of manual power calculations given in cohen ?"
125005,actually i meant $ o ( sigma ^ 4 ) $ but yeah . and it's the taylor expansion of the exponential ?
125200,"you may not be able to find a named distribution with a good fit . there seems to be a sharp lower bound ; is this a known quantity ( for whatever reason , it must always be bigger than some value $ c $ ) , or does it just work out that in the data it's always ( but sometimes * just * ) bigger than some value ?"
114060,is this for a class ?
121826,what are you fitting the model for ?
125470,i don't like the sample size . can you get more samples ?
125800,"please tell us the purpose of "" writing it down . "" because you have been able to communicate the entire distribution to us in a clear and simple fashion , the purpose would seem not to be for communication but rather for calculation : but what kinds of calculation ?"
125985,flip the question around -- why should the p-values be the same ?
124889,"i believe rmse is about quadratic loss , not exponential . also , i suggest you make your question stand out visually ( use double asterisks from both sides for boldface font ) . to me it seems your main question is , in your own words , * * are you validating the training model , or the process by which you ascertained the training model ?"
125269,i'm not sure what you mean here . how does the classical test way determine how much information is offered by an adaptive test ?
126495,can you say more about the missing values ?
35693,so what are you trying to achieve ?
126596,what does your initial assessment look like ?
125908,"the margins don't really contain information * about the joint distribution ( indeed this is the point of copulas ) . $ : $ * or at least hardly any - obviously the margins do contain at least some information , since the interior counts can't exceed the margins they occur in . do you have a specific joint distribution in mind ?"
126869,to clarify : are iv1 and iv2 independent ?
126880,please add at least some information about the variable and the problem . why do you think your dataset has to be normally distributed in the first place ?
127033,yes it looks like to me they may be symmetric on a linear scale . what kind of answer do you want though ?
127054,did you do anything to the data before you fed it into the rbf svm ( e . g . centering or scaling ) ?
126932,what are you trying to do ?
127350,are you using straight log likelihood or a penalized version like aic / bic ?
127501,"one could make several different educated guesses , depending on what information is available in the problem . could you elaborate on what this "" certain problem "" is ?"
129181,are you sure about the double squares ?
129211,"how exactly are these "" events "" observed ?"
46352,the problem of this procedure is that the distribution of the estimators can be skewed and / or heavy tailed . why don't you use a quantile-type confidence interval instead ?
129293,what is your ` effect ` variable and how many categories does it have ?
129816,what is the origin of the problem ?
130271,"in the sense of multiple different continuous response variables , or in the sense that the single continuous response variable can take multiple values ?"
130283,what do you mean by 'relevant' ?
130367,can you elaborate : ( 1 ) how reliable is the periodicity of your step functions ?
130592,can you plot your data ?
87421,what do you mean by 'normalizing the standard deviation' ?
130820,"what do you mean by "" explain "" ?"
131032,do you have any data ?
131466,"these constraints seem highly artificial , even to practitioners . they would rule out things like gamma distributions , for instance ( which are not necessarily smooth at $ 0 $ and require a "" branch "" to describe the negative part ) . since copulas automatically apply to * any * marginal , your objections to their use are hard to fathom . you might have gotten lost in the abstractions . if you have a particular statistical problem where you would like a model that incorporates bivariate distributions having no necessary relationship between covariance and independence , then why not provide that context ?"
125920,exactly what will you be computing the correlation for ?
132606,"what is the range of the continuous variable , what values does it take in the sample ?"
132511,your post can be questionned on multiple grounds . first : why did you prefer pca and not true factor analysis ?
132688,can you write down any of the two probabilities ?
132531,"i don't know about the effect on memory usage , but the ws and er models are not supposed to produce graphs possessing a community structure . so why use them to test community detection methods ?"
117254,"kate , i am not sure i fully understood your problem . so you have 20000 people answering how bad they see each of the 21 items ?"
132816,"what do you mean by "" normal distribution "" and how is "" number 5 "" related to these statistics you quote ?"
132859,""" 140 , 000 entries , and after cutting out all the "" bad "" entries , there's about 2 , 000 entries "" . . . so wait . . . you throw out about 98 . 6 % of your data . . . * and then begin trying to 'cut out outliers' * ?"
133029,do you already have a graph constructed ?
132993,do you have any burn-in ( / warm-up ) ?
133058,are the data paired ?
133072,more insightfully - consider the symmetry of the situation . any of the $ x $ variables are essentially interchangeable . what does this tell you about their coefficients ?
132726,how big are your n's ?
133090,is this for some subject ?
126590,some general advice : url url try to use all the levels that you have ?
133320,"0 . 41 means what it means . this entry has 0 . 41 probability to be a success based on the fitted model . i'm truly confused on what you asking . you do realize that you are calculating the expected ` target ` ( i . e . ` e ( target ) ` ) rather a classifier , do you ?"
132751,why are the numbers divided into groups ?
133603,"could you elaborate on what "" stationary in levels "" means ?"
133436,have you considered using cohen's kappa ?
111738,"you would have to stipulate what you mean by "" importance . "" we all understand that such weights would be positive and increase with greater "" importance , "" but that would not differentiate between using the weights as given or , say , their squares or cubes . how are we to know exactly which numbers to attach to the various levels of importance for the purpose of fitting a model ?"
133799,"i'm a little lost in the vagueness of your description . could you perhaps provide a formula or concrete example of what you mean by "" the likelihood involves the sum of the residuals squared "" ?"
133965,nickthieme how is the second equation a variance ?
134207,are you sure em as in expectation-maximisation applies to your problem ?
134383,what is it that you actually want to know about these data ?
134390,"are you open to suggestions about other ways to present the same data visually , such as sequences of boxplots , smooths , and other such visual summaries ?"
134250,"is your primary interest in comparing two different website flows , or in knowing the confidence intervals per se ?"
134429,"you can represent factor analysis models as graphical models , do you have some idea of what the structure of the data is ?"
134655,"is your ev continuous , binary , categorical ?"
134774,what do you want to do ?
134961,"the plots make it clear a cubic will be a poor fit to these data . higher-order polynomials will almost surely diverge wildly for predicting or retrodicting values . what , then , is your purpose in attempting a polynomial fit ?"
135417,the parameter ` cl ` is the response variable ( your y variable ) . what do you mean correctly estimate the parameters ?
135442,if you want an output between zero and one can't you just use a logit / sigmoid activation function on your output layer nodes ?
135703,is this a homework ?
135810,"perhaps you could bootstrap confidence intervals for each $ r ^ 2 $ and see whether they overlap , and if so , by how much ?"
136024,you can get the urban / rural ratio from census . does it not satisfy your requirement ?
135743,this is explained in some detail by several of the answers to [ why do political polls have such large sample sizes ?
135804,"is time of day of theoretical importance to you , or is the variation across hours of the day ( within month ) just error ?"
135967,have you considered choosing the variables ` x ` and ` y ` ?
136337,the code in my answer at url should get you almost all the way there . but are you asking to estimate a region that contains 95 % of the * density * or 95 % of the * observations * ?
136375,url do you see the pr ( x = k ) in the page ?
136504,"the average result from tossing an ordinary six-sided die ( presuming it's sufficiently close to fair ) is 3 . 5 . yes , you can't actually get that number from a single toss , but so ?"
136649,i think that this problem is addressed by _sparse topic models_ . is that what you have in mind ?
136987,"time series data are typically a combination of ( say ) trend , seasonality , & noise . are you wanting just a linear combination of the trends ?"
136658,"to address the title ( perhaps somewhat loosely ) , the cdf defines a distribution because the cdf ( or equivalently just df / 'distribution function' ; the "" c "" acts only to clarify that's the object we're talking about ) is what the term 'distribution' literally refers to ; the "" d "" is the clue on that part . that it's unique follows from the "" f "" -- functions are single-valued , so if two distribution functions are identical the object they define is the same ; if the dfs differed anywhere the thing they are the definition of would be different at those points . is that tautology ?"
137205,a permutation is for testing some hypothesis . what's the null hypothesis ?
137593,"what about 13 february , 2009 . wasn't that a friday ?"
136810,"it's not the k-r correction ( 98 df is effectively the same as infinite for these purposes ) , it has to be something about the way the tests are being defined . what are the results of ` drop1 ( ) ` ?"
138187,"how , exactly , did the authors determine the "" significance "" of the correlations with gender ?"
137363,is the reset time random ?
137073,what is the length of the column ?
58952,"do you mean that you have a database of people , with each person having one or more diseases ?"
138879,"do you mean a * categorical * variable ( where there is no sense of "" order "" , e . g . red / blue / green ) , or an * ordinal * one ( where there is a sense of "" order "" , e . g . small medium large ) ?"
138891,what variables would you include in your multiple regression model ?
138224,could you tell us a little about how you are assessing normality ?
138214,"since almost all permutations will produce a white-noise-like fft and since there is an astronomical number of possible permutations ( more than $ 10 ^ { 1051299 } $ of them ) , your very ugly solution won't work . could you explain what connection this question has with statistics or data analysis ?"
138667,was it randomized ?
139264,"based on ljung-box statistics , model 1 looks much better . this cannot be due to overfitting since there are only 3 parameters ( plus intercept and error variance ) in model 1 , so that is not a spurious result . therefore , model 1 looks better to me . although admittedly residuals have some remaining pattern in model 1 : there are some large positive spikes but not negative ones . . . maybe try a model ( 2 , 0 , 0 ) ( 1 , 1 , 0 ) ?"
139444,"yes , but why would you want feature selection if you do clustering ?"
139301,"poisson ( & negative binomial ) is a distribution for * counts * , ie , 0 , 1 , 2 , . . . that isn't what you have here , so i'm not sure if i understand your question . where do these % s come from ?"
138204,"whuber : i appreciate your replies ( and am sorry for taking your time ) , but am now thoroughly confused about what you mean . let me ask a clarifying question . do you agree with the following ?"
139757,wuldn't a model that would need you to impute their values make no sense ?
139936,"i don t understand your example : if you checked at time $ t = 2 $ ( this is the "" uniformly distributed random time "" right ?"
139869,these are all pretty elementary questions and are normally covered in introductory time series courses . have you tried looking them up in a textbook ?
140061,"which "" it "" did you try ?"
140223,"could you do it if it was instead on $ [ alpha , beta ] $ ?"
140367,related ( but not a duplicate ) : [ what is the difference between testing of hypothesis and test of significance ?
140925,ok . can you provide a bit more background on this ?
140964,"lucy , your question should start with something like that : i have such and such data , and i am using pca as a method of factor analysis to obtain such and such goals . without such clarification , all your questions about "" what is better ?"
140498,are you asking about the * * motivation * * to study random matrices ?
140674,don't you have an adviser for your thesis ?
141293,what's mlr ?
72783,did you find a solution to you problem ?
141341,are the scores normally distributed ?
141729,what book is this ?
141285,the general theory i've already mentioned . it's a subject that fills books ; i have several of them on my shelf - could you perhaps ask a question that might be answered in half a page or so ?
141917,"regarding 2 . , you could either ignore the dummies being endogenous and assume they are exogenous , or you could endogenise the dummies by including equations describing how the dummies are determined . that could be a logit or probit equation for each "" 0 , 1 "" dummy . also , regarding dummies with levels "" 0 , 1 , 2 , . . . , upper "" , how do you include those in the model ?"
142081,it is not really clear what kind of two time series are you taking ?
142038,what is your outcome variable measuring ?
142398,there is a related question [ is there any difference between $ r ^ 2 $ and $ r ^ 2 $ ?
142766,the actual value in a cell is not its expected value--but you seem to equate them . could you clarify this by describing the typical * expected * values in the cells ?
142846,"your statement ( edit : the comment that's now deleted ) makes no sense . let $ g = frac { ( 1 r ) [ ( 1 r ) ^ { t } -1 ] } { r } $ . you just said that $ e ( g ) = g $ , implying that $ g $ is a constant ( since $ g $ always equals the same quantity ) , but then $ r $ doesn't have a normal distribution . further , if $ g $ can only take one value as you suggest , then its variance is zero . i'm afraid your question must be properly clarified . what are the parameters of the normal distribution for $ r $ ?"
143173,where did you find the mse formula with $ n-k-1 $ rater than $ n $ in the denominator ?
143270,can you provide the context in which you saw these ?
143456,"don't think that the use of document here is appropriate -- each tweet is still a document . if you want to measure an average divergence in author styles , why not compute pairwise distances between each authors' documents , and scale by within author divergence ?"
143420,perhaps you mean sparse * inverse * covariance matrices ?
143388,this is hard to interpret as presented . can you clarify your q ( & use proper english punctuation etc ) ?
143943,"the ` predict ( ) ` method doesn't refit the random forest model at all , but instead uses the information in ` fit ` to generate predictions for new observations provided to argument ` newdata ` . hence i am somewhat confused as to what you mean by this question . is this just a misunderstanding of what the ` predict ( ) ` method is doing or is your question more subtle than that ?"
22313,i guess i'm wondering what sort of autoregressive formulation you want . are you thinking of something like $ log lambda_i = x_i beta alpha log lambda_ { i-1 } varepsilon_i $ where $ varepsilon_i $ is some additional randomness driving the evolution of the rate parameter ?
144294,"when you say "" the chance for three women "" what event do you mean ?"
144405,"the fact that you have a negative eigen value means the matrix is indefinite which means that the correlations specified are not jointly feasible . it not that one variable is causing the problem , rather it's the entire system . it's also really peculiar . . . how did you get that correlation matrix ?"
144702,what do the different variables in the dataset mean ?
144691,are you sure that by selecting the outliers one variable at a time you are being conservative ?
144821,if you're embarking upon a project that requires the application of time series analysis yet you don't know what it is and the reference you have is hamilton then you're probably not going to have an easy time ! what sort of deadline are you working under ?
144587,are you asking about a way to call x11 from r or about statistical approaches for testing for the presence of seasonality ?
145296,"are you talking about using data , or proceeding from some specified density / cdf ?"
145192,"gavin i'm afraid i don't follow you : "" different "" distinction compared to what ?"
145741,it's unlikely that you should treat observed and expected as a 2x2 table though it depends on what the expected actually are . how are these expected numbers obtained ?
146101,"which definition of "" mixed "" ?"
146341,"let's start at the beginning and forget about the ` r ` stuff ( which is off topic here anyway ) . exactly what do you mean by a "" correlation "" between * categories * ?"
146765,"quoting another thread : "" real data are likely never actually normal . the useful question is not "" are my data normal "" ( no , they're not ) , but something more like "" is the extent to which my data deviate from normality enough to affect my inference in ways i need to worry about ?"
146491,"you are likely looking for the ` ecdf ( ) ` function ( "" empirical cumulative distribution function "" ) . look at ` ?"
147010,"( 1 ) clt applies when $ n to infty $ . it doesn't imply than a mean of 500 terms is normal , and it doesn't imply that a welch statistic has a t-distribution . if you want to mention a result , possibly the berry-esseen theorem might be more relevant ( but it still won't necessarily tell you about the distribution of the welch statistic , nor about power properties in particular ) . ( 2 ) what did you understand the first two sentences of my previous comment to be saying ?"
147020,( because it would impact the style of answer i'd give ) . . . what do you understand the terms ' * random variable * ' and ' * distribution * ' to mean ?
146696,"if this is a homework or assignment question , please add the [ self-study ] tag . also could you show us how you have approached the question and what you have tried so far ?"
146964,is there any reason you cannot use time fixed effects ?
147475,"this question ( as stated ) has many answers on this site which give the density function explicitly . could you therefore elaborate on what you mean by "" the behavior of "" ?"
147679,"do the exams have different questions each year , are the questions different or do they partly change ?"
76856,"what do you mean by "" the predicted probabilities for c under a or the predicted probabilities for c under b "" ?"
148438,i don't believe you can have made a serious attempt or the point i'm making would be totally obvious . what did you try so far ?
148193,what does your scatterplot of words learned against age show ?
148496,"when you say "" correlations between factors "" do you mean ( 1 ) true correlations between the factors , or ( 2 ) observed correlations between the estimated factor scores ?"
148503,have you looked at [ marin & robert's bayesian core ] ( url ) ?
148206,hi dan and welcome to cv ! i suggest you briefly describe what a blockmodel is . may you also link the paper ?
145613,i have never seen anything like this . where did you hear this ?
147688,what kind of regression are you dealing with ?
148929,""" linear "" as a function of what ?"
148772,such as levenshtein ?
149113,the title is a bit misleading . it does not seem that your data is irregular . or is it ?
149407,is the output from a observed without variation ( so a repeat would yield an identical $ x $ each time ) ?
149753,""" test whether the mean is significant "" doesn't mean anything . without using statistical jargon terms can you explain in plain words what it is you want to find out about the mean ?"
151051,"for the heatmap , have you considered transforming the values ?"
151157,"just to clarify : you are analyzing data from individual groups , correct ?"
151463,this seems highly artificial : it is difficult to conceive of a circumstance where this is the only information you would have . what actual problem are you trying to address ?
151945,"asking for how to do this in spss is off-topic here . i think you have a legitimate statistical question , though . can you clarify it & make it software neutral ?"
151763,you seem to be thinking of a threshold when ( sd of sample ) ( mean sd of series ) . do you really mean that ?
151645,what are you trying to do with the distribution ?
151991,"could you explain more precisely what you mean by "" relative variability "" in a situation where values could be zero or negative ?"
151675,have you looked at kernel methods ?
152506,isn't ozone more nearly a response to temperature rather than _vice versa_ ?
152439,"it's not clear what your last question means . what do you mean by "" determine torque "" . . . the torque measurement apparently varies from measurement instance to measurement instance . what is it you want to find out ?"
152757,"i have a lot of problems understanding the actual premise of your regression . specifically , the answer coded as 1 seems to include two contradictory responses : "" yes "" to the question , "" are we spending too much or not too much on scientific funding ?"
152806,"what do you mean when you say "" validate "" ?"
152823,there is no definite answer to this . it depends upon the domain of the problem set . secondly it will be easy to answer if you share some sample after masking the data and what is the type of independent variables in your dataset ?
153169,"to me , an "" ode "" is an ordinary differential equation , but i do not see how this would be related to the rest of the question . what do * you * mean by "" ode "" ?"
153113,have you had a look at the lmertest package ?
152912,"what do you mean by "" describe numerically "" ?"
153679,is this for some subject ?
153745,"how do you deal with the case when he knocks on all doors and makes only 0 , 1 , or 2 sales ?"
153867,"is it possible some photos may have the orientation "" swapped "" ( taken in portrait mode on something that has a landscape orientation ) ?"
153766,what's the name of the book ?
154027,where do you see the 97 % ?
153899,"my comment listed some of criterions which can be used to select the "" better "" cluster partition among partitions of different "" k "" when data are not continuous . i cannot take care about what specific software you are using . you say you use ` rapidminer ` . does it provide any clustering criterions i've listed ?"
92064,how many conditions do you have ?
153705,"can you please give more information on what you mean by "" non-normally "" . do you mean it has outliers ?"
155007,"could you amplify what you mean by "" linear model theory "" and "" considered "" ?"
155510,what program are you using ?
155700,did all 190 in one group receive one treatment while the other group of 80 receive the other treatment ?
155429,what variable are you measuring ?
155215,"in trying to understand this , i realized that in most cases it's extremely unlikely that two * random * samples of the same population would actually have the same means . do you really want us to assume the means are the same ?"
154847,"i've faced similar problems in the past , but can't say i have a completely satisfactory answer . can you put them on approximately the same intervals by taking a subset of one of the timeseries ?"
155774,"i am not sure if * unconditional * heteroskedasticity exists , especially if you pick hard on definitions . but maybe there is an answer somewhere on this site ?"
155680,did you train the model with * nested * cross validation ?
88999,"is your algorithm assignes a case to that cluster to which centroid it is closer by the distance , inversly weighted by the variance of the cluster ?"
156300,what is the motive of the analysis ?
156003,"if the units on both variables are the same , they wash out in forming the slope coefficient . the coefficient itself is unit-free . ( on a smaller detail , why say "" reduces "" and "" increases "" in different places here ?"
156516,"that might be hard , given that for each combination of e . g . $ y $ and $ z $ you will only have a fraction of the data to compute the ecdf of $ x $ . you will have to apply some kind of binning ( discretization ) of the variables that you condition on . how large is $ n $ ?"
156766,"` dput ` creates a text version of an object that is unambiguous about the content , unlike the print representation where you cannot tell is a column is a facotr or text , or a date or text . you just call dput with an expression that can be an object name or as is suggested one that would deliver a smaller verion of your data object . read ` ?"
156854,what kind of sgd are you using ?
146480,welcome to cross validated ! did i understand all right ?
157236,who wins when two or more horses first reach $ 20 $ at the same second ?
157378,"have you tried using option ` method = "" css "" ` in the ` arima ` function ?"
157914,"you want to estimate some property of the soil , say its humidity or temperature , based on samples at various depths ?"
158229,it looks to me your subsums cover every element once ?
158343,what is the data generating process ?
157570,can you write out a formula for explicitly computing the loss function ?
158970,how did you work out which day you wanted to test ?
158932,"1 ) what do you mean by "" a statistical certainty "" ?"
158951,could you provide a reference making that claim ?
159257,"no matter what transformation you use , all the zeros will end up in the same place as all the other zeros . how would that help ?"
159289,"for a 3 category predictor in which no ordering of levels is assumed , you must have 2 hazard ratios . and why would unadjusted ( univariable ) hazard ratios be of any interest ?"
159316,how many rows are there in your data frame ` newdat1 ` ?
159836,yes . something particular puzzles you ?
159812,* i'll need to do this for each time i check the experiments * . can you explain why ?
159895,what are you trying to accomplish with this test ?
159905,"hint : instead of drawing 5 cards one at a time , let's say you draw 34 . would you then say your probability of drawing the ace of spades is $ 1 / 52 1 / 51 ldots 1 / 19 approx 1 . 04 1 $ ?"
159332,why not try out your suppositions and check ?
160112,do you know the number / percentage that it's supposed to have ( ie good ) ?
160304,"this is a bivariate dataset , whereas a gamma distribution is univariate only . what , then , do you mean by "" fit a gamma distribution "" to it ?"
160295,"because the results of your t-test will depend on how often you resample , it tells you nothing about your data . if you want to compare the means of the two groups , why aren't you simply applying a t-test to * them * ?"
160410,as an aside what is the value of $ k $ ?
160736,am i missing something ?
161211,"i don t have an answer ready , but i think you are posing the wrong question , or at least the wrong approach . your figure show the mean ( = y ) as a function of time ( = x ) . as you dealing with continuous data that seemingly are not getting negative , i would go for a gamma-distribution . but why are you interested in the type of distribution ?"
162026,for each of your 9 columns you have several hundred rows . what do the rows represent ?
161843,"interesting , does the fact using diagonal covariance matrix implies feature independence assumption or this is not related ?"
162368,"how are you measuring "" propensity "" ?"
162861,"stepwise regression often isn't a useful approach , as the results can depend heavily on the particular sample at hand . why do you need to limit the number of variables , and for what will you use the results of your regression analysis ?"
130019,have you found an answer ?
163454,"it depends on what you want to know , doesn't it ?"
162952,the change in your case is at particular point in time one detector starts to lose the signal and the another picks it up ?
163593,have you considered trying different kernels ( e . g . polynomial ) ?
163284,what kind of thing are you after ?
163801,which variables are censored--the response or the explanatory variables ?
164036,what kind of data are they ?
163698,could you possibly provide more details about the situation you wants to be solved ?
128948,could you be more specific about generating a new variable ?
164682,which statistical software you use ?
164885,can you provide the reviewer's criticisms ?
166375,you really don't have enough data to include 8 ivs . you probably don't have enough data for 5 . how many addicted's vs not's do you have ?
166344,what about appling binning ?
166795,why is there a statsmodels tag ?
166654,i don't see why you have written $ sign ( kappa ) $ and absolute values of $ kappa $ since $ kappa 0 $ ?
26344,a real hash should not give such non-uniform results . are you sure the hash algorithm is correctly implemented ?
167305,i'm confused over your use of percentages for your coefficients . are these expressed as marginal effects ?
167872,what methods / tests do you already know ?
167737,"what do you mean with "" is it true that autocorrelation "" ?"
168000,do you have a reference for the claim ?
167681,. . . to failure over a that time interval . so why are you * choosing * the interval ?
167972,can you explain how the central limit theorem comes into that ?
168297,"1 ) yes , you are correct : the two indicators are competing to tell you the same information , which is called multicollinearity ( it's more technical than that , of course ) 2 ) use only one of the predictors : if they're essentially giving the same information ( high correlation , resulting in multicollinearity ) then one predictor speaks for both of them . 3 ) more data is always better . 4 ) what are the dependent and independent variables ?"
168183,is it deterministic ?
168924,"i m not really equipped to answer your question , but i think if you answer these two questions , it might help narrow down your search for an answer . ( 1 ) is the goal purely to predict x or would you also like to draw some sort of conclusions about how your 10 variables are related to x ?"
168629,"this certainly cannot be generally true , you will need some assumptions about $ f $ and $ c $ ( also it's not clear if $ x $ is a scalar or a vector ?"
35956,possible duplicate of [ what is the community's take on the fourth quadrant ?
169494,"when you say "" proportion "" , is that a count divided by a total count ( a count-proportion ) , or is it s continuous proportion ( such as the proportion of one substance in another ) ?"
169604,why should one blindly worship some authority ( such as stevens' typology ) to refer to ?
168635,what kind of $ r ^ 2 $ are you getting ?
171431,can you tell us a bit more about the study design ?
171542,"what do you mean by "" rotation "" ?"
171676,"what , exactly , is the constrained optimization part of the question ?"
78579,"compulsory xkcd reference : url . anyway , does it really matter ?"
172773,"1 . are these values between 0 and 1 discrete ( e . g . a count divided by a total count ) or continuous ( each number could be any value in [ 0 , 1 ] at all , rather than an individual number only being able to take a limited number of distinct values ) ?"
172378,"can you specify your setup more clearly , perhaps load a figure of your path diagram ?"
173480,see also [ best way to bin continuous data ] ( url ) . but don't do it : see [ what is the benefit of breaking up a continuous predictor variable ?
173558,"i don't understand the statement that the pattern between dependencies is non-stationary . i take it that the n samples are ordered , and that you're talking about transitioning from one m-dimensional state to another ?"
173549,"do you have any special structure on the parameters $ mu_i , beta_i $ ?"
173748,"when you say "" * the * goodness of fit test "" , which goodness of fit test do you mean ?"
173865,"it depends on how you define $ r $ . ( in * my * definition , which is a common and well-known one , $ r $ is automatically invariant under affine transformations . it is defined in terms of the standardized values of $ x $ and $ y $ : it is the average of their products . ) what is * your * definition ?"
173907,when you say glm are you talking about a * generalized linear model * ( the thing most usually abbreviated to glm in statistics ) or a * general linear model * ?
59446,[ corrgrams ] ( url ) ?
174282,is it possible to link the aforementioned paper ?
173713,epaminondas how many subjects are there ?
174544,it's often a good idea to leave numerical dvs as numerical as opposed to binning them and doing classification . what kind of features are you using ( number and type ) and do you have a lot of data ?
174621,are you getting at a glm with a poisson distribution but an identity link ?
171877,have you considered cart models ?
174633,maybe you should try lasso instead of elastic net ?
175450,is your question whether or not it is possible to cast the model in state space form and then let the long-run relations vector ( often called the $ beta $ vector ) vary according to a random walk process ?
175493,what kind of model are you using ?
174981,an auc of 71 % is pretty good . the reason for the drop is likely due to overfitting . it could also be caused some some unique features of the validation datasets such as outliers . have you examined the distributions of the covariates between the training and validation datasets as well ?
175767,why do you expect the average response to be ~ 0 . 5 ?
175788,"who is included in "" we "" in your first sentence ?"
175232,why do you assume there is a lot of bias simply because the numbers are vastly different ?
175851,what is your goal ?
176147,did you forget the plots ?
176129,what country is the data from ?
176236,"this isn't off-topic , but might be a duplicate of ?"
176606,what is the ram available prior to loading the data into r and ram available after loading ?
177002,"the must be a text , which explains the table . otherwise it is useless . to which exercise is the table related ?"
177125,"cliffab , aren't there already papers on the subj ?"
175593,what is your intuition for why you would do such a thing ?
177447,"what data do you have on the rooms , when you talk about room characteristics ?"
177562,would it make more sense if $ e ( u ) = 0 $ ?
177534,what are your sample skews and kurtosis' ?
177819,"given that "" $ a $ "" and "" $ b $ "" refer to * compartments * , which presumably are fixed during the drawing of particles , what could the probabilistic expressions "" $ pr ( a ) $ "" and "" $ pr ( b ) $ "" possibly mean ?"
178086,if there were two players there is no guarantee that there is an empty door to reveal . what if both of the initial choices were empty ?
178330,or maybe in such hypothesis that $ 1 / m = m $ ?
178532,"it's * not at all * clear what your question means in this situation . how are we to interpret "" effect of var 2 "" in this situation ?"
178578,i'm not sure i understand the last paragraph . do you mean the range of the scores within quantiles ?
178897,how many categories do you have ?
179111,"are you considering $ x $ to be random , or fixed ?"
179189,"setting cagdas ozgenc's questions as to the logic of this metric aside , to me your metric represents a simple difference . unless there are overriding reasons to preserving the ordering of the texts , why not just take the absolute value of that difference ?"
179160,"what about c ( 16 , 16 * 7 ) ?"
179540,"i have a clarification or two : when you write that "" multicollinearity is a sample problem , "" do you really mean a "" small "" data sample problem ?"
153961,you did not find it because just maybe you did not look hard enough ?
179726,"in your comment above , do you mean something like "" i want to show that as $ x_ text { obs } $ increases , the expectation of $ y_ text { obs } $ increases "" ?"
179823,what exactly do you want to do ?
179863,"i don't get what you mean by 4 consecutive parts and then 1000 features . so you have 10 samples of 1000 features , each measured 4 times in a time serie ?"
179948,how many groups are there ?
179813,"would you describe your target or dependent variable , "" active layer depths ?"
180042,are you sure that the dummy-variable approach results in a partial pooling ?
180196,isn't it telling you that the survival function isn't defined in a case where all observations are censored ?
179728,"do you think the standard convergence diagnostics such as gelman , rubin or geweke would not be appropriate for binary / categorical variables ?"
180188,"this sounds a bit open-end to me . did the specify how they meant the knn , or what k they think of ?"
180382,"you have many options , because practically any coordinate system or projection of the sphere that is continuous throughout the upper hemisphere ( which excludes angles of longitude , as noted by nickcox ) will do the job--mathematically . some choices will work better than others in terms of creating approximate linear relationships with the response . often a theoretical understanding of this relationship can guide the choice . are you able to disclose the nature of your response variable ?"
180503,why ppca does not work ?
180561,"what is it you're checking for normality , exactly , and why ?"
180798,"what exactly is a "" non-overlapping substring "" ?"
181068,"you likely have only one price per time point ( or per customer ) , so you don't necessarily have * multivariate * time series , but * causal * ones . you could try running a regression on price with arma errors , using ` auto . arima ` in the ` forecast ` package for r , feeding prices into the ` xreg ` parameter , possibly after some transformation . it's a bit unclear to me where the multi-product aspects come in . do you assume some total demand that breaks down among the different products ?"
181376,"the first link directly * * shows * * that the bounds on the correlation between x and z can be negative ( in the notation of that question , it shows that $ rho_ { bc } $ is ( attainably ) bounded by $ rho_ { ab } rho_ { ac } pm { sqrt { 1- rho_ { ab } ^ 2 } sqrt { 1- rho_ { ac } ^ 2 } } $ ) . e . g . take $ rho_ { ab } = rho_ { ac } = 0 . 5 $ and the lower bound is negative . aside from the need to substitute $ a $ for $ y $ and so forth , how does that not directly answer your question ?"
181757,are you after a reference explaining how it's usually a really bad idea ?
181805,how about not using stepwise selection at all ?
181899,"if you have an indicator for before / after in your model , how does testing the coefficient being different from zero not achieve that ?"
181566,why would dtw has anything to do with your data ?
182010,* why * do you model ?
182610,do you mean if the order of columns will play any part in the predictions ?
182628,does your logistic regression model only have one explanatory variable in it ?
182275,have you tried contacting the authors ?
180618,"so , just to clarify : it seems that you are interested in a single latin hypercube sample of size $ n $ , where $ n $ is large ?"
183285,can you tell us what you have tried already ?
183351,exactly what test are you using ?
183611,"because you have already applied some kind of test , what's the matter with reporting * its * test statistic ?"
183628,you may want to remove the ` * ` from your body text as well . your question is covered in the answer here : [ how do i find values not given in ( interpolate in ) statistical tables ?
183764,can you clarify ?
183544,did you look at importance for random forrests in r ?
84100,"categorization of bmi is invalid , and the use of percentiles for categorization defies the laws of physics . do you think that increasing bmi puts physical strain on the cardiovascular system or do you think that the number of other persons in the sample who have bmi lower than yours affects your cardiovascular system ?"
184326,how are you thinking about the multiple dvs ?
184362,why you cannot fill those question marks ?
184350,can you give more details ?
184609,when x = 100 must y be 0 ?
184697,what software do you use ?
184712,what exactly are the y-values ?
184523,"this feels like a time series model ( arma , arima , etc . ) . is what you have the profit for several years , and the a vector of predictors for each of the prior years ?"
184968,"your difficulty is with $ p ( a , b c ) = p ( a b , c ) . p ( b c ) $ ?"
185282,can you provide some sample code and data ?
185362,isn't this a duplicate of the [ many binomial distribution self-study problems that have appeared ?
29017,"it is closed under ( independent ) * sums * , but not arbitrary linear combinations . if you include your work , i suspect you'll end up seeing why in the process ; and , if not , someone will be able to point it out . yes , there are some inversion analogues to that of characteristic functions . what do you know about the laplace transform and bromwich contour integration ?"
185729,is this a question from a course or textbook ?
185750,i'm not sure why the identity link would fail because that's the true model . what exactly went wrong ?
185598,"note that an equation like "" total expense = a b employee pay c utilities noise "" is linear . are you really asking about nonlinear relationships ?"
185925,does y = a bx necessarily follow from the fact that x and y are correlated ?
186887,"how can you say that the difference "" increases "" when the transformed data are * logarithms * and the original data are not ?"
187024,"for me the title and post seem to be a bit at odds . you ask about sampling ( i . e , drawing from the population ) in the title and the last line but in the post you talk about random assignment ( i . e . , allocation of people to groups ) . these two are not the same . you can have random sampling without random assignment and vice versa . so perhaps you could clarify ?"
187154,"according to the definition of confidence interval , $ pr ( theta in ( a , b ) ) = 1- alpha $ ( with $ a $ and $ b $ viewed as the random variables ) . so , how are $ pr ( theta in ( a , b ) ) $ and $ pr ( eta ( theta ) in ( eta ( a ) , eta ( b ) ) ) $ related ?"
187263,what is the purpose of your fitting ?
187366,"$ p ( x a ) = int_ { a } ^ { pi / 2 } sin ( x ) dx $ . avoid the notation $ p ( x x ) $ , since this leads to ambiguity in the notation- is $ x $ the lower bound of the integral or the variable of integration ?"
187440,why would it be true that $ e ( m_n ) = 1 $ ?
188460,"because this question appears to involve intuition rather than any rigorous concepts or definitions , it seems pertinent to ask this : what exactly do you mean by "" picking "" a number ?"
188838,why pretest at all ?
188995,"1 . what do you mean by "" constant process "" ?"
189068,any restrictions on the random tosses ?
189216,"do you want to compare 1 color to another ( controlling for size ) , 1 size to another ( controlling for color ) , or sizes & colors combined over time ( sales for december compared to november ) ?"
189264,what is the * purpose * of your analysis ?
189515,"i count 42 observations , 11 predictors and an inclination to fit a model with 22 parameters . in addition to high correlations , i see everywhere skewness and long tails in the $ x $ . one might guess that $ lambda_j 1 $ would help , but the aim seems over-optimistic . why do you think the model is even plausible ?"
189466,"according to most standard definitions of a random variable , there really isn't a question here , because the answer is immediate . could you please , then , tell us what you understand a random variable to be and what your definition of these partial derivatives is ?"
78570,"no , but that is not a problem . if something is reported to be constant , there is no sampling error and you are not in statistical doubt about its real ( mean ) value , and no t test is relevant or needed . ( of course , there could still be measurement error , but the t test could not fix that any way . ) ( another "" of course "" is : do you really believe data of that kind ?"
189793,i think you should clarify your assumptions . do you consider sampling from a discrete distribution which then puts equal probability on each support point and the support is the given dataset ?
117709,"i'm also having some trouble here . $ p ( y- theta theta ) $ is the density with parameter $ theta $ evaluated at point $ y- theta $ , right ?"
186947,what data are they ?
191146,"please give the model explicitly , including what values $ x $ and $ n $ are defined for ( or at the least , explicitly state whether the distribution is discrete or continuous -- it looks like it's intended to be discrete but it's better to be plain ) . please show your working - how did you get your answers ?"
191549,can you tell us a bit more about the context ?
191774,could you provide data example for your question ?
191816,each instance - is not clear . what is instance ?
191885,i am not familiar with this test . but did you try classical unit root tests ?
192843,"so each person has 5 trials that they get right or wrong , is that correct ?"
192476,you need to alias som of your * * c * * categorical levels to get down to * * c * * = 5-15 . how many samples do you have ?
192770,do all the points refer to the same day ?
193080,why is this a problem ?
193287,"do you have all your data , or just the summaries you listed here ?"
193360,what definition did you use ?
193417,my guess is that it has to do with the ` class ` of ` basetemp ` . can you specify it - is it a factor or character ?
193723,"let's do some thought experiments . ( 1 ) suppose you had a dataset of constant $ y $ values , such as $ ( 0 , 0 ) , ( 1 , 0 ) , ( 2 , 0 ) $ . rotate it by $ pi / 2 $ . what result would regression give you ?"
193715,why won't the methods you mention for continuous variables work for a continuous and a categorical variable ?
193647,why do you care about normality ?
193815,"if you have the possibility to do a step back , have you tried to compare the area under the curve of your both outcome , first ?"
194032,the purpose of your plot is unclear . what feature of your data do you want to emphasize ?
193987,"if you can't just aggregate the two data sets , how about simulating the original number of points from each , and then doing a single estimate ?"
194226,"i'm certainly no expert in this area , but whenever i've run random forests it's always been a 2 / 3rd 1 / 3rd split and run cv on the training set still . also , isn't there some preprocessing step or postprocessing step that will clean up the random forrests ?"
194172,given you can calculate the log-likelihood as well as count the parameters of the optimized model what stops you from using aic ?
194270,"the summing is incorrect , but you'll have to provide a bit more information about how your data were structured to get an answer about the best way to proceed . in particular , were condition a and condition b entered as separate predictor variables into the cox regression , or were they two separate levels of the same predictor variable ?"
194523,""" heard from some sources "" --- which sources , where ?"
194561,gga do you mean : journals that focus on * * methods * * for meta-analysis or journals that focus on publishing applied meta-analyses ( usually with focus on a particular discipline ) ?
194626,"your meaning of "" applicable "" is strange , because it is equivalent to "" nonzero . "" could you please clarify what you mean by this word ?"
194635,where do you * see * seasonality ?
194594,"what do you mean by "" approximate a model by an explicit expression , using given data points "" and "" vanishing "" approximation ?"
195022,do you know how to do it when it is $ mu $ instead of $ beta $ ?
195017,is the list of possible things ( the middle column ) fairly limited ?
195522,"again , the most common questions : what is your data , is it real-values , structured , etc . . . ?"
196745,"do you mean "" arithmetic mean "" rather than "" arrhythmic mean "" ?"
188582,"if the dag you provided holds , then the causal effect of exp on the outcome is identified , use e . g . the back-door theorem ( that is , if the dag is correct ) . i don't understand your second paragraph , though . for starters , how does one know what's causally related before doing the analysis ?"
196815,"it might depend on your data , also on your task . i . e . how many features and samples do you have ?"
196868,how is mi being estimated ?
197144,[ this one ] ( url ) ?
195470,"the null hypothesis is that means are equal . the ( usual ) alternative hypothesis is that they are not . the extra words in your formulation don't help at all ( what would "" near "" and "" extreme "" mean ?"
197273,'weights' in the last line of the code is a matrix ( or a tensor ) not a scalar right ?
197418,you have 4 features but no target value or class ?
197327,"( egads , has that show been on for 20 years ?"
197468,what about the power in this sample size ?
198084,adding a constant to random variable would not change its variance . do you want to add different values to each observed case ?
191008,dare i say : * partial f-test type iii * ?
198906,exactly how did you compute this posterior probability ?
198994,"what do you mean by "" better "" ?"
199203,"it's pretty clear those dots at 50 , 000 aren't the real monthly income : presumably , your data are * censored * at this value . there are also a visible preponderance of incomes at 40 , 000 , 35 , 000 , and 30 , 000 , suggesting that some appreciable proportion of the incomes have been rounded heavily . these issues can influence the choice of regression methods . the dot with an age of 0 and the relatively large number in the 90s and 100s suggest there may be issues with how the ages are recorded , too . what is the purpose of exploring the age-income relationship ?"
198801,edm the residual deviance would be null then -- wouldn't it ?
199782,"if i understand you right , you have $ d $ independent $ t_ { nu } $ distributions , and you are wondering if their sum is equal in distribution to a $ sqrt { d } t_ { nu } $ ( being loose in notation ) ?"
53380,do you have a particular distribution in mind ?
199945,"do you need a plot , or the data to achieve the plot ?"
200250,are you sure ?
200338,"actually , it depends on your precise definition of "" average "" . . . maybe you can try to elaborate your question ?"
200284,"exactly how would you apply any form of "" coordinate descent "" when a gradient is unavailable ?"
200492,have you performed forward / backward selection ?
200806,what is the mean of a poisson process with rate $ lambda $ at time $ t $ ?
200587,"what are ` y ` , ` x1 ` and ` x2 ` ?"
201052,"are you talking about negative binomial regression vs poisson regression , or just estimating the distribution parameters for some data ?"
201636,is this true for all $ i $ ?
201653,is that a new question ?
201625,"can you explain how this "" sample-correction "" was done ?"
201813,"what do you mean by "" line graph "" ?"
201886,"( 1 ) it depends on exactly what this "" mapping "" is . could you tell us what it is ?"
202062,would a better solution be to perform a chi-square test on the whole contingency table ?
202227,it looks to me that it is the same question than url ?
202282,why would you like to calculate that ?
202345,"you ask rather short and often challenging questions , but they are also often cryptic . what is the question about ?"
164668,do you have multiple measurements within each brain region of each rat ?
202409,"what do you mean by "" varianced estimator "" ?"
202387,"do you really mean this : "" i'd like to get a confidence interval over the p-value "" ?"
202433,bootstrap distributions of * what * exactly ?
202528,scroll down to assumptions : url if you didn't assume the errors were uncorrelated then how else would you conclude this ?
202407,regression models don't entail assumptions about marginal distributions . are these the residuals ?
202629,is histogram worse in every way than a representation of the whole distribution ?
203260,"i can't see that you are plotting categorical variables here at all . you have three measured variables each divided into 10 bin histograms on the diagonal and heat-maps in off-diagonal cells . either way , one answer is that this example doesn't encourage me to look at any more , as i don't know how to interpret what i see and most patterns appear random blurs . can it be that solid black at bottom left and top right encodes * * low * * frequencies ?"
203138,is this a question from a course or textbook ?
203435,"you could further : collapse by whether people are child or adult ( cut at 18 ) . the data reduce to 2 points ; the correlation is -1 . in broad terms , averaging reduces scatter and increases correlation . there could be exceptions : you can always imagine groups such that after averaging the correlation is nearer 0 so there is no theorem here , but it is a broad tendency . a moral is to keep thinking of patterns on scatter plot sand to remember that correlation is an automaton answering one question only : how close are these points to a summary line ?"
203097,"( 1 ) taking to heart the wisdom in the comments by nickcox and edm , i still like the nature of this question , which might be rephrased to read "" when i plan to perform both univariate and multivariate analyses of data , is there some preferred order in which i would * examine * the dataset for univariate and multivariate outliers ?"
203364,what is the ultimate goal of doing this ?
203655,"probability is calculated for an event , and expected value is determined of a random variable . so i am not sure what your question is asking . can you expand on the sentences using some equations that you might be referring to ?"
202508,is a - b a regression ?
203543,"how will you be using the "" myocardial infarction at an early age "" variable differently from the 2 underlying source variables ?"
203839,"among many other possibilities , how about half the students are in 6th grade and half in 10th grade ?"
203984,could you go into more details ?
202225,can you clarify some things ?
204008,"dsans could you provide a link to these other mnist implementations for reference , specifically where they use the lr of 3 ?"
204057,if you have only one independent variable then the $ r ^ 2 $ is the square of the correlation . maybe that helps ?
203947,what exactly do you mean by this ?
204442,any assumptions about the form of the curve ?
205078,aren't there standard dictionaries and agreed upon lists for stop words ?
204704,have you tried ` dwilcox ` [ in r ] ( url ) ?
205056,"in order for this question to be answerable , you need to specify some way to quantify the accuracy of the estimate . for instance , suppose there are 800 red and 2200 blue balls total . if you estimate 900 red and i estimate 700 red , who is closer to the truth and by how much ?"
205279,are the data continuous & normally distributed ?
205386,"mpiktas , do you have an opinion on which of the two terms suits better in this case ?"
204975,but why do you want to transform it twice ?
205610,"i have no idea what you're doing . if the system has converged , why are you continuing to train ?"
205653,see e . g . [ what is the meaning of p values and t values in statistical tests ?
205511,"your first link says that uniform p-values are a bad thing . your second link says fdr does not require uniform p-values , which makes sense because a uniform distribution implies there are no effects to find ) . where is the conflict ?"
206490,do you have more than three studies ?
206500,sounds right . seems plausible . presumably you know the trees in question . does it make sense to you ?
206617,mean of what ?
206918,"is there an ordering to the items , ie , the [ german tank problem ] ( url ) , or are we just estimating the size of an unknown population ?"
206969,optimal based on counting cards ?
207154,"a powerful and effective way to make this comparison is to construct the qq plot . however , your reference to the ks test suggests you are looking for a formal hypothesis test . but what would be the purpose of that ?"
207176,what is wrong with using the normal mgf ?
207220,what do the numbers represent ?
206903,"to use rand index or any of the external measures * you do need labels * , but your question title says you don't have labels . your question body however appears as if you have labels . . . so what is it ?"
207707,"what do you mean by "" how are the neurons in the hidden layers decided ?"
208044,what about example 3 . 2 . 3 [ here ] ( url ) ?
208597,"lots of incorrectly-specified models have significant and robust coefficients . setting aside any numerical questions , just think through what you're saying : people who can access the internet carry out terrorist attacks . that's insane . can you think of at least one other reason people carry out terrorist attacks , other than having access to the internet ?"
208645,what kind of passwords are case insensitive ?
209106,is this a question originally from a course or textbook ?
209418,how did you initialize your problem ?
209663,your model specification is incomplete : what did it assume about any differences between the data and the fitted curve ?
209647,"i give you pairs of points $ ( x_i , y_i ) $ . can you infer the function they came from ?"
208393,can you explain how lda is a word representation ?
209535,"you seem to have the raw data , why not calculate the sd directly ?"
209802,"you've left a number of things unclear here . first , what is your question ?"
204847,"it isn't completely clear just what you mean by "" analyze them "" or "" this analysis . "" what is this "" single , ordered list "" intended to represent ?"
209813,what is the nature of variables - datatype ?
209753,"what do you mean that the models were "" not accurate "" or "" not great "" ?"
210520,thanks for the shout . would running ` anova ` on the two models work to distinguish the specfications ?
210209,"that's a start , but you haven't specified whether you care about heterogeneity within variables among samples , or within samples among variables . it would also be help to know more about the raw data on which the proportions are based : for example , are they successes among trials and if so how many trials ?"
59493,"question for priyaj : when you say accuracy do you mean ( 1 ) the difference between the mean error and the true value , ( 2 ) a measure of the width of variation of errors , or ( 3 ) the measure of the appropriateness of the particular / fitted model in representing the information and not the noise given the particular set of training data ?"
210205,"what is a "" valid "" conclusion about the "" real world "" if not an inference about the population ?"
211057,when exactly do you get divizion by zero errors ?
210639,"the go-to question might be worded in a confusing manner . for example , the use of $ x $ with a capital would make $ x $ seem random . but since you're mentioning minimum variance , it would seem like you want $ x $ to be non-random ( in which case , why does the variance of the estimators not have a written dependence on $ x $ ?"
210771,"i'm not sure i follow your thinking . if there are more readmissions within a given interval , don't the readmissions have to be closer together ?"
210988,why not use rma . mv and take the clustering into account ?
209166,how did you equity ratio ?
210500,"if the data look like that , and the data are all i have to go on ( presumably i'm doing some form of sample splitting to pick my model and again to evaluate , fitting on the remainder ) , then why would i choose a regression model rather than something else ?"
211860,"i guess it would work to some extend , probably also depending on how balanced your outcomes are . but why don't you give a bit of info as to why you'd do this i the first place as opposed to use a more suitable model ?"
212188,possible duplicate of [ how to test hypothesis of no group differences ?
212125,why on earth would you name files like this ?
212031,"i don't understand why you say you data are "" not strictly paired together "" . for each individual , don't you have mean behavioral values for both the wet and dry seasons ?"
211793,"this requires some matrix algebra , and the schur complement , to explore . are you familiar ?"
212803,is your training estimate for $ w $ the same as the coefficients coming out of the standard glm ( ) function ?
213138,why did you divide it into two groups ?
213202,"from description of your problem i don't see how poisson regression relates to it . . . first , you do not to have count data , but rather categorical variables . second , it seems to be rather hypothesis-testing than modelling problem . could you describe your data and problem in greater detail ?"
213528,i can't understand this . is that code from some language ?
213510,how would you compute a distance between two subjects' data if they have different number of time-points ?
213416,how big are the categories ?
213644,possible answers to this question are infinitely numerous and almost completely arbitrary . could you perhaps tell us what you are trying to accomplish with this random vector ?
158792,is this a homework question ?
213658,"when you say "" by chance "" do you mean in the case that the population correlation is 0 ?"
213015,"you are standardizing all your predictors , right ?"
214646,directionality can be difficult to test when the range of values may include differences of 180 degrees or more . are such ranges of values realistic in these data ?
214882,"( just thinking through this myself , quick thoughts and questions ) based on the 3 t / f questions , we can group individuals into $ 2 ^ 3 = 8 $ buckets . within each bucket , was there random assignment of individuals to ( 1 ) normal procedure or ( 2 ) modified procedure ?"
212154,what is the theoretical basis for your calculations ?
215149,why are you interested in estimating the inverse hazard rate ?
215728,can you give a reference to the claim about normality of the auc ?
215885,"what do you mean by "" train a logistic regression . . . w / a poisson assumption "" ?"
215971,"it's possibly a difference in handling ties ( note that ` wilcox_test ` offers several different options for dealing with ties ) . where you say "" usually "" , can you show a case that is neither equal nor half as big ?"
216070,"please check if my simple-word understanding is correct . you have actually a rectangular frequency matrix r defined by rows a and columns b . you want to form some disjoint "" clusters "" whose elements are cells of r - the ( x , y ) pairs - with "" high "" value ( frequency ) . am i right so far ?"
216025,do you have a link to download the article or can share it personally ?
216023,is there anything theory suggests about a particular functional form for the non-linear relationship ?
216203,1 for whuber's answer . that's the absolute most basic thing you can do . are you familiar and comfortable with matrix notation ?
216019,` regardless of that we know the responses for each of the six are not independent ?
217545,have you heard of the gau-markov theorem ?
213012,you say you _have_ to compute it per group . can you state why ?
217812,"at the moment this question is rather unclear - what do you mean by "" statistical significance "" in this context , what is your null hypothesis ?"
217935,why do you think that this is a problem ?
218204,"if you are only asking about the code , that would be off topic here . if you want to know how to derive something , that could be on topic . can you paste in what you want to derive ?"
218194,"if you're estimating parameters , how are you calculating p-values in the kolmogorov-smirnov test ?"
217683,do you have the distribution table supplied ?
218282,"welcome to cv . it would help your potential respondents if you were to say a bit more about your data . for instance , what is the sample size ?"
218357,"what do you mean by "" tried lagging the variable ?"
218385,is the experiment run in a way that assures the data are independent from one protein to the next ?
218217,"what are you trying to compare between the two samples correspond to "" attention deficit "" and "" other types deficit "" levels of your categorical variable ?"
219001,could you also work with the question whether one die rolls a higher average ?
219150,"so after generating random numbers for these 4 variables , i should simulate using bootstrapping ?"
219319,are your models nested or not ?
219521,what would you like to test for significance in the algorithms ?
219460,can you please give more details in general ?
219733,"is is theoretical , or applied statistics . . ?"
219830,"there's a disconnect here : you state you want to change the weight based on what "" you think , "" but then you ask for an algorithm "" with no human interaction . "" is it supposed to read your mind ?"
220204,how many months of data do you have ?
140493,how is time entering your logistic regression ?
220849,are you predicting event-arrival-time as a function of any other parameters ?
221114,are you asking for help with the code ?
221185,"yes , all variables . why not ?"
221004,any particular kernel ?
221203,( 1 ) what are the lag populations in those empirical variogram plots ?
221744,what's your rationale for removing the items with a low loading ?
222184,what do you mean by accounting for possible differences between patients ?
222381,what exactly do you want to do ?
222485,student law ?
222514,"i think neither model is likely to be suitable for several reasons each , though with ( what i guess to be ) artificial data like these it can sometimes be tricky . what are you trying to achieve with these models ?"
222522,do you have any subject matter knowledge of the data being fitted which leads you to a particular model ?
182094,your idea of moving averages is promising . why do you think that the false positives occur ?
222975,what are ` i ` & ` s ` ?
223004,likely none are actually normally distributed . why do you need marginal normality of the dvs ?
223368,just wanted to clarify : are you asking how to best model the data ?
223406,"could you explain what is "" inconsistent "" ?"
223421,have you looked at the formula for its density ?
218940,"ashwinnaresh i have the same problem when i'm using lstm . would you please let me know what you decided to do finally and were there improvements over garch ( 1 , 1 ) when you tried it ?"
223591,"you may be using sledgehammer where a normal hammer may do better for your problem domain . is extreme predictive accuracy actually important for your application , or just good enough accuracy ?"
223758,` for measure i will choose count ` . are your dataset _counts_ to choose that ?
223767,if you do not have label ( unsupervised setting ) how do you know the class is imbalanced ?
127475,perhaps you could explain why this question has statistical relevance ?
225392,"i don't understand the question . can you describe the network architecture and training procedure in more detail , and how the inputs / outputs / latent representations of the different networks relate to each other ?"
225036,"see ottom of my answer , does that help you ?"
225759,how does this question differ substantively from [ test for no corelation ] ( url ) ?
56684,can you also give the page number ?
223987,have you looked at our threads on [ post-stratification ] ( url ) ?
225153,so you would like to do feature selection and end up with a model including a smaller number of features ?
226230,"the question has already been answered , but what hyperparameters do you want to tune in random forests ?"
226780,"what does "" general "" mean in this context ?"
226273,"a quick look at the object returned by ` model . avg ( ) ` indicates that random effects are not averaged , though i could be wrong . why are you averaging in the first place ( you seem to be interested mainly in inference , not prediction ) ?"
183696,have you found an answer ?
226982,"you you want to change the size of the partition itself used with cross validation , or do you want to change the $ k $ ( for number of partitions in cross validation ) for this too ?"
228411,"it's not clear what the adjacency matrix represents , but do the weights correspond to a euclidean distance somehow and satisfy the transitive property of euclidean space ?"
208026,did you consider online learning ?
228815,one could probably argue for any of those categories . . . without having the context that your teacher was presenting this material we cannot give you an answer . why don't you ask your teacher ?
226699,"what do you mean by "" dedicated ?"
228780,"this is very broad , and probably not answerable in its present form . can you narrow this down from "" somebody wants to share their opinion "" ?"
228941,can you tell us more about what you already knows ?
228507,is there a time dimension as well ?
229211,in what way do the results * change a lot * ?
229264,"what do you want to use , the delta method or the bootstrap ?"
228887,the title is somewhat misleading as what is given seems to be data ( iid ?
229404,"for "" statistical significance of eigenvalues "" to have any meaning , you need to specify a null hypothesis . what do you have in mind for that , especially in light of your desire to assume a non-diagonal covariance matrix ?"
229439,where did you read that the mann-whitney u-test requires equal variance ?
229623,"at the moment this question is quite unclear . what does "" double digit lead in gold "" mean ?"
229598,please show us exactly * how * the results don't match . are you referring to predicted log odds ?
229319,"the formula ( in words ) that follows "" also , "" and the formula you ask about are * identical * ( the latter merely uses a more compact notation as defined in the intervening sentence ) , yet you say you have understood the former . what , then , is left to add ?"
230171,"do you you have two observations , or two samples containing multiple observations ?"
230279,could you post a small samples of the predicted probabilities ?
230332,could you tell us why you are trying to do this ?
230369,johnnyboycurtis . . . why ?
230713,"( 1 ) as you know , $ j $ is merely a compact way to write "" sum of squares . "" the sum of squares of numbers is zero if and only if all the numbers are zero . note , though , that $ j $ is not a quadratic form in $ hat beta $ , so the usual meaning of "" positive definite "" does not apply . ( 2 ) the blue expression is a * number * . strictly speaking , then , ( a ) it has to be viewed as a $ 1 times 1 $ matrix for "" positive definite "" to make any sense and ( b ) it will be positive definite if and only if that number is positive . that's not always the case : the value could be zero . what are you actually asking , then ?"
230818,what would be the proportion ?
230658,"it looks to me that the thread over there and the question posed here really amount to the same thing . perhaps you should edit this question to make it more clear , what aspect of the other thread was unclear to you ?"
231029,"you want to predict a * general * relationship , lumping data in from different shows ?"
231024,"nicolasbourbaki , just for the sake of clarity , you are specifically referring to the model $ xi = beta_0 beta_1 eta epsilon $ , with scalar $ xi $ and $ eta $ , right ?"
231103,do you get coefficients for all your variables ?
231135,can you show the linear algebra behind your question ?
231351,so you're saying in the second case there would be more observations because you observe the same person in 2 different regions ?
231581,"first question : $ p ( x le x ) = int_ { - infty } ^ infty p ( x le x y = y ) df_y ( y ) = int_ { - infty } ^ infty phi ( x ) df_y ( y ) = phi ( x ) int_ { - infty } ^ infty df_y ( y ) = phi ( x ) $ . so $ x sim n ( 0 , 1 ) $ . agree ?"
231763,"it will help if you can be more specific about range of models in the set . here's a simplified example - things only get more complicated from here . assume that truth has one local minimum over a 1-d interval of interest . and assume the same for the models . a metric of which is best could be the distance from the minimum of the model to the location of the true minimum . this could also be done in higher dimensions , with possibility of weighting per component . if multiple minima and maxima , then combine errors in locations . but what if you don' ; t know how many minima or get number wrong , etc . ?"
232095,what would be the objectives of the visualization ?
230978,whats your goal with the model ?
232475,"i'm not sure that the situations are really all that different . the sub-questions are ordered in difficulty , so if you get q1 wrong you're unlikely to get q2 correct , and if you get q1 correct then you're ( a little ) more likely to get q2 correct . i would just say give a person a point for each question they get correct , but the fact you're asking makes me think you have a reason for believing this would potentially be inappropriate . am i right ?"
232843,"for your first case : what is the chance that you predict 0 , whereas the correct value would be 1 ?"
232551,are you open to using bayesian methods here ?
230410,"you use the term "" runs "" for your experiments . am i right in assuming that you are performing "" computer experiments "" , i . e . , running a costly simulation code for each point in your design ?"
233506,why do you want to see the covariance matrix as a regression ?
233816,would it be better to not modify the probability ?
233973,"so your study design tries to get the maximum wtp for each participant , is that right ?"
215654,what does your notation in $ m = arg max_ theta pr ( d theta ) $ mean ?
234517,did you consult with some existing algorithm of ml fa extraction or invented yours from scratch ?
225991,i believe this is actually the classic example used to describe non-proportional hazards . is there any reason * not * to just use the km curves ?
234830,"this is a little hard to follow . can you make this more concrete , somehow ?"
234783,"could you please indicate where you find "" effect sizes "" in this table ?"
235142,"counterquestion : assume myself and dirk nowitzki ( who has enjoyed the "" treatment "" of decades of basketball training , as well as talent ) each throw three free throws , and we both happen to succeed twice . so there is zero difference between the sample means , which hence cannot be significant . would you be willing to infer that i am no worse than dirkules , i . e . that the treatment had no effect ?"
235238,"if 6 comparisons will be done , why not 0 . 05 / 6 , but 0 . 05 / 5 ?"
235167,"you have 21 observations , and a categorical variable with 10 levels . is that correct ?"
235600,it seems to depend on the initialization a bit . i commonly got to 5 % or so . ( i think i took down the batch size to 5 also ) . you used sin ( x ) & sin ( y ) * in addition to * x & y ?
235665,why 30 and not its root ?
235410,you mentioned training error . isn't that just the sum of residuals for your model on the data set that you used to create the model ?
226021,what if you have a stack of images as data ?
235789,your time series model does not know any more than what you feed it in your data series . do you expect this fall / winter dip to repeat this year ?
235507,"the choice of language is also curious as it say "" fits * the * data "" . did the question offer any explicit data ?"
235946,"what does "" i didn't get exactly what i am looking for "" mean ?"
235854,is this a [ tag : self-study ] question ?
235923,do you mean a simple poisson regression with count data ?
236023,"your intuition about overfitting is probably correct but i do not understand what you mean by "" * moving on , as i continue to fit more models . . . * "" didn't you stop modelling after you reached your optimal rmse from your previous step ?"
236149,why not simply use inverse transform url ?
207447,"is it a ' self study "" question ?"
236411,is this a question from a course or textbook ?
235794,did you checked anovas assumptions ?
236385,are there any reputable code academies ( code bootcamps ) in your area ?
236422,"your question seems interesting but the complete absence of either comments or answers despite over a dozen views suggests that important information about your problem may be left out . i am challenged by the mystery that surrounds your explanation but i am also at a loss as to how to respond . this air of mystery may be deliberate if you are attempting to camouflage your query to maintain privacy . regardless , would it be possible for you to elaborate a bit more ?"
235997,"you would use squared returns , right ?"
236814,"these seem like extremely poorly defined statements ( what is "" not many "" or "" a few "" ) ?"
237523,"i'm a bit unclear on what you are trying to achieve . if you use three different thresholds $ t_a , t_b , t_c $ and classify a sample as $ a $ if its predicted probability satisfies $ p_a geq t_a $ , then you may well end up in situations where * both * $ p_a geq t_b $ * and * $ p_b geq t_b $ , and what will you do then ?"
235115,can you tell us about how large is your $ p $ ?
237573,djohnson : * poisson regression * for classification ?
237790,"can you define how * you * are using the terms "" test set "" & "" validation set "" ?"
237821,what is a log return ?
237958,"you're on the right track . try being more specific about what the 0 . 0418 is , that is , what is it the probability of ?"
237804,"i don't understand the setting - there may be some notational confusion . in what sense do the components of the _proposal_ have "" likelihoods "" ?"
238226,independent variables that are dependent ?
237437,why does anything need transforming ?
238343,i think you have separation as discussed in that link . leaving the variable out means leaving out your best predictor . is that what you really want to do ?
238029,"not a lengthy answer here , but the error he is likely referring to is actually related to a p-value . for example , in regression , the estimate divided by the standard error is the t-statistic . when this is 2 . 0 or above ( actually 1 . 96 ) the you can say the effect is "" significant . "" of course , there are also issues of degrees of freedom to get the p-value . that said , a "" significant "" finding can very generally be thought of as the estimate being twice the se . so , what if the the estimate has slightly more error due to measurement , sample size , or whatever ?"
238356,1 . the phrasing is imprecise : do you mean one specific student among the 39 or there exists one and only one student in the group with no neighbour ?
238440,can you give us more detail ?
238659,do you just mean empty strings ?
238734,"` closer they are , more interactions is observed ` that looks like similarity , not distance . in what sence then ` values are proportional to euclidean distances ` ?"
239266,it isn't clear to me exactly what you're asking for here - is it how to know substantively which variables are ordinal and which are not ?
239210,"hi , what do you mean by "" what test can i use to determine that mutants which have 40 % of x is statistically significant ( p 0 . 05 ) ?"
239420,"if "" $ b $ "" stands for "" 2500 favor it in 5000 adults , "" then isn't $ pr ( b ) = 1 $ ?"
239473,what do you ultimately want to learn from these data ?
239016,can i ask how you identified your outlier ?
239337,"what is "" index "" ?"
239875,"notice that the spread is related to the mean , if there are no exact zeros , it's probably worth taking log ( y ) , and looking at that . it may also be worth considering log ( x ) , but it depends on what it actually measures as to whether that will also make sense ( if the origin is arbitrary , it probably doesn't ) . what do the y and x variables consist of ?"
239687,"could you tell us what "" contributed by "" means to you ?"
240263,can you clarify qualitatively what you want to measure ?
240424,"what do you mean by "" performance ?"
241218,"out of curiosity , why a bootstrap test rather than a permutation test ?"
241074,"your post suggests that a higher in-sample r ^ 2 is always better . be careful with overfitting ! you could improve your r ^ 2 by increasing the degree of the polynomial , but that would very likely be a bad model in the sense of having poor out-of-sample performance . what's wrong with your linear regression ?"
241672,"how do you propose to compute the distance between , say , the nearby points at $ ( -179 . 99 , 0 ) $ and $ ( 179 . 99 , 0 ) $ ?"
242115,"is your time series daily , weekly , or otherwise ?"
242451,"if your question also depends on software , why don't you include the information which software you are using in your post ?"
242408,is there a particular paper you can point to that is giving you trouble ?
242526,"in what sense is your model "" unstable "" ?"
243000,"do i understand correctly that you have a regression w / only 1 x-variable , which is centered , & it tells you you have a large condition number ?"
241912,why would you want to do that ?
242833,"* no * . ( please be more specific in your question , as it stands it is too broad . you need to clarify your situation as well as what you mean by the statement "" as an algorithm "" - as opposed to something else ?"
243077,where did you read this ?
243230,could you please clarify * how * you would use the bandwidth parameter to carry out a comparison of histograms ?
243155,"what do you mean by "" the independent ones "" and "" predicted outcome "" , simply variables ?"
243299,"how spread out the distribution is is a different issue . do you want to know if the expected rating is . 6 , or do you want to know the proportion of ratings will be . 6 ?"
243621,why you want two priors for a single parameter ?
243881,any penalty-based regularization works by adding a term to the objective function . so why not just include your penalty term in the objective function ?
243958,"did you run the algorithm twice or is it an ensemble of trees , i . e . two trees on the same set ?"
243995,why not try both and see what works better ?
243834,what is meq ?
244046,what do you seek to understand by getting 'variable importance' ?
244320,what are the distributions for the individual disturbances ?
244097,"since 90 . 28 % and 90 . 309 % differ by from the average accuracy of 90 . 284 % by less than one standard deviation , they cannot be considered significantly different . there doesn't seem to be any evidence of a problem . what , then , do you mean by a "" stable mean "" ?"
244295,possible duplicate ?
243800,what's the distribution of the number of events in 60 days ?
244657,is your question : hoe many times do you have to throw a fair coin to see them occurring with frequency * exactly equal * to 1 / 2 ?
245025,will each model have just 1 input variable & 1 output variable ?
245101,is this a point process ?
245144,"no not only , but * what kind * of dependence will you expect ?"
245208,couldn't you just add the constant data as another time-series with constant value ?
245548,"i think you need to more explicitly state what the question is . i think that you have used the data to bucket birds wing geometry into clusters by gender , and now you want to use that to do what ?"
245874,"subhash that is incorrect . nonlinear data transformations ( even continuous ones ) can change arbitrarily large positive correlations to arbitrarily large negative correlations . dqingqong : please explain what you mean by "" percentage changes . "" what are they relative to ?"
245798,how are you checking the the normality assumption has not been met ?
246161,do you have access to volume as opposed to share which would make forecasting much easier ?
246481,parameter estimation and hypothesis testing are * different * things . i never heard of such debate and i don't know what it would be about ?
246347,how did you get the estimates of the regression coefficients ?
246581,things may not be as bad as they seem . how does this 55 % correct classification compare with the proportion based on the actual dependent variable ?
246042,what is your setting ?
246927,you wanted a natural cubic spline ?
247260,"if you are doing principal components regression , then why don't you do partial least squares ( pls ) instead ?"
247281,"what you mean by "" normalise "" ?"
247294,"could you show some example data to give a feel for this , or at least give more details ?"
17050,you've never seen which form ?
247472,"what does "" close to diagonal "" mean ?"
247206,how can there be one ?
247094,can you explain why you want to do this and what other constraints there are on you ?
247623,are p and g independent ?
247625,1 . which answer did you see ?
120350,` i then assigned each document to a cluster based on cosine similarity ` - cosine between a doc and a centroid ?
248231,"for $ x sim n ( mu , sigma ^ 2 ) $ , $ bar { x } $ has a normal distribution not a t-distribution . . . but it's a distribution whose variance we don't know , since we don't know $ sigma $ . the t-distribution comes in when you standardize $ x $ ( or $ bar { x } $ ) using the estimate of its variance . see [ why does the t-distribution become more normal as sample size increases ?"
247605,have you checked the residuals ?
120642,it is not clear if the pressure in second eye was tested at each time period or only once ?
248418,"since you are the one doing the calculation , could you please tell us how you computed such a confidence interval ?"
248627,maybe you can explain why a t test addresses the hypothesis test you pose . i don't see it . it sounds to me more like you are interested in correlation or simple regression . maybe you want to test for significance of a regression slope parameter or a correlation coefficient . . you need to explain what you did in stata to get those results ?
246929,have you seen [ this ] ( url ) ?
248783,could you do pixel classification based on the patch surrounding the pixel ?
249761,"if each criteria is equal , why not alpha ?"
249461,"the error is self-explaining . package nlme supports only one value per combination of week / block / treatment . if you have repeated measures inside this grouping , you can't use it . do you have subplots ?"
250020,"you do care for endogeneity in forecasting . then again you contradict yourself : if you're forecasting , why do you care for t-statistics , that's inference thing ?"
17336,"does it help at all if you relabel things as follows : "" exposure "" becomes "" laziness score "" , "" outcome "" becomes "" bmi "" and covariate becomes "" gender "" ?"
250409,"could you explain what you mean by "" $ y = 1 $ "" and what the "" relative proportion of 1s "" might be ?"
250514,of course you are talking about central chi-square random variables . yes if y is chisq ( b-a ) ( where a and b are degrees of freedom ) . u will be chisq ( b ) . but is that the only way ?
194273,how do the box plots help you ?
250530,"it sounds like time series data to me . however , if your goal is "" music mood classification "" i am not sure if you want to do much with this . for example , "" major vs . minor key "" might not need this , while "" fast vs . slow tempo "" may be extractable without doing in-depth analysis . is this a clustering problem or a classification one ?"
250278,so what you're saying is that in your data set you have a column ( variable ) of correlations . and you're using that as a covariate in your analysis . is that correct ?
251172,welcome to crossvalidated kim . please give more detail in your question . what are the groups ?
251161,usually it's the other way around . is your validation set randomly drawn ?
251166,does the question include fractional factorials ?
251370,you don't have to re-run the tests to fix this . have you considered summarising the results by heart rather than valve and recalculating the confusion matrix ?
251410,have you checked url ?
251202,"what do you mean with _fitness_ of a model , you mean the likelihood $ p ( text { data } textbf { x } ) $ ?"
251566,"538 was predicting 90 % chance ( or something like that ) of winning for clinton . we have a sample of size one . there was a 10 % chance that trump wins , and he won . does this invalidate the model ?"
251304,can you explain why are you ruling out multivariate splines ?
251810,depends on what data you have available to predict apple sales . what does your data look like ?
250246,"i would not use that method , joshua . if you have a 3-d table , & you only want to know if rows are independent of columns , & don't care about pages , you could use the [ cochran mantel haenszel test ] ( url ) ( in ` r ` , [ ?"
252308,"just to be clear -- are you primarily interested in the 2x2 case or the general r $ times $ c case , or something else ?"
252633,can you please provide more information about your problem at hand ?
252741,?
252622,just stating that the curves are different would seem not to be of great interest because the differences are likely not identical across all values of the horizontal variable . would you not want to know where the differences occur and an estimate of the size of the differences ?
252834,please consider adding the self-study tag . have you considered url ?
253065,where is the variability here ?
253271,you need to provide more information about the quote so that we can see some context . do you know what conditional probability means ?
252566,this is way too general . what ann ?
253722,"for each combination of continuously adjustable parameters , can you conduct multiple simulation trials , each of which results in a sample error ?"
253863,by deep learning do you mean neural networks ?
253714,"i also think that you are confusing some concepts when you say : "" they usually used a combination of k-cross-validation and / or bagging with decision trees / forests "" - these are very different things . . . bags of words are a way to build features , decision trees or forests are models to represent the data , and k-cross validation is only a way to compute the accuracy of the approach ( it is not part of the model , only a way to quantify how well it works ) . what are the algorithm that you applied ?"
253839,what sorts of outcomes are you looking at ?
253973,don't the answers at url clear this up ?
253689,"conditional heteroskedasticity models are much more common with high-frequency time series , i . e . many thousands of time points . why don't you leave this effect out ?"
254173,"i don't know what you're talking about now . you mention normal equation , which is a terrible way to solve a least squares problem , but only applies to linear least squares , which is a convex problem . nonlinear least squares may be either convex or non-convex , but is not solved by normal equation , but potentially could be solved by karush-kuhn-tucker conditions . so what are you taking about ?"
254212,"if the medoids are pre-determined , why do you need cluster analysis ?"
251496,cliffab my understanding of the ops question is the same as yours . can you explain ( or refer me to ) why fisher scoring / iwls for mle would be slower than some numerical approximation for the above loss function ?
254357,to me the simple algebraic proof is satisfactory . i am curious as to why you seek a geometric demonstration or anything else ?
254381,"almost certainly . are these datasets from the same units ( eg , patients ) , or are they unmatched ?"
254544,also see : [ how can adding a 2nd iv make the 1st iv significant ?
192420,have you had any luck with this then ?
254595,i believe what you want would be a * prediction interval * for future p-values * constructed under the same conditions as the original p-value * ?
254586,"could you please explain what you mean by "" gradient "" ?"
254729,"what is the "" uncertainty propagation "" ?"
254695,"could you elaborate on why this result "" does not make sense "" ?"
254670,it sounds as if you would like to cluster your data and plot the cluster centers instead of all data points . could you upload your current scatterplot and add it to your question ?
254900,"the question is not clear to me . you already mentioned that you've three continuous variable , where does the last factor variable come from ?"
255041,is this a question from a course or textbook ?
255229,what if $ a = c = 1 $ and $ b = d = 100 $ ?
255126,"mcnemar is a test of difference between two paired / repeated-measures samples , i . e . between two variables . homogeneity chi-square test is a test of of difference between two independent samples ; which means that it an association measure between two variables - one taken as "" grouping "" and the other as "" response "" . for 2x2 situation , standardized version of chi-sq , the phi coefficient , is equivalent of pearson correlation coefficient . will that info help you to decide ?"
255502,"if you are running all networks simultaneously , wouldn't you have the same memory issue ?"
255738,would you be able to share this algebraic expression with us ?
255783,is this a classification problem ?
254370,"mathematically there are straightforward ways--i'm sure people will describe some in answers . i just wanted to point out that the values for the females appear to be hyper-confident : it is implausible that any population of birds , no matter how specialized , will exhibit values that consistent . i also wonder why it would be relevant to use a standard error to run a stochastic model . in some specialized circumstances an se could be used in a meaningful way , but for most applications wouldn't you want to model the * population * rather than * the uncertainty in your estimate of the mean * ?"
245104,can you elaborate on what your goal is with this analysis ?
256074,"see also [ in a poisson model , what is the difference between using time as a covariate or an offset ?"
256080,( 3 ) did you look at the residuals at each step ?
99446,do you have to use an svm ?
256429,is 100 the variance or the standard deviation ?
256550,"could you elaborate on what you mean by "" what is the rule "" ?"
256889,what do you think $ x_i $ are ?
256545,"if you don't want to make parametric assumptions you can always bootstrap , no ?"
245675,"what are the estimation results of a , b and indirect effect ?"
257199,which measure you care most for the final performance ?
242004,another interesting question would be : will mini batch order also has an impact on overfitting ?
257267,url ?
257454,can you display the scatterplot of the ranks ?
257550,no ; the standard error is * * not * * any individual difference or measurement for any individual sample proportion . the question is like saying what's the use of 50 mm standard deviation of people's heights if there are giants and dwarfs ?
257756,more common where ?
257769,seems like you need to define some specific researchable questions which is why you are probably here : p besides time spent for each document in each thread do you have information about each document being processed ?
257561,how can you be sure the variables are not correlated in any specific bootstrap sample ?
257999,what ann do you mean ?
258374,i am failing to see how plotting the distribution of the stats examines the assumptions of the data which the t-stat relies on . how does examining the computed stats help examine the assumptions of the data from which the stats are being calculated on ?
255422,can you say where you read this claim in relation to anova ?
258440,interesting . could you tell what drawbacks variance and other methods had ?
160019,jmb do you have a code to compute the bic for each model using glmnet procedure ?
244717,could you explain * how * you performed the model fitting ?
258711,usr11852 i'm curious about the reasoning behind training a classifier to learn the mapping onto clusters . could you elaborate on why you'd do this ?
259028,is this [ tag : self-study ] ?
259169,why does the result come out to be near 0 rather than exactly 0 ?
257775,"as i understand your question , you are planning a limited role for simulation in this matter , such that simulation will be used * only * to derive estimates of $ delta $ and $ sigma $ from your model of the drug effect . but why not go all out , simulating * the trial itself * all the way through to the individual-level outcomes for the $ n m $ subjects , the tabulated outcomes and the reported p-value ?"
259344,i think the question is rather broad but it seems in order . possible answers could be research papers and examples from various media . but where do you stop ?
171638,the two - why do you think they are either-or ?
258264,what sort of acceptance rate are you getting ?
256698,michaelchernick i got the impression that the first plot was ols with the questioner's manual ( maybe mistaken ) computation of the error bands -- or is first order ( i read this as not polynomial ) another name for deming regression ?
259588,why bootstrap ?
259367,i agree with mdewey . could you at least post an example of what it's supposed to do ?
259600,"i think you may need to give us some more details here . can you clarify what , in your use case , differentiates response from remission ?"
259890,"whuber but all singular values are positive , aren't they ?"
259398,"this is a good question , but note that such questions cannot logically be answered without specifying * useful for * * * * what * * * ?"
260042,why do you have two terms with the same structure ?
260026,"the derivative with respect to $ z $ implies calculating the derivative in each component of $ z $ . for example , the derivative in component $ z_1 $ is $ y_1 $ . can you finish it from here ?"
259754,can you just do a chi-square test ?
260364,"unless the view is taken that all hypotheses arise from pure thought alone , why shouldn't data analyses be accepted as a possible source of inspiration ?"
260523,"we could use more contextual information : in particular , * exactly how is the sample obtained * ?"
260637,what are you trying to do ?
260762,"what are the null and alternative hypotheses , and why are you performing a test ?"
260910,"the actual question is : is there any data where this works and is used , or does everyone simulate only ?"
260948,"if the patterns are known , why not just scan for these ?"
261096,"do you mean your network , when fitted on test data give you a regression of 1 in most cases for house prices ?"
261128,what are you using as software ?
40384,have you heard of [ halton sequences ] ( url ) ?
261040,how many tags are in the data ?
261491,"thanks for posting this as a question . while no proofs are discussed , you might be interested in : [ why do statisticians say a non-significant result means you can't reject the null as opposed to accepting the null hypothesis ?"
260955,how is randomness included in your model ?
232660,"frankly , the request for a proof - particularly for such an elementary case - looked rather like [ routine bookwork ] ( url ) , as might be set for an assignment , homework etc . . . which is why i mentioned an approach but did not give the proof . in what context do you require a proof outside of that ?"
261977,"mark999 , does it say why it defaults to true ?"
262087,"this the explanation in the [ website ] ( url ) : "" in the book we use the package aed to load data . however , we haven given up compiling a new version of the aed package each time a new r version comes out . therefore we no longer provide aed . "" is there any other way to get the package ?"
261877,how many pc's does it take to account for 95 % of the variation ?
262531,do you think your simulated numbers come from the same function as the real numbers ?
262899,the model with 10 dummies is apparently different model than that with 20 dummies . why would you expect same coefficients ?
15716,what is the purpose of fitting a curve to these weights ?
263244,"are a , b , and c independent ?"
263724,you'll need some measure of concentration or dispersion -- there are many . the nro variable -- are those unordered categories ?
264039,this is a different question . why not start a new question ?
204471,do you have a solid reason to think that your premise is actually the case ?
262584,yes . on another note : what you trying to compute ?
264063,have you been able to calculate the confidence interval ?
263766,why are you comparing to * random * normal data rather than comparing to a normal cdf ( i . e . why use a two sample test rather than a one sample test ) ?
264275,"i'm probably misunderstanding something , but what are you trying to get ?"
264362,what do you want to test ?
264594,"good start . next , you need to include more information . babies / females does not make any sense by itself . what is this ?"
239532,"hotelling is the name of a statistician and goes with capital latter . discriminant must be referring to "" discriminant function analysis "" and goes with lower-case . but what does ` discriminant hotelling ` mean - i don't know , sorry . do you mean hotelling as derivative from "" hotel "" : short-term provision of office space to a temporary worker ?"
264530,"how many images do you have , . are all of them labelled ?"
265179,"firstly , reporting something as not significant when your test says it is , just because your gut feeling disagrees with the test , is certainly wrong . you should report the results as you got them , although you are of course free to then qualify those with your own interpretations . to answer the rest of your question , i think we'd need to know a bit more about your data . in what way is there "" clearly "" no difference when you look at it ?"
88391,it would help to explain your notation : what is $ d $ ?
246853,"are you saying that the model works well on the data that was used to train it , but not as well on new data ?"
265859,are your hypotheses mixed up ?
265802,do you assume that you have all correct answers in your data for each record or just some of them ?
266126,"all you do is two coordinate independent random sampling z ( rand ( 1 ) , rand ( 2 ) ) . how is that a problem ?"
267044,alex . f keep following that thread . what if $ mu_a mu_0 $ ?
266775,fedrica fuci time spent on research activities - percentage on different classified fields or hours etc . ?
74013,maybe one approach is to ask the opposite question : when does the elastic net beat the lasso by a lot ?
267249,possibly of interest : [ should the mean be used when the data are skewed ?
267534,perhaps a good question for meta . what's the right course of action when an old but popular answer on a popular question has a small error in the code and what appears to be a figure generated from that code ?
268197,do we need it . . ?
268144,"kjetilbhalvorsen your comment is largely besides the point , if you the model is actually linear then why use a nonlinear model ?"
267691,are these non-overlapping data sets ?
268426,just a question . . . why ?
268358,so what ?
268401,why * cluster * at all ?
268289,so you have 9 groups and you want to compare all of them with each other ?
268754,what have you tried and with what success ?
266734,some more details : are $ s $ a $ 2 times 2 $ matrix ?
267600,it seems the method of solution is presumed . why the jump straight to conv-net and not something else ?
269624,why not just look at the last principal component [ s ] ?
269799,"cant you include a third category , "" case dropped "" , in your data ?"
269482,possibly . it depends on what you want to infer from your data . can you provide more info ?
270128,how about putting time on the x-axis and aggregate score trends on the y-axis ?
270910,"personally , i like it . but you're not just going to drop these symbols in out of nowhere , right ?"
271401,can you be more precise about what is the format of your data ?
271821,"what do you mean by "" relative importance "" ?"
271630,i think you need to discuss how group1 has zero values for response . do they represent a null set of some kind ?
271872,is your objective to estimate the mean of the $ y_i $ or is it to fit a linear model to the $ y_i $ ?
271875,are you inspecting the standardized residuals from the garch model ?
272014,"sounds like two have two categorical variables , and you want to test association . anything wrong with chi-square test ?"
272143,which group corresponds to x and which to y ?
272558,"if you were to remove the $ ( v_2-v_1 ) $ term , you would simply be computing the probability . if the $ 2 $ weren't there , what would the total probability work out to ?"
272766,what do you consider nice ?
272756,is the difference between two consecutive $ x $ 's here equal to $ 0 . 001 $ ?
272984,did you buy this book because it's required for a class ?
273261,"in a sense , yes , but have you considered reducing the dimensionality of the problem ?"
273304,"i think this is an interesting question so 1 , but i'd also be interested in why and how you think any within-resample-correlation would affect the ( t- ) test which is performed . have you performed simulations which point in this direction ?"
273377,you have an interpretation for the $ mathit { lnpopdens } $ variable correct ?
273312,1 . what do you mean by * granular * variables ?
274060,what is your definition of $ langle . rangle $ ?
274041,is or an acronym for odds ratio ?
274416,how did you get the pdf for x ?
274415,"two basic facts about counting votes : ( 1 ) different regions tend to vote differently ( 2 ) different regions count their votes at different speeds . in the united states , dense , urban areas tend to take longer to count their votes and tend to vote democratic . statewide elections in illinois can change depending on whether results from the city of chicago have come in . a simple [ straw man ] ( url ) would be that the mean of the first 80 % of the votes is the same as the mean of the last 20 % of the votes . but can the result be reasonably explained by geography ?"
274577,shouldn't [ datascience . stackexchange . com ] ( url ) be on the list ?
274733,what is your exact question ?
270603,"it all depends on exactly what you mean by "" better . "" for instance ( continuing your example ) , if by "" better "" you mean * lowest possible standard errors in the estimated coefficients * and there is just one explanatory variable , then the optimal solution takes 12 measurements at one extreme of that variable and the other 13 measurements at the other extreme ! could you therefore elaborate on what * you * mean by "" better , "" "" best , "" "" optimal , "" and "" more powerful "" ?"
275009,"math courses and gender are the explanatory variables , but what is your response variable ?"
274325,what data do you have ?
174416,you want to determine 95 % ci for what ?
275396,"roc curves aren't defined for multinomial classifiers , so your question makes no sense at all to me . are you actually asking for ways to convert multinomial classifications so they can be used for roc analysis ?"
275670,what variables are used as predictor variables in the regression ?
275564,"1 . this is a slightly weird approach to mle . typically , you don't integrate over the space of parameters over which you are optimizing . are you sure you want to be integrating here ?"
190984,"your question is very valid , and has been addressed a number of times from different perspectives on cv . the duplicate nature of these tests is puzzling . it's easy to say anova = linear regression , and i do think that all the comments made so far are helpful and on point , but the reality is a bit more nuanced and difficult to understand , especially if you include ancova under the umbrella of analysis of variance . check other entries , such as [ this one ] ( url ) . i'm 1 your question , although it is , strictly speaking , a duplicate . can you give an ex . ?"
272260,perhaps you could add a picture with the output ?
37993,a sample size can be substantially smaller than 15 if the assumptions hold . was the validity of the t-distribution the only reason he suggested a larger sample ?
277125,"i do not get this analysis , or i am missing something . if the six tiers of shares are just a binned ( aggregated ) version of the continuous share variable , what is the point ?"
276831,obligatory link to a . gelman's blog-post on [ what are the key assumptions of linear regression ?
277373,how do you propose to remove the correlation ?
277403,"is your question truly "" fully general "" or do you have a set $ s $ in mind ?"
277318,"you mean * piecewise * linear , right ?"
277269,erm . . . is there a problem with considering a parametric test ?
277153,zahavakor i don't see it says anywhere it's random ?
277779,what's excess kurtosis of the data ?
97689,"if your variable is a "" coarsened "" latent variable , then i would agree . but take bond ratings . there's an underlying latent variable called creditworthiness that some agency has divided into many bins , which range from aaa , aa , a , bbb , and so on to d . you can imagine coding these as 12 , 11 , 10 , . . . . but you could just as well use another coding scheme . which one should you use ?"
278181,"what do you mean by "" evaluate "" ?"
278271,the integral $ int_0 ^ t e ^ u / ( e-1 ) du $ is very much not $ e ^ t / ( e-1 ) $ . how do i know that without doing anything ( even pretending i don't know the answer ) ?
278217,"well , whether your data are the entire population or just a sample from the population depends on whether your data are the entire population or just a sample from the population . were your laboratories sampled , or do you have data from all labs ?"
278407,"why not concatenate them and then add an a variable for day , where day = 1 , 2 , . . . k = 20 ?"
278416,sounds very interesting ! ! ! can you give more insight with an outline of what are the random variables you are trying to model ?
278295,"it depends on what you mean by "" higher maths concepts . "" should we stop at arithmetic ?"
278515,"another question . why are you drawing two random samples of 10 , 000 ?"
278657,do you mean that your data is a 8x3100 matrix ?
278746,isn't the whole point of getting a lot of observations that you can resolve even small differences in the means ?
248019,did you ever find a solution for this ?
279442,"you probably know that as sample size increases , the variance of the ols estimator decreases . that is not surprising : given more data we can estimate the model parameters with higher precision . so what is the puzzle ?"
279374,where did the percentage come from ?
279615,that argument is nonsense . what is a convenience population and why would emulating it lead to a margin of error ?
279850,micha why not ?
279970,"even without the important issue whuber raises ( that the s . e . of the intercept depends on the origin of your x ) , intercept and slope parameters aren't even in the same units ( one's in units of y the other is in units of y per unit of x ) . . . so how does "" wider "" even come into it ?"
280054,why does small uncertainty mean that you need to do something else ?
278289,"this seems mostly a matter of psychology , so let's ask about your awareness : have you considered that a "" state "" can be a very rich and complex thing ?"
280383,how did you get this data ?
279913,what in particular you did not understand ?
281004,is this a question from a course or textbook ?
281045,"individual points can't be "" skewed "" . and with 80000 it wouldn't be unusual to see observations more than 5 standard deviations away from the mean . are you sure you want to do this ?"
281198,"with a constant % cv , working with a log transformation of the dependent variable might help . then in the log-transformed scale , errors are independent of values . have you considered that ?"
281321,"yes , that can be done . i suspect you might not find it satisfactory , though : the approach can produce unusual joint distributions . you have a lot of flexibility to specify many more properties of the distribution you are looking for . could you explain the ultimate purpose of this exercise ?"
281883,""" combine more variables into one . not sure what to call this one "" "" feature aggregation "" , perhaps ?"
281857,"this question appears rather broad , vague , and subjective : "" simple "" in what sense ?"
282208,""" is it valid to take df / dt vs df / db "" what do these symbols mean ?"
282271,"what does the "" uncertainty "" represent , exactly ?"
282269,"please explain what you mean by "" using the tests like t-tests etc are givings unexpected results like the relation which is not actually significant becomes significant "" . . . how can you tell it's "" not actually significant "" ?"
282177,* which * chi-square test do you wish to apply ?
283282,i would be most concerned about non-randomized assignment of patients to treatment . how do you plan to control for that ?
283316,do you have a test statistic and a rejection rule ?
283290,"for $ beta $ , wouldn't be the same as for linear regression ?"
283630,"1 . under "" 2 ) "" . . . how did you get from the first line to the second ?"
236637,kodiologist but why would frequentist do that ?
283694,could you explain why in step ( 2 ) you are proposing to apply a standard * normal * distribution as a reference for residuals that you assume have a * student t * distribution ?
283762,"you don't give any reason to do this , particularly multiplying x and y , let alone an arbitrary function f . without more information the answer has to be something like "" might be , but probably not . "" one might find this useful , but i don't know how . why multiply and why use f ?"
283932,"1 . "" for a normal distribution , the unbiased estimate of variance better approximates the true variance , than the mle . "" . . . what is the basis of this statement ?"
283381,tiip ?
284071,"it's not clear to me what you mean by "" explain the results via an anova "" but any calculation you're planning to use an anova for can be done within the glm framework . ( if you're using a glm how could the anova assumptions hold ?"
284464,i believe my answer at [ why are all known distributions unimodal ?
284769,"i am kind of confused here , do you only have the max and min for your data , or do you only want to use those two values ?"
284774,what exactly is your question here ?
87465,"when you say $ { 0 , 0 . 1 , , 1 } $ do you mean the data is all multiples of 0 . 1 , or something else ?"
285089,what data do you have in the ceilometer logs ?
284990,"the phrase "" contour is linear "" is so specific and unusual that i would like to confirm its meaning . to me , it means that all sets of the form $ m ^ { -1 } ( c ) $ for real numbers $ c $ are either empty or are lines . if that's the case , then $ m $ can be written $ m ( x ) = f ( x beta ^ prime ) $ for some fixed vector $ beta $ and arbitrary function $ f $ * of one real variable . * is this what you mean ?"
285023,the usual way is from the hessian . what's the conditional distribution ( given $ t $ ) of the angle in your model ?
285210,""" effect of the predictor "" * relative to what ?"
285486,are you assuming that $ lambda_d $ and $ lambda_p $ are known ?
285584,i'm not sure this question has a better answer than laplace and gauss . are you sure that the refinements on the method since them haven't been gradual ?
286203,what exactly is the hypothesis you're trying to test ?
286236,""" they are strongly correlated with each other ( r ^ 2 . 75 ) "" these should not be considered as different independent variables . i would probably just average across them , no ?"
286580,you already have a good answer . a few points to note : what is non-significant ?
286011,are you interereted in anova or regression ?
286374,"let's back up : what do these data mean and what questions do you hope your "" monte carlo method "" will answer about them ?"
26323,"non-linear models are a vast area . i suspect you might also be interested in patterns recognition which is a close cousin of non-linear modeling when applied to forecasting . can you make the question more specific , maybe with an example of your problem ?"
286856,could you elaborate on the difference between your use of classification vs . prediction ?
287045,are you using the coefficients without regard to their standard errors ?
287221,are all other relevant assumptions fulfilled ?
287176,in what context ?
287378,"jotadepicas you mean each epoch you shuffle from the whole datasets , so the validation data may appear in next train data ?"
287343,why do you want to split it ?
212325,what's the data ?
286324,are n and m the parameters you are trying to estimate ?
287488,can you be more specific about what you mean when you say it does not work in your first example ?
106158,that depends on your model for the states . is it linear or nonlinear ?
250332,""" it is not possible to combine different activation functions within a neural network "" -- you mean that it would lead to a decrease in the network performance ?"
288082,"i believe i just did . why not work through a few tiny examples explicitly , such as $ u = 1 , 2 , 3 $ ?"
250072,"you created two new tags without wikis . i think it would be a cleaner approach to avoid that . also , what about quantile regression , doesn't it fit here ?"
287771,""" how do we know "" is vague . are you asking about how to * estimate * the $ u_t $ or about their * meaning * and * interpretation * ?"
164304,"zacharyblumenfeld : you are right that the state variables are estimated by mle and when the parameters are also unknown then maybe em etc is used . so , what is the motivation for choosing kalman filter when the essence of it is mle . moreover , mle can be used to estimate nonlinear functions as well , then why to use ekf and ukf ?"
288883,how many houses and events you have in each interval in model 2 ?
288596,"markov models ( hidden or not ) are generative , so the whole setup is different ( rnns are discriminative ) . this is a bit like the discussion of neural ( "" predictive "" ) word embeddings vs . the traditional distributional ( "" count-based "" ) models . and overall , to me at least , it is not entirely clear what kind of insights you are hoping to get from an answer to your question ?"
288975,"well i stand corrected ! i guess that makes sense , it's the operation of subtraction that causes the rounding . why not answer his question ?"
288785,where did you read that gp is parameter-free ?
289225,would it not be better to just refer to the relative efficiency of your estimator and the sample mean ?
288747,"can you confirm that r is storing your factor variables as "" factors "" in the dataset ?"
291111,""" if you're absolutely certain of predicting it correctly "" can you elaborate on how would you be absolutely certain of predicting something correctly ?"
291121,( do people in your area do power calculations before collecting the data ?
291065,"from reading your code , it looks like you create an array of 180 & 3 then you use gmm to find the cluster centers , is this correct ?"
291230,had a higher proportion of b than what ?
291308,are the values binary ( 0 or 1 ) ?
291196,neither display is easy to read ( on my machine ) . how do you show negative values on a logarithmic scale ?
287877,can you find a value of $ g ( theta ) $ to make the density function a valid one when $ theta = 0 $ ?
291449,1 . your title talks about standard deviation but your body text talks about mean . can you relate the two more clearly ?
103521,"when you say "" could be chance "" about 2010 , what do you think is the likelihood that most of the predictions would be correct by chance ?"
291614,what are the sizes of the residuals ?
291961,can you link to such claims on cv ?
291725,"what does the phrase "" * central mean * "" mean ?"
292306,"what do you mean by "" regression between different groups according to altitude "" and "" if using just lm is meaning for my case "" ?"
292369,"in other words , you're looking for patterns in the signals , correct ?"
292407,"yes . pick some causal arma ( 1 , 1 ) model and try to write it as an ar model . how many parameters does it have ?"
291304,can you say a little more about the structure ( if any ) of the messages ?
292727,possible duplicate of [ when is unbalanced data really a problem in machine learning ?
292708,"it's unclear how you are thinking of using winsorizing in a least squares setting . would you winsorize the regressors , the response , both ?"
293946,what do you mean with normalized ?
201503,i would be cautious using conjugateprior's recommendation . this is highly dependent on how the data were collected and sampled . was a simple random sample ( srs ) used ?
269031,is your question about how to calculate the difference between probability distributions ?
290589,"but i am very disturbed by the statement that we should remove "" outliers "" from the data . how would the results have any meaning or integrity if you just remove data that don't fit some pre-conceived distribution ?"
294532,do you know how to do hypothesis testing for parameters ?
282844,is your dataset unbalanced ?
294702,i suppose there is also an id variable that determines the specific car ( i ) ?
294729,"what is "" mixed data "" ?"
294400,"if you start with a particular definition of "" kernel "" , such as [ "" a symmetric positive-definite operator , "" ] ( url ) then this result is immediate ( and trivial ) . you must therefore be using some other definition--but what would it be ?"
139863,"to be sure : you are trying to find sets of posts given a topic , instead of topics given a set of posts , right ?"
295067,why are you transforming your variables ?
295146,"there is no agreed upon importance measure for predictors in a model , and the t statistic is not meant to be used in this way , the use of it in this way in carat is a dubious decision . indeed , variable importance is just a slippery and borderline undefined concept . so heres a question : if i told you a measure , what would you use it for ?"
280316,what is the purpose of averaging ?
295160,when we're talking about discrete distributions such as bernoulli or binomial the ks . test can tell you nothing more than you already know ; there is a yes or no answer to whether or not they can be used . what kind of glm did you have in mind ?
295417,now solve the system . what do you get ?
295362,"if those are your research questions , why not just compare the % ages using , for instance , t tests ?"
224190,where did you see that theano is still in the beta phase of development ?
295626,how * many * trees do you think you will have that split the training fold well ?
294906,"the vignette ( url ) adds a little clarity : the metric is the mean importance * weighted by species r2 * . however , i fail to see how a negative r2 would become positive based on weighting alone . are both metrics calculated the same way i . e . by conditional permutation ?"
295987,oh my . interesting question . how many data points are there in your dataset ?
295992,do you mean that you are bootstrapping a null distribution twice from the same data ?
296394,is $ lambda $ fixed ?
291715,why would you need to test anything ?
296572,what is the difference between a banana and fruits ?
296527,do you have a particular source of data in mind ?
296127,do you expect age at t = 0 to have a proportional effect ( over time ) ?
287690,can you post your architecture of the network ?
297075,why not ?
297150,what association are you looking at and how do you want to interpret them ?
295246,does my answer help ?
297023,can't you draw trials from the posterior distribution of your parameters after the vi ?
297380,""" why not come up with . . . ?"
110576,"think a neural network as a collection of matrices describing the connections between nodes . now , read * carefully * matlab documentation also playing around with a basic neural network . now , as example look at the definition of ` inputconnect ` : "" if net . inputconnect ( i , j ) is 1 , then layer i has a weight coming from input j , and net . inputweights { i , j } is a structure describing that weight . "" do you start to understand the right way to create your own neural network ?"
297586,what is the goal of your analysis ?
297810,"you appear to have only three data points : the rest are values that require interpolation . unless you can provide very strong and definite assumptions about how ` growth ` should be related to ` meal ` and ` temperature ` , there's little you can hope to do . since you tell us you don't have any "" function or model , "" it would seem this question is unanswerable . would there be any other information you could provide ?"
297718,"you're interested in regression , not interpolation , right ?"
297073,does this paper help at all ?
297581,"glen_b i usually imagine logistic regression as a regression model for the probability of success of a bernoulli rv , as a function of some predictors ( in this case ` species ` and ` dose ` . instead than successes or failures , here what we measure are counts . . . i'm not saying that using log reg is wrong here , but could you explain me how this connects with the idea of modeling a bernoulli-distributed response ?"
295745,"if you see what happens to a after a sudden change to d , and you describe that in the language of statistical models , then i don't see what could be going wrong . what do you mean by "" regularly disrupts the model "" ?"
298318,are the balls distinguishable ?
298467,""" if p is = 0 . 05 then we accept h0 "" don't do that . if you fail to reject the null hypothesis , you haven't obtained any evidence that there is no difference . "" if grade is associated to group , then it can be said that the groups are different in some way if they are producing different results ?"
298805,are you speaking of discriminant functions values or of fisher's classification functions values ?
298904,"using year as a contrast variable is common when your goal is to find the effect of the other variables without taking into account the "" yearly "" effect . when doing such an approach , you need to predict this effect after . e . g . if you did a glm , you need to find the coefficient for 2014 . you may rely on your past observations ( is there a link between a coefficient and the one of the previous year ?"
298928,why is your last data point 40 ?
299012,we can't comment on your grounds for expecting a normal distribution ; what difference would slight non-normality make to your project ?
299130,"nonparametric approach , like wilcoxon test , maybe ?"
298131,what problem would generating new data solve ?
299308,what is the variance that you are analyzing ?
298734,what is $ d $ ?
299612,"parts of your question make no sense . in particular , since $ p_x $ and $ p_y $ are parameters--not random variables--you don't estimate them ; you just compute their ratio . although you introduce random variables $ x $ and $ y $ , you never use them or ask about them . this all suggests you haven't succeeded in asking what you intended to ask . could you please clarify your question ?"
298917,so what is the question to people ?
34970,"could you elaborate on "" then the $ l_1 $ term doesn't have any effect ( because $ x _1 = 1 $ by fiat ) "" ?"
299519,what are important variables too you ?
299312,what does it mean to hope to minimize the confidence interval of the parameter ?
299673,how would you compute the conditional probabilities in question if you do not already have a fit logistic regression ?
299792,hint : don't you think the standard errors of the estimates ought to have * something * to do with the response vector ` y ` ?
219200,are you asking how to to calculate the estimate of $ p $ from these data or are you asking how to derive the formula for the mle ?
299443,"it seems a little artificial and perhaps biased in the sense that your "" manufactured "" labels are the result of some function $ f $ you have defined ; hence , the learning problem is simply to approximate $ f $ . if you could do this , why not just directly categorize / cluster them based on that $ f $ , rather than add the extra step ?"
300144,"ambesh : yes , i was not sugesting the prediction in order for actually doing the prediction but in order to figure out exactly what you want : to find some deviance between the 'expected normal' behaviour [ the prediction from the past ] and the actual behaviour [ the values you have observed ] because according to what i understood you are looking for this criterion . . . how do you want to say what the 'normal' behaviour is otherwise ?"
300297,what is your aim ?
300157,"could you add a little bit more background to your question , such as whether you are considering the tabular forms of these dynamic programming techniques only ?"
300187,* a probability density is a function mapping each element from the sample space of the random variable to the reals . * are you sure this is correct ?
300486,"autocorrelation appears to mean here some kind of feedback loop , whereby employees with better qualifications get higher salaries , which is self-perpetuating ( how ?"
300527,"your question raises many red flags for me , because all these procedures appear likely to bias any subsequent analyses . could you explain why the measurements are integral , how negative values can arise , why double values need to be eliminated , and why unusually large values ought to be considered suspect ?"
300412,do you know what the minimal sufficient statistics are for these two cases ?
300612,"then i'm even more confused . if $ g $ is an * arbitrary * operator , what does $ e_f [ g ( x ) ] $ mean ?"
298861,how would you force someone to quit game a in your experiment ?
300837,with options being what exactly ?
300892,"i think the premise of the question is wrong ( i . e . your characterization of how the argument goes is not a suitable nor a typical argument for hypothesis testing ) . i don't think either fisher or neyman and pearson make the claim that if $ p ( d h_0 ) $ is small , so is $ p ( h_0 d ) $ ; indeed that reads like an argument a bayesian would use to suggest there was a problem ( which if it's not how the proponents make the argument , would be something of a straw man ) . where does this argument come from ?"
300530,it looks like your model is learning the thermodynamic function just seems like it hasn't gone through enough iterations . have you tried bumping up the number of iterations / epochs ?
300999,"what do you mean by "" having the jacks "" ?"
301349,there is also an implication that linear regression may not be a good choice for you . could the response ever be zero or negative ?
300388,"yup . i'm with mdewey that more information is needed . for instance , what is the source for your data ?"
289371,could you give an example of your data inputs and desired outputs ?
205561,"but you are not using both percents in the analysis , are you ?"
301646,"nothing wrong . you had one correlation for $ ( x , y ) $ and a different correlation for $ ( f ( x ) , g ( y ) ) $ , where $ f ( cdot ) $ and $ g ( cdot ) $ are some functions . why should the two correlations be the same or even similar ?"
301742,"given that the 10th percentile is 2845 , the 50th percentile is 7482 , and the 90th percentile is 13390 , what percentile is 6096 ?"
301754,so what ?
301990,please clarify : are you comparing the orderings of the two classifiers with each other or with the human expert ?
302044,is this work for some subject ?
302263,"can you clarify whether you are talking about ( a ) clustering images with similar images based on their colors , or ( b ) clustering similar color regions within an image ?"
302166,what do you mean by each class was taught the same lesson type ?
302716,"i'm afraid i don't think that's clear at all . do you mean "" processed "" rather than "" processes "" , for a start ?"
302398,could you explain your likert scale more please ?
302792,"what do you mean by "" smooth predictors "" in your second sentence ?"
303052,is there anything * other * than black or white going on ?
303199,"it might be best to use a mixed model , using subject as the random effect with the rest as fixed effects . repeated measures anova is not going to work with missing values ( you would have to exclude subjects list-wise ) . can you give the specific example of the data you are working with ?"
302623,so what ?
303523,where did you find the formula ?
303742,"it's an attempt to apply the definition of "" $ e sim n ( 0 , sigma ^ 2 ) $ "" . all that's needed is to plug $ e = y- ( x ^ prime beta alpha ) $ into the usual formula for the normal density . somehow $ alpha $ was omitted--but isn't it obvious where it belongs ?"
304507,what hypothesis is this p-value testing ?
304790,what is your purpose in fitting the regression ?
305116,do screwdrivers make hammers obsolete ?
305134,how is that not what your doing if you are using fake data to fit a model ?
305990,you seem to be asking for the impossible . is the discrepancy large enough to be of concern or not ?
305973,"please edit your post to clarify that point . it currently states "" components "" --in the plural--pass through the centroid , but now you seem to want to ask only about the first one . i am curious what blogs you refer to , because it is definitely not that case that any component must pass through the centroid . are you sure you are remembering them correctly ?"
306266,"what are your "" other models "" mentioned in last step ?"
306619,"as you intimate , the sense of "" non-randomness "" is * psychological * . i would suggest it is * purely * psychological . repetitions , forms of symmetry , etc . , are categories imposed on perceptions by the human mind : they are not properties inherent in the number sequences . how , then , could we hope to solve this problem without obtaining relevant data ?"
307156,why is it not legitimate ?
306428,"upvoted the answer , but why would you fit a gam to 20 data points anyway ?"
307293,"since we're not taking about physics but numbers ( and often , numbers representing a * non-physical * quantity ) , what is the intent of the word "" physical "" in your question ?"
307276,"how are you determining the ridge penalty parameter , and are you eveluating your model on a properly held out data set ?"
307808,so the idea is that all 50 ids share a similar predictor-response relationship ?
307445,do you know anything about the quality of the originally fitted model ?
307871,are you referring to mcmc here ?
303284,"why are you using 1 , 2 , 5 , 11 ?"
307776,did you mean to type beta instead of theta ?
308623,what are your goals ?
308744,why are you trying to do a z-test in this situation ?
308581,"amoeba , post as answer ?"
309101,what is the sample size here ?
309318,could you show us where the problem provides information about the chance that a swamp fever victim will have all four symptoms ?
309408,it is not so difficult to try that out is it ?
309398,"what's your architecture , loss function , activation functions , etc ?"
310003,"whuber that "" since then "" is particularly bad . have you ever considered writing the authors of these texts ?"
310249,why wouldn't you ?
310039,"i will post an answer later . but i have a question in the meantime , just because i am curious about how these questions are born . in what type of context did you get this question ?"
310255,can you point to the source of the question ?
310549,your guess is not right ! what is the value of $ lim_ { n to infty } left ( 1- frac { 1 } { nx } right ) ^ { n } $ ?
310932,how do you determine what data is an outlier ?
311023,"if there are two groups of participants , and the manipulated variable has two levels , how does the outcome variable look ?"
311397,"this appears to be home work . please add a self-study tag and descripe , what your own thoughts on the matter are . analysis of variance can check different groups for differing means . is your question about means ?"
311496,"there is the 'no-free-lunch' theorem stating that the error a concrete predictor $ f $ makes must be 'big in average' , i . e . for a given learning strategy we can find a distribution $ p ( x , y ) $ such that the learning strategy fails miserably ( is arbitrarily close to guessing ) . in general im unsure about the nature of the question : i ( x , y ) is something that does not involve neither $ f $ nor tha strategy how to build $ f $ . . . so , what do you mean ?"
311840,"i'm a bit confused about the tests you did . when you say fine-tuned , do you mean just trained ?"
19952,maybe fit a kernel density estimate for your data and estimate the mode as the peak of that ?
276414,1 . which model ?
311742,"what do you mean by "" relate "" ?"
312011,"clarifications needed : do you want to filter the signal ( get the best estimate as of the latest sample ) or smooth it ( extract the signal at points in time after you have acquired points both in that point's past and future ) . do you know any signal parameters ahead of time -- e . g . , slope & intercept during the linear period , or parameters in the exponential period , or is just the form assumed ?"
312635,is this a meta-analysis of already-completed studies found elsewhere ?
312711,"if i understand correctly , then you are looking for an entire * time series * of "" similarities "" . if so , then why is the simple series of differences not enough ?"
312803,does [ this ] ( url ) help ?
312719,how would that even be possible ?
126498,"can you say more about what you mean by "" expect to get 375 items every time "" ?"
310432,possible to post a data set ?
312761,"why do you need a "" definition "" of medium vs . large ?"
314236,why is that interesting / useful ?
314152,"could you clarify what an "" f-distribution "" is ?"
314389,"the message is that attempting a transformation with many 0's is pointless ( "" you cannot make discrete data normal "" ) not that it's not needed . it's unclear what you're doing that means it requires transformation . please respond to my second comment above ; in the absence of discussion of those issues , it's difficult to say much of value . why are you trying to transform something with many 0's ?"
314173,"what do you mean by "" empirical distribution "" ?"
313957,what is importance here ?
314553,"there seems to be some confusion expressed in this question : the chi-squared test does not minimize a chi-square statistic . it merely computes it and compares it to quantiles of a suitable chi-square distribution . the "" reasonable assumption "" about the uncertainties makes no sense in this context . the characterization of an optimal $ lambda $ makes little sense , either , because it corresponds to an infinite set of simultaneous equalities for $ n = 0 , 1 , 2 , ldots $ . could you clarify what you mean by "" uncertainty of the frequency "" ?"
313330,testing difference in proportions is not the same thing as goodness of fit ! which of the two you want answered ?
314859,why do your beta distributions have 4 parameters ?
314998,why not let the algorithm figure it out ?
315663,but what if the best fit for the given data set actually is at $ hat { beta } _1 dots = 0 $ ?
315124,do all nodes have a feature vector of the same length ?
316103,"1 ) why not just include v6 in your model with v4 , v7 & v1 ?"
311744,"i'm lost : ( 1 ) what is "" poisson $ ( k lambda ) $ ?"
316530,"you did not describe your data well , i think . how does it look ?"
316976,do you have data to show for example how many times it ; s goes with location and how many times it goes with organization ?
317037,"what do you mean "" wired values "" ?"
317314,"reading "" deep learning "" by goodfellow , bengio , and courville perhaps ?"
317342,"you should provide more information about the process underlying the tweets to determine if there is a test that would work . do you view the tweets as coming from a fixed location with some sort of measurement ( boy vs . girl , type of tweet , time of day , etc . ) ?"
316051,are the sequences independent ?
317491,where do you get the inequality in your last expression ?
317335,is the measure used in the randomization scheme ?
283685,have you considered doing your analysis in a bayesian framework ?
317613,"do you mean ( a ) using mle when the assumption of normality is not met , or ( b ) using non-gaussian likelihood function ?"
317684,depends on your current level of knowledge . do you already have a solid foundation in linear least squares modeling ?
318192,"you would usually log-transform your data ` x ` if you can safely assume that the underlying probability distribution of ` y = log ( x ) ` is normal ; you can then use a linear model with normally distributed residuals for a downstream modelling / prediction analysis . the fact that you have negative values suggests to me that this is not the case . could you please clarify , what is the rationale / justification for log-transforming the data ?"
318109,is rainfall explaining population ?
317958,do you want a simultaneous confidence region for several coefficients ?
318355,"are you familiar with the "" 8 schools "" example ?"
318256,are deliberation and rulef deliberately not correlated ?
318962,as i look at the curve it seems that rf is consistently closer to the actual when compared over all the data points . i would go with rf wouldn't you ?
319113,"would it help to score it 2 , 1 , 0 , 1 , 2 instead of 1 , 2 , 3 , 4 , 5 ?"
319255,what is the purpose of finding a simple density that fits your data ?
319085,"sorry if i missed it , but what exactly is the main difference that is confusing you ?"
319566,"by definition , no , you can't have cointegration between stationary series . so , why did you run the test ?"
319638,have you heard of the central limit theorem ?
319480,"well , you realized * just now * that you cannot delete other people's comments in your question ?"
319747,first question - why do you need normalisation ?
199139,"boosting is based on weak classifiers . theoretically , any weak classifier that is slightly better than random will do . in practice different algorithms are more suitable to some datas set so the weak classifier you choose is important . can you specify more about the algorithms you used , their results and the data set ?"
319561,"out of curiosity , let's say after 100 , 000 samples all 317 model weights have converged . what are you planning to do after that ?"
319774,"what does it mean to calculate auc "" with "" variables ?"
320072,"have you considered just , not rebalancing ?"
319801,and 8x not 8x ^ 2 ?
320457,"did you make the variable a "" factor "" in r ?"
319928,"regarding your first question , a comparison is impossible because they do two different things . most likely you'll need both--you'll need to estimate the parameters with some mcmc procedure ( either of those 1990's papers ) and then use those estimated parameters to run particle filters on live data . and when you say var are you talking about vector autoregression models or value at risk ?"
320790,is your question simply how to classify this design ?
321061,have you looked at normaility tests ?
321157,patternrecognition then i would first make absolutely certain you really are the first person to ever translate * regression * to that language ( seem unlikely no ?
321147,you'll have to be a little more specific about what you're trying to do with minibatches . are you asking about minibatch training ( e . g . minibatch gradient descent ) or something else ?
321754,"please explain what you mean by "" double the size . "" do you prolong the time period during which you collect data until it is twice as long ?"
321787,"it seems adding latent variables hurt the model . maybe , there is no linear relation , did you try using regularised regression models ?"
68276,why ?
322188,what's the problem you see with weighted least squares ?
322902,say they are bimodal perhaps and then give the modes ?
322921,how does linear regression reduce dimensionality ?
323326,"well , what are you going to do with the scores ?"
322712,how do you know it's mcar ?
323836,can you describe these data in any greater detail ?
317760,and why do you even need that ?
323929,do you know practical cases in which all the components are kept ?
324145,"it's a bit unclear what you are asking . when you say multicollinearity , you must mean multi-correlation , since lasso still fails to find a unique solution in the case where there is a strict linear dependence between predictors . with that said , what exactly do you mean by "" address multi-correlation "" "" ?"
324423,how would you define residuals any way ?
323509,"to formulate it as a rl problem , you need to ask youself , what is the mdp ?"
324185,"are you looking specifically for confidence intervals , or would you be interested also in credible intervals ?"
324963,"do you know the definition of "" complete statistic "" ?"
325026,are your data images ?
325190,"the meaning of this equation is explained ( without any mathematical demonstration ) at url could you explain what it means to be "" stuck at the very beginning "" ?"
325318,according to your code you model species ~ temperature ?
325365,"if you are doing simple linear regression , why do you have a learning rate etc . ?"
325107,"nice question . on general principles , adding noise is a poor idea : why degrade your data in order to apply some procedure that might not be appropriate for those data ?"
326112,"wait , how can you extract causality from logistic regression coefficients ?"
326131,what is the chance of occurrence * precisely * at time $ t $ ?
326353,what happens when the sample mean of the $ x_i $ is zero ?
314908,"the clipping changes the objective function and its gradient , or so it appears to me . why do you say otherwise ?"
326428,"that information changes everything ( btw , likert scales are 5 point , not 7 ) . with scaled metrics like this the issue isn't one of * skewness * but of * end effects * . as such it becomes a psychometric property of your data . is your dv some kind of measure of satisfaction ?"
327220,how do you obtain $ e [ x ^ 2 ] = 0 $ ?
327152,if you have logits have you back-transformed them to proportions ?
326457,"some questions : 1 . what do you mean precisely by "" condition "" ?"
327295,"is this a question about the mathematical relationship between the distributions of $ x $ and $ log ( x ) $ , or is there more to it ?"
327573,"don't confuse "" never married "" with "" not married yet "" . do you know the age of the people who are coded as "" never married "" ?"
326907,so before running linear regression you would use machine learning algorithm to test the assumptions of regression . ( 1 ) what than would you use to test the assumptions of the ml model . . ?
328422,did you try skewed student t ?
328401,"sorry , i don't speak physics . what's an "" mc "" ?"
44788,"if you assume your distribution is gaussian , it doesn't matter how many moments you have calculated : the first two moments provide good estimates of its parameters and they are the most stable of the whole collection of moments . so what specifically do you want to assume about your distribution ( and why are you bothering to compute high moments in the first place ) ?"
329188,"that depends , is this paired data or not ?"
329586,what do you mean by the datasets cannot be mixed ?
329624,it looks like your dv is ordinal . is that correct ?
329051,might this contain the answer you are looking for ?
329637,why don't you calculate the coefficient of variation on the relevant portion of your data ?
260605,"if "" statistical physics "" means what it sounds like , your question likely belongs elsewhere because it's about * physics . * but of course the presence of "" statistical "" suggests it could be on topic here--depending on what this field means to you . could you elaborate ?"
330412,what does $ eta $ refer here ?
273281,what is the question here ?
37461,many undergraduate textbooks on _probability_ theory mention all the above results ; but perhaps _statistics_ texts do not cover these ideas ?
331099,why would we limit ourselves ?
330948,"what would constitute "" determin [ ing ] how similar "" they are ?"
331253,do you mean this map in $ n $ dimensions ?
327937,the question is unclear : what do you mean by a pool of sample ?
331372,do you have a research hypothesis ?
331404,and how many age groups ?
330956,do you actually know the functional relationship ( s ) between your inputs and your output ?
329818,do you have a link to the paper ?
331416,"what do you mean "" inverse gamma posterior "" and "" normal posterior "" ?"
331434,"jbowman are you perhaps conflating "" parameters "" with "" data "" in that last remark ?"
331676,how would we quantify the uncertainty of our estimates from the empirical distribution ?
332166,are the data counts or some other type of variable ?
332227,"a math comment on part 2 : it is * always * the case that $ ab / b = a $ * * when it is defined * * , i . e . not the equation is the problem but the mere definition ! in that sense , assume that $ b $ is a rv such that $ b ( omega ) neq 0 $ for all $ omega $ . then $ ab / b $ and $ b $ have the same distribution simply because they * are * the same random variable . a random variable is simply a function from some probability space $ omega $ into whatever set ( the reals if you want to do this kind of algebra in a natural setting with it ) . . . also : what exactly do you mean by $ a neq 0 $ ?"
332257,"you can't do arithmetic formulas on survey scales , unless somehow you know that the scales are linear . why would they be linear though ?"
332313,is this for prediction only or also inference ?
332465,what do you mean with the data is not parametric ?
332405,this is just really confusing . is your measurement looking at the number of days you will sell boxes or the total number of boxes that you sold ?
332485,"uh , wouldn't it be zero ?"
332563,could you describe more clearly the connection you implicitly assume between pca and hypothesis testing ?
332565,"` segmented ` and ` splines2 ` have different purposes . the former * automatically find the breakpoints * whereas the latter requires you to specify them . that's why you're getting different results . one general way to work out slopes and other spline parameters ( but not the best in your case due to its simplicity ) is to reverse-engineer the splines , as i explain at url anyway , what is the thrust of your question : understanding piecewise linear splines or understanding how ` segmented ` finds and reports breakpoints ?"
333038,what are relativities ?
332935,"could you please explain , what you mean by $ 100 leq s_ { 1 } , s_ { 2 } leq 1000 $ ?"
332371,have you tried calculating the derivatives of the mixture density ?
163915,"related ( although perhaps not obviously so ) : [ if mean is so sensitive , why use it in the first place ?"
333653,"okay , thank you . where , then , do you run into problems in your proof ?"
333691,remove it from what ?
333898,is it not self-study ?
333872,i do not quite understand your question . have you tested for whether your variables are integrated with an adf test ?
330163,what is your broader goal ?
333798,what is your data ?
333906,what's your background ?
335411,"tell us how you count random variables and then we can tell you the answer ! for instance , when sampling tickets from a box , suppose each ticket has two values written on it , labeled $ x_1 $ and $ x_2 $ . from your perspective , would that be two random variables or a * single * random variable $ ( x_1 , x_2 ) $ ?"
336142,"is it a theoretical question , making all kind of unrealistic assumptions like uniform distribution , independence , illnesses that can long for any random number of days ?"
336133,"once you find the best subset of predictors , can't you just use the standard glm package to get coefficients ?"
336747,have you read the paper ?
331045,since your model is using regularisation ( l1 / l2 ) ?
337251,are you interested in estimating the yearly trend ?
337329,are you using cross-entropy loss ?
337457,what is min ( x ) and max ( x ) ?
337685,what is $ p $ ?
337517,"would you mind pointing out how it is "" obvious "" that the relationship is not linear ?"
338175,sorry but the zero here is clearly wrong right ?
337952,is it possible for them to use both hands at the same time ?
338318,what would you put on the y axis ?
338324,how can you have odds ratios within categories ?
338890,what criteria are you using to determine the sample size ?
338301,"satwik bhattamishra makes a valid point at the start of his answer , but not one that is necessarily universally applicable . could you provide some insight into why you feel an aggregation of the per label results is preferred over direct calculation ?"
338740,can you tell us somewhat more ?
338798,what's symbolic regression ?
339187,would you please post a link to your data ?
340253,why do you need the marginal distribution of $ x_2 $ to be normal ?
340089,another regression method ?
340286,"what is the problem with using the correct , fully accurate value for the difference ?"
340566,i should have been clearer - i meant your broader goal . what are you attempting to achieve with this analysis ?
340877,"it's perverse of r to use an abbreviated name here . the test is due to ( frank ) wilcoxon . ( it's a bizarre coincidence that he did write one paper with a wilcox . ) on the weights : it seems to me that you can use any kind of weight that is compatible with ranking . for example , if ( say ) 42 occurs 3 times , meaning that your data come as values and frequencies , then expand the data before ranking . what other kind of weights are compatible with ranking ?"
341387,i don't think a cv chat is going to appease your curiosity . why not set up some simulations to convince yourself what works and what doesn't ?
341527,hint : a count must be a non-negative whole number . are your fdi per capita values such numbers ?
341341,could you show your data in a form suitable for copy-and-paste ?
333507,"before concluding that such an example destroys frequentist probability , one would have to investigate under what conditions countable additivity is saved . furthermore , what you get in your example is a random measure , and maybe one could show that , insome sense , such bad examples occur only with probability ( limiting frequency ) zero ?"
340389,why are you using one lstm network for all the series ?
340464,"my initial thought is , since there's no real 'gradient' here , you probably need to brute force all possible rotations / positions . perhaps you could quantise / downsample the map and path and brute force over that to find a shortlist of potential matches , then check each of these at higher resolution ?"
342225,"would you include decision theory , as posterior loss minimisation ?"
342354,where did $ hat { theta } _1 $ and $ hat { theta } _2 $ come from ?
342918,how did you obtain an infinite value from a finite sum of ones ?
342921,"what have you gotten , $ p ( a_1 text { observed test results , prior information } ) $ and similarly for $ a_2 $ and $ a_3 $ ?"
343108,can you say more about what specifically you are seeking to learn ?
336268,can you share the links to a couple of these blog posts ?
343519,does the individual get one day of sick leave every 2 weeks ?
343627,"perhaps you can provide very specific references ( page , equation number , or whatever ) as to exactly what you're talking about , both in the linked paper and the mgcv documentation ?"
343767,"it sounds like a "" scored label "" might merely be an arbitrary assignment of numbers to distinguish different values of a response . if so , your model is unlikely to work well ( and the residuals show that ) . could you explain more about these "" scores "" ?"
343734,i am unable to understand your subgroupid . how do you code - non whites and whites ?
343788,* describing * your data would be a lot better than posting your data . what are the goals of the modeling ?
343721,i thought np hard was non-convex ?
342832,""" but you can't take an ml course , to what extent is taking an econometrics course worth it ?"
344180,plot name : performance vs regularization strength ?
343845,please clarify : as a first step you perform kde of pca of a large dataset -- correct ?
343753,why not using exact rank tests plus a clean multiple testing strategy ?
344254,how can you have an integral in which one of the bounds of integration ( $ x $ ) is also the variable being integrated over ?
2891,is this compositionnal data ( i . e . do the lines sum to a constant ) ?
4023,i've reformatted your question . is the table now correct ?
10265,"looks like the one that was suggested to you on [ metaoptimize ] ( url ) , right ?"
18843,can this library find values of inverse cdfs for beta distributions ?
20119,how exactly is rounding applied to survey results ?
22561,"to keep this question on topic , we will need to keep it focused on comparing the "" likelihood principle "" and the "" repeated sampling principle "" : answering it in full generality requires a several-volume text . but i suspect i'm not alone in wondering precisely what you mean by the "" repeated sampling principle . "" could you please indicate what * you * understand these principles to mean , or at least provide links to the definitions you intend to use ?"
23049,"alternatively , one could interpret the initial results of no relation as the "" statistical fantasy , "" because the subsequent "" meaningful "" relationships found upon controlling for demographics suggest the original model was a bad fit to the data . what results do your goodness-of-fit tests and other model diagnostic tests show ?"
23535,can you clarify how an error is measured or quantified ?
27685,could you edit your title to be more descriptive ?
29124,"it is usually nice to have an equal number of observations in each cell . if you have not yet collected the data , you might consider using the same number of large and small targets . in any case , what statistical analysis were you planning to use ?"
32477,is $ x_k $ one of the predictors you want to include in the model ?
43273,"so you first obtained $ x_2 $ from $ x_ { 2cont } $ , then calculated $ x_1x_2 $ , then normalized $ x_1 $ and $ x_1x_2 $ ?"
43773,what is ` r ` ?
45277,what's a 'deman' series ?
47075,"i'm not familiar with the phrase model diversity . however , it sounds like what you are after is related to the concept of model _sharpness_ in forecasting . a model has _sharpness_ ( a . k . a . _resolution , discrimination_ ) if its predictions are sensitive to differences in the input data . one could construct a measure of distance between two models based on the degree to which they exhibit sharpness on different subregions in the space of input data . one could then derive a measure of diversity as a function of average or aggregate distance between models . is this sort of what you are looking for ?"
48615,per the help-file for the e1071 package in r on skewness and kurtosis there are several ways to calculate these quantities . . . do you have a preferred method for use in the answer you receive ?
50834,"do you mean that x , y and z are co-linear ?"
56046,could you post the 'related question' as a different question ?
59177,confidence intervals for what ?
61447,could you explain what is meant by adstock variable in statistical terms ?
63959,"it "" doesn't work "" ?"
70252,"statistics is not as unified as other disciplines : often different words are used for the same thing and the same word for different things . i suspect that frankharrell is right , but it really depends on the exact context in which you found these words . so can you tell us where you found references to these models and why you think that they are different ?"
70811,have you tried asking a professor in your department for ideas ?
73019,in what context does this arise ?
73121,are you aware of the difference between descriptive and inductive statistics ?
76210,"what is your definition of "" statistical analyst "" ?"
77439,do you understand the 'big o' notation ?
85553,"the conclusion is false . did you perhaps mean to stipulate that $ y $ is a random variable that takes the values $ { -1 , 1 } $ with equal probability ( of $ 1 / 2 $ each ) ?"
86313,this question puzzles me . why do you believe your coefficients should be in sprecific ranges ( and these ranges symmetric around zero ) ?
86434,"clarification : you seem to want to ask , "" provided that standardization is optional ( one of the special cases where the results are not skewed by different magnitudes ) , then will standardization improve out-of-sample generalization ?"
88632,is the question about the statistic itself or about its significance test ?
93047,"by "" mca "" & "" multiple correlation analysis "" , did you mean * multiple correspondence analysis * ( b / c you include the ` [ correspondence-analysis ] ` tag ) ?"
95305,"have you tried to compute $ mbox { cov } ( z_t , z_ { t-1 } ) $ ?"
95669,why do you eliminate the data points after you do loocv ?
96664,"when you say "" best one "" , in what sense was it best , exactly ?"
96848,have you considered using [ tag : r ] ?
96862,what are the points with the upper and lower ticks shown on the graph ?
96937,have you seen eq . ( 2 ) in [ here ] ( url ) ?
97168,is this a [ self-study ] ( url ) question ( they are handled differently ) ?
97312,why are you doing mle if you're dealing with a bayesian problem ?
97549,what does your data look like ?
97697,"do you actually have the values 3 , 1 , 2 , and 4 , 1 , 4 , 5 etc available ?"
97854,"first , to answer the question about whether your system is accurate , you need to have a measure that you consider accurate . but i don't see that in your description . do you have such a measure ?"
97908,do you mean how to compute the probability of a sequence of possible latent states ?
99154,"using two boxplots comparing the two algorithms might not be sufficient to show the difference . you have paired data , and thus it would be nice to retain that . how about a scatter plot with a line with slope 1 and intercept 0 ?"
99169,is this homework or self-study ?
99256,are your variables continuous ?
99382,"it is a bit unclear to me what you mean by simulation . do you mean that one would randomly sample the state at time $ t 1 $ ( say , $ x_ { t 1 } $ ) based on the state at time $ t $ ( $ x_t $ ) , then $ x_ { t 2 } $ based on $ x_ { t 1 } $ , etc . until $ x_ { t k } $ ?"
99402,"could you please describe what it means for a "" point "" to be "" crossed by [ a ] line "" ?"
95785,"gof = goodness of fit , grm = graded response model , right ?"
99531,computed in the same way as what ?
99736,"the figure is rather puzzling . it is not a histogram ( despite what the text claims ! ) , nor does it plot categorical variables . how is it related to your question ?"
100159,1 : ( 1 ) is not a confidence interval . 2 : it might be incorrect to assume that the 100 values are independently identically distributed from some stable distribution when there is clear dependence in the folding . 3 : is there some reason you want a confidence interval rather than just report ( 1 ) as a way to describe the 'range' of possibilities ?
100204,"so you want to check if there exist $ w , v $ such that your observation $ y $ fulfills $ y = w v $ ?"
100459,what is your question ?
100540,the multivariate tests are all those tests common in manova . any textbook on manova will tell you what they are . but why should you interpret them ?
100686,it's not understandable to me that $ sqrt { mbox { sst } } = sqrt { mbox { ssr } } sqrt { mbox { sse } } $ could be true . how does that follow ?
100976,"while it looks like your understanding is correct , given the chisq . test function already includes the ability to simulate to get the p-value ( which works perfectly well down to very small expected values and can be made as accurate as you wish , simply by simulating more ) , why would you do this ?"
101129,was the answer below of any help ?
101178,is there any reason to believe that these newly found records are anything but iid random variables ?
101353,"ok , but "" looking for information on a topic "" isn't really a question . have you read a good textbook ?"
101393,you would need to give us more information about the data . . like are they counts or something ?
102717,what is your sample size ?
102658,"could you please tell us exactly what would be meant by the "" variance "" of the five-dimensional dataset that results from a projection of a dataset into five dimensions ?"
102855,can you add some more details to your question ?
102871,unless i missed something there's no test at all . possibly a trend test could be carried out since bp is treated as a categorical variable with ordered levels . what are the degrees of freedom for the test used in this article ?
102982,how many grid cells do you have ?
103028,what is a uvecm ?
103055,where did you get those formulas ?
103299,are $ sigma $ and $ delta $ known ?
103403,what does the exercise say besides giving this table ?
103485,it the julian day your response variable ?
103512,do you mean for two teams that are equally good ?
103599,"it's not data that's 'significant' or 'not significant' . presumably you're after a hypothesis test of something , but it's not 100 % clear what you want to test . what do you mean by 'is significant' there ?"
103628,i think you may need to expand on your question to get a useful answer . what do these numbers represent ?
103687,"i might be mistaken , but it seems to me that the best answer would rest somewhat in the prediction approach you intend to use . maybe you could add some details about that ?"
103728,can you say a little more ?
103824,why do you need subsampling if you have only 4000 observations ?
103825,where have you obtained the expression ?
103845,"are b and c independent , correlated to some degree or linear ?"
103872,what is the unit of analysis ?
103974,are you talking about binning a single likert item or the sum of several likert items ?
104009,this appears to have little or nothing to do with [ conventional meanings of var ] ( url ) . what source are you using for this ` r ` code ?
104045,why don't you use the [ conjugate prior of the beta distribution ?
104080,who suggested it and what was their reasoning ?
104097,"have the same problem , could you find a solution for this ?"
104237,"maybe i'm wrong here , but shouldn't $ x_ { 0ij } = 1 $ or maybe some element of a design matrix ?"
104236,* nelsen's * book ?
104259,is this for some subject / course / study / self-study ?
104278,what kind of problem ?
104459,"pardon my ignorance , but what is a continuous dataset ?"
104582,what does your response variable look like ?
104609,you get get everyone's group assignment at each time point and in the end you could have the relative time a person was in each group . your last paragraph is still a bit unclear ; not quite sure what you mean by groupishness . could you elaborate ?
104722,"smartpls and the [ tag : pls ] tag refer to partial least squares . are you sure you're asking about , and performing penalized least squares regression ?"
104780,"do you have any reference or source for the statement "" * in small samples the mom is superior to the ml estimation * "" in the case of the gpd ?"
104828,"could you please be more specific in what context you need to know that , whether this is a homework question and what is wrong with url ?"
104896,"some additional constraints are needed , for after all one can achieve a minimum sum of distances by choosing no elements from either set . do you intend that * all * elements in the smaller set have pairs ?"
104908,"are you interested in knowing what regularity conditions are in general , or which regularity conditions are specifically required for the consistency of gee estimates under misspecified covariance structures ?"
105058,"out of curiosity--because this is a pretty unusual thing to encounter--what application is it that models data in $ [ 0 , 1 ] $ using truncated normal distributions ?"
105248,"by 'residue' in your title , do you mean 'residual' ?"
105319,"sample 1 is complete data , but sample 2 is the * exact same * data with random values deleted ?"
105445,do you mean externally studentized residuals ?
105519,are you assuming that the two estimates you have are independent of each other ?
105574,how many years data have you got ?
105641,what's wrong with using the % value ?
105661,where did you read that the em algorithm finds a map estimate ?
105729,what do you mean by pivotal quantity ?
105822,what is the general statistical area ?
106072,"are you saying , in effect , that you have just * six * data values ?"
106225,out of curiosity do you have a theory where the line should be beforehand ?
107481,"can you add more details about your data & your model here , maybe paste in some output ?"
107671,what are the parameters of the regression line ?
107679,are you asking about generating ( simulating ) such data w / some software ?
107693,"with ridge parameter low , optimization problem becomes ill-defined , so it's not surprising that weights look messy . what is surprising is that cv chooses low ridge parameter value . are you sure observations are independent ?"
107779,is this a statistical or a software question ?
107859,"no impact , or no * significant * impact * with p . 05 * ?"
107897,"when people use the phrase "" independent and identically distributed "" they're talking about random variables being independent of each other , and identically distributed to each other . you seem to mean something else . in which case , what's the random variable or variables , independent of what , and identically distributed to what . . . and against which alternatives ( what kind of dependence , for example ) ?"
107935,ordinal ?
108063,"could you expand a bit on what it would mean to "" draw "" this data structure ?"
108128,the last equality ?
108198,"your question admits a direct mathematical implementation : you know the population mean $ mu $ , you know the sample mean $ m $ , and the margin of error is $ 0 . 03 mu $ . why aren't you just checking that $ m- mu le 0 . 03 mu $ ?"
108208,"the nature of your data are not yet clear . are you saying that at time 1 a total of 10000 hours were spent and of those , 2920 were in program 1 and 4200 in program 2 , etc . ?"
108218,are you after a reference to some texbooks on gp ?
108493,"stepping though is not the problem . my question is what you want ` a ` to do while you are rolling your forecasts . right now , ` a ` is the mae over the entire holdout sample , but if you do rolling forecasts , ` a ` would be based on fewer and fewer holdout observations . is that what you want ?"
108551,what country is the data from as holidays can have an impact ?
108685,"laura : the equation you wrote in the comment is not correct . first , try to figure out what $ p ( x = 1 mu ) p ( mu mathcal d ) $ yields ( is $ mu $ in front or behind "" $ $ "" ?"
107597,david did you figure out how to extend this to an arbitrary number of explanatory variables ( beyond 2 ) ?
108814,"why not treat genotype as continuous , i . e . , assuming the additive model ?"
108820,are you sure you'd want to let the subsample influence the mean of the overall sample for the purpose of this comparison ?
108869,have you checked out the visreg package ?
109402,"what's the basis for the assertion that "" * x is poisson-distributed * "" ?"
109445,"what distribution do you expect the numbers to follow across the groups , the uniform ?"
109608,is the question just on how to specify the model ?
109688,in what way are you measuring error now ?
109781,"first , i think you changed the ` seed ` without changing the slope & intercept in the ` abline ` function . otherwise , where did you come up with the "" ` a = 29 . 887120 , b = 4 . 525572 ` "" ?"
109789,mind sharing the method that you used ?
109802,why can't you do the same as in the question you linked to ?
109959,"i am not sure to understand your problem . have you an angular variable , say $ theta_i $ and some linear predictor $ z_i $ ?"
110047,"are the * x * stimuli different in an ordered way , as might befit penalized regression , or are they more nominal , as would suit an anova ?"
93188,what happens when you run the hausman test on the mundlak model ?
110205,"i didn't understand what were your objects , i . e . did you compute the distance matrix between the rolls or between the ingredients ?"
110270,what is sap ?
110325,what are you trying to do with these kernels ?
110410,where in the video does the thing you're discussing occur ?
110355,could you possibly share your syntax ( do file ) so we can exercise your solution ?
110690,"do you want to check if two categorical variables $ a $ and $ b $ , each with two levels ( $ a = 1 $ and $ a ne 1 $ plus $ b = 1 $ and $ b ne 1 $ ) are independent ?"
110833,do you need to find the value of the deterministic parameter as well or do you have it avalilable ?
110925,can you give the reference for the paper you refer to ?
111101,"thank you : that really is 3d ! it is a histogram in which the vectors $ ( r , g , b ) $ have been binned and counted . since chi-squared statistics apply just as well to such objects as the usual histograms , and you seem to be seeking alternatives , i would guess you have some particular kinds of comparisons in mind . what are they ?"
111139,was it explained why skewness should be eliminated ?
51175,could you clarify how you think the terminology would be misused ?
111255,"categorizing continuous data ( eg , age ) is always a bad idea . multiple regression & ancova are ultimately the same thing , but sometimes software present them differently ; it might be best to think of this as a basic multiple regression . a bigger issue , though , is that it sounds like you want to affirm the null , which is logically impossible . it may help you to read my answer here : [ why do statisticians say a non-significant result means "" you can't reject the null "" , rather than accepting the null hypothesis ?"
111422,so you're dealing with potentially 10 billion rows * and * p n ?
111483,why not report both ?
111544,did you tried it ?
111579,what is your goal ?
111589,can you say what you have done / understand so far ?
111596,in what sense would someone 'prove' a measure of something ?
111683,""" what if you assume the correlation has nothing to do with distance but with nearest neighbours ?"
111690,""" you have just come across expected values "" . . . by what path ?"
111741,can you add more details about your situation ?
111851,"are you after the standard error of the mean , or some estimate of the standard deviation of the process ?"
112080,the problem is knowing precisely what you did when you bootstrapped . what did your bootstrap involve doing ?
112513,have you cross-validated with and without it ?
112534,do you have a reference to the other study who's method you are trying to reproduce ?
112795,"could you clarify what you mean by "" implement "" ?"
112882,are you insisting on the exponential form for the hazard versus time ?
112899,where is beta in this formula for eva ?
112961,what is it you want to accomplish with the model ?
112972,"type ` bl-fu ` . now ` sd ( bl-fu ) ` . if it's not obvious , yet , do these : ` dif = bl-fu ` then ` n = length ( dif ) ` then ` mean ( dif ) / ( sd ( dif ) / sqrt ( n ) ) ` . . . do you see now ?"
113012,"you seem to be saying "" what if the data aren't paired ?"
113540,"you can learn more about the difference between these two syntaxes ( ` wilcox . test ( x ~ g ) ` and ` wilcox ( x , y ) ` ) by reading what is said in the help file ( ` ?"
113557,"the sample variance of a is 107 . 3 , and the sample variance of b is 21 . 8 . why are you assuming that the variances are equal ?"
113552,what is your target variable in your training data ?
113637,do you want to compare the means of the two ( or 3 or more ) groups ?
113683,"do you want to have a confidence interval at each time point , or * over time points * ?"
113726,i might not be well versed on this but can you tell me what you mean by dependent features ?
113800,what about the two variables do you want to compare exactly ?
113935,"the only way i know is creating a custom set of functions to get a family through make . link , and then calling it from the glm . you need to define the function itself , the inverse , and the derivative i think . . check make . link ?"
114032,"this looks like an equation , not as a function . where is the variable ?"
114051,did you attempt to read anything on the topic ?
114129,can you edit your question to give equations for both model steps ( or at least for the second model step ) ?
114163,that's some complicated function . can you show it as a formula ?
114234,do you have any citations where this occurs ?
114347,do you know the system input ?
114417,"it's unclear which "" probability "" you mean in "" we can not predict from these two but can from probability "" . ( pdfs ?"
114211,""" is it possible to predict the finish time for this task when a new task instance is given ?"
114472,"welcome to cv ! i would double-check your text for the question and answer . if the two are [ mutually exclusive ] ( url ) , the answers are straight-forward : 0 . 8 , 0 . 3 , and 0 . is there anything more to the question ?"
114490,optimal for what purpose ?
114569,can you give a reference / citation / description of what are ` discriminant components ` ?
114751,is it really an either-or issue ?
114863,i am struggling with kn too . i think the probability of an unseen bigram p ( w1w2 ) could backoff to the continuation probability of the last unigram w2 . when you are left with an unseen unigram you had nothing . what to do next ?
114861,in which time interval are you interested ?
114916,have you considered out of sample / hold out testing of your predictions from different forecasting methods ?
115129,what exactly are you testing ?
115144,"context might help . where do these phrases come from , and what's he context in which they occur ?"
115148,i have no idea . what is the theoretical question you are trying to answer ?
115571,is this not one of the problems that is solved by log-linked gaussian glms ?
115671,how is it that your response variable is a julian date ?
115227,is there perhaps a typographical error near the end ?
86322,can you be explicit about what 'combined' means ?
115724,"for clarification : you want ideas for testing a change on a single feature a against multiple alternatives b1 , b2 , bn or testing changes of multiple features a1 , a2 , . . each against b1 , b2 , . . or both of them combined ?"
116062,why must it be * that * function rather than some other ?
116361,"are these really dependent , ie . a crime is known to have occurred but not reported . . . . or do you have two separate database from which "" parallel "" models are being developed ?"
116557,"you appear to have repeated y values at your x values . that's okay , just include them in the regression . or is each point on the plot the average of other y values ?"
116535,did you leave out any information ?
116580,"bootstrapping can be a good method of getting confidence intervals , but it is not usually a default method and there are others ! why flag r here ?"
116592,which value are you referring to ?
116709,your question is not very clear - can you clarify your question ?
116731,i assume 'average accuracy of the respondents is 36 . 8421 % ' means that 14 respondents got the correct answers ?
116829,does your count of successes include the lost trials ?
116840,have you looked at cohen's book ?
116971,is $ b $ assumed known ?
117063,is it the same dependent variable for each ?
117075,are the dependent variables all measuring the same quantity ?
117260,"it depends , as ttnphns suggests on what kind of average is suited for your particular purpose . what's it * for * ?"
117561,how did you create your training and test datasets ?
117460,it depends - can you link to some examples ?
117742,"what do you mean by a "" nonlinear model that is linear in the parameters "" ?"
117763,are you saying that a visitor will see one of 3 pricing options based on their business ?
117796,you may be mixing up multi-class with multi-output . what are your target values in this example ?
117867,"i recognize that you want to account for the autocorrelation in the data , but why are you using standard linear regression for a time series ?"
118029,can you clarify how / why you modify the posterior ?
118307,a statistician in whose eyes and in what context ?
118309,"i am not sure to follow : using the covariance of standardized variables is the same as using the correlation matrix , no ?"
118519,"is your response a count , then ?"
118549,your question implies that you are adjusting the parameters to get good results on the training data . this is a very bad idea and will very likely lead to severe overfitting ( and hence poor generalization performance ) . it would be better to optimise a cross-validation based selection criterion ( use nested cross-validation for performance estimation ) . have you tried other methods ?
118565,why process html code and not the actual text ?
119781,what does acd stand for ?
120057,can you say why the residuals are not what you want ?
120071,what do you mean by 'a 5 % margin of error' ?
120084,how were the hazard ratios calculated ?
120334,do you compare n vs s for outcome a and also n vs s for outcome b ?
120665,please try to focus your question more . at present it is too broad . have you read anything about these topics already ?
120750,have you considered the as . table ( ) command ?
120902,weighted sampling ?
121106,can different players have different p's ?
121121,"to what "" problem "" are you referring ?"
121188,"could you describe what you mean exactly by "" using 1000 bootstrap samples "" ?"
121211,did you try url ?
121231,are $ a_i $ and $ b_i $ independent random variables ?
121257,what's wrong ?
121288,"` confirmatory factor analysis suggests a high ( standardized ) correlation ( 0 . 59 , -0 . 45 ) for 3 latent factors ` . how to understand this passage ?"
121300,"what do you mean by "" features "" ?"
121417,did you look into bootstrapping ?
120363,"if there are only 5 input variables , why shouldn't you just remove each of them and check how this affected your results ?"
121604,what other variables do you have ?
121633,there are multiple questions similar to yours with multiple solutions in this forum did you check those ?
121702,robert exactly how would a hierarchical model be applied here ?
121773,"multiple times / points in a time series , not multiple time variables , right ?"
121815,by 'skewness' do you mean the moment-skewness ?
121870,you should know what the distribution of time for each job is . do you know anything about the sum of such random variables ?
122091,""" statistical significance "" is not a concept that applies to random variables : it applies to * hypothesis tests * concerning * data * . what data are involved here ?"
122282,"perhaps you meant "" c ) x and y are _dependent_ "" ?"
122347,"this seems to be essentially the same question as [ this one ] ( url ) . . . in the same class , perhaps ?"
122399,isn't trade between countries the usual outcome in gravity models ?
79192,"welcome to the site , user35965 . please spell out your acronyms . by "" rbf "" , do you mean * radial basis function * ?"
122775,"depending on circumstances i usually either discretize to a large power of 2 bins , and use the fast fourier transform ( ` ?"
122786,are giving your users a dataset or model results ?
122829,"you could in principle do this in r ( ` lme4 ` ) package via : ` glmer ( y ~ treatment ( 1 pair ) , family = gamma ( link = "" log "" ) ) ` ( i would recommend the log link rather than the canonical inverse link for stability . ) have you considered log-normal rather than gamma modeling ( i . e . , do you have a strong reason to stick to the gamma distribution ) ?"
122833,are there measurement errors ?
122951,what tool do you use ?
123055,"i don't think you have given enough information to answer . if you have a dataset from a pull at 1 m / s and a dataset from a pull at 2 m / s , you can make them comparable in the sense of matching positions inside the black box by throwing away every other observation in the 1 m / s dataset . whether this is a good idea depends a lot on what question you are trying to answer and especially how you think the process ( es ) you are measuring work . like , is position inside the black box the critical variable ?"
122702,"is there a set way the weights depend on the samples , or is it arbitrary ?"
123128,"barry the definition need not be recursive : in the graph whose vertices are the $ n $ points connected by edges only when their distances are less than $ t $ , $ n $ is the number of connected components containing three or more vertices . how exactly would one apply a markov model to this ?"
123192,"ummm , compute the value where the cdf is 0 . 2 ?"
123230,what have you tried ?
123295,"do you know the "" interesting states "" that you are looking for ?"
122852,how big are the groups ?
122570,"hypothetically , you can use an unbalanced test to compare the difference between the two populations for each category . however , i am not sure this is what you are really interested in , as that tells you * nothing * else about the underlying populations . are you not rather interested in the potential connection between those factors ?"
123740,"suppose , just to get some intuition , that it turned out $ s_x ^ 2 = 2 $ instead of $ 20 $ . this gives you two choices of $ f $ statistic : $ 2 / 25 = 0 . 08 $ and $ 25 / 2 = 12 . 5 $ . the latter clearly exceeds the critical value you computed . in this case would it make any kind of sense to conclude that $ sigma_x ^ 2 $ exceeds $ sigma_y ^ 2 $ ?"
123985,these read like routine textbook questions . is this for some subject ?
124349,"this question seems more suited for [ stack overflow ] ( url ) , or is there any methodological issue in your question ?"
124455,"does elsewhere include , r-wrapped c / fortran code ?"
124450,why do you want to add ( or subtract ) one standard deviation from the mean ?
124461,wouldn't length of road also be a factor ?
124481,is this for some subject ?
124595,you have a study with reaction times for plants ?
124978,is it possible to treat only one eye in each person ?
124928,could you be more specific with respect to what kind of data you have ?
125036,"i suppose a name matters if you want to learn more about it , but that seems to beg the question : what * do * you want to learn about this distribution ?"
125134,did the matching process involve discarding any patient data that were already collected ?
125183,this looks like routine bookwork . is this for some class ?
125225,where do * * weights * * come in ?
125250,why not * standardized mean deviation * ?
125230,"you are asking how to define an outlier in this case , correct ?"
125287,what does it look like if you remove this item ?
125412,near-duplicates : [ is every correlation matrix positive definite ?
125427,why not include both ?
125455,what kind of information do you have ?
125707,"by "" geographical "" , do you mean * demographical * ?"
125945,what kind of model & what kind of features do you have ?
126017,"exactly what "" literature "" are you referring to ?"
126036,have you read [ wikipedia ] ( url ) and [ breiman's original article ] ( url ) ?
126051,what are you going to do with the clusters once you've found them ?
126329,do you know the exact value of alpha ?
126439,"for clarity : by full batch , do you mean the version that first feeds forward all of the training data , and then back propagates the summed error ?"
126450,how are the variables measured ?
126496,"this may have some slightly tricky issues with it , since you're dealing with things with ( at least potentially ) quite different variances . if there's not a lot of variation in mean you may be able to get away with lmm , but if either of the components gets close to 0 or 1 , or varies substantially ( say between 1 % and 30 % or something ) , you'd be better ooff looking to glmm ( a quasi-binomial model , one with an over-dispersion parameter can approximate the mean-variance relationship of a beta ) . do you have any exact 0's in your response ?"
126532,what is your perceptron learning rule ?
126628,can you tell us what is the purpose ?
126630,"your previous question , paul , and the way you phrase this one , make me wonder what you might mean by "" class . "" does it refer to a class taken at school , or is it perhaps a * classification * into which you have placed the student based on a previous analysis of their performance ?"
126664,have you looked at the cross-correlation function ( ` ccf ` ) ?
126753,"you model seems to be ignoring * within measurement * variability , is that right ?"
126843,"is it possible to fixate on the middle of the screen , or are they either looking at the top or bottom ?"
126882,"what you call "" biased "" is actually called "" sparse "" ; you might want to edit . also , if you have 1 trillion features , how many samples do you have ( probably a lot less ) ?"
127078,"which $ f $ -test effect size measure ( $ r ^ 2 $ , $ eta ^ 2 $ , $ eta ^ 2_ { rm partial } $ , $ omega ^ 2 $ , $ omega ^ 2_ { rm partial } $ ) ?"
127115,could be relevant : url ?
127131,was the mle obtained with the constraints in place ?
127353,is it a homework ?
127385,""" i'm interested in determining the exact point in which the predicted probability "" are you saying that you are seeking , by way of sequential analysis , the necessary sample size to show that , according to the mean model , you may obtain confidence intervals for any one mean value of $ y $ at a given $ x $ for which $ e [ y x ] $ is significantly different from $ bar { y } $ as a general test of hetereogeneity ?"
127471,is there a reason you cannot use the ` predict ` function ?
127484,"just out of curiosity , how do you compute similarity between different rows ?"
127573,is this an assignment for a course ?
127614,neat problem : did you have a try with the moment generating function ?
128678,would extreme value theory apply here ?
128859,"i do not understand what you mean by "" take into account "" . given $ mu $ and $ sigma $ , when you specify $ z = ( x- mu ) / sigma $ you * uniquely determine $ x = sigma z mu $ * . what more do you want ?"
129107,how do you forecast the individual series ?
129146,"is your question different from a number of posted already , such as [ this ] ( url ) or [ this ] ( url ) . by the way , which of the two variables - nominal or interveal - is the dependent one ?"
129316,why not simply code the shifts as a categorical variable ?
129367,"in what way do you want to "" compare "" them ?"
129541,"it depends on what , and how strong , your prior information is . a weak or uninformative prior will tend to replicate the classical frequentist analysis . but if your question is "" is it valid to use a bayesian model if a null frequentist model cannot be rejected ?"
129579,are you solving for $ x1_i $ for a given point $ y_i $ and $ x2_i $ ?
129602,"as presented in your question , there is no indication that you should scale $ sigma $ one way or the other . do you have actual data to relate with ?"
129741,could you edit your question and write something more on your data ?
130057,"are all the magnitudes from the same study unit measured repeatedly over time , or are these n different units & the time of measurement just happens to have been recorded as well ?"
87501,this sounds like a routine textbook type question . is this for some subject ?
130122,did you look at [ roc ] ( url ) ?
130156,how is that subset determined ?
130170,"it all depends on what you mean by "" better "" : there is no golden , universal statistical procedure to tell you which errors matter more . * you need to tell us . * what is the cost or harm in erring on an endpoint of an interval ?"
130340,are you planning an analysis based on model-based standard errors or on sampling standard errors ?
130341,"the way you wrote it $ sigma $ seems to be fixed , so why would you care about its distribution ?"
130504,"please consult our [ help ] for information on what is on-topic here . in particular , we are a * question-and-answer * site , not a "" what is my question ?"
130630,"do you mean lda in r , or lda in general ?"
130837,"hint : you don't need to know the full distribution of $ t ( x ) $ . consider , for instance , the case $ t ( x ) = 2 $ : what is the conditional probability distribution of $ ( x t ( x ) = 2 ) $ ?"
131063,"are $ r $ and $ c $ measured in the same units and you wish to maximise $ r-c $ , by choosing $ n $ subject to the constraint ?"
131208,"i may be reading this wrong , but you say x is the dependent variable , but then say that y is regressed on the 10 bins of x , making it sound like y is the dependent variable . can you clarify ?"
131360,"some expansion of this is surely and sorely needed . you are unlikely to get personal tutorials by return just by mentioning some technical terms . in particular , what are rosenthal inequalities ?"
131482,are you asking about how one obtains $ 0 . 975 $ from the 95 % specification ?
131491,"what do you mean by "" which even is more efficient "" ?"
131486,you have a pretty clear indication of spread related to predicted value ( what a pity that this package - is that spss ?
132617,four 0 / 1 binary variables ?
132631,interesting question--but strange data : the specific gravities range from 0 . 78 down to 0 . 05 . maybe somebody mistook the styrofoam decorations for real fruit ?
132634,which coefficients in the first model are significant ?
132676,"your question is a bit dim . what is the relation between gower coefficient and "" standardization "" ?"
132718,"natalia , are those two means statistically independent or might they be correlated ?"
132733,why would you need $ mu_y propto 1_p $ ?
132691,welcome to cv ! the [ empirical cumulative distribution function ] ( url ) ?
132846,"did you put estout in a folder called "" e "" ?"
132847,are your data / observations are nested within several sites ?
132552,are the observed values that you have 1s or 0s ?
132903,are the rows of the x's all the same from iv to iv ?
132906,"do you mean to say that the 3 ` pre ` are comparable , i . e . they are 3 attempts to measure the same thing , and the 4 ` post ` are likewise comparable ?"
132948,is this the binomial coefficient $ $ { x choose 2 } = x ( x-1 ) / 2 $ $ in which case the second equation is missing a division by 2 . . . ?
132949,it is unclear how you define $ x_m $ : is $ x_1 $ always part of it for instance ?
132996,this is called the second [ moment ] ( url ) of $ x $ . does the [ wikipedia page ] ( url ) help ?
133009,are these from a course or textbook ?
133043,1 . your title and the body of your post ask for very different things . do you want a test for a $ t_n $ or a test for a unimodal symmetric distribution ?
133124,""" without directly fitting a functional relationship "" - why don't you want to fit this ?"
133229,what model is it ?
133263,do you know much about kernel density estimation ?
130077,how do you expect the outcome variable to be related to height and weight ?
133592,"when you say hierarchical regression , do you mean multilevel / mixed model , or variance proportioning ?"
133686,"are you saying that your data are categorical , not quantitative ?"
133740,you mean solving by * hand * ?
133911,what is the question ?
133920,what is your goal here ?
134041,it depends what level you are on . how comfortable are you with logistic regression for example ?
134350,are you asking about * expectation * or--as it appears--about * arithmetic means * of data or random variables ?
134449,what do you know about the form of the dependence ?
134627,you have to be more precise because it is not clear what you are asking . compare what to what ?
134669,"by 'a dag without arrows' in the final sentence , do you mean a dag without edges at all ?"
134759,"if i get your question correctly , you are trying to replace na values in your data using some procedure based on knn ?"
135044,what did you try ?
135061,what is the time unit ?
135119,"since the term log- distribution name is unfortunately used in two opposite senses , can you be precise - do you mean the distribution of the log of an inverse gamma random variable or do you mean the distribution of a variable which if you took its log would be inverse gamma ?"
134995,what is your question ?
135353,"so you had one sample whose subjects were subjected ( subsequently or by cross over ) to treatment a and b and another sample whose subjects got treatment a and c , right ?"
135351,what is $ hat mu $ ?
135512,"you need to provide a little more detail on what you are asking about . your title asks to compare random effects regression - do you mean linear , poisson , or negative binomial ?"
135645,is it a homework exercise ?
135739,i wonder if this question might be better suited for the [ data science stack exchange ] ( url ) ?
135761,crossvalidation ?
135814,maybe because we want to calculate the _average_ distance ?
135923,possible duplicate of [ what is the relation between statistics theory and decision theory ?
136035,do you see large fluctuation in mse due to sample size ?
136169,"how are the "" 10 condition levels "" related to the numerical values in the "" condition "" column in your data sample ?"
136181,"most of the models ( like arima , var , vecm ) normally do need consecutive dates ( although there are models like autoregressive conditional duration model where the dates themselves are being modelled and need not be consecutive ) . do you have an idea of what model you are going to use ?"
136188,"could you explain in what sense finding the critical points "" does not yield the estimator "" ?"
136213,"how large are the counts , typically ?"
136281,"possible duplicate of [ random forest , is it a boosting algorithm ?"
136345,could you add the [ self-study tag ] ( url ) ?
136339,have you already done anything trying to solve the problem ?
136385,what don't you understand about how to calculate c ( t ) ?
136415,how about converting t-values into z-values ?
136370,hint : what does the pdf of a gamma distribution look like ?
136585,could you describe your model a little bit further ?
136600,0 . 46 what ?
136665,"since you're just fitting a gaussian model , you would call this model a "" multiple regression "" . are you interested in the interpretation for glms more generally , or specifically for the gaussian multiple regression model ?"
136670,is the original dataset finite ?
136673,"why for each graph , only one blue data point is visible to me ?"
136701,"your sample number 4 seems quite small , wouldn't that be a concern , too ?"
136877,"dividing by a variance usually would not be considered a form of "" normalization "" at all . are you sure you didn't need to divide by the * square root * of the variance ?"
136927,why do you want to do this ?
136704,why do you think you have a problem at all ?
137007,from what kind of information do you wish to compute these parameters ?
137079,"yes , why not ?"
137095,can you summarize what exactly does he writes ?
137149,what * exactly * does the author state ?
136990,can you make the data available ?
137182,"are we assuming equal mean and variance , and the same distribution , for the two variables ?"
137227,"why does the first link not answer your question , i . e . what the canonical link is ?"
137353,have you tried [ borel-cantelli ] ( url ) ?
137445,what is the circumstance that you have both of these logs but not a canonical mapping from ids to emails ?
137451,you seem to be proposing an interaction - that the difference in one group is different to the difference in the other . is that right ?
137692,"what do you mean with "" it should be more "" ?"
137721,"the mathematica questions are off-topic here , but there is [ mathematica . se ] once you have the conceptual issues sorted out . your q isn't that clear however . can you show a plot of some sample data & / or say more about your ann ?"
137378,asymptotic distribution of what ?
137910,"since you used k-means you already assumed that each component of the customer information is equally important . so you can either continue like that , i . e . match the new customer with euclidean distance to cluster centers , or think of what the gain / loss of misclassification will be ?"
137965,"yes , unimodal is correct . what's the name of the book ?"
138001,is this a homework question ?
138043,"what did you mean when say "" negative samples "" ?"
138262,"what do you mean by using a dummy variable "" as discriminant "" ?"
138279,have you considered normalizing columns instead of rows ?
138320,have you looked at the k nearest neighbors method ?
138325,how big is n typically ?
138504,what kind of variable is it you have ?
138734,what are you sampling ?
138784,do you mean the standard error of the ( least-squares ) estimate of b1 ?
138791,"there are the "" willing "" people here , however you should state your question : what you do not understand about smoothing ?"
138945,"what's "" $ chi ^ 2 $ for gender "" mean ?"
138986,are you after an explanation of what it is or an explanation of how to calculate it ?
139079,"are you asking about how kodama works , or about how the code works ?"
139113,an odd ratio between the two conditions ?
139152,can you clarify the part about hours and uneven distribution . do your samples have different numbers of trials ?
139198,"by "" 2 factor regression "" , do you mean an anova ?"
139223,"can the 'noisy' assumption be described by saying that the observed values for $ x' $ and $ y' $ differ from their formula by two noises , while $ x $ and $ y $ are known ?"
138971,this might come down to interpretation . does it make sense to cluster solely on a single axis ?
139535,"well , no for a number of reasons ; for example what if the two that are most different in sample mean also have the smallest $ n_i $ ?"
139672,have you drawn the venn diagram yet ?
139724,it seems to me that the question you're asking in your post is different from the title of the post . could you make the two consistent ?
139766,"i'm not sure i follow your edit at the end , but if you believe you have an answer to your question , could you post it as an answer ?"
139841,"what do you mean by "" error analysis techniques "" ?"
139871,where are you stuck in the resolution of this standard exercise ?
140037,"did you try an ( 0 , 1 , 1 ) model ?"
140215,"i've edited to try to clarify ( also if you put spaces at the beginning of a line , stackexchange will treat it as code ) . to your second para , boosting is so what ?"
140221,"why do you "" therefore need to produce 1 row of data from the multiple rows relating to each participant "" ?"
140201,please check the following thread on [ when should you center your data & when should you standardize ?
140239,is this a class exercise ?
140272,"really not clear at all . lack of data for some countries : understood , but are you trying to impute missing values ?"
140334,you have two factors that define sales $ s_i = r_i cdot n_i $ for each campaign $ i $ . you know that properties of $ r_i $ and $ n_i $ . your problem is that you don't know how to obtain properties of $ s_i $ given the above . am i correctly capturing the essence of the issue ?
140380,where to begin ?
140499,"it might be better to avoid words such as "" complex "" which also have other meanings . why not something like "" the standard error is _defined_ as $ sqrt { frac { s ^ 2 } { n } } $ where $ s ^ 2 $ is the _sample variance_ $ frac { 1 } { n-1 } sum ( x - bar { x } ) ^ 2 $ "" ?"
140611,did you try it ?
140624,""" unrepresentative "" of what characteristic of what population ?"
140614,are you looking for help programming matlab or do you need guidance on the random number generation process ?
140897,could you please write down the density of your vector ?
140926,which papers have you read ?
140968,"a t-test is only appropriate for something that has a t distribution , which commonly comes from a situation where an underlying variable has a normal distribution and we're estimating it's mean and variance simultaneously , so the estimated mean has a t distribution . depending on what f is i don't see why you would expect it to have a t distribution . but i don't think that's the point of your question is it ?"
141135,"multicollinearity may or may not be a problem , depending on the objective of your study . can you describe a bit more about the objectives of your data analysis ?"
141166,is this a home work ?
141203,"is your question about how to get the code to work , or about the issues underlying getting standard errors here ?"
141238,exactly what do you know about each document in advance of sampling ?
141322,"1 / this seems to be some kind of homework . is so , please tag it as self-study . 2 / do you understand what you have to prove ?"
141364,` in statistica there are non ` . how then did you get the pairwise p-values you are showing ?
141468,"is it right to say that participant1 described stim1 in the following way : 8 objects a , 0 objects b and 3 objects c ?"
141608,you want to add lags of explanatory variables to your model ?
141633,are those two binomials independent ?
141730,"if you don t provide more context , it will be difficult to answer . . . what is bootstrapped ?"
141660,"please tell us what your understanding of these two terms is , because for many people they are synonyms . what distinction do you make between them ?"
141814,why are you specifying that it should be a t-test in your title ( and tags ) ?
141938,does your set of test instances represent the true distribution of all likely instances ?
142172,"do you have the times at which subjects retired , or times at which follow-up ended for non-retired subjects ?"
142230,what are you asking exactly ?
142276,what do you mean by * significant difficulty * ?
142323,can you paste in an example graph that you want explained ?
142471,"i would compute it as $ $ binom { 10 } { 2 , 5 , 3 } left ( frac { 1 } { 4 } right ) ^ 2 left ( frac { 1 } { 2 } right ) ^ 5 left ( frac { 1 } { 4 } right ) ^ 3 = frac { 315 } { 4096 } . $ $ this raises the question of what you mean by "" calculate "" : do you want to * estimate * the probability by simulation , * compute * it by means of exhaustive enumeration , or * derive and apply a formula * ?"
142495,"aleksandrblekh , why not make that an official answer ?"
142598,i wish you could explain what is meaning of meta-regression ?
142624,"what do you mean by "" size "" here ?"
142626,"please explain what you mean by a "" distribution to be convex . "" you probably need to restrict the convexity to the support of the distribution function ( for otherwise * no * distribution function is convex ) . but are you referring to its density function , cumulative density , or perhaps something else ?"
142718,"if you don't have any information about the joint relationship between $ x_1 $ and $ x_2 $ , how can you sample ( simulate ) from them ( jointly ) ?"
142733,are you computing the variance of $ x $ or the variance of income ?
142777,it is interesting that you associate signs with granger causality . can causality have a sign ?
142779,welcome to cv chris . if this is for homework or an assignment could you please add the [ self-study ] tag ?
142806,"you ought to ask yourself what "" 95 % accuracy "" might actually mean . could it be that after the experiment is over you are absolutely sure the ctr is between $ ( 1-0 . 95 ) times 4 % $ and $ ( 1 0 . 95 ) times 4 % $ ?"
142818,what makes you think otherwise ?
143000,i would still call it a negative binomial distribution . that's because a nb distribution approximates the poisson when theta approaches infinity ( nb variance = lambda lambda ^ 2 / theta ) . so it seems like negative binomial is already compound sort of ?
143014,what is the * null model * supposed to mean ?
143100,why would you try to eyeball a correlation ?
143199,there is a [ signal processing se ] ( url ) - would that be more appropriate than than the stats se for a question like this ?
143235,can you post code for a reproducible example ?
143334,"so , you don't mind if some of the coefficients are negative ?"
143335,are you going to ask a person to choose among 120 alternatives ?
143367,"do you know if these are discrete proportions ( eg , number of units in categories a , b , & c , given a total number of units ) or continuous proportions ?"
143389,in what sense do you mean that the p-value is 'meaningful' ?
143496,"what is "" the other zero mean variance algorithm "" ?"
143529,"somewhat more concretely : consider a random sample $ x_1 , ldots , x_n $ such that each $ x_i sim mathcal n ( mu , 1 ) $ . what is the expected value of the estimator $ hat mu_1 = x_1 $ ?"
143327,are you aware that you can post figures ?
143622,"there is no unique solution . for instance , the geometric "" alpha hull "" algorithm has a tunable parameter that adjusts the "" stiffness "" of the hull , providing infinitely many solutions . thus , to make any meaningful progress , you need to consider ( 1 ) the nature of the data--especially any uncertainty in their values--and ( 2 ) the intended interpretation or use of the hull . could you share this kind of information in an edit to your question ?"
143680,you are using ` ivprobit ` for the probit 2sls ?
143781,"is it possible to dance more than once per night , or is each night a 'i dance yes or no' event ?"
143996,the ` perceptron ` class you link to is for a classifier ( binary output ) rather than a regressor ( continuous output ) . is that the actual code you used ?
144038,can you add a reference to the source discussing variational em for lda ?
144081,"if you assume it to be exponential , why wouldn't you use exponential function rather then polynomial . . ?"
144092,superior in what sense ?
144269,can you add some context here ?
144288,"spatio-temporal modeling is a huge and quickly evolving subject . even one book cannot do it justice , but you might start with a look at [ cressie & wikle ] ( url ) . the answers to your questions are--in order--what do you mean by "" condense ?"
144424,"you'll need to say more for this to be answerable . are the pre & post numbers on the sample people , eg ?"
144586,"there are many tools available , your choice should depend upon what is the exact aim of your analysis ?"
144596,"would you mind explaining the connection this has to our site's interest , which is statistics , data analysis , and machine learning ?"
144744,"can you say more about your situation , your data , & your goals here ?"
144779,"i don't think you can know that the data are missing at random . to know that , you have to know the values of the missing data , and if you know that , you don't have missing data . perhaps they're assumed to be missing at random ?"
144814,"i'm not sure if this is properly described as "" sensitivity-analysis "" . it seems more like standard experimental design issues in engineering . are you assuming / worried about the possibility of interactions ?"
144892,for 1 : have a look at the [ wiki ] ( url ) for the kruskal wallis test . for 3 : robust in what sense ?
144907,what are these 3 measurements ?
144923,what does . zph mean ?
144929,self-study ?
145061,it is an unusual formula . could it perhaps be related to the [ finite sample correction factor as applied to the standard error of the mean ?
145071,"what is the ufldl tutorial where "" we saw "" this ?"
145141,""" if one has to perform correlation matrix "" -- this formulation is not clear at all . do you mean "" if one has to test for significance each correlation in a correlation matrix "" ?"
112223,i disagree with the mods decision to close this . how is this unrelated to the topic of machine learning ?
145258,your third question is irrelevant then ?
145400,"at a minimum you will need to know the number of entries in $ v $ , for otherwise all is in vain . assuming you know this quantity , do you have any objections to dividing $ s $ by it to estimate the mean ?"
145492,"assuming you were using ljung-box test for autocorrelations in model residuals , why do you conclude that your series is nonstationary ?"
145523,are you sure you want to train it on a set that's a third the size of your test set ?
145531,are you wanting to ` pool ` the estimates from the models from your five imputations ?
145540,"converting your temperatures to fahrenheit solves that problem . : - ) indeed , why not use a temperature scale at which the freezing point of water is a million ( 1e6 ) degrees and the boiling point is one degree higher ?"
145548,"you're asking about preventing the cycle from happening and making the optimization run better , not merely suppressing the warning , right ?"
145605,perhaps ` chisq . test ` ?
145700,do you want to find a confidence interval for a true mean of means ?
145846,i'm sorry but i could not understand what you need . are you trying to fit a model ?
145932,those sounds like homework questions--possible ?
145947,what is your exact research question ?
146069,"i just looked at the wikipedia page for canonical correlation and i am a bit confused . i always thought that canonical correlation maximised the squared correlation , but the wikipedia page suggests that it maximises the correlation directly , which means negative correlations are "" ignored "" . i don't have my book on multivariate data analysis here , but i'll check this when i get home . maybe someone else knows how the "" canonical "" canonical correlation analysis is defined ?"
146078,"in your analysis of deviance you haven't tested for trend at all , but simply compared the null model with one having a four-level categorical predictor . [ orthogonal polynomial coding ] ( url ) is useful for examining trends , & in fact is the default when you tell r the predictor is ordinal ( see ` ?"
146166,how big is your sample ?
146235,"when you say "" construct a confidence interval for a given distribution "" , do you mean something like "" construct a confidence interval for $ theta $ , given the observations are from the distribution below "" , or do you mean to actually construct a ci for $ f $ ?"
146307,what on earth ?
146348,"if i try ` x - 100 ^ runif ( 1000000 ) ; plot ( density ( log ( x ) ) ) ` then i get something which looks sensible between $ 0 $ and about $ 4 . 6 approx log_e ( 100 ) $ , so what did you run to get that oscillation ?"
146367,what statistical test did you use ?
146479,do you have raw numbers available ?
146487,why do you want to do kruskal-wallis test if friedman test is recommended for this situation ?
146522,"you say "" an increase in achievement scores "" , do you have achievement scores from both before & after the intervention ?"
146679,i don't get your question . what likelihood are you talking about ?
146932,"the nature of your confusion is unclear . the title asks how ols can model non-linear relationships among explanatory and response variables . at the end you observe that the example you provide actually is such a non-linear model . what is the problem , then ?"
146970,"if you are interested only in ` r ` solutions , then this thread is off-topic here . it would be on-topic if you would re-focus it on * how * to visualize variance partitioning . if you make that edit , then could you please elaborate on what you mean by "" variance partitioning "" and the intended context in which it would be applied ?"
147321,would it be possible to give us an example and more information about what you have tried ?
147363,"i have attempted to edit this post for readability . to do so , i compared it to statements in the paper . because this frequently caused the meaning to change , please check that the edits are consistent with your understanding . i wasn't able to find any reference to "" very expensive , "" nor has it ever been the case that computations in student's t test were difficult or time consuming , so your remarks about that are unclear . finally , in reading through this post i don't see you making any points at all , so how are we to address your last question ?"
147372,"just out of curiosity , which implementation of rbms do you use and why bother with 15 iterations of gibbs sampling ?"
147663,how much data do you have ?
147681,what is waves data ?
147731,is your question about specifying / imposing a specific variance-covariance structure in ` lme4 ` ( as opposed to ` nlme ` ) ?
147813,"you did not show the results of ` plot ( dcc . fit ) ` , ` fitdcc = dccfit . . . ` and ` plot ( fitdcc ) ` but only show that of ` plot ( fc1 ) ` , right ?"
2499,"not to be rude , but isn't this a question that is already answered ad nausea on wikipedia and the likes ?"
147958,does [ this ] ( url ) help ?
147962,why use pca at all ?
147986,"could you explain the sense in which this is a "" meta-analysis "" instead of a standard regression problem ?"
148088,which $ r $ ?
148114,what is your null hypothesis that you want to test here ?
148122,do you know how the error bounds were calculated ?
148123,"i don't know much about ica , so let me ask , what are the * sources * you are referring to ?"
148194,an example : a simple regression model $ y = beta_0 beta_1 x varepsilon $ where $ varepsilon $ is assumed to follow some heavy-tailed distribution . the model coefficients and perhaps the tail-heaviness parameter could be estimated by maximum likelihood . it could be estimated by ols as well but ols estimates would not coincide with ml estimates . but what are you trying to model ?
148352,what is your exact question ?
148527,are you in fact saying you have just one observed count & want to compare its distribution to one expected from theory ?
148594,"could you clarify what you mean by "" significant difference in the proportion of tweets between different ages "" ?"
148597,"k-means on binary data is always a bit random . you may be using a too large k , and expecting clustering to do some magic that it cannot do ( also , you probably meant to use the transposed data ?"
148829,"sorry , i didn't get your question . which algorithms did you check ?"
148884,could you explain the purpose of this exercise ?
148891,what do your data represent ?
148918,do you have data on what the promo code should have been ?
148993,how are you handling the nominal variable ?
149089,"you can't actually test to see if the rankings are * the same * ( see [ here ] ( url ) ) . you can test if they are * different * , or if their difference is less than some amount you find negligible , or you can test if their agreement is greater than chance . are any of those what you want ?"
149160,"you use the terms "" compare "" and "" correlate "" . those are two very different activities ( one is useful for answering questions like "" which is bigger "" , while the other is useful for answering questions like "" does variable a increase as variable b does ?"
149274,"maybe i'm confused , but aren't you just looking for a confidence interval rather than a prediction interval here ?"
149358,"when you say : "" i dont what to do ?"
149377,"do you have a variable name with a simple hyphen like ` pre-interrupted ` , or did you just make it up as an example ?"
149620,you should provide more information on your data ( how much data you have ?
149685,"it is unclear what you are asking . what do you mean by "" distributing them according to the bell curve "" . . ?"
149838,"interesting problem . how many studies do you have in each categories ( 1 , 2 & 3 ) ?"
149920,"questions like this don't always ( or often ) have good answers , unfortunately . what are you actually looking for in the data ?"
149932,can you give pointer to those packages ?
151024,"the "" new "" gaussian is a prior for * what * ?"
151212,do you actually get samples of brains for each of the 11 individuals under both of the 2 conditions ?
151224,"what does "" $ phi $ "" mean ?"
151255,are all measurements equally far apart in time ?
151262,did you look at weighted least squares ?
151401,what makes you think that the output variable should be gamma distributed ?
151470,"this sounds like self-study : if so , could you add the tag and read the wiki ?"
151528,"mahalanobis distance itself does not require normality . but what is m . d . "" between two groups "" ?"
151606,"it reads to me like you're fitting an exponential * curve * to ( x , y ) data . you should clarify the properties of this noise , since the idea of noise actually being constant is counterintuitive . can you please provide more details about what you're observing and what this 'noise' is . without the $ c $ term , what's the variation around the mean in the model like ?"
151664,would it be an option to create a control group post hoc ?
151745,"it is very difficult to understand what are you trying to do , and where the difficulty lies . you write that you would like to be able to specify a probability of reward conditional on the location . why can't you do it ?"
151784,is this one helpful : url ?
151785,did you define what is a bad customer and what is a good customer in business terms ?
151808,"am i correct that you have 4 groups of animals , subjected to different treatments ?"
151832,` x / y ` = x * ( 1 / y ) . am i correct ?
149861,i doubt this is any better with a hurdle model . can you paste in your residual plots ?
152042,"can you say more about your situation , your data , your models , & your goals here ?"
152127,is this answer helpful : url ?
152190,"are both variables drawn from the same gamma distributions , or are you asking about ( say ) a gamma and a gaussian ?"
152514,"in your example , are model1 and model2 nested ?"
152578,did we already talk about this ?
152633,"when do you say 'sparsity' , do you mean that weight matrix in neural network are 'sparse' ( and the same for 'dense' ) ?"
152714,"what's your criterion for "" best "" ?"
152883,hint : if you assume $ limsup x_n $ is a finite number . . . can you show this leads to a contradiction ?
153039,"please show some actual ( sourced ) numbers that you think need explanation ; i don't think it's reasonable to be expected to explain a phenomenon we cannot even * see * , merely on your claim that in one case it only took "" half a decade "" . how would we know your claim is accurate ?"
153103,if none are continuous you cannot use multiple regression . what is it you want to find out about these variables ?
153143,how do you know what to expect ?
153218,i think it might be useful to expand on what you mean by an appropriate test . what sort of research question are you trying to answer ?
153301,are you wanting to study correlations or causation ?
153317,"if 10 is the number of subjects , how many tasks are there in this experiment ?"
153396,do you have any data ( directly or indirectly ) related to z ?
153412,it seems you are considering the inequality between the components in $ v $ . you may want to use gini coefficient ( url ) . ( imagine $ v $ as a vector of people's income in a nation . ) another measure could be $ d ( v ) equiv n times { median ( v ) - mean ( v ) } $ when $ n 2 $ ?
153567,"please research our site . although you could not have guessed it , searching for [ anscombe's quartet ] ( url ) will be a good start . since according to the conventional technical meaning of "" correlation "" the answer is obvious , i suspect your understanding of "" correlation "" might be different from the technical one that would be assumed by many readers . could you please edit this post to elaborate on what precisely you mean by "" correlation "" ?"
153724,"could you provide references , authors , and context for where you've encountered this ?"
153781,how about median ?
153917,"why not , instead of binarizing your response , build a model to predict your continuous response variable and then binarize the prediction itself ?"
154061,did you check whether you got the same predictions ?
154288,you mean leave one out cross validation ?
154343,do you want to symbolically factor the polynomial ?
154512,is table 7 the rotated or unrotated matrix ?
154660,"if you calculate tf-idf on the entire data set , how would you check if your model generalizes ?"
154883,are you looking for general knowhow / theory ?
155099,have you used k-folds ?
155203,"did you really mean to include "" not "" in "" not be significant "" ?"
155361,"what you are describing is invalid . no r function will overcome that fact . we can discuss this process & a strategy that might be valid instead , however . ( note that asking for r code is off-topic here anyway . ) but why do you feel the need to collapse insignificant groups in the first place ?"
155388,but why do you want many models ?
155394,what type of matching are you doing ?
155668,any chance you can post some sample data ?
155722,""" but for lda i usually come across ( symmetric ) kl divergence . "" where did you see that kl divergence in lda ?"
155878,"in dols , leads and lags compensate for autocorrelation . why would you want to use hac s . e . s on top ?"
155855,"there are quite a few ( answered ) questions on this already , including [ what is the expected distribution of residuals in a generalized linear model ?"
155918,"i would start with the definition of variance : $ var ( x ) = e [ ( x - e [ x ] ) ^ 2 ] = e [ x ^ 2 ] - ( e [ x ] ) ^ 2 $ and the law of total variance . are $ x , y $ independently distributed ?"
155927,have you tried finding a counterexample ?
155934,are the users the same in x and y ?
156179,are you really asking about collinear predictors or only about * nearly * collinear predictors ?
156363,are your 6 measurements independent ?
156372,"there are , quite frankly , any number of ways to answer this question . i think you're going to have to add more context around it . what is this analysis for ?"
156381,optimum in what sense ?
156493,"if you are not allowed to use the independent increments property , what properties of poisson processes _are_ you allowed to use ?"
156657,coul you state the expression of the regularization you are using ?
156733,"you're using the same notation , $ z_n $ , for two different things . did you mean you're going to re-assign the value of $ z_n $ ?"
71946,"can you say which video , or at least give a little more context ?"
156921,not enough data for what ?
156971,by continuous features do you mean something like spatial or temporal continuity ?
157433,"in what sense do you want to analyze or quantify "" restrictive "" ?"
157480,"how "" publicity reach "" is defined , and measured ?"
157860,"this is a nice question but the title is not search-friendly , unless somebody happens to be searching for the same data set as you ! i wonder if "" why does the variance of a sample change if the observations are duplicated ?"
157927,"is the example data the group averages , or are the the numbers from just 4 animals ?"
157964,interesting question . have you advanced since posting it ?
158077,you need to specify better your question . is it about probability or frequency ?
158139,what loss function are you using to train the network ?
158160,"ok , but what tells you that the variable must be normal ?"
158306,what confidence interval are you trying to compute ?
158387,"i find the situation slightly unclear . do you have only a single accuracy value for your model-not-generated-from-random-data , or do you have one for each random set of data , or something else ?"
158441,"when you say that you can find the errors terms , is it why any desired precision or should we consider that they are estimated too ( as p1 ) ?"
158661,do you want to simulate a random variable x at time $ t $ or a stochastic process $ ( x_t ) $ in continuous time or do you want to invert the failure rate into a distribution ?
158688,how many covariates do you have in total ?
158806,are you performing a multiple hypothesis correction ?
158974,"can you explain for us how $ n $ , the number of observations , could not be an integer ?"
159135,have you tried the updated wrs2 package ?
159155,is that transformed data or original data ?
159243,"what are the "" obvious reasons "" you don't want to add a small value to the numbers ?"
159277,what's the matter with it ?
159345,"what do you mean by "" statistically equal "" ?"
159407,what do you mean by ml ?
159425,"there's not enough information to know . how does "" $ n $ "" arise ?"
159550,the statement that you've heard ( where ?
159552,"it's not clear what you mean by "" making statements "" -- are you asking primarily about * derivations * / * proofs * or something else ?"
159803,""" ard "" = "" automatic relevance determination "" ?"
159851,can you clarify your actual question ?
159873,is this for some class ?
160210,"what is the "" many worlds assumption "" ?"
160451,can you please give few lines of your data here instead of excel file link to the google drive ?
160493,"sorry , i can't help solve the question , but out of interest what kind of phd program was this for ?"
160461,are you sure you wrote the proof correctly . . ?
160508,i don't think that is at all easy to test properly . you need an explicitly parameterised probability distribution as a mixture . is either distribution truncated ?
160667,is your difficulty in computing $ e ( y ^ lambda ) $ ?
161163,did you do factor analysis after removing dependent variable from data or with it ?
161354,"how to resolve this depends primarily on how well the two volumes are measured . are the measurements accurate enough to ignore any measurement error , or would measurement error potentially be a concern ?"
161387,"i'm not sure if i understand your question . . . do you want to solve df / dx = 0 , f ( x ) = 0 or something else ?"
161504,"what do you mean "" uncertainty "" ?"
161510,surely they explain their notation ! have you looked closely through the text to find out what they say ?
161529,i am wodering what type of censor you will use for a case-control study ?
161831,"hi : you would need to de-trend them and then calculate the cross-correlation . ( which needs stationarity of the two processes ) . the problem is that the standard de-trending approach assumes a constant slope . if you the series that doesn't have a constant slope then it's a problem because there's no easy way to figure out what the trend is so that it can be removed . others hopefully can say something more useful . generally , most ( if not all ?"
161982,"by "" size t of the training set "" are you referring to cross validation ?"
162077,"there are obvious ad hoc ways of doing it , like just randomly selecting some proportion of the data and censoring them somehow . can you give some more details about the data you're trying to generate ?"
162102,"so there were 0-10 ( dollars , euros , whatever ) in an envelope , & each person was told they were allowed take some amount , $ a $ , but they actually took some amount , $ t $ , & subsequently reported taking some amount , $ r $ . is that right ?"
162235,how do you define a multivariate cauchy distribution ?
162285,why do * you * use it ?
162383,can you explain in words what this code is doing ?
162635,"could you explain what it means to "" mark "" an animal with a gps ?"
162880,what are your research questions ?
163242,what is the question ?
163394,"alecospapadopoulos , a drift in first-differences implies a linear trend in levels , not exponential growth . by drift i mean a constant term in the model for the first differences . or am i wrong ?"
163580,as tim rightly points out your data is deterministic in nature and can be easily modeled using simple rule . if you have five 1s followed by two 0s why do you need to do any modeling ?
163615,"you use either what theory or the data suggest . please , then , tell us something about one or the other ( or both ) ! in particular , what is a "" signal "" in your application and why does it last only a finite time ?"
163649,i completely agree with whuber . what exactly are you attempting to prove here ?
161861,"are you sure you want "" post "" in the denomerator of these quantities ?"
164158,what about this two links ?
164171,what are the actual data ?
164186,"of course it fails using ` na . pass ` , because the nas are just sent along to the code and will propagate through all the calculations . what happens when you use ` na . omit ` , which presumably was your intention ?"
164182,are you referring to pairwise correlations & a multiple regression model that includes all the variables as predictors ?
164354,""" suppose $ x $ is a normally distributed random variable . "" i am supposing , i am supposing , . . . . but what does ` normal-distribution ` have to do with this question ?"
164487,is this a class assignment or an exam question ?
164518,what do requests to your server actually look like ?
164560,can you say more about your models ?
164521,can you explain your question more ?
164709,variables don't fit data sets . variables may fit a distribution . what are you trying to do ?
164756,why do you add ` ones ` to your ` data ` before projecting it with ` w ` ?
164969,"parallel regression lines would suggest that a constant had been added to the values , rather than a constant * percentage * applied ( which would be understood as * multiplying * each value $ y $ by a constant $ 1 delta / 100 $ , where $ delta $ is the percentage ) . could you clarify which of these operations you mean ?"
164991,"are you asking how to deal with this kind of situation , or are you just asking for software that will deal with it for you ?"
165140,what kind of data is your response variable ?
166471,the way this question is phrased and the tags you have applied suggest there is something special about the numbers 2 million and 200 in the context of a t-test for you . what would it be ?
166712,not sure what you mean by saying that a is varied parametrically . do you mean that a has only 2 levels ?
166786,"how do you plan to transform the residuals in order to perform an anova when , in order to obtain the residuals , you have to perform the anova * first * ?"
166872,there are many good ones to choose from . what do you want your measure to describe about the rice distribution ?
166915,"navneet why don't you simply stick to ` rpart ` , if it works ?"
166960,do you have an example in mind ?
167010,"to what "" statistical implications "" are you referring ?"
167167,"the bootstrap doesn't work for the max , see : [ what are examples where a naive bootstrap fails ?"
167296,what was your reason for using a cube root transformation for the predictor ?
167318,"what is meant by "" the objective function is actually a computational algorithm , not just math "" ?"
167447,where did you see the 40-80 figure ?
167455,what is it you want to know about them ?
167558,you are going to have to be more specific . do you have sample data that we could look at ?
167695,what is the probability model here ?
167736,"i do not quite get the question , but i will try . although a pair of parentheses is missing , this is one equation from a vector error correction model ( vecm , or vec model ) . did i answer your question ?"
167892,is this a quiz or home work ?
167997,what model are these residuals coming from ?
168072,"well , what are your needs ?"
168193,"can you tell us more of your problem , in applied language ?"
168170,what about a gamma or a log-normal distribution ?
168366,"are you trying to estimate the expected value within the bounds ( ie , as it manifests ) , or of the latent variable ?"
168695,"are you after a generic term ( such as "" group "" ) or a specific to this problem term ( such as "" membership group "" ) ?"
168962,it would be helpful if you specify what exactly you're trying to measure from your groups . do you have a hypothesis for example ?
169037,"dates themselves are not circular values , but * day of year * is . which one do you mean ?"
169315,"questions : 1 . does the policeman have to commit to one hand or the other for all situations , or can he choose depending on the situation ?"
169515,"test error will always be larger than training error . why are you surprised , precisely ?"
169635,"you mean joint distribution of $ ( a , b ) $ or distributions of $ a $ and $ b $ separately ?"
169531,why should the known first two moments provide a good approximation of the pdf ( and thus of its parameters ) ?
169628,are we talking continuous biomarkers or dichotomoizations ( e . g . biomarker # 1 threshold x ) ?
169707,"however , your question is unclear . the title says it's a factor , the details say it's an item . which is it ?"
169831,"i am curious how you would go about kriging an outcome that is a nominal variable ( "" type of traffic crash event "" ) . are you perhaps using a geographic generalized linear model in a multinomial logistic form ?"
169560,"it is difficult to tell precisely what you are asking , because several distinct interpretations are possible . could you perhaps give a small example or two ?"
169897,"what's the definition of this "" mega-median "" ?"
171137,"you should enter into this endeavor fully aware of the possibility that missingness could have a ( strong ) relationship to the region ( and therefore the answers probably should not be uniformly or randomly assigned to the regions ) . did you collect , or can you collect , any information bearing on this ?"
10578,is there anything in the [ wikipedia article ] ( url ) which is causing problems ?
171304,"the last equation looks suspicious . there is $ j $ on the right hand side but not on the left hand side . also , why is the process nonstationary ?"
171290,self-study tag maybe ?
171403,1 . how does ggplot2 come into this * anywhere * ?
171458,"by "" energy "" do you mean "" probability "" ?"
171532,( 1 ) presumably $ m_n $ is the maximum observation * in an iid sample of $ n $ * ?
171622,"well there are some long sequences of m's there , but are those really what you're looking for ?"
171745,"you are exactly right , why do you have to use matching / propensity score matching ( psm ) when it's randomized ?"
171770,can you / did you cross validate ?
171851,what method are you proposing to use for testing if there are differences in parameters ?
171971,do you know the formula for standard deviation ?
172012,reliable perhaps ?
172018,"are you asking whether the model should be respecified as ` quota ~ conco1 ` ( removing promo1 and its interaction ) , or as ` quota ~ conco1 promo1 : conco1 ` ( removing a 'main effect' of promo1 but leaving in the interaction ) ?"
172179,` ?
172502,could you please give some context ?
172594,"upon looking at whuber's comment , in what perspective do you want to know ?"
172732,"are you looking for that particular triangle [ * motif * ] ( url ) , or perhaps finding [ * strongly connected components * ] ( url ) ?"
172758,did you have any luck ?
172764,numeric or categorical variables ?
172770,"could you explain what you mean by the abbreviation "" prop "" ?"
172871,"second sentence has "" low arsenic "" twice . i am a little puzzled at the presumption that you will reduce this to anova with field as a categorical controlling variable . you have many as measurements ; why not aim to use as many as possible in a regression ?"
172958,when you said you manually expand the levels what do you mean ?
173211,how does this problem arise ?
173322,how did you optimize ` b ` ?
173432,` so does it always come up with a final single cluster ?
173568,i am wondering if you replace 0 and 1 with 0 . 05 and 0 . 95 what link function will you use then ?
173644,do you refer to confidence intervals of [ prediction intervals ] ( url ) . . ?
173715,what are your data like ?
173780,you have only 16 observations ?
173808,"in short , you want to predict the ltv values with respect to time , right ?"
173926,"can the relationship be curvilinear ( eg , e [ x y ] = f ( y ) = y ^ 2 ) ?"
174297,why do you assume a linear relationship between number of students and average duration of illness ?
174362,"when you do the transformation , what happens to your limits ?"
174585,"is the question asking whether the "" 50 % btn 6 and 8 "" is sufficient to determine the mu and sigma of a normal curve and , if so , what is the mu and sigma ?"
174590,"i suspect few experienced statisticians actually proceed by trying to classify variable types ( and i know that many counsel against it ) , so i am wondering : why do you care how these variables might be classified ?"
174611,in what context ?
174626,you haven't explained why you are carrying out these calculations . what is their purpose ?
174759,is this a question from a course or textbook ?
174847,"does "" measure "" mean "" feature "" ?"
174850,"assuming you're talking about bayesian priors that have hyperparameters ( thus forming a model hierarchy ) , perhaps [ this baseball model ] ( url ) example might do ?"
175031,"that never worked well for anybody . ; - ) there is absolutely no guarantee that there is only one topic in the cluster , so how could there be a single meaningful title that isn't "" a and b and c and d "" ?"
175073,is there some reason why you want to limit the number of controls you use ?
175195,what is 'the third case' you added ?
175243,is this a question from a course or textbook ?
175252,are these time series models ?
175254,""" identical "" implies the distributions will have the same mean . when $ beta_1 ne 0 $ andf $ x_i ne x_j $ , do you suppose the means $ beta_0 beta_1 x_i $ and $ beta_0 beta_1 x_j $ will be the same ?"
175358,what kind of algorithm are you using ?
175490,what do you mean by * * exact counts * * ?
175423,"this is confusing because you appear to use the notation "" $ u_i $ "" to refer both to random variables and to "" bets "" . specifically , you state that $ u_3 $ is a "" bet . "" could you please edit the post to remove this inconsistency ?"
175517,"i did not mention in my comment that you need to use the ` personalized ` input of ` page . rank ` from ` igraph ` , i hope you saw that . anyway , i guess you expect a matrix because each column corresponds to a specific topic ?"
175771,why do you say linear classifier ?
175825,"kurtosis has little to do with bimodality , see figure 2 in [ westfall ( 2014 , * the american statistician * ) ] ( url ) . that said , your $ bc $ seems to only compare * one * distribution against the uniform - how would you use it to compare * two * distribution against each other ?"
176251,how are your dependent variables coded / measured ?
176272,what is your question ?
176496,"are the scientists' values surveys also , or are they on a different scale ?"
176595,did you tried to convert your data in order to get the linear correlation ?
176666,why not use logistic regression ?
176689,what are your data ?
176815,can you explain what it is that you know that would suggest it should be higher ?
176845,"imagine a dataset with 10 variables and 100 data points . you compute correlation matrix and perform pca . you find out that the first pc explains 15 % of the variance . is it "" significant "" ?"
176882,"depends on the learning method . if you're using powerful methods that * learn * structure like ( deep ) neural networks or random forests , then yes , because you are effectively giving the second level classifier less data to learn from . you also introduce potential performance dependencies in unintuitive places , since the overall performance of your scheme depends largely on the first classifier ( even for levels 2 , 3 , 4 ! ) . suppose you have low recall for level 1 in classifier 1 , what do you do with those seeping level 1's in classifier 2 ( problem : they are not part of any of its known targets ) ?"
176936,your question is rather broad ( how to do cv ) . what have you tried ?
177192,have you considered constructing a function that does the job of the optimized network manually ?
177288,"you're probably going to have to provide more information . can you produce a [ reproducible example ] ( url ) , e . g . by simulating data that * looks * like your data set ?"
177323,what if $ p ( b ) = 0 $ ?
177406,do you know what the confusion matrix tells you and why you calculate it ?
177765,why is $ z $ not just the residuals from fitting the initial model $ y = ax b varepsilon $ ?
175104,what happens if you run your anova / kruskal-wallis with all five groups ?
178240,"this may be a naive question , but why would you have variability in y , are you just referring to to measurement error ?"
124448,"can you give some more context , please ?"
178275,i don't understand the situation you are asking about . can you say more ?
178387,have you seen [ this ] ( url ) ?
178511,"what software is "" the econometrics toolbox "" ?"
178228,"what do you mean by "" stable global result ?"
25608,"that's a rather vague question . are you interested in specific applications , theoretical textbooks , or something else ?"
178584,are you saying $ x $ is a binary variable ?
178587,"to get the intuition , think about $ n = 2 $ points in 3d . what is the dimensionality of the subspace that these points lie in ?"
178744,could you give an example of how the ranks would change upon taking the logarithms ?
178783,"it might be neither . quite possibly "" variance "" refers to the variance of the data . * how do the studies describe this statistic ?"
178912,the answer depends on what your formula is . perhaps you could disclose it ?
178916,what function are you using to fit the model ?
179090,( 1 ) that minus sign does not belong in the expression for $ h $ . i guess you intend it to mean an inverse or a pseudo-inverse of the quantity within parentheses . ( 2 ) are you perhaps asking what a matrix is and how to multiply matrices ?
179324,"when you say "" abundance "" do you mean that you have a count of spiders collected in each trap for each of the ~ 15 summers ?"
179326,"what does "" statistically valid "" mean ?"
179422,that is the formula for within-cluster sum of squares ( wss ) . what exactly are you trying to do ?
179471,do you have a sample consisting of 32 observations ?
179561,"before getting your reply , i must add that the answer sounds incorrect since the natural parameter should be $ theta = ( ln lambda , nu ) $ . could you provide the reference from which you extracted this excerpt ?"
179655,what's the reference for what you've done so far ?
179871,why do you need a reference ?
179912,( 1 ) * why * do this ?
180004,"it's very unclear what you mean by "" converge to the wrong value "" . with mcmc chains , they should converge to a * distribution * , not a single value . do you mean the expected value of the posterior distribution for a given parameter is different than the true value used to simulate the data ?"
180135,"is the ` ` in ` gamsim ( 1 , n 0 , dist = "" poisson "" , scale = . 25 ) ` a typo ?"
180142,how many individuals / non-missing alleles were in studies 1 and 2 respectively ?
180268,"you seem to be treating $ lambda_ { 11 } $ sometimes as a constant and sometimes as a random variable , bivariately distributed with $ mu $ . which is it ?"
180278,"is the dependent variable continuous , or is it a number of incidents ( integer , thus discrete ) ?"
180323,are you commited to using stepwise regression ?
180336,"when you say * i'm not sure whether max ( ) can be used . . . * , is the question about notation , definitions , programming or what ?"
180476,do you know * anything * more about x and y ?
180447,"were the sex = "" unknown "" cases included in the analysis ?"
180579,"see e . g . [ this ] ( url ) -- answer by mpiktas , points 3 and 4 ; also [ this ] ( url ) and [ this ] ( url ) . also search for "" consistency "" and "" efficiency "" ( separately ) on this site . have you tried reading a textbook ?"
180644,is this a question from a course or textbook ?
180667,is it possible that there are many responses ?
180888,what is the purpose of this analysis ?
180901,have you tried simply making 3-d scatter plots and trying to possibly use visual cues and your intuition to flag potential outliers ?
181040,what hypothesis do you want to test ?
181138,you're simulating autocorrelated data . what is it about the fact that the result is autocorrelated that confuses you ?
181135,"( 1 ) does your notation mean that you draw $ k $ independent values from a $ gamma ( alpha , beta ) $ distribution and then independently weight them with $ k $ values from a dirichlet distribution ?"
181213,are all the characteristics equally important ?
181109,could you be more specific ?
181461,what kind of numbers are x and y ?
181130,why can't you join two sets of features and have your data points leave in $ mathbb r ^ { ( n m ) } $ ?
181583,do you have the resources to evaluate * * every * * play in the nfl ?
181595,"welcome to cv . this question isn't clear , at least to me . your matrix decomposition seems correct since it describes the hessian as the matrix of second derivatives or "" the rates of change in the rates of change . "" as such and as ron gallant describes it in his late 80s book * nonlinear statistical models * , it is both an expression of the acceleration or momentum in the slopes as well as a statement of any inherent nonlinearities . what isn't clear about this ?"
181612,"you need to clarify what your data is . if you say set of 288 dimension set , do you mean you have one single sample from a 288 dimensional distribution in each case ?"
181623,"the temperature data per city is auto-correlated , how much depends on the time between the measurements . you need to take that into account . in the specific case , i would not trust any result based on 30 subsequent days regardless of the method used . it also sounds like you define your hypothesis : are you trying to determine if the temperature is different in a specific months ?"
181700,"welcome to cv . this question is best answered based on the bis iii recommendations . that said , why not simply assume one of the standard levels for alpha as discussed in the bis literature ?"
181758,"this sounds like an homework , could you please add the ` self-study ` tag ?"
181976,this reads somewhat like a routine textbook-style question . is this a question for a class ?
182276,how do you estimate the features' relevance ?
5937,can you define 'tiny' ?
182437,was the additional sample contingent on not finding any in the first sample ?
182521,what hypothesis are you testing with the above chi-square test ?
182744,"welcome to cv . what is the link between these 1 , 500 hospitals and energy consumption ?"
182786,"is there a reason that you cannot subtract , the given non-zero value you want to test against , from the appropriate sample and then test if their means are equal ?"
182807,"what do you mean by "" for any input x , it will always give the same ( or nearly the same ) output y "" ?"
182894,"moebius , have you found a solution for this ?"
182928,what formula are you using to calculate the degrees of freedom ?
183183,do you consider those probabilities to be independent ?
183265,related : [ when is r squared negative ?
183307,what about linear regression ?
183415,it might make sense--but unfortunately it can make sense in a lot of different ways . could you perhaps supply a small worked example to illustrate what you mean ?
183453,"i'm confused , do you want an analytical solution for the integral or do you want how to calculate it numerically through simulation ?"
183604,"are you saying there's * no * association between the "" important "" hashtags and the others ?"
183626,is my answer helpful or are you looking for * other ways of marginalization * ?
183801,what are you trying to do ?
183814,can you link to where you saw this formula ?
183842,what is your model ?
184093,"do you know what the threshold is , or do you also want to estimate that from your data ?"
184098,i think it would be relevant to specify what the sample size is required for . for achieving the same predictive accuracy ?
184104,have you looked at url ?
184254,how are you using confidence intervals to distinguish ?
184270,is this presumed to be a linear function in a linear system ?
184354,what about a hidden markov model ?
184383,could you please define your variables or copy-paste relevant sections from the lecture ?
184551,"can you relate the equations $ x_1 x_2 = 7 $ and $ ( w_1 , w_2 ) cdot ( x_1 , x_2 ) 7 / 2 = 0 $ ?"
184463,"what constitutes being "" known "" ?"
184706,is this a question from a course or textbook ?
184686,"yearly minima , monthly minima , daily minima ?"
185004,do you believe that it should be possible ?
185122,i find this question very unclear . can you please clarify what do these four matrices contain and what do their sized represent ?
185133,can you please tell us what you have tried ?
185337,"do you observe if someone is eligible for the discounted price , even if they do not buy ?"
185399,because there is chance you are over-fitting have you considered looking at a cross-validation check ?
185439,"isn't this implied by "" the errors are indepedent of each other "" ?"
185608,"you have lots of run-on , and not a lot of clarity . what was the general form of the data . why is it not amenable to use in ts modeling ?"
185649,"as you said , you know the answer , so what is not clear ?"
185743,"no result ever will be resilient , because it depends on how you normalize your data , will it ?"
185792,"i'm not sure why there is confusion here . if your instructor is asking for the average , then you should compute the average . what is the exact wording of the question for your assignment ?"
185991,why not use heteroscedasticity consistent robust standard errors to eliminate the need for excessive testing ?
186053,could you please provide a graph ?
185627,why are you boosting a random forest in the first place ?
186425,this really comes down to the issue in the post [ why do statisticians say a non-significant result means you can't reject the null as opposed to accepting the null hypothesis ?
186458,it's impossible to provide adequate advice without knowing the payoffs . perhaps you could let us know what they are ?
186570,are you looking for an explanation of the _difference in meaning_ of the two parameters or for an intuitive explanation of their relationship ?
186641,a paired t-test is used when you have the same set of subjects being tested for a single metric before and after an intervention . can you make this case for your problem ?
186709,there are estimators available for kurtosis but in most instances i can't see how this would be an issue . why are you concerned about it in the first place ?
186578,what do you mean by ` the gradient of the regression line ` ?
186751,can you be a little more specific ?
186745,what kind of correlation ?
186896,"in * multiple * regression , the betas for standardized variables are not quite the same as correlations ( see : [ are standardized betas in multiple linear regression partial correlations ?"
187021,are you looking to compute a confidence interval for average loan application amount ?
187315,# 2 is easiest . z-scores make no sense for nominal data ; the negative part of the definition of nominal data is that numerical coding is completely arbitrary so long as distinct values are coded distinctly . ordinal data are sometimes treated as if they were measurements : purists regard that as unjustified and some pragmatists will argue that it is better than nothing . but the biggest question of all is why do you think you need standardize every variable ?
187316,are the new data within the typical range of the training data ?
187559,why would you ever want to divide continuous data into a binary outcome ?
187678,"what is "" the first paper "" ?"
187739,"for ( 3 ) , if you use leuven and sianesi's ` psmatch2 ` , you can use the bundled ` psgraph ` command . similarly , stata's own ` teeffects psmatch ` has a ` teffects overlap ` and ` teffects balance ` commands . on the modelling side , how long to do you expect of the effects from the treatment to last ?"
187919,"what do you mean by "" validate "" ?"
188185,do you have enough positive label results to do cross validation ?
188230,"hi giorgio - just out of curiosity , did my answer worked for the problem you were experiencing ?"
188489,"how do you know the signs are wrong , and what exactly do you mean by this ?"
188496,"distribution of what , exactly ?"
188551,is this sampling * with replacement * ?
188657,maybe [ this ] ( url ) can be helpful ?
188740,"keep in mind that cart is not just biased against factors with many levels , but potentially continuous variables too if your sample size is large . is there a particular reason you want to stay within the cart framework ?"
188742,"this seems like less of a methodological question & more of a question for people who are expert in this area . what does it mean to "" estimate [ someone's ] nationality "" ?"
188798,what's the purpose of estimating alpha ?
188825,"are you asking * for * a database , or are you asking about the properties of a dataset that are necessary for this particular algorithm to work ?"
189012,"possible duplicate of [ how to tell if data is "" clustered "" enough for clustering algorithms to produce meaningful results ?"
189077,excuse me but how do you have feature that their correlation is greater than 1 ?
189303,have you checked the keyword ` simulated annealing ` ?
189557,are you including daily seasonality ?
189562,can we make any assumptions about the distribution of the numbers ?
189589,how many 'red bars' would you expect if you compute a 95 % confidence interval ?
189379,"a one-sentence summary of my answer is : that's the mode and there are workable ways of finding it directly without the arbitrariness of choosing a kernel type or width ( or a grid on which to compute density ) . but independently of that , i envisage a column of values and a corresponding column of density estimates ; why isn't this a question of finding the row with the maximum density ?"
189772,"maybe i misunderstand , but the outcome is a three-way interaction ?"
189509,what is your goal with using cross-validation ?
189812,"i have a vague remembrance of a sas code including something like ` 2 / 100 ` . and that does not mean $ 0 . 02 $ , that means something like "" 2 among 100 "" . maybe you saw something like this ?"
189851,are you allowing for the possibility that $ m $ and $ f $ are time-varying ( they carry a $ t $ index ) : - ) ?
189886,just to be sure you are referring to accuracy with respect to a classification problem correct ?
190097,1 . what's the image from ?
190187,"this question appears to be confounding three distinct and different things : countable additivity , a countable domain , and countable sets of propositions . could you clarify the sense ( s ) in which you think they are all related in this context ?"
190349,i'm not familiar with the test . did you try hosmer-lemeshow ?
190369,what are your data ?
190458,is there any problem with the formula when $ lambda = 0 $ ?
190492,was this a randomized experiment ?
190552,"first of all , rbf net has only one hidden layer . have you look into this book url at pages 230-250 ( about rbf nets ) ?"
190880,"you can , but why not use a test that is actually appropriate , such as z- or t-tests for means ?"
190903,why do you have missing data in price returns ?
190966,what is your sample size and frequency of each level of $ y $ ?
191000,"is it the residuals from a model or the actual series that you're attempting to model ( dependent variable or output variable , etc . ) that you want to normalize ?"
191070,"patrick "" unbalanced "" usually refers to the design , not the response . charles it's not clear why you'd add "" ( maximum likelihood ) "" there -- a statistician that * doesn't * maximize likelihood would be just as likely to say "" skewed "" . ( also , you have me curious -- would you really call it "" class imbalance "" even if your response didn't have classes ?"
191156,"sure they do . the link was just for distributed lag models ( lacking the 'autoregresive' part ) , but that was just to get you started . look at the first equation here for example : url that is exactly what you have , is it not ?"
191248,are you referring to a change of a change ?
191290,"note that this doesn't really have anything to do w / pass ( which is good , since software help questions are off topic here ) . do you have any idea what the mean posture measurement was for the reported cohort ?"
191291,is this a question from a course or textbook ?
191412,"there are many methods applicable to the prediction of binary outcomes . you should perhaps start by thinking about whether you want to predict the probability that a student will pass or fail , or merely "" pass "" or "" fail "" - & if the latter , is it worse if they pass when you've said "" fail "" or if they fail when you've said "" pass "" ?"
191847,what is your sample size of the group ; this could explain why the data doesn't look normally distributed ?
191851,are you using second differences ?
191892,"without more information , i doubt it . is there a probablistic component to the algorithms , maybe ?"
192094,with which statistical packages are you familiar ?
192126,are you asserting that the claim $ p ( a_1 ) leq p ( a_1 ) $ is _false_ for some choices of event $ a_1 $ ?
192159,"in what sense is "" $ [ f_l , f_r ] $ "" a "" confidence set "" ?"
192200,"what is the basis for saying "" the covariance between two binomial variables is -np ( 1-p ) ?"
192207,something like ordinal logit or its relatives makes sense for your 4 level variable and logit and its relatives make sense for your 2 level response . either or both could fit your research goals . but why regard 1 time as fundamentally different from 2-5 ?
192218,"have you tried correlation methods to first detect , model , and remove seasonal trends ?"
192301,you want to make the * sample * skewness and kurtosis the same ?
192361,"i think you need to clarify what your specific question is , what do you understand ?"
192401,which of the equations do you find problematic ?
192256,what are these values ?
192553,"please describe what the result or output of your calculation will be . what exactly do you mean by "" find overlapping of the clusters "" ?"
192596,can you provide the data for one of your factor ?
192604,"the amelia documentation is really good , but i don't recall any of it specifically addressing speed . however , it's just a convenient interface for a model that's described at length in the documentation -- why not code it in a really fast mcmc engine like stan and then use that directly ?"
192666,what is the special need for binning here ?
192673,i didn't quite understand the title . what is ` dimension dimension ` ?
192784,were there no baseline measurements taken in the rates before surgery ?
192804,what performance do you get if the junk data gets its own class ?
192782,it all depends on what these data mean and how they have been collected . could you include that information in your question ?
192854,"what do you mean by "" i am not allowed to give estimates separately "" ?"
192925,"are you primarily interested in the * count * of items purchased , or the * fraction * of customers who buy anything ?"
192973,"you haven't described a design : you have only described two variables . see url to appreciate the distinction , one might ask "" what is the architectural style of a house that is built of bricks and timbers ?"
192990,why would you do a bayesian analysis if you want frequentist properties ?
193108,is that all you know about these random variables ?
193345,perhaps $ a $ is supposed to be a $ j times j $ matrix ?
193492,"linear regression is probably a "" generic supervised learning algorithm "" and was originated in the early 1800s ; probit regression , at least in some form , apparently originated [ in the 1930s ] ( url ) . do you mean something in particular by "" generic "" here ?"
193577,is it 63 samples in 27k dimensions or 27k samples is 63 dimensions . what is the nature of the data ?
193581,what's your objective ?
193908,"is ` i ` indexing over the data set size , or over the elements of the vector ` x ` ?"
194486,"perhaps ( ! ) , cast the model into state-space form ?"
194935,is this a question from a course or textbook ?
194980,"are you asking how to get the numbers from the graph , how to convert from log ( weight ) to weight , or both ?"
194639,how big is your sample ?
195044,welcome to cross validated ! depends what assumptions you're willing to make ; & what assumptions are sensible depends on where the numbers come from . can you edit your question to add some context ?
195220,do you have a reference where the methodology is clearly explained ?
195326,what is $ f ( h ) $ ?
195289,"arkoudinos , do you have only two measurements per subject or it just happens that all your "" curves "" are straight lines ?"
195337,why must the contours be elliptical ?
195366,could you explain why you think there should be any relationship at all ?
195367,exactly how are your representing these data when there is more than one member per household ?
195411,"what exactly do you mean by "" systemic errors "" ?"
195476,do you know how decision trees work ?
195544,"what do fish in a lake have to do with a "" nationally representative sample "" ?"
196659,how much below . 5 ?
196803,are you evaluating the r2 on the training sample or on an test set ?
196910,can you say more about the context for this formula ?
196951,can you provide more detail on what your dependent variable is ?
197015,maybe ` boruta algorithm ` will help you : url ?
197037,can you clarify what you don't understand from the previous posts on adf ?
197074,is this exploratory or confirmatory factor analysis ?
197176,read the associated reference ?
197285,is this an exercise question ?
197298,"this q is both off-topic and also unclear ( for example , may the two subsamples intersect by their case composition or not ?"
197563,imho your solution is more general . may i ask how big is your net ?
197588,"could you provide a full citation to the referenced essay , thanks ?"
197602,sorry . . _standard_ deviation $ sigma $ is a sample statistic . do you rather mean just deviation of a point from the mean or such deviation divided by $ sigma $ ( and known as _z-score_ ) ?
197786,isn't delta the error ?
197943,wouldn't it make more sense to give students several multiple choice questions to test their political knowledge ?
197961,"you first state you * do * know the distribution of $ y_1 cdots y_n = n bar y $ , so how could you * not * know the distribution of $ bar y $ ?"
198004,what is the purpose of pca in your case ?
198015,is it causing issues with the model ?
198267,"it could be tree depth , i've often seen that used as size . looks as though the c50 package has a plot method so perhaps you could just try to plot it and see how it looks ?"
198430,"note that all you need to do is show that the error sum of squares is positive . if you have distinct values of $ x $ but for some $ x $ you have more than one value of $ y $ , is it possible that all the points fall on a single line ?"
198554,"can you give a little more details , what do you want to achieve ?"
198827,"please be more specific about what you mean by a "" hierarchical structure "" in this case . if you have 20 levels of a categorical variable , is there some reason why you can't just analyze it that way ?"
198870,is it always the case that your trigger signal is a series of positive rectangular pulses ?
199017,have you considered the possibility of getting * exactly * one six ?
199085,"blain , if you care about the sign of your pc scores , you need to fix it * after * doing pca . you can e . g . fix the sign so that it is the same as your variable 1 ( this means : do pca , check correlation of the pc with variable 1 , if it is negative , flip the sign ) . however , can you tell us if you are going to standardize your variables ( make them both unit variance ) before running pca or not ?"
199098,can you provide a direct quote when the phrase appears and it's source ?
199129,can you provide some context for this ?
199142,can you please explain exactly what information you have & don't have ( in the two cases ) ?
199181,can you model an anomaly as a state ?
199389,"please explain what you mean by "" computing "" $ hat f_h ( x ) $ . exactly what data or inputs would you begin with and what output do you expect ?"
199390,"what do you mean by "" variance "" ( i . e . $ x - x ^ 2 $ ) ?"
199396,"if you're predicting a "" value "" with a bayesian approach , then the output certainly is a distribution . under well-known assumptions for linear regression it will even be normal . but what exactly does this have to do with "" confidence "" or that the "" output is no longer a line "" or that some "" complex curve "" is present ?"
199467,"i think in this case you are assuming mean is changing linearly with time , is your standard deviation also changing linearly with time ?"
199290,what do you observe / know ?
199499,"welcome to our site ! have a look at our [ help / off-topic ] to see what kinds of subject are on- and off-topic here . the question as it's currently written seems to have a heavy focus on a software implementation ( "" how do i accomplish those tasks using scipy "" is generally off-topic ) . but it seems to me that you may well have an underlying statistical issue which is on-topic here . do you think you could edit the question to bring this to the fore ?"
199561,do you only observe their sum ?
199604,are these actually proportions ?
199658,how are you saying f-test result means b1 b3 = 0 ?
199848,"well , what are you applying the test on ?"
199957,i'm a bit confused by your hypothesis . how do we know if anyone has correctly identified anything based on your data set ?
200235,"please explain how a * line * can be a "" best fit "" to points in three dimensions . how did you find it ?"
200340,what data have you got ?
200405,looks like there's no stratification for outcome . why do you want to avoid reshaping the data to wide and back to long ?
200482,"i don't quite follow this . are you trying to evaluate some clustering methods & want to create simulated data w / true clusters a , b , c , . . . , or are you trying to simulate categorical data where the variables have differing numbers of categories ?"
200499,how many values is each correlation based on ?
200729,the use of a hat and a star over the expectation operator is unusual . could you explain what they mean ?
58939,"what exactly is your "" current data "" ?"
200762,which of your dots belong to which group ?
200802,perhaps you could give a bit more detail about their background and how long you have to explain your report ?
200834,"what do you mean by "" compare to one another "" ?"
201181,` arma . sim ` is not part of base ` r ` . what package is it in ?
201441,what is exactly your question ?
201490,"gabby , i'm not trying to be snarky , but you have a sample of 1 person ?"
201557,did you do any cross-validation or the like to account for your model building ?
201664,i don't think you can calculate the se from only the effect size & n . do you also have raw means ?
201677,no ; how could it be ?
201890,"hello greetreepython , what are you trying to achieve ?"
201909,` it should either be an universal rule or a check list of sorts where if certain conditions are met then the data either should / shouldn't be normalized . ` can you justify that ?
201991,do you know what the standard errors are ?
201994,are you looking for the fraction of the variance in the dependent variable explained by the independent variables ?
202037,is $ y $ a deterministic function of $ x $ or is there some random error ?
202295,"$ f ( a ) $ should be $ p ( x leq a ) $ , yes ?"
202342,"if you first run mcmc , shouldn't the initial weights be one ?"
202439,is this a question from a course or textbook ?
202519,could resolve this issue ?
202649,"have you looked up the definition of "" law "" in a good dictionary ?"
202760,"where do these statements come from about "" the bootstrap statistical test "" ?"
202763,"willvousden , why not develop that a little and make it an official answer ?"
202897,"could you explain what you mean by "" limited by the data "" ?"
202990,do the underlying gaussians have to have equal variances ?
203031,a correlation matrix is not the same as a set of pairwise correlations . what is your precise goal ?
203088,"by "" oversampling and under-sampling methods "" , have you tried smote ( synthetic minority over-sampling technique ) ?"
203495,did you find any way to deal with this ?
203501,is thresholding the continuous predictor not an option ?
203520,in what sense do you understand a t-statistic as depending on a parameter ?
203106,"on p . 2 , immediately before equation ( 1 ) and the subsequent introduction of givens rotations , the paper states $ mathbb { a } $ is an $ n times n $ matrix , not $ n times c $ . could you therefore be more specific about where in the paper these expressions appear ?"
203544,"it's not clear what aspect of this situation you are considering "" problematic . "" to the presence of any zeros at all or to a proportion close to one-half ?"
203626,"what is the "" severity of the fishes "" ?"
203731,is the actual problem in reading the graph or in reconciling what you think is implied by the model with what you see in the graph ?
203867,"can you make your question clearer than "" [ d ] oes this make sense "" ?"
204103,you just want to test if . 23 is different from- . 29 ?
204192,"questions about how r code works are off topic here . in addition , please consider reading the documentation ( [ ?"
204232,what do you mean with 3 times ?
204238,what is the context ?
204247,"of course such functions exist , in enormous abundance . for instance , add the expectations of the variables to their covariance . ( that formula , although it satisfies your condition , is probably useless for any practical or theoretical problem though . ) it's impossible to recommend anything without knowing what you intend this function to tell you about the variables . could you elaborate ?"
204374,"what are v1 , v2 , . . . , v40 ?"
204427,"could you explain what you mean by "" solve this kind of thing "" ?"
204477,how are your classes distributed ?
204553,"if you know how many lags you want to include , why don't you just include them as regressors ?"
204903,"what exactly do you mean when you say "" eof loadings "" ?"
205032,"why would you think dividing by the range of $ v $ would cause your measure to lie within $ ( 0 , 1 ) $ ?"
205250,how does the body of this question relate to the title ?
205287,are you sure that you want to use rl for classification ?
205333,ml -- maximum likelihood or machine learning ?
205334,what are you trying to predict with is your final prediction in step 2 ?
205504,how do you obtain these p-values ?
205502,"i'm missing something . if you had a billion upvotes and a billion downvotes , your agreement and disagreement would both be 1 / 2 , and your controversialness would be zero . i'm pretty sure that's not what you intended ?"
205524,any references for the method you alludes to ?
205533,what's the ratio of positives in your dataset ?
205541,"label the observation-categories ( i . e . the values taken by $ x $ ) as 1 , 2 , . . 5 . if you observed a "" 1 "" what would be the most likely value of $ theta $ ?"
205605,are you sure your feature selection algorithm won't crash with these predictors ?
205667,are you asking whether you can use the * * baseline * * score to predict the * * difference * * in scores ?
205791,what is var ( x-y ) ?
205846,can you add some additional context ?
205849,could you explain why the answer would matter ?
205843,are you asking for a transformation that'd take one nb-distributed r . v . into another with a different size parameter ?
205877,what happens when $ t ( x ) = -x $ ?
205928,"to clarify , is $ x $ a vector , $ b $ a matrix , and the inequality is component-wise ?"
206001,can you post any attempts you've made at getting from the rhs to the middle term ?
206095,"if the ratio that you describe is bounded by -1 and 1 , it seems likely that the individual $ a $ and $ b $ values are either all positive or all negative . is that the case ?"
206235,"do you have the information necessary to test seasonality , i . e . , monthly data for a minimum of two years ?"
206275,do you access to the computer program so you can run it yourself for choosen inputs $ x $ ?
206286,"welcome to cv . i'm not sure i understand your question . are you asking if you can * contrast * the average price of the combination of categories a , b and c ?"
206298,can you explain your notation ?
80407,how do you use seed ?
206363,welcome to cv . i don't think this is an appropriate question for this site . you are asking someone to write the code which will linearize this function ?
206409,"welcome to cv . it's not immediately apparent to me what you are asking . would you please elaborate on what a "" server getting a connection "" is about and / or means -- in non-it terms ?"
206432,"can you say more about your situation , your data , your models & your goals here ?"
206729,"are $ x , y $ assumed to be independent ?"
206980,is this a question from a course or textbook ?
207040,what results did you get from your tests ?
207104,why do you want it to be linear ?
205704,you are asking how we estimate $ beta $ given a set of data ?
207316,"what do you mean by "" 400 . 000 text dataset "" ?"
207523,how big was the data set they used ?
207545,"please tell us what would constitute a good answer . currently your question is too vague and subjective to determine how to respond : it only asks "" can someone please help ( me understand ) ?"
207568,what is ls-svm ?
207569,do you mean * * probability distribution * * ?
207632,comment 1 : are not all ( or nearly ) all approaches in some sense trying to deduce something that generalizes and thus predicts what will happen ?
207736,did you center before you created the interaction term or after ?
207854,"did you try to fit some model , like a negative binomial one ?"
207821,"the correctness of the answer might depend on what the "" learner "" or the "" model "" is . obviously a traditional linear least squares solution will not compute or directly use distances , but differences in latitude and longitude will be imperfect proxies for distance nevertheless . please , then , clarify your question : what exactly is your "" learner "" and are you interested in distance * per se * or not ?"
207938,of course you can pool the data . are you planning to use a particular software ?
207944,"i don't follow your question . did you mean , "" * do * i need to be able . . . "" ?"
207804,"do you mean a recursive bivariate probit , where one binary outcome appears as a regressor in the other binary outcome equation ?"
207921,"does hmm stand for "" hidden markov model "" ?"
208049,you want to compare two means - why do you consider t-test inappropriate ?
208203,incorporated how ?
208300,i guess from your gut feeling that there are several balls of each color in the urn . am i correct ?
208434,i am facing the same problem with water quality time series which do not start at the same time and sometimes do not have the same frequencies over years . have you found any answer to your question ?
208459,what do you mean by $ bf { a } ^ alpha bf { b } ^ beta $ ?
208504,"what exactly does "" 10 % accuracy "" mean ?"
208518,have you tried simulating this with a small example ?
208642,could you give us some sample data to work with ?
208845,"when you say "" missing at random "" are you using that phrase in the technical sense as it's used in imputation literature ( distinguished from the more stringent "" missing completely at random , "" mcar ) or in the colloquial sense ?"
209364,"dear dendrobates , welcome to cross validated . maybe you could provide a reproducible example showing the structure of your data ?"
209479,i see a substantial lag-1 correlation . but is the coefficient $ geq 1 $ ?
209636,i too think variance or sd should serve your need . why do you think variance or sd doesn't seem to be used in panel studies ?
209652,"by "" boxplot "" , you presumably meant "" * bar * plot "" , right ?"
209659,can you give examples of places where the link function is estimated ?
209974,i couldn't be confident on _usually_ without surveying all texts and teaching ! i think there is a a lot of bad advice out there on data types . the best way to disambiguate in my experience is to give examples . what's your purpose downstream of this ?
210029,just to make sure : were these treatments non-randomly assigned ?
210047,do the rankings ( z ) exist a-priori ?
210124,both train and test need the same pre processing . your code appears ok . are you seeing very different scores on train and test datasets ?
210203,"if this is logistic regression , there presumably are no outliers in your ( 0 , 1 ) response variable . are there any technical issues in reliably measuring your covariates ?"
210484,"i don't follow this . what is a "" tamagotchi "" ?"
210488,i don't really understand this . can you provide more context ?
210743,did you take a look at the ucr time series classification archive ?
210830,[ * which * $ f $ -test ] ( url ) are you interested in ?
3713,can you try to give more specific description of what you want to cluster ?
210855,"i'm not sure what you mean by "" made 9 linear models for each . "" can you try being more explicit about what steps you're taking here ?"
210930,what is the frequency of the predictions ?
210950,do your data contain exact zeros in the y-variable ?
210875,what is the nature of the self-report data ?
211072,"since the formula references only ` y ` and the constant ` 1 ` , * how could it possibly even know about any covariates ?"
211147,is this a question from a course or textbook ?
211236,"is there some particular hypothesis that you are testing , like whether these "" beliefs and perceptions "" are related to their having mammograms ?"
211465,is there a reason for 4 lags in adf and 13 in the other ?
211583,have you tried url ?
211616,"what do you mean by "" increasing sample size "" ?"
211643,could you clarify your question ?
211795,can you tell us what you understand about the rule for assignment given centroids ?
212321,is this a question from a course or textbook ?
212461,it seems from the wikipedia article that you referenced that two players can have the same elo ranking . why would you want to prevent two players with equal skill to have different ranks ?
212466,do you have reason to believe that the predicted response line would necessarily have to be travel through the origin and be zero at some combination of your dependent variables ?
212807,many unclear issues in your question . starting from ` match the distribution of some observed data set ` ( what properties of the distribution ( s ) ?
212926,"if you chose $ epsilon $ to be a vector , wouldn't $ sigma ^ 2 $ be the 2 by 2 covariance matrix ?"
213040,do you mean you want to test if a sample proportion ( a statistic ) is different from a population proportion ( a parameter ) ?
213075,is your graph embedded in the cartesian plane ?
213077,"i guess the answer depends on what are you trying to do ( and even then it wont be definitive ) . please tell us whether you're trying to predict , uncover the data generating process ( inference ?"
213121,"hi tarek , is the metric a calculated value or is it a raw ( base ) value ?"
213179,what question are you trying to answer worth your sample ?
213233,pardon me ?
213074,"well , one * is * trending -- the black one on your second plot , i'd bet it's the first pc . maybe you are confused by the fact that it's trending upwards and not downwards ?"
213487,what's the precise question you're trying to answer here ?
213518,are lower amounts better than higher amounts ?
213645,"uhm , the question does not make sense . . . how does this situation * differ * from feature ranking for binary classification ?"
213648,what is the objective of your analysis ?
213650,"the rule of thumb $ ge 5 $ applies to * * expected * * frequencies . it's widely considered very conservative , and i could cite authorities for $ ge 1 $ as a fairly safe rule of thumb . but it's always good advice to watch out when you have very small expected frequencies . for 0 or 1 "" sample size "" here , read "" observed frequency "" ?"
213670,"do all participants see the same list of possible developments , or do they see particular sets ?"
213761,why does that line only have zeroes ?
160805,are you intetested in confidence for mean or confidence intrrval of % age change ?
213874,which part of the sample mean is independent of $ x_1 $ ?
213960,maybe the classes just aren't separable at all ?
214107,do you have within study correlations between biomass and temperature ?
214378,why do you want to convert to cohen's d ?
214442,why would you want to do that replacement ?
214639,"a single linear constraint of this nature intersects a hyperplane with the simplex , producing a simplex of lower dimension . why not just choose a ( scaled , translated ) dirichlet distribution on the intersection , then ?"
214700,"yes , you have to specify the alternate . indeed , the complement of the null is determined by the set of all distributions you are considering , so your professor merely pushed the answer one step back without saying anything informative : you could have replied , "" complement of the null * in which space of distributions * ?"
214830,why do you have bounds ( a bounding box ) ?
214876,is the first column average return in excess of risk free rate ?
214965,"1 . what assumption do "" parametric tests "" collectively make ?"
215115,can you explain them a bit further ?
215156,"you write "" we see that the median lies between 3rd and 4th value . "" are you sure ?"
215350,depends on what do you mean by compare . what do you mean ?
215372,i'm guessing you want to assess the goodness of fit of your model . where did it come from ?
215606,what regression method are you using ?
215621,welcome to cross validated ! could you please add the full reference for aste's paper ?
215625,what can you tell us about the ten sample sizes ?
215756,can you explain the pictures - what do the red 's represent ?
215757,why can't you just check the absolute value of gradient of your cost function and if it is small enough than optimizer found a local minimum and training could be stopped ?
215804,what exactly did you integrate ?
215813,what's the test error of both algorithms ?
215922,see [ machine learning feature encoding ] ( url ) or [ how to handle with missing values in order to prepare data for feature selection with lasso ?
215905,can you make your goal more explicit ?
216230,can you provide the context in which you found this phrase ?
216289,have you tried exploring the data / features you constructed ?
217335,how did you compute p = . 018 ?
217361,you should define ` information loss ` . what / which information of the data ?
217412,"not critical to your question , but out of curiosity , when you say , "" the set b has been observed by hundreds of users and they often point out if the classification doesn't match their experience , "" do you mean that : a ) algorithm h doesn't do so well and its results are often criticized , or b ) that set b was created by algorithm h but also has crowd-sourced modifications where users with some level of expertise have provided feedback ?"
217582,""" different "" by itself is meaningless : * * to what * * do you wish to compare these data ?"
217652,"are you quoting something directly when you say , "" can be explained as the . . . "" ?"
217827,"i'm not sure what you mean by "" so much granular probabilities "" . can you clarify ?"
217975,"the point here is that the data actually are paired , you just don't know the pairing , is that right ?"
217981,one typically makes two assumptions : that the error is uncorrelated with the included explanatory variables ( this screws up the coefficients ) and that the errors from different observations are uncorrelated with each other ( this screws up the standard errors ) . which ones do you need explained ?
217986,why do you want to use a hmm for this problem ?
218007,"if your grouping variable has only two levels , then fitted probabilities will only take one of two values , won't they ?"
218291,"the only google result for ` "" dende kars "" binomial ` is this page - is there a transliteration issue here ?"
218321,"what are the "" multiple treatments "" in this scenario ?"
218378,there are many . your choice depends on what you know or assume about $ f $ . what can you tell us about it ?
218487,what do you actually want to test or rather what kind of model do you want to fit ?
218530,"try elki . it has imho the best dbscan with data indexing . there was a blog somewhere on using it on twitter coordinates ( with haversine , and also very big ) . maybe doublebyte blog or something like that ?"
218661,at least 5 or exactly 5 ?
218898,what exactly would * two * sets of weights mean ?
219008,why not compare that output with what you know about your data ?
219144,are the drugs mutually-exclusive or could a patient have more than one at a time ?
219241,"when you say the "" gradient "" , what gradient do you mean ?"
219622,` most textbooks seem to end the elaboration . . . ` really ?
219668,"it's not completely clear what you mean by "" flexibility "" . can you perhaps provide a relevant quote from the textbook ?"
219731,why would you want to do it 1000 times ?
219836,what is your ultimate goal ?
219623,random sampling ?
220002,some details are not completely clear to me : a ) what form of data is your time series composed of ?
220080,"are you alluding to the canonical example of zero correlation but a clear relationship : $ e [ x ] = 0 $ , density of $ x $ is symmetric , and $ y = x ^ 2 $ ?"
220094,"i am not sure i understand your problem , how big is your dataset ?"
220239,this isn't clear . are you just asking for r code ?
76093,"what does it mean for one set of clustering results to be "" more reasonable "" than another ?"
220524,"this is an interesting question , but i think it's quite fair to suppose that there's no such thing as a pseudo-r ^ 2 for a model with a cauchy distribution , for exactly the reasons you suggest . maybe you could use a link function that's a t-distribution with 2 df ( rather than 1 df , which corresponds to cauchy ) ?"
220549,"why are negative predicted values "" an issue "" ?"
220660,"what would it mean for a particular variable to be "" more crucial "" & another to be 'less crucial' in this context ?"
220714,what types of variables are in the training data ?
220807,"how would you argue only his result could be achieved by chance , not yours ?"
220918,have you checked a table that gives the probability of finding a chi-square value of 456 or more with 2 degrees of freedom ?
221029,can you paste in the output you're wondering about ?
221053,where exactly did you encounter assumptions a-c ?
221173,what program is being used ?
49991,"presumably $ x ( t ) $ is the process and the $ 1000 $ exemplifies an unmentioned parameter , the * length * of the realization . but what else do you know about the process ?"
221710,"first , there are many different types of "" decision trees "" , different algorithm will have different ways to select variable to split , select threshold for a given variable , and have different ways to define variable importance . in r , rpart , ctree , party are different . are you talking about breman's cart ?"
221965,doesn't it . . ?
222018,"can you give an example ( title & author of a book or other document that says this , preferably with a direct quote and page number ) ?"
221955,"bagging often refers to repeatedly fitting a model on bootstrapped data points , then averaging the results . but , some people call randomly selecting a subset of features 'attribute bagging' . it sounds like you're referring to the second case , is that right ?"
222112,"you use different terms in the first couple sentences . are the "" plots "" the same as the "" habitats "" ?"
222435,"` glmnet ` supports weights for both samples , and for various predictors to increase or decrease the regularization strength on a by-variable basis . which are you asking about ?"
222681,"all you need is a simple clustering algorithm ( e . g . , k-means , k-means , k-medoids / pam , dbscan , . . . ) where instead of a typical distance function ( euclid , manhatten , etc . ) you should use a string edit distance . did you already looked up these ?"
222687,what are the details of your goal ?
222857,what sort of data are you dealing with ?
223164,what is the nature of your situation and your data ?
223214,"you ask about the meaning of probability ( explained as a long-run phenomenon ) in a context where just a single result ( such as the sample mean ) is available . here is a perfect analogy . when we say a coin is "" fair "" we mean that * in a sufficiently long run of repeated independent flips , * the proportion of heads will be close to $ 1 / 2 $ . if i ask you about the chance that * one * flip of this fair coin will be heads , if you are rational you will answer "" 1 / 2 "" . but that's only a statement about * one * flip , not a long run of flips ! why was your answer of "" 1 / 2 "" * good enough * ?"
223334,why do you think that a non-parametric test would be preferable ?
223337,no . have you tried reading an elementary probability book ?
223454,what's that $ beta $ ?
223525,"it's pretty safe to assume the running time is independent from the other runners . so you're really asking for how many runners in the ( self selected ) sample will be above "" john's time "" . are these elements still relevant to your actual problem ?"
223936,is this a homework question ?
223997,"why can't you use the q-function for the relevant distribution ( eg , cauchy ) ?"
224138,are you asking how to formulate a prior without having seen any data first ?
224257,do you need an analytical solution ?
224278,"wait - do you want the product to always equal one , or only equal one in expectation ?"
224360,"do you mean that when you consider response w / o predictors , the distribution of response is similar to gamma or weibull ?"
224416,what is the nature of your data ?
224566,what threshold are you talking about ?
224706,your description makes it sound like the same piece is never measured at two time points . is this correct ?
224793,what is your question ?
224883,do we understand correctly that you have 2000 samples with 14 features each ?
224925,what do you mean by flipped ?
224953,"do you really intend that ( b , a ) and ( b , c ) have * identical * relations "" f "" ?"
225156,could you expand your question to be independent of the code presented ?
225344,"if the goal is to detect outliers it makes sense to merge the remaining classes . i wonder however , how are those outliers defined ?"
225487,are you asking for code ?
225877,could you give a full reference for patton ( 2011 ) ?
226091,"if you know you have complete separation , why not use cart instead of the models that do not work properly when one needs to fit probabilities of exactly 0 or 1 ?"
226122,"in what sense is the interquartile range "" biased by outliers "" in a way that trimmed data would not be ?"
226299,how do you know that the posterior mean of is equal to $ p_0 $ ?
226488,"what exactly do you mean by "" statistical difference "" ?"
226545,"1 : no , it's a test statistic to test the null hypothesis that the estimate is zero . 2 : don't you mean "" how can i obtain the * effect size * "" ?"
226684,the poisson model is for counts . are you using this as an approximate way of fitting a log-binomial model ?
226791,can you say more about how you intend to use this comment generator ?
226942,"hey nucular , are the ` p ( a b ) ` s here independent or are they conditionally independent given some distribution ?"
227063,1 . how did you obtain this covariance matrix ?
228194,it's not clear to me what you mean by your last sentence . can you clarify what you want to know ?
228528,would you please set a seed so your code is actually reproducible ?
228660,"what do you mean by "" approximating the original population "" ?"
228822,why didn't you like the outcome ?
228834,so this is an alternative to kalman filter methods for positions / trajectories ?
229141,multiplication of numbers is commutative . division is the analog of deconvolution . is division commutative ?
229148,the dendograms are almost identical . why do you think they are completely different ?
229270,can you add more context here ?
229289,have you tried formulating and solving this as an optimization problem of maximizing entropy subject to equality constraints on the n known quantiles ?
229301,is the plot using the training data or the testing data ?
229362,"the scale is part of the likelihood and usually fitted with the model . maybe you could give a bit more context - what kind of models are you estimating here , and why do you fix the scale by hand ?"
229387,"instead of partitioning the problem into multiple networks , would it be possible to use a single neural net ?"
229502,is $ f $ a constant ?
229533,are you worried that the difference between the aic for one model and another is large ?
229572,"( 1 ) please edit your title to make it more descriptive . ( 2 ) it looks like you mean to say that x1 , x2 , and y are vectors , not entire datasets . is this correct ?"
229702,"i would suggest adding the formula for the model you are using and more description of your data , perhaps even adding part of your data . what is your response variable ?"
229888,"the residuals plots show a break in the last period . if you exclude that , the p-values are almost the same , as model2 and model3 are not different according to ` dm . test ` . why your reference model is negative correlated ( almost perfect in one case ) with the other models ?"
229928,what are you using the kernel for ?
229953,"1 interesting question--and your proposed approach is good ( although sensitive to the assumed normality of price changes , which will break down at low prices : you will need to check that assumption after estimating $ sigma_1 $ ) . please note that your question asks for a * prediction interval , * not a confidence interval . but why did you apply the [ tag : bayesian ] tag ?"
229984,what exactly are you attempting to test ?
230070,"has conflict been analysed as a "" raw "" or an orthogonal polynomial ?"
230086,what is lti ?
230092,can you show the results of ` str ( df $ outcome . var ) ` ?
230097,think it may be to do with model checking : see [ why is a bayesian not allowed to look at the residuals ?
230154,do you want me to migrate this question to cross validated ?
230168,what's the point of using lda in such a case ?
230748,what aspects would you like to compare ?
230761,variability of what quantity ?
230675,could you give more details ?
230869,"this is unclear . which "" next tests "" ?"
230927,"confidence interval for the mean , assuming the numbers come from a normal distribution ?"
230934,"i don't really understand your first sentence . what is g , just any old sub- $ sigma $ -algebra of f ?"
230964,you want to sample from the copla or from empirical distribution ?
230974,"how do you define "" exceeding "" ?"
231088,do you have a baseline to compare against ?
231094,i notice that your comment appears to have no bearing on your question . what are you trying to ask about ?
231336,can you label the data yourself ( or at least some of it ) ?
231340,your clustering idea sounds like a really natural strategy . do you have any past data on _unsuccessful_ calls ?
231357,"welcome to our site ! "" does anyone know an r function that does x "" is not really on-topic here - see our [ help / on-topic ] - as it is really a programming question . however i wonder if you have an underlying statistical issue that would be on-topic here . i think your question would benefit from some clarification on what you're interested so we can determine whether your needs are really on-topic here . also you should clarify - when you say "" testing if they are significant different from zero "" , you mean "" testing if the difference in proportions is significantly different from zero "" ?"
231560,is this helpful ?
231628,what's your question ?
231755,why would it not be possible ?
232117,"for ( b ) , how do you know how many cities the country has ?"
232290,what do you mean by coming from the same population ?
232470,"do you have the number of characters and the number of deaths , or just the fraction ?"
232465,possible duplicate of [ what breaks the comparibility of models with respect to the aic ?
232563,could you give us examples of dependent and independent input examples to the classifier ?
232575,can you provide the source of this formula for the normal cdf ?
232717,competing risks survival analysis ?
232727,can you expand on * why * you want to highlight an input feature ?
232870,can you be a bit more clear about what there is to fix ?
232848,have you checked whether the pattern of the results is the same ?
232917,what is the goal of your comparison ?
232937,"one possible example is political polling . prior to election day , political pollsters * cannot * randomly sample actual voters . randomly sampling the general u . s . population or even registered voters isn't the same thing as sampling actual voters because many people don't vote and who does or does not vote is correlated with all kinds of demographic variables . what to do ?"
233249,"i'm wondering , is there are seasonality issue here ?"
233385,what was unsatisfactory about the results ?
233441,did you include an intercept ?
233481,"can you clarify what "" this test "" is , in your last paragraph ?"
233499,"what does the distribution of the output look like over [ 0 , 1000 ] ?"
233743,are you doing this numerically ?
233623,"engrstudent you can code the same algorithm in different languages , yes ?"
233810,could you indicate * which * fractal dimension you are referring to ?
233982,is the interval circular ?
234119,what question would you hope to answer with all 5 timepoints at the same time ?
234474,"does "" occurs in an interval of $ l $ days of a month "" mean : ( a ) fix $ l $ specific days , say days 1 through $ l $ , and ask whether it occurs exactly once during these $ l $ days ?"
234544,why would you expect it to be so ?
234600,do you know the direction and magnitude of the skew ?
234664,"note that there are numerous measures of skewness . while you can do hypothesis tests with them , a skewness of approximately zero ( by any of the measures ) doesn't imply symmetry . why do you want to * prove * skewness ( rather than have a good way to investigate distribution shape , say ) ?"
234761,divide by 12 . . ?
234895,are the strings of the same length ?
234946,"in what sense do you mean "" equivalent "" ?"
234965,have you heard of hidden markov models ?
235038,are you familiar with the basic ( linear ) kalman filter ?
235145,how many students are there ?
235196,"` no overlap ` in what sense , and how strictly ?"
235236,do you mean $ v $ takes values from $ x_1 $ and $ x_2 $ with equal prob ?
235464,what does the inequality-like symbol mean ?
234302,how many predictor variables do you have ?
234289,can you please give us more details ?
235559,have you tried the changepoint package ?
235560,thanks leonbloy . how can i get this question moved to the stats site ?
235945,"ultimately , this is a question of generating points from a uniform distribution on an ellipsoid in $ mathbb { r } ^ k $ . what can you tell us about $ p $ and the relative sizes of the eigenvalues of $ h $ ?"
235993,what kind of non-iid'nes do you have ?
236009,"please explain what a "" correction "" would be . it sounds like you have in mind some idealized behavior to which your data do not conform , but exactly how do they depart from it ?"
236031,from your description it sounds more like a study of incidence rates where you have the number of events and the person-time in each group . for survival analysis you would usually need the observation time for each person . does that framework fit your scientific problem ?
236142,what kind of statistics are you calculating ?
236150,could you clarify ?
236205,"can you specify what __range__ , __value__ and __min__ mean here ?"
236372,i keep thinking about this and can't come up with a solution that wouldn't potentially introduce artefacts that could lead to spurious results at the inference stage . i assume you want to know whether one sample is older than the other . could you not just compare the proportions of people appearing in the different groups ?
236478,what model do you have in mind ?
236623,"ok , i guess my first comment was too subtle . by definition , the value of $ s $ for a "" standard normal distribution "" is $ 1 $ . therefore you don't have to estimate anything . what , then , is your question really about ?"
236924,isn't that the case for the array you show ?
236962,do the two negative binomial distributions have the same parameter values ?
236636,quick question - how did the bank set the initial product rates ?
237077,"it does not imply normal residuals . for example , suppose that i use monte carlo simulation every second of a time series for a minute using a linear model let's say y = x . then let us say i use a student's-t distribution with 3 degrees of freedom to generate noise in the y direction . i then do my linear regression and discover that the residuals are student's-t . am i surprised ?"
237119,is this homework ?
237117,where is the likelihood ?
237154,i'm missing something . isn't this just the binomial distribution with chance of reproductive success in a given year equal to f ( x ) * g ( x ) for that year ?
237315,i do not follow why do you consider sse a wrong metric ?
237338,the obvious measure of central tendency would be the mode . does that suit your scientific question ?
43078,what kind of limit interests you ?
237408,are you looking for an indication of what to expect for next month's bill given the past few months ?
237552,can you provide a little more context and detail about your question ?
237463,how do you distinguish your procedure from dimensional reduction algorithms ?
237673,do you mean multivalued labels ?
237908,why do you want to remove them ?
237924,"can you please add some more information to the question , e . g . which software are you using ?"
237956,1 . what do you know about pivotal quantities ?
237977,"what does "" of form regardless or not "" mean in this context ?"
238016,can you give an example of part-of-speech information ?
238018,i was going through my old answers and noticed this one was not accepted . do you perhaps need further clarification ?
238200,"combining maximization and marginalization occurs in monte carlo em algorithms . is p2 a parameter of interest , or a nuisance ?"
238278,"there may not be a single "" correct "" answer to your model selection problem . what form of incorrectness are you most worried about ?"
238418,how did you initialize the weights ?
238562,what hypothesis exactly do you want to test ?
238670,did the survey constitute a genuinely random sample ?
238671,can you find an unbiased estimator ?
238693,what did you try allready ?
238698,have you tried differencing ?
238706,"i think you will need to provide significantly more information here . in what context do you mean "" billing high ?"
238717,hint : how many people voted for the party ?
238840,"if you use multiple linear regression ( with unemployment as outcome and aggregate demand and productivity as predictors ) , your unstandardized regression coefficients will be partial coefficients . is this what you are trying to do ?"
239044,see [ does down-sampling change logistic regression coefficients ?
239166,this certainly isn't overfitting . how are the training & test sets selected ?
239347,can you ` dput ( ) ` your data to make this reproducible ?
239485,why not qualitatively report your findings ?
239576,can you clarify your question ?
239608,what do the variables treat and post represent ?
239626,by zero values do you mean missing values ?
239691,"i would imagine that marketing expenditures are for * distributed * types of results , e . g . pay for an ad that then runs for days or weeks ?"
239708,"are they all jointly normal , in addition to being marginally normal ?"
239778,does this post answer your question sufficiently ?
239855,do you want to tell us what you've tried so far ?
239893,"could you explain what you mean by "" do "" something with data ?"
239904,"this question will be marked off-topic here . i am not a python user , but could it be be that the order of variables in the function matters ?"
239920,"what are you considering "" really different ?"
240060,"see url the authoritative reference can be found on the [ spss technical manual pages ] ( url ) : link to the statistics algorithms pdf , go to the "" descriptives algorithms "" chapter , and look up the formula for "" skewness and standard error of skewness . "" as far as ` r ` goes , the base software provides no skewness function , so exactly what ` r ` "" information "" are you referring to ?"
240076,this is hard to follow . can you paste in your output ?
240216,what are the 4 measurements ?
240305,is karma farming permitted here ?
240312,at the moment it is a bit difficult to see what you are trying to do . could you give us a few more details ?
240453,what exactly your supervisor would like you to test ?
240302,how could you get the scoring before training starts ?
240885,stochastic gradient descent ?
240935,this seems a little underspecified & probably too broad to be answerable . can you clarify & narrow down your question ?
240941,have you thought about anova ?
241093,"what makes you think that a "" discrete lognormal "" ( whatever that is , but it's clearly not actually a lognormal ) will "" have a peak "" ( again , whatever you quite mean by that ) ?"
241193,can you expand a bit on what you mean by the last paragraph ?
241213,how are you estimating $ hat { a } _1 $ ?
241283,possible duplicate of [ what's the difference between multiple r and r squared ?
241552,it sounds like you want to fit a trendline . this is a standard function is for example excel . are you interested in the math behind it or in programming such a function yourself ?
241851,if your users can handle a correlation coefficient ( which goes from -1 to 1 and is unitless ) why would this be more difficult ?
241939,"assume your answer is correct . the question "" is that all "" would only seem to take the answer "" yes "" . "" yes "" is generally not adequate as an answer . if possible , can you reformulate your question to ask something for which a longer-than-one-word answer makes sense ?"
242077,"in the title , you say "" coefficients "" and in the text you say "" factors "" . do you mean levels of a single categorical variable , and you're asking how to combine levels so you only have 4 levels in this single variable ?"
242090,what is the value of the coefficient related to work experience ?
242095,is this really repeat measures ?
242178,"1 for the question , seems like its impossible to solve this exactly , since a complete graph is going to match any observations . so probably just assume a link between points with high correlations ?"
242571,are you expected to do this by hand ?
242613,so the idea is you have 2 sequences of categories that are temporally ordered & you want to assess if it's reasonable to assume they came from the same data generating process ?
242694,what are the characteristics of words and non-words ?
242880,are you quite sure that the only way to get what you need is to fit logistic regression models on phones ?
242940,please give more context . why do you need a combined model ?
243323,"what do you mean by "" sensitive to classification score "" ?"
243396,what is the range for $ z $ ?
243569,"it depends , why do you want to subsample ?"
243682,are all of the weights identical ?
243784,are your predictors highly correlated ?
244035,"what is the origin of the "" $ 4 $ "" and "" $ -4 ( 2 ) $ "" terms in your calculation ?"
244050,"for your "" thing i have noticed "" what do you mea by full model ?"
244134,by comparing relationships are you implying correlation between two variables ?
244142,what kind of prior beliefs about p do you have ?
244236,what would you do with that mse ?
244563,"are you thinking of human input that says "" no , these samples are no good , "" or some kind of automated mechanism ?"
244943,how sure are you that your data are well fit by this type of 4-parameter logistic model ?
244955,"you need to add more detail if you want a good , or any , answer . what does "" not work "" mean exactly ?"
244964,"with "" zero correlation "" , do you mean this is true theoretical in the underlying distribution , or do you mean this is true in the actual sample ?"
245042,what do you know about $ n $ ?
245051,welcome to cross validated . can you clarify if you are trying to calculate it manually or obtain it from the package you are using ?
244566,this is awfully sparse . can you say more about your data ?
245307,i've never really been too keen on that dot notation . does the dot denote the derivative of the state evaluated at discrete time points ?
245394,is this what you meant to ask ?
245435,binomial [ converges ] ( url ) to poisson so such approximation is often used . also don't you mean binomial rather then bernoulli ?
245542,what exactly is unclear for you in here ?
245560,"what do you mean by "" probability of getting samples "" ?"
245552,"are you asking about binary / trinary factors as outcome / dependent variables , or as predictor / independent variables ?"
245643,overfitting is only indirectly quantifiable as how well the model does on holdout data . you have the holdout data . how well does your model do ?
245698,what do you mean by sparsity here ?
245763,why are you asking effectively the same question you asked yesterday ?
213595,which distribution would you assume on those $ 10 ^ { 21 } $ random letters ?
245813,why is training a weighted squared-error cost function much slower to train than a unqeighted square-error cost function ?
245835,"what or who defines "" acceptable "" ?"
245960,does this refer to a continuous self-rated extraversion score ?
245984,what happened to the factorial terms ?
246001,have you considered to nest player within team ?
246061,are you referring to k-means clustering ?
246228,""" consider a gaussian kernel as a linear combination of infinite number of gaussian distributions "" wouldn't this statement imply that a gaussian mixture in general can be summarized exactly into one gaussian distribution ?"
246050,"please explain what you mean by "" maximum error . "" after all , you have only two measurements and ( by definition ) the error is their difference . how would the concept of maximization apply ?"
245413,"it sounds a bit as if you are asking : "" which methods exists in classification and clustering ?"
246463,can you describe or copy the description of the plot / image ?
246504,well the expected and obtained results are very similar . were you expecting them to be exactly the same or were you expecting there to be more uncertainty given the limited data ?
246628,have you tried to get results excluding this variable ?
246670,"1 . what makes you say "" it seems right "" ?"
246732,i am trying to understand the setup . could you expand how the * thereby * works in * a variable outside the model exists that correlates with two values in the model and thereby causes the structural shock and the impulse response * ?
241018,is this a question from a course or textbook ?
246816,are the y counts ?
246938,isn't that a least-squares problem you are solving ?
247066,can you provide references to those papers ?
247177,both $ f ( n_0 1 ) $ and $ bar { f } ( n_0 1 ) $ are variables ?
247299,"correlation , very informally speaking , measures "" overall "" similarity between pairs of values . if you don't have pairs , since your vectors have different length , then what do you want to measure . . ?"
247341,can you spell out mfpt ?
247346,"this is quite a broad question . just how much data do you have over what time periods , how many words do you want to analyse , do you want to do them all simultaneously , and so on ?"
247429,"these questions seem to be largely calling for what i'd regard as opinion and as a result largely constitutes call for discussion ( "" chat "" items should go on [ chat ] ( url ) ) . could you attempt to orient your questions toward things that could be addressed with facts , references , or specific expertise ?"
247475,is $ a $ symmetric ?
247493,"welcome to the site . it's not clear from your post what you meant by "" for each product we performed three analyses . "" did you mean evaluation of the stains or did you mean statistical analyses ?"
247525,"as response y_i is a matrix , beta is a matrix too . i am curious what kind of situation requires sum ( beta ) = 1 ?"
247565,the question and the title ask different things . could you disambiguate please ?
247970,see also [ how do r and python complement each other in data science ?
247996,what's the purpose of the analysis ?
248026,possible duplicate with this url ?
248461,do you have an example ?
248544,what are you interested in finding out from this new data ?
248659,"if it's normally distributed , then there are no outliers . right ?"
248691,( 1 ) do you know the sample size or not ?
248827,why do you want to do that ?
248903,"what kind of model did this come from ( normal , logistic , etc ) ?"
248924,how much correlated is the new variable with your regressor ?
249055,you have a binary data tag . are any of your inputs actually binary or are you using that tag because of continuous variables that are between 0 and 1 ?
249600,"i don't get it , mavavilj . you have asked 98 questions here , but you've only accepted an answer 10 times & you've only upvoted 9 answers . if you think the information you get here isn't worthwhile , why do you keep coming back & asking more questions ?"
249678,what makes sense will depend on what question you're trying to answer . what is your research question ?
249617,can you try solving for $ y_ { t } $ in terms of $ y_0 $ ?
249810,"do you want to use learning outcome ( module mark ) , motivation , satisfaction , perceived expertise as dependent variables , i mean take them all as dependent variables ?"
249867,where have you seen it expressed in the second form ?
250013,multivariate mgf ?
172382,what about scaling ( e . g . center and reduce ) the values to predict to have comparable errors ?
250220,a possibly more important question is : why are you discretizing your continuous variables ?
249123,"are your weights , $ f $ and $ x $ correlated or derived from the same data in any way ?"
250305,"this question is completely confusing , especially its title . i think what you want to ask is : "" what does the column named "" f "" mean in the manova output in spss ?"
250435,"if you don't know , then what difference does it make ?"
250447,tda seems more like a marketing thing than actually useful . why is it absent from all the big tools ?
250488,"to what does your final "" that "" refer ?"
250493,"( 1 ) from $ f = t ^ 2 $ you may conclude $ t = pm sqrt { f } $ : that ambiguity reveals the importance of the clue "" i recall that it is positive . "" ( 2 ) how is $ t $ computed in terms of the estimate and its standard error ?"
250511,"when you say groups , does that reflect topics a to f ?"
250575,could you clarify your language a bit ?
250731,how much do profit do you make if you win one bet ?
250896,is your goal to understand the science or to do predictions as a black box ?
251045,"a standard normal distribution has * no * parameters . how could it possibly be a normal distribution , then ?"
251227,this should still have the self-study tag . which bootstrap confidence interval method are you suppose to use . does the professor specify ?
251262,can you expand a bit on what data you have and why you want to do this ?
251388,this sounds very strange . are you making the evaluation out of sample ?
251331,why are you interested in zero ?
251527,have you learnt about conditional expectation ?
251542,the real question is : does chamaeleon actually exist / work ?
251863,do you have any clues about why the intercept changed so dramatically between the two models ?
251747,can you clarify which of these is your outcome variable ?
252013,do you really mean to imply that there _must_ be a causal relationship between smoking and drinking ?
252095,""" smaller subsequences in it . "" are these subsequences of the same length ?"
252114,"this histogram isn't gaussian in appearance , truncated or not : its right tail is much too heavy . so : would you like answers to the question you asked or would you like advice about how to characterize the data you show ?"
252212,"have you considered using cartesian coordinates ( that is , cosine and sine of the angle ) for the directions ?"
252233,daniel it all comes down to something you haven't explained : exactly how is $ sigma ^ 2 $ defined ?
252371,"it depends on your data and your problem . however , it may help to graph the data with ` plot ( sort ( abof ) ) ` does the data shift continuously from 0 . 95 down to 0 or are there gaps ?"
252407,you haven't told us what y is . how have you paired x1 and x2 and how many observations do you have ?
252430,do you want to link to the paper you're referring to ?
8297,shouldn't this question be made cw ?
252740,for interpretation does this q & a url help answer ?
252855,"this strategy is not quite correct , because it doesn't define a true mixture distribution . ( in a true mixture , the numbers of observations from each component will have a multinomial distribution rather than having fixed values . ) could you please clarify , then , what you are trying to accomplish ?"
252918,if all the balls end up as black ( or white ) at the end of one step what happens now that there are no balls of opposite color ?
252925,"there are a lot of tools to deal with 3d datasets and even with higher dimensions , although they are hard to visualise in 2d . what do you want to test ?"
252935,are you saying your training data does not have negative examples ?
252999,"what does "" it always hold that p50 mean p90 "" mean ?"
253043,what is ccc dcc gjr ?
253046,"are the five levels you quote ( 0 . 2 , 0 . 4 , 1 , 2 and 3 ) measured values ?"
253108,"just to ensure clarity , can you specify the question ?"
253351,can you maybe explain why you want to do that ?
253657,did you forget a few words in the question ?
253711,if you have 150 observations already why not use all of them ?
253535,"are you asking the same question over and over again , every time erasing the previous version ?"
253856,are you speaking of regression ( * i . e . * numerical predictions ) or classification ( * i . e . * categorical predictions ) ?
253938,"it could mean literally anything . it looks like "" $ dx $ "" is used as a single symbol where other authors might use "" $ x $ "" or "" $ x $ "" , but it's impossible to tell from looking only at this formula . how does the book's author define his / her notation ?"
581,what do you mean by 'viterbi training' exactly ?
254030,"there doesn't seem to be enough information to answer this question , because you haven't posited any connection whatsoever between the locations of these points and the geographical area in which you might consider them to enclosed . could you provide more specifics about your actual problem ?"
254175,does the scan give a measurement on a scale or just a category ?
254187,"what do you mean by "" finding the most likely hidden state for 1 time sequence before "" ?"
254213,why do you prefer not to cross-validate ?
254323,"this question probably has as many different interpretations as it has readers . to make it understandable , could you explain what "" overlap of the samples "" is and how it is measured ?"
254754,"what do you mean by "" approximating the 2d histogram to the gaussian "" ?"
197529,what do you mean by this ?
254843,couple of questions : 1 ) where is the humidity sensor located ?
254883,what would be the purpose of randomizing in that manner ?
254911,"for multi-objective optimization how to proceed really depends on what you want to achieve , so i would say there is not necessarily a standard . in your case you say the mean is continuous . is the standard deviation also continuous ?"
254952,sometimes there are guidelines for these decisions . but often in boils down to modeling your intuition . do you think that there is a random / fixed intercept / slope ?
254979,"what do you mean by "" effectiveness "" ?"
255172,you are looking for classification or importance of features ?
255198,don't you see that ` auto . arima ` includes drift while your manual ` arima ` specification does not ?
255404,why do you want to discretize ?
255405,"furthermore , a normal distribution * does * look like a hierarchical result , compared to a uniform distribution . so 0 = uniform , 1 = normal ?"
254112,what neural network architecture do you use ?
255371,"could you please clarify what you meant by "" ts1 "" "" ts2 "" in the original post ?"
255475,are you asking for the standard * error * of the grand mean ?
255441,"that warning bells don't go off in your mind when you find that $ max ( x , -x ) $ equals $ - x $ ( instead of $ x $ ) is worrisome . surely , $ max ( 3 , -3 ) = max ( -3 , 3 ) $ should be $ 3 $ and not $ -3 $ , no ?"
255601,what is the model for your time series ?
255545,why do you need a panel ordered logit if the endogenous variable is is binary ?
255716,what do you mean by fixed utility score ?
255782,can you include more information from the text so we can have more context ?
255850,"cronbach's alpha is a property of the set of items not each item separately . can you clarify what you mean by "" one item alpha is negative "" ?"
255921,"do you mean with "" random subject slopes "" a predictor serving as a random effect ?"
256045,what makes you think that these events are not independent ?
256050,is this something you want ?
252324,do you mean the unconditional variance or a conditional variance ?
256246,is it possible that size and market are collinear ?
256303,` if pca and k-means clustering could separate ` you mean that you did pca first and extracted ` m ` strobgest components and then did k-means on them ?
256308,"what exactly do you mean by "" run it multiple times "" ?"
256417,"what are you actually trying to measure when you refer to "" randomness "" ?"
256462,why would you wnt a constant moadel ?
256493,"are you saying that you know $ lambda ( s ) $ only for $ 0 s leq t $ or maybe just $ lambda ( t ) $ , and from this you want to deduce the value of $ lambda ( t alpha ) $ ?"
256474,"binomial distribution assumes that each trial is an independent event . if p ( win ) is changing with the the trial , it's not binomial . also , where is the poisson part ?"
256626,"where you say "" next step is to substitute "" . . . you don't then do any such substitution . if you did there would no longer be $ b $ 's there . it seems like you must have a mistake in what you're writing ( either the substitution isn't being done there or you copied the rest wrongly ) . however , the last 2 equations follow from the previous ones simply by splitting up the sum ; this is completely straightforward algebraic manipulation of the kind $ ( a-b ) x = ax-bx $ . can you explain why the sums go from 0 in the lower limit ?"
256722,it may help to clarify how you would like to estimate $ s $ : is this the kaplan meier estimator you are interested in ?
256851,your approach looks right . i don't see how there can be an upper bound when there is only an exact bound ?
256936,what is the origin of the multiple fits ?
256983,"if you have some many variables , wouldn't you prefer to start with a reduction technique , such as pca ?"
257046,could you write down your model ?
257168,"if response rate is not your criterion , what is ?"
257206,why do you have a cost associated with 0 leads ?
257366,what is your question ?
257411,answering with a question : why did you choose cauchy at the first place . . ?
257447,"it's unclear what you're asking . what do you mean by "" an extreme value exists "" ?"
257534,did you mean [ statistical methods in diagnostic * medicine * ] ( url ) ?
257553,logarithmic scale ?
130754,can you clarify what you are asking about ?
257663,it's not totally clear to me from your description but i guess we can assume you have partial information on the z's ?
257686,what do these things you're summing consist of ?
257771,what does i ( 1 ) and i ( 2 ) mean ?
257851,can you explain the 4th point more clearly ?
257898,"what are your concerns / "" expected safety issues "" against using a multilevel model ?"
257972,` n = 5000 ` should be enough for any race / ethnicity that's more than 2 % of the statewide population . can you find an example of the cdc stacking multiple years of brfss ?
258033,a trivial solution to minimize this objective function is to ignore the input and force all outputs to the same value ( e . g . force to 0 by setting a large negative bias ) . are you sure this is what you want to minimize ?
258061,is this a question from a course or textbook ?
258333,"when you say the "" probability of having an adult subject which is sick "" , do you mean the probability that a subject is sick , given that the subject is an adult ?"
258429,if you have already a model with 100 % accuracy what's the advantage you want to obtain with stacking ?
258524,any reason not to just take the mean of your repeated measurements to average out the noise ?
258844,"what is it you want to do , exactly ?"
259036,please explain what the $ x_i $ are : you haven't supplied enough information to determine much at all about them . are they independent or not ?
259136,"would you mind explaining what you mean by "" sequence analysis "" ?"
259322,"can you say more about your study , your data , & your goals here ?"
259419,this might be due to class imbalance . does the same behavior persist if you increase your batch size ?
259441,which function are you using from the pec package ?
259586,how many coefficients do you have ?
259627,how do you rescale ?
259508,how do you obtain the distributions in each year ?
259783,did you try qq-plots against gamma distributions ?
259846,please explain the * purpose * of this exercise . that will help suggest appropriate solutions ( from among the myriad possible ones ) . * why * are you generating synthetic data ?
259925,"since $ y $ is defined but never referenced , could there be a typographical error in this question ?"
260074,i think your confidence interval for the or is wrong . how are you calculating it ?
260354,"you have estimated $ x $ with the ordinary least squares solution . why not , then , use the standard estimates of its variance-covariance matrix ?"
260360,do you really mean just 2 individuals ?
260407,don't you want to add any background information ?
260454,"1 . in what sense do you mean "" converges to "" ?"
260471,"do you mean the expected number of days that event "" 0 happened in last 3 consecutive days "" occured first time ?"
260491,"why do you want to use $ z $ -scores , what scientific question are they helping you with ?"
260513,pca identifies the directions of maximum variance . does the scan direction neccesarily be the one with the highest variance ?
260589,"please show us the details : how were the standard errors computed , how was the t-test conducted , and how have you determined that the t-test result is not significant and at what level of significance ?"
260615,what article is this ?
260680,"hi and welcome to crossvalidated . your question seems a bit unclear , i can't understand what you are asking and what is your point of discussion . could you explain it better ?"
260831,"by "" stable "" you mean stationary ?"
261022,"what would it mean to "" fix the mean without transforming the data "" ?"
261076,what type of data are you analysing ?
261070,have you thought of swapping to a negative binomial model and then sampling using that distribution ?
261185,"it's still not evident what you are doing , because "" $ x = f ( x ) e $ "" makes no sense . if $ x $ is a real number , then the equation $ x = f ( x ) $ generically describes a discrete subset of real numbers . for instance , with $ f ( x ) = x ^ 2 $ , the equation $ x = f ( x ) $ determines the numbers $ 0 $ and $ 1 $ --that's all . what is the addition of $ e $ attempting to model ?"
261181,what is your question ?
261218,is there variation in the three ms across treated neighborhoods ?
260711,"what is "" p "" ?"
261395,we need more information . why were you asked to change the coding ?
261420,"it's not clear what you mean by "" variance using l1 norm "" . do you mean something like "" what if the mean absolute deviation from the medians were equal "" ?"
261497,"i realize the comment by cardinal is cryptic , but doesn't the paragraph following "" what does the mgf say about the moments ?"
10871,could you indicate school grade ?
261792,"ummm . part of "" random forest "" is "" random "" isn't it ?"
261922,you have one feature & one response variable ?
261923,what distribution are you working with ?
262006,what is your goal ?
103731,"are these percentages continuous ( like the percentage of cream in milk , for example ) , or discrete ( like binomial proportions , a count in some category out of a total count ) ?"
262082,what is $ p_ { ij } ^ { ( n ) } $ ?
262138,"i am not familiar with zernike basis functions , but . . . are the different numbers of the zernike basis functions your different explanatory variables ( i . e . this is a multiple regression ) ?"
262162,"what do you mean by "" poc "" ?"
262272,maybe mean ?
262359,maybe calculate $ p ( x k ) $ using geometric series ?
262532,what do you mean by populations ?
262594,welcome to our site ! please consult the information about the [ tag : self-study ] tag concerning how to make your question more focused on what you need . as a hint : have you considered working out the mean and variance of $ sqrt { gamma_0 } y_t / c_t mu $ ?
262609,"since you don't actually tell us what you think "" correlated "" means , we may have difficulties answering your question . but here's a hint about the situation : what is the value of $ e [ epsilon ] $ ?"
262630,"cetainly not : extreme value distributions are continuous , whereas the maximum can take on only integral values between $ 0 $ and $ m $ . unless all the probabilities are $ 0 $ and $ 1 $ , the maximum will not degenerate to an atom , either , so it cannot even be a limiting case of an extreme value distribution . is your question really about finding the distribution of $ x $ ?"
262642,moreover : what are you trying to predict ?
262863,$ p ( theta theta ) $ ?
262872,you have many covariables ?
262907,"how , in your view , is an ar ( 1 ) like $ y_t = 0 . 5y_ { t-1 } e_t $ not stationary ?"
263004,"are samples for a , b and c independent ?"
263065,you refer to $ x_1 $ and also to $ x_1 . $ are those two different things ?
263152,what exactly does your plot represent ?
263613,what about 1-fnr ?
263699,can you tell us the context ?
263897,"why would you want to "" distribute "" the records into regions / strata and perform separate analysis ?"
263905,"when you say * high level description * , do you mean detailed and technical or intuitive and "" big picture "" ?"
263885,your question is rather sparse . how familiar are you w / irt ?
206162,is this homework ?
264163,"do you have any idea what might relationships might exist in these data , or what you might want to look at ?"
264152,it should be possible . could you include a sample time series that would illustrate what kind of data you have ?
264393,test set should have target variable ; otherwise how would you calculate the generalization capability ?
264394,why not just plot the data ?
264628,"see dave giles' blog post [ "" can you actually test for multicollinearity ?"
121650,which mean are you interested in testing for difference from zero - the products or the original stock returns ?
264658,is your categorical variable binary ?
264936,"if you throw a dice once , than you get one result . still that result ist taken from a distribution . even if there is only one value sampled from from that distribution . every single residual stems from some distribution of possible residuals that could have emerged . does that answer the question or was the question broader ?"
161006,it is not clear what exactly you want to determine . do you want to compare versions in different diseases ?
265200,with prevalence do you mean absence / presence data or counts ?
265449,"are the 3 different phyla each from the same statistical unit ( patient , plot , etc ) ?"
265498,"on line 4 $ b = b ( a ) , $ ?"
265817,is this a self-study question ?
265907,asplre94 is y out of x ?
265912,what is your goal ?
265033,are your levels continuous or discrete ?
266092,the purpose of this question is somewhat unclear to me . as a pure coding question it would not be on-topic here ( see our [ help / on-topic ] ) but i wonder whether the underlying question is what kind of graphical output is appropriate here in the first place ?
266166,"1 ) self reported ethnicity is prone to errors , 2 ) did you used ld thinned data , did you have a look at the loadings ?"
266505,have you included responses for neither ?
266531,"i'm a bit confused here . are you fitting a binary logit model , multinomial , or ordinal ?"
266541,i don't understand the question . is this something unexpected in your case ?
266585,can you use ` glmnet ` ?
266675,"sure , why not ?"
266741,are you trying to perform an anova type analysis where you want a trend alternative ( e . g . like $ mu_4 geq mu_3 geq mu_2 geq mu_1 $ with at least one strict inequality ) ?
266998,is this a question from a course or textbook ?
267034,are you sure that your formulation of the null hypothesis is what you want ?
267289,"i am not clear on the problem . there are 2 mediating variables , z and m ?"
267423,knowing that you are dealing with $ y = f ( vec { x } ) $ verses $ y = f ( x ) $ is a huge difference . what is the size of your input vector ?
267529,what happens when you replace your second line of code with the following ?
267895,can you provide some context for this to help clarify what you have in mind ?
267930,"you may want to explain what a 1 , 1 distribution in bridge is . your more likely to get a response if you don't assume prior knowledge about bridge . what do k and x stand for ?"
268311,what exactly do you mean by $ hat { y } _t $ ?
268381,"you should probably add self-study tag to your question . you are using a scholastic dataset , aren't you ?"
268584,have you taken a look at gams ?
268606,what exactly is unclear for you ?
268768,"how to "" defend "" your model depends on what you are trying to accomplish , and how well it accomplishes this specific objective . are you trying to forecast , or make inference about the parameters , for example ?"
268953,[ glamour stocks are ] lower than * what * ?
269109,what is the question ?
269170,have you tried for $ n = 2 $ ?
269236,"what do you mean by "" corrupted "" ?"
269258,are you controlling for other variables in your regression model ?
269335,this is not a direct question . what do you want to know ?
269426,what * exactly * is your premium variable ?
269653,"you refer to "" another "" method . which method are you currently using to find $ d $ and why do you need another ?"
269981,* * hint * * : of course not . can you construct a counterexample ?
269983,"this looks like a statistical question to me , fjp : could you explain what model you're trying to implement with ` lm ( categoric ~ . . . ) ` ?"
270084,why use p = 0 . 0667 ?
270286,what * exactly * is unclear for you ?
270287,how exactly does your data look like ?
270351,what is the pairing in these data ?
270405,"please explain what you mean by "" underlying distribution "" ( doesn't the problem assert this is normal ?"
270429,have you checked out-of-sample performance ?
270589,"we appreciate your efforts to clarify the question . in order for it to be re-opened , it has to stand by itself without requiring us to visit another web site to understand it . but before you go to the effort of providing those details , why not explore your questions about regression and regression formulas ?"
270671,how should one answer your question ?
270802,would the difference between $ 19 . 9 $ and $ 19 . 8999999999999999 $ matter ?
270846,clustering is descriptive . it is not used to produce small errors . otherwise wouldn't you make the clusters consist of single points ?
270944,does this help you url ?
271138,what is not clear to you ?
271505,how did you determine that the result is three factors ?
271641,did you determine that there are exactly two clusters ?
271643,"what quantity do you mean by "" uncertainty "" ?"
271651,why not simply stack the data up forming an anova using a 3 level factor or variable specifying the partitions ?
271686,i'm getting nothing but nans for ` m ` . . . can you tell me what version of python you're running ?
271736,"knn is used for classification , k-means is used for clustering . which one are your referring to ?"
271751,"just out of curiousity , why do you want this technique ?"
271809,is your question mainly about how to decide on ther optimal number of factors to extract ?
271835,"could you elaborate on what you mean by "" valid "" ?"
271857,have you thought of looking at the cran task view on metaanalysis ?
271968,"` cause numerical troubles ` . after all , are you talking about correlatedness or about multicollinearity ?"
272077,"could you elaborate on what you mean by "" $ t $ is not a constant "" and "" each observation varies in time ?"
272204,is 'ecg' referring to electrocardiographs or something else ?
272342,don't you mean not independent ?
272344,"are you thinking about the true variance ( $ sigma ^ { 2 } _ { y x } $ ) , or the sample variance ( $ hat { sigma } ^ { 2 } _ { y x } $ ) ?"
272653,pls define decay ?
272808,what's the question ?
272834,why do you need $ pi = 2 ^ { -t / h } $ ?
272891,perhaps estimate ar ( 3 ) and check for auto-correlation in your residuals ?
272972,"please explain what you mean by the "" cumulative statistic of my sample "" : what is that ?"
272993,do you mind if i ask what are you counting ?
272994,"provided $ ( x_1 , x_2 , x_3 ) $ is independent of $ ( x_4 , ldots , x_ { 10 } ) $ , the second equality will be true by virtue of the very definition of independence . does anything remain to be said ?"
273119,"answers will depend on the structure and semantics of your data . depending on what you have , you might use paneled scatterplots , or scatterplots with a third dimension indicated by colors . can you tell us a little more about your data and maybe post a sample ?"
73250,what is the deterministic example you have in mind ?
273251,"what about the graph "" makes no sense "" ?"
273291,did each student get the same set of puzzles ?
273388,"you'd like to set a bounded continuous prior on regression coefficients , is that right ?"
215521,url why not work it out for yourself in the case $ k = 2 $ ?
156016,"the eigenvectors are the same in both cases-- $ p $ and $ p ^ { -1 } $ play their roles in both formulas--and therefore are subject to exactly the same interpretations . which part don't you "" get exactly "" ?"
15662,how would you even do a t-test on the two correlations ?
45874,why not simply compare $ s ^ 2 $ ?
55928,is there a danger that an underlying spatial feature is a significant factor - beyond just the issue that close cells have similar scores ?
80499,"if the other conditions hold , sure , though if the categories are anything but nominal it's not an especially powerful test . are you talking about distributions of counts ?"
49731,did you try the ` lsmeans ` and ` multcomp ` packages ?
64409,ok a few other questions : 1 ) are there any random effects in this model ?
71206,what does the standardization need to achieve ?
258447,"you should give some thought as to * which * p-values are different when you fit the same model to the same data using raw & orthogonal polynomials , & their interpretation . what about the model predictions ?"
182949,can you point us at the formula you are talking about ?
123758,do you intend $ epsilon $ to be close to $ 1 $ ?
143468,"you have the three full conditionals , where is the difficulty for you ?"
263703,did you read the explanation at this answer ?
267957,is your data cross-sectional or is it time series ?
273602,"what exactly do you mean by "" applying weights to the glm "" . are you referring to adaptive / weighted regularization using a vector of regularization parameters ?"
144555,interesting question ! i don' t think it is trivial . . . can you give some context from where comes the interest in this question ?
273820,"to what does "" solutions "" refer ?"
273868,"it's not entirely clear to me what you're trying to do . i am guessing that you want to explain / predict the number of goals scored for each team in each match . so what you have are observations on the number of goals for each team $ i $ as it plays another team $ j $ : i . e . $ y_ { i , j } $ . is this correct ?"
273877,"i am not sure that there is a correct or more correct approach . i think your hypotheses and analytic strategy should guide you in the model specification . however , i am curious about two things . ( 1 ) can you create indices for different types of capital using those 37 ivs ?"
273993,is there any reason you've asked this question twice from different accounts ?
274374,"the plot you posted shows a clear pattern to me , namely a correlation and hence dependence between x and y . that's exactly what you expected . so where is the problem ?"
274436,wouldn't a standard change of variable put $ psi-c $ for $ theta $ ?
274534,what do you consider an outlier to be for your problem ?
274674,what do you mean by interfere ?
274743,how are these tests different ?
274856,is the length of that example series typical ?
275052,"it ought to depend on what you are doing with $ y $ , shouldn't it ?"
275033,is each $ p_i $ a pmf ?
275192,did you search this site ?
275276,"if $ y = x_1 dots x_5 $ in population ( and not just due to random sampling ) , then this is your ideal prediction . why would you choose anything else ?"
275483,"yes , you can try it . why would regression not be possible ?"
275541,which are you asking about unequal variances or unequal sample sizes ?
275573,"what is "" bijective "" intended to mean here ?"
275642,you mean a study published in a peer-reviewed journal ?
276004,did i answer your question ?
274817,i think the issue here is explained in the package author's pages url but not in the context of bootstrapping . perhaps you can have a look and then maybe clarify your question if i have mis-understood ?
276105,are you looking for correlation or a regression function ?
276135,"5 to the 6th power is 15625 , and a standard 4th-order polynomial curve has 5 parameters - might this be related to what you had read ?"
276097,"given that some function names occur in more than one package , can you explicitly say which package the function ` rlm ` you're using is in ?"
276196,would it not be better to impute them rather than selecting both variables and cases ?
276403,"is the question you're interested in answering nearer to "" does one tend to rate higher than the other "" ?"
276527,"could you explain what kinds of "" patterns "" you are seeking out ?"
188252,maybe i am missing something but what is the prior ?
276652,"so which one of the parameters $ theta_1 , theta_2 $ you want to call a name ?"
276829,"can you clarify - why can't you use a stochastic forecasting approach , one for each variable using the others as exogenous regressors ?"
277122,"hint : $ p ( c mid a , b ) p ( a mid b ) = ?"
277183,"i don't understand anything here , starting from the second table . what are v2 and v3 ?"
277285,"i think that when you use factors , then r automatically transforms these to dummies ?"
277573,the questions are very general . did you use a test set to check the accuracy ?
277645,what does visualize a matrix mean ?
277733,"it is not clear for me , are you talking about dependence between persons , or "" questions "" ?"
277774,mcmc algorithms can be used for a variety of purposes . is this for some bayesian model ?
277785,can you give the authors and title of the paper ?
277909,what kind of information do you truly have ?
278010,"what does your "" gestation "" variable look like ?"
278219,what is your dependent variable ?
278569,"there is a corpus of published material on this subject . have you read any of their work , including what attributes they found informative ?"
278751,can we assume large $ n $ ?
278824,are they different patients each year ?
266540,"do you mean an intercept parameter that is estimated , or do you mean a term in the model that has a constant effect ( an offset ) ?"
278904,` how should i calculate it ?
279043,"looks like this could be an assignment . in which case you need the self-study tag . also , although you don't say it are you assuming that the weights have a normal distribution ?"
279098,have you tried adjusting the learning rate to smaller ?
279117,are the $ q_t $ s fixed beforehand or do they depend on the history of the chain ?
279279,"i am no expert , but for terminology : you would first decide on a statistical * model * for the data , and then * estimate * the model parameters , and that is the point where you would use a statistical * test * to evaluate the size / significance of any effect . you want to treat the run number as an ( integer- ) time ?"
279307,"are you able to implement a garch ( 1 , 1 ) in r ?"
279591,"could you tell us where in this dataframe we could find information about "" promotions "" ?"
279806,"one question to consider is whether means and standard deviations make sense in this situation . why should the difference between "" strongly agree "" and "" neutral "" be the same as between "" agree "" and "" disagree "" ?"
279888,"what are the treatments , different temperatures , or the presence / absence of smoke ?"
279918,"rare count can be modelled by poisson distribution , so a poisson regression might do . . . or time series , but with a few sightings of a rare animal i doubt if time correlation is important . more sightings might be because of more effort , are you sure the effort was approximately constant ?"
279943,"i got lost at "" the treatment group receives much stronger benefits from the intervention than the control group , "" because i understand a control to mean * by definition * that its members do not receive the intervention at all . what's going on here ?"
280050,could you clarify your question ?
280098,"your simple b & w cases should be pretty simple to solve with keras . you mention you tried but didn't have much luck . two possible issues , did you normalize the greyscale pixel values to 0-1 . 0 , and did you normalize the coordinates / radius ?"
280085,which othet tests impeach your mind ?
280171,could you post more information about your design ?
280220,"could you tell us a little more specifically what "" validate "" means to you ?"
280230,do you truly have $ x beta $ or do you have the * predicted * responses $ x hat beta $ ?
280306,"your hypothesis is identical to $ mu sigma ^ 2 / 2 = 0 $ . call its left side $ tau $ . what is to prevent you from , say , replacing all occurrences of $ mu $ in $ f $ by $ tau- sigma ^ 2 / 2 $ ?"
280355,what do 3 plants mean ?
280398,"this * sounds * like a three-way table : rows , columns , and before / after . would that be the case ?"
280405,are you really good at programming vba macros in excel ?
280559,is traveling the same as going from a to b ?
280626,are you familiar with mediation ?
280680,you are calculating statistics on 10000 students manually using paper and a calculator ?
280757,your categorical dependent variable is nominal or ordinal ?
143741,"i'm not 100 % but if your values are low , is it possible to use fisher's exact test to compare each time-slice of data to each other and then as new weeks come in , add it to the computation ?"
280899,please indicate major components / elements eyc . of your model ?
280929,why is the intercept not in the model ?
281048,what was your rationale for removing the intercept ?
281051,can you post the entire coefficient table ?
281162,do you know the ( theoretical ) minimum and maximum of the original values ?
281563,what is your objectives ?
281719,"there are many ways to solve your problem . the simplest is to keep generating numbers until $ x $ of them fall in the interval $ [ a , b ] $ . the only challenge is that could take a long time when the probability of that interval is small . but in that case you could use other methods , such as rejection sampling . and in any event , applying the quantile function to a suitable range of uniforms will always work . so the real question concerns your objectives : how many values do you need to produce at once ?"
281743,are those numbers counts ?
281801,what are you calling r ?
281881,"please tell me if i am understanding you correctly . you are attempting to calculate a bayesian estimator from a pearson-neyman parameter estimate and a fisherian likelihood estimate , is that correct ?"
281683,"in fact , $ x_ { ij } $ has influence on $ _ { ij } $ means $  ne 0 $ . how can test statistics does not involve mle of $  $ ?"
281984,could you explain more about what's confusing ?
282075,what kind of data is your dependent ?
282275,what are you trying to do ?
282381,are you sure the three are comparable ?
282382,the two approaches you mention can help you answer somewhat ( or very ) different questions . what research question ( s ) do you want to answer ?
282391,"this generally looks right , but it's hard to tell without any accompanying text and descriptions of your notation . will you supply some ?"
282497,1 . i take it the exp1 and exp2 are two instances of the same experiment ?
282736,may i pose the consideration that the variance you seek is not defined ?
282926,the question you link too have two upvoted answers . can you explain why they are not satisfactory ?
283018,"could you supply a context , reference , and / or example ?"
283026,"odds ratio means one's odds vs another's odds . in your example , the ratio of odds of married vs not married is 3 . 747 . in your question , one person is married and has a professional suffix . which one is another person ?"
221072,what source is telling you to whiten time series data ?
283238,great ! do you mind pointing out which citations you mean ?
283336,do you have a reference for the machine learning lecture notes ?
283347,can you show sone density plots or pairs plots ?
283499,can you provide some context for this ?
283703,it might be helpful if you could provide some context here . what do you understand about these already ?
283715,"a nonstationary process does not necessarily have a constant mean . so , if the process is ergodic ( say that $ displaystyle frac 1t int_0 ^ t x ( t ) , mathrm dt $ converges where $ x ( t ) $ is some sample path to realization or "" time series sample "" ) , what exactly should it converge to ?"
284010,"this isn't really enough information for an answer , can you tell us more ?"
284424,"could you explain--preferably quantitatively--what you mean by "" important "" ?"
284425,x2 not having readings on weekends . does it mean something on its own ?
284710,"what does "" best fits "" mean ?"
284208,i think you need more detail about the level of explanation you want . are you sure there is no answer on this site already ?
284848,are you asking why use sgd rather than gd ?
284856,"why don't you use an "" approximate randomization test "" instead of mcnemar ?"
285140,"to match a paper , you may do best to contact the authors ?"
285163,it's a good question . but doesn't it have a trivial answer ?
285188,"what do you mean by "" multiple r "" ?"
285262,your question is very unclear . are you asking how to evaluate the l-skewness and l-kurtosis for that list of distributions in order to make a plot something like [ this ] ( url ) and [ this ] ( url ) ?
285423,what models are you using ?
285466,add a second plot that shows the differences between the two ?
285544,why are you interested in the significance of certain items ?
285554,how do you justify throwing away some ( how much ?
285610,could you be more specific ?
285631,could you try plotting $ x_1 $ against $ y $ to look at their relationship ?
285713,probability distribution with negative values ?
285900,"please spell out your acronyms . what is "" pmi "" ?"
285927,what don't you understand about them ?
286064,"welcome to cv . since you re new here , you may want to take our [ tour ] , which has information for new users . i am not sure why you think that your analysis has anything to do with interaction and mediation as your title indicates . are you asking about how to include an interaction term or how to conduct a mediation analysis ?"
286131,have you looked at arch / garch models ?
286176,"it doesn't look like there's much to say : since the whiskers in all three of these plots are visual representations of the tails ( specifically , the outer quarters of the distributions ) , what are you hoping the answers will tell you that isn't already extremely obvious ?"
286219,"the first sub-question regarding the "" * why isn't there an implementation of gbdt in weka ?"
286382,"this is way out of my experience , but a quick search suggests [ this ] ( url ) might be relevant ?"
286421,what value do you use for ` tt ` ( the length of the time interval ) ?
286498,"what do you mean by "" extracting matrix "" ?"
286501,"so , you want to find the point in one group which is the closest "" on average "" to the second group ?"
286599,can you clarify your last sentence ?
286633,how do you select your random sample from the transactions ?
247582,do you have replication per individual & day ?
286645,can you explain what variables x and y are ?
286812,are you actually interested in confidence intervals ( i . e . the model itself or the model parameters themselves are what you are interested in ) or do you look for prediction intervals ( i . e . uncertainty on predictions [ for new cases ] ) ?
286845,what would it mean ?
286986,"if you're asking for a complete description of the lars algorithm , i think that's too broad to answer here . have you read the relevant papers ?"
287056,maybe you just missed a minus sign on the loss calculation ?
287362,what is your question ?
287623,what does mlp stand for ?
287635,"what do you mean by "" physical meaning "" ?"
256422,i dont understand the notation in your second displayed equation . can you explain ?
287928,would your question be different after reading the parameter estimation section of the wikipedia page on the [ weibull distribution ] ( url ) ?
288003,"in what way do you "" see "" bias in this plot ?"
288021,do you mean that you have a log transformed outcome or are you analyzing categorical data ?
288084,did you randomly select the training half ?
288001,"it looks like you have a [ non-linear errors-in-variables problem ] ( url ) . in respect of the remaining symbols , please clarify their role -- are they variables without observational error , constants , parameters to be estimated ?"
288091,"there's no attached image and i think this is more of a stackoverflow question , but do you want ` ribbon ( ) ` ?"
288100,can you not reconstruct x from delta x by integration ( up to an additive constant ) ?
288138,you only need to include the time points for which you have data . does that help ?
288273,how exactly would you define what you're trying to find ?
288338,"been wondering this myself recently , considering making a similar post i can't seem to find a comprehensive guideline with references . perhaps we could put one together as a cv community ?"
288449,"out of context , this appears to have many possible interpretations ( and it might difficult to arrive at one that's actually true ) . could you therefore explain the context of this quotation ?"
288496,"if you only have time , you may use conv1d . if you have a stream of images ( such as a video ) , you can try conv3d . can you give more details on "" additional inputs "" : additional to which original features ?"
288819,what is your question ?
288956,i don't understand . what is the problem you face ?
288560,by skewed distributions did you mean class imbalance ?
289061,you want to estimate the impact of 15 year olds or of age generally ?
289336,what is your main hypothesis ?
290530,are you talking about a functional relationship or a statistical correlation ?
290651,did you mean to say that the integral equals something else ?
291019,"can you expand to give more details and also clarify what you mean by "" correlate most with the missing values "" ?"
291087,why only those two rather than say mean deviation ?
290962,why don't you plot the functions $ f ( x ) = x ^ 2 $ and $ f ( x ) = x $ and compare them ?
291158,"what does the "" reservation column "" denote ?"
291356,perhaps you mean a uniform distribution ?
291410,is there some reason why you don't use penalized regression ?
291445,your values for ` ssr ` are strange . what exactly do you mean by this quantity ?
291492,"what would a "" traditional function "" be ?"
291572,questions that are only about how to use software are generally off topic here . a question like 'shouldn't varimax induce non-correlated factors ?
292263,go up for those that can benchpress more ?
292295,what's the fitted mean for your poisson ?
292308,is this for professional work or as a student ?
292378,"as explained [ in this thread ] ( url ) , computational complexity is proportional to the size of the network . isn't it reasonable that , given more local minima , a stochastic algorithm will have a harder time finding a near-optimal solution ?"
292384,compute their variances : could they possibly be constant ?
292427,all i am trying to do is get the best out of the n metrics by combining them using a weighted sum model ( weights unknown ! ) - how do you measure best ?
292517,your sampling weight should depend on your sample design . how did you design / collect this sample ?
292583,is this similar to what you are referring to ?
292691,possible duplicate of [ what is the difference between test set and validation set ?
292793,"before you go further , what are the p-values for your coefficients ?"
293823,did you google this ?
294098,have you seen this post : url ?
294154,what is bishop's book ?
294182,what does the curly $ n $ on the denominator represent ?
294210,"i suppose you are to derive the * conditional * variance of the ols estimator . so are you maybe asked to derive the variance of that ratio * conditional on $ x_1 , ldots , x_n $ * ?"
287848,"outlier detection is often one of those hand-wavy areas of statistics relying on subjective or context-dependent definitions . one thing to be wary of is the implicit assumption of normality you get when you use that 68-95-99 rule . furthermore , it may be useful to apply some regression to see if the variability in the outputs is due to drastic differences in the inputs . for instance , fit a linear trend to x = ( 1 . 5 , 2 , 3 , 3 . 1 , 50 ) , and y = ( 6 , 8 . 2 , 11 . 5 , 13 , 210 ) . is the last observation an outlier ?"
294388,"without any question , this * model * "" controls for "" $ x_2 $ . the question appears ambiguous , though , because it seems to be asking about * the method of fitting the model * rather than the model itself . do you conceive of the $ beta_i $ as taking on the values estimated by the elastic net or do you re-estimate them using least squares after having selected the two variables ?"
294577,how many different labels are there for the occupation variable ?
53210,do you know how to bootstrap in r ?
295182,what is aht ?
295203,standard error is respect to a statistic . are you referring to the sample mean ?
154009,what is the likelihood you intend to use ?
295492,can you elaborate a bit about your data and which algorithms you are using ?
294762,"firebug , why not write that up as an official answer ?"
295264,"can you elaborate on ` use a regression model to estimate the error . then i could compare this to the error obtained by using the model to a very large sample . . . ` , preferably with a concrete example ?"
295813,what ml are you referring to ?
295817,"why , in your mind , do you need to do anything ?"
296036,why not perform the train test split first and then cv over the train set ?
296393,both correlation and cosine similarity / distance are measures of similarity / distance . is your question specifically about pearson's correlation and cosine similarity ?
296486,what exactly do you need ctt / irt for ?
296650,have you plotted the simple two ways ?
296685,"presumably because your $ x ( t ) $ is unobserved , or only parially-observed ?"
296716,did you allow for a random effect of time in your models ?
296616,this is very broad . i doubt it is answerable at present . can you make this clearer & narrower ?
296805,"this sounds more like an outlier test for f , than a test for comparing means . would you agree ?"
297143,"if you care about minimizing the l2 distance from $ x beta $ to $ z $ , why not just use ols as follows : $ beta = ( x ^ tx ) ^ { -1 } x ^ tz $ ?"
297259,what does the line look like between the top of one head and the top of the next head ?
297451,"is any of the variables you want to impute the dependent variable , or are they all independent variables ?"
297487,"although you refer repeatedly to "" illustrations "" and "" results , "" there are none of the former and only incomplete accounts of the latter . have you had problems including this information in your post ?"
297235,how does that equation give you expectation $ b $ ?
297756,are all 3 regression models fit to the same data ?
298576,do you want a closed form analytical solution ( using laws of probability and calculus ) or are you looking for a way to estimate the expectation using r or python ?
298717,"sorry , i missed the part where you said that you had almost identical coefficients . but what exactly did you mean by almost identical ?"
298719,"if you run it once , 20 , . . . infinite times doesn't it coincide to be the expected value of your distribution ?"
298753,"suppose your factor has levels a , b and c . your procedure assumes that the difference between a and c is twice the difference between a and b and b and c . is that what you want to assume ?"
299073,why ?
299086,why does it seem wrong ?
299306,how are you measuring the collinearity of the variables in question ?
299408,"you mean clustered barcharts , don't you ?"
299503,"but whether you are using ols or qr or something else , i would specify the same model -- a model that reflects my knowledge of the object being modelled . e . g . if you think it makes sense to include the dummies in the ols regression , then include them in the qr , too . regarding endogeneity , have you tried searching the literature ?"
299426,"to clarify , is the setting that $ p_1 , ldots , p_n $ are iid with mean $ mu $ and variance $ sigma ^ 2 $ , and for each $ t in { 1 , ldots , n } $ you draw $ n $ bernoullis with probability $ p_t $ . so overall the data consists of $ n , n $ bernoulli variables ?"
299691,do you have any randomness in the learning ?
300508,"just out of curiousity , what would a negative count be a count of ?"
300548,i understand your question as whether to fit a model with all observations or split the observations into n subgroups and fit a model for each subgroup . is this what you want to know ?
300829,whether a method is good depends on what you're trying to do . can you say more about this ?
300945,"i'm having trouble understanding your question . what do you mean by "" useful in categorical data ?"
301022,do you suppose it might be a coincidence that $ 1 / 2 . 05 = 0 . 49 $ ?
301048,could it be the coefficient instead of the hazard ratio ?
301054,why would you want to do matching on the pc scores ?
301099,"a few questions : do you expect that the influence of position-in-the-order ( pio ) should be monotonic if h1 is rejected , or do you need to test for idiosyncratic / non-monotonic effects of pio ?"
301472,there are many possible explanations : ( 1 ) are the differences in rmse really significant ?
301481,"` eucledian distance measure on the jaccard similarity index matrix ` this is misty . jaccard similarity is a proximity measure . euclidean distance is another proximity measure . maybe you meant ` or ` , not ` on ` in that sentence ?"
301572,"just to clarify , you are interested in knowing if the "" cont "" group differs from "" pps / pws "" group on all four variables ( 500r , 500l , 1000r , 1000l ) ?"
301764,have you considered starting with a minimal sufficient statistic and then enlarging it to include more components ?
301767,""" but for practical case , i cannot visualize a high dimensional data set first before i choose the method . "" - i don't get this part . what do you mean you can't visualize the data first ?"
301977,price elasticity of what quantity ?
301971,is the smaller reward always 10 ?
302081,please clearly indicate that this is related to work for a subject ( see the [ help / on-topic ] on homework-style questions . what makes you think a gamma glm is * necessary * ?
235493,you're fitting regression to time series data ?
302168,"taking the logarithm is called a log * transformation * and is within the broader category of [ power transforms ] ( url ) . i wouldn't call it normalization since typically when i see the word "" normalization "" i think of scaling ( and perhaps a shift ) ?"
302215,what leads you to claim pearson residuals * follow a normal distribution * ?
302202,what question are you trying to answer with the regression ?
302315,is this a homework assignment or self-study ?
302402,if you want to know how to implement this in spss you would be better on an spss site . do you have a statistical question about how to compare them ?
302533,"what do you mean by "" treating all items equally ?"
302621,do you have a control group to compare against ?
302718,why would you do that ?
302839,what happens if my first roll is 1 ?
64624,"the semi-partial correlation isn't inaccurate because of interaction ( correlation ) between predictors variables , it controls for this correlation and statistically removes the effect of the conditional "" predictors "" ; i . e . provides the correlation estimate between the "" response "" and "" predictor "" of interest while controlling for the rest . what is it that you expect / want ?"
303358,are you measuring the r-squared using the training set ?
303439,can you show the results of pca ?
303778,"my values come from a bernoulli $ ( 1 / 2 ) $ distribution . $ v $ is large enough that there is at least one $ 0 $ and one $ 1 $ in $ v $ . thus , $ o ( t ) $ is $ 0 $ when $ t lt 1 / 2 $ , $ 1 $ when $ t gt 1 / 2 $ , and indeterminate when $ t = 1 / 2 $ . since this will be the case no matter how large $ v $ is , how do you suppose $ v $ could possibly be estimated ?"
304080,it would help to know more about how those 300 tests came to be . how are they or aren't they related ?
244738,could you give more details on what you mean by regression adjustment ?
304391,how would you interpret the predicted results of two parallel regression lines ?
304515,"not a whole lot . if this information were accompanied by a description of the eigenvectors , the units of measurement of the original variables , and their univariate distributions , it is likely much more could be said . why are you performing an eigenanalysis of the covariance ?"
304557,how many animals are there ?
304687,is there any reason why you have no test set ?
304934,can you elaborate on how weights can be endogenous ?
304964,what do you mean mle is undefined ?
247578,"could you please explain what you mean by "" decomposing "" a sum ?"
305168,why do you think that is a problem ?
305190,fourth-order or for any order bigger than 2 ?
305203,"naive question : could you project to 2d with pca -- as in your graph , above -- and then use ` dbscan ` or some other standard clustering in 2d ?"
305306,is your output perfectly represented by your input ?
305326,"just to clarify , are you testing goodness-of-fit for a multivariate distribution ?"
305475,may we presume the variations in the sampling rate are independent of the values of the samples ?
305503,"a problem with this approach is that , if $ k n $ , then the determinant of each covariance matrix will be zero . an intuitive analogy to this situation is that the volume of a 2d surface in a 3d space is zero . one could potentially get around this issue by operating in a lower dimensional subspace . but both ellipsoids must occupy the same subspace . does this apply in your problem ?"
305612,"there is a great deal that can be said . for starters , you might consider plotting the product of ` s ` and ` js_avg ` against ` js_avg ` . along those lines--is there any theory to suggest a functional relationship between these two variables ?"
305649,"i say no , if i understand this correctly . aggregation typically reduces variability and thus increases correlations . high correlation is typically a measure of how much information you have thrown away . in any case what does representative mean ?"
305688,are these time-series data ?
305900,how about use splines ?
305902,when people used to do this by hand they used the harmonic mean of the $ n $ s . but why not use software which fits linear models for you ?
305890,it is not clear to me which variables here are predictors and which are outcomes . can you edit to clarify ?
305914,"how is partial eta-squared or even "" total "" r-squared defined in a model with correlated errors ?"
305918,is the outcome fairly rare ?
305971,"what do you hope to accomplish by formally pooling the studies , that you can't achieve by analyzing and discussing them separately ?"
306081,sampling vsriance = s . d . ?
56397,"what , if anything , differentiates among the three distributions from each treatment ?"
306238,what type of analysis are you performing ?
306536,"can you be more precise about what you mean by "" signal / noise "" here ?"
306591,"it is not clear to me what hypothesis you are testing . are you trying to compare two time series "" pre-period "" vs "" post-period "" ?"
306637,can you clarify by editing your question what you mean by the trendline of your model ?
306440,some sidenotes : 1 ) have you ensured that your software is properly working for directed networks ?
306582,"for a procedure that has been stated in such generality , without providing any context , it's hard to conceive of any other answer than that this is called "" changing the data . "" perhaps you could explain the purpose of your procedure and the criteria you are using for the modification ?"
306648,is there a max number of classes ?
306722,"you begin your questions with : "" * i have one park . . . * "" and end with "" * . . . are the two parks significantly different ?"
306725,is it an option to use a simpler method which takes less computation time ?
306927,"it would help to know the joint distribution of $ ( y , z ) $ . do you ?"
306962,that doesn't sound right . there are ways to plan stepwise testing that preserve the type i error but it doesn't sound like this was done in a preplaned stepwise manner . it seems that you mainly worried about the type i error after the two tests conflicted . am i right about this description ?
307000,"how about adding in some features for time , like eg ` sin ( dayofyear / 365 * pi ) ` , ` cos ( dayofyear / 365 * pi ) ` , etc ?"
307011,what model are you using ?
307128,what's your use case ?
307408,"no , aic / bic assume same data are used in both models . why wouldn't you try to fit both models with the same amount of data ?"
307720,"* * what's the meaning of "" units do not interact with each other "" ?"
307880,have you tried arima or exponential smoothing ?
308125,have you tried moment generating functions instead ?
308135,"these are bizarre variables and model specifications . you don't state how age is scaled , e . g . , is it an integer or bucketed ?"
308164,it's not really clear to me what specifically you are interested in . are you interested in [ inverse transform sampling ] ( url ) ?
308190,interesting question . what do you need this for ?
308224,"do you have a specific density $ f $ given to you , or is this a general question for any $ f $ ?"
308409,"how are you doing model selection , i . e . choosing number of clusters ?"
308562,why would you expect higher n when the correlation is stronger ( further from the null value of 0 ) ?
308760,i think the last sentence is not correct . why don't you try to write the likelihood replacing $ sigma = frac { mu } { c } $ and find the mle ?
308780,can you add additional information ?
309002,do your extracted features keep a notion of spatiality ?
309085,"how are you defining "" patient notices symptoms "" ?"
309241,where is that data from ?
309274,"can you please define what "" a few "" points refers at ?"
309358,how are you planning on validating the model ?
309402,how does pca reveal information about the optimal number of clusters ?
309632,"you say "" to solve the issue "" as if there is necessarily an obvious issue to be solved , but what is the issue , and what is its nature ?"
309678,is this question related to coursework ?
309826,"it does help . so your data is daily , and the "" time "" probably refers to weeks ?"
309943,you really don't need the blue curve to conclude that ( why entertain normality at all ?
310037,"idk , is separation truly preserved ?"
310055,what is the full code you are currently using ?
310082,can you elaborate on what you mean by you controlling the explanatory variables ?
310322,"could you say more about the nature of the time series ( frequency , what is measured , . . . ) and the question you want to ask of the data ?"
310353,should i post this as an answer or would you perhaps just delete the question ?
310403,"a p-value of a slope never measures the quality of a fit , at least not in any usual sense of "" quality . "" could you elaborate on what you mean by "" quality "" ?"
310442,why not just fit a model with x and an indicator for which half of the data-set the observations are in ?
310719,details ?
311035,have you tried reading books and articles about sabermetrics ?
311066,"if you have historical demands by day , you can simply aggregate these in weekly buckets . can you be a little more specific what the problem is ?"
311207,did you try a search here ?
311228,what are your numerator & denominator in these ratios ?
311382,can you provide more details about where this was proposed and what the context was ?
311589,why did you choose cube root ?
311619,do you have continuous or discrete time ?
311675,where did you see the notation ?
311739,what form is $ sigma $ in ?
312045,could you please add a reference to the textbook where this exercise appears ?
312506,"why not just search for "" inventory control "" ?"
312559,"by l2 and l1 normalization , do you mean * regularization * ?"
312609,what kind of data is it ?
312712,does this help ?
312726,"many threads here have discussed the distribution of $ x / x ^ 2 = 1 / x $ : because ( no matter what $ mu $ and $ sigma gt 0 $ may be ) $ x $ has positive density around $ x = 0 $ , $ 1 / x $ has an undefined expectation . that takes care of the left hand side . can you evaluate the right hand side ?"
312767,do you have some clear hypothesis you want to address or are you fishing for any difference on any question between any of the groups ?
312916,could you please add a reference to the paper or tutorial you are using to try and figure this out ?
312873,"what would be the reason for round numbers besides "" aesthetics "" ?"
312951,the difficulty here may be related to . . . what if they are * both * cheating ?
313103,what do you mean with the ` village * individual interaction ` ?
313124,"to be clear , say the hidden states are $ x ( t ) $ and the outputs are $ y ( t ) $ . are you saying that $ y ( t ) $ and $ x ( t 1 ) $ are not independent ?"
313140,"could you explain what an "" anova "" would mean in this context ?"
313160,are you familiar with the beta function and its relationship with the gamma function ?
313186,is the question of interest specifically about b doing * more * - a one-tailed hypothesis - or is that wording just a resulting of it being higher in the observed data and the underlying question is really just about a difference ?
313320,how about a mixture ?
313499,what's the problem ?
313715,what are you using the categorical values for ?
313915,"what does a scatterplot of $ ( y , z / x ) $ look like ?"
314325,"does "" simple slope "" mean something different than "" slope "" ?"
314526,good question . have you tried a few simulations ?
314541,you tagged this t-test so is there some doubt in your mind about using a t-test for independent samples ( since you cannot use the dependent samples one as the pairing is unavailable ) ?
314766,is your model linear in ( all ) its parameters ?
314755,"are you supposed to show this directly , or by showing that the clt applies to $ u ( -1 , 1 ) $ variates , using this to show that the limit of the ch . f . of the sum is $ exp ( -3t ^ 2 / 2 ) $ , and deducing from this that the limit on the left is the right ?"
314877,"also , why did you stop the test after 10 weeks ?"
314939,you're asking how rbm is different from logistic ( sigmoid ) activated neural net ?
314936,"you ask "" would they have a confidence interval ?"
314956,a point of clarification : by * redundancy * are you referring to collinearity and feature dependence or do you mean linear combinations ?
314926,"i believe one version of this is answered ( and extensively analyzed ) at url but it depends on what you mean by "" this "" --what generalization do you have in mind ?"
314872,ttnphns : why transform ?
315368,have you done an augmented dickey-fuller test ?
315363,"are you trying to predict some variable $ y_t $ conditional on $ y_ { t-1 } $ , assuming that $ left { y_t right } $ follows a first-order markov process ?"
315493,why don't you post the actual data in single column csv file ?
315855,"you ask "" is there any difference between the income of the people who have a wm in the young age ?"
315929,why are you interested in whether the tests correlate and why are you calculating separately for the two disease states ?
315943,did you try out higher-order garch and see whether model stabilizes ?
316083,why ?
316186,"so you know that for matrices $ a $ and $ b $ , [ $ langle a , b rangle = operatorname { tr } ( a ^ * b ) $ is an inner product ] ( url ) # inner_product ) , and then [ $ cos theta = frac { langle a , b rangle } { a b } $ where $ a = sqrt { langle a , a rangle } $ ] ( url ) ?"
316341,"ckf is not "" a time series model "" so this still seems somewhat unclear ( does any use of ckf count ?"
316525,"when you use the word "" important "" do describe a predictor in the context of your problem , what does that really mean to you ?"
316705,"can you explain why "" no ma component "" would suggest that no other variable is influencing the process ?"
315009,you introduced a new tag [ rtree ] . can you please add a tag wiki ?
316808,why are you taking x = y ?
316834,try to formalize your objective . what is formally a good solution ?
316949,""" pretty okay "" ?"
317305,can you present evidence of this using a sample dataset ?
303425,1 . is this for coursework ?
317690,"don't the studies you "" often see "" analyze based on data available at the time of hospital discharge ?"
317812,are $ y $ on the left hand side and $ y $ on the right hand side the same ?
318283,"what do you mean by "" flipping arrows "" ?"
318527,when you say recurring are you saying that a probability of winning any game is statistical independent of winning any other game with probability 0 . 53 for a winning ?
318987,i'm guessing an issue here is that actual credit events are quite rare in the data ?
319043,""" we know that ( on average ) neighbors answer 50 % of all questions jointly correct . "" i'm not sure what this means . does it mean "" for any question , any two students have a 50 % chance of both answering the question correctly "" ?"
319202,what do we understand by zero conditional assumption ?
319266,what have you tried so far ?
319288,why should your proposal give the same value as the definition ?
319473,"if you reverse those inequalities , which are standardized to be of the $ leq $ or $ $ type , what will happen to the direction / color of the bars ?"
319522,"do you get any feedback after the reseating , so that you can adjust the reseating , get feedback , adjust , etc . ?"
319590,"why would you say [ 0 , 1 ] ?"
319632,since $ log ( 1 / x ) = - log ( x ) $ what does this tell you . . ?
319796,why do you think the integrals from your $ n $ simulations would be normally distributed ?
319934,you do appreciate that post-hoc power is a controversial topic ?
320210,what size blocks are you planning ?
320430,the lorenz curve is not a bivariate plot . one uses it only to depict the distribution of one variable : income ( according to wikipedia ) . if you plotted immunization ( percentage ?
320962,what do you mean 'add' ?
321277,what is the hypothesis and formula used for computing chi -square statistic ?
321385,have you rescaled the variables ?
317668,"do you have data for only 1 year ( i . e . two observations : one for summer , one for winter ) or do you have data for multiple years ?"
321853,does the single component improve the performance of the rf model ?
321960,what do a and x stand for ?
322197,how you turned $ y $ to be $ log zw $ ?
322261,"this is conceptually similar to [ ` overfitting ` ] ( url ) , isn't it ?"
322352,are you looking for constant variance in the original series or in the first differenced series ?
322411,"what does it mean to "" follow "" a subject ?"
322514,"if i reproduce this on my machine , in fact i do see a negative intercept but positive co-efficient for zb . r version 3 . 3 . 2 ( 2016-10-31 ) platform : x86_64-pc-linux-gnu ( 64-bit ) . what co-efficient values do you see ?"
322547,"( 1 ) what's the problem with a "" mathematical expression only "" ?"
195385,"i don't think this is do-able without some hacking : if it gets re-posted on stackoverflow , i can try to answer . basically , you have to follow the steps in ` ?"
322851,hint : what proportion of people win ?
322855,"$ ( x , y ) $ is bivariate normal ?"
323054,optimization method of neural networks is called gradient descent . are you talking about hyper-parameter tuning ?
323189,what is the sum over ?
323522,"assuming $ theta_1 $ is restricted to the interval $ [ 0 , 1 ] $ , it ( obviously ) is a beta distribution , because it's in the form $ $ c theta_1 ^ { a-1 } ( 1- theta_1 ) ^ { b-1 } $ $ for values $ a , b , c $ that do not depend on $ theta_1 . $ however , your formula doesn't make a lot of sense , because no $ n_i $ appear on the left and $ theta_2 , theta_3 $ do not appear on the right . are you sure you transcribed it correctly ?"
323615,interesting question -- i look forward to reading the answers from those more knowledgeable than me on this one . is the information in the first two bullet points from company records ( i . e . accurate ) or from respondent answers ( i . e . subject to error ) ?
323803,"how to compare the dissimilarity measures depends on what you're trying to do with them . you included the 'clustering' tag , so are you trying to find dissimilarity measures that lead to similar clustering of the data points ?"
324168,prediction accuracy for the training set or the test set ?
324170,your question isn't especially clear . is there a particular sense in which the converse doesn't hold ?
324439,yes . the model depends on time . is that not a desired function ?
324442,"- could you provide the definition of "" collapsible "" ?"
324462,can you edit your question to clarify why you are computing mahalanobis distance here ?
324916,""" i . e . would the noise be expected to be constant per image or per recording site , or be random for every datapoint ?"
325062,are the quoted 95 % ci from the anova or from tukey's hsd ?
313428,rather depends on what your scientific question is . what is the comparison ( s ) of main interest ?
325182,what are you actually trying to do ?
325234,we ought first to establish that this question actually has some content . could you provide us an example of any reasonable statistical procedure that requires more information than the likelihood ?
325575,"could you possibly add a reference to the paper you were reading , so that people can see the context ?"
321590,"can you * select * a single model for all series ( e . g . , additive error , additive seasonality , no trend - an ets ( a , n , a ) model ) and then * fit * the parameters separately for each series ?"
325856,i think you need to edit this to clarify . what do you mean by an integer parameter ?
325921,does this answer your question ?
325932,did you try histogram equalization ?
326088,"sorry but if $ phi ( x ) $ is the cdf , its distribution should be uniform ( 0 , 1 ) independently for $ n $ and its variance should be $ 1 / 12 $ . am i missing something ?"
326121,"since you know the forms , you know precisely how they differ . what , then , do you want explained ?"
326123,does this help ?
326273,"the auc does nt have to be 0 . 5 on a test set , as your model could conceivably generalize so poorly as to be worse than random assignment . a 0 . 08 points to a programming error though , since you could reverse all the predictions of your model and have another with auc 0 . 92 , which is really good . maybe you reversed your classes at some point accidentally ?"
326343,"frankly i don't understand what you're proposing , nor can i tell if it's actually different from em . why don't you set up an implementation ?"
326346,it would simplify your answer--perhaps greatly--to observe that you can obtain it by combining the results of two separate questions : ( 1 ) what are the moments of a truncated normal distribution and ( 2 ) what are the moments of a mixture ?
326354,"what do you mean by "" predictive power "" in this context ?"
326586,"what do you mean by "" flattening "" ?"
326615,"hermitian matrices are diagonalizable with real eigenvalues . that simplifies the question somewhat . a special case that is easy to handle occurs when all eigenvalues are equal . otherwise , explicit formulas are hard to come by and slightly more delicate analyses is needed . are you considering that special case or not ?"
326682,"it's not clear to me from your description why dv1 is a dependent variable as opposed to just a covariate in the model for dv2 . the relationship between iv1 , iv2 , and iv3 is also unclear . . . could you fill in the gaps a little ?"
326684,ols regression ?
326691,""" analyze the % respondents who responded agree / strongly agree to the items "" . this is somewhat ambiguous . are you interested in analyzing each item individually , or counting the 13 items together ?"
326828,does this have an application other than getting a good grade on homework or a take-home exam ?
326955,have you seen this paper ?
327009,"please say what you mean by "" working example "" : a simulation ?"
327148,"is there a "" 1 "" missing in your number for cars in 2004 ?"
327339,"the issues of loss function and censoring are separate . it is difficult to see how they are related . you have already alluded to the proper loss function : it needs to balance the expense of monitoring wear against the cost of a break during production . notice that this makes no reference to censoring ! this makes me wonder whether you might be using "" loss function "" in some other sense : what exactly would it be ?"
327446,"you might want to rethink how you describe the hypothesis test . you probably mean "" there is a 0 . 05 or less probability that if the two means were equal we would see the data we did "" , which is not the same ?"
327551,"i'm concerned about the design : you have a well controlled experiment . but your analysis loses focus when you separately present statistical results for two model parameters when your overarching interest seems to be whether "" condition "" interacts with either group or the group-by-time growth / interaction term . why not perform the 2 degree of freedom test for nested models taking as a null model the same as the above but omitting the 2- and 3- way interactions with condition ?"
327571,is there another solution . . . to what problem ?
327641,"consider writing it as ( something ) times what you'd like the ratio to look like . can you say what happens to the "" something "" in the limit ?"
327734,"question : in the result comparisons with and without bias that you mention , are the bias values close to zero ?"
327766,the model is $ y = c epsilon $ where $ epsilon $ is a random error . what is the distribution of the error term ?
327903,are you familiar with [ simpson' paradox ] ( url ) ?
327953,has all of this analysis you've described been performed on the same data set ?
328286,are the products all the same type ?
328293,are you asking about $ r ^ 2 $ or adjusted $ r ^ 2 $ ?
328245,hint : choose a number $ 0 delta 1 $ . what is the limiting probability $ f ( delta ) $ ?
328850,is china in your country list ?
328853,are you testing a 'before-and-after' scenario ?
329043,"what does it mean when you say "" the _average_ number of people in the queue at time $ n $ "" ?"
329059,"you know the coefficients of the model you want , what is the need for refitting ?"
329130,why wouldn't it ?
329652,i don't see why would you consider this approach to be better ?
330140,"this is a very broad question - the distribution of weights will depend on many different things : architecture of the net , data , used regularizers ( weight decay , dropout , weight / batch normalization etc . ) are you interested in some particular architecture ?"
194874,"if you're in doubt about the parameters , why not just put hyper priors on them ?"
330271,"the error correction term having the same sign in all equations is actually incompatible with cointegration . see my answer to [ this question ] ( url ) and [ this one ] ( url ) , and [ this one ] ( url ) . perhaps your question is basically a duplicate of one of those ?"
330927,are you using a random forest implementation that is explicitly aware of nominal / categorical variables ?
331096,"i would understand "" injective "" to mean you can recover the sample from the value of the statistic . but since that makes the answer obvious , i wonder whether you intend "" injective "" to mean something else : what would it be ?"
331175,"knn can be used in different contexts ( commonly regression and classification problems , but also others ) . there are certainly ways to choose k automatically , but it depends what knn is being used for . can you edit your post to be more specific ?"
331336,can you write down the formula for the classifier ?
331388,"are you asking whether these assumptions are strong enough to justify $ ( z_t , z_t ^ 2 ) $ as an instrument for $ ( x_t , x_t ^ 2 ) $ ?"
331429,"the question is unanswerable unless you make additional assumptions about all other ways in which customers can be lost or gained , such as there is no growth in the market and no other competitors . also , by "" 20 % chance "" shall we presume this applies to * all * customers independently and doesn't just mean that there's a 20 % chance a * single * customer switches ( and therefore an 80 % chance that * no * customers switch ) ?"
331578,"your notation is at odds with itself : "" $ sigma i $ "" ordinarily would be understood to mean a matrix with common values of $ sigma $ ( a * number * ) on its diagonal and zeros elsewhere . in this context , $ sigma_ { ij } $ is either $ 0 $ or $ sigma , $ rendering your reference to "" $ sigma_ { ij } $ "" confusing at best . what , then , do you mean by "" variance matrix "" versus "" covariance matrix "" ?"
332021,"so , that is a small point for angular over direct use of logit . there should be something more biological that drives comparisons in time . are we looking at stage in life cycle , seasonality or some other time pattern ?"
332109,"i would guess "" $ sigma_x $ "" is shorthand for $ sqrt { operatorname { var } ( x ) } $ and likewise for $ sigma_y , $ but what do you mean by "" $ s_y $ "" ?"
332382,can each subject only ever be in one state at any given time ?
332399,mme means what ?
332443,"you're right : you can't calculate this from that information , because you need to know the full multivariate distribution of the explanatory variables . as an analogy , suppose you estimated that the height of a person ( in meters ) is 1 / 40 of their weight ( in kilograms ) . what is the average height of people ?"
332570,why not use our site ?
332688,""" the general consensus is that dates can either be considered binomial or count data "" - uh , what ?"
332934,"the probability $ p ( x_ { 8 : 10 } m_x ) $ is the probability that exactly 3 of the variables realize above the median . what is the probability that $ x_1 , x_2 , x_3 $ realize above the median and all other variables realize below the median ?"
332972,"* * "" opposite from its correlation to the response variable ?"
333029,your question is unclear . what is $ mu $ ?
333284,can you please clarify how big is your sample ?
333482,hi there ! please add the details : what is an elman and jordan network ?
335181,are you using additive seasonality or multiplicative seasonality ?
335350,could you explain the notation in the paste-ons ?
335542,what is the sensitivity / specificity of the pregnancy test ?
335733,you introduced a new tag [ mmse ] . can you please add a tag wiki ?
335867,"why don't you compute power in the usual way , by taking repeated samples with replacement from your target population ( presuming your population is not finite ) and computing the value of the test statistic of interest for each such sample ?"
335891,what makes you think it is a false negative ?
335931,"it generalizes the idea of a [ derangement ] ( url ) , which is a permutation with no matches . deriving the formulas is the subject matter of combinatorics . for a good modern introduction , see chapter 1 of richard stanley's book [ enumerative combinatorics ] ( url ) . there are good approximations in your particular case : have you noticed the pattern in which the initial value is divided by $ 1 $ , then that is divided by $ 2 $ , then that one by $ 3 $ , and so on ?"
336190,"the proposed duplicate addresses calculating accuracy in a multi-class classification . you will find more threads by looking which [ questions are tagged * both * "" accuracy "" and "" multi-class "" ] ( url ) . i am not sure about the "" expected "" part in your question . are you just asking about training a classifier on training data and evaluating it on a holdout test dataset ?"
336459,you could try bootstrapping ?
336698,"i just want to verify something , are you running mann-whitney u pairwise of all groups versus all groups , as in a round robin ?"
337070,"what does "" beta "" represent here ?"
337176,could you share more detail on the calculation you are using ?
336859,can you elaborate on what you've tried and where you got stuck ?
337315,isn't this simply truncated distribution ?
337316,in the formula for $ y $ did you intend to stipulate that $ i lt j $ ?
337318,""" but in cases of balanced classes , why is precision and recall good metrics ?"
337434,"what do you mean by "" error "" ?"
337462,what methods have you considered ?
337615,do you know how they should change over time ?
337725,is the outcome also logged ?
338027,xi'an why does this require the self-study tag ?
338029,the question does not make much sense to me : what is the meaning of independence of two parameters in this mh context ?
338140,"the variance of the raw price data is 242 , 000 , 000 , 000 , so mse of 350 , 000 would be impressive . surely you mean the root mean squared error ?"
338154,do you know if $ delta $ by itself is a kernel or not ?
338379,"does your data simply consist of ( or be transformed into ) two columns with weights , one the before weight and the other the after treatment weight ?"
338705,how would it work ?
338825,"do you have the data , or just the model ?"
338838,"what do you mean by "" first 10 "" and "" second 10 "" , etc , exactly ?"
339391,is your design what in clinical trials is called a crossover study ?
339509,why do you think you need stepwise model selection at all ?
339694,"let me try again : * data * are never iid , but your * model * of the data can be . this doesn't raise an objection to your motivation , but it suggests restating the question along the lines of "" what justifies the use of iid models for statistical analysis "" ?"
339698,"are you getting new categories in an existing variables , or are the labels of the categories changing between train time and test time ?"
339811,"i think that this is where your goals and domain knowledge need to influence your choice . what are you trying to achieve with these clusters , and how would you decide if they are acceptable or not ?"
340140,can you clarify : what's x ?
340212,why do any test ?
340387,what type of parametric terms are you thinking of ; categorical or linear ?
340465,try writing it out more explicitly . . . $ p ( x y = y x = x ) $ . do you see the simplification now ?
340542,could you explain what you are trying to accomplish ?
340797,what exactly are you trying to achieve in here ?
340837,welcome to cross validated ! can you provide more information on how your data was collected and what your research hypothesis is ?
341263,what do you mean by the variance of a function ?
341307,"are you looking for a dataset that can be reasonably assumed to have this property , or a theoretical example in terms of random variables ?"
341758,what is the range of summation ?
341876,why would you transform the dependent variable if you are already using poisson regression ?
341910,are you sure the missing values in the removed portion were coded correctly as missing ?
342074,"i believe the null hypothesis should be of the "" greater-than-or-equal-to "" variety for a one-sided test . where did you see it defined as the simple equality ?"
342104,"seems reasonable to divide the total number of species by the total number of randomized squares , no ?"
342182,the answer depends on the details of the test you use . which one ( s ) do you have in mind ?
342468,are you estimating the model with or without a constant term ?
342560,"are you interested specifically in xgboost , or would regular old gradient boosting be sufficient ?"
342686,in what context are you planning to use the histogram ?
342944,a ct scan yields a set of images . what sets of numbers would you correlate ?
343066,did you bootstrap the sample ?
343206,do you have any additional information as to what the data represents ?
343338,could you edit to include the expression you're talking about ?
343451,could you explain what the intended purpose of binning these wages might be ?
343662,what exactly do you need to compute ?
343686,"it's quite likely a standard anova is the best procedure , but that depends on which "" distribution "" the title refers to--is it the distribution of the responses of of their residuals ?"
343921,could you describe a bit more your dataset ?
344267,your dependent variables ( 'died' and 'alive' ) are not categorical . and are you sure you want to do a test on the * number * who died or lived ?
344181,"if it is sinusoidal , then how can the data have multiple-frequency components ?"
347390,"do you have any definition of "" degree of information "" in a probability distribution ?"
347705,you do not need to one-hot encode f2 . do you need to one-hot encode f4 because it is not ordinal ?
97637,small sample size ?
100609,i'm interested in what your goal is here . are you trying to match recipients to donors ?
102696,"are you familiar with some of the many measures of association , such as phi coefficient and spearman rank-order correlation coefficient ?"
103385,what's the error ?
104374,i'm not sure i understand exactly . is the problem simply that the two variables have many levels ?
104551,"i think doing this might introduce some undesirable dependence between your independent variables since , as you said , ` then "" nyc "" will always be 1 when "" bronx "" is 1 ` . what about trying something like splitting your ` nyc ` variable into two distinct factors - ` nyc-not bronx ` and ` nyc-bronx ` ?"
101222,is your example taken from a particular graph ?
104883,"do your data represent a complete census of the population ( in which case the fitting procedure is intended as a means to * summarize * that population , not to make inferences about other populations ) or are they based on a sample of the population ?"
105034,what is $ 1 / x $ when $ x = 0 $ ?
105286,what is your question ?
105403,"the mean square error in the * predict probability for binary outcome * case is the [ brier score ] ( url ) , which is a [ proper scoring rule ] ( url ) . optimizing proper scoring rules corresponds to finding predicted probabilities that are well calibrated to the actual probabilities in the data . is this the kind of "" accuracy "" you are looking for ?"
106359,"please explain why underflow is any problem at all . to a very high precision , it is indeed the case that $ exp ( -800 ) exp ( -3000 ) = exp ( -800 ) $ , as your analysis shows . do you really need $ 955 $ decimal digits of precision in your numbers ?"
107883,1 ) what do you mean by 'warped' there ?
109582,are you perhaps typing or reading the formula incorrectly ?
109592,"not easily . . . the skewness coefficient is a pretty flaky statistic . i suggest avoiding it . are you sure you wouldn't do just as well comparing their ranges , or number of different pages visited ?"
109333,it might be easiest to start with the moments of $ log ( z_n ) $ in terms of moments of $ x $ . how does this problem arise ?
109709,"glad it was helpful . before i do anything like that , i want to check . i'm fairly new to stack exchange , and wonder if it is a welcome practice to resubmit a comment as an answer . can somebody advise ?"
109736,"for each "" read "" ( you'll have to excuse me , but i don't know precisely what a "" read "" is ) , something is either in a particular category or not in that category ?"
110008,do the parameters you have in the model include any interactions or is it strictly an additive model ?
110626,what were the response * rates * ?
111132,"it doesn't make a lot of sense to me . why not just train your classifier on the known data ( perhaps using cross validation to get a better sense of it's out of sample accuracy ) , & then use the trained model to predict the class membership of the unlabeled data ?"
110311,there are hazards involved in imputing data . can you just use the data you have or collect more data ?
111518,is this in the context of a vector autoregression ?
113405,"since you aggregate over time $ x $ cannot be the _same_ random variable -only $ n $ _identically distributed_ random variables . in which case , the question arises : are they independent or not ?"
113456,can't you transform between the spaces ?
113646,could you expand on how the answer to [ examples of when confidence interval and credible interval coincide ] ( url ) doesn't answer this exact question ?
113643,how exactly are the categories labeled ?
113810,where does he make the suggestion ?
114220,"ari , what do you mean by "" remove the time-series variance from the panel data "" ?"
114485,"what does it mean for the odds to be "" 2 . 20 for a turkey win , 3 . 40 for a draw and 3 . 20 for a ukraine win "" ?"
114769,please describe your data further . what do you mean by three samples - three groups or three replicates . what are the 2 variables the interaction of which you want to evaluate ?
117784,"question ( 2 ) is answered at url ( on the mahalanobis distance ) . as to the first question , is there a particular context in which you have seen $ s ^ { -1 } x $ used that would demand an interpretation ?"
118020,"it's not clear what null and alternative you're dealing with when you say "" to know that the results that placed whoever / whatever is positioned in the 1st place ( according to # of votes ) are statistically significant ?"
118089,are you just trying to draw a density ?
118045,correlation between the return and the index ?
118606,"have you reviewed the definitions of "" irreducible "" and "" communicates "" ?"
119822,"do you have the time indices from which the "" segments "" were recorded ?"
120004,what is mi ?
121041,"usually what matters more than the possible presence of spatial dependence is its potential effect on your analysis . in many cases the effects are inconsequential ( suggesting , if that's your situation , that the best answer is "" who cares ?"
121917,what does ` a jump occurred in t' ` mean ?
121983,what is the purpose of the intended description ?
122338,"when you say "" the errors are all equal "" do you mean that they have the same value ( which $ delta x_i = delta x $ would imply but which seems a bizarre thing to have ) , or do you mean that they're of the same average magnitude in some sense ?"
122532,have you looked at the manual page for this function ?
122236,"what method would you use in the case of residuals , and why would that not apply for a predictor ?"
123188,"if you have evenly spaced data points ( which you do , if we ignore weekends ) , it's best to use that time period . so , yes , in your case , a day would be the correct time period . you might be confusing fourier analysis with natural time period ?"
123462,i think [ online least squares regression ] ( url ) could be adapted . would this be the sort of solution you are looking for ?
124407,"what is a "" 36-gene signature "" ?"
124987,"here are some things you might want to clarify . if you have 3 products , why are you expecting the shares to be equal ( 1 / 3 ) ?"
125059,why re-invent the wheel when there is a large body of research ?
125515,this is where substantive knowledge of the data becomes important : what _is_ the spike ?
126305,it is not apparent that this question is intended as a duplicate because the question itself is unclear . on what basis should the features be ranked ?
126688,is this a homework ?
127609,in addition to glen's request that you clarify whether you are seeking the product of 2 random variables ( or trivially two pds ?
127539,where did you see that the park test has 3 forms ?
130059,"in my opinion , under no circumstances should you use a malcom gladwell book for anything in undergrad as a cautionary tale of how not to think . ( and maybe setting a bonfire . ) none of the books that you listed strike me as stats books at all . to get more precise answer , i think you should be more specific with your question . what level undergrad are you referring to ?"
108532,"so the variance of , say , $ z_1 $ , which is $ omega_ { 11 } $ is $ e ^ { x } $ ?"
130940,can you make this more concrete ?
132615,"there actually are environmental regulations and guidance prescribing laboratory data quality objectives in these terms , so i would expect comparable regulations to apply to medical laboratories . what kinds of qa / qc procedures does your lab follow and what is its guidance about this ?"
132954,"given different people might use the same phrase to mean somewhat different things , some context and definitions might help . presumably $ alpha $ is a parameter vector , but does it include all the parameters ?"
130220,is the data actually integrated or have a moving average component ?
133535,"as described in detail elsewhere on this site , fisher's "" exact "" test is not very accurate due to conservatism . so why is it worth the trouble to you ?"
134268,must you use the pearson correlation coefficient or are you open to other types of correlation coefficients ?
134377,"could you please be more specific about what you mean by "" the linear taylor series expansion of a normal random vector "" ?"
134611,what are $ a_i $ and $ b_i $ ?
134481,as opposed to what technique ?
134869,"regarding the "" conversely , . . . "" statement : this makes sense if you are predicting the past . but what about predicting the future ?"
133584,could you please give us some more information about the real problem you want to solve ?
134893,it is not clear what you are asking for - but you can imagine a chimp who is going to be replaced by your code ; how many classes do you have in your case ?
135035,"what do you mean when you say "" random connection "" ?"
135539,"please give a little more details : what are your objectives - compare them , simply describe them ?"
48048,you probably have read the wikipedia article : url could you explain more clearly what you are not understanding ?
136014,possible duplicate of [ what is a hazard rate ?
136369,"is this for study purposes , or do you need it for some task ?"
136713,isn't a single model that accounts for the differences between stores possible ?
137203,what is the null-hypothesis you want to check ?
137300,"i am puzzled about the remarks on "" normality violation . "" it's impossible for data on a nine-point discrete scale to look even remotely normal except with very small data sizes . with 317 or even 177 data * of course * the responses will be demonstrably non-normal . but so what ?"
137962,where to begin ?
138107,you have made the comparison and found your data do not look like they have a weibull distribution . what that means to you depends on why you were doing this . what was your purpose ?
138444,is this a problem from a course or textbook ?
138564,"unless you take a very narrow view of "" functional invariance , "" you have already answered this question . what , then , do you mean by this phrase ?"
138586,did you really mean to take the derivative of the quadratic form with respect to the matrix ?
138642,why in the world would you want to ?
138763,"this is hopelessly and irretrievably incorrect from the second equation onwards . have you given any thought to the fact that the quantity in square brackets on line 2 is _not_ a function of $ y $ at all , and so the derivative with respect to $ y $ must be $ 0 $ and not the gobbledygook that you have conjured up out of thin air ?"
139182,how many observations total ?
139545,what hypothesis are you trying to test ?
140148,"are you interested in nn unsupervised learning in general , or specifically in unsupervised clustering with neural networks ?"
140518,1 ) can you explain your alternative method better ?
116297,what is the type of time series problem are you trying to solve ?
140998,did each participant see exactly the same list of words or were there randomly choose ?
141590,"the standard $ chi ^ 2 $ distribution has mean equal to the number of degrees of freedom ( and variance double that ) . when you look at your data , do you still believe the distribution should be $ chi ^ 2 $ ?"
139453,an upper bound for the size of each final group is the size of the smallest initial group . have you any other preferences or requirements for the final group size ?
141874,is this a question for some subject ?
142015,"your distribution is absolutely continuous with respect to the lebesgue measure on the square $ ( 0 , 2 ) x ( 0 , 1 ) $ . what is the lebesgue measure of the line $ { ( x , y ) ; x-3y = 0 } $ ?"
142173,is there any reason why you have ruled out the poisson distribution ?
142482,""" limiting your sample "" sounds like * truncation . * censoring means that values in the sample are * replaced * by censoring limits . the effect on the nominal correlation coefficient ( as incorrectly calculated by replacing each censored value by its censoring limit ) is profoundly different from removing such values altogether ( truncation ) . which one do you really mean ?"
144877,"no matter what transformation you used , every datum in the same category would end up w / the same value in the transformed space . why do you need means & sds ?"
144922,you always have to do * something * with missing values . i must say i don't really understand your question - you are looking for some one-size-fit-all approach . . ?
145039,"is there a statistical component to your question , as defined by the cv help center ?"
145422,"there's a slight ambiguity . are you saying that when a dosage of 1000mg is recorded , it really was 1000mg ( so even though it was feasible that it could have been say 1005 and then recorded as 1005 , that simply doesn't happen because only doses that are multiples of 250 are ever given ) , or are you saying that when recorded as 1000 , the dose was actually somewhere between 875 mg and 1125mg because they're only * recorded * to the nearest 250 ?"
145500,what is the final aim of the study ?
145592,you mention 2 rating systems in text but in table there are 3 ratings ( columns ) shown . what exactly is being done here ?
146661,it is not clear for me what do you mean by the first question and how does it relates to the second one ?
147447,i don't think you're going to be able to avoid at least dealing with $ np $ and even then you're stuck with an approximation . is $ n $ very large ?
147600,"i'm not sure what you mean by multivariate / bivariate - the mcmc in the blog post by me to which you link samples from three parameters , so it's "" trivariate "" ?"
147843,"isn't that the point of using heteroscedasricity-robust standard errors that ( a ) there isn't _one_ residual standard error but residuals have potentially different standard errors , and ( b ) you don't need to specify in which way they are heteroscedastic ?"
148663,what is $ x_i $ and what is $ p ( x_i ) ?
148971,what sort of model are you using ?
151419,"yes , you can . it looks like the last article created a spike . is this the case ?"
152215,so to be clear the hypothesis is $ mathcal { h } _0 : d t $ vs $ mathcal { h } _1 : d geq t $ ?
152214,"i think you should go over your terms a bit , $ ( theta_1 , theta_2 , theta_3 ) $ is not a distribution , in this case it is a random variable , it has a distribution . when you say marginal , what does that mean , what are the other variables you are integrating out ?"
152218,"maybe far to trivial , but how about inversions ?"
152740,can you have all of your participants play all of the games ?
154241,"i'm not sure i understand the question . are you asking if x a b implies x ( a , c ) ( b , c ) ?"
154788,can you say more about what you are looking for that you are not finding in introduction to statistical learning ?
155070,what do you mean that the probabilities do not sum to one ?
155224,"clearly you need to allow for the possibility of intercepts that do not depend on the coefficients of the exponential , rather than forcing all of them through zero as you currently do . if these curves indeed have exponential forms , that will fix the problem . why don't you try that and show us the results ?"
155573,"what do you mean by "" show "" a model ?"
155771,"it sounds like you're trying to compare 2 different types of things , a continuous versus a yes / no predictor . what do you hope to gain by this comparison ?"
155503,why not use the combined data from both a an b ?
129641,did you handle interaction variables properly ?
157331,do you actually have a categorical variable with more than 53 categories / levels ?
157903,"i know an algorithm for this , but it is somewhat involved . have you already created a correlation matrix to test for perfect correlation between pairs of variables ?"
158066,"if the thread at url does not answer this question , then please edit it to explain what your definition of "" time series "" actually is . at the end , where you write "" multivariate case , "" do you mean that * each * of the $ y_i $ is a vector ?"
158401,why do you want to merge these dataset ?
159592,are you asking for the expected time between two * successive * failures or for two failures to occur ?
160272,"a "" mean "" doesn't of itself have a property of "" signficance "" . a test statistic in respect of some specific hypothesis may do . what hypotheses are being considered ?"
161526,"when you say "" to compare between 3 ( or more ) distributions "" -- what exactly do you mean ?"
161702,you don't give the interval the prior is defined on . is it $ r ^ times r ^ times r times r times r ^ $ ?
162139,"the minimax solution does not have to lie along the line of equal risk unless the line of admissible procedures is concave . you might want to sketch some of the contours of maximal risk on this plot : that is , draw contours of the function $ f ( r_1 , r_2 ) = max ( r_1 , r_2 ) $ . where in $ s $ is the lowest contour going to be ?"
162628,"interactions in nonlinear model can get tricky to interpret . you should take a look at [ ed norton's papers ] ( url ) . the logic carries over to the multinomial setting . also , what software are you using ?"
163008,"just to be sure , , , , which series is the response series ( y ) , the one you are trying to predict based upon the other ( x ) . what country is this from ?"
163280,"it's not entirely clear to me that this question is off topic . however , almost all conventions i am aware of that have any kind of general following are determined by the software : specifically , its lexical and syntactic processing of the input as well as the physical and logical formats of its native files . certain characters are often ruled out--spaces are common--because their use in programs or commands can be ambiguous . if you are asking a question that might be of use in statistical analysis , could you edit this post to make that connection more explicit ?"
163385,is there a reason not to use each player's average as your prediction for the next season ?
163435,are you aware of [ mixed-effects random forest ] ( url ) ?
163481,"by a gaussian rbf you mean $ k ( x ) = exp left ( - gamma lvert x - c rvert ^ 2 right ) $ , right ?"
163606,"are there any relationships among the parameters of those distributions , such as having a common mean or common variance ?"
163995,"it would help if you could say more about what the a and b values represent . presumably they are numeric , but are they integers or on a continuous scale , what are their ranges , are they necessarily non-negative , are their distributions skewed ?"
164106,i think we should get more information about your case . what is your observation ?
164665,do you have 5 time points ?
165027,to what purpose are the authors using the square of age ?
166474,"the estimator will be a vector ( since the mean of a multivariate normal distribution is a vector ) , so the variance of the estimator will be a matrix . when you say standard error of this estimator , do you mean the vector composed of square roots of the diagonal of this matrix ?"
165262,can you demonstrate that this limit exists though ?
166848,would you be using the poisson assumption anyways for constructing a confidence interval ?
167163,"i'm curious how you calculated a cdf and z-values , because if your data are in anything more than one dimension , then velocities are vectors , by definition . are you sure you don't have * speeds * ?"
167671,how is beta related to alpha_i ?
168599,you seem to have only one x-variable . do the two differ ?
169213,"what do you actually intend by the phrase "" nonparametric "" there ?"
169395,"sure , there's just one value for $ theta $ . but , * since you don't know what that value is , * you need to compare statistical procedures based on how they perform * for any possible value of $ theta $ . * think in terms of game theory : it's a two-person game between you and nature . nature chooses $ theta $ and you will guess $ theta $ to be $ hat theta $ . your payoff depends on the discrepancy between $ theta $ and $ hat theta $ . what is your best strategy ?"
167599,you need to supply some more information about your data . is it a case-control design with controls matched to the patients or are they simply different groups ?
171829,do you have an extremely low-off the chart outlier around frequency 1 . 7 ?
172440,could you explain what statistical problem this question might be connected with ?
173929,it's * impossible * to tell with the information provided . why do you want to do that ?
173983,"this is all confusing . let's focus on the final statement : you appear to equate "" best "" with "" close "" ( both of which are qualitative vague terms ) and are asking how to quantify them . how should we know ?"
174040,do you by any chance have the idea that there is actually only one model but you estimate it using 10 different subsamples of the data ?
174796,so does this refer to the current track a user is listening to ?
174825,"we're not assuming multivariate normality , i take it ?"
175726,"why do you think it might not be "" fair "" to test for an interaction or the other main effects beyond $ x_1 $ ?"
176047,"is it price of petrol , production volume of petrol or what ?"
177252,what is the purpose of the comparison ?
177967,"you will get no good answers to this question without providing more detail . what you do you mean by "" invalid ?"
178183,"a 66-steps-ahead forecast should not yield the same forecast as a 1-step-ahead forecast using a model that has 65 more historical data points . i suspect an error . or are you updating your model using your * forecasts * , instead of a "" rolling origin "" approach where you successively add more * observations * ?"
180394,"suppose the population has 100 people , 50 males and 50 females . how many males are rich ?"
181453,i am not quite clear on the question : are you meta-analyzing reported results of individual studies that used locf ?
164839,"what do you mean by "" separating the digits "" ?"
186856,"well , more generally we assume a data-generating process * as if * the observations were sampled from an infinitely large population . with your die example , you might just say that symmetry & background knowledge make a certain distribution a plausible model for the data-generating process without reference to a population . but i don't understand your question : if you know what a sample average is , & what an expected value is , what more do you need to distinguish them ?"
187118,are you comfortable with logistic regression ?
187466,this reads rather like a [ routine textbook-style question ] ( url ) ( as might be asked in coursework for example ) . but in any case : are you aware of the definitions of type i and type ii error ?
187792,i don't see any reason why it should not be true for a kernel svm with polynomial kernel . can you please say what makes think it might not be the case there ?
188101,are you sure about the title ?
188685,what did you do cv on ?
188795,treat it in what sense ?
189837,do you have data on both the specific bank and the other banks ?
190371,"you refer to these as "" series "" , are they time series data or cross-sectional ?"
190834,what does it mean to select a best model but then improve upon it ?
191421,"well , not familiar with glasso . perhaps some other implementations are fasyer but your matrix is pretty big to calculate an inverse . what is your performance goal ?"
191676,i don't think this is answerable at present . are you thinking of something like a [ poisson process ] ( url ) ?
192054,how do you measure tiredness ?
8242,you are looking for [ sparklines ] ( url ) . searching in r for ` ?
192780,are you comparing the 12 groups all toghether right ?
193093,"the mathematical answer to such a question is "" of course "" and it would go on to point out there is an infinite variety of possibilities . but that begs the statistical context : what is this "" similarity "" supposed to measure ?"
193711,is this a question from a course or textbook ?
21326,can you provide some more information about exactly what your data is and how you plan to use hmms to classify ?
197779,why are you asking about the variance ?
198633,is it reasonable to assume the data are normal ?
198819,"if the random variables are i . i . d , why do you need to distinguish between the marginal densities of the random variables ?"
199107,i don't quite understand your question . are you asking why it is possible to use gradient descent to fit a logistic regression model ?
201607,"what is "" sub-distribution "" ?"
203610,""" two random variables are identically distributed if their cdf is the same "" seems reasonably intuitively clear -- as long as the students know what the ( cumulative ) distribution function is . what were you seeking other than something like that ?"
202930,"when various textbooks want to illustrate time series with outliers , there are some well-known datasets that get called upon . one dataset i came across that is used for teaching the analysis of time series with outliers involved , if i recall correctly , recordings from a weather balloon . the balloon was rotating , and every so often , fairly periodically , something ( possibly one of the balloon's ropes ?"
204576,what happens at each iteration ?
204438,"by "" simple way , "" are you asking for an implementation of lda that does this , or for a description of the math so that you may implement this yourself ?"
205009,"is this a single variable regression , or multivariate regression ?"
205007,knn or kmeans ?
205471,why are you thinking to do pca first ?
205676,does yours * * ring domain * * mean really interesting new gene finger domain or it refer to some kind of loop ?
205888,"it shouldn't be a problem unless you're creating training and test datasets . random partitioning on such rare events likely would create problems in that all 3 observations could end up in one group . depending on the underlying algorithm , convergence issues could arise , e . g . , quasi- or complete separation . do you have any information on dealing with rare event models and data mining ?"
206203,have read the working paper that accompanies it ( url ) and the vignette url ?
206107,i assume that you are asking about * log * marginal likelihood ?
206358,"as usually defined in texts of mathematical statistics , bias ( $ = text { e } ( hat { beta } - beta ) $ ) is a property of the estimator , not of the particular estimate . but , bias also has its meaning from colloquial use , and that is maybe what the students mean in the second instance . i think what the students are saying in their argument is understandable , and interesting , showing that they actually thought by themselves , and are not only paroting some text ! so , you should take that as an opportunity , not simply mmarking as an "" error "" , and ask "" is this interesting argument actualy true ?"
206134,"is the 8-bit value recording a truncated , or a rounded version of its input ( or indeed , something else ) ?"
206846,"by "" post-hoc test results "" do you mean pairwise comparisons corrected for multiplicity ?"
206105,did you try [ 1 ] in place of 'y' and see if that works ?
207161,"if you are observing $ v_t , v_ { t-1 } , ldots $ to update the system state $ x_t $ , why not observe $ ( v_t , v_ { t-1 } ) $ jointly and update the state only when $ v_t = v_ { t-1 } $ ?"
207156,"first you say * 50 time series * , then * both time series * . so do you have 50 data sets and consider modelling one of them in this question ( and hence * both * refers to the two time series in this particular data set ) ?"
206862,what does your fitting equation look like ?
207836,may we presume $ x $ and $ y $ are independent ?
208192,"it will be useful to explain what a "" regular "" meta-analysis is . do you want to summarize the findings in a structural equation model with one single effect size ?"
208654,"this is a bit hard to follow . we can't know why the model doesn't predict better w / o more information about the data , the model , etc . it always could be that there isn't really a relationship . are you just asking about the code ( how it works / how to use it ) ?"
208797,what about a knn classifier ?
209837,"do the letters a , b , and c have an ordered relationship or are they nominal categories ?"
210316,wouldn't random effect for firm and random effect for year nested in firm be more realistic ?
210702,"this is awfully sparse , & i'm not sure it's answerable . can you provide more context here ?"
211995,?
212174,are you sure your categorical variables are coded as factors ?
212453,without knowing more about the underlying science it is difficult to be sure but as a general principle why would you always expect to repeat the results of the past ?
214287,"i think some more details would help - for instance , are you assuming normal ( or some other distribution ) errors ?"
214871,"let $ f $ be bernoulli $ ( 1 / 2 ) $ and $ n = 1 $ . if my quick calculation is correct , i believe your statement then asserts $ 1 / 4 gt 1 / 3 $ . are you making some implicit assumptions about the size of $ n $ or the nature of $ f $ ?"
215474,"would the second line be obvious if you were to erase all instances of "" $ y $ "" from the notation ?"
72391,did you solve that problem ?
215946,you can't use estimated densities in a ks test ( at least not using the usual distribution / tables ) . but why do you need to compare the kde rather than the samples from which you computed it ?
215683,"your predicted species data doesn't sum to unity since 93 64 43 100 . perhaps you could clarify what "" confidence "" you're looking for ?"
216313,could you work it out if the function had been $ frac { 1 } { n } ( y / x ) $ ?
218296,are you asking for logistic regression ?
218381,how can it have success probability n ?
219075,"if i ` set . seed ( 1 ) ` before running your first two code lines , i see parameter estimates of 0 . 76 and -0 . 22 , which seems to be close enough to 0 . 8 and -0 . 2 , given sampling variability . ` auto . arima ( tsts ) ` fits a simple trend model with no arma dynamics , which appears reasonable once you compare the strength of the trend signal to the arma signal ( e . g . , by plotting ) . i think i'm not fully understanding your question . could you please elaborate ?"
219818,are you just asking about the scikit_learn code ?
219839,you don't say what you want to do with these transformations . . . use them in a regression ?
220138,the answer depends on what you are willing to assume about the underlying distribution from which that sample was drawn . what can you tell us about that ?
220958,"instead of non-parametric test , is it possible for you to transform the data to normal distribution ?"
221476,do i derive correctly that this feature is thought to be continuous ?
221968,what kinds of trends are possible ?
221725,is this a question from a course or textbook ?
222749,"for continuous random variables , does $ z $ equal the _median_ value of the three ?"
224217,"it seems like you have a lot of terminology confused , such as using "" power "" to mean "" predictive accuracy "" ( i think ) and "" regressor "" to mean "" dependent variable "" ( or do you mean "" model "" ?"
224738,could you clarify ?
225033,how do you get those results for normal variables ?
225550,what kind of ensemble is it ?
225819,how many pictures can possibly be taken ?
225769,do you have a complete list of what ties two rows together ?
225859,do you also have the standard deviation in the subgroups ?
225966,why would you seek to negate the squared terms when the variable is negative ?
226583,in what way are they random subsets ?
226803,"are you trying to get 1 imputed dataset , or multiple imputed datasets ( mice ) ?"
60580,can you describe the structure of the dataset in more detail ?
229176,"just to clarify , do you have multiple income curves like the one you show or does this curve is your final object you try to model ?"
103029,this perplexity : url ?
229287,are the numbers drawn from a uniform distribution ?
229593,"because i'm sure you read the documentation before posting this question , what part of the lars documentation is unclear to you ?"
229440,"while the thread asks the question in terms of comparing the "" success "" of two files , do you have existing data for many other files ?"
230141,why do you need your dependent variable to have a normal distribution ?
230193,how may neurons are at each hidden layer ?
231087,"you description of your data and what you did to the values is unclear . if you only have 35 observations , would you be able to show us what you have , describe what numbers you started with and attempt to explain the calculations you did ?"
231541,"you must have a very particular model in mind , or some very special definition of "" chi-squared . "" could you state what these are in your question ?"
229209,could you explain more clearly what you are doing ?
232826,"have you asked the maintainer of the caret package , or read any relevant references cited in the documentation ?"
233066,presumably a significant contributing factor in most of the $ p $ s being . 05 is because they've been adjusted to take into account the multiple comparisons ?
232967,"whuber far sides of the tails don't exist in real life , they clip . eventually you won't be able to measure anything . can you actually give me pointers to references that show there is signal at the tails ?"
233427,can you provide a little more information about the variable that has missing data ?
233543,how do you get your posterior samples of a and b ?
234138,is the question about ''dependency'' or about ''correlation'' ?
234139,"is this coming from macroeconomics with $ y $ being the gdp , $ p $ the price level and $ w $ . . . ?"
233741,mood perception is recorded in what scale ?
234810,"what do you mean by "" negative link "" ?"
235055,"the phrase "" trust the p-value "" seems strange to me ( what are we trusting that it should do ?"
235157,your title is extremely vague . can you change it to something more specific ?
235864,seems obvious no ?
233259,"if i observe the word "" the "" , are you saying that this ought to have no effect on the probability distribution of the next word to appear ?"
236032,"out of curiosity , how is "" withdrawal "" defined ?"
236162,depends by what you mean as distribution . do you mean the proportion of each of the five categories appears differently than the proportion of the appearance of each category in 'real' data ?
236245,can you show use your code for splitting your training and testing set ?
236603,"it isn't clear what role a "" histogram bin "" is intended to play in this analysis . could you elaborate on that ?"
236345,"` ws ` looks decidedly discrete , rather than continuous . this suggests it might be derived from some other variables , such as counts . could you explain what ` ws ` is and how it was measured ?"
236563,"have you considered propensity score , genetic , or mahalanobis matching , which all appear much simpler ?"
236807,"except for the bit where they wait until "" the effect is gone "" , this seems pretty standard for an ophtamology study , i'd guess there must be other studies with this design that are published . i would assume they would have analyzed this with a mixed effects repeated measures model that account for the correlation between eyes in a subject and the correlation of assessments of the same eye over time . the bit where the duration of observation depends on the effect seems tricky - how is "" effect gone "" judged and how can we avoid a bias ( e . g . due to stopping the time series at the lowest value ) ?"
237314,what are the effective samples you get if acceptance rate it increased ?
237597,exactly what are you approximating the distribution with and how do you want to measure the approximation error ?
237763,how many features and samples you have ?
237061,"your use of terms is unclear ; please clarify and then i can likely answer . in the first sentence you state that you have one questionnaire , but in the third sentence you state that raters complete three questionnaires . also , you state that each question has 5 rating scales that are categorical but not likert . are you saying that each question has raters choose one of five nominal categories once , or that they do this five times for different sets of nominal categories ?"
237754,it is common to add an 'insignificant' amount to the denominator . for a company insignificant debt might be ?
238777,what's your alternative definition ?
239900,"your question may be starting at the wrong level : if you are "" not seeing good results "" , how do you know if the problem is the feature-similarity measure vs . the features ?"
239731,in your case are you interested in model selection or estimation only ?
240535,"i'm not sure this is really answerable in its current state , as it's rather speculative - only someone with links to ibm could give anything approaching even a definitive answer and even that would be hypothetical . i wonder whether you could refocus the question on those points are more objective ?"
241258,"this seems like classic , time-series seasonality kind of issues ?"
241792,"in what sense do either of these expressions $ p $ deserve to be called "" distributions "" ( for either $ x $ or $ mu $ ) ?"
242049,what's a loss ?
242017,1 . this sounds rather like routine bookwork . is this related to work for some subject ?
242665,"difficult to say . you could try a different linkage method , to see if you get better results . are you using the euclidean distance or some correlation for the distance matrix ?"
243101,what _is_ the next stage of analysis anyway ?
243206,"there would be a variety of possibilities , but it depends on how the items are arranged on the list - are they in randomized order ?"
243791,have you tried performing multiple kmeans runs ?
244642,the help for ` ?
245309,what is the proportion of 1s and 0s in your target class ?
245884,continous data with bounds ?
246549,could your items not be thought of as being sampled from a population of possible items ?
246599,"could you explain what you conceive the "" total error "" to be ?"
246679,and do you also want to be able to detect e and f seperately ?
246644,it would be a rather unusual thing to do ( with some consequences for the usual inference ) . can you say more about what's going on and how you came up with this ?
247362,what do you mean some reads had standard deviation values ?
247457,"do you use any character embeddings ( i . e . , using mapping each character to a vector instead of mapping to an integer ) ?"
249651,"this is a "" possible "" dublicate . if you scroll down on that question , you can see some examples in answers . besides , what do you mean by particular situation ?"
251158,there is a trick for turning the bias into a feature and then you don't have to treat it differently than any of the weights . is that the type of thing you're looking for ?
251320,"what is ` p ( x , y ) ` in your question ?"
251778,are your conditional distributions in the exponential family ?
253247,"hint : if a b 0 , and a 0 , what does that tell you about b's relationship to a ?"
253537,shouldn't $ gamma ( 1 ) = e [ y_ty_ { t-1 } ] -e ( y_t ) e ( y_ { t-1 } ) $ ?
254110,"the inverse operation of differentiation is integration . or , for your discrete problem the cumulative sum , i . e . , r function ` cumsum ` . however , differentiation is not lossless : you lose any information about an offset ( a constant ) . are you doing forecasting ?"
254378,"do the subjects make single statements about multiple fragments , multiple statements about single fragments , or multiple - multiple ?"
254790,"could you explain how you obtained the interval $ [ 8 . 4 , 24 . 74 ] $ ?"
254841,does this happen if you drop an arbitrary observation ?
255440,why not try to find out why there's error for ar ( 4 ) models ?
255534,would you find it helpful to have answers that might refer to measure theory ?
255867,but the numerical example is given in the linked answers . . . what exactly is unclear for you ?
256027,"afaik you can't use the lrt for non-nested models . i do not know what exactly you mean by a spatial restriction , but if the dfs do not change , the lrt is out of the question . moreover , which model will be your null-hypothesis model ?"
256177,"imagine that red was simply more popular than blue - so it showed up more often for every word , even opposites . would you want to detect that as a difference between red and blue on each word or would you want to remove the average effect of color popularity and only pick up deviations from it ?"
256603,"can you be more specific than "" examine the inter-individual variation in foraging duration "" ?"
254305,could you share the link of the article ?
258860,something to consider - what do you need to apply bayes theorem ?
259597,is there a problem with setting the range of the y-axis to include all the log values ?
259693,"if your depression scores are nominal , how can you tell which score indicates severe depression . since you say you want to identify the site with more severe depression , you must have at least an ordinal scale . that would mean you could do tests other than a fisher's exact test . pls clarify your scale . also , what size groups do you have data on ?"
259936,"many tests could be proposed , depending on the alternative you consider what makes you think that they may not be not randomly shuffled ?"
260172,"risking the obvious , the reward function is what it is in any mdp : a function mapping $ ( s , a , s' ) $ tuples to real numbers . what else are you getting at ?"
262958,do you know what eigendecomposition is ?
263555,are you looking for the hypergeometric distribution ?
260695,"i posted a proposal for a notion of distance between two curves ( specifically , two probability distributions ) . i don't fully understand what you mean by the euclidean distance ( which only makes sense in finite-dimensional space ) or what bayesian statistics have to do with distances between curves - maybe you could elaborate ?"
265069,"you say you have 3 years of data . does that mean you observe each loan from origination to origination 36 months or does it mean that you observe a basket of loans with various origination dates , terms , and termination dates as they evolve for 36 months ?"
266359,"by normalize do you mean "" standardize "" to mean 0 and sd 1 , "" scale to length 1 "" , "" convert to be on [ 0 , 1 ] "" , "" make approximately normal "" or something else ?"
266685,what are you trying to show ?
266800,"welcome to [ stats . se ] ! please take a moment to view our [ tour ] . by asking about in or out of the estrous cycle , are you defining out as before menarche , after menopause , or after full hysterectomy with ovaries removed ?"
267853,why exactly are you averaging rather then using something like random effects model . . ?
267951,"hint : alpha measures the extent to which different indicators are measuring the same essential thing . do you want , or do you expect , pre and post scales to be measuring the same thing ?"
268095,enough for what ?
268462,"how about : $ x y = n $ . if $ x $ is a tail , why do you call $ y $ a fail ?"
269000,are reps' votes independent ?
269245,have you heard of the [ poisson distribution ] ( url ) ?
274644,you might want to elaborate a bit . how many data points do you have for training ?
275739,"i don't understand your main goal : "" i want to compare what proportions of outcomes is positive for each test "" . could you try to specify the null and alternative hypothesis behind your question ?"
276016,"is there a distinction between "" unknown severity "" and "" non-verbal "" ?"
257231,"consider this : when predicting a time series x1 , x2 , x3 if we do not backprop through time , how do we obtain the total loss of a training sample involving not only x1 but also x2 and x3 ?"
276227,why do you want to do this ?
276325,"could you describe what you mean by "" similar "" more precisely ?"
276557,"i cannot understand : "" a geographically weighted regression analysis "" means one model in the first step . then you get estimates of one intercept and several slops . just one observation , how to do regression again ?"
276765,can you provide a definition of sawtooth ?
277129,"seconding nickcox , you may want to check the raw distribution ( min , max ) etc . . . of your variables ?"
277298,"when you write "" e . g . "" and then "" for example : "" is there a hidden functional relation betweeen the two sets of values ?"
277926,"for a given $ x_t $ , if you know $ delta x_ { t 1 } $ you easily get $ x_ { t 1 } $ as $ x_ { t 1 } = x_t delta x_ { t 1 } $ . does that help ?"
278262,if you are using multiple imputation you should be doing separate anovas for each imputed set . do you how why the data is missing ?
281945,"is the $ f ( x , y ) $ that you state a valid joint density ?"
282967,you are looking for [ quantile function ] ( url ) . but from your description it is not clear if what you are trying to do has any sense ( e . g . normal distribution does not seem to be good choice for cloud cover -- how could it possibly be negative ?
282990,when it's non-zero is the response positive ?
283801,do you have a reference for their calculation ?
284115,related url as about your question : what are $ f_x $ and $ f_y $ are they known cdf's of empirical cdf's ?
283966,it is unusual to use two-sided values as the input as it means that studies with completely different conclusions are treated as giving the same results . can you clarify why you want to do that ?
284978,"what is a "" mic "" ?"
285145,"what is a "" beat "" of a combination ?"
285084,mugb aren't you in effect restricting yourself to the exponential family ?
285215,"more info is needed about the "" stigma "" and "" soc "" variables ( are they continuous or binary variables ?"
286634,but theyre random at time 1 ?
287144,"even though the parent distribution has zero means , are you certain that it is correct or appropriate ( depending on defn ) to remove the sample means from the defn of sample ( co ) variance , when your intention is to calculate moments of the sample ( co ) variance . are you imposing that the sample means are zero ?"
287642,do you only have those variables ?
288352,with pen and paper ?
288932,"please explain what "" deep / broad "" is intended to mean . could you provide a definition ?"
289021,"i think the answer is no , but it's worth double checking -- those "" one month "" values are not included in the "" historical "" set , is that right ?"
289044,inverse square root of sample size ?
290597,"welcome to cv . in order to increase the likelihood of an answer , please add some details : what is your application ?"
291154,"why not just drop the public holidays from your analysis altogether , as in , remove them from the data set ?"
291161,"they certainly vary from one discipline to another even within a language . engineers assume "" log "" is a common ( base-10 ) log whereas mathematicians assume "" log "" is the natural log . computer scientists will typically assume it is the binary ( base-2 ) log . solution ?"
291247,"i think the issue at hand here is how you are defining "" low "" . why do you say that a 3 % reduction in brier score is "" low "" , and a 63 % c-index is "" not very high "" ?"
291262,"could you explain what it means to "" evaluate the p-norm with an integer "" ?"
239309,screenshots taken with a phone are essentially unreadable . please * describe * your variables ( what values do they take ?
291578,"how quantitative , definite , or rigorous do you suppose "" below by very small amounts "" might be as a criterion ?"
291080,are abnormally high values similar in magnitude to one another ?
292664,"pca doesn't work on a single vector . rather , it requires a collection of many vectors . can you say more about what your goal is and the structure of your data ?"
292498,have you considered cross-validation ?
293914,your post seems a bit unclear . are you talking about null hypotheses or also specific tests ?
294059,what are hypotheses 2 and 3 ?
295220,"do you have exact date information of the incurred costs , or only the ?"
295873,"aren't the summations going over the "" i "" as well ?"
296093,maybe first you should tell us why would you expect $ mathbb { p } ( { x = ( x_i - mu ) ^ 2 } ) $ to see there . . ?
297474,"you might be able at once to clarify your question and perhaps even answer it by considering what you actually mean by "" subsample "" and "" sample "" . how are you defining these terms and what role do you see for the distinction in your analysis ?"
297566,huchesh what is the context for your question ?
297840,are you sure your plotting code is correct ?
298020,i ma have misunderstood you here but would generating normals and then exponentiating not do approximately what you want ?
299216,i think we may need more detail for anyone to attempt an answer here . did you both use the same model ?
298787,is this a school assignment ?
299784,why do you think you need to resample ?
300064,"have "" number of observations "" and "" sample size "" distinct things ; usually these are synonyms . do you mean "" number of variables = 6 "" ?"
299826,"this may seem a bit rude , but could you include in your question what the words "" classification "" and "" regression "" mean to you ?"
300428,"what makes you unable to answer this question , whether the function $ h ( x ) g ( theta ) e ^ { eta ( theta ) t ( x ) } $ , with $ h ( x ) = x ^ 2 $ , $ g ( theta ) = sqrt { tfrac { 2 } { pi } } theta ^ { -3 } $ , $ t ( x ) = x ^ 2 $ , and $ eta ( theta ) = frac { -1 } { 2 a ^ 2 } $ is an exponential family or not ?"
297985,where are you stuck ?
300296,what is $ x $ in the right hand side of your final equation ?
302688,what is your hypothesis ?
302840,do you still have the original dataset ?
302775,what are ` x ` and ` y ` ?
121771,"what you're asking isn't "" relatively basic "" , which is why you don't see answers saying how to do it in those packages . most likely if you want to do it in spss or excel , & w / o a lot of programming , it can't be done . do you want to generate sample data from a population w / those parameters , or do the sample statistics have to exactly equal those values ?"
303462,"what do you mean by "" the whole horizon "" ?"
304292,"what do you mean by "" accuracy of prediction interval "" ?"
302980,"heteroskedasticity and error correlation have the same effect on ols estimators in the linear model . the ols estimator is still unbiased , consistent , and asymptotically normal . however , the usual standard errors are biased and inconsistent , so all confidence intervals and hypothesis tests based on them are wrong . also , the estimator is no longer efficient ( i . e . there is a better unbiased estimator called gls ) . having both problems at once just means that you have two reasons for these facts to be true . is your real question how you should fix the problem ?"
305088,"please , be more precise in your question : what information do you have about that old segmentation ?"
305092,"honestly , this is a terrible , uninterpretable metric . . . why wouldn't you use one of many available metrics for continuous outcomes ?"
306631,"could you clarify what "" add and subtract "" variance means and does ?"
307318,"if you have frequencies of those fish , why is there a column proportion rather than frequency ?"
302712,"the nature of your data is not clear . is "" score range "" a categorical variable ?"
309033,"what do you mean by "" total tf-idf "" ?"
309030,"i'm guessing you want to express where you are relative to the others , so maybe you can use the percentile ?"
309593,"if you imagine a 2d example , are you asking what would be closest if you move a new point up one axis ?"
309708,"how bit is e , both in absolute and relative to n ?"
310175,"where , exactly , do "" intelligent "" and "" accuracy "" appear in the two possible values of "" a "" and "" b "" ?"
310490,"could you indicate how these errors were obtained and what exactly you mean by "" non-symmetric "" ?"
310799,wouldn't using a ( or many ) jupyter notebook help you here ?
312187,what [ loss function ] ( url ) do you have in mind for the non-euclidean case ?
312877,all the misclassification are always high or just some ?
313236,can you give some sample or toy data ?
314041,i'm going to throw an idea that might not be statistically pertinent if i did not understand the question : could you not just use an lme and compute the null distributions ( of your coefficients of interest ) with permutations ?
313628,what is your goal precisely ?
315268,is there any problem applying the standard $ chi ^ 2 $ goodness-of-fit test ?
314400,please state your objective and hypothesis ?
287367,were you ever able to get an answer elsewhere ?
317774,what do you mean by reasonable fit ?
313586,"see ltkepohl [ "" new introduction to multiple time series analysis "" ] ( url ) ( 2005 ) , section 4 . 3 "" criteria for var order selection "" , it gives a thorough discussion . trying to summarize it here would be quite some work , though , but i hope you can access the original it is pretty readable and clear . see also [ "" aic , bic , cic , dic , eic , fic , gic , hic , iic can i use them interchangeably ?"
318914,how do you determine the type and amount of regularization ?
319077,who are the subjects ?
320575,"well you certainly * can * , but why do you want to transform the raw data at all ?"
320629,"part of the "" question behind the question "" is "" how do you measure the 'done' of that first step "" . why is "" x "" a feature and "" x / y "" not one ?"
321343,do you expect calendar time ( specifically time of year ) to be important here ?
321610,"we have to guess a little . it sounds like your ta may have been thinking of the least squares problem of minimizing $ y-x beta ^ 2 $ by considering an arbitrary line of possible parameters $ beta = alpha gamma t $ for $ t in mathbb { r } $ , which gives $ $ y-x beta ^ 2 = y-x ( alpha gamma t ) ^ 2 = y-x alpha ^ 2-2 langle y-x alpha , x gamma rangle t x gamma ^ 2 t ^ 2 , $ $ which ( when $ x gamma ne 0 $ ) is a quadratic in $ t $ , obviously the equation of a parabola . does that match your "" basic idea "" of least squares ?"
321885,"how do you interpret the event "" 30 cabs will drive by in 1 hour "" ?"
322511,roughly what percentage of the 80 patients have the condition ?
322856,have you tried doing some basic exploratory data analysis ?
322996,"let's consider a simpler problem . imagine we had no noise at all , so we had an exact equation like $ y = a b x_1 c x_2 $ . for any given value of $ y $ , say $ y = 10 $ , there's an infinite number of possible pairs of ( $ x_1 , x_2 ) $ solutions that lie along a line ( the one that's formed by the intersection of the two planes $ y = a b x_1 c x_2 $ and $ y = 10 $ ) . if you specify one , you can work out the other : $ 10 = a b x_1 c x_2 implies x_2 = ( 10-a-b x_1 ) / c $ . is the line $ a-10 b x_1 c x_2 = 0 $ the kind of "" solution "" you're after here ?"
324751,probability of drawing a black sock from a drawer filled evenly with black and white socks . you can invent infinite number of examples like this . what do you need it for ?
324923,1 . what sample size do you feel you need for a t-test ?
318309,there have been a large number ( hundreds ?
325269,"have you considered replacing status with "" number of days since cancellation "" ?"
325569,"are you asking about "" confidence intervals "" or * confidence * itself ?"
325817,what kind of features are you using ?
325815,evaluating correlation has almost no bearing on sampling points randomly from within the sphere . is your question about correlation or is it really about sampling from this distribution ?
326114,welcome to the site . have you been given any information on $ y $ like its distribution ?
58580,"my basic understanding of these ordinal regression methods is that they extensions of the glm ( usually a link function is applied to the lhs ) . $ f $ is a cumulative link . the advantage of explicitly stating $ f $ is that the parameters are interpretable . but if $ f $ is allowed to be anything , then perhaps the objective is more for prediction than inference . is that correct ?"
328954,1 . linear in what ?
329303,is the plot training or validation error ?
329113,two questions : ( 1 ) how strict is the requirement that $ t $ have minimal volume ?
329347,"i'm having trouble even making sense of the statement to prove . in what sense is "" $ o ( 1 ) $ "" meant , given that $ x $ has * finite * support ?"
330600,how about a square ( or cube ) root transformation ?
295799,"a quick question just to clarify from which angle you try to understand it : is it 'ok' for you to take basis functions other than the very simple projections $ phi_j ( x_1 , . . . , x_d ) = x_j $ in linear regression ?"
330643,"social media companies don't serve content in time-series order , they serve it according to user interests and interactions . "" time of day "" is only relevant if you also know the locations ( i . e . local times ) of potential consumers . views are plausibly strongly correlated with follower / friend counts ( because who else would see it ?"
332025,"some relevant discussion on this general type of design [ here ] ( url ) . the summary is that ancova is better than the t-test because it controls for the pre-test scores as a precision variable , and thus more precisely measures differences in follow-up . does this answer your question ?"
32853,peterflom how do you think this compares with gui11aume and steffen's discussion about a two-stage model and sample selection bias ?
332350,what initial distribution are you talking about ?
241752,please clarify your question . do you have just two sentences or do you have a bunch of pairs of sentences ?
335258,probably you are expected to use gamma regression ( ?
335810,"besides that , do you make your features stationary ?"
337255,"first thing , if you discretize it , it will still be non-normal . so that helps you none . what is the actual distribution of the raw values ?"
338119,are the symptoms mutually exclusive ?
338311,"the "" * 100 "" doesn't belong there . presumably you included it to convert the probability ( by definition , a number between 0 and 1 ) into a percent . the rest of the formula implicitly assumes that once a song is played it will never be played again--is that really how your playlist works ?"
338462,are you using dropout during the test phase ?
338766,is this a homework problem ?
338770,so you have $ n $ years of data for $ k $ measures of regulation ?
339538,what are you doing this for ?
341015,"could you explain what you are trying to achieve with this "" combination "" ?"
341546,"what does "" repeat "" refer to ?"
341849,point for clarification : what is the response scale for the $ n $ item ?
342402,"how can we tell that the residuals are "" strictly positive for large y "" ?"
342632,"what do you mean by "" understand "" ?"
343211,do you know the functional form of $ f $ ?
343356,"your analogy to children is a bit faulty . very young children might confuse different types of four-legged animals ( calling all such animals "" cats "" for example ) but children just a bit older wouldn't make that same mistake . what happens in the intervening time ?"
343331,what are you testing ?
51317,"what exactly do you mean by "" batch effect in correlations "" , and what would constitute having 'taken care of them' ?"
89933,the [ hypergeometric distribution ] ( url ) ?
96803,your calculations suggest all $ n_x n_y n_z $ observations are independent . are you sure this is the case ?
97345,you will get better responses if your question is more specific . what are the models you have in mind and what do you want to achieve with this approach ?
97703,"surely , you are aware that robust statistics and outlier detection has improved a lot in the last * 150 years * . is there any reason you are using this test ?"
97754,"in _your_ formula , what happens if you divide numerator and denominator by $ p ( a ) $ so that in the numerator $ p ( a ) $ disappears while the denominator becomes $ p ( a cap b ) / p ( a ) $ ?"
103316,"manova compares the * mean * of the variables x , y between g , p taking into account correlation of x , y . it is a different think to compare the * distributions * of x , y between groups g , p . what exactly is your purpose ?"
103399,"there is too little information for you to get a good answer . for starters , why do you look for an alternative and hat is the setup and goal of whatever you have in mind ?"
104614,"to answer the question one has to establish a quantitative understanding of "" better . "" some common meanings are ( 1 ) in terms of average error in approximating individual binomial probabilities , ( 2 ) errors in approximating tail probabilities , ( 3 ) errors in approximating central probabilities . all these errors can be assessed in different ways--as absolute differences , relative differences , with various weights , and so on . then the scope of $ n $ and $ p $ must be specified : what will their typical values be ?"
105232,do you got sales development from other cities to compare with ?
105896,"i do not see how you could possibly do this without making some assumptions about the distribution , for then * any * point configuration is consistent with a likely realization from some 2d distribution and , relative to it , does not "" lack "" any points in any region . at a minimum you must make some assumptions about homogeneity or stationarity . what is the practical problem you are really trying to solve ?"
107707,your question is broad and unspecific . what do you need to understand about it ?
108677,can we see a reproducible example please ?
110113,so should the probability for 21 heads out of 21 be 1 ?
113936,how are the particular datasets you are working with relevant to your questions ?
114397,"you are not explaining how your wiggly curves were derived . at a guess , your green line is a linear regression , which looks like a bad idea . the downward turns are not very convincing and seem to be governed largely by # 132 . do you have any independent grounds for suspecting a turning point ?"
114428,"if it's a pearson correlation , why do you cite cramr's [ nb ] $ v $ ?"
114535,"for clarity , latent * semantic * allocation ( lsa ) or latent * dirichlet * allocation ( lda ) ?"
117029,do you mean the population standardized third-moment skewness $ mu_3 / sigma ^ 3 $ ?
117520,"to help potential answerers , can you describe your notion of entropy ?"
118105,what ` statistical properties ` ?
120939,what's the cnn's output ?
120978,is this really a classification problem ?
122917,"did you mean to write "" that a sample median could often be "" ?"
124041,"i think one can do unpaired t-test between pre values of control and test groups and if there is no significant difference , do unpaired t-test between 2 post values to see if test intervention has any significant effect . if there is a significant difference between pre values from 2 groups , then ( postmean - premean ) differences ( i . e . deltas ) in control and treatment groups can be compared using unpaired t-test . but i do not know what would be the sd here ?"
124434,"a two-variable distribution function , by definition , maps $ mathbb { r } ^ 2 $ to $ [ 0 , 1 ] subset mathbb { r } $ . as such , it cannot have an inverse ( in the conventional mathematical sense ) . what exactly do you mean by "" inverse "" then ?"
126066,"welcome to cv ! "" all subjects will be carrying out the exercise stimulation "" - or is there a control group who won't receive the stimulation ?"
126918,are you asking about adding additional _data_ ( = datapoints ) or additional _factors_ ?
127104,"ah , crap , this happened to me a month or two ago , but i forget what the problem was . is it possible that those are dummy codes and that you've included all of them , i . e . is it possible that one of the variables is a ( perfect ) linear combination of some of the other variables ?"
128864,do you have a model that says what new state results from taking an action in a given state ?
129317,what do you mean by 'precise' here ?
130939,which distribution did you have in mind ?
132924,both ` isolate ` and ` temp ` are numeric variables ?
137844,"it seems that a * single * observation in which $ a $ and $ b $ do not behave in the same manner would discredit the hypothesis that they "" always "" behave in the same manner , whereas * no amount * of observation will suffice to prove such an assertion . instead of "" always "" did you perhaps intend to mean "" tends to more often than not "" ?"
137948,"is your question about r functions , or is it just about the underlying models ?"
138119,can you clarify ?
142082,are we discussing one-sample or two samples ?
143913,multicollinearity is only a problem in interpreting coefficients and does not reduce the predictive validity of your model . are you okay with this ?
143918,"it is crucial to know what $ p ( x ) $ * means * . is it the chance of a random variable $ x $ equaling the value $ x $ , or is it perhaps the chance that $ x le x $ ?"
144168,isn't $ z $ just a mixture of gaussians ?
144218,ancova is regression - what function are you using to do ancova ?
144621,"this is unrelated to your main question , but when you say "" attrition "" , are you building survival models ?"
145054,did you mean to say methods to deal with panel data * * attrition * * bias ?
145906,is this a question about the dummy variable trap ?
145977,"fitting the model multiple times will give you the same coefficients each time , assuming the training data are fixed and the fitting procedure is deterministic . in that case , there's no point fitting more than once . could you add some code showing us what you've tried to do ?"
146140,to what extent does your example resemble the function you want to estimate ?
146304,is this question from a course or textbook ?
147869,how did you get your feature maps to be of dimention 28x28 shouldnt it be like 24x24 ?
154307,"what do you mean by "" if there was a link between the two clusters , [ 5 , 3 ] or if 3 points only had two links : [ 1 , 2 ] and [ 2 , 3 ] "" ?"
158331,"( 1 ) what is a "" meni sequence "" ?"
159581,i am not quite clear about your question . can you explain that more ?
161784,"questions 1 and 3 are good and clear , but what does question 2 mean ?"
163471,"a difference must be relative to something . what do you mean by "" difference "" ?"
163544,"i'm not sure if i understand what you mean , but does ` exp ( fm ) ` give you the information you need ( replace "" ` fm ` "" with whatever your model is called ) ?"
163601,"why do you write "" one-way "" in the titel ?"
164172,"what do you mean by "" combination of some attributes "" ?"
164572,can you clarify your situation ?
164920,` examining high level of cos2 ` what is that ?
166506,this link requires that the person create an account to see the paper . can you ask a complete question here instead ?
169004,having 50 data points is good enough for arima . do you have a control group ?
169679,what is it you ultimately want to know about these data ?
171481,"what is an element , and how many different elements are there in total ?"
171587,what is it you want to know about these data ?
172208,can you explain your dataset further ?
175182,maybe this question calls for the self-study tag ?
175387,is there a particular area you are interested in ?
175547,"matlab also has kmeans . i just googled "" kmeans matlab "" and found this : ( url ) . did you do even the most basic web search on the topic ?"
175986,"since you specify nothing of any import about $ g $ , $ dg ( mu ) / d mu $ can be arbitrarily large and negative even when $ f ( g ( mu ) , mu ) $ is close to $ 1 $ , so the answer has to be "" of course not . "" if this problem is derived from a practical situation you face , is there any additional information that could provide a lower bound for the derivative of $ g $ ?"
177094,how did you get this covariance matrix ?
177350,do you have any idea what value to use for $ alpha $ ?
177548,"i don't understand why we would do this , either , and i haven't seen this approach before . could you give a reference ?"
178527,"can you clarify what you mean by "" two step cluster analysis "" ?"
180650,i think you should clarify your question a bit further . what exactly do you want to use the logit function for ?
181592,this question is redundant with this question . . . url any reason you're asking it twice ?
182529,"perhaps i am missing something , and i don't want to assume what your distributions are for you , but can you tell us what the likelihood of your data is , and what priors you are using ?"
183476,why not simply using a chi-squared ( $ chi ^ { 2 } $ ) test to test whether differences between allele / genotype frequencies exist between populations ?
186287,"what kind of data are "" normalized speedups "" ?"
187619,can you post your data ?
189053,"yes , it is possible to do it . i could indeed see that a reviewer might ask that question . is it perhaps easier to interpret the predictions for particular covariate combinations ?"
189723,what kind of data are you asking about ?
190993,what is the connection between the title ( which focuses on $ lambda $ ) and the question ( which appears to be only about the $ beta_j $ ) ?
191353,the most important thing that you * didn't * mention is what is aim of your study ?
191538,better in which way ?
191697,superior in what sense ?
192177,in which context did you find 'significant rank correlation' ?
193774,what is the data ?
194391,"also , could you please type your formulas in mathjax ?"
195216,"what is meant by "" max ( w_1 x , w_2x ) "" ?"
197340,what are the signals for ?
199211,can you do it for one train ?
199939,see also [ what is the difference between linear regression and logistic regression ?
203457,are the $ x $ s and $ z $ s correlated ?
203859,to make this answerable you could specify what regression model you are talking about . apparently there's a regularizer in your frequentist estimation ( what kind ?
204905,what is it that you have tried in r ?
206565,"can you clarify what you mean by "" ( without solving ) "" ?"
206962,"it all depends on how detailed a portrait you want to present , what your audience is , and why you are using such summary statistics in the first place ( instead of , say , a picture ) . could you be more specific ?"
212161,"i don't understand why at the beginning you said there are a potential reason for missing value , and at the end for simplicity you assume missing values are at random ?"
212469,what happens if two examples have identical feature vectors but opposite labels ?
212752,why do you want to call it a multivariate model if you are really interested in the random effects structure ?
214684,"could you explain what "" good "" means to you ?"
215380,are you familiar with [ respondent driven sampling ] ( url ) ?
218016,"what are you integrating , the density or the distribution , or something else ?"
218508,"unclear , for me . are you going to do cluster analysis or to generate clusters ?"
218527,"welcome to crossvalidated . several things to ask : first , i am assuming you mean cronbach's alpha . second , what is alpha now ?"
219501,. . . and in which context did you find people looking at whether they are equal or not ?
220756,i don't really follow your situation . can you say more ?
221382,"i don't understand what 'choose the sequence of models' means here . in this wrong case , if one chooses the number of regressors based on the entire data set , what exactly is happening in the cross validation loop ?"
221511,can you edit your question to make it clearer to people who do not work in your field of science ?
222726,"your response variable is binary ( 0 / 1 or any two other distinct values ) , right ?"
223111,"welcome to cross validated . it would be helpful if you can provide more information about the outcome variable . you mentioned the cox ph model , so it seems you have information on survival / failure in your data , yet your question asked about "" optimum price of a new given task . "" i'm having a hard time visualising how these two are related , especially if the task is categorical . what is meant by "" new given task ?"
224049,could you please provide the full reference of the paper in case your link dies ?
229300,what do you mean by classification result ?
234442,"fixed and random effect are panel data models , right ?"
235369,"could you clarify what you mean by "" test the hypothesis between these likert scale variables "" ?"
237231,are you sure this property holds at all ?
237476,can you give an example of where you saw the term cohort and it confused you ?
238070,is it homework ?
238716,what does ` test ` mean ?
240064,"* * it makes no sense * * to refer to a confidence interval for a characteristic of a * sample * ( such as its maximum ) , because by definition confidence intervals are about the probability law ( or population ) from which the sample was drawn . could you please clear this up by providing more specifics about your situation ?"
241342,"can you elaborate on "" the rate at which the data from group h is greater than the one in group i "" . what do you mean by rate ?"
241369,could you elaborate more on the types of datasets where you are trying to measure relatedness ?
243758,it can be hard to say without seeing the data . can you edit in a part of the data and the model itself ?
245155,"$ nx = z sim mathcal { n } left ( n mu , n ^ 2 sigma ^ 2 right ) $ , did you mean $ sum_ { i = 1 } ^ n x_i = y sim mathcal { n } left ( n mu , n sigma ^ 2 right ) $ where $ x_i $ are i . i . d . ?"
246760,why ` t ( rbind ( . . . ) ) ` instead of ` cbind ( . . . ) ` ?
247110,any information on the nature of the dependend variable ?
247232,"you might want to provide some more background on what you mean by each of these terms . one-vs-one is fairly well defined , but i'm not sure if "" linear one-vs-one "" is , linear w . r . t . what ?"
248841,"have a look at url for an answer to your first question . for the second , what is "" the "" bias formula ?"
250404,i'm not sure i follow your question . can you clarify ?
251596,"try creating a sample and see if your estimator makes sense . for example , set $ n_1 = 100 $ , $ n = 2 $ , and $ x_1 = 102 , x_2 = 110 $ . what do you get ?"
252714,difficult . can you give us more information about the different measures ?
253467,"welcome to cross validated . when you say data nested , you just mean many observations about the same user , correct ?"
254723,"are you writing your own naive bayes algorithm , or are you using a package in r or python or another software ?"
255191,are you interested in comparing each mean to each other mean as is done with tukey or each mean to the mean of the other groups ?
256875,what do you wish to achieve ?
257905,do you know the exact number of downloads ?
259365,can you elaborate on this noise process you have prior knowledge about ?
259564,"are you sure it's not $ y sim mathcal { n } ( x beta , tau ) $ where for $ tau $ gamma prior is used . . ?"
259993,what is the exact ( error ) message you got ?
260803,there are a number of potential connections between the two ( or indeed between other pairs of distributions ) ; for example one is sometimes used as an approximation to the other . can you clarify what sort of thing you're seeking ?
260953,"could you elaborate on what you mean by "" chi square homogeneity "" ?"
263829,it is not clear what do you mean . . . do you have * only * the mean ?
269334,"why not use regression techniques with , for instance , interactions ?"
271639,"the most immediate deduction is that something is going wrong . $ k $ means has to get better ( on average ) as $ k $ increases . so what does it mean when you say you are getting "" best performance "" ?"
272483,can you give some more information ?
272545,"first note that the linearity of expectation means you don't have to worry about the $ beta $ terms . then , why not calculate explicitly what happens when $ p = 2 $ ?"
273792,it is interesting to note that for a gaussian distribution the sample mean and variance are independent and hence the covariance is 0 . how this works for other distributions i am not sure about . have you checked this site for other posts on this topic ?
274748,what is the dependent variable in this problem ?
275517,if a and b are events how can they be compared to a number like 0 ?
276186,"well , lars is an algorithm to fit lasso models . of course , [ glmnet fits sparse logistic regressions ] ( url ) , although it doesn't use lars ( see section 3 . 2 . 2 in [ hastie , tibshirani & wainwright ] ( url ) . i'd assume that the nonlinearity in glms precludes using a least-angle approach . why are you interested in specifically generalizing lars ?"
276481,is each mouse measured repeatedly over time ?
276950,improve the description of the question . what kind of data you have for each individual ?
277406,i think you mean probability rather than likelihood . is a * b the product of a and b ?
280621,832 examples is not a lot of data for a neural network to train on . did you consider something like one class svm ?
280813,convolutional networks can be deep . do you know what makes a conventional network convolutional ?
281354,"i don't think that i completely understand your question . the reason that you take a sample from a population is that you want to find out something about the population . i don't see how you can accomplish that by using the same weight for the responses of different people in your sample . in addition , it seems like a bad idea to allow multiple people to answer . what's the sampling distribution under the null going to look like ?"
283907,what are you trying to predict ?
284080,"firstly , what have you attempted so far ( i . e . where are you getting stuck at ) ?"
285446,"welcome to cv . your question is not clear to me . how do you define "" best "" , how features will be used ?"
291452,"( 1 ) you must be missing a factor of $ s $ somewhere in the inequality . ( 2 ) apply chebyshev's inequality to the empirical distribution function of the $ x_i $ . ( 3 ) when you do , which way does the inequality go ?"
292710,this unusual situation makes one wonder what you are trying to achieve and whether the procedure you describe would be a legitimate way to do it . could you explain ?
294335,"can your question be generalized to "" how to do and to report hypothesis testing based on bootstrap "" ?"
294557,there are several plausible ways to do this so perhaps you need to expand on what you regard as correct by editing the question . for instance do you want 50 on the old scale to map to 50 on the new one ?
296255,"if the data * really * comes from a poisson distribution , it depends on the value of the parameter , but it can be worked out . if the data just * looks like * a poisson , then it depends on the actual distribution it comes from . if you specifically want to look at the 5 % of observations that are most outlying , why not do that directly by computing the empirical quantiles instead of making assumptions about the distribution ?"
297439,"it does generate iid samples , but i doubt this is what you need . can you explain more about what you're trying to do ?"
298602,"let's call your two 1-sample tests , test a and b . think about the logical relation between a and b test . do they depend on each other ?"
299185,log-loss ( i . e . logistic loss ) is the standard . do you have a particular reason not to use that ?
299698,what are you quoting ?
301894,your question is automatically flagged as low-quality because it is so short . can you extend your question please ?
302877,what is dependent variable in a cluster analysis ?
303739,"what do you mean by "" performance "" ?"
309323,". . . what is this $ q $ , $ p $ , and $ n $ ?"
316495,what is your target ?
318715,"i am assuming this is homework or self-study , so will give a hint : given $ x_ { ( 1 ) } $ and $ x_ { ( 4 ) } $ , what distribution do each of the remaining two variates have , unconditional upon order ?"
323128,"it may be that you are fitting too many gaussians . have you looked at metrics like aic , bic for model selection ?"
325273,what is a meaningful error if there is no equal variance across categories ?
326837,getting 0 % accuracy is the same as 100 % accuracy with inverted binary labels . hence your model is basically perfect . what's the question again ?
330502,do the two wards have the same number of patients ?
330702,because $ hat beta = ( x'x ) ^ { -1 } x'y $ ?
331051,could you explain how substituting zero would yield * both * a mean and a variance ?
332171,can you give us an example of the dataset you are using ?
337677,"hi larry , how is my answer ?"
340499,maybe search this site for clustering of time series ?
342352,could you provide more details--maybe an example of the command you used and the output you received ?
342619,"confidence intervals with normality assumptions , bootstrap confidence intervals ( e . g . percentile or bca-intervals ) , . . . ?"
343295,can you add a lot more detail ?
344595,can correlation be considered a type of learing at all ?
344797,it depends on the new analysis . perhaps you could edit your post to say something about that ?
344545,"technically , you're not doing maximum likelihood , but minimum log-likelihood ; so you're not trying to maximize the given expression , but minimizing it . i'd like to understand what you're doing , but there are some missing pieces . what is meant by your model -- please state explicitly what the parameters , what the dependent and what the independent variable is . also regarding the initial description , is the variance $ sigma ^ 2 $ really the same in both terms ?"
344956,did you bother reading the linked how-to articles ?
345333,why do you believe that an accuracy better than 60 % -70 % is possible for your problem ?
345409,having a variable on the denominator that can be 0 with prob 0 is problematic ; how are you dealing with this ?
345681,why do you need proofs ?
345872,couldn't you just find confidence intervals ( 95 % is typical ) for each ?
345628,why do you think evaluating accuracy per batch is more efficient than evaluating it on all samples at once ?
346165,are you doing regression or classification ?
346171,can you elaborate more on the nature of your response ?
344544,"what is a "" posterior confidence interval "" ?"
121703,do you see what shift invariance means in general ?
346455,what is 'it' ?
345372,"you actually give a compelling reason not to truncate any variables in your opening paragraph . you have a prior belief that class 1 observations will take extreme values . if your goal is to distinguish the two classes , why would you ever want to hide this information from the model ?"
344717,"this is precisely what autocorrelation is used for . if you say more about your situation , including what type of data you have ( daily ?"
347349,how many observations do you have ?
281614,"some misc topics that i personally find interesting : - parameter expansion ( pxda , sandwich algorithms , etc ) . - as mentioned by bjorn , the effects of parametrization on convergence and the geometry of the target ( does this count ?"
347430,why do you think removing them is going to help answer your scientific question ?
347328,"hi helen , welcome to cv ! at the moment , your question is a bit too broad : what do you mean by "" best algorithmic choice "" ?"
347802,what is your ( current ) forecast based on ?
347939,why don't you do ` fit - aov ( quant ~ qual ) ; summary ( fit ) ; tukeyhsd ( fit ) ` ?
347905,there are many ! for what purpose do you want to use the distance ?
347374,"interesting plot . indeed , probabilities below 0 or above 1 don't make sense . can you explain how you got these numbers ?"
348148,"i don't know if i understand you correctly , but if the time windows are so small , that you see almost no differences , then why not take previous value as your prediction and forget about machine learning ?"
348177,""" matched with testing data "" in what sense ?"
29131,maybe this question is more suitable for stackoverflow ?
138404,""" negligible , "" like other comparative adjectives "" larger , "" "" worse then , "" "" richer , "" etc . , is in the eye of the beholder ( and subject to assessment in light of their "" intents and purposes "" ) : it has no universal definition . is a loss of a million euros "" negligible "" ?"
348172,do you understand how to interpret parameters of a log normal distribution ?
348265,what is a mediation rate ?
341417,does auto . arima allow for multiple seasonality ?
348441,your feature selection might be too noisy ?
347964,how many quantiles do you have ?
348419,"you have answered it a bit yourself already . * "" . . . that because of the two parts of the hurdle model ?"
347200,hi there and welcome . 1 ) please provide more context : what kind of variables are we talking about ?
299227,"wunsch punsch : it's not really clear what your motivation here is . are you trying to train a network from scratch using polynomial activations , or are you trying to approximate an existing ( already trained ) network with polynomial activations ?"
348622,"this comment raises a rhetorical question . the authors of the paper * statistical and machine learning forecasting methods : concerns and ways forward * found that machine learning time series models , at a minimum , did not improve predictions over statistical models and in many cases were less computationally efficient ( url ) given these fairly conclusive findings , does it make sense to proceed with a nn model of time series * at all * when statistical models are so much more tractable , efficient , etc . ?"
349118,"you assertion that the first set of data has "" near perfect correlation "" doesn't fit with the * actual * definition of the correlation coefficient in statistics . can you explain why you think "" often having the same value "" implies "" near perfect correlation "" ?"
349210,can you clarify the meanings ?
349173,what loss function do you use to train the network ?
349466,which wikipedia page are you referring to ?
349366,it does not really make sense to have a binary variable $ x $ with distribution $ p ( x ) = exp ^ { cx } $ : what is $ p $ in that case ?
152,"i was considering asking "" how can i do an mcmc model of the output on lmer for models with random slopes ?"
165,should be community wiki ?
224,"what do you mean , standalone application ?"
242,"could you edit the title to something like "" using time series analysis to analyze / predict violent behavior "" ?"
321,what other variants ?
411,"i like the question , there may be already most of the possible answer in the question . . . do you have an idea of the type of answer / developpement you want ?"
652,you tagged this as bayesian and machine-learning . what kind of data analysis are you interested in ?
847,have you tried asking google itself ?
11,can you be a little more specific ?
886,i don't see the interest of these questions about trying to bridge a fictive gap . what is the aim of all that ?
899,can you assume that the other two groups are from different normal distributions ?
924,"by the way , is this a duplicate of what you posted here ?"
1015,is your your probability score identical to what is called the brier score ?
1093,"by the way , will the binomial not work for you ?"
1126,community wiki ?
1194,this question is proposed to be closed . see : url i see that it has 2 votes . could the up-voters or the op comment on why they would like to see the question stay open at the meta thread ?
1224,i think we need a bit more information . what are you comparing ?
1249,do you want a lower or a upper bound ?
1266,"tal , may i ask whether you found a solution for this ?"
1278,can you have a control group ( ward ) ?
1286,has anyone noticed that the number of questions that should be in stackoverflow r rocketed up here recently ?
1378,1 for interesting real case ! can you help us to understand what is blood test ?
1493,your gaussian variables are iid ?
1555,"you need to explain the data structure more , otherwise it is not clear how would a chi-square test apply . what do the values represent ?"
870,"your question , as it stands , is difficult to understand . what do you mean by "" referred to "" ?"
492,"are these differentially corrected gps measurements of plate motion , by any chance ?"
1646,i'm having some trouble understanding the dependent measure in your question . how is team effectiveness being measured ?
1580,how would you explain a situation where coefficients change signs when including predictors but there definately isn't any multicollinearity involved ( as low vif values would suggest ) ?
1708,can you write some crash-introduction of what you want to do ( including eigenstrat step ) ?
1709,it is not clear what you want . do you want a visualization of the 5 points you collected or a plot of the theoretical distribution that you feel generated the data ?
1621,"fisher's information gives lower bound in parameter estimation . it is a natural metric because it roughly says something like "" in this direction the difficulty of my problem cannot decrease more than that "" . what you call generalization bounds are upper bounds ?"
1807,what problem are you trying to solve ?
1813,"just as a clarification : isn't it the case that a genetic algorithm searches randomly for a solution , so that the initial segment of any run is unlikely to produce any worthwhile solution ?"
1912,sorry if it is my english ( unfortunatly i'm french ) but is it proper english ?
1944,maybe ` standardized ` ?
1963,"ilhan : therefore you ( and presumably everyone else , in the name of "" fairness "" ) should be allowed to break them ?"
2111,are you refering to the following paper ?
2131,this asymmetry does not look * so * bad ; are you sure you don't have an error somewhere else ?
2146,"do i understand it right that you have two sets of time series , and you want to check whether or not they differ significantly ?"
2151,is dimension reduction an option ?
2169,what is the distribution of $ x $ ?
2104,do you want to look at sphericity or a factor to correct f-values because of violations in sphericity ?
2234,"do we have to assume that you are considering a fixed set of predictors , i . e . you are interested in getting a reliable prediction given $ k $ predictors , or are you also interested in some kind of penalization on the $ x_j quad ( j = 1 dots k ) $ ?"
2294,"i'm trying to imagine a situation that is matching your model . maybe a physician checks their patients weekly to see if they are ( 1 ) still sick , ( 2 ) dead , ( 3 ) cured or ( 4 ) lost to follow-up . are you trying to estimate the dead / cured ratio assuming that the transition probabilities of lfu patients are the same ?"
880,"but still , what do you want to measure with cv and in what purpose ?"
2337,"ideally , the question should be self-contained . could you please give the relevant formulas as well ?"
2420,"technically speaking , a histogram is used to show summary information about a frequency distribution . i think you want to ask "" is a bar chart satisfactory ?"
2446,onestep : good point adam : do you have access to the underlying data ?
2467,"could you confirm that "" classification "" is not meant as "" cluster analysis "" ( which is called * classification * in french ) , that is do you really seek to apply a supervised method following your fa ?"
2481,kolmogorov test is for distributions hence object lying in infinite dimensional space . . . not obvious to get asymptotic power = 1 . t-test is about testing the mean of a real valued random variable ?
2493,do you have a the raw data from the gps devices ?
2513,could you add the calculated t as formula using latex ?
2483,"insights into the warning process would help in precise answers : are your events of interest ( i . e . , weather in your example ) continuous variables which are discretized or are they truly discrete ?"
2537,are you working with r or stata ?
2547,it seems like you already had a reasonable answer on the other site ?
2585,should this be community wiki ?
2648,does $ y $ increases monotoneously ?
2617,daniel : which probability integral are you using ?
2806,there are loads of public svd algorithms . see url can't you use or adapt one of them ?
2852,could you explain how data were collected and what they intend to measure ?
2849,what's the other dimension of the panel ( i . e . n ) ?
2828,can you give more information about what attributes are available about the models ?
2894,any reason why you marked this as cw ?
3038,"what do you mean by "" this assumes the null hypothesis to be true "" ?"
3051,have you seen [ this ] ( url ) ?
3052,could you provide a small data sample ?
3086,how many individuals are used to estimate the item intercorrelations ?
3100,"when are two curves "" consistent , "" jeromy ?"
3119,"please elaborate : do you want to scale x2 so it lies between 0 and 0 . 5 like x1 , or do you want to be able to predict x1 from x2 ?"
3156,what's p ?
3163,misha what's wrong with joris's response on stackoverflow where you cross-posted ?
3171,i am not sure i see what the issue is . don't you associate the responses of each respondent over time with some sort of dummy id ( to preserve anonymity ) ?
3199,2x2 matrix's upper left corner is only one element . . . can you reformulate the question ?
3214,can you provide an example of the outcomes you consider in your experiments ?
1622,"when you say that the sharpe ratio is the mean divided by the sample standard deviation . . . "" up to a constant factor ( sqrt ( n ) , where n is the number of observations ) "" . . . what does this last part mean ?"
1066,"you mean that you are looking at the distribution of subsample * * lengths * * of subsegments covering each position , right ?"
3244,could you link to the spreadsheet mike lawrence provided ?
3252,i'm not quite sure why the size of your sample matters . can you offer anymore specific reasoning as to why you think it is different for small n than it is for big n ?
3261,what is $ epsilon $ ?
3289,what is the statistical motivation for this question ?
3372,kaelin : do you mean whether there exists 'on the fly' method for computing summary stats such as median and quartiles ?
3412,"your models are not nested , what would be the rationale for using an lrt between the two ?"
3296,could you indicate what classification method ( s ) is / are used ?
3589,"this does not sound like you have observations ( or "" cases "" ) on which you observe both an x and a y realization . how do you find out which x is associated to which y ?"
3641,what's wrong with the moving average ?
3640,"david - since your variables are all positive , why do you want to fuss with $ mu = 0 $ ?"
3707,"since ms-excel's rand ( ) gives a uniformly distributed number between 0 and 1 , how did you get ranges from almost -2 to almost 4 ?"
1781,just so i understand correctly the censoring issue : when you dilute a sample the concentration of a compound falls so low that the test instrument can fail to detect its presence . is that an accurate re-phrasing of the censoring problem ?
3752,"you wrote "" on the other hand , variable kernels are usually thought to lead to poor estimators in kernel density estimation "" , what is the part of the paper you mention that makes you believe that ?"
3762,shadi how many discrete values do you have ?
3698,"hmm , that's what i get too : o-e / sqrt ( e ) = 17-16 . 5 / 16 . 5 = 0 . 123 . can you add a link to the paper if it's available on the web ?"
3793,what's the reason for the vote to close ?
3799,"your small example is very useful , but i assume your real dataset is larger . how much larger , i . e . ( roughly ) how big are your real * n * and * k * ?"
3805,how many percentiles are included in your real data ?
3779,should it not be 'pick k tiles * without * replacement' ?
3788,why do you want to know if the data are independent ?
3856,what type of data are you working with ?
3931,"tal , this is why schools suck . you ask them "" why * this * ?"
3907,have you seen the august issue of the american statistician ?
3974,what do you mean by 'trivariate' ?
4019,"it would be helpful if you could give a bit more detail about the nature of the machine learning algorithms , in particular what is meant by "" randomly generated initial approximation ( parameters ) "" - does this mean something like a random set of initial weights for a neural network , or do you mean somplething like a random choice of kernel parameters for an svm ?"
4065,"wrote "" the overall precision of the scores should be e . g . 0 . 1 "" do you mean you want the score to be a random variable with mean 0 . 1 ?"
4068,did you mean to ask about the population variance definition or about the * sample * variance definition ?
4104,max how large is your dataset ?
4131,"quick clarification : do you want to assume that exactly one functional form should fit all of the participants , or do some participants have one form and some another ?"
4125,what have you done so far ?
4140,"probably i didn't understand something , but can you please clarify how can you simulate "" real "" cdfs ?"
4150,"robert1 if you could disclose the purpose of this fit you will increase your chances of getting really effective responses . why do you need a parametrization instead of , say , the empirical distribution function ( as revealed by the sample quantiles ) ?"
4174,"the iteration numbers are surely just identifiers , and should not be used as numbers in computations . how many iterations did you do in total in your original trial ?"
4175,what's the purpose of the experiment ?
4233,"does it predict new data with 85 % accuracy , or part of the original data set that you held back for validation ?"
2397,what exactly do you mean by limiting distribution in this case ?
4276,how frequently is the sensor capturing its readings ?
4305,do you have a three measurements on one individual or three measurements on three individuals ?
4354,i am not sure if i understand the question correctly . are you asking if there are any distributions apart from the normal that are completely specified by the mean and the variance ?
4367,user1566 : i formatted your equations using latex . would you double check that i didn't introduce any errors ?
4138,"gregor what is "" l "" in this problem ?"
4394,biostat = application of statistical methodologies to biology ?
4422,what is the aim of your analyses ?
4437,what is the question exactly ?
4445,"whuber , would you be willing to provide an answer to your own question here ?"
4471,is $ x ^ 2_ alpha $ meant to be a quantile of the chi-squared distribution ?
4501,i was more worried about the subject matter than the subjectivity to be honest . how about proposing it as a suitable question for url ?
4519,"if i understand you correctly . in your case , for the tuple ( a , b ) , a and b are both observation ( may be missing ) ?"
4610,can you use r ?
4658,"is the "" fat-tail "" tag really meaningful ( for future questions ) ?"
4667,which other languages are you interested in ?
4454,"are you interested in publishing ( online or offline ) or editing solutions , finally ?"
4734,"i don't think the preceding question has anything to do with cfa . it was clearly about efa vs . pca , with the possible confusion that efa can actually be based on "" principal components "" . but maybe you could reword your question if you have a specific application in mind ?"
4741,what do you mean by assigning an uncertainty ?
4768,are we to suppose it does each of these with probability $ 1 / 4 $ ?
4766,i am not really familiar with r but it seems that there is a problem in your implementation : you should only keep the first ( k p ) lines ( or columns ?
4805,by 'sas em' do you mean sas enterprise miner or the sas implementation of the expectation-maximization algorithm ?
4830,"the raw proportion of defaulters is apparently 1 case out of 4 , but it seems you also have a lot of variables . did you try them all , have you any set of primary variables of interest ?"
4840,"your question lacks some critical details -- first of all , what should be the protocol of this forecast , i . e . you want to predict the ozone level for next day every day ?"
4912,"x seems irrelevant to your question of whether a is more often positive than b . unless perhaps you might wish to stratify by x , i . e . ask ( 1 ) whether a is more often positive than b when x is positive , then ( 2 ) whether a is more often positive than b when x is negative ?"
4908,how many contexts do you have and how many data points per context ?
4942,$ v_0 = ( m_1 m_2 ) / 2 $ seems to be a relatively good candidate ( at least by symetry ) ?
4949,is this question the same as url ?
4972,"legend 'scenario' means that you already have some hypothesis , no ?"
5016,where do the empirical estimates come from and in what form are they ?
4991,"the way it's posed , this seems like a degenerate problem -- the errors could equally be attributed to the observation noise or the process noise . are there more constraints ?"
5136,"that seems rather a general question - would you like to take a look at url and see if that helps , or if not , which bits you don't follow ?"
5144,"it sounds like it is indeed the topic of design of experiments . however , your description lacks some information ; e . g . , what's the sample size , are all variables crossed , is this a repeated-measures design ( i . e . , data are collected on the same statistical units ) ; how many levels have your variables , and most importantly , are you interested in a predictive or an explicative model ( from what you described , your use of the term 'predict' is not obvious ) ?"
5172,do you know the sample sizes . . . the range of them ?
5184,"just a comment . a guideline based on $ p geq something $ smells like a misuse of a $ p $ -value , in that a non-significant $ p $ value is not a measure of non-evidence . since $ p $ -values are uniformly distributed under the null hypothesis , why not just flip a ( biased ) coin ?"
5187,you mean something like url ?
5171,"is each row the count of a different structure for the same conversation , or the count of the same structure for different periods of time ?"
5238,what kind of operations do you actually do on the files ?
5249,i do not understand the issue of csv and reliability . do you mean that csv is not strict enough ?
5327,"you should not be using truncated regression just because you have skewed or bounded data . it is specifically for situations when values below a threshold ( eg negative values ) are possible , but would not be observed for some reason . is that the situation you have ?"
5351,"question is not clear . what do you mean by "" standard error for a vector "" ?"
5343,"what do you mean by "" n some cases i can observe . . . "" . does that man that neither y1 nor y2 can be observed all the time ( i . e . for all the x ) ?"
5347,are your p_i fixed throughout the modeling exercise or can they change from one calculation to the next ?
5392,"don't you mean $ var ( w_1 a w_2 b ) $ , since you weigh them ?"
5461,what do you want to know ?
5503,i don't really see the point made by this quote . is there a computational philosophy ?
5571,"you want to compare the models' * fit * using a statistical test , right ?"
5572,is treatment randomly allocated ?
490,is it a question or a pool ?
5517,( 1 ) i'm surprised that pvals . fnc still works at all ; i thought mcmcsamp ( which pvals . fnc relies on ) had been non-functional in lme4 for quite a while . what version of lme4 are you using ?
5650,"what is a "" loess / arima model "" ?"
5691,do you need to reproduce any of the marginals in the table ?
5696,it looks like situation where functional data analysis methods can be applied . did you consider them ?
5750,"presumably one can use the permutation procedure to generate a null distribution for significance thresholds for the largest correlation , a different threshold for the second largest correlation , and so on . hopefully this would only take a few hours in python or r . ( ha ! famous last words . ) but surely someone must already have done this and saved the code somewhere ?"
5765,it would be useful to know more about the scale these values come from - is the data continuous or categorical ?
5791,what assumptions are you making about the distributions ?
5814,i'm having trouble following the question . it might help a little if each opening parenthesis was matched by a corresponding closing parenthesis . also are the vehicle flow rates for each lane averages ?
5836,so . . . why don't you write it as in the top graph ?
5844,what kind of connection you are looking for ?
5854,what exactly are you displaying ?
5853,"welcome to crossvalidated , nealwalters . you may find that a common response to asking a statistician "" how do i do this "" is "" why do you want to do that ?"
5870,the quality of an approximation tends to depend on the values of the parameters . can you stipulate anything about the values of $ n $ or $ beta $ that you are interested in ?
5874,how much freedom do you have to change question ordering ?
5967,why does heteroscedasticity in the * independent * variables bother you ?
5982,could you add a bit more context please ?
6044,"to keep the responses relevant to the question you have in mind , could you say a little more about what these data are , what you mean by "" difference in percentage , "" and why that's important to you ?"
6050,"i think it is hard to answer this question in a general context . if possible , can you pls provide some insights about what is your data ?"
6066,this is a problem with stepwise regression and categorical variables . see this ( very ) recent question for more information : [ how should i handle categorical variables with multiple levels when doing backward elimination ?
6067,it is hard to imagine how this could be . perhaps you are cutting the predicted probability at 0 . 5 ?
6097,have you considered vector-valued autoregressive processes as a model ?
6154,"i am not an expert on sas or sem , but if you get t-values , can't you calculate p-values yourself ?"
6226,"why are you doing "" data preparation "" in openoffice ?"
6151,please clarify your question - it is not clear that you need a 'treatment' to answer your question . can you provide a list or some examples of the questions in the survey ?
6243,"thanks , mbq . seems to me the overhead would simply cancel out when taking the difference between two overhead-corrected means . or am i missing something ?"
6265,"this does not directly pertain to the violation of independence , but have you considered multiple imputation to deal with your missing values ?"
6279,why exactly are you testing for non-linearity ?
6302,why do you need to report cdf ( empirical or estimated ) when you are happy with the pdf ?
6306,"this is an interesting subject . i am curious why you ( mckay et al 1999 ) would choose 'war and peace' as a control rather than , for example , random strings of letters ( perhaps weighted by their observed frequencies ) . in other words , is it sufficient for the text to be sufficiently long , or does it have to be sufficiently long and comprehensible ( or sufficiently long and of some literary value ) ?"
6318,could be a more focused question ?
6364,i am having the same problem . i did try sqrtm ( x ) function but it did work just for few iterations . did you find the solution ?
5559,could you provide additional context about this ?
6421,"it's subjective , sure , but isn't it still okay for cw ?"
6410,can we assume that all machines are identical ?
6455,"user2875 , i've deleted my answer . fact is that for large $ h $ the test is not reliable . so the answer really depends for which $ h $ , $ p 0 . 05 $ . furthermore what is exact value of $ p $ ?"
6478,how does this question differ from url ?
6483,what is your data ?
6484,lcl23 listwise deletion is usually for subjects with missing data on any one of the covariates . could you indicate how you define an outlier in your particular case ?
6513,you try very general models for specific problem . did you any research before trying these models ?
6538,what field of mathematics you received your doctorate ?
6535,what software are you using ?
6601,"( i don't know enough to put this as an answer , hence adding a comment . ) i always thought it was strange that pi crops up in statistical equations . i mean - what's pi got to do with statistics ?"
6642,"hm , what is the usual practice for questions duplicated in two se sites ?"
6658,"just to be clear , you've got 4 tables , each one if of 2 by 2 , with number of "" fatality "" for each population ( from the people who got and didn't get treatment ) . is that correct , or are you having it in any way different then what i described ?"
6754,"could you clarify what you mean by a "" common entity "" . it's not clear to me because it seems you are describing two features ( for me , a feature or attribute = a variable ) with different units ( meters and seconds ) rather than a single one ?"
6770,so . . . you're saying you don't see any consistent relationship between the amounts at the various lengths ?
6791,why do you say likert scale and then categorial / ordinal ?
6855,"this is quite strange since those are implementation of the same algorithm . . . are you sure you are not comparing oob error estimation with error on train ( this one is usually near 0 for rf , and this does not mean overfitting ) ?"
6876,mpiktas are you saying that knowledge of asymptotics will assure that one is excellent at visualizing data ?
6891,"to be sure , your design is really 3x2x3 ( 3 factors , all with 3 levels except the second one ) , with three replicates , that is 54 values for each statistical unit ?"
6896,"what is your motive behind "" determining the closeness "" of these data sets ?"
6927,br whats the bottle neck here ?
6939,"tom , how did you uncover the obvious pattern ?"
6946,"queops , are the three consecutive pages assumed to be predetermined or is it the probability of finding errors on any set of three consecutive pages out of a total of $ n $ ?"
6963,"ukasz can you say anything more about the parameters $ n $ , $ alpha_i $ , and $ beta_i $ ?"
6795,"belmont , what is $ u ( alpha ) $ ?"
7020,"` if i have say a 6-sided die , i can imagine my prior knowledge of side "" 1 "" being equivalent to 10 ones in 50 trials and my prior knowledge of side "" 2 "" as being equivalent to 15 twos in 100 trials . ` is there a special reason why you do not want to unify your ' equivalent sample sizes' for "" $ 1 $ "" and "" $ 2 $ "" ( namely $ 50 $ and $ 100 $ ) by using their least common multiple ?"
6913,why would having a 5 star rating be fairer ?
7045,"mariana , i don't understand . both models you listed are linear in the coefficients . are you looking for something that automatically does both feature extraction * and * model selection ?"
7059,"david how do you compute the "" amount "" ?"
7029,"out of curiousity , have you got a citation for the source where you saw this originally ?"
7146,"judging from the graph , the problem is not the lag . what you have plotted is roughly goodness of fit . so it seems that weibull distribution is not apropriate for your data . i see that there is a bunch up near zero , do you have zero values in your data ?"
7173,could you clarify how you sample from the four industry strata ?
7128,what is your research question ?
7218,i don't think your graphs are right . i've just drawn some graphs of the distribution derived from the fisher formula which show it is correctly centered . in fact it's pretty obvious from the formula that it must be asympototically unbiased for $ n rightarrow infty $ . could you post the mathematical core of your code ?
7297,"could you please define your initialisms , or avoid using initialisms ?"
7286,how come you don't have 100 bonus from your so record ?
7344,have you tried plot on the ` lm ` or ` glm ` object ?
7366,can't you collect the mean ?
7376,"what do you mean by "" valid statistical calculation "" you should say valid statistical ( estimation ) calculation of something . here the something is very important . correlation is a valid calculation of the linear relation between two set of data . i don't see why you need stationarity , did you mean auto-correlation ?"
7175,are you looking for further clarifications or are you unhappy with mariana's response ?
7422,does the identical hour on different days count as the same hour or not ?
7259,"what you're asking for shouldn't be that difficult , but it's difficult to wrap my head around what you're after without some sample data . can you update your question with some sample data ?"
7476,what percent of your studies lack an estimate of se ?
7511,"what is a "" measurement "" ?"
7523,could you provide more information on the context and what you would do with the weighted composite ?
7084,"could you elaborate on "" using a mathematical model evaluates functional meaning of the measured data "" ?"
7564,why wouldn't you just treat the 5 categories as 5 separate features ?
7308,"jyotirmoy , what if the minimum happens at the boundary of your parameter space ?"
7594,this sounds an awful lot like a homework question to me . could you provide some context ?
7631,"do you by any chance mean that x2 is distributed as u [ 0 , x1 ] ?"
7644,"also , what do you mean by "" solutions for just the intercept and slope are fine "" . those are your only two parameters ! or were you hoping to try to back out the "" true "" regressor as well ?"
7668,"is there any additional info regarding your question that i could help you address , but haven't already ?"
7607,i lost my question acceptation : ) you could have written another question don't you ?
7701,is your binary categorical variable _o_ your dependent variable ?
7699,does your regression has an intercept ?
7542,what would you like to approximate ?
7721,"andy , can you clarify your question a little bit ?"
7754,"could you clarify what you mean by "" increased by 3 ?"
7772,andy . may be a silly question : how did you control the levels of other variables when you were collecting $ y $ . each row in $ y_i $ matrix contains entries $ y_ { ij } $ which denote the observed variable corresponding to $ j ^ { th } $ latent variable . one more request : can you please modify your question instead of comments ?
7775,"i suggest trying the other models and see whether the code works or not . r is usually nice , so anova should return similar things for different models . the problem is with your initial formula . does it hold for other models ?"
7786,"user3136 what kind of variables are you considering , and what kind of relationship are you interested in ?"
7805,"what do you mean by "" expectation between two variables "" ?"
7788,some points to clarify : 1 . is your dependent variable the same for both countries ?
7869,"imran , i edited your question , to make this question more apropriate for this site . my question is what is your optimisation criteria ?"
7891,can you please cite these references ?
7915,how many datapoints do you have ?
7919,"the zero is an observable value , that is your predictor can take such a value ?"
7868,"i'm not understanding something : if a prefix of the numbers "" points to "" a geographic region , isn't that your solution ?"
7925,"what do you mean by two $ ( t , m , s ) $ nets being uncorrelated ?"
7912,"the mahalanobis distance makes no sense when the distributions differ . ( it's like saying "" peter lives on a sphere and paul lives on a euclidean plane ; how do we compute the distance between them ?"
7969,"all you need to do is divide each gamma variate by their sum . how , then , does underflow occur ?"
8010,"i have updated your question with your "" answer "" ; was this really an answer or just a comment ?"
8036,did you check url ?
8044,care to say why is that book not good enough ?
8072,"just to clarify , margin-of-error of what ?"
8103,"i * think * i know what you mean , david , but i'm not quite sure because "" support "" means several things in statistics . among them that might be relevant here are ( a ) values that a random variable can attain and ( b ) the physical extent or amount of any sample of a substance ( such as a volume of soil or water ) represented by a measurement . however , neither seem exactly right for this question . could you perhaps indicate what you mean by "" common support "" ?"
8083,"maybe you could ask some more specific question , even to get an example of bootstrap use ?"
8127,"t-tests , significance , sample distributions , and estimates of proportions deal with * conclusions * you draw from the data . finding "" representative cases "" is a matter of * selecting * cases from the dataset . the two activities are completely different . what , then , do you really want to do ?"
8012,are you trying to compute $ var ( bar tau ) $ ?
8135,"could you clarify what you mean by "" the overall mean of all my independent variables should be 0 "" and how you know this ?"
8130,"could you clarify what you means by "" margin of error 5 % "" ?"
8143,"hint : by "" randomly "" you probably mean that all such sequences have the same probability . so : how many possible sequences of four bits are there ?"
8119,could you provide a reproducible example ?
8184,wouldn't the likelihood ratio test give you the most powerful test by the neyman-pearson lemma ?
8187,"before you get into the statistical side of things , you need to wrestle with the design side--and validity . how do we know these states didn't have radically different rates of the disease before either of the two treatments were begun ?"
8169,"i am little bit confused . my first guess was that you are trying to predict the probability of occurrence for a value of n ( . , . ) , but your heading says "" classifier "" . what is the label / target / response variable you are trying to predict ?"
8156,"i don't understand what's on your x-axis . if it's one of a , c , t or g then as that's categorical it's a bar-chart not a histogram , but then i can't see how you can have "" plateau-like regions "" . neither do i understand what you mean by "" linear dropoffs "" . could you link to an example histogram ?"
8232,"can't what does it mean to "" understand "" a distribution ?"
8246,is the performance measured with the training dataset or with a held-out dataset ?
8251,can you pls elaborate on what kind of data are you / they looking at ?
8240,do you need the expected distance ?
8278,"do you have , like in your previous question , the information on mortality before start of treatment ?"
8150,you need to give more information . how much data have you collected ?
8358,drwho is this intended as a replacement for your previous question at url ?
8351,what is ` y ` in your second code snippet ?
8377,"the two together don't tell you anything more than the second one would alone ! the main effects are uninteresting and misleading when there is interaction present . the second model tells you all you need to know . describe your variables more ( what are they , what are their ranges like , are they both numeric or are they factors ?"
8392,"although there are statistical aspects to this q there are also sysadmin aspects , suggesting the folks over at serverfault . se might be able to contribute . is this perhaps a rare case where cross-posting a q on more than one se site would be acceptable ?"
8401,typo in the last paragraph ?
8418,"what do you mean by "" isolate speed bins "" ?"
8462,'periodic chart' ?
8466,please check your statements . in the first line what is $ v $ ?
7946,"bb01 as mpiktas mentioned , we can't help you unless you'd give some details about the data -- are those continuous or discrete data ?"
8446,why do you need a * formula ?
8490,"how many tests do you have in total , what is the measurement ( grading ) technique , and are you certain that the 'same test , different subject' option is viable given the nature of your test data ?"
8545,the chow test assumes that there are no gaussian violations in either the sub-models or in the composite model . have you verified the gaussian assumptions ?
8380,"suppose the exact variable values are $ x_i $ , the exact output value is $ y $ , observed variable values are $ hat { x } _i $ and the observed output value is $ hat { y } $ . is it true that in your model $ y = sum_i w_i x_i $ ( i . e . the exact output is a linear function of the exact variable values ) ?"
8586,are you comparing * variances * ( as asserted in the first line ) or * means * ( as indicated in the third line ) ?
8405,"could you show a reproducible example of what you can do , and a mock-up of what would you like to achieve ?"
8581,"i'm a psychology phd student as well , and i made the choice to take a significant amount of math in my undergraduate years because there were so many psychology phds who have no idea how a pca ( for example ) was computed . the very first thing you need to do is work your way through any decent linear algebra textbook . what's a decent linear algebra textbook ?"
8611,could you clarify what precisely are those measurements ( time to perform a given task ?
8669,"why not regress 0 on $ 1 , x_1 , ldots , x_ { 11 } , y_1 , ldots , y_4 $ ?"
8375,"a couple questions : first , are you wedded to using a discrete time model ?"
8710,"gps units * require * time information to work , accurate to the nanosecond , and are capable of reporting it . could you not just collect the timestamps from the gps then ?"
8729,celenius why is collinearity a problem ?
8744,is the cluster size also specified ?
8747,"there might be a bit of text analytics involved . are "" title "" and "" descriptions "" true independent variables , or do they just supply information about image ?"
8755,"perhaps , having found what you call "" the mean $ y $ for several $ x $ "" , you are now being asked for the confidence intervals around those estimated values of $ y $ . might that be possible ?"
8742,"i think your notation may be a bit off , or your probabilities are inconsistent . for instance , there is only one link for asia ( a ) , and that leads to tuberculosis ( t ) . so this means that $ p ( a ) geq p ( t ) $ . but you have assigned $ p ( a ) = 0 . 01 0 . 0104 = p ( t ) $ . so this is inconsistent . i think this is actually $ p ( t a ) = 0 . 0104 $ . but then the rest is unclear , are these conditional probabilities ?"
8807,i found really interesting the question . is there a way i can mark a question to follow it ?
8846,can you tell us what your three $ n $ s are ?
8859,using the log-odds is the same as using the probability . its just on a different scale . so i'd say use log-odds if that suits you . sounds like you need a decision rule - gets classed as spam if $ log ( p ( spam d ) ) -log ( p ( non-spam d ) ) c $ . you choose $ c $ based on the consequences of false classification . which is worse to get wrong ?
8884,could you give more details for your second question ?
8885,in microeconomics you can show that if ordering satisfies certain conditions there exists a real convex function $ p $ which for $ u le v $ gives $ p ( u ) le p ( v ) $ . using this result then the question of ordering the unknown set given the known set is the question of fitting appropriate function for the known set . did you pursue this line of attack ?
8899,"if $ p ( b ) = 1 $ then $ p ( b a ) $ should be $ 1 $ also ( except , maybe if $ p ( a ) = 0 $ ) ?"
8800,"i have some questions ( just to be sure ) . 1 . you have 5000 records , 13 features ( 12 predictors 1 response ) and the response variable is binary with values "" flower "" ( 15 times ) and "" not flower "" ( 5000-15 times ) = is this correct ?"
8972,why wouldn't you resample participants with replacement and then resample their data as well ?
8774,what is $ x $ precisely ?
9022,you might like to review replies to [ what is the most surprising characterization of the gaussian ( normal ) distribution ?
9033,could you please check if the formula is ok ?
9043,"there are a lot of terms which could be what you are after , but without more details or at least more context ( how is the estimate calculated ?"
9129,what is your ultimate goal for the clustering ?
9131,"tal sorry , but it's not really clear to me what you actually mean by "" predict the lower and upper predictions of y "" . does it have something to do with prediction or tolerance bands ?"
9132,can you edit and add more context ?
9148,what about open access scientific publications ?
9171,could you tell us the difference between ( 1 ) and ( 2 ) ?
9201,"you don't tell us what your data is , but i'd be very suspicious of any procedure that adds random noise to data and then runs a statistical test on it . in addition , are you sure your code does what you think it does ?"
9220,"nick , just to clarify , both $ a $ and $ b $ are random vectors with values in $ mathbb { r } ^ 2 $ ?"
9275,how does one even apply the $ chi ^ 2 $ test to smoothed data ?
9276,just out of curiosity : is anything in this model conditional on whether the accused is actually * guilty * ?
9237,do the nominator and denominator and denominator add up to 100 % in your formula ?
9295,"also , what do you mean by "" ensure "" ?"
3874,"before i update the answer , is treatment a repeated factor ?"
9217,"is your question , simply , how many people are employed as an interaction designer in the united kingdom ?"
9365,do you have some general interests that you'd like to list ?
9378,gurzo : what ?
9447,"i'm missing something . if we are predicting "" the average number of days in a year "" -- why would this necessarily be seasonal ?"
9392,yo2go what would / should your confidence score reflect ?
9475,"in your application , what is a * trend * ?"
8968,"how do you do a regression when m is a single "" observation "" and n is a single observation ?"
9501,"rosh , by $ lognormal $ you mean probability density of log-normal distribution ?"
9512,simply reestimating ` arima_s ` with updated ` series ` is not ok ?
8007,is plotting it a requirement ?
9556,( 1 ) what do you mean by affecting a gene ?
9656,"also , your call ` graph . laplacian ( g , normalized = true ) ` returns the normalized graph laplacian . in other words , if $ d $ is a diagonal matrix of the degrees and $ a $ is the adjacency matrix , then ` graph . laplacian ( g , normalized = true ) ` returns $ i - d ^ { -1 / 2 } a d ^ { -1 / 2 } $ . you appear to be multiplying on the right and left by $ d ^ { -1 / 2 } $ again , which would yield $ d ^ { -1 } - d ^ { -1 } a d ^ { -1 } $ . is that * really * what you mean to calculate ?"
9659,it sounds like the only reason you use beta is because its conjugate ?
9674,"user4212 , what is your system locale ?"
9699,"a "" long installation procedure "" ?"
9739,did you find any good r package to cluster spatial data ?
9774,do you mean profit or revenue ?
9775,"if you have a function which checks for the pattern in the row , simple ` apply ` will work . are you looking for something more complicated ?"
9797,"it appears there is a strong dependence in these data : namely , is it the case that if obs = 1 for subject $ i $ on day $ t $ then necessarily obs = 1 for subject $ i $ on day $ s $ whenever $ s ge t $ ?"
9327,"j . winchester i'm afraid your question still appears to focus on aic , and responses to the related question on aic apply as well here . however , i feel you are also wondering whether your ` lmer ` syntax allows you to test the hypothesis formulated in your first paragraph . if this is the case , you can simply * edit the title and your question * and focus on this issue , rather than aic . you might also consider adding the output of ` summary ( lmera . 1 ) ` . finally , the outcome you consider is a ratio of counts ( % ` sp_a ` ) : is it usual in your field to treat this as a continuous response variable ?"
9813,"durrett , according to your examples you are averaging $ z_ { i_ { k-1 } 1 } , dots , z_ { i_k } $ . may be you could add some story behind the formal setup ?"
9841,do you mean that essentially you have two data points : the day of pupation in 2005 and the day of pupation in 2006 ?
9852,are the models nested ( i . e . are the models the same except for the one variable in the four variable model ?
9859,what is the assymptotic bias ?
9895,the notation is strange : the only independent variable is $ n_o $ and you are trying to model $ n_e $ in terms of itself ! what really are you trying to do here ?
9911,"clarifying question : if rows in your matrix are "" events "" and columns are "" trials , "" then what is an entry in the matrix ?"
9947,"if i understand you correctly , you want to match each ( estimated ) $ k_i $ with only one ( predefined ) $ c_j $ ?"
9951,"well i do not understand the question , do you want to simplify the informal description of stationarity concept you quoted here ?"
9965,do you mean events have $ n $ outcomes or $ n $ * possible * outcomes ?
9988,""" cluster analysis "" means ?"
10017,"ricardh , curse upon all economists for not checking whether the term they want to use is already used in statistics . cluster in this context means group and is totally unrelated to cluster analysis , this is why rseek gave you unrelated results . hence i removed the clustering tag . for panel data analysis check out [ package plm ] ( url ) . it has a nice vignette , so you may find what you want . as for your question it is not clear what you want . within group standard errors ?"
9835,where did f and alpha come from ?
10058,the plot suggests that the effect of wet / dry is different for the two species . how about a ` species : type2 ` interaction term ?
10010,"do your spectra have their peaks at the same locations , but varying powers ?"
10065,what do you mean by * inverted list * ?
10049,"i can obtain a misclassification rate of just 10 % with these data , sight unseen , by always predicting 0 ! surely * any * method you try will improve on this , right ?"
10117,"you seem to want to do forecasting using time-series or longitudinal data ; presumably modelling , not data mining . you have data for each student at multiple time points . are these data collected at regular time intervals ?"
1681,deviation from the mean of what ?
10145,"a few questions : ( 1 ) "" level of disclosure "" and "" index "" imply a variable with more than two levels ; have you considered using an ordinal scale as the dependent variable ?"
10150,this is a very general question that no one can answer without more information . it really depends on the nature of your data . do you have a reason to believe that past behavior can predict future behavior ?
9814,could you describeyour data and / or the model you want to fit in a little more detail ?
10182,"please , take the time to look at the [ reliability ] ( url ) or [ inter-rater ] ( url ) tags . the icc is based on an anova table , but the idea is merely to analysis components of variance rather than produce a single test statistic with know distributional properties , like the f-test . what application do you have in mind ?"
10204,"it seems like some clustering , but can you elaborate a bit more ?"
10211,behacad - well-explained problem . you are estimating a heck of a lot of parameters using very sparse data . so inference is going to be awfully shaky . but i'd like to step back and ask - are you using these 42 to infer relationships among a larger population ?
10242,do you picked the exponential distribution because its pdf decreases smoothly from 0 to infinity ?
604,i am not sure why you feel that in regression you will get r2 = 1 if you try to predict the predicted variable . can you clarify ?
10293,"so you have 4 binary variables : cat1 , cat2 , cat3 , and cat4 . what do you mean when you say that you want to optimize cat4 as a function of cat1 , cat2 , cat3 ?"
10271,"cryptron , do you have any data on what is a false positive ?"
10308,rockscience i've added two tags . could you confirm they're correct ?
10295,why would views not contribute to interesting-ness ?
10347,lars what do you want to modify : the heatmap or the dendrogram ?
10346,"ayush could you edit your question clarifying what you mean by "" certain values "" and "" event rate "" ?"
10369,"$ x_i $ is also assumed independent of $ y_i $ , yes ?"
10385,how about ` stepaic ( ) ` in package mass ?
10388,what about changing of the starting values ?
10396,"ayush when you say "" dependents "" , do you mean like "" this person has five dependent children "" . if so , what happens if someone has 0 or 5 dependents ?"
10359,"emre , by level of dependence you mean what ?"
10432,colin have you tried any clustering analysis by now ?
10441,what does that last bracket mean ?
10459,"nice idea for a collection ! mods : beside cw maybe renaming to "" movies every statistician should have seen "" or something like that ?"
10540,learner : is the silhouette function inbuilt in some library ?
10607,"i'll second mpiktas's comment , and i would recommend you take some time to think about your question ( s ) and how to improve them ( i'm not speaking about english typos , but about their clarity ) . i also noticed that you only accepted few answers so far . any reason why ?"
10608,do you have much of a budget to explore this problem ?
10592,do the columns have a natural ordering to them ?
10657,you may want to be a bit more specific about your data and what you want to do with it ?
10711,"how would you define "" well-roundedness "" in the se context , first of all ?"
10628,"this question is loaded with typographical errors . ( for example : the first two equations are identical but shouldn't be ; the expressions for the probabilities of the vectors $ x $ and $ y $ are incorrect ; the pdfs are not normalized to unity ; the indicator in the integral makes no sense . ) since you're being quite technical in expression , it would behoove you to check over the text and fix the mistakes so that you are not misunderstood . perhaps , though , it would be easier and clearer to express the problem in plainer english and provide some motivation ?"
10768,"yes , that's a pretty well-known result and is easy to generalize . ( how ?"
10767,is your problem to model the pct % of hours contributed by each position ?
10774,"plots 37 and 39 are both at x = 18 , y = 10 . typo ?"
10795,did you read the entire wikipedia page ?
10884,"jeromy , by beta weights you mean the linear regression coefficients ?"
10897,"x i also wonder about your "" negative exponential "" assertion . fixing a segment of length $ x $ in a unit rod ( without any loss of generality ) , the chance that any single breakpoint misses it is $ 1-x $ . because the breakpoints are independent , the chance that all of them miss it is $ ( 1-x ) ^ n $ . that's not a negative exponential : it's a polynomial in $ x $ . perhaps you're thinking of an asymptotic characterization for small $ x $ and large $ n $ ( and bounded $ nx $ ) ?"
10943,"im not sure what the r program is doing but we have $ $ var ( sum_ie [ x_i ] ) = a ^ tvar ( e [ x ] ) a $ $ where $ a $ is a column vector of ones and $ var ( e [ x ] ) $ is the covariance matrix for $ e [ x ] = ( e [ x_1 ] , dots , e [ x_n ] ) ^ t $ . does this help ?"
11000,"what do you mean by "" i can calculate each row individually "" ?"
10986,"could you explain what evidence do you have that the "" adjusted regression "" is not multiple regression ?"
11008,do you mean the * * standard error * * for each proportion ?
10975,what are the fitted values from ?
11069,"ehab , there are several problems with your question , which should be addressed . 1 . why do you mention gls , ` arima ` uses maximum likelihood . 2 . what is your model ?"
11072,what your s regression model is designed for ?
11091,"` expit ` = "" inverse logit function "" from the [ msm ] ( url ) package ?"
11088,crucified any statistical package in mind ?
11113,user4701 do you still get the significant results for ` sex ` when you do the correct separate analyses using ` aov ( ) ` within ` exp1 ` and ` exp2 ` ?
11102,"what do you mean by the "" reconstructed matrix "" ?"
11101,"how many factors did you extracted and what kind of rotation did you use , if any ?"
11079,"maybe you could be a bit more explicit about your design : do you have two fully-crossed within-subject ivs , ` stimulus ` and ` condition ` , meaning that each observer had all stimuli in all conditions ?"
11209,"did you implement the test in matlab yourself , or are you checking against code from the statistics toolbox ?"
11208,dober dan ! do you know if the official law is designed for roulette or for some other gambling devices ?
11242,i've tried adding clarifying wrap-up at the end . does it help you ?
11252,"it seems you are asking two things , am i right ?"
11256,what is the purpose of the regression ?
11270,"what kind of variable is "" weblog publishing software "" , "" weblog comment system "" ?"
6723,"you have 6 independent variables , is there a particular reason you need only a subset of them in your model ?"
11336,"what "" link function "" did you use to fit the model ?"
11327,"i wouldn't say it's "" not sensible "" to do what you have done . however , because you already know the factors which determine gpa - namely the grades in various courses , it may make more sense to model those factors rather than gpa . perhaps a "" better question "" might be , for example : * what factors are most strongly associated with high math scores ?"
11384,i am not sure if i understand your question . why would this be any different for a binary variable ?
11389,what kind of students are they ?
11372,i don't speak ( german ?
11413,f1r3br4and it may help if you add some details about exactly what is your data ?
6071,are $ e_i $ and $ delta_i $ ( assumed to be ) independent ?
11515,"i've added the latex , but your question does not make sense . if $ a $ is integer , how come it is also a random variable distributed with binomial distribution ?"
11557,can you think of a counterexample ?
11565,can you clarify just a touch ?
11568,how many values are in your sample and what level of significance do you need ?
11590,you may want to take a look at these related questions : [ logistic regression : which pseudo r-squared measure is the one to report ( cox & snell or nagelkerke ) ?
11595,what is your dependent variable ?
11607,what are the messages ?
11615,which variables were measured at two time points ?
11611,presumably the ` glm ` routine would bonk if it could not handle zeros . have you tried it ?
11620,why not just remove the 999999999 values ?
11650,why do you need to reduce dimensionality ?
9731,"if you don't find an answer in the existing threads on multiple testing for correlations , could you please explain how this question is different ?"
11645,thislstheld what code are you using for fitting your logistic regression ?
11765,doesn't [ the section on difference functions ] ( url ) in the wikipedia article directly answer this question ?
11832,what do you know about how the variance changes when you scale a random variable ( or vector ! ) ?
11835,can you tell us which two texts gave you these sets of instructions ?
11878,"if i'm understanding you correctly , these parameters "" converge "" on one fixed value in each chain ( after some iterations it doesn't change at all ) , but that value is different for every chain you run ?"
11807,"when you say "" cart-like "" do you specifically want decision trees or any sort of predictive model ?"
11909,have you fit the model both with and without the infrequent classes ?
11919,"i think you have a typo related to the min value of x . . . it should be -62 , right ?"
11929,how you determine best lags ?
11935,""" ( . . . ) 16 rows and 6 columns "" : are you saying you are using an fa model with 16 subjects and 6 items ?"
11968,"if some of the terms in your model cannot be estimated , how _would_ you compare it with models that can be estimated ?"
11975,"what do you mean exactly by "" where every out of diagonal entry of r is the same number in ( 0 , 1 ) "" ?"
11977,exponential in what quantity ?
12020,"the table shows multiple rows of data . are the rows from different units of analysis ( e . g . , people ) ?"
12050,maybe some plots instead of raw data ?
12080,is free a requirement ?
12087,"are the 20 answers replicates for the same item , or are there 20 different items with one response for each ?"
12039,"when you have only one sample , how do you obtain two means ?"
11892,"with just "" two time points "" you can describe the entire dataset with a 3 by 3 table ( giving the counts of the nine possible transitions ) , which is hardly a challenge to display or visualize ! how does your situation differ from this ?"
12134,"are you saying you cannot draw a sample that includes every element in the population , or that you cannot draw a sample such that every element in the population has equal probability of making it into the sample ?"
12152,how about the tensor-product basis of your one-dimensional polynomials ?
12161,"it will depend on how you weigh the different variables , but you can obviously combine any number of marginal measures as you see fit . i'm not sure , though , that it makes much sense from a prediction point of view to combine a 0-1-loss with a sum of squares . why do you want a single measure of predictive accuracy , could you provide an example ?"
12165,"in this regard , what would 'statistically significant' mean ?"
12182,"are "" top floor "" and "" corner unit "" correlated with each other ?"
12193,"* * questions * * : what do you mean by "" parameter "" ?"
12290,"such large statistics , with 4 df and non-significant p-values , look rather strange . how were they obtained ?"
12309,"thanks for accepting my answer , but after the remark of cardinal i do not think that it is worth it ( although it might be a contribution to consider ) . i hoped you would clarify the point whether you work in a "" statistical "" environment with only small amounts of data ( instead of mass amount plus skewed class distribution ( which i assumed ) ) . may i suggest to edit your question / extend it to hopefully get more attention ?"
12301,were the hens selected at random for slaughter ?
12314,the question is too vague to answer . what kind of inference is desired ?
12319,how are you obtaining the predictions from the models ?
12360,glmnet has been undergoing quite a bit of change recently and has had some problems with numerics in the past . is it possibly due to this ?
12381,do you mean ` rfeiter ( ) ` ( which expects train x and y and test x and y ) instead of ` rfe ( ) ` ?
12397,would you include some example data ?
12398,have you tried the commands ` summary ( aov ( dependendvar ~ independendvar ) ) ) ` or ` summary ( lm ( dependendvar ~ independendvar ) ) ` ?
12410,"santiagozky i've made some edits to your question to make it clear that you're trying to predict values from a linear regression model . however , you'll need to clarify some issues : ( a ) are you trying to predict new ( unobserved ) values or get the fitted values for your actual observations ?"
12415,"you may be interested in reading this related question , [ inter-rater reliability for ordinal or interval data ] ( url ) . about your point 2 , are you speaking of * raw agreement * or * corrected agreement * ?"
12498,what is an outlier ?
12492,what do you mean ?
12508,"i think we may need more information , in particular , what is this metric to be used for ?"
12465,are you aware that there is already a function in r doing that ?
12547,what is the question ?
12510,this question is not quite clear . how do you sample every 100th person * exactly * without implicitly counting * all * of them ?
12529,"( 1 ) what is "" emd "" ?"
12562,do you mean the mechanics or conceptually ?
12582,svaha : do you know * when * the level-changes occur ?
12588,"just curious , could you elaborate on the field ( 2000 ) reference ?"
12515,i assume what you intended was the expected log ratio of the * estimates * of the variances ?
12604,what software are you using ?
12647,does the problem imply the assumption that the population ( sample ) sizes are very different $ n_ { male } n_ { female } $ ?
12642,are you asking for a derivation of these results or are you asking for a more intuitive explanation ?
12654,"by ` in ( -1 , 1 ) the probability of a single event is 0 ` do you mean the probability of getting exactly a given value is infinitesimally small or that it is impossible to get any value -1 and 1 ( i . e . the probability density function is zero ) ?"
12700,"i did not say it is a duplicate : ) . _ "" i want to know how to calculate without any approach . "" _ what you do mean ?"
12703,what is the point of the threshold ?
12709,are you sure you're coding correctly the factor variable ?
12140,you mean an explanation that goes beyond what is described in [ hothorn's paper ] ( url ) ?
12712,how's that ?
12704,"you have , in a roundabout way , created histograms of 500000 observations with 500 evenly spaced bins , and you want to know if there is a functional form you can use to summarize the results ?"
12753,"( 1 ) to chl , nice answer regarding ` scope ` option ( and there is enough information on this pre-selection in ` ?"
12796,alefsin why don't you make an answer ; ) ?
12789,these constant multiples are a curious effect ; have you by any chance managed to clarify since 2011 why it happens ?
12612,"what are the $ x_ { i , j } $ ?"
12678,"daniel hint : the situation determines four cases altogether : truth yellow , etc . can you work out the chances where blue is involved ?"
12816,"your question lacks a host of critical details . the situation you just programmed gives no context as to what you are trying to accomplish , nor to what "" previous non missing value "" refers to . is your data a time series ?"
12839,uwe ligges on r-help has already given the [ 'answer' ] ( url ) : you cannot have standard deviations of 0 . are these missing values ?
12826,standard deviation of what ?
12869,"can you provide more information on your design : what are 'concepts' , how many subjects , context , etc . also , shall we assume that this is standard 'metric'-scaling ( equivalent to pca for the first two pcs ) , or did you rely on non-metric multidimensional scaling ?"
12900,does this answer your question ?
12908,"do you mean like the "" graphical moments "" illustrated [ here ] ( url ) ?"
12911,"it might help if you knew what kind of distribution "" gfp intensity "" ( [ green fluorescent protein ] ( url ) ?"
12907,"are the categories mutually exclusive , that is there is no hierarchy linking them together ?"
12897,i cannot figure out what you are trying to detect : the amplitude ?
12913,"to be sure to understand , the three datasets refer to different cross-classifications of two attributes ?"
12938,"ehrm . at the end of the link you provide , there's the text : "" to estimate google 's population , allen tracks surnames that appear on the site . here's how he describes his methodology "" , after which it is explained how this is possible . what more do you need ?"
12947,"you don't say explicitly that eligible members ( that is , those that didn't win in the previous week ) all have the same chance of winning the raffle . is this the case , or is there a mechanism ( like buying different numbers of raffle tickets ) by which members differentiate their chances of winning ?"
12955,first graph your data to see if there are any obvious patterns . do you have any theory suggesting the data might be non-random ?
13009,why would a poisson process ( which is defined on $ mathbb { z } ^ $ and nondecreasing in time ) ever make sense for your problem ?
12998,there's nothing here but a table . what's the question ?
13059,is each component of each sequence uncorrelated with each other ?
12341,do you have a justification for using bic ?
13172,can you assume a correlation structure on your data ?
13186,"it is not clear to me how your data points can "" contain "" the distributions . could you give an example ?"
13235,"is there a reason you can't vary dosage along your scale continuously , and treat dosage as a continuous variable ?"
13221,did you consider aggregating the data to normalize the times ?
13259,may i ask where did you get this problem ?
13132,what kind of mp correction are you referring too ?
13275,"daniel , a probability density can exceed 1 at a given point ; a probability mass function cannot . are you looking at a posterior density or a posterior mass function ?"
13296,"i think we need a bit more information . what precisely is $ p_i $ : is it the probability of any given word being $ i $ , or the probability of $ i $ occurring in a document ?"
13342,what exactly is your goal with this discretization ?
13347,"if you can easily integrate the pdf , to acquire the cdf , can you easily invert the cdf , $ f ^ { -1 } $ ?"
13352,not sure i see what bayesian issues there are in this question . maybe remove this ?
13371,"if model a fits dataset 1 and model b fits dataset 2 , there's nothing at all to compare : the models and the data are totally different . so what exactly are you trying to accomplish ?"
13445,can you provide more information ?
13499,url didn't address your question ?
13515,can you give an idea of the size of the dataset ( i . e . t = ?
13532,is your model log-log regression ( interaction as the restriction as ok with them ) ?
13555,"the purpose of the plots will , to a large extent , determine which solutions are appropriate . what , then , are you trying to show with them ?"
13584,your added images are pretty good evidence of association between the two trends ( especially the detrended image ) . what else do you want ( an actual regression equation ?
13630,"have you checked ( for ideas ) in the "" obvious "" places yet , like , e . g . , [ devroye's text ] ( url ) ?"
13655,"the 2nd-to-last paragraph seems especially important : what practical use do cis have , given their abstruse true meaning ?"
13743,this seems like a question from functional data analysis . did you look at the standard [ fda reference ] ( url ) ?
13740,what is time index and what is cross-sectional ( i guess it is for each $ i $ ) index in your notations ?
13739,i think you are trying to mix completely different techniques in statistics that may not be correct . could you please explain in a bit more detail : i ) what are the data ?
13778,what is $ rho $ and what is $ eta $ and what is $ beta $ ?
13797,"hint : "" the drug is effective "" has not been sufficiently quantified to be either a scientific or a statistical statement . * how are you going to make it quantitative ?"
13834,"sounds good to me . for your second approach ( permutation test ) , a standard reference seems to be [ good , pi ( 2005 ) permutation , parametric , and bootstrap tests of hypotheses ] ( url ) . is there a specific reason for choosing the ratio of your performance measures as a test statistic instead of their difference ?"
13884,"it's possible , also are you sure the coefficient means a decrease of 230 % or 2 . 3 % ?"
13921,( 1 ) what would you do if you were just to use all seven body parameters ?
13867,"this is a * three * variable optimization problem ; the variables are $ a $ , $ b $ , and $ c $ . the objective function is quadratic in those variables , so you don't even need calculus : you can use elementary methods to find the minimum if you like . but it's easiest to characterize the unique global minimum as the point where the gradient $ ( partial / partial a , partial / partial b , partial / partial c ) $ vanishes . ( consider the one-dimensional analog : if you want to minimize $ alpha a ^ 2 beta a gamma $ with respect to $ a $ , which derivatives would you take ?"
13984,"what is the forecasting model ( arima , ets , some other ) ?"
13974,"why can't you just pause every few cycles , check the system clock , and commence repainting once enough time has elapsed ?"
14025,"did you miss the conditioning variable in p ( news ) , p ( sports ) or it means p ( . all three keywords ) ?"
14048,which faces function are you using ?
14106,"to give you some intuition , consider two scenarios . ( 1 ) both boxes have 9999 1's ; one has one 0 and another has one 3 . ( 2 ) one box contains only 0's and the other contains only 3's . in scenario ( 1 ) , you will have to pick all 10 , 000 numbers from each box before you can identify the one with the higher average ; in ( 2 ) , most routine tests will fail but the answer will be obvious after a half dozen draws from each box . given such a range of possibilities , can you say * anything * more about what might be in your two boxes ?"
14082,"by $ z $ -scores , should we assume you meant $ ( x- bar x ) / s_x $ ?"
14146,maybe your fitted model is not what you think it is . repeated observations on the same unit does not constitute replication of evidence . what are the experimental units in your model ?
14147,"biorelated there's a very good online help for ggplot2 , e . g . url i also provided some example of use of ` geom_errorbar ( ) ` in [ this response ] ( url ) . is this what you're after ?"
14168,you have implicitly specified nine categories--all 3 * 3 combinations of the two variables--along with their probabilities . why not use the answer to your [ previous question ] ( url ) ?
14199,"do you have the actual weight measurements , or is it just those categories ?"
14205,most dangerous ?
14229,what is the analysis ?
14209,wonder about ( 1 ) . could you comment on your bias ?
14246,which of your variables is a predictor and which a correlate ?
14272,"by "" 4 within subject conditions "" do you mean 1 within subject variable with 4 values ?"
14301,if he's only manipulating the dice with his mind then someone should be throwing them . i think things like d6 or d20 should be left up to george . what kind of manipulation did george say he could do ?
14310,"what , precisely , do you mean by "" graph this "" ?"
14345,what sort of assumptions on the error term are you making or willing to make ?
14355,compare what exactly about the two populations ?
14368,do you want an implementation in matlab specifically ?
14369,did i get the right link for ` orstat ` ?
14364,maybe your update could be posted as an answer ?
14373,"yep , more detail is needed . are you sure that the poisson parameter can be different in * every * cell ?"
14315,what is your measure of the number of details ?
14416,andy any suggestions about how to steer away from a rant ?
14422,when you say 'optimal weights' - optimal in what sense ?
14444,"a lot of introductory lectures on [ bayesian inference ] ( url ) can be found with google . as it stands , your question is very broad and is likely to gather a collection of links to such tutorials . what are you interested in : how do the frequentist and bayesian approaches compare each other ( e . g . , when interpreting a p-value ) ?"
14449,"it sounds like you have one sample of people who answered a question 4 times in different circumstances . why then you mentioned "" unequal sample size "" ?"
14497,multiple columns on the same x and y in r ?
14504,"you need to specify an alternative hypothesis that you want to test this normal distribution against . if your hypothesis is false , what will you put in its place ?"
14482,can you post the papers you are referring to ?
14531,how do you combine the estimates for the sur model if they are different samples ?
14572,what is your sample ( individuals ; members with in teams ) ?
14522,if you can't post data can you at least put up the model output rather than just the anova ?
14611,how do the three experiments differ ?
14628,could you pls also provide the code ?
14643,significant of what ?
14660,could you please elaborate on your two factor rcbd using 2-way anova ?
14665,are you trying to predict lifetime value of a customer ?
14664,how were the proportions calculated ?
14689,what is your goal ?
14739,"do i understand the data right in that you have 3 variables ( columns time1 , time2 , time3 ) with a common list of 5 possible categorical values ( nix , bv , etc ) . each row of the data is an observer ; at time1 he observes , say , nix , at time2 , say , bv , at time3 , say , nix again . if that is the case than why does amount of observations differ for 3 times ( 50 in time1 , 44 in time2 , 41 in time3 ) ?"
14762,'12 participants chose 1' out of how many ?
14785,are the models nested ?
14781,welcome to the site ! similar questions were asked before with these tags -- have you checked whether a working solution can be found among these ?
14800,why don't you want to use percentage ?
8505,how do you plan on taking logarithms of any counts that are zero ?
14844,if all $ x_i $ are distinct both $ x $ and $ x ^ prime x $ are non-singular . in your case it means you can have the same $ x $ ?
14873,"it seems to me this problem has nothing to do with a random variable $ z $ . there is an unknown * number * $ z $ and two pieces of "" evidence "" $ x $ and $ y $ : that's it . this simple description makes it abundantly clear that your question cannot be answered until you explain how $ x $ and $ y $ were obtained . did you consult the oracle of apollo at delphi ?"
14872,why do you want the intercept to be 0 ?
14905,"i'm not sure about the weighting strategy you're proposing . say you have a 2d grid of points , and the weight is your third dimension . a clustering algorithm would cluster things with huge weights together regardless of their x , y coordinates ( because all points with z x , y would be close together in 3d space ) . that's not what one usually thinks of as a weight , and i don't think that's what you want , from bullet point 2 , right ?"
14931,"when you say that you want to do the regression for the first level of the factor , what exactly do you mean ?"
14889,can you add some more details ?
14948,have you predicted the last values of response variable for $ t $ from 228 to 233 ?
14966,how were participants sampled ?
15002,good question . do you have an idea of what $ g $ looks like ?
15007,"are you looking for it to never be biased in all cases , on average , or in a specific case ?"
14997,"out of curiosity , are people always weighed at the same location ?"
14998,we don't use r . can you post a single column of numbers ?
15031,what software are you going to use for that ?
15044,"perhaps it's me , but i don't get the paragraph "" i've then iteratively . . . "" : for each k from 1 to n , you've collected all subsets of size k that hold the highest degree node and expand down ?"
15090,a test implies some comparison of an estimated parameter ( population means for example ) . are you saying the questions and answer are identical in each survey ?
15069,can you explain a bit more what cpt . var does ?
15042,"if i am interpreting your comment correctly , by "" observable periodicity "" you mean that if $ n $ is the number of points in your sample , then the period $ t $ of a periodic signal satisfies $ t ll n $ . yes ?"
15127,"probably this is specific to machine learning , but isn't doing auc-roc enough ?"
12769,how long is a piece of string ?
15118,would all the fields need to be explicitly referenced in the models as well ?
15163,how many statistics courses have you had ?
14400,"could you elaborate on the sense in which this is a "" random walk "" ?"
15208,what is the motivation for this question ?
15239,this really is a basic math question and not an r question . perhaps someone with 'power' can redirect the category ?
15278,rolando2 could you please provide a link to ( at least ) one such thread ?
15283,i wonder whether looking at correlation coefficients would be useful . what would the test results tell you ?
14215,just curious - is this financial data or something else ?
15326,is this related to one of your [ earlier question ] ( url ) ?
15364,"did they really * mean * "" standard error "" ( of the mean ) and not "" standard deviation "" ?"
15394,"at first blush , to get something meaningful , i think you will need to put further restrictions of the function $ sigma $ . differentiability is not much of a constraint , and the function can be essentially arbitrarily wild . ( can you construct a differentiable function $ sigma $ such that $ sigma ( t_i ) b $ for all $ t_i $ and any fixed $ b $ ?"
15395,what makes the data points correlated ?
15433,i am not sure that reinforcement learning is appropriate here . question for clarification : do you can get feedback for an observation only once or can you elect it for feedback multiple times ?
15445,"i suspect what mbq is getting at is that it would be only a little short of miraculous if there's any method that will match various identifiers with any reliability . even people can't do that , and when they can it's due to knowledge of the products and of how abbreviations are made . to have any hope of progress , you need additional information about these identifiers . in particular , there's no well-defined problem here , so there's nowhere in the literature we can direct you . don't you have [ upcs ] ( url ) for these products ?"
15454,"do you mind elaborating on what "" eligibility "" is in this situation ?"
15392,what's the purpose of the comparison ?
15483,"perhaps you could clarify this question by indicating how the data are used to predict a value ( and what value is being predicted ) . what do you mean by "" changing subset of node "" ?"
15502,related q : [ how to conduct conditional cox regression for matched case-control study ?
15530,what do you want to forecast ?
15548,"you're speaking of assessing "" misclassification "" . do you mean that you had some classification of observations prior clustering , and now you want to compare that classification to the one given by clustering ?"
15565,what software do you currently use ?
12742,what kind of asymmetry are we talking about ?
15572,"normally one uses $ t $ for time , which would be the "" x-variable , "" so i'm wondering about the connection between your question and the equation you have provided . where in that equation is the one month return ?"
15578,"actually , come to think of it : what do you mean by uniform distribution in this case ?"
15596,why don't you use a simple anova ?
15597,"this is not a new question . if you wanted to add the part about to garch , you should edit your original question , which will bump it back up in the list . plus , what happened to the approach that we came up with in chat ?"
15589,"what do you mean by a "" validation test "" ?"
15618,how well do the two models compare on their validation data sets ?
15616,""" x per y "" is a * frequency , * not a mean . could you therefore elaborate on the sense in which people might be referring to medians or means ?"
15649,tell us this : how would a finding of a * significant * difference in a correlation affect the recommendations you make ?
15567,"re the edit : what exactly does the "" weight "" mean ?"
15701,what is the ` 30 percentile of the most eaten foods ` ?
15730,"by the way , can you give an exact citation from which you're drawing your question ?"
15598,i notice this is the latest in a long list of questions that use correlation coefficients to assess relationships . using correlation coefficients in this way is at best a weak approach and at worst it is wrong and misleading . have you considered using more conventional analyses ?
15771,the answer to this question depends on the purpose for the request . can you add that to your question ?
15802,do i understand correctly that you want to find solution to $ f ( x ) = 0 $ ?
15904,have you seen this ?
15940,from what you describe these sounds like independent groups . did you apply both treatments to each case or is there some other matching ?
15911,"sorry , i'm a bit confused . when you say "" reservation "" you mean something like a restaurant reservation ?"
15970,( do you want to assume the $ x_i $ are independent ?
15982,"it sounds like you want to run 15 t-tests , 3 at each time interval ( which , themselves , wouldn't be very informative about the drugs effect over time ) . don't you have any theory that might guide this analysis ?"
15989,are the three experimental conditions independent or is it repeated measures ?
16032,you may want to reiterate the details of your design on this question . is your design repeated measures or between subjects ?
16084,"what are the units of each of the variables , and the dependent variable in particular ?"
16103,is there a big distinction between 0 and 1 ?
16022,"are these * time * series , where each data value follows after the previous ?"
16108,"sureshvenkat , sorry , how specific must i be when defining an outlier ?"
16122,"briefly , what is * seo hand-waving * ?"
2688,what r package did you use for hc3 estimation ?
11259,by to produce $ beta $ 's you mean to move to standardized regression ?
16088,lots of details are missing . what is the goal of your analysis ?
16174,it might help to more clearly state the high level goal . what do you want to maximize ?
16178,"speaking of anova , have you tried to look at the models separately from an anova point of view and see what you get ?"
16193,when you say every possible comparison do you really mean comparing outcome2 : male with outcome3 : female ?
16229,"are you assuming that your "" process "" is instantenous , or does it take some time to run ?"
16233,what would the tensor represent ?
16249,"are you asking about the inequality in the display equation ( involving * residual sum of squares * ) or are you asking about an inequality involving the sentence preceding that equation , i . e . , involving $ r ^ 2 $ , the coefficient of determination ?"
16317,you have told us some testers may be better than others . are some bugs easier to find than others ?
16321,cardinal -why not make that an _answer_ ?
16327,what are the dimensions ( no . variables ; no . samples ) ?
16344,which browser and rendered funny how ?
16334,does your language has random number generator ?
16402,"can you say a little more about the academic level of the course , the assumed mathematical and statistical background of the students , and the nature of the course for which the refresher is meant to be preparing students ?"
16432,what do you have in mind in applying pca to signal processing ?
16479,"could you explain what you mean by "" probability "" in this context ?"
16485,"andy sines and cosines are not the only basis , nor are they even the only orthogonal basis , for the ( square-integrable ) periodic functions . one of their merits is that often * physical theory * implicates them in relationships with other variables . this suggests we should be acutely interested in the hypothesized or expected relationship between the dv and these covariates . davidr , what can you tell us about this ?"
16514,"assuming time increases left to right and y increases bottom to top and that the normal plotting positions have been correctly computed , this is a plot of right-skewed times . why does it look skewed left to you ?"
16537,let me rephrase how i understood your question : you want to measure whether the process is increasing or decreasing based on the five previous samples ?
16295,can you somehow identify the trials in which you expect the results to be the same ( vs . being different ) ?
16542,"it seems this question would have a better home on math . se because it does not appear to be motivated by any statistical applications , but is a purely mathematical question . is there a reason to post it here ?"
14711,what's the context of the study ?
16562,"the third sentence of your question is confusing - a randomized trial is not typically what one would call an observational study . is the question really a two part one , or do you mean "" trial "" in that sentence as well ?"
16628,"what will you do with this relationship , if you'll find it ?"
16602,"it is not quite clear what your questions is . is it , "" does it make sense to use vif in assessing formative indicators ?"
16686,"what is your understanding of an "" estimator "" ?"
16688,what is his outcome variable ?
16492,are you aware that there are [ astm standards ] ( url ) for a geostatistical analysis ?
16727,is this homework ?
16790,"i'm wondering whey you see a need for a special algorithm . if any matrix has unique eigenvalues , then just decompose it : its eigenbasis will be an eigenbasis for all other simultaneously diagonalizable matrices . for evs with multiplicity , iterate recursively by decomposing additional matrices on the eigenspaces . what is the problem with this approach ?"
16815,non-dominating or non-dominated ?
16780,can you clarify this ?
16834,clairec what kind of variable is your dependent variable ?
16857,who did the rounding ?
16750,you mean drawing pictures like this you linked or drawing ready models from some other software ?
16872,converges in what sense ?
16882,what does your control run look like ?
16883,are you still interested in an answer to this question ?
16870,""" appropriate "" for what purpose ?"
16911,"what do you mean by "" relationships between the observations "" ?"
16923,please tell us a little about the objective of your analysis . what would you like to find out with these data ?
16939,because it's wrong ?
16916,do you include any interactions ?
16966,what do you want to use the chart for ?
16958,carol i've assumed that condition is within-subjects and groups is between subjects . is this correct ?
17021,what software are you using to fit the model ?
17022,have you considered rewriting so that $ zn = ex_n - ex_ { n-1 } $ ?
17107,and what is the question ?
17112,( 1 ) what * are * you a fan of ?
17160,"what other constraints , if any , do you want to put on this problem ?"
17029,"what do you mean by "" countably infinite "" ?"
17177,i've removed my answer as it was obviously wrong . your code works for me ( no red anything ) . what versions of r / ggplot2 are you using ?
17183,"if the outcome is independent of the treatment , then your treatment effect is zero . are you sure you are testing what you explained above ?"
17156,the question is a tad vague . can you focus it a bit more ?
17209,have you looked [ here ] ( url ) ?
17243,"why not just add across libraries and do a $ chi ^ 2 $ test , of 5 : 251 vs 22 : 322 ?"
17249,which typical textbook says that ?
17258,can you post a plot of what you're getting ?
17242,how many categories do these points occur in ?
17271,what makes an observation positive for each class ?
17272,"another non-statistical example from edward tufte , [ powerpoint does rocket science ] ( url ) . although it is bit more closely related to logical progression from statistical thinking in general than the metric mishap you mention . also are you familiar with this book , [ the cult of statistical significance ] ( url ) ?"
17349,"in general , if you have * any * data with a positive mean and nonzero sd , any sufficiently large number of sds below the mean will be negative . given that this is a mathematical certainty , an appropriate reaction would be "" so what ?"
17354,i'm assuming that the dependent variable in each condition is numeric and is measured the same way in each condition ?
17350,"if we change "" generalized linear model "" to "" regression "" will your question change ?"
17387,"if you multiply each average by 8 , do you get total numbers of times each face comes up ?"
17402,is this a homework question ?
17413,"there is an inherent difficulty with this question , though : its interpretation appears to require a subjective understanding of "" accessible , "" which will vary among consultants and their clients . can it really be answered , then ?"
17455,why would you want to approximate this via monte carlo when it can easily be solved explicitly ?
16470,"just to be clear : if we define $ f ( p , q , r ) $ to be the set containing the maximum and minimum of $ { ( s_p ( i ) s_q ( i ) s_r ( i ) ) , 1 le i le 3600 } $ , then you want to find a data structure of smallest possible size that allows for computation of $ f ( p , q , r ) $ for all $ 1 le p le q le r le n $ . furthermore , you appear to allow $ f $ to be computed with some error : but how much error is acceptable ?"
17400,"i'm not sure i quite understand your question yet . is $ mu $ a vector , as in $ mu = ( mu_1 , ldots , mu_n ) $ ?"
17504,"could you define what you mean by { a b } clusters : the body of your question suggests either clusters of variables or cases , while the title looks like it has more to do with two unlabeled classes ( of cases ) ?"
17510,"it's actually just incredibly hard to understand what you are on about . your previous question seems to be pretty much the same , but it's easier to understand : url maybe you could have another crack and try to get to the point . maybe this belongs on a more culture / language-based stackexchange site ?"
17559,you have only 24 objects and reduced the set to 3 attributes ?
17578,what kind of thing or observation do these values represent ?
17592,"ok , i see . what could be the problem here that the species population index is not precisely known ( ?"
12067,do you mean the arcsin ( square root ( x ) ) ?
17617,"i'm a bit confused here . could you write the model ( with math , not programming code ) you're trying to estimate ?"
17624,why do you seek a more parsimonius model ?
17628,"using a table suggests you have made many tests of such equality . this is an unusual thing to do , perhaps because it may be difficult to interpret the results and perhaps because differences in correlation do not appear to reveal much . suppose two variables do have different degrees of correlation for two subsets of the data . what does that * mean * ?"
17660,what is the purpose of the intended approximation ?
17710,what is the variance of a 2d gaussian random variable ?
10874,tal should we set this as cw ?
17755,did you consider using central limit theorem ?
17756,"by concatenating i would imagine something like stacking , while you mean binding / juxtaposing . while in general more data is indeed a good thing , it it not necessarily the case . particularly in your scenario where it is unclear what the data is used for . could you please be more specific regarding what you are trying to do with the data ?"
17757,andrie you should be able to use any statistic for hypothesis testing if you can come up with a suitable distribution for it . . . which i think is what ian's code is doing but i'm having a hard time following it . . . ian could you maybe explain in words how your code works ( at least for my benefit ) ?
17782,"thanks for the fixes . the typo changes nothing material , however : now the parameter $ mu = cos ^ 2 ( omega t ) $ is located in the interval $ [ 0 , 1 ] $ instead of $ [ -1 , 1 ] $ . there is still only one parameter . $ omega $ is not identifiable : from observing $ ( d_i ) $ you can estimate $ mu $ but obviously from that estimate you cannot recover a unique value of $ omega $ ; it could be any real number . * if we take $ t $ to be fixed at some ( known ) nonzero constant , * we can estimate $ omega $ modulo $ 2 pi / t $ , but that's all . perhaps $ t $ varies in a given way from one trial to the next ?"
17788,"i realize that this is not the subject of your question , but in the way you have restated your hypothesis , do you notice that you have gone from testing for any statistical connection to presuming a causal connection between the two variables ?"
17772,could you explain the data a bit more or maybe provide a shortened sample ?
17816,where do you get 150 % from ?
17846,steffen i don't follow - isn't there a programmers . se ?
17850,epigrad : what kind of date do you have in mind ?
17856,i am agree but method like ridge or lasso for regression to ?
17877,are you referring to type i error ?
17978,is the question about understanding the mathematics and / or mathematical formulas behind the mentioned quantities or is it about * numerical algorithms * to actually * compute * them ?
17946,why are you trying to make the posterior distribution symmetric in the first place ?
17972,what is your error function ?
17760,"really , $ - frac { 1 } { n } pm frac { 2 } { sqrt { n } } $ ?"
18087,"although dealing with ties can be an issue in some analyses of categorical data and in applying certain nonparametric methods to continuous data , ties * per se * create no problems for computing correlations . perhaps you could say a little more about the data you are concerned about ?"
18077,could you provide more details on exactly what you want ?
18131,"before you can do significance testing , you need to specify the null and alternative hypotheses . if there is no alternative splicing , what do you expect to see ?"
18045,"why would you think your data should follow the gamma distribution , which has an infinite support ( all $ x 0 $ ) ?"
18119,"after the line ` i fit the following model ` in the first paragraph , what is ` y = 1-2 . 18 ` referring to ?"
18125,do you have individual level information or only aggregate information ?
15564,"pardon for asking , what define "" dimensionality "" in your case ?"
18088,could you please provide the reference of that paper ?
18205,"it seems this issue has been addressed at url how does your question differ , if at all ?"
18219,"i don't understand the 1st paragraph with experimental methodology , what the groups mean , or how you assign a participant to a group . can you clarify ?"
18162,perhaps a chi square test for each icd-9 code and correcting for multiple comparisons in some way ?
18102,"you should provide some details about the data structure . suppose , you could arrange your data in a spreadsheet format . what would the columns represent and what would the rows represent ?"
18257,"as whuber points out , the hypotheses are meaningless when the mean is infinite , or undefined as in the case of a cauchy random variable . how about thinking of a test for distinguishing between hypotheses $ $ begin { align * } h_0 : & theta = 0 h_1 : & theta 0 end { align * } $ $ where the observations are assumed to have density function $ f ( x ) = frac { 1 } { pi } frac { 1 } { 1 ( x- theta ) ^ 2 } $ , that is , a cauchy density with _mode_ $ theta $ ?"
18281,why are you using an absolute residual as a dependent variable ?
18284,"might it be help to plot the acf up to larger lags , perhaps a few hundred ?"
18290,"simply due to the boundedness of the metric , it clearly cannot be a hybrid of an exponential and a normal , both of which have unbounded support . judging by your picture , such a mixture is not a viable candidate distribution , even as an approximation . you say that this is a metric space . is it not euclidean , then ?"
18316,"see the link to "" [ possible duplicate ] ( url ) "" at the top of this question ?"
18330,is your only problem that the data aren't normal ?
18325,"as can be seen , you only have one numerical variable ( ` age ` , because ` sugar ` will actually be treated as a factor ) : how would like to summarize it with other factors ( quartiles , median , mean ) ?"
18379,does url help ?
18396,what exactly do you want confidence intervals for ?
18400,"what you call glz is actually known as a glm : ) ( fixed in my edits ) could you indicate what you mean by "" equalize "" ; when you speak about "" normally distributed "" scores , do you refer to the response variable or the covariate ?"
18425,"could you clarify what you mean by a "" binomial group "" ?"
18423,"if you could disclose the purpose of the classification , rachel , that would likely reveal an appropriate way to compare two classifications . for instance , if the purpose is to estimate costs , then you should be comparing the precision of cost estimates made with the classifications . by the way , what is this "" variance "" you refer to ?"
18431,"do you mind citing the evidence that tufte / minimalist style charts contradicts all psychological research we have regarding humans , their memory recall , and pattern recognition ?"
18450,"studying the [ wikipedia entry for nonparametric statistics ] ( url ) might be enough to prepare you for an interviewer . you could answer the question with a question , as in "" what do you mean by non-parametric ?"
18470,just checking : have you tried using ` predict . fregress ` using the ` newdata ` option ( from the fda manual [ here ] ( url ) ) ?
18491,"there does not appear to be enough information to answer this question , but it's not clear . are you saying that there is a stochastic process $ y ( t ) $ of losses over time ?"
18490,does removing the intercept from the model with ` - 1 ` help ?
18493,what is the connection between cluster analysis ( ca ) and rf ?
18504,what is the length / timeframe of your training data ?
18542,why not use the built-in mvnpdf ?
18574,just a thought . how come you see weekend tasks at work ?
18581,"do you know when a user uses your recommendation ( e . g . , rents a recommended movie ) ?"
18596,"presumably , in the second formula , $ le $ is a typo for $ sim $ and $ p 1 $ is the number of parameters ( including the constant ) , right ?"
18607,good question . would this be better on the stats . se site ?
18576,"max-gordon , is your response variable a quantity , or the time elapsed until an even occurs ?"
18615,"the point with "" joint significance "" is not clear to me . what is that ?"
18650,"disclaimer : i am not a biologist , so please don't hesitate to correct me if i use the wrong terminology or have a stupid question . * * questions * * : ( * * 1 * * ) it is not clear to me what you are counting . each array has length 7 . what is this ?"
18700,i'm not asking anything . the wikipedia article is quite clear about what the regressors are in the bp test . your mention of two prices in the previous comment does not seem to have any connection with the question itself . have you perhaps forgotten to mention some important things about what you're trying to do ?
18709,i'm pretty sure that models 2-4 are not possible in ` lme4 ` . can you ( a ) tell us why you need to do this in ` lme4 ` rather than ` asreml-r ` ( b ) consider posting on ` r-sig-mixed-models ` where there is more relevant expertise ?
18797,"what is a "" distribution table "" ?"
18819,stupid question : it is a problem to store the denominator for each t ?
18699,"how large a number of samples do you have , roughly ?"
18876,"as far as intuition of the score , do you understand the intuition of a derivative ?"
18941,"with only 1 or 2 data points for each month , you don't have a lot with which to test results on a monthly basis . as for the day-to-day results , you'll want to make your hypothesis more specific . you might test for an early-late difference ( e . g . , first few months vs . last few ) ; for the presence of particular days that stand out from the rest ( outliers in the distribution ) ; or other effects . what is most important or interesting to you ?"
18954,i could not see cluster analysis in what you've done . is that grouping of cards by experts you call cluster analysis ?
19006,"your question needs some clarity . it appears you are talking about a hazard ratio , not a hazard rate . is there a reason you've chosen that particular regression equation - there are many ways to approach a survival analysis . and what do you mean by "" when "" can we assume this - do you want a set of circumstances where it's true , or a means to assess whether its true in your case ?"
19021,"there must be something missing from this recipe you are following , because it appears to make no statistical sense and in many cases will be a terrible procedure . is this "" manuscript "" accessible to the rest of the world to consult ?"
19022,how are you coding age and education ?
19035,"could you state precisely what you mean by "" hazard ratio "" in this context ?"
19072,do you have a reference ?
19115,scottritchie is the data available ?
19173,"i'm not convinced of that incompatibility , cardinal . is there a proof ?"
19147,could you be more specific about which chi-square test you are performing and how ?
19169,"could you please supply a definition of the "" extended binomial density "" ?"
19243,narendar reddy kalam : why have you chosen the quantile regression model ?
18836,"( 1 ) welcome to cv , and be sure we welcome such questions . what do you mean by "" this should probably use a * non-parametric * test "" ( emphasize is mine ) ?"
19271,"you mean that ` rs ` is defined as ` interaction ( r , s ) ` ?"
19302,"about your 3rd paragraph--- "" between sex and the predicted variable b and the sex "" ---do you mean there is some correlation between a and gender , * and * b and gender ?"
19314,any chance of some references to where 'it has been reported' or this stuff about training images ?
19258,"given the notation $ p ( x_i , c ) $ i would rather think this is the frequency "" viagra "" appears in a c class email , relative to the number of words total . otherwise , it would be $ p ( x_i c ) $ . it is also more coherent when looking at the entropy formula : $ p ( x_i , c ) $ and $ p ( x_i ) p ( c ) $ are comparable . ( with respect to which index is the sum computed ?"
19375,not quite sure what you want to test . you took your 500 detected peaks and averaged their profiles and get a peak . you took 500 random locations and averaged their profiles and get something fairly flat . are you trying to compare these two averaged profiles to say that the one is significantly more peaked than the other ?
19311,"user721975 the second thread of cardinal is the way to go . the suggested book "" programming collective intelligence "" requires no prior knowledge except basic math skills ( it has been written for cs-guys ) . one level below pci would be introductory books to programming and high school mathematics . do you have a "" from-absolutely-zero-to-hero "" -book guide in mind ?"
19405,"sorry , missed the bit on the probability model as the purpose . . . so the two patterns are either alternating rising and falling or continuously increasing by an unknown amount ?"
19448,it is unclear what the scores are ( parts of the ratings ?
19459,why not just average the individual time series ?
19469,did you look at log-linear models as well ?
19504,just for clarity - do you mean you'd like to see the covariation among the variables or among the coefficient estimates ?
19512,"could you indicate how a single number like $ mu $ is presumed capable of expressing an entire "" spatial distribution "" ?"
19537,duplicate of url perchance ?
19567,did the variable blip and then return to its earlier value ?
19576,"does your stat package provide some form of "" predict "" function ?"
18940,"define "" effective . "" your goal is to assign cases to clusters , right ?"
19636,why are you being asked to do homework without having gone over what you need to know in order to do it in the class ?
19688,if the $ y_ { i } $ 's are count data then why have you written there that they follow a normal distribution ?
19693,"similarity measure is selected mostly on the basis of theoretical / logical rationale , not empirically . is it that you fail to work out the rationale that you go for distributional properties in order to select among measures ?"
19713,i assume you meant $ vert mathbf { x } - mathbf { y } vert $ in your last line of math ?
19724,"could you elaborate on how you think a lower mean could "" drive overall variance "" ?"
19717,"do the "" standard "" assumptions include the normality of the $ epsilon_i $ or not ?"
19794,have you computed and plotted the residuals ?
19870,what data do you have or could you collect ?
19891,is this a homework problem ?
19911,"i am note understand well what are "" changes in hospital-level variation in the outcome during the period . "" what kind of data do you have ?"
19927,can you give some more details on what kind of data this comes from ?
19928,"this question may be difficult to answer due to the use of terms that are vague or undefined . for instance , what is an "" annual duration "" ?"
19954,"some more links . url url have you tried searching for "" analysis of variance r "" in your fav search engine ?"
19972,what is exactly the question here ?
19964,what is your objective ?
19981,"due to its bimodal shape , you might want to try a gaussian mixture-model ( weighted sum of two gaussians ) ?"
146,"why did you put ` r ` tag and what do you mean by "" why this is so "" ?"
20001,"i'm not sure how to interpret the sas probabilities . . . is that 0 . 0072 % , 1 . 884 % , 0 . 954 % ?"
20011,"the question is interesting one , but i think it is not answerable . can you please make it more specific ?"
20039,what do you mean by process ?
19894,could you clarify via an example exactly what you are looking for ?
20070,surely age will be a ctn variable and not a factor ?
20146,how do you compute a variance of $ 2 / n $ in state 0 and $ ( 4m 2 ) / n $ in state 1 ?
20169,why do you want to implement these ?
20245,"now that i re-read the question and its title , it's not clear to me where the pre-post measurement process arises ?"
20281,do you really want to do an fmri analysis with absolutely no chance of localization of the functional differences ?
20271,"have you looked in , e . g . , the classical [ seber & wild ] ( url ) ?"
20300,"what kind of confidence interval do you seek for two _numbers , _ say $ x_1 = 3 . 8 $ and $ x_2 = 4 . 8 $ ?"
20349,"could you be a little more specific in terms of "" code a pretty basic version "" ?"
20357,"what "" you mean by adjusted manually by user "" ?"
20235,is bayesian * * probability theory * * any different from regular probability theory ?
20381,"tags function is enough for us to distinguish the problem categories . if subdivision is necessary , why don't we divide math stackexchange into applied math or pure math ?"
20397,have you thought of using poisson regression instead ?
20409,is there a statistical question here ?
20435,where does the weighting scheme comes from ?
20533,i don t get it . do you mean that they should use a unilateral test instead ?
20543,"in the definition of $ d_i ^ 2 $ , do you still view $ x_i $ as a random variable or are you now treating it as a fixed vector ?"
20555,it's a reasonable question but the sense of 'confidence band' needs to be made more precise . what properties do you need it to have ?
20591,csr = corporate social responsibility ?
20616,( 1 ) where does the one degree of freedom in ( 4 ) come from ?
20643,* * first * * : yes . can you think of an example ?
20645,"what do you mean by "" modeling "" in your last paragraph ?"
20590,are you drawing all unique values ?
20655,"if she has the ability to start the next haircut earlier than scheduled , she is not allowed to do so ?"
20583,"is this : url helpful , or do you mean something else ?"
20692,how exactly are you fitting the data and how do you combine all the variables into 1 ?
20708,"given that the new diagnostic procedure is more accurate , is it likely that the other sites will shift to it ?"
20710,"what kind of "" patterns "" are you interested in ?"
20721,"what is a "" [ crf ] ( url ) "" ?"
20749,"that's true . spss is * much * more user friendly than r ; you can run many analyses quickly and easily with its point and click interface . that can be nice sometimes , but is it worth the money ?"
20758,"imagine you try to integrate the constant function $ f ( x ) = 1 $ on the interval $ [ 0 , 1 . 96 ] $ . you will sample 1000 values $ x_1 , dots , x_n $ in this interval , compute the mean of the $ f ( x_i ) $ , which is 1 . the value of the integral is 1 . 96 ! do you see now what s going on ?"
20797,is your variable var continuous or categorical ?
20834,"could you clarify what you mean by a "" discrete "" variable with a single "" continuous "" value ?"
20854,what about ` confint ` ?
20892,what's your question ?
20932,"how is it possible for a time series to be both "" stationary "" and to have a changing autocorrelation ?"
20915,"what is the distinction between "" beta1 [ group [ i ] ] is drawn from a distribution with zero mean "" and "" all the beta1 [ ] are drawn from a distribution the mean of which is fixed at zero "" ?"
20805,"just asking question of vanity ( as from me a practicioner , not mathematician ) . . . why do you need a proof ?"
20936,have you tried applying a function to the weight ?
20962,"it's not really clear what you're asking here . what "" multiple contents "" are you referring to ?"
21020,"a plot would be interesting and , potentially , helpful . how close to sinusoidal are the two series ?"
20992,does [ this similar thread ] ( url ) answer your question ?
21015,"how do you define the "" risk "" of an estimator ?"
21022,could you outline the exact procedure how the coefficients are calculated ?
21137,isn't lwr and upr the confidence interval ?
21081,"maybe you can give more specifics to the problem , as what is the purpose of the model ?"
21153,"do you want some key textbooks on sem in an applied perspective , or more general and formal textbooks ?"
21173,"mfrmn , i am eager to learn , can you explain a little bit where this problem comes from ?"
21278,could you indicate what information is required from table 2 ( or are there multiple outcomes ?
21268,ttnphns i do not follow your point . where is it stated that the op does consider latent classes rather than latent traits ?
21303,"just to be sure : you are not just interested in finding the corresponding $ p $ -value associated to your resampling procedure ( in which case the wikipedia entry on [ resampling ] ( url ) might do the job ) , but rather in expressing a rejection region in a formal way ?"
21308,"maybe if you could post some of your own work , someone could point out where you are going astray ?"
21335,is this an homework ?
21370,"just to clarify , you're looking for a way to plot quantile markers , correct ?"
21375,"i "" m a little confused by the wording . you say , "" determine some value of error between the systems "" . do you mean "" difference "" between the two systems , or "" error "" of one of the systems ?"
21332,how about simply using a moving average ?
21365,"you appear to be expressing your p-values in an unusual way : normally , using a p-value of 0 . 95 means you expect to make false positive determinations in * 95 % * of a set of * independent * tests . do you perhaps mean to write "" 0 . 05 "" instead of "" 0 . 95 "" ?"
21429,"do you mean that two marginal distributions for $ x $ and $ y $ , $ p ( x ) $ and $ p ( y ) $ respectively , don't dictate the joint distribution $ p ( x , y ) $ ?"
21515,"if you only have one measure per subject , you can't measure within-subject reliability . but if each subject does the 200 trials ( is that what happened ) you can use a measure of reliability if you have that individual trial data . what data do you have ?"
21467,"i find this data are little hard to visualise ( if you can excuse the pun ) . is it stored as a rectangular dataset , and if so , how many rows and columns ( and what are they ) ?"
21549,i do not understand your question . what do you know and why can't you use convolution ?
21556,have you looked into using a real-world pre-existing dataset ?
21565,are you sure this is a constrained regression problem ?
21572,is it this one : url ?
21591,is this covariate associated with the dependent variable ?
21592,could you edit your question to clarify which measures are computed on the training set and which on held out data ?
21665,"not a stupid question . i'm not sure though whether you have either : a system of two equations ( because y is somehow caused by x1 and x2 , and x2 is also caused by x1 and y ) ; or just one equation , about which you don't mind the causality , that you have switched around and want to estimate the second for some reason ( what ?"
21677,how was your biplot constructed on the original dataset ?
21691,"are you saying that you are going to start with a set of known cases , next perform your biomarker test ( collect data ) , and estimate the sensitivity ?"
21685,why do you think you need mds - your data matrix are already pairwise distances rather than original cases x variables ?
21695,"did each subject touch all 4 surfaces , or did some touch some surfaces more than once ?"
21718,"i think i get the idea , but i'm concerned my guess could be mistaken . could you perhaps elaborate on what you mean by "" functionally equivalent "" ?"
21656,"interesting and tough question and you've put your finger on some of the key issues . how many judges in total , so how many projects would each judge judge ?"
21791,"shouldn't ` kcluster $ tot . withins ` be ` kcluster $ tot . withinss ` ( two "" s "" at the very end ) ?"
21747,how do you know the income level of customers . what about customers who don't buy the product - are you only interested in purchasers ?
21818,"i consider myself to be reasonably good in structural equation modeling , but i cannot really see how to answer this question . what is a clinical formula ?"
21851,"do you mean very * dependent * at the end of your 2nd paragraph . if so , have you thought of some type of markov chain approach once the first variable is estimated ?"
21844,what do you intend to use the model for ?
21847,converges in what sense ?
21900,two questions : ( 1 ) is there an illustrative plot you could include and ( 2 ) can you give some sense as to why you want / need the $ alpha $ -stability ?
21920,"technically , 'we' don't try to minimize the determinant to achieve robustness but to achieve high break down point ( which is a provable property of an estimator ) . it turns out that volume minimizing estimators ( and hence also truncated likelihood ones like mcd ) achieve this property . are you asking for a proof that mcd has high break down point ?"
21989,here are some things to think about : ( * * 1 * * ) what does slutsky's theorem say ?
21990,"hi , i'm a bit lost by your question . normally we compare groups on the basis of outcome ( percent tumour reduction ?"
21995,what is $ hat { p } $ ?
22034,can you clarify your question a bit ?
22039,"so you have 1000 observations , each of which is now categorised into into one of 15 groups , which you want to shrink to 2-3 . what is your objective in shrinking to a predetermined number of groups ( what will you do with the results / conclude from the grouping ) , and how many variables have you measured that you can group on ?"
22050,do you know the relationship between a correlation matrix and a covariance matrix ?
22000,"what do mean by "" general-to-specific estimation "" ?"
22091,"so this is a ( finite-state ) [ birth-death ] ( url ) chain ( with self-loops , which the link doesn't mention , but are common in the literature ) ?"
22125,"thanks . there still must be some typos : for instance , what does a margin of 3 mean in "" apply "" ?"
22055,"z-scores are variation measures . i think you're trying to describe an anova : url but i'm not sure . can you say what your research question is , and what sort of data you have ?"
22156,i'm confused . you're subtracting something in y1 from something in y1 . is y1 the forecast or the actual data ( outside of your sample ) ?
22144,"hi there , is there any qa process that is undertaken that you will need to take into account , e . g . recalibration , machine servicing ?"
22163,do you have good reasons to believe that whatever causes the big drop is not independent on past data from that series ?
22188,"hi there , good question . what is the name of your performance measure , and what does it represent ?"
22198,have you looked at the residuals to see if the ones associated with values below the intercept tend to be positive and those above the intercept tend to be negative ?
22209,"could you explain what you mean by a "" nearest-neighbor query "" in this context and how it is related to dtw ?"
22233,"adding to macro's comment above , in this situation i look for "" practical "" or "" clinical "" significance in the findings . for what you are doing , is the effect large enough for you to care ?"
22243,could you please give some more context for the parameters ?
22284,is this a homework question ?
22282,is this homework ?
22288,do you expect the death rate to vary between hh hh and hh ?
22298,"why not just calculate the mahalanobis distance from $ x_ { test } $ to each $ x_i $ , using the sample mean and covariance matrix for the appropriate subset ( 1 , -1 ) of the $ x_i $ ?"
22294,"a fairly basic example that comes to my mind is r's [ lme4 ] ( url ) package for mixed-effects modeling , which relies on sparse design matrices to handle lot of random effects . however , i feel like you are more interested in sparse input , am i right ?"
22084,i think that there is a mistake in your formula for the probability of winning . shouldn't it be $ frac { textrm { my chips } } { textrm { total chips } } $ ?
22420,how were the pilot regions selected ?
22438,"are the two scores measuring the same attributes , so they are repeated measures of the same thing ?"
22454,what do you mean by * path dependent * here ?
22464,have you looked at repeated measures anova ?
22473,"i assume "" 1 "" is the same component in both series , etc . have you tried plotting actual 1 versus sensor 1 , 2v2 , 3v3 as separate scatterplots to eyeball the data ?"
22543,"how many participants do you have , and was talking duration / topic controlled ( e . g . do you have word information for 5 minutes of talking per participant ) ?"
22552,"just to clarify , when you find the optimal parameters , are you taking the test data into account ?"
22401,"when you write $ min ( x - ( y_1 , y_2 , ldots , y_m ) ) $ is this intended to mean the same thing as $ min_ { 1 leq i leq m } ( x - y_i ) $ ?"
22630,"hi there , exactly what type of experimental data analysis do you need ?"
22595,"if you take two samples at precisely the same point , will you get the same value of f ( ) or different values due to the error term ?"
22195,"a nice , practical , interesting question . how many are on each team , and does this change at all - so are team matches always with 3 players . are you interested just in wins or are you also interested by winning margin ?"
22497,"i don't quite follow : given $ theta $ and $ sigma $ , you know the distributions of $ x $ and $ y $ . assuming independence gives you the joint distribution of $ ( x , y ) $ , whence you have all you need to determine the distribution of any measurable function of $ x $ and $ y $ , such as $ min $ . what is the "" more information "" you seek , then ?"
22654,what is the relation of question 2 to question 1 ?
22684,"why are you grouping instead of , e . g . , running a regression ?"
22671,could you show a sample of your dataset ?
22690,"i'm not sure whether you're using the term "" power "" in the standard statistical sense--namely , the probability of finding an effect statistically significant based on a sample , assuming that effect exists in the larger population . unless i'm way off , power is always calculated with respect to a particular procedure-- * t * -test , logistic regression , etc . maybe that's what you meant by "" algorithm . "" what procedure are you planning to use ?"
22699,do you mean that you want to bin your data ?
22702,is this homework ( it kind of reads like it ) ?
22746,"can you produce forecasts for the number of sign-ups by day , with confidence bounds , then check for sign-ups that occur outside the bound ?"
22787,is there any censoring ?
22780,this question needs additional information and clarification . what are you attempting to * calculate * with these models ?
22819,( 1 ) for a well-posed and interesting question . ( did you mean to call $ x_i $ a dependent or independent variable ?
22843,"another note . the question title is strange . as far as you are aware , there's two types of loadings after oblique rotation , pattern coefficients ( which are regression coef-s ) and structure coefficients ( which are correlation coef-s ) . then , what else "" loadings "" are you striving to compute ?"
22838,could you report the output of ` str ( data ) ` ?
22764,"the spherical symmetry immediately implies all marginals are uncorrelated and have equal covariances , reducing the problem to calculating the variance of a single marginal . but first , could you clear something up ?"
22742,"i do not know python and the following is likely to be silly , but isn't there a problem with the ( i-j-1 ) as the index of ar . shouldn't it be ( i-j ) ?"
22805,could you add your r code to question ?
22914,hints : ( 1 ) exactly how large can $ 1 - sin ( 20 x ) / 4 $ ever get ?
22767,what percentage of your features have 100 true values ?
22530,"i think this is a show-and-tell kind of question . maybe plot the accelerometer data , by axis v . time and give us a peek ?"
22945,why doesn't ` indexvector ` appear in the body of the ` meandiff ` function ?
22949,"hi there , i'm not clear on what the application is doing . you say it is getting a list of strings , but then you later talk about sorting . i'm not seeing the link between your first paragraph - data collection - and your second paragraph - data sorting . can you add more detail ?"
22976,are you assuming the fit is done with least squares ?
22967,"if you have a sufficiently group of engineers with varying levels of experience , maybe you could look at the less / medium / very experienced groups separately and then define proficiency on the basis of the overall results of the very experienced group ?"
23072,"i don't think this is a meaningful question , given the usual meaning of similarity . you can measure how close points are to a line , and do so various ways , including median absolute deviation and mean squared deviation . but is this really "" similarity "" ?"
23032,"exactly what operation are you performing when you "" rescale "" an $ m_i times n_i $ matrix into a $ p times q $ matrix ?"
23110,this is one of my problems with r . what library is ` train ( ) ` from ?
23120,what have you tried ?
23134,"hi there , can you put in a link to the online calculator you have been using , and also let us know what your various analyses are ?"
23137,which edition / printing do you have ?
23146,what is $ x $ - ie what parameter is it ?
23177,"to clarify : are you using "" maximum entropy classifier "" as a synonym for [ logistic regression ] ( url ) ( via mle ) ?"
23182,"hi there , as alpha is increased , your prediction interval shrinks , so you can literally plug different alphas into a standard formula and get various widths of prediction interval . this does not seem to answer your question . what do you mean by smallest prediction interval ?"
23218,"what do you mean by "" posterior mean of simple exponential function f ( x ) = exp ( x ) "" ?"
23221,_disagreement_ and _randomness of votes_ are two different things . for example when there are only $ 1 $ s and $ 5 $ s the pattern is very far from random ( and means that it is either loved or hated ) . so do you want '0' for random rating and negative for 'controversial' stuff ?
23235,can you give us a little bit more detail on the learning algorithm and architecture that you ( or the r package ) used ?
23181,is this homework ?
23317,i'm not sure i quite understand your question . is there a reason you don't like or can't do an eigendecomposition ?
23292,"the implication seems to be that you want to select the same columns of $ x $ for all the response vectors , but allow for a different linear combination of the former for each of the latter . is this your intent ?"
23335,have you considered of using some dimension reduction methods ?
23433,"are you working on retrieval , where you're looking for unique qualities of a particular audio clip ?"
23470,"do you have a lot of data , but little labeled data ?"
23502,can you give ( more ) examples of the data you have in mind ?
23501,"i am undecisive whether this question is brilliant or complete nonsense , i . e . i am not sure whether there is a ml perspective on this discussion can you name an example / algorithmn / field of application for each reasoning in ml ?"
23575,so what do the 500 rts mean ?
23540,what is $ p ( a 'b ) $ ?
23598,could you elaborate on why you are considering only absolute values ?
23623,"just to see what's causing the difficulties , could you tell us whether you have any similar difficulties ( with concepts , terminology , or computation ) when there is exactly * one * observation , $ x $ ?"
23634,` ?
22964,"given your comment to gong-yi liao that the combination of id , start and end is the "" window "" , the question does not make sense as written . do you perhaps mean you want to rank the data according to how * close * score1 and score2 are in each row ?"
23656,how is the sample data non-random ?
23658,"just curious , where did you find that illustration ?"
23697,convergence ?
23696,can you clarify how you understand machine learning & statistics to differ from data analysis ?
23702,"i like that [ math processing error ] in red ; it fits in well as a transition between the previous and subsequent paragraphs ! perhaps , however , it is unintentional ?"
23708,"so what are your 21 points in the first vector - is it 21 numbers , each of them between zero and one ?"
23704,"when you refer to the "" autocorrelation of the residuals "" , are the residuals from estimating $ y_t = beta_0 beta_1 x_t e_t $ or from the joint estimation of equations 1 & 2 ?"
23711,"this sounds like you will have hundreds of p-values , many of which will be spuriously statistically significant . can you explain why you wish to use such an approach ?"
23709,part of this question looks cut off . is there some content missing ?
23778,"what do you mean by application of caic or maic "" outside of aic "" ?"
23761,"your uneasiness with the language of confidence intervals , but otherwise rigorous presentation , suggests you may be in a good position to give us a little more information to help you . ordinarily you can specify one of two properties of a ci : either its coverage or its length . the other will be determined by the data . it's unusual to stipulate the length , though : are you sure this is what you want ?"
23790,"hi there , could you please explain how you wish to incorporate costs into your model , as your problem statement in your first paragraph only talks about quality ?"
23795,what kernel are you using ?
23775,"if you already know that these "" standard "" effect sizes are a poor idea and best interpreted within the context of particular research why are you asking the question ?"
23839,is the response variable continuous ?
23849,"to be sure to understand your question , you are interested in textbooks about the measurement of psychological traits , say , in designed experiments ( e . g . , controlled tasks in a laboratory ) ?"
23800,why test ?
23875,what is a response supposed to represent ?
23879,are var1 and var2 character or numeric variables ?
23942,"what exactly does "" amount of evidence "" mean ?"
23955,"it is unclear what the sum formula has to do with the clustering or even what "" clustering "" is . here's one interpretation . suppose the cluster sizes are $ n_1 , ldots , n_k $ . an obvious way to generate random partitions with these sizes is to permute all $ n $ items and assign the first $ n_1 $ to the first cluster , the next $ n_2 $ to the next cluster , and so on . given its obviousness , i presume you have rejected this as a solution , but why is it not a solution ?"
23944,does this test make sense if i only have beetween 4 and 9 numbers in my sample that i will be comparing to the normal dist ?
24003,this is probably a bad combination of identification issues ( too many 0s ) and numerics . why don't you stick with stata if it works ?
24077,"hi melory , that sounds like an interesting experiment . for your ` iv ` s , are you interested in knowing how each is related to the ` dv ` on a continuous scale , or are you more interested in the effects of ` iv ` groups , e . g . that overweight people eat more slice than normal weight people ( for your ` bmi ` measure ) ?"
23921,what is your sample size ?
24121,"i don't understand what you mean . maybe it would help if you explained more what you mean by "" observation . "" also , what do you mean by closest ?"
24135,"i'm not sure why you have these weights , as weights are usually based on the sampling method , which is not your basis for weighting . when you say "" same distribution "" , do you mean ( 1 ) both are from a ( e . g . ) normal distribution , or do you mean ( 2 ) both are from a ( e . g . ) normal distribution with the same statistics ( e . g . mean , standard deviation ) ?"
24197,your difficulty is that you have yet to formulate a research question . what is the purpose of conducting this test ?
24257,what distribution does $ { bf y } $ have ?
24267,"both models seem to have a problem - there are some fitted values that are much higher than all the others , and there are some outliers . can you tell us what you are trying to do ?"
24313,"do you have a deterministic , but noisy process that is yielding your measurements y_i ?"
24302,"just out of curiosity , what is the scale of your data ?"
24318,hi isaac . is there a little more precise way of stating the model you are considering ?
24293,what's binary survival data ?
24344,what have i misunderstood ?
24360,"what do you mean "" there is no noise in the model but there is in the data "" ?"
24362,"would you like to see a proof , is that it ?"
24377,do you have some typesetting errors here ?
24397,welcome to the site . how large is the state space ?
24398,can you be more specific regarding what aspects of time series you are seeking to learn ?
24399,how so ?
24371,"hi there , to clarify , you wish to identify the best method to predict stock prices , the latter being a random / chaotic process ?"
24337,"hi there , what is your research question with respect to the influence of time ?"
24418,does this help ?
24420,"i am having great difficulty following this . can you describe the situation you are studying , the data you have , and the algorithms you are applying ?"
24416,can you give an example ?
24488,"may i ask whether there's a reason why you go through all the effort creating a kernel density estimator . why don't you just create a 2d histogram , estimate the marginals from that , and use it to estimate the mi ?"
24518,classify as in supervised learning a map to a given target class label ?
24331,"you can run linear regression with binary outcomes if you like . ( though i'd recommend ensuring that ` gender ` is indeed binary , and not stored as a factor . ) but why do you want to do this ?"
24648,is there some structure within the rows you are interested in exploring ?
24659,"hi there , could you give some more context around the decomposition you wish to do , as i have not seen it applied to time series data ?"
24662,the intended statistical package is r or spss ?
24707,why aren't you using a two-sample t-test on the individual observations ?
24742,are there exactly five sites ?
24777,"hi verity and welcome to the site . could you provide some more information about your study , for example are the same people in group a ( and group b ) undergoing all three treatments ?"
24782,"hi there , what techniques / models have you used so far for analysing your data ?"
24781,"also , check the treatment of missing values . in your spss code , you delete them pairwise . in you r code - . . . ?"
24878,is this homework ?
24877,"what do you mean by "" no result in common "" ?"
24875,is it a linear model ?
24731,"yes , this is straightforward , but it depends on what you mean "" actual regression value "" . also , if you post the code that produced your graph it will be easier for someone to give you a pointer on how to add an eqquation to it ; but as a starter try ?"
24904,are you asking for a * list * of such books ?
24910,"on the mudflat question , how many birds per brood ?"
24912,"i find this question a bit vaguely worded and ambiguous in a couple of places . pinning down precise meanings for terms like "" better "" , "" comparable "" , etc . may guide you to a more easily answerable question . you also talk of the observations being $ a_i $ , but then presumably you also ( somehow ) observe $ a_i cup a_j $ ( for all pairs $ i , j $ ?"
24921,is this homework ?
24980,"it's a little unclear what you want . when you say you just want one result for cor ( matrix1 , matrix2 ) , are you trying to correlate ( all the numbers in matrix1 ) with ( all the numbers in matrix2 ) ?"
24937,does the book have an author . . . ?
25025,what is e ?
24994,"it is noteworthy that the answers reflect two very different interpretations of these data , so a clarification is in order . the reply by matt parker ( and also the edit by chl ) views $ x $ as indicating two groups ( 0 and 1 ) and takes the question as a request to compare the $ y $ values between the groups . the reply by glen_b takes the question as a request to compare the 14 values of $ x $ to the 14 values of $ y $ . * * which interpretation is the intended one ?"
25013,"could you perhaps clarify the distinctions you are making among "" sample , "" "" site , "" and "" replicate "" ?"
25068,"i don't know if you can upload the plot ( sometimes newcomers can't ) , but if not , could you at least add some data & r code to your question so people can evaluate it ?"
25071,do you think the independence assumption is valid ?
5015,"this in indeed a very interesting question , but maybe ( only maybe ) more appropriate for url ?"
25082,"yes , you're on the right track . not sure there's much more to say . . ?"
25086,what do you mean by 'the minimum range' ?
25125,"as ben mentioned , such analyses can be performed using the open-source [ * * r project * * ] ( url ) . i m not sure if i quite understand the nature of your analysis . is the outcome ( score ?"
25134,"what do you mean by "" not linear "" ?"
25139,does each of your datasets contain the same number of samples ?
25155,"it sounds to me like your company already has a model ( that you don't understand ) and that you want to use that model to make predictions and see how good the predictions are . i take it you have not just expected spending , but actual spending for some users ?"
25179,"wenhao . she i would strongly suggest that you , as the human , select the variables that go into the model based on logic and theory . the best a machine can do is data mine . stepwise selection methods are notorious for capitalizing on sample idiosyncrasies . as for your fit statistics , have you considered looking at something like the area under the roc curve ( c-statistic ) ?"
25204,can you say anything about the distribution of the numbers in $ s $ ?
25208,"even if your adviser isn't available , isn't there someone else you can speak to locally ?"
25211,perhaps considering a two-character alphabet will make the difference clear . let the letters be $ h $ and $ t $ . we can ask : ( * * 1 * * ) for what $ n $ do we have at least a 99 % chance of the $ n $ th string being a duplicate of a previous string ?
25235,what is your null hypothesis ?
24209,are the double subscripts in the displaymath deliberate ?
25286,"given that the classical bootstrap can be thought of as a computer-implemented maximum likelihood method ( i . e . a non-bayesian ( flat prior ) technique ) , would it be better to rephrase your question to something like "" when to use frequentist vs . bayesian technique ?"
25291,it seems you want to use some kind of a supervised algorithm ( where class membership is known in advance ) as opposed to unsupervised methods ( like clustering ) . can you confirm that what you are after is simply devising a 'scoring rule' ( prob ( individual i has disease ) ) from all 15 features ?
25309,a t-test does not measure correlation . a t-test tests whether the means of two samples are equal . what types of data have you got ?
25318,"does "" summary ( model1 ) "" deliver what you want ?"
25282,what's your dependent variable in this data ?
25359,"* * this question needs disambiguation . * * does it ask whether ( a ) there are conditions on $ x $ and $ y $ that assure $ tau = 0 $ implies independence of $ x $ and $ y $ or ( b ) there are alternative statistics other than $ tau $ whose vanishing implies independence of $ x $ and $ y $ , not matter how $ ( x , y ) $ are distributed ?"
25391,what about a confidence interval obtained through bootstrapping ?
25415,"isn't what you are looking to adjust for , precisely what you want to measure - i . e . how the probability of "" incident "" increases with the number of patients ?"
25417,which fluctuations ?
25377,"to add to chl's remark : it is not clear what you mean by an "" eigenvalue transformation "" ; one cannot tell whether you are referring to negative eigenvalues or negative random values ; and--most importantly--the purpose and constraints of the simulation are ambiguous , because if you can arbitrarily add "" some factor "" to the simulated data--which changes the means--then exactly what statistical characteristics are you attempting to reproduce with this simulation ?"
25381,what is the connection between the model shown here and the time series ?
25409,could you provide some more details about where you're getting stuck ?
25485,"it's not clear exactly what you mean by "" accuracy "" here . do you mean the probability that the player who wins is the player with the objectively highest skill ?"
25521,this question isn't quite clear . are you interested in estimating the exponential * rate parameter * $ lambda $ and incorporating the final * censored * observation in that estimate ?
25499,"what information are you using to conclude that "" on average , $ a cap b = 1 $ "" ?"
25542,"you have included in your model diagnosis and diagnosis * ef , but no main effect for ef . why ?"
25483,please clarify : are the dvs themselves non-normal or are their * residuals * non-normal ?
25575,"i'm confused , because the difference in sample means is the sample mean of the differences . so why not do a $ t $ -test on whether the mean of ` x1 - x2 ` is different from that of ` y1 - y2 ` ?"
25583,is your goal primarily prediction or some form of inference ?
25593,"i think this is going to be pretty complicated . a couple of additional pieces of information would help . 1 ) do you want practical help generating these , or to understand the ideas behind it theoretically ?"
25611,"cardinal , what are the alternatives then ?"
25615,"could you describe what you are doing precisely ( which dialog box , etc . ) ?"
25599,this model suggests you're only interested in group and interaction effect ?
25661,should your equation be $ a x ^ 2 2b 3 / 2 = 0 $ or $ a x ^ 2 2 b x 3 / 2 = 0 $ ?
25209,"randomizing visitors ( i . e . 50 : 50 chance of control or experimental treatment ) is in general a [ good design ] ( url ) , assuming your experimental treatment doesn't do anything terrible to visitors . also , 1000-200 , 000 is a big range ; is there any reason to think that visitors on quiet / busy days would ( on average ) would be affected differently by control / experimental treatment ?"
25666,what's the problem ?
25704,( 1 ) it would make a fairly challenging homework question : - ) . do you need a general answer or could you ( perhaps ) focus your attention on specific values of $ n $ or $ n $ ?
25712,"once you run hclust , can't you calculate cluster centroids in the original space ?"
25714,"just to make sure i understand the terminology you are using here . . . a "" dynamically consistent "" model is defined as one that is linear in its parameters ?"
25349,"this is an interesting question , but as posed is quite broad . i think it will be asking quite a lot to obtain a concise answer which addresses your question as currently stated . is there a particular form of the problem that is especially interesting to you ?"
25726,"according to the conditions in the first equation , shouldn't the upper limit in your integral be $ p_i $ ?"
25727,"how could you know , that your data comes from gumbel distribution with known parameters ?"
25672,how is julia better than incanter ( url ) and other similar projects ?
25811,it seems there is also a bit of professional chauvinism in your professor's comments . how is being an economist a guarantee of reliability ?
25841,but you say that $ 2 log lambda sim chi ^ 2_d $ . why don't you use this relationship ?
25848,a discussion following a now-deleted reply noted a * * possible ambiguity * * in this question : do you seek the sd of the monthly averages or do you want to recover the sd of all the original values from which those averages were constructed ?
25932,it sounds like you are quoting something . could you provide a reference or link to the source ?
25972,how are the elements in the table sampled ?
26007,"i am thinking of possible numerical issues . let's try to carry out the ` linktest ` manually , but with centered variables . fit your logistic model . then run the following commands : ` predict xb , xb ` , ` su xb , meanonly ` , ` gen xbc = xb - r ( mean ) ` , ` gen xbc2 = xbc ^ 2 ` and then ` logit outcome xbc xbc2 ` ( where ` outcome ` is your outcome variable ) . does it work ?"
26011,can you tell us what this one data point represents ?
26018,"gung's point is still a good one that your term "" multiple linear regression "" is a confusing one in this context . could you re-write your question with terminology closer to that used normally ?"
26020,"this is not quite clear to me . if $ j le w $ then it is possible that no black ball is observed , while if $ j gt w $ then the particular value of $ j $ is irrelevant to the calculation . is your question asking for the expectation conditional on a black ball being observed ?"
26028,i have two questions regarding your training algorithm . 1 . how would you get initial parameters of your hyperplane ( normal vector and intercept ) ?
26060,is your intent for the data to have one row per household ?
26121,"i don't quite understand your second paragraph . do you keep only the minimum and maximum for each interval or do you have other observations , too ?"
26137,have you read the glmrob [ documentation ] ( url ) ?
26144,is there a particular reason you're avoiding using two hidden layers ?
26147,"just so you know , regarding the formatting , it looks like you used the ` code ` format instead of the blockquote , which is why it looked funny . is this copied verbatim ?"
26107,aren't $ v_1 $ and $ v_2 $ the same ?
26141,"some more information would be helpful in coming to an answer . for eg . how do you define your outcome variable i . e "" learning about xxxx "" . is it a simple yes / no outcome or an outcome with several categories or an outcome with some kind of a continuous scale ?"
26176,"the $ r ^ 2 $ is not * necessarily * larger . it's only larger without an intercept as long as the mse of the fit in both cases are similar . but , note that as macro pointed out , the numerator * also * gets larger in the case with no intercept so it depends on which one wins out ! you're correct that they shouldn't be compared to one another but you * also * know that the sse with intercept will * always * be smaller than the sse without intercept . this is part of the problem with using in-sample measures for regression diagnostics . what is your end goal for the use of this model ?"
26170,"whuber , i asked a ( vaguely ) related question here recently url that i found that the distribution of the sample was very far from normal - in fact it was close to uniform . i realise you are talking about the sampling distribution of the mean , but here , don't we just want to know what is the distribution of the sample ?"
26197,could you tell us what you're doing ?
26234,why do you want to do this ?
26276,"if you take exponential of -e , isn't it the likelihood , thus always positive with the same rank ordering ?"
26281,more information would be helpful . is it a sequence of finite alphabets ?
26277,"just to clarify : the implicit model for "" gmr "" is that the dataset $ { ( x_i , y_i ) } $ consists of iid draws from some unknown bivariate ( normal ) distribution . by "" prediction interval , "" then , are you asking about making inferences about the conditional distribution of $ y $ given $ x = x_1 x_2 x_3 $ ?"
26286,"please tell us more about what you are doing . it seems to me that , in software evaluation , a low variance might be ideal ; we want computers to perform consistently . but what is it you are doing ?"
26294,did you see that i extensively revised ( again ) my answer to the original question at url which may render this whole approach of using a contingency table of bin counts not necessary ?
26237,"some more information would be helpful . but , in the case of a t-test , dependent samples usually refer to 'paired' samples ( like before / after measurements on a set of individuals ) . independent samples are just the way they sound . based on anonymous_4322's comment he / she interpreted your question as a matter of a sample of individuals that are independent of each other vs . a sample of correlated data . perhaps you can clarify the context a bit more ?"
26372,is the question aimed at multivariate distributions or multivariate statistics ?
26401,"yes , it's the same . could it be the version of ` lme4 ` and / or ` r ` ?"
26427,"i think you're describing two related , but different questions here - 1 ) how does your respondent space group together to find cluster of participants who behave in a similar fashion ?"
26429,can you be a little more specific regarding * which * arcsine law you are interested in ?
26431,"i'm not quite clear on what your data look like . how does a "" query "" ( in your last paragraph ) relate to a "" sentence "" in the rest of the question ?"
26454,is this homework ?
26473,"if you sample $ x_1 $ twice , does $ mu_1 $ remain the same or does it change ?"
26486,"just to clarify , the same participants replied to the * before * and * after * question ?"
26518,what exactly is confusing your here ?
26541,are you opposed to using a full versus reduced test instead ?
26556,there are different ways to compute degrees of freedom in a mixed model . you can change the method sas uses with the ddfm option after the model statement . maybe using a different method produces the same results as r ?
26585,"following up on giorgio spedicato's answer : are we to suppose that you do want a set of models that treat each dependent variable separately , as ` lm ` does when you give it a matrix ?"
26584,why are you binning the data ?
26656,"in linear models , the explanatory variables are usually assumed to be non-random , so talking about their distribution ( or , indeed , correlations ) is meaningless . are you sure that multiple linear regression is a good choice here ?"
26661,"care to elaborate on what icc ( 1 ) , icc ( 2 ) and rwg are ?"
26650,what kind of model object is this ?
26684,"it seems like a lot of what you have will depend on how representative the photos are of the actual moth population in each photographer's area . do the photographers actively seek out new species , or might they follow their whims to photograph "" pretty "" or "" interesting "" moths ?"
26696,i assume you're familiar with [ stigler's law ] ( url ) ?
26613,note that the ligne repeated is useless here . what did you expect about this line ?
26665,"just to double check i'm understanding your notation , when you write $ [ 1 , x ] $ , then $ x $ is ( presumably ) a positive integer and this refers to the set of values $ { 1 , 2 , ldots , x } $ ?"
26528,"the smoothing parameter is not statistically estimable but is using chosen to maximize out-of-sample fit using , for example , cross validation . i think the standard packages for lasso and ridge regression in r have built in functionality to do this for you - have you looked into that ?"
26733,"i'm interested to know some more background . e . g . , what would be the consequence if your program created distributions that were * moderately * non-normal as opposed to * slightly * non-normal ?"
26635,"spss's two-step clustering procedure may fit the bill . it's hard to tell what you mean by "" considering it as a continuous data stream "" ( is this something other than treating variables as continuous ?"
26741,"moreover i remember i already had a similar problem , but i do not remember well . . . instead of km $ time , try to use sort ( time ) , does it work ?"
26824,are you interested on a [ calibration model ] ( url ) ?
26829,what is y in your circumstance ?
26844,"out of curiosity , why would you bid for emails and who buys them ?"
26874,"i have looked at the data and i am still a little confused . are you monitoring a particular sample / item over time while applying a "" factor "" at each point in time or sometimes not applying a factor or maybe not even observing / recording each unique sample / item at certain points in time ?"
26914,"rolando2 is right . what do you mean "" too many predictions "" ?"
26924,is this homework ?
26978,"what is the nature of your outcome , $ x $ ?"
26987,so you're looking to do outlier detection ?
27007,"the coefficient of variation is $ frac { text { sd } ( x ) } { text { mean } ( x ) } $ . this is the same as $ text { sd } ( frac { x } { text { mean } ( x ) } ) $ . if you square this you just get the variance of $ frac { x } { text { mean } ( x ) } $ , i . e . x expressed in units of $ text { mean } ( x ) $ . does this help you ?"
26933,"with logarithms , it is rare for a multiplicative comparison ( e . g . , "" factor of 10 "" ) to be meaningful . is it perhaps the case that the two procedures return a constant * difference * in the log likelihoods ( for datasets of a fixed size ) ?"
27020,can you post a ` str ` of your data and the call to ` lmer ` ?
27038,that was the first thing that came to my mind too . how big a sample do you have ?
27067,how do you define $ alpha_ { orig } $ and $ beta_ { orig } $ ?
27029,"what does "" a- c -b "" mean ?"
27106,"the corresponding continuous model is guaranteed to remain positive , but the discrete model does not have that property : $ y_t $ can end up negative , and the process is no longer defined after that point . could this be the cause of your problem ?"
27167,can you explain where these distributions came from ?
27212,what function are you trying to minimize ?
27214,what is ` mictrb ` ?
27230,"the expected value does not mean the value that you expect to see on the next roll of the die ; it is what you would expect to be the average value of the outcomes on a large number of rolls . roll the die $ 100 $ times . you are * * likely * * to see a * * total * * of $ 350 $ dots for an average of $ 350 / 100 = 3 . 5 = e [ x ] $ . this is * * not guaranteed * * , you might get some number smaller than $ 350 $ ( in fact the minimum is $ 100 $ , right ?"
27254,can you be a little more specific in terms of data you have ?
27257,"multivariate usually indicates multiple dependent variables - you meant multiple predictors , right ?"
27279,is bartlett decomposition of any help ?
27283,why is there an issue here ?
27341,"given that you only have one case , wouldn't it be best just to plot the two measurements , steps taken and body fat burned , and spot a relationship from the graph ?"
27394,"this is all rather unclear to me - are you saying you have 4 , 449 different time series ?"
27385,"have you considered ` drop1 ( newmod2c , test = "" chisq "" ) ` ?"
27404,what is p ( - m ) ?
27431,"may i ask , why do you care in the first place ?"
26038,"when you say "" calculate "" do you want mathematical formulae , or a way of getting a numerical approximation ?"
27446,are you looking for data entry software ( database ) or statistical analysis software ?
27436,"part of your problem may be that your expression for the log-likelihood has an error - you have $ sigma $ where you should have $ log ( sigma ) $ . also , by any chance did you mean $ { sigma } ^ { -1 } = - frac { { { partial } ^ { 2 } } } { partial { { theta } ^ { 2 } } } log p ( theta y ) $ ?"
27467,this looks very similar to a question you previously asked ( that appears to have been deleted ) . i'm afraid this question is not much clearer than the first time you posted it . some additional detail would increase the probability that you get a good answer - for example - is this a markov chain ?
27455,"nesting the individuals within the replicate their are from , and nest the replicate within the location ( individual / replicate / location ) sounds like a good idea , if compared to the non-nested forms . what does a loess of your six sub-populations look like ?"
27495,community wiki ?
27448,how are you identifying outliers ?
27586,"in your dataset with 132 observations , is there an associated count and offset term , implying it is actually a weighted dataset with many more than 132 observations ?"
27588,is this a homework problem ?
27572,aren't these cumulated frequencies rather than % variance accounted for by each component ?
27554,could you explain what you mean by a 'prototypical plot' ?
27700,you have some outlying residuals . what do your regression diagnostics say about their leverage and how many of them there are ?
27749,how do you calculate $ p_k $ ?
27774,"this is an homework , right ?"
27803,did you ever receive any feedback on this or everyone left you dead in the water ?
27826,are you assuming that the sample size is always even ?
1529,"your question strikes me as oddly worded . you don't "" choose "" residuals . those are given / implied by a procedure / analysis . the underlying model implies certain ( abstract ) error terms , and the analysis produces residuals . in that sense you choose the * analysis * not the * residuals * . maybe rephrasing to "" what type of post-fit analysis of residuals do you use "" may be better ?"
27829,"i think this needs some more context , what is "" this method "" ?"
27950,i suspect poisson isn't the best choice of family . is your dependent variable non-negative integer-valued ?
27951,"also fyi naomi robbins has a very straightforward article on the topic as well that should be of interest , [ when should i use logarithmic scales in my charts and graphs ?"
28006,"is your aim just to be able to do a test including with existing software , or to be able to write a program from first principles ( eg for learning purposes ) ?"
28012,why not use an arithmetic mean ?
28027,where does 60 % coming from ?
27991,"the question is indeed vague , because you do not define what "" similar "" means , and that is a very important point . for example are [ 0 . 99 , 1 . 99 ] and [ 1 , 2 ] "" similar "" ?"
28067,"shalizi likes to be provocative . . . his argument appears to me to be essentially the same as the creationist argument that evolution violates the second law of thermodynamics because "" later "" organisms are more complex , in an organized way , than "" earlier "" organisms , but the second law says entropy is nondecreasing . however , 1 ) there's nothing in the second law that prevents local decreases in entropy , and 2 ) the argument implies no-one can learn anything about anything , ever ( why should learning via bayesian updating be any different than any other learning process ?"
28086,"i don't have access to that volume at the moment , but if you provide a little more detail , we can tell you how to make it . specifically , do you want 2 figures side-by-side , or several boxplots in the same figure ?"
28115,i guess simulation is always a possibility but if you have the values for all the observed independent and dependent variables and you assume a gaussian noise term you can directly compute the variance of the estimated y . are you looking for a situation where only group averages are available ?
28121,would an analysis geared toward * mixture designs * fit here ?
28186,"let me add this : what precisely do you mean by "" impossible to compute "" ?"
28190,"lower variance in the predictor leads to larger standard errors - they are exactly inversely proportional in a least squares model , but are only generally inversely related in glms like a logistic model . in the extreme case where you have no variance in the predictor , the effect is not estimable . is this what you were asking about ?"
28199,"re : "" is there an easy way to determine what is 'wide' or 'narrow' in this context . "" - what exactly is "" this context "" ?"
28202,msh210 are you still interested in the answer to this question ?
28229,"are you interested in the full covariance matrix or just the variances of the elements of the resultant vector ( i . e . , the diagonal of the covariance matrix ) ?"
28242,"aov has a strange way of indexing it's information . is "" summary ( aov1 ) [ [ 1 ] ] [ [ "" pr ( f ) "" ] ] "" what you're after ?"
28251,"so by "" highest value "" you mean the longest run of increments in the sequence ?"
28178,aren't the two expressions algebraically equal ?
28289,do you have access to previous auction results for product x ?
28290,"look very carefully at the covariance matrix . very , very carefully . look at the numerical values . . . what do they tell you about the relationship between $ x $ and $ y $ ?"
28298,"i'm not sure i understand the question : if you have 10 data points for each iv , what's wrong with regressing all ivs , including the non time-dependent , against the 10 dvs ?"
28233,cardinal : perhaps nick meant folded-normal ?
28337,do you basically want to estimate the distribution of the inter-arrival time between threads ?
28349,"i think you meant to compare the "" vocab size of parents to the vocab size of their children "" ?"
28368,* * hint * * : what is the definition of * symmetric * ?
28382,i think n is the number of trials which represents the number of times you generate the results of the investment plan . why do you need simulation ?
28413,"well , for one thing , the average income probably does not include children , while the average family size does . also , is that the average income of people who work , not including unemployed ?"
28431,"how about a histogram , a kernal density estimate , or a violin plot ?"
28419,"do you need to know about fa , or only how to get one from ` r ` ?"
28515,what's your sample size ?
28566,"one thing to bear in mind is that you need to specify an error distribution . in addition , i don't completely follow your "" p . values "" or "" f_value "" lists ; is the idea that the sampling distributions of f & p be centered on the listed numbers ?"
27033,this question is too vague . what kind of confidence intervals ?
28573,what have you done ( other than finding a solutions manual ) ?
28576,have you got as far as reading the data into r to make a data table ?
28633,does [ this ] ( url ) help ?
28658,"is $ n $ , the number of points , fixed ?"
28630,what does $ x_j $ denote ?
28681,$ beta $ is the vector of regression coefficients - does that clear up the confusion ?
28664,"how many regions and observations do you have , roughly ?"
23963,what software are you using ?
28714,what about shreve's stochastic calculus 1 and 2 ?
28702,what makes this a non linear model ?
28721,"the term empirical distribution refers to the sample distribution for the discrete set of n observations . if you have n observed values xi i = 1 , . . . n then the sum is just a single number . so what do you want from it ?"
28729,"when you say it looks like it follows an exponential distribution , are you referring to the time between visits ?"
28730,"yes i agree with procrastinator , and the interaction questions are essentially the same consideration . we have a [ few highly voted questions ] ( url ) on the topic . in addition to pro's suggestion , see also [ do all interactions terms need their individual terms in regression model ?"
28748,why do you claim p ( no car in 5 minutes ) is . 5 ?
28755,are you looking for a list of all possible transformations on the predictors ?
28601,"i'm guessing your dependent variable is "" time "" , can you say more about that ?"
28760,what if you play with the keyboard ?
28756,do you mean to say that you have 61 numeric characteristics and 7 character valued charactersistics ?
28832,perhaps there is something in the middle here . . . what about a multinomial classification ?
28881,are you asking for the sample variance as observed or some measure of the expected sample variance or something else ?
28903,what does the notation $ f ^ { * 2 } ( x ) $ and $ overline { f } ( x ) $ mean ?
28904,you can treat the topic mixture vector for each document as its position in this latent topic space . simply run your clustering using this as the input data . what is the point of the hard clustering though ?
28898,the prior is gaussian . do you have the actual book ?
28916,is $ y $ always a square matrix ?
28942,"just to clarify , what sort of spatial data ?"
28987,didn't know there is stats - would anyone move / migrate my question ?
29005,what exactly is perturbed in these simulations ?
29020,"take $ s = t 0 $ , then the left side becomes $ int_0 ^ s dfrac { bar f ( s-u ) } { bar f ( s ) } df ( u ) $ . adding this and the second term in the right side you get $ int_0 ^ s dfrac { 1 } { bar f ( s ) } df ( u ) = dfrac { f ( s ) -f ( 0 ) } { bar f ( s ) } $ which is not equal to the remaining term . am i missing something ?"
29038,have you considered beta regression ?
29051,is this a homework problem ?
29058,"what's the matter with just allowing $ theta $ to lie in $ [ 0 , 360 ] $ ?"
29083,what part are you struggling with ?
29052,are the $ x_i $ independent ?
29019,"is the example data for different postings of the same item , part # 015-p3-1580-ar ?"
29133,what are you doing with the data ?
11508,"could you elaborate on the models that you are considering , and how the error term assumptions deviate from the data ?"
29179,"could you get to the same result by first clustering with k-means , then constructing your 'groups' by taking m points from each cluster ?"
29170,"i don't see the problem here . you can't take the difference of two data sets , only the difference between a function ( like the mean ) of one and the same function of the other . if there's some reason to disapprove of the mean ( which i don't understand yet ) , there are other options ( like the median ) . the standard error of the mean difference is the denominator of the t-test , which you can find anywhere . can you state your final goal & why you don't want to work w / the difference in means / t-test ?"
29201,( 1 ) perhaps they were expecting you to mention the [ approximation ] ( url ) using $ i ( hat theta_n ) $ ; ( 2 ) are you sure it is rao's * * or * * wald and not rao's * * and * * wald ?
29222,why do you want to $ log ( cdot ) $ this model ?
29200,"what precisely do you mean by "" stepwise regression "" ?"
29279,when you say $ x geq 0 $ does this mean each element of $ x $ is $ geq 0 $ ?
29281,should that second $ overline { f } _1 $ in the first line be an $ overline { f } _2 $ ?
29328,did you know that $ a ^ x $ is * defined * as $ exp ( x log ( a ) ) $ ?
29389,"why would you compare means and covariances between models , where one is such that you know it's true ?"
29400,have you tried adjusting the weights vector ( ` w ` ) to achieve this ?
29415,what is the purpose of your study ?
29430,"are the $ n $ stones drawn out all at once , as a group , or are they drawn one at a time and replaced each time ?"
29396,"the "" with replacement "" makes this a classical multinomial distribution problem . is this homework ?"
29468,are you sure it is not $ sum ( y_i- hat { y } _i ) ^ 2 $ ?
29497,you mean a sum of a sequence of independent rvs ?
29466,are the numbers in a randomly selected from the positive reals ?
29510,"you call both of your random variables ( i . e . , your events ) x , but it might make more sense to call one y . then we can ask , are x and y independent ?"
29560,is that roughly what the table is supposed to look like ?
29589,can you upload the data and a plot ?
29563,"the residual standard errors , in combination with the other information , make it look as though the ` rlm ` weight function is throwing out almost all the observations . are you sure it's the same y in the two regressions ?"
29590,"( 1 ) you implicitly assume correlation is the way to "" examine the relationship . "" why is it of interest here ?"
29625,"this is matlab code , isn't it ?"
29628,"if you are using a valid semivariogram , you should never run into these difficulties . however , for certain data configurations and certain variograms you can get * close * to singular matrices . ( i have never seen kriging software that uses a pseudoinverse--that would be appropriate only when data fall on a regular grid or when all data are used at once ; directly solving the system $ ml = g_s $ is more stable and far more efficient in most applications . ) what semivariogram are you using that causes problems ?"
29646,patrick i don't understand who and what are you talking about ?
29669,so you want a sample of size 1 from the probability distribution of each row ?
29681,"are the three quantities you call x , y and x measured in the same units ?"
27322,i'm not observing this in my simulations . can you paste your code ?
29702,"i don't really understand your question . in your supplied code , is each row a "" sample "" or a "" data point "" ?"
29743,are you sure you did not miss a $ 20 $ in your data set ?
29765,how can there be a dependence that is not due to causality ?
29760,"by saying "" between for different properties "" , do you mean "" between four different properties "" ?"
29785,"could you describe exactly how the parameter "" don't make a lot of sense "" ?"
25952,just to clarify : do you have any hidden layers of neurons ?
29834,have you noticed that this model for $ y ( x ) $ is not a good fit to the values you give ?
29836,"whuber , what do you mean by "" theoretically , a pdf has no value at any given point "" ?"
29876,"hmmm , could you print those results with fewer sig figs ?"
29916,can you clarify what your actual goal is ?
29918,for question 1 : in ` ?
29980,what is the form of $ f_ beta $ ?
29987,"this is a dot product , right ?"
30009,"what do you mean by "" reasonably tight "" ?"
30041,"you shouldn't expect a simple relationship between $ e ( y x ) $ , which is estimated by the first model , and $ e ( x y ) $ , which is estimated by the second model , as gung has pointed out . also , can you please clarify what you mean by an "" endogenous variable "" ?"
30069,"what do you mean by "" tiny example "" ?"
30054,the approach you mention seems to be a form of the method of moments with restrictions on the higher order moments . is there some reason that maximum likelihood does not work for this parametric model ?
29986,logistic mixed effects models seems like an extremely advanced topic for high school . are they part of your high school syllabus or are you studying independently ?
30129,how much flexibility in your coursework is there in your masters program ?
30190,"is there a particular reason you're using ` nlme ` rather than its successor , ` lme4 ` ?"
30228,"do you choose the words you suspect of being over-represented based on looking at the data , or do you have a hypothesis developed beforehand you want to check ?"
30237,"not my area , but are [ low-discrepancy sequences ] ( url ) any use ?"
30109,( i ) what are the possible values that $ y $ can take ?
30000,because this is one of the best approaches imaginable--you only have to decompose the 3 by 3 correlation matrix once and linear combinations of simulated random fields are fast and easy to compute--why do you seek a different algorithm ?
30272,is your dependent variable continuous or discrete ?
30251,what is the nature of your response variable ( dependent variable ) ?
30303,why do you want them to be exactly like the published results ?
30328,"re "" clearly this is less than "" : this statement appears to be equivalent to asserting that the ols estimate of $ sigma ^ 2 $ is * biased * ! am i missing something here ?"
30339,yes i think you should be concerned about this . why are you using an estimated coefficient for another variable on a new variable ?
30343,why can't a difference of 0 . 5 be significant ?
30436,"when you say "" $ a $ could be given "" , do you mean it is specified by the user or it is estimated by the model ?"
30457,"would solving up to proportionality be permitted , or is this one of the cases where you need to explicitly calculate the normalization constant ?"
30474,i don't understand why you want to do this . using a model instead of real data means that you have tremendous confidence that the model is correct . what is the classifier doing to categorize the time series ?
30483,"this may be a difficult search , cardinal . given that the solution is best expressed in terms of stirling numbers , i [ searched for such threads ] ( url ) , to no avail . did you have a particular set of keywords in mind ?"
30397,"i am having difficulties to understand your question . why does your title refer to "" multivariate anova "" but your question not ?"
30527,i don't think that i understand that behavior . have you tried to do that in 1d ?
30545,"just to clarify - the "" minimum distance was about 3 . 9km "" is from memory , right ?"
30525,how can nominal variables be correlated ?
30574,"ok , thanks . please tell us whether this is a correct interpretation : given a known stochastic matrix $ q $ and a confidence interval for $ vec { p } $ based on multinomial observations ( with about $ 1000 $ classes ) , you wish to compute a confidence interval for $ left ( q ^ t diag left ( vec { p } right ) right ) ^ { -1 } vec { p } $ ?"
30633,"the nmf is not , in general , unique , so some or all of the parameters may be unidentifiable . why should you , then , expect to get confidence intervals for them ?"
26688,online as in * growing * timeseries or as in * additional * series being added ?
26145,are you looking to see if the average scores on your test will increase after your learning module ?
30643,where do you get hung up in the derivation ?
30609,is the three-way interaction term in that second model necessary ?
30764,i don't think you meant to refer to mutinomials did you ?
30778,do you have the number of trials the proportions are based on ?
30773,yes but does degenerate mean the probability distribution is concentrated at 0 or some other value . if it is 0 then they coincide in the sense that the functions are the same with probability 1 as procrastinator states . but if it is a constant different from 0 then of course the two models always differ by that constant ( a bias existing in the case of the stochastic model with the degenerate distribution ) . can anybody tell me what the significance of this question si ?
30728,why are you taking $ log $ of the observations / variables ?
30809,"i am confused : first you say you want to calculate an average , then you deny that the average is meaningful ( by pointing out problems with it ) , and finally you say you can't even get enough information to compute an average . what exactly do you want to do and what kinds of data do you have available , precisely ?"
30813,how many observations do you have available ?
30829,"you do not provide enough information to show how a regression model might be applied : no covariates or explanatory variables are mentioned . in the same vein , what would a pca or factor analysis show ?"
30835,"you've presented a sort of abstract formulation but is there a concept of a "" null "" model , say , $ m_0 $ , that reflects a believe that non of the parameters are useful ?"
30868,from ` ?
30247,"david , this problem sounds like you want to do a variance decomposition on a multivariate outcome but the title seems to indicate you're after something else . can you clarify ?"
30842,"independence of what , precisely ?"
30876,how have the coefficients been standardized ?
30886,do you mean you have several random effects and that you assume all of them to have the same variance ?
30936,can you describe the context a bit ?
30649,do you have any additional constraints on $ a $ ?
30954,what is 72 % ?
30986,"intepretable coefficients are highly overrated . nevertheless , have you tried principal feature analysis ( url ) or convex principal feature selection ( url ) ?"
31014,is the value of the paired difference exactly the same for every pair ?
30766,"the code you've written fits the model that has season and clipf as fixed effects as well as a random intercept shared by those with the same value of controlf , and a random slope in seasonf that is shared by those with the same value of controlf . is this what you intended ?"
31034,is this homework ?
23536,"i think this is * exactly * the "" method described elsewhere "" , just in disguise . * * hint * * : what do you know about the poisson process ?"
30604,"some of your parentheses are off , can you please fix them ?"
30815,"it would help if you can write out the model equation ( s ) . also , how are you fitting this model ?"
31080,"luna , i tried to fix this up so that it is readable ( in its previous state it was extremely difficult to tell what was being asked ) . i tried to transcribe your estimating equation verbatim but i'm not sure i did it correctly since what is there now is difficult to make sense of - what argument is being minimized over ?"
31108,"for the purposes of this question , are you only interested in the association between ` x1 ` and ` x2 ` ?"
25325,it might be a case for non-linearity . can you show a plot of fitted values vs . residuals ?
31167,have you take a look at collombier's or tinson's books ?
31122,"when you say "" if we know absolutely nothing about $ f $ "" , what do you mean exactly ?"
31197,"i assume that you measured reliability using something like cronbach's $ alpha $ - which actually does not measure reliability , but internal consistency . a low internal consistency does not necessarily mean that there is low reliability . for example , in [ formative measures ] ( url ) , you can even get negative internal consistencies , while the measure itself can be highly reliable . could you post your items ?"
31208,have you considered competing risks ?
31233,clarifications : ( 1 ) are the categorizations of the targets and delivery methods already available ?
31278,"sorry to be skeptical , but if it isn't a homework question then what is the context ?"
31276,have you ever heard of the geometric distribution ?
31317,what role will that biomarker play in subsequent analyses ?
31326,are you specifically interested in the rating context ?
31299,how many data points do you have ?
1386,is there a reason that prohibit the use of the welch t-test ?
31322,"while i agree that gwas studies involve many statistical tests , how do you get $ 10 ^ { 13 } $ ?"
31394,"a key to a good answer may lie in understanding how the "" various issues "" leading to missing rts could influence the analysis . could you then perhaps provide some information about the reasons for missingness ?"
31395,you can certainly have group ( school ) level predictors in the model - is that what you're asking ?
18152,homework ?
31329,does the ` total sales ` column represent the total revenue of each entity from yo-yos ?
31391,"when you say 1 to 4 scale , do you mean a single item with four response option or do you mean the average of many items on a 1 to 4 scale or do you mean something else ?"
31354,"that's right , michael : but are you then implicitly agreeing that temperature or sea level series truly are "" random walks "" ?"
31478,"i don't understand the point of this implementation . why are you trying to do this in "" real time "" ?"
31501,"what do you mean by "" defined a priori "" and "" fixed a posteriori "" ?"
31492,"this is a comment and not an answer , but this is what would make some sense to me . you get estimates which are probably the values for which the posterior distribution is maximized . it might also be possible that they are just the means of the posterior ?"
31576,is this paired binary data ?
31190,did you calculate the variance considering the two possible ways to see if they differ greatly from each other ?
31591,"ever heard of [ "" six sigma "" ] ( url ) ?"
31553,"could you please explain what you mean by "" distribution of student questions "" ?"
31633,a p-value is always computed in relation to a hypothesis . what is the hypothesis that you wish to investigate here ?
31636,what is the null hypothesis ?
31689,how do you intend to interpret this average density ?
9016,berkay how do you define an error rate for this unsupervised method ?
31705,"you mention predictions prominently . are you developing this model primarily to use in the future to predict unknown response values , or do you want to better understand the relation between your covariates and the response variable ?"
31708,"what is the "" original pattern "" that you seek to preserve or not ?"
31714,"based on some of your other posts , you know how to markup equations . the text equations here are difficult to read and the ( subscripts ?"
31690,"luna , why is that wrong ?"
31749,are you just trying to compare the proportion that perform the action in one variant compared to the other ?
31764,i'd say they form much stronger * vertical * than horizontal lines . scnr . and can't you just use the number of values you have for each ` x ` value as the number of clusters ?
31771,"i have edited your question to make it easier to read . please , check everything is ok . regarding your question , in what sense would you extend your procedure ?"
31755,"i just want to add to all the other answers that your first statement is wrong : * * you have not conclusively shown that the means are different * * . a t-test's p-value is telling you whether the probability of observing your data or more extreme values of it is likely / unlikely * given the null hypothesis * ( which for the t-test is $ mu_a = mu_b $ , i . e . , $ h_0 $ : { "" the means are equal "" } ) , * * which does not mean that the means are , in fact , different * * . also , i assume that you also performed an f-test in order to test the equality of the variances before doing the pooled variance t-test , right ?"
31772,of course ; there are * lots * of them ! what other properties do you want ?
31590,"not all those samples are similar : the second snoring sample is sorted . please , then , tell us more about what these numbers mean and how they were collected . are the numbers lengths of pauses ?"
31800,"note that "" succinct "" & "" depth "" are pretty much contradictory . you should clarify this ; eg , if you found the ideal book , roughly how long would it be in pages ?"
31807,if you could provide more information about y maybe we could be of more assistance . in short tailed cases the nonnormality is not as severe a problem as in heavytailed case . have you tested your regression model on data that wasn't used in the fitting process ?
31833,what is pca in discrimination analysis ?
31837,"* "" it's not the case "" * - i don't understand what you are trying to say here . can you re-phrase ?"
31937,that's right . did you have it that way to start ?
31952,what are you trying to achieve ?
32007,"could you explain--with some detail--what it means to you for one line to be "" significantly higher "" than another ?"
31449,thanks for the large amount of detail . how does the null model come into the question ?
32063,""" i realize that writing code to do this would be relatively straightforward "" . ah ?"
32072,response times to linguistic input are often done with repeated measures . how many subjects in this experiment are there ?
32080,"the quoted text seems like . . . well , like a quote . where is it from ?"
32093,have you considered the 'polygon ( ) ' function ( url ) ?
32038,"do you have access to the paper referenced by c . pallier , [ measuring recognition memory ] ( url ) ?"
32099,"the predictors a , b , c , etc . have to mean something . what could you sensibly be comparing ?"
32130,"i'm confused . doesn't ` 4iii ` say that ` p ( r ) , p ( c ) , additivity = p ( x ) ` ?"
32134,"yes , and i directed you to a step-by-step derivation of expression 3 from expression 2 in an answer to a related question . at what point in that answer would you like some clarification ?"
32186,at first glance this seems like a very roundabout and probably inefficient way of performing parameter estimation ; can you give any intuition as to why you might prefer a simulation-based approach over e . g . [ maximum likelihood estimation ] ( url ) ?
32179,can we assume that all instances of overall_tumor_grade = = 'x' also have tumor_size = = 1 ?
32187,"i don't see "" ?"
32255,since a treatment is unique to each site can't you just use ` i ` to index both ?
32284,"we're happy to help , but is this homework , or what is the status exactly ?"
32282,am i understanding correctly that your $ y_i $ 's are univariate ?
32319,"` the regression test yields no result ! ( i receive only 0 values ! ) ` this remains mysterious , can you add more details about the problem ?"
9315,"what do you mean by "" predicting the topic of a new document "" ?"
31947,what did you set the burn-in to ?
32416,what do you mean by 24 / 60 8 / 60 etc ?
32425,"are you analyzing a sequence whose length is changing or are you just considering the last , say , $ k $ elements ?"
32435,"no [ question mark in the title ] : only the re-descending behavior matters from a bdp point of view . yes [ first question mark in the text ] , from an irls point of view this loss function is not more difficult than , say , huber's . no [ second question mark ] , there are other asymmetric $ m $ functions and these could be solved by irls ( although in practice they are not ) . but i'd be remiss if i didn't ask : what are you trying to achieve ?"
32463,"what do you mean by the "" huber loss weights "" ?"
32519,"since you are simulating , do you know the true hazard ratio ?"
32523,is the outcome whether or not the gene is expressed ?
32524,` but perhaps there is an effect ( or : a bigger effect ) on today's svi and tweets and tomorrows tradevol ` this was not quite clear meaning to me . maybe there're typos ?
32541,what makes you think that you can assume the number of adults ?
32531,maybe a better fit for cross validated ?
32564,"can you write a python script that will recode your ` speaker ` variable into a set of new variables ` speaker1 ` , ` speaker2 ` , ( etc ) , with some instances where more than one variable has a 1 in it ?"
32584,"i can't follow this question . eg , "" under both models i get the same estimated variance per each covariate "" , does that mean the beta estimates are the same , or the se's are , or what ?"
32566,"your first sentence makes me wonder exactly what outcome you're modeling and where exactly the repeated measurements are coming from . it sounds like your repeated measurements are just the left and right hand binary outcomes for each person . or , are the repeated measurements the two different tasks , with the left / right measurements collapsed to a single binary outcome ?"
32634,regarding your update . 1 ) i can see no point in doing this . arima ( ) will produce the fitted values and forecasts . why should i produce additional r code to do the same thing as arima ( ) already does ?
32632,"i'm having trouble following this . first , do you have 100 or 1000 variables labeled "" y "" ?"
32651,when you say you want to * say i wanted to investigate the proportion of different types of nuts in bags of mixed nuts * - what do you mean ?
32653,"ok , it wasn't clear there were interactions in the model - i suppose the final three terms in the second model are the interactions ?"
32673,how large are $ n_1 $ and $ n_2 $ ?
32661,the last paragraph does not make much sense . what is meant by the notation $ mathrm { pr } ( x ( t_1 ) ) $ ?
32672,you need to explain first what you want to do . are you looking to draw samples that are normal distributed in euclidean x-y-z space and convert the result into spherical coordinates ?
32697,how have you used pca to initially developing the questionnaire ?
32246,"to get a better idea of the potential difficulties you are encountering , what are typical and worst-case values of $ p $ ?"
32659,are you saying that both the numerator and denominator means are much greater than zero ?
32715,what does it mean to measure the volatility of a stock at a particular point in time ?
32781,"well , it appears quite curvilinear , isn't it ?"
32733,do you have access to any linear programming software that can solve integer programming problems ?
32790,it might help to get a little more information . is your response variable continuous ?
32756,i take it that you're wondering how to do this in matlab ?
32810,can't you simply do a mutliway anova ?
32805,can you give us a link to the paper ?
32816,what is your sample size ?
32825,"i'm thinking that your concern is that the scores are ordinal data instead of interval , is that right ?"
32826,did you normalize your data before running pca ?
32852,the data do not appear to be the same as the plot . ( where is the 42 in the data on the plot ?
32848,"what are you trying to learn about , tim ?"
32439,did you use warnings ( ) as suggested ?
32880,can you tell us more about your problem ?
32616,just to help understand the problem - why do you care about range restrictions but not so much about variance ?
32896,do you have a single model with the 4 covariates ?
32850,"in proposing a $ 2 $ by $ k $ table you suggest there is some importance to assessing different values of $ i $ and $ j $ . however , your statement of the question does not imply any need for that . this makes me suspect there's more going on here than your abstract description would suggest and that the details may be important . could you share with us more information about how these data are obtained and what the values of $ i $ and $ j $ might mean ?"
32921,"hi , max , that seems to be exactly the answer to this question . would you mind making it an official answer ( possibly elaborated a little more , i gather the op won't be familiar w / that ) ?"
32694,how many geographic regions do you have ?
32913,kris my thinking was that with six unknowns you couldn't construct enough equations to solve for all the correlations . but i forgot to consider the f statistics . how many f values do you have and which tests are they being used for ?
32991,"can you quantify what you mean by "" $ theta $ is moving smoothly and slowly ?"
33025,"one note . what is the effect of rotation in your 1st command , there being only 1 factor extracted ?"
32971,"for the record , this question is related to [ how do i conduct model selection for logistic regression in spss ?"
33053,what language or software are you planning to work with ?
33066,you don't explain your objection to the ( quite intuitive ) ` general idea that any link between the original dissimilarities and the cophenetic dissimilarities could be related to the suitability of the classification ` . classification should reflect original dissimilarities . dendrogramic classification's basic feature to do this is via cophenetic dissimilarity . is there smth . wrong ?
33002,"i'm not clear what you mean by "" live "" here . are you talking about testing data on-line as they come in ?"
33078,"could you crudely filter the data to isolate the two trendlines , then use those trendlines on the whole dataset to identify points on the trend less crudely , and separate the dataset on that basis ?"
33105,how many observations do you have ?
33101,"off-topic : just out of curiosity , why do you think winbugs fails at fitting dirichlet processes ?"
33141,how are you estimating the icc ?
33148,why are you using chaid ?
33155,have you tried specifying the weights in the predict function ?
33133,michaelchernick are you sure about the meaning of exactness ?
33177,"are the features binary , tf-idf . . . ?"
33180,"when you say "" the distributions are overlapping "" do you mean that they are the exact same distribution or that their support ( the range of possible values ) is overlapping ?"
33204,note that you can still standardize data that is not normally distributed - the question is whether or not the number of standard deviations from the mean ( which is what you get when you standardize a variable ) is meaningful for your data . what is your purpose for doing this standardization ?
33189,hi luna - ok but there is no mention of weights in this post . what kind of weights ?
33231,is there a reason you can't simply correlate the two variables w / o categorizing them into quantiles first ?
33234,"rushdi , it then reads ` although it s unlikely that you know sigma when the population mean is not known , you may be able to determine sigma from . . . a pilot test / simulation ` . is that not clear ?"
33236,"are you saying that the iv & dv correlate , but when you add in the mediator they no longer correlate ?"
33260,"jbowman , why don't you convert your comments into an answer ( since that's what they are ) ?"
33297,"gung , i think onestop's answer to the linked question gets directly at the question posed here - * how do i interpreted the results with the two ln ( size ) variables ?"
33286,"this may be just me but i don't know what you mean by "" estimation theory "" - could you give a reference ?"
33337,"so , presumably $ mu $ is known * a priori * ?"
33377,"this question didn't completely make sense to me . please make sure it still asks what you want to know . further , can you provide more detail about your data & what you want to know from it & thus , what you want to know from us ?"
33380,did you read the vignette ?
33324,"although you describe a * procedure , * you haven't yet told us what it is for . i am concerned because there are several statistically suspect aspects of this procedure ; likely you need an alternative . could you back up and plainly explain to us what you are trying to learn about these data ?"
33379,"so to confirm , you are asking about how to compare model fit when the models compared have heteroscedastic errors ?"
33165,could you add the fitted line plotted on the original data as well ?
33381,what do you want to test about them for different ?
33414,rocr is not bound to a specific model . the only information you need are the true labels and the predictions of a model . can you please provide some code and tell us where exactly you get stuck ?
33467,"before proceeding i have a few clarification questions and comments . one problem i see is that you have duplicated trial numbers for each participant . thus , although each participant completed 80 trials , you have 1-40 twice . a trial number should be a unique identifier . also , is it the case that each of the forty sounds you have represents a separate manipulation or emotion ( which is what you are testing if you included 40 levels of the iv ) or are they grouped into the 5 emotions you mentioned ?"
33435,"in the end , it all comes down to the philosophy of "" what you believe in "" ( yes , in science we also have to believe in things ! ) . you think probabilities refer to long-run events ?"
32527,"is $ sigma ^ 2 $ a "" nuisance parameter "" or is it of particular interest ?"
33477,"could you please provide an explanation of what "" left "" and "" right "" sds are , either using conventional mathematical notation or in english ?"
33450,"i might be understanding this incorrectly , but do you mean you have a binary classifier where all the outputs are equal ?"
33549,doesn't your second displayed equation have a typo ( should be tn instead of tp in the denominator ) ?
21541,"there are numerous methods for sensitivity analysis among which some of the most popular are morris' screening method , variance based sensitivity estimation ( sobol' method ) and use of meta modelling . you should provide more information about your ` process ` to narrow the choice of tools . is it deterministic or stochastic ?"
33749,did you run it both for $ h_0 $ true and for $ h_1 $ true before computing the rejection rate ?
33765,snow_leopard what is a valid keyword ?
33768,forced by coauthor's quirky use of stata ?
33785,your q title mentions centring constraints but then you discuss identifiability constraints in the body . are you interested in both or just the latter ?
33823,"have you looked into using [ coherence ] ( url ) ) ( in the signal processing sense , not the statistical ) , a cross-spectral measure ?"
33639,"you've analyzed the data as if it were from a completely crossed design , with each of 20 people rating all 7000 comments , but i can't find anything in the writeup that rules out a nested design , with each of the 7000 comments rated by a different set of 20 raters , or something somewhere in between , some sort of incomplete block design . how did you decide that the design was completely crossed ?"
33857,typically $ { bf beta } = { bf 0 } $ works well when there are no collinearity problems . could you provide more information about the sample size and the number of covariates ?
33777,"hi james , welcome to the site . i tried to edit your question a little , make sure it still says what you want . re annualizing the "" standard error "" , do you mean the * standard deviation * ?"
33873,what is this mdd ?
33829,"katarina , what exactly would be "" inappropriate "" in comparing 20 patients to 1200 controls ?"
33878,is this not what gls in nlme does ?
33933,i don't understand the use of the term concatenate in 1 . do you simply mean pooling all the subjects into one large sample of x-y pairs ?
33947,why not just use run-length encoding ?
33961,i don't understand your plots . could you give more info about the data ?
33808,don't you mean an inverse-gamma likelihood and an inverse-gamma prior ?
33985,"what exactly are you wanting to predict , whether or not the bone breaks , whether it's loose , medium , or tight , or the amplitude of the frequency ?"
33998,* * hint * * did you notice that stata has omitted ` industrym ` ?
33848,"well , umvu estimation is a classic idea so should maybe be teached for that reason ?"
34017,if you are looking at clusters in k-dimensions aren't the centroids k-dimensional ?
34033,"could you explicit what you mean by "" i calculate the mse for variable two and three where the third variable is my ground truth "" ?"
33796,"just to clarify , when you say "" irregularly-spaced "" you don't mean "" regularly-spaced but with missing values "" , right ?"
34052,what is your null hypothesis ?
33862,i agree with rioraider . how do you know that the forecasts should not be higher than historical values ?
34072,"martin , there's no question or ambiguity about the quartiles here , because they would comprise the first and second smallest , the third and fourth , and so on , giving ( { 1 , 1 } , { 4 , 4 } , { 4 , 4 } , { 8 , 8 } ) , from lowest to highest . when the amount of data is not a multiple of four , however , then ( somewhat ) arbitrary choices have to be made . but what are the definitions you have read ?"
34076,re # 2 : url re # 1 : useful for what ?
34094,what have you done to try to answer this question ?
34100,what test do you have in mind ?
29009,this question is rather unclear . are you asking how the observed nodes in a bayesian network affect the probability of the unobserved nodes ?
14832,it would be helpful to have some context : where do the data come from ?
34119,"you say "" but it seems to require the whole data from which the parameters were estimated , which i don't have "" . do you have the individual responses to the items ?"
34071,"parts of this question are confusing , because initially it sounds like just one "" weighted powder bed "" is involved , and therefore the number of particles in it is * known * ( "" a precise counting of the particles [ was ] done "" ) . what would be the point of combining the two rsds then ?"
34136,"welcome to the site , boo . do you see this question as having statistical content , or * only * about how to get this done in r ( ie a coding question ) ?"
34163,"maybe i don't know enough about the analysis of genotypes , but i find it hard to follow this question . the first thing that occurs to me is to use whatever method works for you with individuals , & use that with the group centroids . have you tried that ?"
28321,"welcome to the website , charlie . and by "" compare "" you mean what ?"
34185,additional hint ( following cardinal ) : the cauchy-schwarz inequality is easily proven by observing that $ 0 le text { var } ( x-y ) $ and expanding the right hand side . what can you conclude about a random variable whose variance is zero ?
26828,can you please clarify exactly what your question is ?
34204,why isn't the size of the training sample fixed ?
34255,"irt won't let you uncover 'good' items to devise a scale easily . first of all , you have to identify the dimensionality of your questionnaire , and apply basic item-level analysis ( item difficulty , discriminatory power , item-scale correlation ) and test-level analysis ( reliability or internal consistency ) . second , be careful with $ chi ^ 2 $ tests as they will be impacted by large ( or low ) $ n $ . third , adding extra parameters to your model ( discrimination , and / or guessing ) should be motivated by theory , and not data driven . could you perhaps tell us more about item content / wording and the examinees ?"
34242,"could you please explain what "" intelligently "" means ?"
14539,can't you just replace ` as . matrix ` by ` as . dist ` ?
34238,"hi cel , it looks like you've got * all * interactions in the model , including the 5-way , 4-way and 3-way interactions . i'm not sure about this case , but that will typically wildly overfit the data , which will make your results less generalizable . backward selection ( if you must use it ) does not need to start with a completely saturated model - it should start with the largest model you find plausible . can you reduce that at all ?"
34277,"so , each company was either online only or paper only ?"
34289,how did you calculate the 95 % confidence interval and what is the sample size ?
34304,what do you mean by growth / recession . why not just compute the 14 day percent change in your indicator and the relative difference between the two ?
33967,"when you say "" adjust their architecture "" do you mean the parameters ( weights , biases ) or updating the actual structure of the network ( hidden nodes , activation function , connectivity , etc ) ?"
34325,"where do they use ` glm ( ) ` then ` lm ( ) ` in the chapter you link to . seems to me the ` glm ( ) ` is all that is required and used there , but i may have missed something . you can try generalised least squares ( ` gls ( ) ` in * * nlme * * ) which allows weights to be estimated to control for the type of heteroscedasticity you mention ; see ` ?"
34332,"by "" plot "" , do you mean area of land within which you will count the birds ?"
34279,"have you tried the default ( and generic ) way , i . e . calculate mpeg4 descriptors and cluster ?"
34423,how are you estimating these parameters ?
34430,can the same patient have both diseases ?
34463,are you asking about a * linear combination * of normals or a * mixture * ?
34414,should it be something like : ` ff1 = exp ( -0 . 5 * ( ( log ( t1 ) -mu ) / sigma ) * * 2 ) / ( t1 * sigma * ( 2 * constant ( 'pi' ) ) * * 0 . 5 ) ` ?
34482,i don't see any problems with your nomenclature . is this 60 objects all you have ?
34498,why do you want time series as opposed to a multi-level model or even just summing the 3 days ?
34517,is this homework ?
34518,so is the region you want to be the random effect also the first sampling unit - the one with 300 different levels ?
33352,how you getting on with this ?
34506,have you tried to include another regressor ( like a dummy variable ) in your model to capture the effect of your big external event and improve the fitting over that ?
34565,1 ) you may want to move this to the quant . stackexchange . com site . 2 ) what do you mean by problem ?
34582,can you provide the link to the discussion ?
34598,what does xor y $ _2 $ mean ?
34610,"probably this is a oversimplified suggestion , but what about "" regular "" competing risks ?"
34608,"could you please explain what the inner products $ langle x , x_j rangle $ might mean when $ x $ and $ x_j $ are * points * on a manifold ?"
34644,"as per our [ faq ] ( url ) , we don't provide direct answers to homework problems ( at least not for a period of time ) , so that you can learn by working it out yourself . here's a hint : what kind of model can handle a response variable ( ie the result ) that is 0 or 1 ?"
34648,it's unclear what you are doing . how do you obtain $ 2 ^ { 31 } $ permutations of $ 31 $ things ( when there should be $ 31 ! gg 2 ^ { 31 } $ ) ?
34706,"what do you mean by "" coverage rate of the 95 % confidence interval "" ?"
34724,"[ cont . ] we can close this one as a duplicate of mine , because the latter thread is more comprehensive . what do you think ?"
34611,user765195 : could you backup your claim with some citations ?
34682,what part of interpretting the strength of the relationship are you struggling with ?
34667,you say that you don't understand why variance estimates are biased in eq 2 and then you say that we can ignore your $ gamma $ estimate which happens to be equation 2 ?
34796,okay . but when you actual do a survey you will need that information and wouldn't you think it would be important if you want to construct optimal or nearly optimal weights ?
34775,"do you use a parametric model in that is assumed to hold and you want to different distributions of the same family , or are you looking for something nonparametric ?"
34805,don't you want a bayesian * credible interval * instead ?
34807,"maybe i'm missing something , and i haven't read the paper , but : you're drawing $ x_i $ non-iid from $ p ( x ) $ and then sampling $ y_i $ iid from $ p ( y mid x ) $ . ryabko ( 2006 ) is drawing $ y_i $ non-iid from $ p ( y ) $ and then sampling $ x_i $ iid from $ p ( x mid y ) $ . these seem the same up to renaming . is there something fundamentally different about the objects $ x $ and $ y $ that makes this not the same situation ?"
34828,is there a particular reason why bunched together votes are more worthwhile ?
34843,"model averaging of any flavor only makes sense if you have 1 model - oh , so you have several runs of your function using different variables for n1 , n2 , and n3 ?"
34874,"how do you conclude that the "" gls model "" has a better fit ?"
34844,do you mean z instead of y in the first sentence ?
34961,"you are choosing a particular function to apply to the norm , $ exp ( -x ^ 2 ) $ ( up to scaling ) . do you mean to restrict your question only to distributions of the form $ exp ( - x ^ 2 ) , $ or are you allowing other functions ?"
34960,( 1 ) are the processes and their measurements physically independent or not ?
34921,is this a question about * describing * the data or about making * inferences * about their parent distribution ?
34997,is $ x_1 $ continuous or categorical ?
35029,"two groups-two vectors is not the same , which is why you're having difficulty . the picture helps . lets say you get two groups that overlap somewhat on the 1st 2 principle components , what do you want to do with them ?"
35049,( 1 ) what properties does the utility function have ?
35060,does the order of these points have meaning ?
35089,do you have an answer to this yet ?
35099,"just a thought . . . since alpha is bounded by 0 and 1 , would it make sense to use fisher's zr transformation along the way to doing a t-test ?"
35105,[ what did you end up doing ?
35047,"could this "" disappearing "" cluster be very small , actually a outlier cluster ?"
35088,what is importance of arima component in your question ?
35106,why wouldn't bidding $ x-1 $ always be better than bidding $ x $ ?
35137,"the plot looks smoothened ( interpolated ) to me . that is probably misleading . and "" longitudinal "" i associated with geodata , but apparently you are looking at a time series ?"
34364,could you post a plot of the data ?
35183,"i am currently struggling to understand a paper by airoldi et al called "" mixed membership stochastic blockmodels "" in which they do exactly this ( i think . ) however , i am not very good with variational methods , so you might want to look at the paper yourself . see figure 5 in their paper . a question i have been asking for a while is : why is this em approach not the same as trying to find a global maximum of the lower bound ?"
35218,"the type of tournament matters . many backgammon tournaments are built from 1v1 games , so you can have a lot of data that someone is playing well even if he / she doesn't win the tournament or make it to the money rounds . most poker tournaments are structured differently , as freezeouts , and the finishing position outside the money is not a reliable indicator of skill . so , what data can you collect ?"
35255,what if you are using regression to do classification ?
35271,"do most players always play with the * same * team or is there a ( considerable ) amount of variation in the team selection even for a single ( "" prototypical "" ) participant ?"
35279,i'm confused . why are you estimating the proportion of days that are at different phases of the moon ?
35313,peterflom why would you say you usually don't ?
35358,"i'm confused . if you have a single value ( gotten somehow ) then the tree will have only one branch . also , this won't tell you much - it eliminates a lot of the benefit of trees . or are you talking about two separate runs - one tree and one single number ?"
35347,what $ chi ^ 2 $ test you have in mind ?
35373,"this question seems to call for a * * binomial model * * . e . g . , putting the data in a data . frame with variables name , home , ahead , percent , and n , to get started ( with a simple linear model , no interactions ) you would account for the number of shot attempts by executing ` data $ k - floor ( data $ percent * data $ n / 100 0 . 5 ) ; data $ l - data $ n - data $ k ; fit - glm ( cbind ( k , l ) ~ name home ahead , data = data , family = binomial ( ) ) ; summary ( fit ) ` . is there some reason you haven't done this ?"
35396,"what do you intend to do with this "" normalized percentage "" once you have it ?"
35399,why don't you construct another variable in your data . frame that is transformed and use that one in your model ?
35430,is it safe to assume that sensor 2 has the same error variance as sensor 1 ?
35456,the maximum expected value or the expected value of the maximum ?
35454,the mahalanobis distance assumes a specific covariance matrix . if the two distribution are to have different covariance matrices how are you defining the distances that you take the ratio of ?
35469,"may you help us to understand your original problem first , without introducing a rkhs ?"
35486,is it nonlinear in the parameters ?
35491,"this has been posted on so and removed , which suggests you are looking for a statistical solution to your problem . it sounds , however , that some pieces of information are missing : what are you trying to do precisely ?"
35511,"i think there are two related questions here - 1 ) is this a legitimate thing to do and 2 ) is there software to do it . did you want to ask both , or just one ?"
35516,do you use occam's razor ?
35466,i think you need to be more specific about the problem . what is the model ?
35540,"do you mean plot e , not plot c , when you refer to "" distance to forest edge increases "" ?"
27618,are you asking how to calculate quantiles for the distribution of variables defined as the sum of a uniform and a gamma random variable ?
35544,"how much probability / math do you already know , daniel ?"
35532,"if you have a binomial-glimm model , the traditional $ r ^ 2 $ does not apply . are you referring to one of the so-called * pseudo- $ r ^ 2 $ s ?"
35658,"how about ` c = quantile [ poissondistribution [ e ] , 1-2 ^ p ] ` ?"
35665,are these plots of actual * data * ?
35678,am i correct in assuming that c is a continuous variable ?
35622,are you interested only in proportion of 1st place finishes ?
35687,"what is function $ g ( x , y ) $ ?"
35731,whuber : i'm not sure that is what is being asked . isn't the question about the expected discrepancy between largest $ y_i $ and its corresponding ( latent ! ) $ x_i $ ?
35762,is $ e_t $ an error term ?
35774,how well-versed are you with time-series analysis ?
35778,i can't quite follow your questions ?
35761,"are you talking about permutations here , or about some other transformation of data ?"
35820,i don't follow your argument at all . isn't the question whether or not when n $ _1 $ n $ _2 $ p { x $ _1 $ = k ) p { x $ _2 $ = k } for each k = n $ _2 $ ?
35858,help me understand what you are trying to say . when you talk about probability distribution for a parameter are you talking about a bayesian prior ?
35859,what part of the plot do you find to be strange ?
35855,given that you're discussing only $ 11 $ ( or is it $ 15 $ ?
35903,are the students different each semester ?
35896,i don't really understnad your question . what do you mean by significantly greater ?
35910,"the main advantage of survival models such as cox ( as opposed to ols regression ) is that survival models deal well with censored data . i am not clear enough on what exactly you are trying to model . is it something like "" time to correct answer "" ?"
35937,what are a and b and where do they come from ?
35947,if you are broadening the null hypothesis to get away from equal proportions then maybe you ar elooking for something different from fisher's test . but where did you get the idea that the fisher test is only one-sided ?
35959,why $ / 21 $ and not $ / 6 $ ?
35970,could you elaborate a little on the purpose of the comparison ?
35952,"hi , jim . welcome to the site ! is this , by chance , a homework exercise ?"
36005,can we assume that there is statistically significant evidence for the mixture of gaussians over a normal approximation ?
36024,"sometime this is referred to as treatment cross-over ( unintentional in this design , although it can be intentional in some randomized studies ) . one approach is to utilize instrumental variables and estimate the itt ( [ intent to treat ] ( url ) ) effect as opposed to the effect of the actual treatment assigned . i suspect given your panel design though there is a more direct way to model the treatment . what is the treatment exactly ?"
35976,"hmmm . . . how would you interpret the * negative * confidence that arises if , perchance , $ 5 ! alpha_1 times cdots times alpha_5 gt 1 $ ?"
36047,"you must reformulate your question , as it stands , it does not make very much sense ( maybe only a texnical problem ?"
36058,how are jobs assigned to workers ?
36121,"hint : have you ever noticed the "" residual standard error "" part of ` lm ` 's summary output ?"
36076,"sorry that this isn't my field so probably others would know from the context ; but what are the three dimensions ( horizontal position , vertical position , and color ) of your heatmap ?"
36148,what is the size and structure of your data ?
36100,related to your question [ predicting response for two groups in multiple regression ] ( url ) ( under a different account ) . could you please indicate to one of the moderators ( by flagging your post here ) which account you want to keep and [ register ] ( url ) ?
36188,"i notice that you did not include an intercept for either model , was that intentional for some reason ?"
36223,$ a $ or $ a_n $ ?
36176,"what do you mean by "" in general "" ?"
36221,how many observations have you ?
36232,are your predictors measured subjectively ?
36233,so is it the fimal standings that you want to predict ?
36250,looking at the wiki page on [ irwls ] ( url ) i struggle to the difference between the procedure you describe and irwls ( they just use $ y_i- pmb x_i' pmb beta ^ 2 $ as their particular $ rho $ function ) . can you explain in what ways you think the algorithm you propose is * different * from irwls ?
30461,have you looked into the ` cor ( ) ` function ?
36311,is this question * only * about how r implements this function ?
36309,i see six local maxima . to which three are you referring ?
36331,"your reference to "" outer product "" does not accord with my understanding of this operation , which i believe is a [ conventional one ] ( url ) . the rank of any outer product is at most one , which would produce a highly degenerate matrix : that's not what one expects of a covariance . could you indicate what your "" outer product "" operation is ?"
36319,"just to be sure this is headed in the right direction for you , how do you plan to interpret this tolerance interval ?"
36279,many of us probably don't know what perplexity means and what aperplexity plot shows . i know i don't . could you enlighten me ( us ) ?
36350,"there are non-linear mixed effect models . at least some of these are available in sas ( proc nlmixed and proc glimmix ) and in r ( nlme package , and probably other packages ) and probably in other programs as well . what software are you using ?"
36332,do you have confirmation from spss that it read the data exactly as intended and that it is identical to the data you fed into r ?
37371,"i have done some editing of your question but did not change any of the inequalities you gave . however , shouldn't t $ _a $ be t' $ _r $ so that t $ _r $ can be less than t' $ _r $ as it needs to be by the definition of t' $ _r $ ?"
37387,similar question : [ what is the difference between kalman filter and moving average ?
37390,"do you * know * that these processes are first-order market chains ( and , if so , how ) ?"
37393,"it is worth noting that spam and bad questions are different : the former are generally flagged for obvious reason , checked by moderators , and deleted immediately . the community does its best to improve badly worded questions . you may also be interested in this related meta thread : [ is there a style guide that provides guidelines for question title and question content ?"
37395,what are the degrees of freedom for the t ?
37410,"hint : the data counts are 24 , 5 , 4 , 1 , 2 , 1 , 1 , 0 , 1 , 1 . the * cumulative * counts therefore are 24 , 29 , 33 , 34 , 36 , 37 , 38 , 38 , 39 , 40 . what do you get when you re-express those cumulative counts as percentages of the total ( 40 ) ?"
37451,"$ q $ is a $ p times p $ matrix , you need to elaborate on what $ q = 0 $ means exactly . are the terms on the diagonal zero ?"
37460,"so you're looking for a category of books populated by only a few , bad titles ; - ) ?"
37481,"i see : at the outset you are * asserting * that the probability of $ p $ , conditional on the random variable $ n $ , is $ ( 1-x ) ^ n $ . but where does that come from ?"
37489,can you say more about what you're trying to do ?
37466,have you considered [ r ] ( url ) ?
37613,compensate how ?
37595,"this is , at bottom , an issue of identifying and quantifying separate * components of variance . * your weighting is appropriate when * all * variation can be attributed to the measurement error in los . because you're doing a regression , there will likely be residuals : they will include a separate ( independent ) variance component . if , eyeballing the scatterplot , it appears the regression residuals will be larger than typical los se's , then you are probably ok not weighting anything . the problem is more challenging otherwise , so first it would be good to do this check ! what does it tell you ?"
37625,"what you should do depends heavily on what type of questions you want to ask from the data ! so we cannot reali help without you givibg more background , what do you want to ind out about ?"
37656,the linked pdf is not searchable . where exactly ( pdf - page number etc . ) did you find the quoted statement ?
949,"i assume you mean "" when are the mles of the parameters in closed form ?"
37670,do you really seek a common transformation of * both * the independent and dependent variable ?
37680,do you have any reference data for each sample ?
37698,how did you arrive at your ( 2 ) ?
37737,why did some people get test a and some test b ?
37752,i don't think so . the point i was making is that this probably has nothing to do with sample size . you just can't make statements like that . the issue is similarity of distributions . can you get random samples from tweets and general usage words and compare their frequency distributions ?
37731,cardinal why not make it an answer with a little elaboration ?
37776,"you are not being precise . the model assumption is that the error terms are independent and identically distributed with a distribution that is n ( 0 ,  $ ^ 2 $ ) and is unrelated to the covariate . what is var ( y x ) ?"
37771,are you still trying to understand the classic ipf algorithm ?
37836,"what do you mean by "" samples are unevenly distributed and the probability is unknown "" ?"
37839,why are you doing pca rather than fa ?
36320,perhaps you could tell us a bit more to help us think about your question . do you have any idea what amount of decline is important to detect ?
37880,your notation is quite strange . it seems that you have dependent variable $ y $ and two independent variables $ a $ and $ b $ . you then do the following : 1 . regress $ a $ on $ y $ and get the residual $ e_1 $ . 2 . regress $ b $ on $ a $ and get the residual $ e_b $ . 3 . regress $ e_b $ on $ e_1 $ . you want to find out how to prove that this is identical to residual when you regress $ a $ and $ b $ on $ y $ ?
37943,i think you're being a bit picky about the non-constant variance . it appears ok to me . what is the purpose of the regression ?
37951,cardinal i thought copulas could be any multivariate distribution with specified fixed marginals ( not necessarily uniform marginals and not restricted to a hypercube ?
37963,i do not have much inspiration for the title . feel free to update with a more informative one . is it possible to get a proper link to your lectures ?
37987,"it is hard to make sense of the ( ungrammatical ) phrase "" find out how unlikely y is than x , "" which leaves many readers guessing what this question might mean . could you please clarify it ?"
38008,""" sampling without repetition "" seems strange . maybe you mean sampling without replacement ?"
38063,good question . i find this text a bit baffling myself . i would have thought that whether a sequence is random or not is to do with how it is generated ; not what the result is . i suspect there is a linguistic problem here - for me random means how it is generated ; for common sense ( and possibly less clear-thinking philosophers ?
38065,have you looked at the [ equations for these probabilities ] ( url ) ?
38099,is this for multiple test correction or something else ?
24527,how accurate do you think your simple threshold approach is ?
38106,the brief answer is no . the problem is that higher adjusted r-squared does not always mean better model . what is your criteria for best coefficients and best standard errors by the way ?
38108,where does it say so ?
38107,not allowed by who ?
38117,"this might not matter , but when i run your code i get a warning ` warning message : in cov . trob ( cbind ( data $ x , data $ y ) ) : probable convergence failure ` is this also happening when you run the code ?"
35442,"on a different note , i am not aware of a problem w / using 12 variables in logistic regression . can you clarify what you are referring to ?"
38143,you need to clarify how the election works . i think it is clear you say there just one winner for the whole country . but are they decided by a majority of total votes ; or a majority of states ( each of which is decided by a majority of votes ) ?
38146,peterellis is there a particular reason that you think the unknown interaction couldn't result in an answer lower than 30 % ?
38165,can you give a number of how many effects you are visualizing ?
38218,what is your training accuracy ?
38198,kl is not a random variable . are you interested in the distribution of kl when the parameters are replaced with their estimates based on a random sample ?
38224,"break the problem into steps . first , what's the rate per 110 hours ?"
38308,have you got any information on the people who did not answer and how that compares to those who did answer ?
38337,which of these statistics do you think would be relevant to your question and why ?
38347,are you sure these assertions are true ?
38393,which of knuth's works are you quoting specifically ?
38394,could you explain what you will be doing with this ratio estimate ?
38422,it seems that you have a mathematical generalization . therefore if you want to name it a generalized r square how could we argue against it . now r square has the interpretation of percentage variance explained by the model . what does you generalized r square represent analogous to this interpretation ?
38389,"what , if anything , is common to each of the 15 or so runs ?"
38460,"welcome to the site and thanks for providing context . i did some editing on your question ; i hope i clarified it rather than making it into something you don't want . why do you think 2 clusters is "" un-commonsense "" with 5000 points and 4 dimensions ?"
38420,i don't really understand this example . if $ g ( ) $ does not depend on $ c $ then isn't it unsurprising that the data are not informative as then $ c $ depends only on the form of $ g ( ) $ and is the same for $ any $ sample ?
38494,is it possible to get a link to the paper or at least its abstract ?
38524,"the random effects are also completely different . how does the output compare when you don't include the interaction terms , or simplfy it even further ?"
35948,can you show your code ?
38593,"1 , simulations & figures are 2 of the * most * helpful techniques for building intuition . i've used them commonly to help others & myself understand things . there are lots of answers to cv questions that use sims to illustrate stuff . if you want some links , i could easily list some of my own answers that have used sims in this way . you can also ask a question here on cv in this vein ; eg , 'i'm trying to understand _____ , but i'm having difficulty , can someone provide an explanation w / a sim that will make it clearer ?"
38571,"hint ( for the edited version ) : for a covariance matrix $ mathbb { a } $ , the first principal component $ mathbb { x } $ maximizes the norm of $ mathbb { ax } $ over all unit vectors $ mathbb { x } $ . suppose two components of $ mathbb { x } $ had different signs : could you then demonstrate that $ mathbb { a x } $ cannot have maximal norm ?"
38567,"for the intuition : suppose i tell you $ x = 3 $ . what can you conclude about the value of $ x $ , without considering * anything * about probability ?"
38700,maybe you should give the name of the textbook ?
38734,there isn't a question here yet : ) necessary sample size depends on the question . what do you want to get out of this study ?
38690,"is work additive , such as the amount of some product ?"
38787,"just out of curiosity , what is the alternative your reviewer is suggesting you use instead ?"
38799,` tsset ` is preparation for time series analysis . are you proposing to conduct time series with more than one variable serving the role of time ?
38638,"please describe the nature of your "" rating "" variable : is it good / bad , or on a scale from 0-10 or a-f , or something else ?"
38829,how are you calculating chi-square values on the runs ?
35824,"you need to focus this question more . at present , it isn't really answerable or a good fit for this site . ( you may want to read our [ faq ] ( url ) . ) for starters , have you read the [ wikipedia page ] ( url ) ?"
38841,"can you refine this question , & make it more specific ?"
38852,what is the meaning of stationary ?
38881,i don't understand why you think the mann-whitney u-test can't be used here . can you clarify that ?
38712,doesn't this question answer itself ( in the negative ) ?
38905,"are the "" detected "" and "" actual "" variables observed at the same unit ?"
38975,what does the horizontal line in the plot represent ?
39031,"i'm not sure to understand the link between skewness ( which is expected for this kind of data ) and the use of ordered response categories , as implied by your "" therefore "" . of course these are ordinal data . besides , you also speak of using item scores and the resulting sum score , for each individual . could you explain the purpose of this analysis ?"
39040,the index in $ hat { theta } _n $ is just notation to show that the estimator depends on the sample size $ n $ . you've found the likelihood function $ l ( theta ) $ and want to maximize it . how would you go about doing that ?
39052,there are many possible models . you have to choose one . are the test questions all indistinguishable ?
38413,"do you mean "" the probability of 5 events in at least one 30 day window for the last 10 years "" ?"
39126,are you asking what the sampling distribution for r would look like if x and y are uncorrelated ?
39141,why would you expect that a three-class response variable follows a gaussian distribution ?
8239,"did you look at this question , [ statistics / probability videos for beginners ] ( url ) , and the one that is linked to it ?"
39161,"i don't quite follow your question , monkey ( although , i don't know clustering too well , so that may be part of the reason ) . are you asking if there's some arbitrary value ( like , say , . 05 ) that if your data cross it , they are good ?"
39164,can you be more specific about what you want to know ?
39174,is your new data sample a single point or a new set of data ?
39182,"i provided some discussion on the use of cronbach's alpha vs . other indexes of reliability on this related thread : [ assessing reliability of a questionnaire : dimensionality , problematic items , and whether to use alpha , lambda6 or some other index ?"
39115,what do you mean by reduced components of x ?
39203,"could you please explain what a "" result "" is and how one is supposed to measure "" differences "" among them ?"
39206,"after your last revision of the question , i interpret the context of the question as : given a filtered signal c , how can i reconstruct the original signal a and the filter b , given some information about a and b ?"
39227,do you really want to test * significance * ?
39238,"a first question about the statistical model : you have a random sample from $ mathrm { n } ( mu , sigma ^ 2 ) $ . is $ sigma ^ 2 $ known ?"
39279,the plot actually isn't so bad . . . . but how to improve it depends on what you want to emphasize . do you want to just plot weekly data ?
39297,i don't see why you we need to center anything . all the samples discussed here are of the same size right ?
39306,"is it a "" randomized clinical trial "" ?"
39322,"it's all just multiple regression , but some people might refer to this kind of thing as ancova i guess . . . . is this homework ?"
39317,"that may just be me but i have hard time making sense of this question . could you perhaps add some information : what are "" cluster "" and what is that "" naive structure "" ?"
40343,"welcome to the site , dan . is this homework ?"
40354,can you provide a little more information on your measurement setup ?
39075,"please clarify : your question uses "" x "" , but it seems there are two distinct x matrices . the first x is a 5x300 matrix mentioned in the first paragraph . but the second x , in your regression pseudo-equation , is a matrix of the 8 predictor values , different from the first x , correct ?"
40364,"perhaps adding some more details and context would make this question clearer . for example , do you have repeated measures on each subject ?"
40381,"what do you mean by "" using the deltas "" ?"
40407,"the question is not clear , why can't you have 0 nonconforming products among the 50 units ?"
27450,"surely you have looked at the natural and obvious answer , which is to apply the probability transform to the uniform values . in what respect ( s ) does this approach fail to meet your needs ?"
38091,"i notice you used the * generalized-linear-model * tag , but you don't say much about the nature of your dv . is is binary ?"
38866,"what is "" freezing "" ?"
40456,really ?
40518,what software are you using to fit the predictive model ?
40553,why are they missing ?
40514,i can't follow your question . can you provide more detail about what your situation and goals are ?
40582,what is the null hypothesis of your test ?
40453,what is your question ?
18300,_which_ distributions do you say are equal ?
40604,* * hint * * : the estimator you've given is a mean of iid random variables . ignore the regularity conditions . how can you connect means of iid random variables to asymptotic normality ?
40572,"nico you framed this question as a problem in regression . but really , it seems like a problem from optimal decision theory : given the data , what is the optimal dosage for a particular patient ?"
40670,"roland would you consider rephrasing your comment into an answer , so that sigvard could accept it and mark the question as answered ?"
40704,"how long are these series going to be , & how many of them will you have ?"
40731,"if this is still an active question for you , perhaps we can work out how to apply what i did for the binomial example for yours ?"
40735,"when you have a factor with 9 levels , you need 8 coefficients . each compares one level to others . you need to report them all , but you first need to figure out whether they are are dummy coded , effect coded or some other parameterization . what software are you using ?"
40792,"what do you mean by "" strict bonferroni "" ?"
40854,"i don't understand why you have square roots on the main diagonal . if a is the variance-covariance matrix , the main diagonal should have the variances going down the main diagonal , shouldn't it ?"
38987,"i don't see it on p30 , can you you give the number of the equation ?"
41006,this is quite vague . how do the values returned by the ` predict ` function differ from the ones you generated manually ?
41057,what kind of data quality errors do you expect to see with demographics ?
41089,could you tell me the url of the yahoo site please ?
41117,( 1 ) do you want the most likely customer or the mean customer ?
41152,what do you mean by ca ?
41182,"welcome to our site ! i am struggling to understand what you mean by "" have all lists with a similar frequency deviation and word length deviation ( two separate controls ) . "" could you expand on this , perhaps by showing the output you would like to see for the example data ?"
41186,"you seem now to be asking a question about a multivariate distribution , but it's not clear what you're trying to find out ( at least not to me ) . your use of "" deterministic signal "" in the same breath with "" random process "" looks self-contradictory to me , too . is there any way you could edit the question to clear up these ambiguities about what you're referring to and what you are trying to find out ?"
41159,"in order for this question to be answerable , could you please tell us what the definitions are and the relationships among $ y $ , the $ x_i $ , $ n $ , $ n $ , $ mu $ , and $ bar { y } $ ?"
41208,"this is nice because it's a really easy way to explain the different interpretations of probability ( objective vs . personal ) to someone with no experience - i . e . is the coin fair , or how many possible ways to wake are there ?"
41216,are you able to post your data ?
41143,"strictly speaking , ( e ) doesn't ask you to do anything . it simply makes a comment about what should be possible ( whoever wrote that question needs a jolly good spanking and no supper ) . let's assume the writer of it wants you to obtain the 95 % ci . could you write down the distribution of a quantity such as , say $ theta / hat { theta } $ or $ hat { theta } / theta $ ?"
41177,why didn't you post your updates as an answer ?
41247,this seems like homework . what have you tried so far ?
41254,may i suggest you do a little research on our site ?
41272,perhaps a better thread than the listed duplicate is [ . . . when is it appropriate to use the log of an independent variable ?
41280,why not just add up all the other parties and treat them as one single party ?
41127,"( followed from above ) precisely , i do not understand your remark about $ f ( x ) x sim g ( alpha , beta ) $ . this is not the standard condition : $ u f ( x ) / mg ( x ) $ . inversion is an altogether different method : do you want to use it for simulating the exponential ?"
34851,can you say more about your situation ?
41320,"so _a_ is not only categorical , but even 0-1 ?"
41342,what software are you using ?
40956,are you telling us that you know the same physical quantitiy is measured in different units but you do not know how the units are converted ?
41356,how was stress urinary incontinence measured ?
41375,"why not have "" number of black parents "" as a single iv , with three levels ( 0 , 1 , 2 ) ?"
40861,"well , what you describes seems to be the usual procedure ! what do you think one is doing ?"
41385,"have you considered an intermediate variant where the covariance matrix is taken to be $ text { diag } ( sigma_1 ^ 2 , sigma_2 ^ 2 ) $ so that the variances of the two data components are the same but the data are components are treated as uncorrelated or independent instead of having nonzero covariance $ b $ ?"
41428,"what do you mean by "" then deviations on x means "" ?"
41436,can you give some more detail of what you are trying to match to ?
41390,"it's not a problem with logistic regression per se , it's a problem with dummy variables . in sas , you do get a p value for the effect as a whole . you can't get odds ratios on the effect as a whole because they don't make any sense . with a continuous iv , the or is "" per unit "" of the iv . with categorical dv with more than 2 categories , what would it be ?"
41449,wouldn't the usual statistical analysis with standard deviation suffice to determine a confidence level ?
41448,"your null & alternative hypotheses should be complementary . eg , h0 : b = c & h1 : b c . do i understand correctly that you want to test the coefficients on different variables ?"
41493,"are you able to post a copy of the lecture notes , or link to them ?"
41486,what is the purpose of the analysis ?
41496,welcome to the site . what is / are your dependent and independent variables ( if any ) ?
41506,"well , it seems that with only two alternatives telling coke a coke translates to telling not a coke not a coke , ergo a pepsi . no ?"
41526,"it may just be my ignorance , but i thought pareto variates were continuous and strictly positive . . . how did you determine that the pareto was a reasonable fit to your data ?"
41547,"don't you mean $ y ( beta_1 x_1 beta_2 x_2 beta_p x_p ) $ , and should there be an intercept ( $ beta_0 $ ) in there as well ?"
40939,"could you please explain what you mean by "" follow up "" on an interaction ?"
41559,"i don't quite follow your setup . what is your response variable , & what are your predictors ?"
41616,are you sure you have a guassian * * mixture * * model and not a * * multivariate * * gaussian distribution ?
41628,do you want to do imputation of one of the outcomes ( when one is missing ) or are you only asking about the imputation of the covariates ?
41670,"can you post your r code and a [ reproducible example ] ( url ) , please ?"
41726,naught101 how about making this a community wiki ?
41740,"it is nearly always a bad idea to include an interaction without the lower order terms , and i don't this is an exception to the rule . why force the 2 way interactions to be 0 ?"
41783,"what is "" nmds "" , & what are "" dca axis coordinates "" ?"
39325,"your time series looks seasonal , you may use a square wave ( $ t mapsto alpha left cos ( 2 pi w t phi ) beta right $ , where $ alpha $ is the amplitude , $ phi $ the phase . . etc ) . you can try and remove this seasonal effect and analyse the erros ( gaussian or not ?"
41092,"i am not clear why p ( a b ) is taken to be the prior probability of reading "" kiss "" . what did you thought about the event b ?"
41837,why are you guessing ?
41843,"welcome to the site , erelsegahalevi . i'm wondering if cv is the right place to ask your question . are you primarily wondering about the machine-learning aspects of this ?"
41849,"do you only want really old material , or would serious mistakes that are recent also interest you ?"
41855,"i don't quite follow the impetus behind this . if you have a method to extract & classify "" spider "" & "" cat "" , & these are perfectly nested w / i higher level categories , why not use that method ?"
41867,are n and d normalizing / centering matrices ?
41885,are you just looking for the ` dbinom ` function ?
41784,regarding q1 : are you only referring to observational studies ?
41893,"chl is right about factor analysis , which tries to uncover latent factors ( here disorders ) in high-dimensional data . are the factors interpretable ?"
41906,"this post does not necessarily need to be cw . however , you are not really asking a question , isn't it ?"
41931,which hypothesis do you really want to test ?
41888,why would anyone want to distinguish the priors ?
41944,"i don't quite follow your situation . if you have percentages , why would you want to use poisson ?"
42967,could you please provide the sample sizes explicitely ?
42970,"i have a general answer in preparation , but some more details might help . 1 . where is this formula from ?"
42983,why do you want a single sample equivalence test instead of a single sample t-test ?
41850,"welcome to the site , rykardu . i have edited your question using the markup supported by cv to make it easier to read . please make sure it still says what you want . note that # 2 ( previously "" ( b ) "" ) doesn't make sense to me ; & i don't know what "" $ e $ "" means in your bit error probability , is it "" = "" ?"
43109,thanks . i find the notation mysterious : what is the relationship between $ u $ and the $ q [ i ] $ ?
43127,your explanation doesn't make it clearer . what is matrix $ b $ ?
43209,"what do you mean by "" better estimation "" ?"
43217,` item-specific variance ` are you talking about what is known in fa as _unique variance_ ( uniqueness ) as opposed to _common variance_ ( communality ) ?
38894,hi you post seems interesting but i'm confused by the presentation . it seems you have a model and a sequential sampling scheme of the data . what is you need to estimate ?
43249,"if you just want the fitted line to follow the center points , why are you including the other points in the model ?"
43086,have you considered using a model that would actually be related to the physics of the problem ?
43210,see [ what are community wiki posts ?
43264,so that graph is almost a cumulative sales graph and in recent years you seem to be selling an item roughly every 9 days . what question are you trying to answer ?
43276,the information on the pairing is very important . ( are the observations in the same order ?
43308,"it is difficult to make sense of the first part of this question . how is it you can define $ y $ as the sum of two variables , yet declare that $ y $ has either ?"
43323,are the symptoms really independent ?
43392,"i'd not call the graph * the * learning curve : it is just one instance . first of all , you need to tell us how exactly it was generated : is it a "" growing "" data set , i . e . one sample after the other is added and the model is recalculated and re-evaluated after each additional ( bunch of ) sample ( s ) ?"
43461,are you still interested in this question ?
43467,the reasons why ( b ) is plausible should also indicate why the other answers are not good . so what are your reasons for favoring ( b ) ?
43431,do your observations represent the number of events over the same number of trials ?
43283,"do you mean equal-sized bins ( i . e . bins , which have the same interval ) ?"
43523,"you suggest early in this question that deconvolution might * not * be "" parametric . "" how do you accomplish that without parameterizing $ s $ ?"
43521,"what do you mean by "" reliability "" ?"
43566,"it's regrettable that you can't show the picture it would make much clearer - for example , is it a perhaps linear line or approximate one ?"
43594,does my answer below address answer your question ?
43678,"from what i see , your data is generated by a markov chain . why don't you use all the work that has been done on this ?"
43685,how large is $ n $ ?
43675,do you mean you're using the model $ log y_i = beta_0 beta_1 x_i beta_2 z_i epsilon_i $ ?
43761,do you actually mean that you have a matrix of the pairwise correlations of a number ( how many ) of time series ?
43799,"so you have n cases , each measured twice ( pre and post ) on some ordinal measure ( the dv ) and each from one of two groups ?"
43835,"perhaps the question you are given uses the word "" accuracy "" but i think [ "" precision "" ] ( url ) is more to the point . let's start with a slightly simpler question than the one you ask . what statistic describes the precision of an estimate of the population mean ?"
43845,are the random variables independent ?
43836,"do you mean that $ ( a , b , c ) $ occurs then you pick $ a $ with probability $ p_1 $ , $ b $ with probability $ p_2 $ , and $ c $ with probability $ p_3 $ ?"
43873,is that how you are simulating your model ?
43865,why not use multilevel analysis ?
43874,what software are you using ?
43881,what's the purpose of the simulation ?
43940,do you have individual measures for all 8 conditions ( crossed factors $ a $ and $ b $ ) ?
43748,"why "" should "" the outcome be 0 . 610 ?"
43954,you might want to also look at year / age of the car ?
43982,are the values of objects the same ?
43720,"i don't understand what you mean by "" expected "" -- i thought that group 1 was also collected data , and not theoretical distribution ?"
44028,could you give some more details about what kind of model you fit and what your predictors are ?
15130,is there some significance to the division into hours ?
44109,sounds a bit like the phd thesis of allan birnbaum ?
44100,what about the community of species are you comparing ?
44136,"whuber while i'm not arguing with your point , it's very unintuitive to me - can you give some reasoning as to why this bias occurs ?"
43891,"your canopy seems to be a continuous outcome ( fraction of canopy coverage ) which is then cut into ordered classes . in that case , why not do regression , and use regression error measures ?"
44158,"so that we don't guess incorrectly , please tell us the setting or context of your question , what these formulas are for , and what the variables mean ( variable names are not universal ) . do you have a link to the online explanation you are quoting ?"
44169,"i don't understand how you can ask , "" given the results of a number of such comparisons , how should one pick the optimal vector of design variables ?"
44134,( a b c ) / 3 -- why do you take absolute values ?
44185,"for $ k $ nearest neighbours , the roc can have points spaced by $ frac { 1 } { k } $ only . how many nearest neighbours do you use ?"
44195,then i think the * crux * of the choice is the * optimality * criterion . do you have something in mind ?
44044,"you mention sales at one point . did you mean 'renewals' there , or is sales another variable in the problem ?"
44200,"well , what question do you want to ask of your data ?"
44212,"when you say "" just by looking at the burst of clicks "" do you mean you're unable to compute anything other than n ?"
44223,are you perhaps interested in the pros & cons of different ml algorithms for situations like this ?
44193,"well re : your second question , does your derived distribution put 90 % of the probability mass below 7 ?"
44219,"i have implemented this code and have a question . if i wanted to plot a tolerance interval only on ynew to make tolerance limits on a regression model , could i simply change tolup - ynew - xnew k1 * s to tolup - ynew k1 * s ?"
44262,would you like to write an answer ?
44325,"i searched for "" hampel "" in ` r ` and found one defunct statistic and one from the ` rlm ` ( robust linear model ) function in the ` mass ` library . can you say what you sere using ?"
44370,"it's deprecated on stackoverflow , not deprecated here [ e . g . ] ( url ) . if you hover over the homework tag on a question , it describes the policy . further , [ see this ] ( url ) . feel free to show me something on our meta that suggests it's not used . but in any case , what * is * the source of this question ?"
44410,"aren't these usually just called the "" percents "" when the quantiles are referred to as percentiles ?"
44479,are those normal r . v . 's independent from each other ( and also from $ n $ ) ?
44490,"when you say "" when you perform -1 / 2 and -1 degree of re-expression "" , what are you talking about ?"
44503,""" * due to fact that there are only two sites , than random effect model or repeated measures anova also can't be used . * "" . . . really ?"
44434,are you assuming a particular joint distribution for your two variables ?
44511,how are you thinking about your response variables ?
44528,what kind of a bound are you looking for ?
44531,are those cumulative incidences or incident rates ?
44532,"have you explored * directly * the relationships between $ s , b , n , m $ and the dependent variable ?"
44546,"what is this "" business rule "" ?"
44564,hi captainmurphy . did you find a suitable solution to this code ?
44515,"does "" linear response "" mean that you're dealing with a * continuous * response ( or manifest ) variable in [ 0 ; 1 ] ?"
44587,i guess you tried convoluting ?
44602,"it's not just a simple issue of adopting different or correct methods . instead , a more important perspective is , what hypotheses or tests do you have in mind ?"
44436,what question do you want to answer ?
44609,"1 to stephankolassa . his final sentence is worth emphasizing , as well . we have no idea what would be the proper way to deal w / your situation w / o knowing what your situation is . can you edit this to give some details about your data , your goals , etc ?"
44617,why do you regard these correlations as low ?
44649,do you have analytic expression of your pde solution ?
44650,how did you normalise the sum ?
44677,how does lumping the items triple your sample size ?
44720,"perhaps if you think through what you mean by "" the effect the two dvs have combined "" it will help decide if you need to worry about this or you can just run to separate regressions . generally you aren't thinking about the "" effect "" of a dv . so in what way is it important to look at the two of them simultaneously ?"
44718,why not leave it as 2 . 5 ?
44795,"this question needs additional assumptions in order to be answerable . also , it deserves quite different answers depending on whether this is a homework / test question or if it's something you are genuinely interested in ( and you therefore don't have to guess what a test creator intended ) . could you please tell us which it is ?"
44819,"may i ask what led you to choose a welch t-test instead of a classical t-test ( read , how would you justify your claim that "" the variances are different "" from a statistical perspective ?"
44737,but how do you know which $ i $ ?
44918,"it sounds like you're asking for individual distribution functions of the predicted times , discretized to half-hour intervals . did i understand right ?"
44898,do you assume probability p is constant through time ?
44939,is there any particular reason why you are trying to avoid time series methods ?
44942,two more comments : 1 ) is the 4th step in your algorithm simply to check for convergence ?
44990,"i am confused by this question because although it refers to a * lognormal * distribution , it appears to describe a * power * distribution ( in which there is a linear relationship between the logarithm of the value and the logarithm of its quantile ) . which one do you really mean and what precisely do you mean by the "" slope "" of a univariate dataset like this one ?"
37961,"i need some help interpreting your data . clearly ( from edits ) the middle three columns are v1-v3 , and the outermost are supposed y and v4 . however , i'm not clear on what values y and position take , or if they're even supposed to take values . are each of the x $ i $ discrete positions of the tool ?"
44357,you have asked 4 prior questions without accepting a single answer . have none of the answers provided been of value for you ?
44899,why do you want to use the multivariate clt and the delta method here ?
45071,what about a sequence of bits generated by a bernoulli process with p = 0 . 5 ?
45073,it seems to me that this is about judgment more than stats . are all of the subjects equally important ?
45082,"i don't know what you want to do . principal component analysis ( pca ) is a dimensionality reduction technique . it is not a classification technique . so , what are the "" classes "" ?"
45001,do you know the value of $ m $ ?
45118,"it sounds like you have a zero inflation problem . given this , all of your specified models will be negatively effected . have you tried a zero inflated poisson ( zip ) model ?"
45123,"closely related : url and url and this one appears to be an exact duplicate : url does that answer your questions , tom ?"
45131,"can you please rephrase "" * however , such approach gives me way too many binding regions ( state 0 no binding , and state 1 binding ) * "" into hmm terms , for those of us who don't anything about protein binding regions ?"
44906,are you basically asking how topic models work ?
45159,nice question and nice answer from scortchi . but why are some coefficients $ beta $ and some $ delta $ ?
45189,"when you have both a and x in the model , is the effect of x large ?"
45194,is your end objective to generate a random sample of the $ x_i $ from the distribution $ f $ without having to calculate the normalizing constant ?
45222,have you looked at discrete time survival analysis ?
45225,"it would be nice to have a clearer idea of what you mean by "" inflated . "" this suggests a comparison , so one is moved to ask , inflated * compared to what * ?"
45247,what model do you want to fit and what is your identification strategy ?
45296,there is haze . 1 ) what are the clustering objects - variables or cases . 2 ) what is ` significance ` in your context ?
45286,why are you writing your own algorithm ?
45141,can i ask why do you need a 6-4-4-3-2 nn ?
44475,did you add the same amount of elodea to each of the 3 'treatment' tanks ?
45334,do i get you right ?
45327,could you be more specific about what you checked ?
45341,"it is difficult to understand what is being asked here , because "" track "" lacks a clear definition and no examples are provided . could you perhaps edit your question to rectify this ?"
45348,can you elaborate more on how did u use the z-score to sort the variables ?
45254,"then there's not much we can go on . for instance , because $ mathbb { c } ^ 2 $ is the same as $ mathbb { r } ^ 4 $ as far as the numbers are concerned , you don't have "" circular "" variables at all and you aren't working on a torus . given the information you have supplied , all we know is that you want to test for a difference in multivariate distributions and the only special aspect is that the number of variables is even . that's too broad to be answerable . can't you be any more specific ?"
45352,"druss , why would you omit $ mathbf { y } $ ?"
45399,"what do you mean by "" jointly log normal "" ?"
45415,you should really give some more details about your experiment ! are this lab experiments with independent outcomes ?
33354,"given $ x sim n ( 0 , 1 ) $ and $ y sim n ( 2 , 3 ) $ and that the random variables are jointly normal , _how_ did you calculate the covariance $ a $ ?"
45450,do you have lots of data ?
45480,how do you obtain diagonal values that are not identically $ 1 $ ?
45485,i am a little bit confused by your data . for example what is the meaning of 6325 . 76 . . . and - . 247831 . what is being observed ?
11887,"stan : if i understand correctly , your sample size was 8 , that is , you collected sample from * eight * humans ?"
45515,what are you modelling ie what is the explanatory variable ?
45581,do you have any knowledge of the distribution of errors for the classifier or the distribution of classes of documents ?
45584,shouldn't ` binom . ll ` return a scalar ?
45627,have you considered the eponymous method of cross validation ?
45637,"it's easy to create examples : after $ x_2 $ is removed , $ x_3 $ becomes a proxy for it , so if $ beta_4 beta_5 approx 0 $ , the coefficient $ beta_5' $ should be close to zero , greatly reducing its p-value . a more fundamental question is why do you think there is a problem in the first place ?"
45725,"presumably the monthly investment is constant , right ?"
45747,is this for a power analysis ?
45759,can you say a little more about what is confusing you ?
45234,do you have historical data on the % age of sales that were won in each period ?
45778,can you link the note instead of the picture ?
45782,"to add my own attempt at clarification - is this a gamma that is shifted left , then truncated at zero , so you don't know the magnitude of the shift ?"
45714,welcome to the site . could you spell out what an m m 1 queue is ?
45791,"there's no way to solve the problem without providing 1 ) the true effect size ( 1-2 ) . if it is large , you won't need a large sample size , and if it is small , you will , and if 1 = 2 , then no sample size will say it is significant . 2 ) what probability should it have to reject the null hypothesis ?"
45817,have you tried the hlder inequality ?
45765,"in your notation , is $ theta mu_i ^ 2 $ the standard deviation or the * variance * ?"
45763,"it depends on what your goal is , but i would certainly suggest using a mixture model to find the two distributions that correspond to the two modes . i'm not sure what you mean by * "" trying to assign a value for that statistic to each product "" * ?"
45825,shouldn't the proposed $ h_0 $ be an equality not an inequality ?
45851,did you test the classifiers on the same samples ?
45852,bucket them and do bar graphs ?
45878,can you post your complete data ?
45842,"do you mean , "" any * such * $ hat m $ "" ?"
45897,do you care about the measures of association in contingency tables ?
45905,"i am somewhat unclear on what you are asking . let me see if i can rephrase ; i ask you please to confirm or correct my understanding : ( 1 ) you wish to fit a piece-wise linear model to the original time series . ( 2 ) you want the turning points of the fitted model -- the points at which consecutive line segments meet -- to capture and reflect , in some sense , the "" turning points "" of the original series . ( 3 ) you propose to identify these "" turning points "" by comparing the behavior of the original series with that of a derived ma process , identifying "" turning points "" as points of intersection . yes ?"
45952,what do you want to do with the time series ?
45961,i am not following . how do additional dimensions matter ?
45921,"if the process isn't stationary , how are you defining / calculating the autocorrelation function ?"
45920,"$ p ( x_2 = 2 , x_4 = 5 ) $ is the * joint probability * of $ x_4 = 5 $ and $ x_2 = 2 $ not the conditional probability . also , is this homework ?"
46026,are you just after a 1-way anova on 8 groups ?
45053,what's ` dim ( v ) ` ?
46045,any reason you chose square brackets instead of ( ) ?
46105,"ok , but you need to be more specific : what data would you be using for the tests ?"
46119,what attempts have you made at solving this problem ?
46142,have you looked into bayesian inference as an alternative approach ?
46168,is the 21 at the beginning a typo for 12 ?
46175,"what software are you using ( eg , sas ) ?"
46120,more details ( what form is the compated ud in ?
46219,my head hurts . can you write this with shorter but more sentences ?
46226,"i haven't got the answer , but one question and two notes : 1 ) log of a ratio is , of course , the difference of logs . so your dv is equivalent to log ( treatment ) - log ( control ) . 2 ) which textbook of gelman's were you looking at ?"
46198,"i'm afraid i don't get this at all , because i cannot understand what a "" common variance "" would be . since you say you understand this conceptually , would you mind explaining what the common variance actually is and how you think it would be "" analyzed as a separate variable "" ?"
45870,what is 'sdm' in sdm model ?
46265,what do you mean ?
46270,frankharrell - isnt that the whole idea of dropping insignificant terms ?
46321,can you clarify what you mean by typically required for repeated-measures anova that there is only one observation per condition per subject ?
44888,"since this is homework , can you explain what work you've done so far or what part of the problem is giving you trouble ?"
46302,why do you want to use apply ?
46428,what is your mental model of decisions made by people visiting your site ?
24936,do you know for a fact that all of these subsets were taken from the same population ?
46189,looks like you changed your question half way through the last sentence . are you asking a yes no question ( starts with 'does' ) or a 'why' question ?
46535,i don't completely understand your question - can you flesh it out a bit more ?
46561,do you mean markov chain monte carlo ?
46588,"i know of several definitions of "" gaussian processes , "" so it's not apparent what your question is really asking about . but as you consider how to clarify it , ask yourself this : exactly how would you parametrize the gaussian process you have in mind ?"
46619,just a further note : i have noticed that the value given in the output ( 5e-07 ) is the last value written in 'fit ?
46630,"the questions you ask are strange in light of the equations : the first says that $ y $ is to be estimated based on values of $ x $ and the second says $ x $ is to be estimated based on $ z $ . if you are given $ y $ , * there is nothing to be estimated * and neither of the equations is appropriate . did you perhaps instead want to ask how to estimate $ y $ in terms of $ z $ ?"
46634,"$ x $ is a matrix , $ f $ is a function , how exactly do you put them together into matrix $ tilde { x } $ ?"
46519,"i do not understand why "" number of significant figures to put in a table "" does not fully address your question : what point does that question miss ?"
46640,can you specify how $ y_t $ are distributed ?
46646,are your variables continuous or discrete valued ?
46664,can you explain what your data set looks like and what your model is a little better ?
46674,"the correlations between two variables should not change at all , and i am sure that amos and spss both calculate correlations correctly . therefore , what you are reporting are not pairwise correlations but something else ; but it's unclear what . can you post your code ?"
46689,"i don't see an r package called "" omega "" . i did find a function , [ ?"
46770,what do the colors in you plot mean ?
46681,"note that you don't need to burn in the simulations , as you're not doing mcmc . also how much bias are you seeing ?"
46798,the rapidminer plot does not seem to make sense to me . why are the top left and right corners of the same density ( greenish ) than the center part ?
46809,how can you hope to compare teams in different leagues ?
46833,is there a particular family you have in mind with 2 possible link functions ?
46840,are you trying to predict * * number * * or monetary * * amount * * of donations ?
46776,"wait , ` xtlogit ` does not do panel logit ?"
46877,"welcome to the site , robert . can you expand your question and provide more details as to what you want to figure out ?"
46808,"why don't you just numerically integrate the pdf ( which is a rational function , easily programmed ) ?"
46920,what is your question ?
46928,have you tried simulating ?
46929,aren't the size of the dataset and the size in ram very closely related ?
46872,"you already have a good answer , but just to confirm , 'm' is the same for all dice ?"
46969,"you seem to be taking for granted that * * "" any control variable that has no effect is usually left out of the model "" * * - why is that ?"
46987,""" stops a random number of projectiles "" could mean various things . could you explain this ?"
47009,"are the two samples independent of each other , too ?"
46983,"using univariate means to calculate the multidimensional centroid is fine . however , you also want to think about other aspects of the multivariate distribution : eg , is it unimodal , what about the variances & covariances of the differing dimensions ?"
47020,how many categories does placement have ?
47034,noting that 273 . 15 / 459 . 67 is pretty close to 0 . 6 are we discussing a data situation that involves two different measurements of temperature ?
47040,"if $ y_i sim n ( ax_i ^ 3 , sigma ^ 2 ) $ and the $ y_i $ 's are independent , then the likelihood is just the product of the contribution of each $ y_i $ , right ?"
47092,how is $ hat { beta } $ defined ?
47185,could you be more explicit as to why call center data is not equispaced ?
47190,"are x and y both drawn from the same distibution $ bin ( n , p ) $ ?"
47183,"as far as i know "" poisson residuals "" refers to residuals from a poisson regression , not a multinomial logistic regression . do you perhaps mean some other kind of residual ?"
47246,"you may have misapplied it ( although it's conceivable this result is correct ) : in an edit to your question , can you provide some details describing what you did ?"
47227,what did you try ?
47258,what's the ` unlist ` ing for ?
47284,"then please flag your question on math for moderator attention : they can delete it . in the meantime , some clarification would help . ordinarily $ hat { y } $ refers to an * estimator * but here you use this notation to refer to the * expectation * . is this what you really mean ?"
11375,when you say project do you mean this is for school ?
47356,are you thinking of this as bayesian ?
47406,what kind of model are you trying to fit ?
47431,"continuous ivs are fine for ordinal logistic regression . true , they create empty covariance pattern cells which makes it problematic to rely on goodness-of-fit measures such as chi-square . but think , do you really need to know goodness-of-fit in your case ?"
47339,do you know for sure that the outliers are taken from another gaussian distribution ?
47383,why are you transforming the predictors ?
47454,do you have any measure on the degree of inaccuracy of your second file ?
47444,there is no indication here of whether wigan is the home team or not and it is unclear what the first sentence of the exercise has to do with matters . is this the full problem statement ?
47474,do you have any idea what size of effects you want to be able to catch ?
47481,"did "" d "" mean "" all of the above ?"
47489,"if the demands are $ x_1 $ , $ x_2 $ , & $ x_3 $ , & your certain value is $ k $ , do you want to calculate ( 1 ) the probability that the total demand is less than a certain value $ mathrm { p } ( x_1 x_2 x_3 k ) $ , or ( 2 ) the joint probability that demand for each user is less than a certain value $ mathrm { p } ( x_1 k , x_2 k , x_3 k ) $ ?"
47385,"i think i am missing something . if you * randomly * selected group a * from group b * , then the groups should not be different , right ?"
47265,"welcome to the site ! is one of the predictors categorical and the other two continuous , or the other way around ?"
47512,how many products did the typical person buy ?
47458,"multiple imputation is the usual answer , as has already been pointed out , but ask yourself : if you have this many missing values should you be using glms in the first place ?"
47549,can you post a tiny sample of your dataset so that readers get a better idea of the data structure ?
47570,"it is not immediately clear from your description that the integral would exist in any reasonable sense , much less that one would be able to take an expectation . why should , for example , $ { t : x ( t , omega ) 0 } $ be a lebesgue measurable set for any fixed $ omega $ ?"
47585,how exactly did you train the dbn ?
47594,how large is the set of variables you plan on selecting features from ?
47633,"i don't know as much as i would like to about baysean methods , but is there a reason why you can't just compare aic values ?"
47647,where did your last formula come from ?
46360,can you list the paper in question ?
47676,wouldn't you just minimise the kl divergence - which is essentially moment matching on $ e_ { ga } left [ log ( x ) right ] = mu $ and $ e_ { ga } left [ log ( x ) log ( x ) right ] = sigma ^ 2 mu ^ 2 $ ?
47689,"i think confusion may arise in part due to your notation . when you write $ f_ { y x } $ , it reads as though you are thinking of $ y $ and $ x $ as separate random variables drawn from a joint distribution . however , your narrative suggests that you intend for $ y $ to be a function of $ x $ . in this latter case , once $ x $ is known , $ y $ is known : the distribution of $ y $ conditioned on $ x $ is a single point , $ y ( x ) $ . which is it ?"
40819,what is the matter with simulating datasets ?
47736,are you sure the example data is correctly set up ?
47420,can you clarify your notation ?
47887,how many years of data have you got ?
47900,"aren't the rows you showed about industrial sectors , and not occupations ?"
47942,how many variables did you have to begin with ?
38004,why would you want to use poisson regression for a dichotomous dependent variable ?
47965,a . r which package do already what do you want to do ?
48012,what does your covariate data look like ?
48017,what do you use for measuring similarity ?
48038,"since this is clearly a homework problem , can you please tell us where your confusion lies ?"
48035,is this really a meaningful or important question to ask ?
47864,"i don't think there is an omnibus answer to this question . i am concerned about bias . as an example , consider inconsistencies in geographic data . e . g . , url although * some * inconsistencies are evident here where african conflicts are mapped into non-african locations , the problem is that there must be many other inconsistencies that are not so evident . the ability to detect an inconsistency is correlated with location . if we process only the inconsistencies we detect , we could introduce a geographic bias . what protects your data from a similar problem ?"
48063,how do we know the functional form for the edge length distribution ?
48123,look closely . what is the difference between your formula and the first formula from the answers ?
48125,thanks for edit . have you looked at log linear models ?
48165,what is the reason to constrain the ranges ?
48112,have you searched our site ?
48199,are the three different values just categorically different ?
48208,which variable is the qq plot showing ?
48212,"user603 could you please elaborate a bit , as this alone is unlikely to help the asker ?"
48213,how do you propose to calculate the expected value ?
48253,thanks for the data . superbowl . dat is missing crucial information : what are the actual dates ?
48254,"robert , have you looked into the * methods and formulas * of stata's ` [ xt ] xtmixed ` and / or ` [ xt ] xtmixed postestimation ` ?"
48267,"thank you for the clarification . but what error are you interested in , precisely ?"
48242,why exactly do you need a formal distribution ?
48247,"( 1 ) just a tip : not everything needs to be done using mixed models - you might be fine using "" simpler "" ( more robust ?"
48282,my apologies . i missed that m is a random variable where m and x are negatively correlated . how are you computing the variance of the numerator of $ a $ ?
48287,it all depends on why you are computing the svd . what's the purpose ?
48479,"welcome to the site , ansel . since this is a question on a computing environment , should we move it to so ?"
48543,how many frequencies were measurements taken at ?
48542,i don't understand the original problem . how can the variable be log normal distributed if it has negative values ?
48647,what is your null hypothesis ?
48668,how many missings does a single variable have in your data ?
48582,can you post some sample data ?
48757,"when a smooth function has multiple local minima , then necessarily each one of them will be a critical point ( where all the partial derivatives vanish ) , so your algorithm is correct but typically it's useless : you can get a horribly complicated equation with a huge number of solutions ( even infinitely many ) . but there's another issue : how do you know the k-means objective function is even differentiable everywhere ?"
48437,do you know how many bees are in the hive in all ?
48774,"i am confused . the more products ( x ) a salesman sales , the more revenue has been generated ( y ) and vice versa . so x and y are positively correlated . do i miss something here ?"
48752,"could you describe--either in english or mathematics , but please not in non-working ` r ` code ! --what set of permutations you are attempting to generate ?"
48828,what if you combine categories 1 and 2 ?
48837,how many levels per repeated measures factor ?
48882,what do your outcome y and explanatory variable x look like ?
48897,are you sure about your analysis ?
48894,it is unclear what you are doing . can you provide a more precise description ?
48944,have you given thought to performing a population level inference with robust standard errors to account for intracluster correlation and non-proportional hazards ?
48956,have you tried negative binomial already ?
48872,"what specifically is your "" model "" ?"
48810,"steko , can you give us a little more info on exactly what you are trying to predict ?"
49040,what about comparing accuracy for the same computing time ?
48907,"if you have decided on a parametric family to model your data , why have you decided against maximum likelihood ?"
49062,i'm concerned about some of your reasoning / premises . why would group-size relate to how near to normality the population distribution of difference sores might be ?
49069,can you reference the paper ?
49084,"it is difficult with such a short series to distinguish between the underlying temporal trend and x . [ here is an example ] ( url ) of var in r that should be helpful . visually , i'm skeptical differencing is appropriate . do you expect ` y ` to also have an effect on ` x ` , ` x ` is a near perfect example of an ar ( 1 ) process ?"
48951,"what exactly do you mean by "" accuracy "" ?"
49114,is this homework ?
49120,"i can't tell from your question , are your measurements w / i each regime independent ?"
48766,"tomas , did you ever learn what the delta is exactly ?"
49117,"although you provide two examples of entropies , you do not actually apply anything that would be called an "" entropy test . "" could you explicitly tell us what that test is and how it works with your two files ?"
49184,is this question * only * about how to get something done in r / winbugs ?
49037,"hi , colin . this question looks interesting , but i have several questions about it . perhaps they are just notational issues or unstated assumptions , but much of the math in the question doesn't make complete sense . are the means $ mu_t = mathbb e x_t $ * constant * ?"
49176,"are you using chi-squared to assess 3 variables ( site , mechanism , & type ) ?"
49221,"the sum up to 5 ( not 3 ) gives 0 . 778 . you need to correct your question in one way or another ( either 3 is wrong or 0 . 778 is ) . note also you were asked a question about "" * at least * 680 "" . are you sure you calculate the right quantity ?"
49196,what is wrong with simpky counting up the occurrences in a frequency table ?
49257,why do you say * un * -paired ?
49260,"i'm not sure , but can you just take the diagonal elements of the cholesky decomposition as your standard errors ?"
49284,are you showing equal numbers of cars and bikes ?
49266,"actually , both areas are ( or at least * should * ) be unity : one area is tall and thin while the other is short and wide . have you considered plotting the * logarithms * of the densities ?"
49300,is your question related to this one ?
49324,"what do you mean by "" the significance of a particular variable "" ?"
49344,are you speaking just of one-factor random data ( random spheroid ) ?
49210,sorry i'm not clear on what you mean by a 'trial' . did you roll each die 300 times ?
49246,what do you want to achieve with modelling this data ?
49416,"i can't tell yet whether this question belongs on so or here . are you wondering which method ( eg gain chart vs roc ) would be optimal , or just how to get r to perform that method ?"
49442,"does the linked question provide what you need to know , larry ?"
49480,where did you read that random sampling ensures a 0 covariance between variables ?
49374,"do your algorithms involve some kind of randomness , or why else do you run them 10 times each on every dataset ?"
49162,how are you representing your webpages ?
49537,"in this case , providing sample data ( including information about your parameters such as a and b ) would be very helpful . what is it about a and b such that you need a function of them ?"
49548,do you want each group to have exactly two elements ?
49578,have you tried profiling your code ?
49614,"the negative binomial distribution has two parameters . you don't assume one of them is the same for the two samples , do you ?"
49622,what happens when you try a non-panel version of poisson ?
49644,"first : i don't understand if you want to find the probability that x belongs to v or to s , and if x is a value within v or just any value to assess against s ( and then what is v ?"
49640,"i'm having trouble understanding your question . are you asking if it's acceptable to set your alpha level for significance at 99 % , as long as you do this beforehand ?"
49649,why are you scaling the summands with $ a_1 $ and $ a_2 $ ?
49672,what kind of software is that ?
49702,how large are your two data sets ?
49725,"didn't you already specify that $ f_ { y theta } $ is that of a $ n ( theta , 1 ) $ ?"
48581,"you have not made it easy for us to understand the question here . what , for example , is the "" race model "" ?"
49710,what's a frequency ratio ?
49293,"i guess the question is the following : "" how can one simulate data with binary response and features with predictive power "" , i . e . an artificial dataset for a binary classification problem . zkhan can you clarify ?"
49821,are you interested in the theoretical aspects or in the practical aspects of doing so with some software ?
49703,are you confusing prior with posterior ?
5268,"in addition to galit : do you want primarily to find correlations and hence clustering is just the way , not the goal , or do you want to find clusters of users to discover some knowledge in the data ( with respect to correlation ) ?"
49891,"why don't just define seasons as they are [ standardly defined ] ( url ) , using solstices and equinoxes ?"
49925,are you assuming that the _hazard_ rate is constant over a period or the _survival_ rate is constant ?
49929,"i don't understand . did you ( 1 ) obtained two clusters of the 30 patients ( some in one group , some in the other ) using information from 6 variables ( a f ) or ( 2 ) there are two cluster analyses , one using two variables ( a , b ) and the other based on patient values on four variables ( c f ) ?"
49258,is not weighting g by u is enough ?
49970,"note that $ e ( 1 / y ) neq 1 / e ( y ) $ ; so , the things the arithmetic and harmonic means 'estimate' are different . your prime consideration should probably be 'what expectation do you want to know about - the rate or the interval ?"
50015,"how does any such correlation test for monotonicity - unless it it's 1 ( or -1 ) , the relationship between sample quantities isn't monotonic . how does a p-value relating to to the usual spearman test identify an underlying monotonic relationship as opposed to something else ( perhaps one that is mostly increasing but isn't monotonic ) ?"
50040,does d vary with the alternatives ?
50028,do you mean $ ( 1-p ) $ ?
50140,"can you clarify ` instead , i want . . . obtain d , such that each element d_ij is a function of the entire vectors c_i and c_j ` ?"
50184,two comments which might be helpful : ( 1 ) did you see that a sketch of the proof of the desired result is given in the appendix of the paper ?
50198,how did you measure the values of your data points ?
50229,"what is "" fico range "" ?"
50068,what is $ f $ ?
50239,"welcome to the site , vincentphilion . your comment still makes it seem like the same answer could address both questions . here you state that you'd like to "" understand how to use these tools and choose the right one "" , there you ask , "" what makes these models so different , and how can i choose between them ?"
50263,"you state that your response is pairs of ( x , y ) values , do you mean something like where an arrow hits a target relative to the bulls-eye ?"
50277,"do you mean numerically equally as possible , or both numerically and in terms of the number of items ?"
50282,"can you clarify what each symbol means in your formula for "" the error to the function "" ?"
50321,is this a homework question ?
50329,"pca does dimension reduction within a set of variables . to do dimension reduction that maximizes correlation * between * sets of variables , you may want to look at * [ canonical correlation analysis ] ( url ) * . ( in the case where you have a univariate $ y $ , finding the linear combination of $ x $ that best predicts $ y $ would basically just be regression , wouldn't it ?"
50333,does each of the 25 patients have 19 electrodes ?
50331,is there any way to migrate this question to the data proposal ?
50344,"the usual probit model arises when you assume some underlying latent variable follows a usual gaussian-error regression model and that latent variable is binned into categories . when there are only two categories and the threshold at $ 0 $ separates them , you have the usual binary probit regression model . with more thresholds ( and therefore more categories ) you have the ordinal probit model . i'm failing to see the connect between that and this . what am i missing ?"
50272,"dear pedro , ( 1 ) for your post , which is the kind of question that makes cv very invigorating and stimulating , at least to me . could i ask what the origin of this question is ?"
50343,"what exactly are you asking with * "" how does one balance for the discrepancies between the months you are comparing ?"
50363,"welcome to the site , alan . your question is a little sparse to be answerable . would you mind telling us more about your situation , your data , & your goals ?"
50370,"note that $ p ( x_1 , x_2 , y_1 , y_2 ) = f ( x_1 ) g ( x_2 ) h ( y_1 , y_2 ) $ . what does this tell us about the independence of the random variables ?"
50348,"( 1 ) what does $ mathbb { e } [ sigma_i ] $ mean when it is stipulated that $ sigma_i $ is a "" known characteristic "" ?"
50512,what are you trying to get at by using the number of days as the dependent variable ?
50525,"could you create an "" attendance "" variable that's either the percentage of a "" full class "" or the percentage of the department that attended ?"
50543,"are you estimating a common parameter , or are we in the "" [ combining independent significance tests ] ( url ) "" type territory ?"
50513,estimator of what in what kind of context ?
50556,1 ) what is ` r ` or ` delta r ` ?
50501,what has u got to do with this problem ?
50602,why not use both predictors ?
50626,"this could get rather involved because the two correlation coefficients are not independent ( so the fisher p-value you obtained is meaningless ) . but before you plunge into that , could you please tell us how you plan to * interpret * a difference in correlation coefficients ?"
50657,please show us how you generate your simulations and calculate their variances--how else are we to know what the problem is with them ?
50655,i might be wrong but by calculating percents you've already ranked them against each other ?
50691,if this is homework please tag it as such . please also update your title to something that reflects the nature of your problem . tell us about your 3 items . do they measure the same construct ?
50660,"could you clarify please , which three null hypotheses you mean , and what you mean by "" the initial hypothesis "" ?"
50715,"your final score is a random variable . as such , you need to optimize something to do with the distribution of the random variable . do you seek to minimize * expected * score , or some other quantity ?"
50726,can you include code to reproduce those toy examples here ?
50585,just a point of clarification : is $ mathcal x $ assumed known ?
50781,"would you elaborate more on what you mean by the "" size "" of the classifier i . e . disk storage or complexity or what ?"
50798,"also , where is your data coming from ?"
50812,"do you mean to say that $ x $ is an actual or observed value and $ y $ is it's prediction . further , are you interested in how well $ y $ predicts $ x $ ?"
50822,"welcome to the site , scansally . this appears to be * only * a question about how to get r to do this for you . if that's true , this q would be off-topic for cv ( see our [ faq ] ( url ) ) , but on-topic for [ stack overflow ] ( url ) . are you also interested in understanding ( eg ) the use of the f-test as a simultaneous test to assess multiple variables , or some other substantive statistical issue ?"
50843,"welcome to the site , nkhuyu . i don't fully understand your question . are you worried about multicollinearity , or are you worried about finding an incorrect sign due to sampling error alone ?"
50864,"you will have severe problems , regardless of parameterization , because your data don't come anywhere close to being described by this class of curves . i would like to suggest you would be better served here by abandoning this particular question and telling us instead about your data and your analytical objective : what do you really want to find out ?"
49832,where does ben bolker's comment come from in # 1 ?
50878,it's hard to tell what is being asked here . do you want to know how to negate all components of a vector ?
26999,can you post some data so we can replicate the problem ?
50844,you have already specified the covariance of your data as $ mathbf { sigma } = begin { bmatrix } 18 & 0 0 & 18 end { bmatrix } $ - and you haven't specified a prior distribution for that to be updated from ?
50889,what do your acceptance rates look like ?
50890,perhaps you can tell us in just a tad more detail _what_ integration you are doing to come up with $ ln ( operatorname { cdf } ( z ) ) = -1 $ ?
50947,it is indeed normal for rounding error of $ 10 ^ { -7 } $ to have * profound * influences on matrix operations when the [ condition number ] ( url ) of the matrix is huge--in this case it is approximately $ 10 ^ 6 $ . but why are you using single precision floats and not double precision ?
50953,what is the purpose of interpolating the values ?
51005,those soas . . . they must be just transforms of each other with a little noise . they really look like they're measuring the same thing . what are they ?
51103,"if this relates to some course , could you please tag as homework ?"
51121,1 . is your dependent variable also ordinal ?
50821,"now that you got your tumbleweed badge here , do you want your question migrated to stats . se ?"
51176,since when does regression _assume_ multi-collinearity ?
51208,why run two regressions when you can run one with a dummy variable for weekends and just test its significance ?
51249,"basically what you have is a distribution that is the sum of 2 component distributions . if these were both normal , this would be trivial . do you know what the other dist is ?"
51284,what does _overall should be uniform_ mean ?
51295,"if each person ranked 25 items than the sum across the 25 variables is a constant ( 325 ) . given that , what do you mean saying ` the best ways to compare these rankings ` - _what_ type of difference bw the 2 groups would you like to know ?"
51309,"are you looking for 'distribution free' stuff , or nonparametrics in the sense of "" infinite parametric "" , whether it applies to distributions , relationships between variables or whatever else ?"
51343,"it seems any answer must depend on the missing information lying behind your "" somehow . "" can't you give us more to go on than that ?"
51321,box-muller attempts to give you * two * independent normals . are you asking about vectors of normals ?
51368,could you clarify how this is a markov chain ?
51378,"could you clarify how exactly you want to "" weight your response variable "" ?"
51041,"well you need to have some means of rating the result of the combination of the 5 performance measures , otherwise how will you know if you combined score used to rank the performance measures is effective ?"
51394,it's not that the hierarchical model is hopeless ; rather it appears that your sampling scheme needs some tweaking . have you tried different proposal distributions for the metropolis step ?
51409,do you mean to say that the edges represent interactions which are statistically significant as determined by their use in a regression model ?
51443,in what statistical package ?
49513,are all $ k $ elements of $ y $ numeric ?
51473,is your matrix transposed correctly for the function ?
51510,don't * * all * * data have errors ?
51508,"it's great that you have a substantially less vague hypothesis going into this than usual but it leaves some questions open . what alternatives do you want this tested against and what is "" uncorrelated "" ?"
51074,how do you scaled your training data ?
51524,what problem do * you * particularly face ?
34769,"in order to give the best recommendations , it would help us to know how you will proceed after identifying "" significant predictors . "" are you trying to * predict * the outcome as exactly as possible ; find a * parsimonious * way to predict it ( e . g . , using a set of up to * k * predictors that will efficiently do so ; * explain * what causes the outcome "" in reality "" ; or something else ?"
45947,any idea what causes the clustering ?
51613,what is the basis for your thinking ?
51685,"is 'histfit' in some package , or do you mean you just typed it in in the hope that such a command might exist somewhere ?"
51705,"just to be clear , are you trying to find the var given some horizon in the future with some holdings today , or are you trying to evaluate the var of the strategy in the past ?"
51726,"hello katelyn , this sounds like an interview estimation question to me , like "" how many drycleaners are there in new york ?"
51763,there is no such a menu in spss ` analyse generalized linear model repeated measures ` . are you speaking of general linear model ?
51786,i don't know logit regression . can you give more details ?
51805,"there is no way to prove that it will converge to the global maximum , as that is not the case . do you mean prove that it will converge to a stable solution ( rather than , for example , iterating back and forth between two solutions indefintely ?"
51820,"unless $ a $ or $ b $ are small and unequal , the normal approximation will be accurate to better than $ pm 5 $ % . is that fast enough ?"
51835,is it possible to try to survey those who originally did not respond ?
51801,how does it define its boxplots ?
51872,if this is for some subject would you mind marking it with the homework tag ?
51915,the verbose notation gets in the way of the question itself . ( why on earth do you need * two * subscripts $ i $ almost everywhere ?
51921,why do you believe a quadratic polynomial has to include the linear term ?
51804,this is very odd . what happened to the 55-3 = 52 texts that were predicted to be minus but weren't ?
51930,"hi user45185 . you seem to be posting a lot of 'bookwork' . if this is for some subject , or just for self-study , would you mind adding the 'self-study' tag to the ones that don't have it yet , please ?"
51937,"proton , i don't notice in your previous question where you mention that qq-plots are not well-defined . mathematically the phrase "" not well-defined "" has a specific meaning , & i don't think qq-plots meet that definition . can you state more qualitatively what you are concerned about ?"
51932,"your discussion of ` x1 ` and ` x2 ` indicates you are thinking of them as random variables . however , you do not describe what assumptions you are making about them ( are they supposed to be independent of each other ?"
51950,"( 1 ) are these regions known and annotated as such in your data or do you have to "" identify "" them after the fact ?"
51954,( 1 ) what does a q-q plot show ?
52004,thank you . ( 1 ) are the sets drawn with or without replacement ?
52006,"does "" completely random "" mean uniform ?"
52034,can you be more specific about how you plan to fit the logistic model ?
52041,it is not clear what properties you demand for the factor scores to be ` same metric as the raw data ` ; ` or the latent variable ` is even more mystic ( isn't factor a latent variable ?
41791,"can you say more about your situation , data , & goals here ?"
52087,"please clarify : your question basically is asking how to change the "" weight function "" ( among other things ) in order to make hermite polynomials orthogonal with respect to your mixture--which is a * fixed * weight function . in short , you ask how to change something while leaving it fixed . that makes no sense . what do you really need to do ?"
52027,"by and large your data distributions don't matter : the time to start looking closely is after you have fit some model to the data , for then the distributions of the * residuals * become important for inference . how are your anova residuals distributed ?"
52067,"please edit the question to be more precise . do by ` multivariable ` you mean multiple independent variables ( "" multiple regression "" ) or multiple dependent variables ( "" multivariate regression "" or "" man ( c ) ova "" ) ?"
52182,what do you plan to do with the data after outlier detection ?
52091,"i agree with you about that , john , but unfortunately this question is broad . i would struggle to give a full answer in less than a short monograph and i suspect many other people would have a similar problem . dl10x , could you edit your question to be more specific about the samples you have and what you are trying to learn about them ?"
52191,is this homework ?
52206,does down-weighting actually result in major parameter changes ?
52203,"can you please specify which kind of "" robust "" regression you are using ?"
52080,do the errors come in $ x $ or in $ y $ or both ?
52325,"you can view this is a mixture of a ( shifted ) exponential and the negative of another shifted exponential . raw moments ( around zero ) of mixtures are easy to compute , because they are comparable linear combinations of the raw moments of the component distributions . but must you ?"
52346,"what exactly is a "" vote map "" ?"
52360,"it is unclear what you are doing . what does it mean for a vector to "" contain . . . samples "" and , when $ a $ , $ b $ , $ c $ , and $ d $ are vectors * of different lengths , * what do their products mean ?"
52365,are you asking how to compute means and sds ?
52243,"your question started to become ambiguous the moment you referred to undefined objects and to use some idiosyncratic notation . for instance , $ f $ appears early on but has no apparent connection to $ f $ and it is only by reading much further that we learn you're thinking of it as "" not a discrete distribution "" --but what kind of object is it ?"
52353,what is the question ?
52421,"i might be missing something in your question , but both the ` ltm ` and ` mirt ` packages can handle missing data just fine for 2pl models . have you tried either of those packages ?"
52428,in what way is the question related to spearman correlation ?
52497,"the caret notation , e . g . $ hat { y } $ usually means "" estimated "" . is this ordinary least squares regression ?"
50012,what is the question ?
52561,"( i ) what "" signal "" are you using the wavelet to represent ?"
52562,"` i was reading similar articles on similar experiments , and the investigators used discriminant analysis to verify their cluster groups ` didn't those articles people tell what they did and why ?"
52604,i would interpret this as balanced per each level of factor ` b ` . or am i misunderstanding something ?
52623,your question is missing a crucial detail : what error ?
52632,"some clarification may be required . there are two samples . where it says 'sample size of 30 . . . "" is that in * each sample * ?"
52564,closely related : [ measuring individual player effectiveness in 2-player per team sports ] ( url ) . also of interest : [ how to get started with rating and ranking based on pairwise competition data ?
52722,"did you mean _tf-idf_ , not _tf-df_ ?"
52773,can your question be summarized like this ?
52804,can you explain what exactly constitutes 'mutually exclusive mutation' in the table ?
52828,have you checked how this percentage is actually calculated in the pca case ?
52818,"zen i am absolutely confident that this is what the relationship is commonly called--see the reference--and indeed its proof goes through upon assuming independence , which of course was implicit in the question . ( no harm pointing out that independence must be assumed , which you already did in your nice answer , but why keep harping on that point ?"
52838,your cluster-solution images are from spss ?
52845,so why do you think that srs is not the right approach here ?
52860,"generally , if i see the abbreviation "" ma "" , i would expect [ this ] ( url ) is being discussed . could you explain ( in your question ) what ma stands for the first time you mention it , please ?"
52928,""" * the raw data is not normally distributed * "" - why would this matter ?"
52945,"whuber raises a key question , but i am not so clear as he is on what your answer is : are you thinking of these 27 cases as a sample or a population ?"
52889,user1493368 what type of matching do you intend to do ?
52929,"could you please provide context , details , and an explanation of what you mean by "" diverging "" and "" significantly different "" regression models ?"
53021,"please don't assume people are aware of abbreviations from other disciplines . you say "" the cocomo81 dataset "" like we should know what that is . don't make that assumption . is it something to do with [ this ] ( url ) ?"
53042,which classifier are using in the wrapper fs of weka ?
52426,"if $ y_i = x_i beta epsilon_i $ where $ epsilon sim ( 0 , sigma ^ 2_i ) $ do you want a confidence interval for $ y_i $ or $ e [ y_i ] = hat { y } _i $ or $ beta $ ?"
53115,"are you interested in whether the groups differ on the outcome measure , or whether the groups differ _controlling for_ the covariate ?"
53191,why are you asking ?
53195,are you sure that $ bar { h } $ is not previously defined ?
52873,"in this case , why not email andrew ?"
53151,what's the matter with peter flom's answer ?
53274,what does $ * $ represent ?
53349,can you explain _why_ you don't want to use a monotonic transformation ?
53414,"can you please explain a bit more what you mean by "" the relationship between some pairs of components is highly significant . "" just to clarify , pca does not give you necessarily "" statistically uncorrelated "" components ; only "" orthogonal "" ones . ( these scenarios might overlap but it is not always the case ) . actually , as you present your modelling assumptions it would be worrying if some correlation didn't came forward in certain cases as it would mean that nested structure is practically totally redundant . how big is your sample by the way ?"
53433,could you tell us what units of measurement your numbers are in ?
54514,why do you want to normalize this variable ?
54568,"following from the weight example - are the repeat measures at baseline ( or followup ) supposed to measure the same thing , with differences between measures reflecting only random error ?"
54618,"i have edited your question to make it a little more focused , but it still needs to be more specific . can you give more details on what kind of ncrnas you are searching with , and what the objective of the search is . is it to identify putative ncrnas on a new genome ?"
54645,"the law of total probability allows you to express the law of $ z $ as a weighted sum ( weights $ p $ and $ ( 1-p ) $ ) of the laws of $ x $ and $ y $ . then , $ e [ e ^ { tz } ] $ can be calculated from the law of $ z $ . i assume that you know the formula for finding $ e [ g ( z ) ] $ using the law of $ z $ ?"
54668,"because you appear to be in an exploratory mode ( "" trying to come up with a model "" ) , why not first use exploratory methods like loess smoothing ?"
54674,"if you estimate this by maximum likelihood , can't you just compare loglikelihoods ?"
54692,"an ` r ` comment : ` y - rep ( as . vector ( t ( human ) ) , each = 3 ) ; c - rep ( compound , each = 9 ) ; x . . . ` would give you the same stuff much faster and with less visual clutter . additionally : you seem to discard information about the fact you have replicates . you sure you want to do that ?"
54724,"uh , how do you know what $ mu $ and $ sigma $ are ?"
54753,"consider reviewing what you know about regression . if you were * told * the correlation , as well as given most of the data in the question-- $ 88 $ , $ 64 $ , $ 8 $ , $ 45 $ , and $ 5 $ --could you compute the prorated value of $ 55 $ ?"
51006,have you considered [ * winbugs * ] ( url ) ?
54794,is there some reason why you want to ?
54797,'it is easy to come up with examples for p and k 1 where the solution is unique' can you add one such example to your question ?
54805,have you thought about trying propensity score matching ?
54817,"this seems to be a homework problem , if so please mark this with the homework tag . could you please say in what particular area you are having problems in ?"
54849,what does $ a perp ! ! ! perp b $ mean ?
54884,"there are many ways to make such comparisons , depending on the application . what is your intended purpose ?"
54879,"welcome to our site ! it seems you already know the answer to your question : if your model uses values that won't be available for prediction , then there is no way you can apply it , can you ?"
54896,"it is clear the two approaches are different , because your proposal fails to obtain ( correct ) information about the * uncertainty * in the estimates . so in what sense do you mean "" equivalent "" ?"
54899,"if the outcome is binary , you don't want cox - cox is for cases where the outcome is time and is censored . but do you have one observation per person or multiple observation ?"
54951,will [ overals ] ( url ) - linear canonical analysis which optimally scales ( monotonically transforms ) variables to maximize canonical correlations - be to your liking ?
54750,i find that stata is more likely to fail to converge with complex problems than other software - is there anything else you can try ?
54947,"if $ s_1 , . . . s_n $ are ( assumed to be ) i . i . d . , then $ ( x_t ) $ * is * a renewal process . no ?"
54972,"you appear to be using the term "" confidence "" in an unusual sense . could you provide us a definition , please ?"
46824,is there any way of knowing which classification is correct ( a so-called 'gold standard' ) ?
54943,"offhand i'm familiar with at least a half dozen conventions that could validly be called "" tensor notation . "" one of them is infamously called the [ "" debauch of indices "" ] ( url ) : i hope that's not the one you mean ! but what exactly do you want ?"
53078,"that is alot of wasted space imo ! do you really only have 3 values ( below 0 . 5 , above 0 . 5 , and the observation ) or is that just an artifact of the example you gave ?"
55001,what is the correlation between the replicate samples ?
55011,i get a p-value of 0 . 0046 or 0 . 0030 with ties . are you sure you're doing this test correctly ?
55054,"a "" trivial "" observation : if $ x_1 $ takes values in $ [ a , c ] $ and $ x_2 $ takes values in $ [ c , b ] $ , then whether they are independent or not , $ x_1 x_2 $ takes values in $ [ a c , b c ] neq [ a , b ] $ . have i misunderstood your question ?"
55085,removing outliers is extremely complicated and everyone has a different opinion . why do you believe you have significant outliers ?
55090,what is your research question ?
55093,try r-shiny ?
55018,"i agree that sd vs . se is potentially a pretty silly critique ( absent any other justification ) . a good way to plot the original data is to make the lines very thin and semi-transparent , this allows one to see the distribution of the raw trajectories . can you give an example of what you mean by "" individual differences "" ?"
55104,both images show too much spatial association for either to be purely random ( there's a clear boundary in both ) . what summary of or information from the images exactly would you be testing for being poisson ?
55068,are these predictions on new data not in the training set ?
52412,which hypotheses do you want to test ?
55189,sorry i'm not sure i understand the data - what are decision rules ?
54522,great answer from whuber . but i don't understand why you don't produce the graphics in r too ?
55212,do the sample sizes reflect population sizes ?
55134,do you know if that formula uses kurtosis or excess kurtosis ( i . e . does normal dist have 4 or 0 ) ?
55248,"your language may confuse many readers , because the k-s test compares * empirical probability distributions * to each other or to a reference distribution , whereas in most time series applications the question of interest is to compare how the two series are varying over time . although similar-looking graphs of values may be involved in both kinds of comparisons , they are totally different . which one do you really want to ask about ?"
55251,"terminology sometimes varies ; can you describe your data , your goals , & what it is exactly that you want to do ?"
55273,what's the coefficient on the new variable ?
55298,"the problem with non-point nulls is you can't compute the distribution of the test statistic . equivalence tests done using hypothesis testing only work if you have one-sided tests and then they're two normal tests , not the inequality type you mention . you can do the confidence interval equivalence thing , but again , it's not showing they're * actually equal * -- none of these things can do that . i presume you were the one asking about this stuff [ here ] ( url ) ?"
55300,is there something special about your subsample ?
55333,chi-square can be done with more than two variables ; but it's not clear that that is what you want . is one of your variables ( or more than one ) a dependent variable ?
55356,"this looks to be quite an odd experiment i have to say . i've had a go at answering because i think there is useful information in my answer on using inverse of variance to weight . but to give more meaningful advice we'd need to know exactly what you're trying to do - for example , why do you know that coefficients with a se = x are completely useless whereas those just below that threshold presumeably aren't . but most importantly what is the point of this whole thing ?"
55390,are you sure they are not ?
55443,"your frequency table is curious , because it could emerge under different studies , but you are silent about details . my imagination , for example , take it so that you recruited people aged 90-99 and forced them to exercise under different intensity levels . 12 died during extreme session , 2 died at heavy session , etc . 1 died just being reserved . but how many of the old men survived ?"
55322,"i'm saying that if only some of the people in the second sample's times were delayed , then the two sample difference in means does not reflect the average time delay - to estimate the average delay you will need to know how many times were delayed . do you have that information ?"
55411,"hi , please take a look at the discussion of homework questions in the faq [ the lower part under this heading ] ( url ) and also the [ self-study tag wiki ] ( url ) . with that information in mind . . . what have you tried so far ?"
55473,there is not enough information available here . how large is your data ?
55463,why do you want to fit a distribution in the first place ?
55475,"what's your definition of "" better "" or "" worse ?"
55504,"this question is rather broad . much of the information in it appears irrelevant : what matters is that you have an estimator $ ( hat { x } , hat { beta } ) $ of $ ( x , beta ) $ and you would like to know of methods to evaluate it that do not use a simple or closed formula for $ ( hat { x } , hat { beta } ) $ . so , in effect , you are asking for a general treatise on statistical estimation . to narrow your question , could you tell us about the actual problem you face ?"
55480,"hong , once again in words . for each cluster you have a data matrix * * a * * ( or a row vector ) point ( s ) x variables . center _columns_ of * * a * * and compute * * a'a * * . this is what called scatter matrix ( [ see ] ( url ) ) . ( so , if * * a * * is a vector [ ?"
55598,"( 1 ) likert scale-items are ordinal not interval . they don't * have * a mean . ( 2 ) what are the proportions in each category , and what sample size is this for ?"
55603,did you try to validate your classification ?
55610,"( 1 ) the anova analysis is suspect due to the strong heteroscedasticity in the response ( the variance of a count is proportional to its square root ) , so obtaining a significant result with this method means little . ( 2 ) which better describes such data--the poisson model without interaction or the anova one with an interaction ?"
55629,"i don't understand . if dvrt is the dependent variable and verx_s is the independent variable , then you don't need logistic regression . but you can't recode your iv to match your dv ! that would make no sense . it would help to provide context here . what are these variables ?"
55660,"probably a stupid comment , but we've all done this at some point : are you recompiling your code when you change c before re-running ?"
55662,are these any help ?
55717,where did you get the idea that some of the zeroes had to be false ?
55752,do you mean you took the test ?
55769,"if $ 1 a leq theta $ and exactly one or two or three or . . . or $ n $ of the $ x_i $ 's equal $ a $ while the remaining $ x_j $ are smaller than $ a $ , then it must be that $ max_i x_i = a $ , right ?"
55807,most certainly . what is your goal ?
55827,i think some more information is necessary . why are you only fitting on part of the data ?
55840,a few questions : what is her hypothesis ?
55856,"it is not quite clear what your design is , but i'm trying to guess . ` visit1 ` is time , ` batch ` has two levels , ` sampleid ` is the subject , no continuous covariates . and you suspect that batch has a linear effect on the substance level , and try to see how it reacts over visits ?"
55621,correlation makes no sense if one of your variables is nominal . do you mean * relationship * ?
55939,"could you please explain the sense in which your ` x ` and ` y ` values define a single "" distribution "" ?"
55953,"weight recorded in micrograms is not going to be categorical data , as far as i can see ; do you mean that * location * is categorical ?"
55981,did you mean to include income twice when defining new ?
56018,"if in fact subject # 2 performs better under condition 1 for high values of the stimulus & better under condition 2 for low values of the stimulus , do you really * want * a single number to sum up performance ?"
56036,"diptopoldam , _did_ you read attentively a linked post in my 1st comment ?"
56039,"looking at your item 2 , how is a sum of p's an average of p's ?"
56096,are they worried about power or over-fitting ?
56055,what are your hypotheses ?
56104,"if you have jumbled control and treatment labels , nothing can rescue it . on your last sentence - standard deviation of * what * ?"
56152,` i was hoping the algorithm would decide the factors for me ` it should . why are you dissafisfied and want to do it manually ?
56141,"1 i think this is a great question : it cogently challenges accepted wisdom , forcing us to think harder about why certain practices are correct and good . but , to narrow the scope a little , i would like to ask about your situation . ( 1 ) are you certain the relationship between the dependent and all independent variables is linear ?"
56230,"what do you mean by "" making predictions "" - do you have a value of one of the variables and want to predict the other ; or do you need to predict both variables simultaneously ?"
56139,do you have a cost function ?
55684,i'm a little confused -- you you have data on all of your explanatory variables ?
56303,"what do you mean by "" the variance of a factor "" ?"
56304,"i'm a bit confused about your analysis . when you ran ( or run ) the anova , how many repeated measures variables did you have ?"
56374,""" * the fit does not model the original time series precisely , in my opinion * "" -- why would you expect it to ?"
56385,what math do you already know ?
56392,is there some reason to do pca rather than ca ?
56373,"i am not familiar with lda , but are you doing gibbs sampling ?"
56408,what happens when you also add the ` constant ` option ?
56459,"given your explanation , i don't think the part $ if ( y fx ) $ is wrong . but if your intention is to implement rejection sampling ( which appears to be the case ) , then you need some more work . can you clarify why you think that part is wrong ?"
56466,is there a reason to choose 'likely negative' as the correct imputation from 'unlabeled' ?
56399,what is the purpose of comparing the variability ?
56494,"why not just use an initial segment of the data--such as the first 100 or first 1000 or whatever--to erect "" fences "" for screening outliers ?"
56498,why do you care about the performance on the training data - if you have a test set ( needed if not doing cv ) then why not use that ( which presumably is not oversampled ) ?
56530,"despite the collinearity , is there a reason your results are not interpretable as is ?"
56452,i may have prematurely edited your question . were participants randomly assigned to treatment or control ?
56585,could you explain a little more what you mean by 'differentiating' between them ?
56608,it might be useful to give more details about the r procedure . which package did you use ?
56615,"* * none of these questions are answerable with the information given . * * in some cases , by making some quasi-reasonable assumptions , * ranges * of answers are possible . for instance , assuming the outcome ranks are independent ( which is not going to be the case in most actual races ) , the answer to ( 1 ) is anywhere from $ 20 $ through infinitely many and the answer to ( 3 ) could be just about anything . would you like to say more about your assumptions and the * real * context ( assuming these races are a metaphor for what you're really interested in ) ?"
56534,do you mean you need a ci for the difference of the prediction ?
56651,how is your response measured ?
56676,"with loess , you can adjust the amount of smoothing , did you try different amounts ?"
56701,"for clarity , did the same two raters see all 18 participants for all four time points ?"
56710,"if $ x $ is continuous & its distribution is symmetrical , $ pr ( x mu ) = . 5 $ . is it continuous ?"
56736,why do you want them to have the same variances ?
56724,did you try computing the sum of logs instead ?
56784,"would you like to specifically know how r creates the design matrix for this formula , or are you more broadly interested in how to interpret such a multiplicative ( "" interaction "" ) term in terms of the fitted model ?"
56774,what comparison are you making ?
56868,"if we take "" probability "" merely in the sense of some value in the interval $ [ 0 , 1 ] $ then the answer is of course , in many simple ways ( e . g . , rescale an inverse tangent in # 1 ) and for a full account you would want to ask this question on the math site . but what is the intended interpretation of the "" probability "" ?"
56929,why exactly does this rule out factor analysis ?
56932,my first bet is that the labelling is wrong . are you sure all samples are correctly labelled when you feed them into the classifier ?
56956,forget dose for a second . how would making the intercept 0 in that equation make the survivorship 100 % in any case ?
57064,which final value ?
57027,"could you quote the section , or at least specify chapter and page in the book ?"
57143,"what's your evidence that it is gaussian , other than being rounded and bounded ?"
57147,are you saying that the response scale for each item is 1 to 5 ?
57161,mark . welcome to the site . it's been my experience that the best answers here come from very targeted questions . is there something that you're specifically concerned about with this model ?
57173,i think you need to provide more detail for us to be able to answer properly . you repeated cross-validation 100 times ?
57190,how do you get from 'i don't have spss' to 'sas is my only option' ?
57211,"where does this "" definition "" of mvue come from and how is it related to [ conventional definitions ] ( url ) , where your question simply does not arise ?"
57231,"are you aware that r has the density , cumulative and quantile functions for a t-distribution already implemented ( dt , pt and qt ) ?"
57256,"as far as i can tell , these methods * reduce * the number of dimensions and then ( at least potentially ) plot those . is that what you want , or do you want to plot all the dimensions ?"
57308,that's a first step but that is usually not the problem . at the moment i cannot find an error in the code . it is really strange that the activations become so big . maybe there is a problem with your data ?
57319,"may be start with 2 , then n . what is the sum of two independent poisson random variables ?"
57320,what is your model ( the model you have used for prediction ) ?
57351,"can you say more about your situation , shirley ?"
57348,"not the question at all , but are you really using names like ` var1 ` or are you just being coy about your problem to protect yourself against economists in your field ?"
57363,"hi pitone , have you tried running it and doing cross validation ?"
57372,"i don't completely understand . so you have a within-subjects design , every subject experiences both conditions , is that correct ?"
57427,the relevant quantity for an acceptance region is its probability under the null and under specific alternatives . could you define what you're computing when you say 'area' ?
57486,this seems like a very open-ended question and the best approach might depend on the research goal . do you have a particular one in mind ?
57493,so you want to see whether outcome of interview is related to other variables ?
57498,are you using 'lme ( ) ' or 'lmer ( ) ' ?
57552,do you have repeated measures or is this a cross-sectional study ?
57556,"what would such a distance function look like , even theoretically ?"
57585,"what happens if you run the same model , with the covariate as the outcome ?"
57576,has the data been differenced ?
57618,"when you say "" the original paper "" . . . what paper is that ?"
57620,what's your prior ?
57636,"what do you mean when you say "" * what about the null has more than one distributions ?"
57662,"of course , there is a way . it seems you're new to logistic regression . in the table of coefficients , pay attention to * * exp ( b ) * * . you can open the table and right-click on the field , to ask "" what's that ?"
57733,what does the major exposure of interest interact with ?
57744,"tukey's name is associated with many tests , including more than one test relating to equality of location . it's probably better to be more specific than 'tukey's test' ( though your tags seem to clarify it here , it's best not to rely on that to convey your meaning ) . why do you specify that particular test ?"
57780,what's the purpose of the regression ?
57829,is this a hw question ?
57898,how exactly did they use mcnemar's test ?
57906,could you be somewhat more clear ?
57930,pfs means ?
57933,"to begin with , you do not appear to be generating from an exponential distribution . ( to do that , you would need to compute the logarithms of the reciprocals of the uniform variates . ) why not use the built-in generators such as ` rgamma ` ?"
57949,is there any relationship between y and x ?
58008,"do you need an exact ( analytical ) solution ( not saying that it's possible at all ) , or will a numerical approximation do ?"
58010,"could it just be a compulsion you have , like some people obsessively wash their hands a lot ?"
57987,what gave you the idea to remove non-significant variables ?
57982,"welcome to the site , jrod . just for the sake of clarity , what do you mean by "" binomial "" ?"
58061,"could you expand on what it would mean to "" compare "" two different correlation matrices of different sizes ?"
58081,"adam , do your sets $ a $ look like multivariate bricks , or are they of arbitrary shape ?"
58089,your question is unclear . why are you adding them ?
58107,$ r ^ 2 $ has a beta distribution with parameters depending only on $ n $ and $ p $ . no ?
58198,did the answers come out ?
58225,do you expect the difference between regular and random to change over the time of the experiment ?
58265,"why do you assume the "" error "" is in ` r ` ?"
58293,"for intuition on why the sample size matters , take it to the extreme . imagine a sample of size 1 . now think about a much larger sample , maybe 1000 . what do you think happens to $ v_ { max } $ ?"
58308,you seem to be missing all assumptions about the distribution of $ lambda $ among the attendees--or do you assume they all have the same value of $ lambda $ and arrivals are independent ?
58342,what do you mean by maximum order ?
58354,"presumably the predictors omitted are collinear with some of those included , but that's spss doing good on your behalf , not being difficult . tastes and standards vary , but in my field firing 25 predictors at 475 observations would not be regarded as statistics worth much discussion . i'd advise against fitting anything like so complicated a model to a modest dataset unless you have a really good theory-based story to back it up . incidentally , if you have 4000 companies , what happened to the other 3525 ?"
58381,have you seen this [ recent post ] ( url ) ?
58419,"re the edit : what , exactly , is being combined when you have only one record per name ?"
58438,"if you entered 1500 each for 4 sides of a 4-sided die , why would $ p . 05 $ ?"
58448,what is your model ?
58444,is this homework ?
58504,why would an unconditional bootstrap be inappropriate for your purposes ?
58506,is there a relationship between the variables ?
58532,"could you please be more specific about how a function $ c ( x ) $ "" defines "" a random variable ?"
58058,"the variance of the gaussian regression error $ e sim n ( 0 , , 1 ) $ is necessarily unity ?"
58549,i have also found this problem with nig distribution . i am wondering if you have solved this problem ?
58600,"out of curiosity , why is an approach like ransac needed ?"
58620,are you after a prediction interval or are you after something else ?
58642,"there is potential for confusion due to different possible interpretations of what is meant by $ f $ , $ hat { f } $ , $ x $ , and even $ e $ ( what probability distribution does it refer to ?"
58646,are you sure it is $ eta ( x ) $ ?
58666,iinception have you considered latent growth curve modeling on observed variables ?
58671,why not just test a cubic model and see if the quadratic and cubic terms are large and / or significant ?
58692,""" can i rightfully assume this is not a true main effect ?"
58706,how about edit distance ?
58708,what tool are you using ?
58764,""" * a number of the tests for normality that i could use * "" - off the top of my head i can only think of one suitable "" off the shelf "" test ( perhaps arguably a second ) , though i can think of a bunch that would work if you specified , rather than estimated , the parameters . which ones were you thinking of ?"
58769,""" best "" in what sense , exactly ?"
58793,i noticed your request to migrate this question to so . any reason why ?
58817,what's the objection to line plots ?
58815,"hi samuel , i have edited your question . if you feel that i have changed it away from your intended question , you should edit it to clarify your actual question . can you define your terms , please , and perhaps give additional context for your question , or point to something that has more context ?"
58859,"welcome to the site , riccardocavallari . please don't sign your posts . notice that your username ( with a link to your user page ) & your flair are automatically added to your posts . regarding your question , do you care if the mean or sd is similar , or only if the shape & ranking is similar ?"
58865,"can you define "" similarity "" ?"
58897,"is the data collected by asking "" how many times have you visited the market ?"
57195,"does "" for some reason "" mean it's homework ?"
58905,can you clarify how the tree comes from the transition matrix ?
58962,isn't that 20 * 12 = 240 variables ( if you don't consider interactions ) ?
59036,"you seem to be confusing significance levels with confidence levels . the "" usual "" levels you cite are described as 10 % , 5 % , 1 % significance levels . that aside , how does what you do out-of-sample lead to a significance level ?"
59115,maybe even ask there instead of here ?
59137,"your question is a little confusing to me . is missingness equal to the response with an "" i don't know "" answer ?"
59163,are you familiar with the concept of * sufficient statistics * ?
17890,"can you tell us , which book is it ?"
59190,"hi christian , welcome to the site . by "" leas-chi-square fit "" do you possibly mean [ least squares ] ( url ) , which is a normal linear regression ?"
59181,"not my field , nor my religion , but i thought cfa meant confirmatory factor analysis . but to increase your chance of a good answer from those who do this , could you give a reference or an example ?"
59161,can you post the error which you get ?
59204,what about the ` r ` package [ penalized ] ( url ) ?
59264,"you don't explain what ` envfit ` is or does . but whatever you are doing , the impression is that you are surprised that one predictor has only a moderate r ^ 2 . the answer seems to be as much ecology as statistics , namely that you surely have many variables at play in your system and you don't really expect one to dominate , unless that's part of your design . otherwise put , are you surprised that everything but lakes accounts for 0 . 81 ?"
59297,"i don't follow this . one point to the pilot is to obtain preliminary information such as useful estimates of population variances , which can then be used to design a full study . the pilot is intentionally made small so that no resources are wasted in collecting unnecessary information . what prevents you from conducting such a pilot study , then ?"
59309,"you mention "" daily "" several times , but i still have to ask : do you really * need * daily forecasts ?"
59327,"dra . alejandraecheverria do you mean that you have one linear regression model with two independent variables and that you want to test the equality of the two coefficients on the independent variables , or , you have two simple linear regression models and you want to compare the coefficients across the two models ?"
55715,"i'm curious : what was the reason you did not like , say r ?"
59328,"in similar problems , the setup is usually $ y sim mathrm { pois } left ( theta right ) $ and $ z y sim mathrm { binom } left ( n = y , p right ) $ . are you sure the problem has been copied correctly ?"
59361,"what makes you think "" * the test he used is called p-test * "" - there's no indication in the text near the phrase "" * all the differences between * "" to suggest what test was used ; only a p-value is quoted . when you say 'fscore' what are you referring to ?"
59282,"please explain what "" enclosing "" means . perhaps you could tell us what problem this procedure is intended to solve ?"
59405,what do the data look like ?
59425,"i'd try rewriting this much more concisely . try standing back from this highly specific question , which is very difficult to follow . tell us what you are trying to do and why . it sounds as if you want to class or bin measured data into intervals . why is that even needed ?"
59444,"godzilla what do you mean by "" good "" and "" bad "" ?"
59467,"( 1 ) what you seem to be missing is that when you change $ k $ , you change $ ll $ . ( 2 ) what do you mean by "" mdl "" ?"
59473,"you can place upper and lower bounds on this probability . for instance , could the information be consistent with a probability of $ 1 $ ?"
59539,what's q97 ?
59546,"do you mean you have * paired * data $ ( x_i , y_i ) $ and you would like to determine whether to use a paired test or unpaired test to compare $ overline { x } $ to $ overline { y } $ ?"
59554,can you be more precise with program / function used for correlation clustering ?
59568,do you mean ` mvrnorm ` rather than your ` rmvnorm ` ?
59569,"i was somewhat confused by the introduction of the time series element , which complicated the considerations . are you just looking for [ nonlinear regression / nonlinear least squares ] ( url ) ?"
59594,"you don't conduct statistical inference by collecting data and then saying "" i wonder what might be statistically significant ?"
59608,you didn't include size as a predictor in your ` aov ( ) ` call . why not ?
59646,"i know of * lots * of tests that might have these abbreviations . could you please write out their names and , if possible , provide references ?"
59674,"to those voting to close : if this were a pure matlab question we would ship it off to so in a moment . but before you can write that matlab code , it seems to me you have a rather difficult statistical question to answer first ! exactly how do you go about fitting a model to a set of data when that model is given only implicitly in terms of differential equations and not explicitly as a parameterized set of functions ?"
59694,how many observations do you have ?
59703,why would you remove replicates ?
59389,what prior knowledge do you have about the support of the data ?
59704,how much ram do you have ?
59469,"it might be good to ask why you have the one f0_02 so close to the shared root . it might be good to ask similar questions of the 10 , vs 08 , and 07 . is there any chance that the dendrogram is not robust , or that the inputs have noise that confuses the algorithm ?"
59657,"hi lynn , welcome . first , what do you mean by "" too much "" variance ?"
59688,one thing i'm quite puzzled about is that both the papers you link are talking about semi-supervised learning . that's quite a different problem to my interpretation of what the rest of your question seems to be asking . could you give any more details as to what your goal is ?
59757,"in general , a test of autocorrelation would be $ h_o : rho = 0 $ , $ h_a : rho 0 $ . ( many economic time series have positive autocorrelation , so often just the one-sided test is done when working with economic data ) why are you trying to test if the autocorrelation is either more or less than zero ?"
59784,"why not just take logs of both counts & num_replies , & fit a standard linear model to them ?"
55472,"i'm not sure what you mean when you say "" . . . as i understood i would need to determine the number of real locations in advance . . . "" assuming i've understood you correctly , there's nothing in the algorithms which inherently requires this . are you perhaps planning to increase the number of cluster components based on the number of reports ?"
59825,"this sounds like a fun new game . we find or provide a justification , you report it and your supervisor publishes it ?"
22625,"i've changed your second rhs term to $ by_ { t-2 } $ , is that correct ?"
59848,"gob00st have you tried to install the package ( ` install . packages ( "" car "" ) ` ) ?"
59933,logistic regression does not apply to count outcomes ; it only applies to * binary * outcomes . what are you * really * doing ?
59944,warning : when you say _subsequences_ you mean consecutive elements or not necessarily ?
59974,what are you trying to compare ?
59988,"i am pretty good with kalman and matlab . i am not ( yet ) as good as i would like in "" time-series "" , whatever that is . can you give me some sample data ?"
60001,"i have too few ( or no ) experience in this domain to comment the quality of your formulae , but to me it seems very arbitrary . there is an infinity of functions matching your criteria , why this one ?"
60047,why not just set $ z_i = x_i $ and then $ sum_ { i = 1 } ^ n ( z_i-x_i ) ^ 2 = 0 $ ?
60063,best in what sense ?
60107,what's the magnitude of input [ 1 ] and input [ 2 ] ?
60167,"what does "" best "" mean in the context of your question ?"
60162,what is the definition of a lexical feature ?
60197,"surely only the observations present in both lists simultaneously tell you anything about the correlation , unless the missingness is somehow associated with size itself . is this missingness * at random * ?"
60186,""" * are goodness-of-fit tests parametric or nonparametric ?"
60226,"( 1 ) what is the distinction between "" test "" and "" test task "" ?"
60203,"hi pjp , welcome to the site ! forgive my ignorance , but if tvc is a count variable , why does it not always come in integers ?"
60221,"prior to performing the experiment , what is the test statistic ?"
60200,"can you give the link to the chapter of the book you mean , and state roughly where it is to be found ?"
60332,is it also true that each must be between 0 and 1 ?
60353,"testing for heteroscedasticity and adjusting ses for it are different questions . if you're asking why stata made the option unavailable after using ` robust ` , i don't know as i did not write that command , but it is quite possibly because users such as yourself might think that using ` robust ` fixed the problem . as ` hettest ` is available without ` robust ` , why the concern ?"
60352,why did you model ` temperature ` as a factor ?
60354,what assumptions of the linear regression model ( i assume that you're referring to ols ) is violated by skewness in the data ?
60428,"just to be clear , you are doing a binary classification problem with a single ( real valued ?"
60431,why would you need to transform your independent variable ?
60323,how is $ z $ a random variable ?
60466,have you tried replicating a simpler analysis to see if that works ?
60394,"you should start with a smaller , but fully-worked example ( the date is beside the point to your question ; you just need an integer to stand for the different values time takes - such as the number of minutes since 15 : 00 ; the solution to the simpler problem solves the bigger one apart from some fiddling ) - i . e . also give the desired result , including for all tricky cases . e . g . what happens if there's only one value at that time ?"
60359,i believe you are unnecessarily narrowing the scope of your question . why not instead ask * how * to solve your problem rather than asking whether linear regression will solve it ?
60454,what does your feature vector look like explicitly ?
60559,"just to be clear , you have no other data , or timestamps , that might be helpful in flagging erroneous 4 . 7's ?"
38835,"please excuse if it sounds rude , but . . . where are you stuck ` after reading thousands of articles on pca ` ?"
60637,don't you have 8 parameters as is ?
60660,"if your data shows a clear pattern , presumably you want a model that fits that shape . why are you trying to transform first ?"
60678,what would be the purpose of binning in this particular case ?
60694,i've seen tables organized at least four different ways . what tables are you using ?
60697,can you say a little bit more about how the data failed the chi-squared test ?
60742,"i don't understand : doesn't 0 mean "" absence "" and 1 "" presence "" ?"
60751,is this what you're looking to do ?
60760,"in the second output , the number of iterations to reach convergence seems to be 4 , not 25 or am i missing something ?"
60746,what about ` t . test ` with ` var . equal = false ` ?
60766,could you tell us a little more about your sample ?
60787,"with "" coefficients at the second level "" you mean the level where the you the parameters of the first stage as dependent variables ?"
60803,is it your contention that the estimate of the intercept parameter must equal the sample mean ?
60809,"this is not actually simulation under the assumptions of regression , but bootstrapping ( resampling your data ) . why do you think this will have the right coverage probability ?"
60816,can you tell us what you have so far ?
60826,what have you tried ?
60864,"i can't follow your question , because it's not evident what role the $ x_i $ play in your "" linear model "" or what you're really trying to do . if you have the raw data , isn't this just a tangential exercise of little relevance ?"
60904,what form does their response take ?
60710,"what , then , is your question ?"
60938,are you aware of [ fieller's theorem ] ( url ) ?
60948,"out of curiosity , is the ability to extract the entities and relationships ( e . g . andrea feels x about ny ) part of the differentiation between algorithms , or is the exercise purely about evaluating the accuracy of the value assigned to x ?"
60958,"yes , that's exactly the deviance . maybe [ this ] ( url ) and [ this ] ( url ) will clarify deviance further ?"
60963,which p-value do you want ?
60990,isn't this related to [ what statistical analysis can be used to validate whether a new release of software was really worth it ?
60994,you're trying to fit a sine wave to the data or are you trying to fit some kind of a harmonic model with a sine and a cosine component ?
61015,what software are you using ?
61036,did you try increasing the bandwidth parameter of your kernel ?
61044,what software do you use for fitting the regression ?
61067,""" reasonable "" implies you have a loss function in mind , for otherwise this question is unanswerable . what is it ?"
61078,"to be clear : cross-validation uses 100 % of the data . at each iteration , some p % of data is trained on , and ( 100-p ) % is tested on , and the average score is returned . to say ` i'm setting aside 40 % of my training data for cross-validation , and so training on 60 % . ` sounds strange . can you elaborate ?"
60885,"we'll need to know more about the behavior , is it ordinal / binary / continuous valued ?"
61106,"welcome to the site , user26594 . can you clarify your question ?"
61130,i think you should give us some sense of what you are trying to achieve or what you think these correlations would reveal because 3-way correlations or which environmental variables are correlated well in all 3 regions is somewhat vague . also how many measures do you have in each region ?
61131,you have both age and year as predictors in the model . can you tell what is the process that you're modelling ?
3381,what's wrong with conventional kernel density estimation ?
61151,"are your permutations properly randomised , if that makes sense in your context ?"
60511,"you don't necessarily need the months and years , just the numbers . what's the error ?"
61221,i am a little confused by the question . how many distinct models do you have ?
61225,what kinds of weights are you using ?
61234,i'd suggest that making clearer what you are doing would have a better chance of eliciting a good answer than offering a bounty . according to this you are estimating 600 parameters . . . from what data ?
61232,"it seems to me that you have * counts * , not the kind of continuous data for which the t-test ( paired or otherwise ) is appropriate . you have values for the number of cases that were opened in each situation , do you know the total number of cases that could * possibly * have been opened ?"
61320,can you say more about your situation ?
61356,the good way is to not do this . why do you want to ?
61372,ummm . . . i guess someone at minitab thought this was a good default ?
61376,"there's much you still need to tell us in order to communicate your question . do you know the parameters $ mu_j $ , $ sigma $ , $ theta_ { ji } $ ?"
61438,"this is a standard question as might be found in a textbook , and should be tagged as self-study . as i was already editing your question for clarity , i've taken the liberty of adding it . please check the [ self-study tag wiki info ] ( url ) . in light of that , what do you already understand about the question , and what have you tried ?"
61480,"the five variables to supply starting values for do * not * include the dependent variable ! ( it's not multiplied by any parameter in the model , of course . ) they should be the * constant * together with one for each of the four independent variables . perhaps that is the cause of your problem ?"
61514,"i don't know what you mean by "" optimization family "" ?"
61569,"if you're interested in population trends , have you considered using a gee instead ?"
61579,"let's start with these considerations : what exactly does it mean for a set to be "" good "" or "" bad "" ?"
61594,aren't you just shifting the energy functional by ` trace w- ( sum_ ( i ! = j ) w_ij ) ` ?
61580,"can you at least say something about what kind of statistical problem you are dealing with , which kind of model you are using and which numerical method you are planning to use ?"
61625,"that's the same as saying "" when does $ text { cov } ( x , y ) = text { e } ( xy ) $ ?"
61626,how does a plot of standardized pearson residuals against predicted values indicate whether or not the data are actually normal ?
61668,"is this the same question you asked at url if not , how does it differ ?"
61678,"perhaps try the ` lmer ( ) ` function in package * * lme4 * * , but singularity issues usually mean issues with numerical stability . you could try centring the data and even reordering the data in you data frame . other causes are trying to estimate too-complex a model from the data . would ` executive_age_group ` by confounded with the random effect ` state_abbr ` ( or vice-versa ) ?"
61704,are these clusters randomized to receive the intervention or not ?
61746,what is the mysterious formula from the literature ?
19550,what is the underlying speech task you are trying to solve ?
61773,have you tried using cov instead of var ?
61842,why do you mean by pull the variables out individually ?
61855,what do you want ?
59212,you can never absolutely trust a prediction - you need confidence intervals . have you tried plotting a projection with confidence intervals ?
51416,"i'm familiar with different types of cross validation and out-of-bootstrap validation , but have not yet come across the term monte carlo cross validation ( i may know it under some other name ) . could you link or quote a description of how monte carlo cross validation works ?"
61906,how is this question different from url ?
61908,""" * plotting the prices into a histogram , it is clear that it is not a normal distribution , so it is not a stationary stochastic variable i am dealing with . * "" -- how does this follow ( or how would the converse follow , in the other situation ?"
61895,why does it seem incorrect ?
61956,"how are you "" looking at the density function "" ?"
61990,what do you have so far ?
61996,unfortunately i am not able to help you with that but i tried to make the title more explicit to have a better chance to attract the right people . do you think the new title is ok ?
2580,do you know the probability distribution of the values in * * each bin * * ?
62004,just to be clear at this . you don't just want the functionality of ` fitdist ` . do you ?
62018,"it looks to me that you want to know if the proportion of ` bad_result ` s differs by ` group ` . i think you would be best to explore [ logistic regression ] ( url ) , instead of using fisher's exact test . out of curiosity , what book are you reading ?"
61989,why are you binning the data rather than say using a regression to come up with a calibration line / curve ?
62023,"instead of "" ci "" might you mean "" standard deviation "" ?"
62032,"welcome to the site , philippe . i don't understand the difference between your conception of "" composite measure "" & "" index "" . to me they both seem like putting individual question responses into one new variable . can you clarify that ?"
62097,what exactly is the 'precision' in this context ?
62102,"do you want to know the number of workers en route at a given point in time , or the typical duration of a worker's commute ?"
61611,"this is impossible if you make no further assumptions and allow all $ 2k $ parameters to be unknown . to see why , consider situations where all the $ mu_i $ are distinct and the $ sigma_i $ are incredibly tiny . the * only * function of the data that could be unbiased for the maximum in this situation then obviously is the maximum of the data . however , that clearly is biased ( high ) in general for $ k ge 2 $ . would you like , therefore , to add assumptions about the parameters ?"
62110,what is your question ?
62146,1 a most interesting question . could you be more specific about what 'jointly skewed' means in this context ( particularly a bivariate one ) ?
11131,"to clarify , is it correct that you are already able to get the required $ n $ , but you're looking for a general formula ?"
62179,what is 'maxlog-likelihood' ?
62185,"1 . this way you are predicting y2 . . yn-1 exactly , aren't you ?"
62206,"the idea of a variable being significant in one setting and not in another is a misuse of $ p $ -values . for your original question it would be better to combine the two samples and to do a combined test of whether any of the ivs interact with the low / high deviance variable . keep to the original variable scales when judging such interactions ( i . e . , you are assessing differences in slopes ) . btw what made the datasets be divided in the first place ?"
62211,do all your grid samples have the same sampling points ?
62231,glen's right . but what was the estimate for the lag one autocorrelation ?
56671,"have you done your model in r , without the distributed lag , say using r's ` lm ` ?"
56562,are you saying that _all_ your observed responses come from bots ?
61827,"you are referring to an ancient question , asked when the site was just beginning ( and eager to field any questions ) and cw had a very different status on se . we , like all sites , have evolved and improved over time . thus an appeal to consistency , although certainly logical , has little force . you need to demonstrate that your question meets * current * standards to be on topic for the site . also , does it really make such a difference to replace "" good "" by "" free "" in an existing question ?"
62285,i have to turn it round . why do you think a trustable final model exists if results depend on seed choice ?
62307,"other than the fact that i would code control = 0 and case = 1 , the clogit looks fine , so the problem is likely with your initial regression . can you post that ?"
25940,don't you need to take the * * square * * of the ( current ) numerator in the calculation of the degrees of freedom ?
62317,are you trying to maximize the chance of an individual ball being drawn exactly once or the number of balls being drawn exactly once ?
62347,why would you want to use hierarchical clustering on variables ?
62361,"when you say 'curve' and 'slope' , note that curves tend to have more than one slope . can you be more specific about your model and what you want to test , please ?"
62391,this is too general to allow good answers . people in this field will surely want to know ( a ) what you are doing precisely ?
62378,"can you describe your situation , your data & your goals more fully ?"
62420,question : is this about interpolation ( interior to the domain ) or extrapolation ?
62434,who said so / where was this ?
52979,are decay lengths known ?
61914,why do you want to do this ?
62482,"what makes the hypothesis you listed interesting , subject-matter-wise ?"
62489,"the plots would certainly be helpful , maybe you could include them into your question ?"
62466,"so , in your dataset , for each subject , you have 19 numbers ?"
62416,can you add the imports at the top of the code ?
62510,"what makes you think the results are weird , exactly ?"
62531,could you please explain better why $ w_i = a_i b_i $ in the linked formula would not fit your needs ?
61756,""" * i tried to use binomial family - logistic regression * "" -- why ?"
62565,you seem to be pretty cavalier about the model of step 1 . if this isn't done well enough that impacts the rest . be sure about your model . how do you measure if time and opportunities are your only inputs ?
62594,"consider - if i tell you that of the $ 5 bills in my house , 25 % are in my wallet and 10 % are in my daughter's wallet , can you answer the question "" what is the probability that a bill drawn from my daughter's wallet will be a 5 ?"
62605,did you try this paper ?
62237,dimitriyv . masterov would that approach work for an innovation outlier ?
62634,what else can you tell us about your population ?
62621,why the negative vote ?
62597,user26221 your question is unfathomably cryptic . andre has done you a service by at least identifying the * package * you're talking about . what function did you call ?
62655,what do you mean by wanting to know the difference 'between the happening' ?
62559,"did you intend to write ` y1 - rnorm ( length ( yhat1 ) , mean = yhat2 , sd = 0 . 01 ) ` ?"
62660,what does your question have to do with ` time-series ` ?
62719,how did you get that answer ?
62726,""" each interview was conducted in the same order , but the order was randomized once as part of the experiment design . "" so , first a number of stimuli were defined , then they were randomized , and then the interviews were performed ?"
62738,"to do a kolmogorov-smirnov test you typically need a known reference distribution to compare against . if the overlap values were random , what would their distribution look like ?"
62666,exactly how did you compute the standard errors ?
62770,why are you calculating the icc ?
62795,""" however , i am concerned that bootstrapping such a population adjusted value might be problematic . "" -- why ?"
62841,"when you say a "" graphical structure that has been learned from observations of real data "" do you mean a probabilistic graphical model ?"
62852,"welcome to the site , user27436 . i can't tell if this is primarily a question asking for help w / * coding * or w / the ideas involved . if the former , this q would be off-topic on cv ( see our [ help page ] ( url ) ) , but on-topic on [ stack overflow ] ( url ) ; if the latter , it belongs here . can you edit to clarify ?"
38552,"not a direct answer , but re bootstrapping in sas , do you know of david cassell's paper "" don't be loopy "" ?"
62797,"okay , what are the assumptions ?"
62899,"what exactly do you mean by a "" threshold "" ?"
62910,your sample sizes are large . why do you think the values are wrong ?
62930,hi lefterav ; your question is quite broad . are you able to edit to ask more specific questions that could be answered in a few paragraphs ?
62960,can you clarify what you mean by $ x ^ t $ ?
62838,could you explain why you want to calculate correlations ?
62294,"i don't get it : you start out by noting that none of the $ e_i $ has a variance and then ask whether the variance of their average would be a reasonable estimator of--that nonexistent variance ! or do i misread this question : perhaps by "" statistically independent estimations "" you have some * different * ( perhaps robust ) estimator of the integral in mind ?"
62953,"please close url ( even delete it ) in order not to leave little messes in your wake . to the point here , what you do you mean "" homogeneous "" here ?"
63096,can you give an example of transformation to vector ?
63101,how many replications did you ask for ?
63121,do you mean coefficient * b * or coefficient * a * ?
63030,what is the purpose of the metric you seek ?
63050,* * is * * a chi-square ( 2 degrees of freedom ) a * * rayleigh * * random variable ?
63140,does your 2-d data follow a certain pattern e . g . linear correlations ( fitting more or less on a straight line ) ?
63156,"presumably we are to imagine observations on several birds and on each of four characters on each of these subspecies . as always , the idea that a test is the holy grail to seek in an analysis is not obvious : you are likely to get much more out of ( say ) a correspondence analysis . whether your three grades are ordinal or nominal is not quite clear . whether you can combine characters is not predictable by us in advance , but why go to the trouble of collecting detailed data only to want to mush it altogether ?"
63176,you should start from what you want to know / learn about these data . also useful would be information on the number of patients . was there a control group ?
62870,upon erasing the parentheses you have a table of $ n $ observations and $ 7 $ variables . what is the obstacle to doing pca with that ?
63245,"please spell out your abbreviations . presumably , "" ssr "" is the sum of squares of residuals and "" df "" is degrees of freedom . if that's so , then how do you determine that df = p-1 ?"
63290,have you thought about binning your outcome and predictions and making a confusion matrix ?
63269,"this question ( especially the second part ) is rather abstract , which makes it seem vague : would you be able to give an example to clarify it ?"
63270,how does time relate to your stated model ?
63327,with * what percentage confidence * that the sample mean is within 5 % of the population value ?
62983,thank you so much for your helpful advice maartenbuis ! can we reference your recent article for use of the above model ?
63353,do both data set have the same number of samples ?
63398,what's a 'predictory' variable ?
63433,wouldn't ordered logit be what you are looking for ?
63366,your statement must be conditional on the set of samples that will be submitted to the instruments . what are you assuming about that set ?
63263,"do you also have a random sample of objects that * don't * belong to the $ x_i [ a_i , b_i , c_i ] $ , $ i leq n $ group ?"
63441,"i thought the 2001 paper establishes properties of fdr ( 1995 ) under dependence . yekutieli and benjamini ( journal of statistical planning and inference , 1999 ) establishes a different fdr procedure . any chance that is the one you are seeking ?"
63501,of possible interest : [ how to view large time series data interactively ?
63568,why only the two most frequent ?
63585,how are you relating the vif to $ 5 sigma ^ 2 $ ?
27772,what about a robust variance / covariance estimator to relax the assumption that the variance is equal to the mean ?
63440,could you precisely define 'overlap' in this context please ?
63659,can you please post the original output rather than the table ?
63647,"although the student t distribution has a * single * parameter , you refer to "" parameters "" in the plural . are you perhaps including location and / or scale parameters ?"
63691,"welcome to the site , user27768 . can you clarify what you mean by "" 50 day matrix of co-ordinates "" ?"
63655,thanks for updating the question . but this is still not a reproducible example as we can't reproduce your error . ` y ` and ` x ` are both filled with ` na ` s ( missings ) . maybe you could just add a very small subset of your data set ?
63715,what's lsa ?
63717,could you add some addiitional information . ( 1 ) how many factors do you have ?
61371,can you say how many rows & columns you have in your dataset ?
63732,"do you just want to compute this expectation , or do you want to find an alternative estimator of $ p $ for which this expectation is minimized ?"
63728,have you considered applying the chernoff bound directly to $ s $ ?
63775,"are you doing two models , one for the linear predictor and then a cox , or am i just misunderstanding your simplification ?"
63760,is there a question we are allowed to answer in there ?
63792,would it make sense to combine the variables ?
63805,this question is mystifying . what exactly are $ k $ and $ n $ ?
45820,i remember reading about this sort of guidelines with respect to factor analysis . are you also interested in that or only in pca ?
63831,"welcome to the site , universalis . are you interested in ways of thinking about how to visualize these , or do you just need help w / matlab code ?"
63869,hi sanna and welcome to the site ! can you explain why you think that the kurtosis of the interaction variable may be a problem ?
63890,aren't you just asking for the gaussian cutpoints needed to match the poisson probabilities ?
63943,what are you actually trying to accomplish . you say you are trying to model it but do you have a model in mind ?
63968,"the second question definitely stands on its own though , does it not ?"
63972,"the wikipedia article you link to states "" it can be shown that the probability is $ 1- alpha $ that all confidence limits of the type $ $ hat { c } pm s_ hat { c } sqrt { ( r-1 ) f_ { alpha ; r-1 ; n-r } } $ $ are simultaneously correct . "" that seems like a particularly clear and full answer to me . do you detect that something is missing in it ?"
39316,"your question appears to be more psychology than statistics . it might be more statistical if you could perhaps operationalize what you mean by 'fraudulent' , since such scores are going to be subjective . could you clarify more precisely what you want to avoid and what you want to achieve ?"
64050,you probably don't want to do this . why not analyze $ log ( q ) $ ?
64053,could you share the code / commands you are using to train the svm ?
64057,"yes , there is information in the placement , for example centrality . perhaps it is possible for you to add a link to the data or show a picture of the graph ?"
64098,why not just run the model on the unstandardized variables to start with ?
64044,what is the x-axis in this plot ?
64112,is this a homework question for some university course ?
61503,"try to search for "" ward clustering "" on this site . the only geometrically correct input for ward is squared euclidean distances . what is ` euclid similarity ` can you show the formula ?"
64150,"what do you mean by "" corr ( i , j ) = 0 : 5 for $ i j $ or for all $ i = j $ "" ?"
63927,"hi charleslondon , welcome to the site ! could you provide the model outputs ?"
64164,"to clarify : do you want to predict the value of a * response variable * based on other variables , 1 of which is time ?"
64194,` y ` looks geometric . is there a relationship between the two ?
64195,"this is not the right path . the 4th equation doesn't hold . for example , with $ x_1 = 1 $ , $ x_2 = 0 $ , and $ x_3 = 1 $ , the left term is zero , whilst the right term is $ 2 / 3 $ . the problem comes from the step where you split the variance ( 3rd line of second equation ) . see why ?"
64229,what version of r are you using ?
64242,"what exactly do you mean by * "" i have replaced the 1's in x with 2's in z and vice versa "" * ?"
64211,` splits the terminal ` how on earth a terminal node can be split ?
64299,"actually , i just realized that if any of the $ w ^ t x_i $ are 0 , then $ w $ will be singular . also , in practice it might become arbitrarily close to singular even if it's not actually singular . you are using a ` solve ` call rather than an explicit inverse , right ?"
64334,have you considered a third option called item parcelling ?
64152,why use ` 0 . 5 * log ( ( 1 r ) / ( 1-r ) ` when you can use ` atanh ( r ) ` ?
64336,"it would be useful to know what kind of variables symbolic , attitude and amount are ; binary , discrete , continuous ?"
64304,"which "" alternative hypothesis "" ?"
64353,is the 90 % interval symmetric ( 5 % out each end ) ?
64370,"b_miner it's kind of hidden , but svd is one of the common methods of obtaining principal components . since you're using r , have a look at ` ?"
64371,"normally , people don't use bands around pdfs as in your illustration , because they are unrealistic : the upper band would have total probability greater than $ 1 $ while the lower would have total probability less than $ 1 $ . a [ standard technique ] ( url ) draws bands around the * cumulative * distribution functions . would such a technique be acceptable to you ?"
64410,what kind of error are you talking about ?
64414,can you explain how the first few sentences of ` ?
64424,"i am no time series expert , but it seems to me that in a time series with bursts and outliers , much of the interest would be in the bursts and outliers . why do you want to give this series to pca ?"
64355,"you are asking about a proposed * solution * to a problem . let's back up : the problem appears to be to estimate the covariance matrix . the ` r ` command ` cov ` performs that estimate and it is known to be unbiased . bootstrapping can accomplish two things : ( 1 ) it can assess the amount of bias ( and let you correct for it ) and ( 2 ) * when the dataset is sufficiently large , * it can display the samling distribution . you don't need ( 1 ) because your estimates are unbiased and ( 2 ) is out of the question . why then look any further at bootstrapping , unless it's purely a programming exercise ?"
64435,"by assuming that $ p ( b cap a' ) = p ( b ) p ( a' ) $ , you are claiming that $ a $ and $ b $ are independent . is that the case ?"
64469,"have you really got just 4 people , each with 4 treatments ?"
64474,are you familiar with the law of total probability ?
64485,"are you familiar w / mixed-effects ( aka , multilevel or hlm ) models ?"
64433,"before proceeding you would need to have justification for there being a discontinuity in the system . i . e . , does a discrete external event happen at the supposed change point ?"
64517,"how large is your sample size , and have all respondents answered all questions ?"
64191,"yes , there are several ways . why don't you edit your question to ask this more refined version about estimating $ n $ ?"
64513,i have trouble understanding what you mean by 'plots' and 'blocks' . do you want to treat these / do you think these can be treated as categorical variables in your analysis ?
64576,"as an alternative to laplace smoothing , would you consider a bayesian approach , with a choice of prior that puts some non-null probability on all transitions ?"
64562,and where is the question ?
64589,( i ) likert scale variable are discrete -- transformation usually won't do much on individual scale items ; . . . ( ii ) why are you transforming these variables ?
64600,this formula looks wrong . where did you get it from ?
64552,how do you obtain a sum instead of a product over the data ?
64629,"by 'clusters' do you mean possible values of the categorical variable , e . g . chalk , cheese , ham , egg , chips , or peas ?"
64617,"where did i say "" covariance shows only the strength of a linear relationship "" ?"
35185,do you treat v % * % diag ( d ) by itself or still multiplied by the original matrix x ( i . e . x % * % v % * % diag ( d ) ) . it seems above you are using the u matrix as the principal component scores ?
64678,"this is normal . in this case , the cdf of the weibull distribution goes to 1 as $ x $ goes to infinity . the [ * empirical cdf * ] ( url ) is 1 for the maximum value in your dataset : ` discreteplot [ cdf [ empiricaldistribution [ data1 ] , x ] , { x , 0 , 400 } ] ` . if you use mle to estimate the parameters of a theoretical distribution , the cdf of this distribution is not limited to your data set . i don't understand the second question . what do to you mean by "" estimated value "" ?"
64683,nested means that individuals did not see all levels of ` f2 ` . is that true ?
64691,"any reason to ask for a 'non-parametric' measure of inter-rater agreement . what's wrong with a weighted [ kappa ] ( url ) , or some [ icc ] ( url ) or [ generalizability ] ( url ) indices ?"
64711,the degrees of freedom can't be equal to the number of lags . and why do you want to do the test at just lag one anyway ?
64710,what is a low confidence interval ?
64767,do you mean using a standard questionnaire ?
64765,are you familiar with [ tag : copula ] s ?
46276,can you explain how you would normally use aic to determine the number of lags ?
64789,"you didn't put it clear what you're after . do you want to see the cloud , every data point ?"
64807,did you ever figure this out ?
60277,where does 0 . 1 come from in your formula ?
64868,i'm not sure of the exact matrix norm you're using . but can you use the definition of trace directly ?
64902,be clearer about what you need help with . what does gamma or gaussian have to do with it ?
64920,is performance a continuous variable ?
64864,there are lots of things missing before we can help you . what sort of data are you simulating ?
65008,a little more details on the nature of the data could perhaps be useful . what is a replicate ?
65024,are you just asking if there are alternative link functions ( other than the logit ) available for the multinomial case ?
65000,"your example data shows two people equal third in the tournament , is this sort of tied result a typo or is it going to be possible ?"
65041,"hmmm . . . ` density ` always plots density , as far as i know , not frequency . . . can you show an example of it plotting frequency ?"
65044,"i seem to interpret your question differently from johnros and anxoestevez . to me , your question sounds like one about plain [ model selection ] ( url ) , that is , a matter of computing $ p ( m mid d ) $ , where $ m $ is either the normal or log-normal distribution and $ d $ is your data . if model selection is not what you're after , can you clarify ?"
65059,how do you measure accuracy ?
65079,"you have a number of distance matrices , but is your question how represent just one of these at a time , or all of them together ?"
65085,possible duplicate of url or url if the question stays at this very general level . we need some more information if you want more help more specifically . what variables do you have for each transaction in the warehouse ?
64705,where have you read that ?
65105,"i believe you forgot about the offsets units , and that your output shows a systematic displacement with respect to the desired output . is that so ?"
65176,"with regard to 2 . wouldn't an f-test of joint significance be considered a portmanteau test ( according to that definition ) , since its testing $ h_0 : $ coefficients are all zero vs $ h_a $ all / some coefficients are not zero ?"
65175,"it is difficult to reconcile your summary information with the description of the histogram as "" bell-shaped , "" because it sounds rather skewed . perhaps , to clarify your question , you could post the p-values or an image of the histogram ?"
65178,"this depends largely on how often you measured personality . i suppose once , so it is a variable on the person ( uppermost ) level in multilevel language and peter flom's answer applies : fixed . but you could have measured personality four times as well , have you ?"
65191,how did you come up with the power of $ -0 . 82 $ ?
65177,are you familiar with probability trees ?
65273,"i'm not sure i understand the question . doesn't the "" p-curve "" primarily depend on the number of expected real effects ?"
65316,hi and welcome to the site ! could you clarify what the numbers from the papers are ( in the example ) ?
65346,"if you're handed $ ( x , y ) $ , what information about $ alpha $ and $ beta $ is there in $ y $ that's not already in $ x $ ?"
65381,could you be more precise about the dimensionality of the construct ?
65382,"arahant , where in your code did you change the cutoff value ?"
65405,the boxplot description makes no sense . how many scores do you have ?
65409,"your text says you want to multiply loadings with variables , but the code looks like you multiplied factor scores with variables . . . ?"
65410,"in what sense do you mean "" variance "" ?"
65424,"what do you mean your "" weights summed to 75 % ?"
27656,"maybe i'm not following - if there is an _a priori_ reason to suspect effect modification , then how do these new methods differ from , for example , including interaction terms in the list of "" candidate "" variables for model selection ?"
65265,"do you think there is some underlying _population_ from which these 30 points are drawn . equivalently , do you have a _model_ for how you think the data should look if things are ok ?"
65516,can you say a little more about your situation ?
65420,"what happens ( in the last example ) when you follow the instructions on the help page and compute ` svd ( a , nv = 3 ) ` ?"
65542,"if you have the original data , why would you like to use percentiles ?"
65566,i am just expanding on roland's point but why do you think there is a problem ?
65581,"what kind of data do you have from "" every town in every state "" ?"
65583,maybe some kind of lattice plot ?
65608,why introduce $ c $ at all ?
65605,"just a question : why are you interested in the standard error and not , e . g . , a confidence interval ?"
65241,it is not clear what your question is ! did you read about empirical likelihood ?
65639,"why not do an explicit test for equality of variances , such as levene's test ?"
65659,"what would it mean to have a "" statistical test "" of "" when to combine attributes in an 'euclidean' fashion . . . "" ?"
65690,would it be possible for you to provide a minimal working example ?
65699,lsa or lsi : same or different ?
65765,"there are other discussions about the r-squared when there's no interecept , such as url did you take a look at these discussions too ?"
65789,what are your unknowns ?
62560,"when you say 'observational studies' , are you referring to single arm , uncontrolled , studies or controlled studies ?"
65801,do you also get not significant alphas in your other portfolios ?
65803,that is even more puzzling . why do you think you can ignore the logarithm here ?
65687,what are the variables ?
44485,could you explain what these data mean ?
65866,"` plot ( density ( rexp ( 100 ) , from = 0 ) ) ` ?"
65877,is your data properly normalized ?
65875,"it just shifts the whole distribution along by $ n_1 ( n_1 1 ) / 2 $ , sample test statistic , quantiles and all . if you're doing it r , the solution i offered you there gives you the correct p-value ( since the p-value was computed $ w $ vs null distribution of $ w $ , and you want $ t_w $ vs null distribution of $ t_w $ and both are shifted by the same amount ) . [ i am not sure i understand the difficulty here , it's a bit like saying "" i know how to tell if i have cut this piece of wood the right size but if i change from measuring in cm to mm , how do i know if it's the right size now ?"
65909,"i thought they would be independent of the history , are they not ?"
65960,what's the reason for this question ?
65963,can you say a little more as to what exactly you're after when you ask what the glm looks like ?
65979,"what about the x values , are they all continuous ?"
65990,how many questions are you asking here ?
65992,why not a simple linear regression with binary variable for each period ?
66011,"are you asking about mathematical methods to show a known distribution is unimodal , or about tests for unimodality of a population given a sample ?"
66015,"i agree with gung : it seems to me that in the duplicate thread james stanley clearly and plainly answers the question stated here , "" why do we divide by $ n-1 $ ?"
66084,do you know / can assume there is only one special night or could there be several ?
66125,how many explanatory variables and what kind of fixed and random effects are included in the model ?
66092,"i'm sorry , i still do not see any valid demonstration that the entropy of $ ( x , y ) $ must equal that of $ x y $ : where is it , exactly ?"
66162,"you could , perhaps with some profit , characterize your data differently : you have a two-way table giving the counts of $ ( x_1 , x_2 ) $ equal to $ ( 0 , 0 ) $ , $ ( 1 , 0 ) $ , $ ( 0 , 1 ) $ , and $ ( 1 , 1 ) $ . the first count is much larger than the rest and the last is much smaller--but so what ?"
66166,"is it just that your response variable is a count instead of a bernoulli trial ( ie , series of coin flips ) ?"
66190,what about using stochastic gradient descent to estimate your svm instead ?
66212,would it be possible for you to upload at least a part of the dataset somewhere and maybe better explain what you are analysing ?
66214,"this looks rather like bookwork . if this is for some subject , would please add the self-study tag ?"
66192,i'd start here ` ?
66246,"your ` k ` etc . statement is certainly possible , but i note that ` b ` does not occur in it . would you mind clarifying what you are getting at there ?"
66249,"curious , why the requirement for a closed-form expression for the cdf ?"
66046,"the model appears self-contradictory . written more explicitly , it makes an assertion about the random variable $ epsilon $ : $ f_1 ( x- epsilon ) = beta f_2 ( x- epsilon ) alpha $ . in general , given $ f_1 $ and $ f_2 $ , there will not exist any constants $ alpha $ and $ beta $ that can make this true as statement about random variables unless $ f_1 $ and $ f_2 $ already enjoy such a functional relationship for all real numbers--in which case you scarcely need to make any observations at all , because you can just solve for $ alpha $ and $ beta $ ! what am i misunderstanding ?"
66173,what happens if you regress the log-return $ y $ on log-return $ x_1 $ ?
66142,"see rick picard and brian williams , * rare event estimation for computer models * . the american statistician feb 2013 , vol . 67 , no . 1 , pp 22-32 . it's very readable and well explained . but why is it important to report , say , 40 sigmas and not just explain that the result is obviously significant and give the actual effect size ?"
66313,"sure , there are plenty of ways . it's important to specify more precisely what you mean by "" multivariate gaussian "" and non "" homogeneous . "" after all , you can take any finite number of locations and generate multivariate gaussian values according to any positive semidefinite covariance matrix associated with those locations . ultimately this kind of construction , by its very generality , is not very useful : what is your * real * question ?"
66315,"you might be interested in a more practical text , have you seen bayesian methods for hackers ?"
66338,are all of the steps gibbs steps ?
66347,what do you mean exactly by iv ?
65907,does it really make sense to classify on the _name_ of an establishment ?
66375,do all the models have the same data ?
66414,"i haven't read your whole question but you lost me in your third paragraph with "" in this case the cell [ 1 , 1 ] can vary between 0 and 40 only "" - i can't think of what you're thinking here but it must be incorrect and perhaps might help explain the rest ?"
66419,"relevant questions : [ r vs sas , why is sas prefered by private companies ?"
66447,which paper are you looking at ?
66538,urschrei . . . numpy returns residuals too ?
66473,"because it caused some confusion in one of the answers , please note that the assertion that the "" ci width should approach 1 "" is either meaningless ( 1 what ?"
66016,4 . your example isn't clear . why does article # 1 appear twice ?
66581,what makes you think that ?
66556,what are you measuring ?
66624,why not average predicted values ?
66674,"is your question about the thought process that goes into feature selection , or about what other additional features for a ner algorithm might be ?"
66692,i think you mucked up your example . your alternative and null hypotheses are the same . you say your alternative is a composite hpyothesis : did you mean to write $ h_a : theta neq 1 $ ?
66738,in what way are text files becoming too big ?
66749,"i guess it comes down to what you mean by "" x % of the data "" --is it the x / 100 percentile or is it x % of the cumulative ( ordered ) total ?"
66604,"the example is mystifying because there is no apparent relationship between ` number of vessels ` and ` frequency ` . the question itself is puzzling because it is not clear which variable you want to fit a distribution to , nor what the purpose the mc simulation will be . could you please edit your question to explain these points ?"
66777,"are the same clusters produced in the second run , or different clusters ?"
66782,what values of $ h $ do your 25 distance values take ?
66857,not sure why the outcome would have to be binomial . are the e-commerce data binary ( yes / no ) or continuous ( # or orders and amount of revenue ) ?
66871,"in method a , it's not clear to me what you want to do . do you add a different value $ epsilon_ { ij } $ to each elements of data , or is it one value $ epsilon_1 $ for all first components and one value $ epsilon_2 $ for all second components , or is it the same value $ epsilon $ for all values in the sample ?"
66914,"what do you mean by "" attributes "" and "" instances "" ?"
66938,"it would appear that condition numbers are used here merely as a surrogate for the sample size , so why don't you just focus on sample sizes ?"
66949,can you say more about what your data are ?
66964,could you post an example ?
66921,which is the part where you are computing z-scores ?
67025,"would you mind showing what you did when "" using the formula above for $ v ( x ) $ "" ?"
67106,"do you need variable degrees of freedom , or just one particular one ?"
67102,you define three conditions & then talk about an undefined fourth . what's with that ?
28769,"one would expect both $ b $ and $ d $ to be * negative * , ben , given that the data appear to have a negative second derivative . the sum of exponentials looks like it will be a poor fit . could you disclose the reasons why this form of function is expected ?"
67295,"sometimes the answer is wait , but my main comment remains that it's not clear what you expect here . no one is likely to write a long essay on what you might do . probably more than half statistics falls under your very general title . so , try to make it much more specific . what do you _next_ want to know ?"
67333,"the form of regression you want depends on the nature of the dependent variable . so , what is y ?"
67329,what quantitative information can you provide about how the pupil image depends on layer thicknesses and numbers of layers ?
67385,how do you know your data is underdispersed ?
67410,can you show code and a reproducible example for what you did ?
67409,why ?
67460,you mean mathematically ?
67465,what about some form of robust regression ?
67473,does it make any difference if you add a small amount of noise to your y ?
67202,"i don't see any other answers here , which is a pity , since the question is interesting . i will like to take another thinking on the matter . can you please clarify / verify the data series which comprise your sample ?"
67616,this question seems astounding to me . i find it hard to believe you could have a model with zero false positives . what is the data being validated ?
67594,"what about the answers on the linked page don't you understand , cynderella ?"
67679,have you read the original hoeffding's paper ?
67647,could you please show what your code looks like ?
67663,did the teacher tell you which one was meant to be correct ?
67624,can you explain the definition of your notation please ?
67713,high correlations shouldn't matter . are you using pairwise deletion of missing values ?
67716,it seems that your model has fall into overfitting . how many observations do you have and what is the number of independent variables in the model ?
67725,"if you are just interested in the effect size ( i . e . , the standardized mean difference ) the question of paired versus unpaired data does hardly influence your results . pairing gives you only an advantage in terms of significance testing . so what do you really want to know ?"
67843,could you add a plot of your regression against the original data ?
67923,i can't think of a good reason you may want to do that . which is your goal ?
67926,"according to [ this page ] ( url ) , ` scipy . stats . f_oneway ` only returns an $ f $ statistic and its $ p $ value . * * neither * * of those things is an effect size ( as the term is normally conceived at least ) , though $ f $ is certainly related to effect size . what makes you call it an effect size ?"
67955,your question is a a bit confusing . can you post some sample data and try to clarify what it is you're trying to do ?
67956,why not give both ?
67976,"you're testing different hypotheses . broadly speaking , both approaches do test whether $ x $ has an effect on $ y $ but the nature of that effect is very different in the two models so it's not a surprise that you're getting different results . i guess my question would be : what is the substantive reason for conducting both tests ?"
67888,how is the subset of p selected ?
68005,did you make your qq plot of the test statistic / p-values associated with the snp or with one of the covariates ?
68008,what is the relationship between the fitness of the child and the fitnesses of its parents ?
68007,are the various lines meant to be non-parallel or is that just the inherent imperfection of photoshop ?
68019,i think this may be very similar to a previous question ?
68069,"ss_11 , have you shown us all the data or not ?"
68074,"when you say that you suspect "" endogeneity between the main explanatory variable and the dependent "" , does this mean you think there is reverse causality ?"
68087,what does ` nrow ( dat ) ` say - i . e . how many observations do you have ?
68108,i do not understand the question : ( ?
68113,"what difference would it make to include $ 0 $ in or exclude $ 0 $ from the support , given that this has zero probability in any case ?"
20917,what covariance function are you using ?
68169,exactly how are you are producing a plot ?
68177,"what causes the "" change in value of this expression "" ?"
68187,"by "" unbiased , "" you mean unbiased predictions , correct ?"
68218,"what makes you think runif samples from [ a , b ] ?"
68219,"question : i am not familiar with the r-code . can you write the regression equation specification in mathematical symbols , so that i can understand whether you are running a linear or non-linear regression ?"
61364,"what is the number of observations in the synthetic data , and what is the number of observations in real-life data ?"
68240,is there a plausible distribution for these numbers ?
68265,seems a remarkable coincidence unless there's something else . could you give any details on the two different response variables ?
68261,""" i also used an unobserved components model ( ucm ) and obtained a good forecast "" looks very promissing . what r-library did you use ?"
68302,this question appears to offer insufficient information for an answer . on what basis are we to compute a probability for correctly guessing that a word has changed ?
68337,"coin flips don't have a normal distribution . if you count the number of heads , they're usually modelled as having a binomial distribution . ( but maybe 'better' just means 'gets a greater proportion of heads' ; did they clearly specify or was that just your guess ?"
68368,"in a multilevel model , the people are the higher level units . you 20 ( or 19 ?"
68380,you don't say much about the nature of your data . have you considered a transformation of the dependent or using a glmm ?
68425,""" between b and s "" is this a typo ?"
22029,"the reference to "" cartographic applications "" is intriguing . may i suggest that you explain more about your application and exactly * why * you think you need a normally distributed dataset ?"
68454,"there are several things going on here . first , * of course * a relationship will look linear provided the ranges of the variables are suitably restricted . second , the * heteroscedasticity * of the data is almost as prominent a feature as the nonlinear relationship : the scatter is greater at high volumes and low powers than it is at low volumes and high powers . regardless , what precisely do you want to test ?"
68468,"in what sense have some "" bad "" instruments outperformed "" good "" ones on this measure ?"
68482,""" randomly pick a number "" is not precise enough to allow this to be answered . if the computer picks a number from a discrete uniform distribution , then the odds of picking a 50 are indeed , 1 in 100 . but if it picks a number from any continuous distribution , the odds of picking a 50 exactly are infinitesimal . if it picks from some other discrete distribution , the odds depend on the distribution . i suspect you meant the first thing . as for your other question : do you mean * exactly * one person picking a 50 ?"
68518,are the 36 conditions matched across sessions ?
25824,"could you explain , what do you mean by semi-analytic model ?"
68532,how many measurements have you got ?
68545,"why do you "" need to perform model selection "" ?"
67978,what is the exact command that resulted in that message ?
68601,you have to explain what you know ?
68129,are you looking for continuous or categorical predictor variables ?
68680,why ?
68710,"the effect of the dummies is to make the residuals tend to form vertical lines : this is especially apparent for the lowest fitted values . the graph is somewhat inadequate in that each point may represent multiple coincident values , but it does indeed show some tendency towards less vertical scatter at the highest fitted values ( but not by a lot : that appearance is due partly to the fact there are fewer residuals at the higher values ) . yet what you do about this--if anything--depends on the nature of the data and what you are trying to learn . perhaps you could share some information about that ?"
68737,does this help ?
68767,"i cannot make sense of this question for several reasons and hope you might be able to clarify them . what does it mean to "" calculate "" an input variable "" with 95 % confidence "" ?"
68599,great edit ! the analysis you do makes the question clear . might i suggest you revisit your calculation of $ p ( xz ) $ ?
68828,the counter-question is how can you * know * that you have poisson processes ?
68865,why do you think bootstrapping requires normal data ?
18705,i am confused by this question . it starts by telling us you are sampling from a definite distribution with a variance of 100 ( or maybe 100 ^ 2 ?
68929,"you probably mean "" clustering of * gaussian * mixture model "" , or something other than "" dirichlet "" i assume ?"
68984,why do you think a density function that has a single point of discontinuity would make it non-integrable ?
69021,"i don't know about multiple sources but there are some really good sparse linear algebra libraries out there . suitesparse ( cholmod , umfpack , etc . ) are probably a good place to start looking . mind you some of those cholmod for example are available in the ` matrix ` r-package . i don't know if those algorithms have multinode variants . care to elaborate a bit more on your "" * much , much larger than the ram "" claim * ?"
69045,why a scatter plot ?
69092,which 'log-linear' model are you referring to ?
69103,there does not seem to be enough information to answer this question . * on what basis * should the websites be compared ?
69097,what is lda ?
69124,"it would help to make your question more clearly on-topic here ( rather than so , say ) if you framed it as 'how do i fit a constrained natural spline ?"
69144,how are you calculating the mse in your code ?
69164,"okay . i'm not familiar with the ukf . from what i can read online you take a set of points with the same mean and covariance as your normal distribution , pass them through the system's non-linear transform , and use the transformed points to re-estimate the normal distribution in the new space by moment matching ?"
69163,"have you tried something simpler than a neural network first , like linear regression ?"
69114,"do you want to understand what semi-definiteness * is * , or do you want to know why correlation matrices * must * be semi-definite , or do you want to know what important results are implied by this property ?"
69219,""" in practice "" you would be sampling from the posterior , which is a gamma . are you asking how to sample a gamma variate ?"
69224,"the maximization step already does climb the likelihood gradient ( conditional on the values chosen by the expectation step ) , right ?"
69259,do you mean 50 of the 100 subjects ?
69292,are you saying you don't know what a p-value is ?
69308,can you perhaps describe your design a bit more ?
69322,is that tukey not tuckey ?
69267,what is the motivation for such a question ?
69338,"i'd interpret it to be a distribution on 4 variables - the next in the series * univariate , bivariate , trivariate , . . . * . however , it's more often spelled * quadrivariate * , which might explain why you had trouble finding it . googling * quadrivariate * turns up many hits . but for that matter , when i google * quadravariate * the second and fourth hits ( that i get , your experience may be different ) are consistent with this interpretation , so it's not hard to find . what's the name of the priestly reference ?"
69349,"what's the 95 % ci on the d , and what's the * p * of the * t * -test ?"
69360,"do you mean "" [ coefficient of determination ] ( url ) "" for "" correlation "" , & "" [ multiple regression ] ( url ) "" for "" multivariate regression "" ?"
69371,"why are some variables "" of interest "" & some "" control "" ?"
69375,"i don't see how there is any contradiction or paradox here . the question you asked of the data with your mixed model ( "" is there a group effect on average across days 1 and 2 ?"
69419,"how did you determine that it is "" not gaussian "" ?"
69483,"suddenly , this looks very familiar . is this for some class ?"
69501,"are you purely interested in implementing the pettitt test in r or do you have some applications in mind , also ?"
69521,"you might try perusing this thread : [ advanced-statistics-books-recommendation ] ( url ) , which includes some discussion of glims . in general , i'm not sure if this question is answerable w / o more info . do you want a mathematically dense book , eg ?"
9851,"how is wunderground not "" legit "" ?"
50418,do you have 60 plants all up ?
69577,"i can't fathom what you mean by a "" true "" $ p $ : could you please explain ?"
69475,"you're accumulating close votes : to keep the thread open , could you please explain the connection between this question and data analysis or machine learning ?"
51489,does this do it ?
69649,"please elaborate and write down the equations relating to "" to deal with the heterogeneity , a colleague advised me to use a gls model and weights on the factor that shows heterogeneity ( in this case temperature ) . if i do that , all terms become significant . "" what is the model specification in this case ?"
69688,why don't you just consider an algorithm that * guarantees * newly generated random values are not in the set ?
69776,what is ` run a ( k = 3 ) -means ` ?
69797,"i don't see why you would be using a stacked bar chart here . if these are times , why not have time on the y axis & present the 2 bars side by side for each test . setting that issue aside , yes , you can average the 5 conditions , but there is a philosophical issue here as well : are all situations equally important ( ie , should you be using a weighted average , eg ) ?"
69802,do you want to get the original dataset if you are given the pca vectors and the projected points ?
69806,"i don't understand why "" this makes no sense "" . you are starting off with a definition of causality that is i think equivalent to definition of independence in statistics . and independent variables have zero covariance , where is the story ?"
69773,why not ?
69834,"are you trying to understand the * pattern of missingness * in your data set , or are you trying to analyze the * entire * data set but minimize the missing data problem ?"
24932,are the measurement errors independent ?
69841,"i'm curious as to the kind of questionnaire you are using : 41 factors for a total of 142 items means you may have factors with very few items , as you pointed out . i would neither trust the % of explained variance , nor kaiser's rule ( which is known to overestimate the number of factors ) . parallel analysis should be ok , providing your factors make sense . what kind of factors extraction are you using ( ml , principal components , principal axis , etc . ) ?"
69857,what makes you think that the residuals and fits are correlated ?
69893,"just to be clear , it seems you want a ci for $ p_1 / p_2 $ where the * estimate * $ hat { p } _1 $ is $ 0 $ . because you did an exact significance test , you should be able to use essentially the same calculations to obtain an exact confidence interval . what formula , then , did you use ?"
69899,where did you find ` gb2lfit ` ?
69902,had you perform * an * anova ( y ~ x1 x2 . . . xn ) or * several * anovas ( each as y ~ xi ) ?
69554,"what is $ h $ , $ s $ and $ l $ ?"
69911,"can you include in your question an elaboration of the "" after some algebra "" part ?"
69906,"what's not "" data driven "" about stl ?"
69949,"the report about your analyses was needless , really . the title and "" question "" would suffice . ` limitation ` ?"
69898,how does it happen that both the minimum value _and_ the median of your data is zero ?
69886,"this is a minor point , but understanding how the score is computed can be helpful in providing good answers . could you edit your question to inform us about that ?"
69606,can you solve this for the special case where $ mu_1 = mu_2 = 0 $ and $ sigma_1 = sigma_2 = 1 $ ?
69970,have you tried simply checking the correlation between the variables ?
69809,what you are doing is a little unclear . have you got a control group ?
70024,"the answer is tied to what exactly you mean by "" important "" . also , what is "" top pc "" ?"
70054,could you clarify what exactly do you want to know ?
70068,"i know you say that you do not want to use matrices , but have you tried solving the matrix equations ?"
70084,can you point out which page contains the interpretation you don't understand ?
70089,what statistical language do you use ?
69518,"can i check - when you do the bootstrap , do you trim first , then bootstrap the trimmed sample , or are you bootstrapping the trimming as well as the mean ?"
69425,"first off , do you understand how a q-value is calculated from a p-value ?"
70138,extremely convenient compared to what ?
70150,"feynman , in the book you reference , already answers this question : "" if he wants to test this hypothesis [ found through exploration ] , . . . he must do another experiment . "" what you seem to be asking concerns whether feynman may have been too extreme ( "" exaggerating a little "" ) : to what extent , if at all , can formal testing of hypotheses be justified when they were developed by exploring * the same data * ?"
70108,"1 ) does the chair picks people sequentially or "" all at once "" ?"
70179,it seems unlikely a gamma would fit daily rainfall records ( except by accident for a sufficiently small dataset ) : there will be too many days in which no rain at all occurred . these * true zeros * have zero probability no matter what the parameters may be . could you share with us your reasons for fitting a distribution ?
70153,what are those numbers at the end of your question supposed to mean ?
70248,the $ p $ -value for the hypothesis $ h_ { a } : mu_ { text { women } } mu_ { text { men } } $ vs . $ h_ { 0 } : mu_ { text { women } } geq mu_ { text { men } } $ is about $ 0 . 034 / 2 approx0 . 017 $ . so you have evidence * against * the null hypothesis . but could you explain what you hope to achieve with this ?
65493,are you sure your full conditional for $ beta $ is correct ?
70307,"closely related threads : [ interpreting pca scores ] ( url ) , [ what are principal component scores ?"
70325,spring23874 can you show us any attempts you have made at this problem or where you are stuck in trying to solve it ?
70286,""" p ( f f ) = 1-p ( f b ) is impossible "" . . . if this is so certainly the case , what do you need us for ?"
70356,"how does "" no change non vegetated areas "" factor into the amount of vegetation ?"
70366,"not sure where the post-heart rate fits in . how are "" post operative complications "" measured ?"
70368,"a guess : the heatmap corresponds to the ellipsoidal contours of a multivariate gaussian density obtained by fitting the data ( probably by maximum likelihood or similar ) . the white contour lines correspond to the conditional ( gaussian ) density obtained from conditioning on the given height , so , e . g . , the bottom line is the density for weights given a height of 140 ( cm , i'd guess ) . do you have access to the underlying data ?"
70385,'wilcoxon rank-sum test' ?
70407,"i've only ever heard of bma being used in the context of evaluating completely disparate prediction models incorporating diverse factors and using several different approaches , such as partial least squares , neural nets , and nearest neighbor prediction models : none of which are nested . what are you hoping to achieve with such a bma application ?"
70410,what do you mean exactly with confidence interval ?
70414,what have you tried ?
70424,""" * i used the quantile function to get the 75th quantile of the distribution . * "" -- why did you do that ?"
70389,"can you show us any calculations , or attempts at solving this problem , that you have tried ?"
70469,hi xochitl and welcome to the site ! could you please add the full references ( preferably with a link to the papers ) ?
70344,what is the support of $ f_i $ ?
70507,have you tried using any of the standard statistical methods for gene expression analysis ?
70490,why is there a minus sign in front of the third term of the taylor expansion ?
70397,"as the large ses are in the binomial part of the model , i check if separation might be an issue - i . e . you can perfectly predict the response at some value of the predictor . have you plotted the data as binary values ( 0 , 1 ) as a function of the seasons ?"
70532,"i'm struggling to understand your question . this is how i understand it : a student answers a series of questions you created . he / she can take multiple attempts to get the answer correct . then , you wish to take the data and determine the student's skill level from 1 ) how many times they attempted it and 2 ) how difficult the question was . is this correct ?"
70556,"according to your ` lmer ( ) ` syntax , you've specified a model where there is a fixed effect of ` station ` and four random intercepts , shared by individuals with the same ( 1 ) combination of ` station ` and ` tow ` , ( 2 ) value of ` day ` , ( 3 ) combination of ` station ` and ` day ` and ( 4 ) combination of ` tow ` and ` day ` , respectively . is this what you intended ?"
68589,"you have skipped crucial aspects in your description . after you uniformly draw an $ x $ , what happens next ?"
70601,"exactly one , or at least one ?"
70629,"if you have uncertainty in your $ x $ 's , you generally shouldn't use ordinary linear regression because it's biased ( though small uncertainties will result in small bias ; maybe you don't care so much ) . are the uncertainties in your y's always constant or do they vary ?"
70650,"stphanelaurent , [ is it so unusual ?"
70672,"can't you just include your ordered predictor , as well as orthogonal ( 1-df ) contrasts to test for linear or quadratic trend ?"
70695,what are you trying to * get * exactly ?
70697,i've edited some of your formulas . could you please check if they are still correct ?
70664,"what do you mean by "" continuous classes "" ?"
70703,"is your issue that you understand the lack of significance when you call ` summary ( model2 ) ` , but do not understand the lack of significance when you call ` anova ( model2 ) ` ?"
70717,"can you clarify your last sentence , user30574 ?"
70655,"when you say you "" check the output $ c_t $ . . . "" , do you mean the * filtered estimates * $ hat c_ { t t } $ , not the * true states $ c_t $ ?"
70100,"on page 245 of long & freese ( 2006 ) they write that negative test statistics are common . they also cite hausman & mcfadden ( 1984 , p . 1226 ) who say a negative value means iia was not violated . the absence of p-values is puzzling . what does small-hsiao iia test produce ?"
70747,"density is not probability . for a continuous variable , the probability of taking any specific value is effectively $ f ( x ) dx $ not $ f ( x ) $ . ( consider a normal with mean 0 and standard deviation 0 . 1 ; what's $ f ( 0 ) $ now ?"
70748,why would a * one-tailed * alternative be reasonable for part ( a ) ?
70799,i think you should thin about this question in reverse . if you draw random numbers ( say for example pulling numbers out of a hat ) will it follow a distribution ?
70804,are you asking about the possibility of 70 % of numbers are between 8 and 12 ?
70815,"( 1 ) could you please tell us what you mean by "" dv "" ?"
70817,can you tell us a little bit more about the design of your experiment ?
70845,what progress have you made on this problem or where are you stuck ?
70906,"it's a nice question . presented abstractly , though , as a problem about arbitrary metric spaces , it strips away all the relationships that could be exploited to obtain efficient algorithms . for instance , $ mathbb { f } _2 ^ n $ with the hamming distance enjoys a tremendous number of isometries . in the general case there's nothing to exploit , so you would just have to make some kind of exhaustive search of the balls , exploiting nothing but basic properties of a metric ( symmetry and triangle inequality ) . what is the metric space you are * actually * dealing with in your practical problem ?"
70917,"it requires a binary variable because it's a model of the "" success probability "" , which doesn't really make sense outside of a binomial experiment . isn't a yes / no question a clearly defined dichotomous variable ?"
70916,"welcome to the site , blub85 . cv is not a discussion forum , it is intended as a pure q & a site . i have edited your q to make it consistent with this . please make sure it still says what you want it to . i gather your question is * what papers are there on qar ?"
70935,"* i don't know what you're trying to convey with the word "" skewed "" there * . can you rephrase ?"
70943,what values are you getting for $ alpha $ and $ beta $ ?
70985,"i think this is a good question . however , could you please be more specific as to what you mean by representativity ?"
70545,what level of text are you looking for ?
71045,do you know * anything * beyond the cv ?
71044,"by "" randomized "" do you mean that you simulated scores ?"
71058,"does the output of ` with ( df3 . emg . m1 , table ( dog_id , cond5 , stride ) ) ` result in every cell being equal in size ?"
71032,"when you say "" largest sample "" do you mean 'largest observation' ?"
66348,please check you didn't make a transcription error ( who the heck uses a significance level of $ frac { 1 } { 2 } $ ?
47880,"what do you mean by "" biased residuals "" ?"
71087,do you have several values ( plants ) per box and time point ?
71096,what are your ` vals ` ?
71150,can you explain what the two models are ?
71221,"edited : to clarify , you're first conducting pca and then trying to isolate the principal components that are best explained by some particular variable ?"
71243,"you most likely use ` lme ` and not ` lmer ` . other than that , why not ?"
70858,"i'm having trouble following the model and this seems to be where the error lies . . . i find a hierarchical drawing showing "" is distributed as "" and "" is equal to "" with the priors can be helpful when visualizing these . perhaps more comments in the model text also ?"
71265,that would be a bad fit . why would you ever do that ?
71289,i don't completely follow your situation . can you provide an example ?
71297,"( 1 ) raegtin , you ask nice , interesting questions . i am fond of bt models , but it seems a tad forced here . are you familiar with the collaborative filtering literature ?"
71332,"this is not a question that can be answered with a "" yes "" or a "" no "" . the more people you have , the more precise your estimates can be . but before we can say exactly how to do this , we'd need to know more about what you are testing . is "" performance "" measured on a continuous scale ?"
70973,possible duplicate of [ when should you center your data & when should you standardize ?
71355,"it depends on what the error bars are to represent ; different things are possible . for example , it's quite common in this situation to use standard error bars to represent the standard deviation . so what , specifically , are your error bars intended to indicate ?"
71404,1 ) your example data make it seem as if each effect size estimate comes from a different study ( $ studylab $ ) . is that correct ?
71424,not sure if i understand . what do you mean by swapping ?
71414,a few more thoughts : i assume you have ` ones ` defined somewhere not in the visible code ?
71446,"if this is for some course , or for your own study , could you add the [ self-study ] ( url ) tag please ?"
71485,"working on an answer , but a clarifying question : are you actually looking for the * best * prediction , or something like an unbiased estimate of association controlling for confounding variables ?"
71498,"hi and welcome to the site ! i don't understand the question : you say that "" there is a 50 % chance that any new product would be successful "" and in the end , the question asks "" what is the a priori probability that a new product would be a success ?"
71509,"to get some insight , it sounds like you are supposing the data $ x_i = f ( t_i ) $ have a particular functional form ; namely , one in which the intercepts vary linearly with $ t $ . because the intercept is $ f ( t ) -f' ( t ) t $ , we can differentiate it to obtain the slope $ beta $ . the derivative is $ f' ( t ) -f'' ( t ) t-f' ( t ) $ = $ -f'' ( t ) t $ , implying you believe $ f'' ( t ) approx - beta / t $ for a range of $ t $ . integrating gives $ f ( t ) approx c_0-c_1t- beta ( t-1 ) log ( t ) $ . is this consistent with how you are thinking about your data ?"
71531,can you explain what you mean when you say you always get a bias when comparing samples from group 1 with samples from groups 3 and 10 combined ?
71541,"the 2 comparisons among means that you stated in english do not agree with the 3 comparisons among means implied by your matrix of contrasts . if i understand correctly , you say that you want to compare a to c , and then b to the mean of a and c . but the contrasts that you wrote imply that you want to test all pair-wise comparisons . ( the 3 contrasts that you wrote actually form a linearly dependent set , so they wouldn't work in an actual regression , but i take them to mean that you are interested in the pairwise comparisons . ) so which set of questions is it that you're interested in ?"
71591,"will the sequence stop immediately if $ x_0 = 1 $ , or are you interested in asymptotic behavior ?"
71603,"can you describe what is the "" no avail "" when you attempted to use logistic and quantile regressions ?"
71614,"your code explicitly takes the magnitudes out and you are asking not to , so why not just leave out the division and use the dot products ?"
71626,"would it be correct to assume your combined data could be accurately and completely represented by a collection of ordered triples of the form $ ( i , x , y ) $ where $ i $ identifies the experiment , $ x $ indicates whether treatment was applied or not , and $ y $ is the protein level ?"
71540,"what do you mean by "" correlated with $ rho = 0 . 8 $ "" ?"
71476,do you think you could impose a meaningful loss function ?
71606,i'm confused by a couple of things - your estimates are 0 . 109 ( from glm ?
71455,"so you're taking other measurements and your algorithm calculates an estimated brain volume measurement based on those , and you want to check the realism of your algorithm by seeing if it is smooth and basically linear ?"
71694,1 . please give the full reference for the book by erna weber . 2 . at what level do you want to calculate the confidence interval ?
71713,"i edited the maths in your question , and changed it from $ ( x ^ t ) x $ to $ x ^ tx $ which is hopefully what you wanted . or was it $ ( x ^ tx ) ^ { -1 } $ ?"
71726,"have you worked out any explicit examples for small $ n $ , including $ n = 1 $ and $ n = 2 $ ?"
71752,can you explain more about what calculations you're actually doing ?
71701,"clarifications : does slot filling takes place on a daily basis , or is the slot "" booked "" in the beginning of the week for the whole week , or for some days of it ?"
71705,""" long-range autocorrelation "" does not necessarily imply non-stationarity . is therefore your question about two stationary , or two non-stationary , autocorrelated processes ?"
71793,why not start from some simpler and probably easier to understand relative risk or odds ratio ?
71776,proportion of what ?
71825,why do you need an approximation ?
35414,"this question is hard to answer without knowing exactly what model you fit in your technique 1 . you mention 3 possibilities , but as far as i can tell , never settle on one . then later you say "" technique 1's standard error [ . . . ] is ~ 0 . 206 . "" precisely what model is this the standard error for ?"
71720,[ deviance ] ( url ) . how are you fitting your poisson model ?
71810,are you sure you want the log transforms of your rhs values ?
71853,you have a sample of 100 randomly divided into two groups ( equal ?
71873,i think i understand it . why not include both a difference term and the raw values of your predictors ?
71914,"henrik tough crowd . . . martyn , could you give the reference for faraway ( 2006 ) please ?"
71960,you should expand your question on how you will analyze similarity : are you using a ` tanimoto similarity score ` ?
71986,"it's hard to say , just from this , whether you should be concerned . can you post the crosstabulation of l1 and the dv ?"
72039,how is this different from * outlier detection * ( applied to residuals ) ?
72087,"the t-test is failing to reject the null hypothesis that your model is unbiased . this is not the same as saying your model is appropriate , after all , the sample mean of the $ y_i $ is unbiased ( no need to run a t-test to test that hypothesis ! ) and is a different model , almost certainly , than your regression tree ended up with . the negative $ r ^ 2 $ means that your model's predictive variance is less than that of the sample mean of . . . what ?"
72126,welcome to the list . is this homework ?
72081,"they way you write it , $ s ( theta ) $ is not the maximum likelihood estimate , but the first derivative of the log-likelihood w . r . t . the unknown parameter . and what do we do with the first derivative in order to find a maximum ?"
71640,"you talk about a regression model . the regressors will be just an intercept and "" time "" ?"
72179,"i have a high degree of belief that exactly one of your hypotheses is true : - ) . your data might be able to cast doubt on one of them . but what is "" small "" ?"
72185,benjamin could you explain how that solves the op's problem ?
72200,this integrand is trivial to integrate because $ x $ does not appear within the arguments to the exponential . perhaps you have a typo ?
72203,the difference in sign may just be an interchange of x and y ; i don't think that in any way explains the difference in ase though . . . . why would you use ase for a sample size of 7 though ?
72219,"it's not quite clear what you're asking for here . when you say "" ideally we would like to have k here as 5 or 6 . . . "" , for example , how are you arriving at that ?"
72224,is $ mathbf x $ centered ?
72250,"it looks to me like it should be possible to estimate survival ( or death ) rate as a function of time-to-treatment and the type of treatment , yielding two curves . . . and that the primary interest is in 'at what time do the two curves cross ?"
72262,can you show ( or construct ) a small example of original values and the effect you're asking about ?
72266,"make a prediction equation for each tree ( it will be simple split points ) , and then average the predictions from each equation ?"
72276,"( 1 ) presumably $ f $ is a bivariate probability density function . ( 2 ) the question asks for a probability , which ( by definition ) is a * number . * the answer you propose depends on some undefined variable "" $ x $ "" : this makes no sense . ( 3 ) the answer is fairly nasty : it will help to write it in terms of the number $ x $ satisfying $ x = exp ( -x ) $ . if this is a probability homework problem , it seems to miss the pedagogical mark by requiring the evaluation of such an integral . are you sure you copied it correctly ?"
72294,what units are your dates measured in ?
72325,what is a / b test ?
72176,your examples all have measurements from one or the other labs but no samples analyzed by both labs . is that always the case ?
72349,do you know which data point belongs to which cluster before you do the sampling ?
72354,"perhaps i'm misunderstand , but why not compare kaplan-meier curves of the two groups . also , why parametric ( specifically cox ) ?"
72381,why would such a property be of any value in deciding which would be an appropriate model ?
72387,which variables do you actually observe / have data on ?
72407,"your question title is about measurement error ; your final question is about bias . the two are not the same . you also ask simultaneously : what is the difference , and is there a difference ?"
72409,"can you give an example of the effect you expect , e . g . 20 % , 30 % , 50 % . also , how do you plan to analyze ?"
72112,can you give an example of table of conditional $ p ( x y ) $ ?
72453,can you post the data via ` dput ( ) ` ?
72388,can you try to determine when the second derivative is 0 or close to 0 ?
72541,is it possible to include all pcs ?
72606,"what exactly do you mean by "" not nearest to any point "" , exactly ?"
72678,there is a substantial difference between the answer to this question for a * single * value of $ c $ and an answer that is valid for more than one value . which application do you have in mind ?
72421,what if you try to increase the plotting threshold ( 0 . 5 ) and to use more than 4 color steps ?
72467,"an interesting question . however , the second "" obviously "" ( about not respecting the marginal distribution ) is not at all clear to me . why is it obvious ?"
72735,this isn't really clear . can you state your situation in simple english w / a concrete example ?
72709,can you be more specific about the 'trend' ?
72752,"your integrals make no sense , because $ u $ and $ u $ have different meanings ( one is a random variable , the other is a dummy variable of integration ) and $ w $ and $ w $ have different meanings . what solution did you get using double integrals and why is it important to obtain one using triple integration ?"
72759,what is the meaning of your data ?
72683,"two normal distributions centered around 0 , one with larger variance ( compare 0 . 1 and 0 . 9 quantile ) ?"
72790,"presumably by "" pho "" , you mean * rho * ( $ rho $ ) . however , your question is not clear . what do you mean by "" what s the tightest bound you can give "" ?"
72717,zhubarb i'm dealing with a similar problem and would like to follow your hmm approach . where you successful doing this ?
72878,"this may be clear to some , but i can't understand the distinction you are making . empirical cdfs are necessarily calculated from the data . what is the modified cdf ?"
72906,"could you elaborate on what "" normality assumption "" you are referring to ?"
72919,"from your comment to learnerbeaver's reply below , i gather that this is homework / self study , which is why i added the relevant tag . so a few hints : what have you learned about the effect on r ^ 2 when adding a variable to a model ?"
72928,"some intuition : in going from $ y_k $ to $ y_k ^ 2 $ , do you lose any information ?"
72955,"do you want to be guided on a journey to figure out the answer or would you prefer to just be given the answer , along with an explanation of why it's the answer ?"
72956,"two questions : 1-what exactly do you want to show , basic data , the multiple comparisons , the comparison's differences , all of the above ?"
72973,do you know anything about the shape of the distribution of the $ y $ -values ?
73004,do you know the functional form of $ f $ ?
73050,"given that you have 5 dichotomous variables , i am not sure what graphs you created . can you tell us ?"
73062,"whenever you are implementing a well-known statistical procedure , it is a * great * idea to compare your results to those produced by working software . when you run your data through a stats package , what does it report ?"
73078,you're not allowed to sample non-event cases because there could be error in those samples ?
73018,what does $ y x $ mean ?
73099,do you need an analytical solution or a piece of code ?
73123,"add "" is there an easy way i overlooked to transform a general lasso to the standard lasso form ?"
73140,why remove mathematical formatting ?
73144,"for others i will add that in climatology "" anomaly "" just means deviation from a reference level ; there is no implication of anything pathological or very unusual . in terms of the question , who is claiming that this is "" optimal "" ?"
73053,what is 80' and 90' ?
73209,what is the best approach depends on the conditional distribution of $ y $ ; you might be looking at either nonlinear least squares ( weighted or unweighted ) or generalized nonlinear models . what are the y-values ?
73286,it's not entirely clear what you are asking . surely you had a reason to use pca ?
73318,take some care . one reason for suggesting you write the cdf was that i was hoping you'd see that your * density * is probably not correctly specified ( i suspect you're aiming to have continuity at $ pm x_0 $ - is that the case ?
73297,"you need to construct a test statstic to test the given null hypothesis . the statistic will tend to be differently distributed ( for many tests , it may tend to be larger , but sometimes smaller or sometimes both ) when $ h_0 $ is false than it typically is when it's true . what are your known quantities ?"
73324,the criteria are yours to choose . why would you declare any observation to be an outlier ?
73371,"what exactly does ` points ` measure and what relationship does it have ( if any ) to a player's "" score "" ?"
73379,"could you please explain how it would be possible for a percentage of * anything * in a group of size $ n = 6 $ to be any value other than $ 0 , 100 / 6 , 200 / 6 , ldots , 500 / 6 , $ and $ 100 $ ?"
73400,it's not clear what the ranking is to achieve . why are you ranking ?
73402,"do you have a particular functional form for $ g ( beta , x ) $ in mind ?"
73386,"could you please explain what you mean by "" register the data "" and what the nature of these "" technical difficulties "" is ?"
73231,do * exactly what * 1000 times ?
73466,what's the point of categorizing it ?
73384,what would be the dependent variable ( s ) ?
73513,"i think this question is subtly on-topic . i don't think the real issue is 'what r function . . . ' or 'how do i use the r function . . . ' . the problem seems to be a confusion about what t-distributions * are * & how they are similar to / different from normal distributions . in addition , "" how would a non central vs a central t affects [ sic ] my sampling ?"
73528,"as nick said , the gaussian is * also * a special case of the t-distribution ( a limiting case ) , though in fact the cauchy isn't the extreme case in the other direction if one allows non-integer degrees of freedom ; i've seen $ t_ frac { 1 } { 2 } $ used for example . i could write down a hundred differences between the two that one might discern ( e . g . a common observation people make is that the cauchy is heavier-tailed and more peaked ) . to list every difference you * might * mean could fill a book ( and mean your question will be closed ) . what kind of things do you mean ?"
73544,"i can guess what is going on , but you need to give more information . the dependent variable is ( daily ?"
73545,"this sounds like a markov chain problem where there are three states : ` 1 . a lot of sales ` , ` 2 . normal sales ` and ` 3 . very little sales ` . and you are asked : given the state was ` 2 ` at w = 1 , what is the probability of the system staying in ` 2 ` for 12 consecutive weeks ?"
73395,"i'm still learning about this , but from what i read this technique was used by turing in cracking the enigma code . turing's method was classified due to the war , but was also discovered by wald ( 1947 , sequential analysis ) . recent research by michael shadlen suggests that neurons or clusters of neurons use this method . i couldn't find that page number in e . t . jaynes's probability theory ( different edition ) . could you share which chapter / section discusses sequential inference or sequential analysis ?"
72824,how large is the reference group ?
73593,""" so for a . , the probability of g i get it just by summing p ( b , g ) p ( g , b ) = 0 . 5 "" this is not correct . remember , you neighbour has told you he has * * at least * * one child who is a boy . what options does that rule out ?"
73606,"could you please explain what meaning the $ -1 $ values have "" from the performance perspective "" ?"
73611,"hello - i think you are or should be asking whether just the first 2 of the r expressions in the equation can be replaced by cronbach's alpha . the last 2 , which are pre-post correlations , should not . or then again , maybe you mean the entire equation produces an equivalent of alpha ?"
73664,do you mean ` scatter y x lfit y x ` ?
73652,what about working with first differences ?
73720,"based on the relative sophistication of your question ( wrinkles pointed out by whuber aside ) , i assume that you've heard of glm's ?"
73435,what is the formula for var [ te ] that you are trying to reproduce ?
73767,maybe [ margin ] ( url ) can help ?
73855,"would it be possible to transform your random field to be normally distributed instead , so you could use hermite polynomials ?"
73837,"in your last line , do you really mean "" . . . the $ theta $ s to generate a sample of $ p ( phi y ) $ "" ( switching the $ phi $ and $ theta $ ) ?"
73613,"i hardly know where to begin . let's start with getting some context for the question and understanding the meanings of the terms you use . precisely what do you mean by the "" probability "" of an outlier ?"
73904,""" * is the difficulty of this the reason why no one does hypothesis tests anymore ?"
73486,"why don't you run formal co-integration tests instead of "" saying "" that the series are co-integrated ?"
73877,"i am not sure how you would do pca on the means . but , if you know what you mean , why not just do it both ways and see if they are different ?"
73907,how does this question arise ?
73980,"it sounds eminently possible , but could you please give more details about your situation ?"
74003,"i looked at only one of your references in order to find out what you mean by "" qp . "" where exactly is this decomposition called an "" svd "" ?"
74018,the link is not working . also have you considered machine learning procedures ?
74033,how do you understand persistence ?
74051,"why threshold at every 100 cases rather than select a sample of 10 , 000 cases ?"
74087,how did you arrive at 0 . 2 in a and why are you multiplying by 1 ?
74078,what was the sample size of positive cases ?
74110,do you know the definition of the conditional expectation as a projection in a $ l ^ 2 $ space ?
74140,why do you want to remove variables in your model ?
74182,what data do you have access to ?
74237,did you try to check your random variable against the definitions for sub-super-martingale ?
74249,"ga ( n , $ lambda $ ) is the gamma distribution . as a hint : think about how you would simulate the queue process ?"
74244,( 1 ) the role of the indexes in this question is unclear : why are they there ?
74243,"in what sense is estimating a multiple regression equation both w / the original numbers for a variable & w / all $ 0 $ 's "" more efficient "" than just estimating the model w / & w / o the variable ?"
74262,"just out of a matter on interest , is a lukring variable the same as a counfounder / confounding variable ?"
74281,couldn't you add a large enough constant to make them all positive and then take the logarithm ?
74297,have you considered propensity-score matching for the 2013 students ?
74329,"i think you need to clarify what is assumed known vs . unknown . you state in the 2nd paragraph that we don't know the parameter or the analytic form of the distribution . however , mle is usually a parametric technique , so some form is assumed . there are non-parametric mle approaches , such as emipirical likelihood , boostrap mle , estimating equations , etc . but it sounds like you are using the usual mle , in which case you should have some idea of the parametric model underlying the data , which you seem know given your last sentence . are you assuming x is a member of the location-scale family ?"
74334,why would the second order partial derivatives be between -1 and 1 ?
74395,why would you want to do this ?
74354,"if this is for study purposes , such as for some subject , please add the ` self-study ` tag . what is $ x $ ?"
74434,"with so many data points , the standard error of the ks statistic is very small , and so the fact that it's visually a reasonable fit is irrelevant - the test can still tell it doesn't fit . but note that you're misapplying the kolmogorov smirnov test , since it's a test for a completely specified distribution and you're estimating parameters from the data . in any case it's not clear to me why you'd do a hypothesis test here . do you really believe the true population distribution is exactly gamma or lognormal ?"
74410,"i'm still puzzled . precisely * how * are you expecting to be "" given "" a theoretical distribution ?"
74406,have you tried using the law of total variance ?
74468,an easy way of getting at this problem would be to use a monte carlo approximation . would this suffice ?
74469,"sorry , i thought $ ( x_i , y_i ) $ was data . if that's parameters , what's the data ?"
74478,"you didn't mention blocks in your description of the design . at a wild guess , did you accidentally ask for blocks when setting up the design in minitab ?"
74472,"likelihood ratio tests are a * class * of test where the test statistic is formed from the ratio of the likelihood under the null to the likelihood under a specified alternative , or more generally , the ratio of the maximum likelihood under the null to the maximum likeihood under a specified alternative . ( sometimes this ratio is a function of a simple sample statistic , e . g . the sum of observations , & so any test based on this statistic gets called an lrt , as it gives the same answers , even though the likelihood ratio may not be explicitly calculated . ) so is there a particular lrt you had in mind ?"
74505,"the problem is : be there any dimensionality reduction or not , you stay with 50000 cases . and you want a 50000 x 50000 proximity matrix . big . ( will your machine cope and in what time ?"
74510,were you given a reason why you should match rather than directly compare the means ?
74527,i suppose you meant $ alpha = 0 $ and $ beta = 1 $ in your third question ?
74561,are you sure that your time series is deterministic in time ?
74275,"welcome to crossvalidated ! you might want to consider either ( 1 ) asking this question on a minitab-related site , where everyone will understand the terms you're using , or ( 2 ) writing it in a more general way so that non-minitab users can help . ( also why do you think the optimum is incorrect ?"
74586,"a probability * density * is a probability density , period--and therefore can have values larger than $ 1 $ . but if $ theta $ has a * discrete * distribution then $ p ( theta x ) $ is not a density , it's a probability . which situation are you in ?"
74042,does each entry belong to exactly one class ?
74612,"fascinating question . is there only a single observation-triplet , or is this for a sample of size $ n $ , say ?"
74615,once again : you can and may check how _greatly_ any clusters differ on this or that variable . what you should not do is to conclude if that difference is statistically _significant_ - when you test on _those_ variables that participated in clusterization . why ?
74382,"if you are using pcs from a pca within some other procedure , their origin in pca is immaterial for significance testing with that other procedure . that is a little contentious , as statistical people don't all agree on whether pca is a multivariate transformation procedure or model estimation , but i think it is a good first approximation . if that argument is accepted , then your question is just about significance testing in whatever you are doing and covered by any standard account . do you regard linear regression and pls as equivalent ?"
74687,is the monthly temperature value some sort of average or an order statistic ?
74667,"difficult to answer your question because it is so broad . two points , though ( i ) what difference do you want to test ?"
74756,"1 ) if you're doing a box-cox transformation and then fitting to a weibull , the data itself isn't distributed weibull , 2 ) what is your time stamp ?"
74716,"something strange happens at the beginning of the second paragraph : whereas the first paragraph refers to the expected value of an * estimator * $ hat theta , $ the second paragraph refers to the expected value of a * parameter * ( which in the theory of unbiased estimators makes no sense : a parameter is a * constant * ) . that may be why you're stuck . as far as the "" just in case "" part goes , what is $ mu $ ?"
74732,can you send the results of ` sessioninfo ( ) ` ?
74841,what is $ n $ here ?
74873,by absolute risk do you mean the probability at some specific point in time ?
74878,"maybe i do not understand what you want , but assuming you want the loglikelihood of a ols model you just fitted ( eg . ` lm_test - lm ( weight ~ age ) ` ) won't that just be ` loglik ( lm_test ) ` ?"
74885,"if he chooses art together with french , does he choose math ?"
74896,"what do you mean by "" true value "" of an individual measurement ?"
74898,why did you multiply the likelihood by $ 10 $ ?
74909,are these four different weeks ?
74946,"your "" actual correlation results "" have nothing in common with the preceding output , which reports a correlation of $ -0 . 131 . $ how are these supposed to be related ?"
74947,can you clarify this ?
74963,""" results "" is vague here . please give concrete details . are you mostly focusing on whether key parameters agree , or are you as or more interested in whether values agree one-to-one ?"
74978,"could you please explain how your question does differ from the "" robust outlier detection "" question you reference ?"
74992,the probability you will observe a red ball on the next draw is always the same : it equals the proportion of red balls . are you perhaps asking how to update an * estimate * of that probability ?
75020,how many measurements do you have and how many missing months ?
75059,"i was thinking about the html-help in r , like ' ?"
76072,"if you're interested in comparing shapes ( say as characterized by curvature in some sense ) , then wouldn't dtw change the very things you're interested in measuring ?"
76074,"perhaps i am going blind , but are you certain that your conditional densities integrate to unity over their domains and for an arbitrarily fixed value of the conditioning variable ?"
76081,"you should clarify what you already know . have you ever done a confidence interval for a mean , for example , and so know what a confidence interval is ?"
76128,"do you mean that for an _arbitrary_ projection matrix this inequality holds , or you need to show it for a specific projection matrix , in which case you must know something specific about the $ x $ matrix ?"
75019,it would help to give more information about your specific task . what are you trying to predict ?
76171,"the function $ e ^ z $ is a strictly convex function in its argument ( $ z $ ) , whatever this argument is ( a scalar , or a function . . . ) so $ $ e ( e ^ { x hat b } -1 ) e ^ { e ( x hat b ) } -1 $ $ and to what $ e ( x hat b ) $ is equal to ?"
74929,"welcome to the site , user23658 . would you mind fleshing out your question a little ?"
76182,"do you only need to solve linear programming problems , or more general ones ?"
76169,"your question is unclear . please explain what you're discussing , expand abbreviations on first use , and otherwise make it as obvious as you can to use what is going on . are you talking about a markov decision process ?"
76201,how are the two tables related ?
76238,"i have voted to keep this question open based on its formulation as a request for algorithms to compute the student t distribution . i do warmly recommend restating the question to focus on this aspect and to make it accessible to non-r users , who are unlikely to know what "" pt "" does but highly likely to be familiar with algorithms to compute student t distributions . do you also need the non-central version ?"
76216,why are you using a ridge regression in the first place ?
19599,"wmmurrah will piggyback on your question , is the only advantage of bootstraping to obtain the confidence intervals ?"
76240,could you please send your matlab code in which you compare the different multiclass classification algorithms ?
76262,why do you think $ k $ should be 10 ?
76087,"you * did * change the definition of ` yvsn ` as well , right ?"
76211,"what does the sentence "" i input this into my model by checking what the % of people displaying 12 repeats was against the actual number that showed in a new test dataset so in this case 10 % into my polynomial regression yields 8 . 7 % chance of developing the condition . "" mean ?"
76332,does it is right to use all dataset sample for feature selection because we are running cross validation procedures . then we use again same dataset for training and test for classification ( either training / test split or cv again ) . is there any biased at the classification stage ?
76333,"what is nice about the slides is that in the pages before stating your problem ( slides 19-29 ) it collects all the definitions that are relevant to the proof , which is a matter of applying these definitions . that might help guide your investigation . at what point are you stuck ?"
43061,where on wikipedia does your t . wrong equation come from ?
76386,"to restate the question somewhat , in an attempt to make sure i understand it , you have a bunch of poisson data that's censored at some number ( either known or unknown ) , and you know how many observations were censored , and you'd like to estimate the mean taking the censorship into account ?"
76388,"if instead of using $ text { age } ^ 2 $ you introduce the functionally equivalent $ ( text { age } - text { mean age } ) ^ 2 , $ what correlation do you find with $ text { age } $ ?"
76392,"usually you would count all cases , significant and not - though it can depend on the actual question you're trying to answer . however , i'm concerned that you don't seem to be using weights at all in your model ; it would surprise me if the log-counts had nearly constant variance across time . do they ?"
76394,""" * if you wanted to approximate a binomial distributed variable with a two-component mixture normal * "" - optimizing what criterion ?"
76427,the coefficient of variance / variation is defined as the ratio of standard deviation and mean of a random variable . can you please explain why your formula in 2 ) looks different to this ?
76411,"if there was anything that was always best you'd know already , because it would be the only kind of interpolation people would talk about . are all your observations without noise / error , or should there be smoothing as well ?"
76463,"some quick comments : it would be helpful to know how much data you put into it and what type of model you are fittig ( i . e . what role do lambda , t , and beta play ?"
76475,"i am not sure that it is meaningful to speak about significant loadings in a non-specific sense : before extraction all variable variance is fully distributed across factors , so what would it mean to be significantly loaded ?"
76490,"there is a lot to discuss here . but i'm caught up on the model issue . if you're planning on using this daily , are there models other than decision tree ( rpart ) that would be practical ?"
76498,can you describe in a little more detail the actual problem you are considering ?
30963,how many training samples do you have per class ?
76499,is the sliding window uniform ?
46429,"if $ y = ax b $ , then $ e ( y ) = a e ( x ) b $ and $ var ( y ) = a ^ 2 var ( x ) $ . does this help ?"
76547,"ok , what have you tried and what are you having problems with ?"
76563,is this homework or a class assignment ?
76564,"your notation cannot be deciphered by readers unfamiliar with the context . it sounds like the $ x_i $ are ordered pairs , whence $ x_i-x_j $ must be some * two * dimensional distance ( euclidean ?"
76601,the line that should be wl is labelled ww . the error propagates down that line . is it that all you have is this figure or do you have the data from which the figure was generated ?
76612,aren't logit models heteroscedastic by definition ?
76626,is the age variable supposed to be here ?
76643,what does $ p ( t_i ) $ represent in that law of total probability calculation ?
76627,"nickcox the first two questions in the body of the post -- "" * how can i diagnose the normality assumption about time ?"
76642,not enough detail here . what is your response ( outcome ) variable ?
76665,is there some reason why you can't simply use the mean of all measurements for a region within a cell line as the methylation measure for that region in the cell line ?
76697,"a binomial variable takes on values in $ { 0 , 1 , 2 , dots , m } $ , and as such can't be an "" expected proportion of successes "" . do you perhaps mean that $ y / m $ is the expected proportion of successes ?"
76737,are the $ sigma $ 's known to the person doing the test or not ?
76772,"a very careful choice on the tukey ladder is one possibility , but it's still not particularly satisfying ; with a bit of fiddling about one can do something like [ this ] ( url ) ; is that the kind of thing you wanted ?"
76807,""" nsfw "" means what exactly ?"
76892,"what about replacing the variable "" current age "" by the follow-up time ( = current age minus baseline age ) ?"
76906,"your example data shows a mixture of data types : sex is dichotomous , age is ordinal , the other 3 are interval ( and those being in different units ) . doing linear pca is right for interval data ( but you have first to z-standardize those variables , because of the units ) . it is debatable whether pca is appropriate for [ binary or dichotomous ] ( url ) data . you should not use ordinal data in linear pca . but the main question with your example data : why _at all_ to do pca with it ; what sense could it make in this case ?"
76907,"could you please explain what a "" uniform random vector mod p "" is ?"
76930,can you clarify the model you fitted please ?
76948,". . . in other words , i believe you meant to ask "" what is the minimum number of data points required for a kernel density estimation to be considered non-misleading / acceptable / adequate ( something like that ) , based on accumulated experience up to now ?"
76987,have you tried doing mc simulations to see the how distribution looks like ?
76994,is your variable discrete or continuous ?
76885,just to be clear : you want to compare clusters of * nests * rather than clusters of birds ( a b c d e to f g h i j ) ?
77008,"the problem is that your description is inadequate : you need to stipulate more precisely * in what ways * a scatterplot might deviate from "" white noise . "" this is perfectly analogous to simpler hypothesis tests , such as comparing two distributions . when we test whether data might come from a normal distribution , we are testing for particular forms of non-normality : shifts in location , scale , or even in a broader sense as measured by the max . difference in cdfs . regardless , * some * measure of deviation from the null is required . how do you want to measure deviation from white noise ?"
74786,"that decomposition should work with any model that includes an additive constant term . what , precisely , do you mean by "" exponential regression "" then ?"
77048,is this for some subject ?
77152,"two things to think about : 1 ) in your posterior , there's nothing to prevent $ theta y $ ( why does this matter ?"
77154,why do you want to do this ?
77156,"one good way to approach problems with largish but arbitrary numbers is to make them smaller so you can see what's going on . suppose there were only * two * kinds of car , chosen with equal probability . it looks like your formula in that case would be $ 1- ( 1 ^ 6 1 ^ 5 / 2 ^ 6 ) , $ but that's a negative number ( and obviously wrong ) . could you solve this simpler two-car problem ?"
77163,are some of the items reverse coded ?
77201,why should p ( h ) p ( d ) = 1 ?
77269,"this is a standard topic in meta-analysis . note that cohen's d is biased & needs to be adjusted . you need to know the sample sizes ( n's ) for this . if you have that , the bias-adjusted standardized mean difference has a variance that is a function of the statistic , so you only need the statistic to form ( eg ) confidence intervals . in addition , there are chi-squared tests in ma to determine if basmd's vary more than they 'ought to' . do you know the constituent n's ?"
77080,you've fitted a model with period $ 2 pi $ . what's the period of your data ?
77302,"well , of course you can use empirical distributions directly . ( your title starts with 'fitting' , so one assumed that's what you wanted to do . ) what do you want to do with the distributions , whether fitted or empirical ?"
77293,"and can you provide the three formulas you are referring to ( entropy , deviance , impurity measure ) ?"
77311,what bandwidth parameter have you set for rbf kernel and how did you choose it ?
77234,""" * 0 . 001513801 ( 1 . 35 % increase in mortality ) * "" -- how do you get 1 . 35 % ?"
77334,1 ) why do you think your small data sets follow a normal distribution ?
77376,i don't follow the nature of your data . it sounds to me like you have * counts * that were adjusted ( with 'distance' somehow ) . is there a max that is meaningful a-priori ?
77391,could you please formulate the null and alternative hypotheses of such test and explain why they would be useful ?
77394,is this homework ?
77430,"this may be drawing on definitions in some literature . it does not seem related at all to the mainstream statistical sense in which "" confidence "" implies "" confidence interval "" . giving some sources and / or more explanation would help greatly . otherwise $ ( x y ) $ suggests only $ x $ given $ y $ ; are you reaching towards conditional probability ?"
13801,why do you want to normalize the data points first ?
77488,it looks like something ( a data file ?
77500,"assuming nonnegative , can't you just invert the observations and apply the km estimator to that ?"
77514,"what happens if , after losing a gamble & refusing to reduce his bet , he has $ d ^ m ! ! / _n $ left over ?"
77320,"the wikipedia article about apriori is poor . i suggest to try the links in [ that answer to a similar question ] ( url ) ( first link is broken , but the others are fine ) . for this question : what are the transactions at the start of the algorithm ?"
77585,why would you use a genetic algorithm to learn the parameters of a polynomial ?
76999,use mvrnorm and then exponentiate to get log-normal variables ?
77528,i tried to clarify the concept of profile likelihood . can you comment a bit further on what you are doing in the above code ?
77575,"i agree with glen . please , give a better description of the problem . like $ x mid n = n , theta = theta sim mathrm { bin } ( n , theta ) $ . which priors have you used for $ n $ and $ theta $ ?"
72144,the effect size measure cohen's * d * ?
77639,"when a student doesn't answer a question , is it the case that he decides not to answer it ?"
77663,what is the relationship between $ t $ and $ n $ ?
77634,"can you provide a source which distinguishes "" test of homogeneity "" and "" test of independence "" ?"
77602,"so , you have n respondents x p variables binary ( 1 vs 0 ) data , and seek a spss solution to compute frequences of "" all = 1 "" for all possible combinations - by 2 , 3 , . . . , p - of variables ?"
77701,why are you fitting linear regression with a non-continuous dependent variable ?
77670,"welcome to the site , mike . i don't understand your question . what does it mean to "" test . . . for a time series "" ?"
77609,is that not just the same as asking to investigate non-linear relationships of predictors to the log-odds of response ?
77728,are you calculating the expected ratio as a function of the bin or across all bins ?
77825,"sorry , your question is not clear . in _what way_ are you going to use information about predefined classes ( clusters ) during cluster analysis ?"
77833,"you seem to use "" exist "" in the sense of "" has a conventional closed-form expression . "" ( "" exist "" in math and stats usually means that it has a well-defined value , whether or not that value can easily be written . ) this raises the question of what you mean by "" compute "" : are you looking for a closed-form expression , or would alternatives ( such as a power series , and algorithm , or a numerical approximation ) be acceptable ?"
77845,is this for some subject ?
77820,have you got some toy example data ?
77882,why do you want your data to 'fit a normal distribution' ?
77888,have you considered a [ q-q plot ] ( url ) ?
77880,"could you please explain the kinds of data and the process used to "" estimate "" a value $ x $ from equations of the form $ y = ax z $ ?"
77907,most full-featured stats software does this with a single command . what software are you using ?
77915,"what leads you to believe that the regression has "" failed "" ?"
77926,"i am not well versed in statsmodels , could you write down mathematical definition of your model ?"
77925,re q . 3 : where on wikipedia ?
78001,the * sample * minimum you already know ; the * population * minimum only exists for distributions with a restricted range & you haven't said anything about the distributional assumptions : are you asking about predicting the minimum for a newly sampled data-set ?
74832,for non-panel data granger causality test is a simple f-test of a certain regression . i surmise it should be something similar for panel data . maybe there is no package because it is not necessary ?
78042,out of morbid curiosity what does the aic tells you about your models ?
78045,"could you post a plot of predicted vs observed values , with the mean regression line superimposed , for each model ?"
78079,"what specifically are you computing when you "" calculate the rmse of the sample "" ?"
77622,"are the observations matched ( e . g . , 10 different problems , each one solved both ways ) or independent ( e . g . , 20 different different problems -- 10 solved one way , and the other 10 solved the other way ) ?"
78104,"maximize the likelihood , naturally . not trying to outsmart you , but what answer are you seeking ?"
78157,is this homework ?
78149,"as far as a pure statistical answer goes , i don't think this makes sense . if your response variable has * any * repeated values , then it must not really be normally distributed ( since the normal distribution is continuous ) . . . if the response is a proportion , should you be fitting a binomial glm instead ?"
78231,hi ioannis ! do you think that your question needs to be tagged 'self-study' ?
78240,missing from this question is the essential piece of information : * what do you want to learn from the simulation ?
78273,"maybe you can write the equations , up the point you have solved ?"
78304,so you ran an ordinal logistic regression & exp ( coeff ) is 1 ?
78322,"welcome to the site , user2598356 . can you frame this in a more general ( non-r specific ) way ?"
78317,do you really mean to write a * two-sided * formula for $ p_ { * } $ ?
78332,"please , tell more about how your data look . e . g . : when you do pca on columns of data , what define rows and what define are columns ?"
78337,"for your 1st question : the $ hat { beta } _0 = 3 . 2 $ is given , so you know this parameter . does that help ?"
78307,what are the relative sample sizes ?
78341,"could you explain how you know the p-values are "" inflated "" due to multicollinearity ?"
78290,what are the items ?
78354,"the question "" what is ?"
77984,do you just need the sample covariance between two indicators ?
78430,"it's possible in any statistical software . just multiply . the result will also depend on z and w . otherwise put , quite what is the problem here ?"
78431,"instead of splitting the dataset and then aggregating , why not aggregrate by group within the full dataset . that said , i suspect that you don't really need to aggregate / collapse your data at all . can you specify the hypothesis or research question you are trying to test or model ?"
78500,"probabilities are constrained to [ 0 , 1 ] , yet polynomial functions always eventually go off to either $ infty $ or $ - infty $ . given you said $ n $ is arbitrary , how will your probability function $ p ( n ) $ respect the constraints on probabilities ?"
78508,"i'd guess whoever said that was using "" points "" in the loose sense of "" score "" or "" measure "" . deviance certainly isn't the number of data-points in your sample or anything like that . and what it is is answered rather well in the linked post , i think ; _what_ question remains specifically ?"
78470,"you are using the term "" experiment "" differently than i do . do you mean something like 'individual seed' or 'combination of conditions' ?"
78556,what's dbscan please ?
78561,which parameter of the binomial is $ k $ ?
78626,which naivebayes do you use ?
78611,"at random , or whether achieved was different from expected ?"
78681,"i'm not sure i understand you question . do you mean that you expected the forecasts to be a little higher , that is , that they follow a slightly increasing pattern with respect to the last years in the sample ?"
78718,why are you not treating the data as binary and calculating the odds ( with 95 % ci ) ?
78713,please indicate what * specific * help you need with this problem : where are you stuck ?
78717,"but how can i tell you to use an uninformative prior , unless you said you wanted one ?"
78741,"` fit1 ` has only 1 ma & 1 ar parameter : did you mean ` fit1 -arma ( diff ( x , 1 , lag = 1 ) , c ( 3 , 3 ) , include . intercept = f ) ` ?"
78765,"let's back-up : do you have the raw data , because if so , we wouldn't start from here ?"
78773,welcome to our site ! do you have additional statistics about the means and standard deviations of the independent variables ?
78744,is that not just the same question as whether / how to standardize the predictors ?
78805,"apologies , it looks like cv doesn't make this distinction between mixed models and mixed effects models . ( i'm not sure why both tags are needed on cv then ?"
78807,"thank you ; it's better . but it is also confusing : this model underlying ` lm ` does * not * treat the data as bivariate normal , so you seem to be asking to do to different things at once . do you want to predict income from education or do you want to model the bivariate distribution of the ( income , distribution ) pairs ?"
78711,"sorry , that was an error . i mean the sample proportion of values that are 7 . 5 ; my son distracted me as i was typing the last couple of words . your sample estimate of the probability of an unobserved event is zero . did you want to apply a prior ?"
78808,when you type ` etasq ` at the command prompt doesn't ` r ` show you the code ?
78819,that seems decent to me . what do you make of the ` please keep in mind that this is a multiple regression ` in the 1st question ?
78820,are you simply looking for [ survival analysis ] ( url ) ?
78776,"is the "" $ r $ "" after the "" $ mathbb { p } $ "" a reference to $ r $ or did you intend to write $ pr $ ( "" probability of "" ) instead ?"
78791,"as your wikipedia link states , the polychoric correlation assumes that the manifest ordinal variables come from categorizing latent normal variables ; kendall's tau & spearman's correlation do not assume this . other than that , the differences are covered in [ kendall tau or spearman's rho ?"
78861,"can you describe what your input and desired output would be , in a bit more detail ?"
78894,""" * the input is just a vector ?"
78907,"this seems to be rather similar to your previous question , though it is perhaps a better fit . when you say 'f' , which ( of many ) f tests do you mean ?"
78950,how do the students express their preferences ?
78955,"what does it mean , "" highly correlated with a poor r . square "" ?"
78953,1 . * what is the exact meaning of the t-value in the student t test ?
78995,what exactly is the question ?
79031,is this for a course ?
77934,"i don't remember whether they do a likelihood-ratio test , but i think a ( the ?"
79055,"what "" training "" is involved here ?"
79056,"ks test assumes continuous distributions . if you apply it to discrete distributions while ignoring that fact it's pretty conservative ; you need to simulate the null distribution . "" * i decided not to use it because it seems that it need at least a value of 5 in each cell of the array . * "" -- did you even read the [ first answer ] ( url ) of the question you pointed to ?"
79043,do you have an references for way ( 1 ) ?
78734,"i had similar questio as nickcox , when you say dataset do you mean a variable or unique identifiable row like customer / product etc ?"
79054,"what do you mean by "" the number of significant results had to be [ . . . ] significant "" ?"
78976,"it's definitely common to add features given by basis functions as you've described , as it allows the modeling of arbitrary nonlinearities in the input space - however , it's not obvious what sort of nonlinearities you're trying to capture ; if we know that , perhaps we can give you more insight . what was your reason for choosing the product of x and y ?"
596,unsupervised learning ?
79147,the interaction between a linear term and a quadratic term ?
79173,"think about the hypotheses behind the p values provided by "" summary "" . are such comparisons to baseline categories really of key interest to your research question ?"
79209,do you think you have enough data for a mixed-effects model ?
79208,"the number of bootstrap samples to use is not one that gives equal results ; that is necessarily elusive and in any case what does "" equal "" mean here ?"
79201,"who is "" they "" ?"
79244,"i notice that each of your groups has only 2 clusters . this is definitely not ideal , and is surely the reason why the confidence intervals around both of your icc estimates are extremely wide ( which i see from the answer of jamesstanley below ) , at least for this sample dataset you've provided . in your * * actual * * dataset , do you have only 2 clusters per group , or ( hopefully ) more clusters than this ?"
79254,"when you write $ u = f ( x ) $ , you define the noise as a function of the regressors , don't you think ?"
79374,why don't you try ?
79348,are you after a type ii error * rate * ?
79382,there are two main reasons you'd expect to reject the deviance test ( i ) the model has a lack of fit ; or ( ii ) the model fits okay but is overdispersed relative to the binomial . might the second main possibility be the case ?
79384,"several questions here , to the extent that this is likely to be declared a duplicate . i would start here url as the real question to many is not can you test for this , but is that a good idea ?"
79397,"the formula is the top of the question is a correct formula , for what it represents . while you corrected an error in copying the formula , you still have not applied it correctly to the question . you might want to think about the formula and the question and consider what you might have missed . ( where does this practice question come from ?"
79460,"is $ x $ a data point , variable , dimension , or . . . ?"
79478,does it make sense to look at each of the eight measurements separately ?
79420,do you need to use bins equally spaced in terms of log10 ( x ) ?
79410,doesn't this depend on how you determine accuracy ?
78591,"i wonder if by "" overhand shuffle "" , you mean what [ wikipedia calls ] ( url ) a "" riffle shuffle "" ?"
79465,"i wouldn't read too much into a curve fitting failure -- that happens fairly often . but how many actual "" 1 "" s do you have on is_win ?"
79578,"in what sense would those five observations be "" representative "" ?"
79351,"it seems that you are doing _multiple_ ( and not "" multivariate "" ) regression . also , that you have many time series . did you treat them as panel data , or you run estimation on each time series separately ?"
79631,"my comment has nothing to do with distributions nor with continuity of distributions nor with distributions at all . ( for instance , a random variable with an uncountable range need not be continuous . ) since you are aware of some of the mathematical implications , where is the difficulty with the interpretation ?"
79630,"what exactly do you mean by "" get rid of "" ?"
79646,"do you mean 'at least 10 % ' , 'at most 10 % ' or 'exactly 10 % ' ?"
79679,what quantitative theory relates increased demand to reduced value ?
79693,did you try drawing a venn diagram ?
79688,"what's "" ad "" stand for ?"
79905,related threads : [ why only three partitions ?
79927,i'm a bit confused . is stimulated = treated and unstimulated = untreated ?
79948,what do you mean by 'the predicted line' . . . what line is that ?
79950,did you record the time they were taken at ?
79951,"it might help to know more about the format of the data here . what is the criterion for assigning tags ( semantic information , word identification , word type counts . . . ) ?"
79902,do you want to test for dependence or just correlation ?
80009,"median age need not represent the biggest age group . in statistics "" changes significantly "" would be best established by a formal test ; changes that are big , striking or notable can be described informally using any simple word . that aside , the median can be unstable too in small samples . first , it must be a sample value or the average of two values . more importantly , you are rounding to seconds , so the median may easily jump by 0 . 5 s . in a larger dataset i would expect the mean for data like yours to be a bit larger than the median , but why not use both ?"
32400,"could you cite the article , or at least outline the methodology it proposes ?"
80035,"have you looked at their own software package , [ $ ell_1 $ -magic ] ( url ) ?"
80049,"should you not be providing the predictor variables to ` predictsurvprob ` as ` newdata ` , rather than ` vsr ` which is the outcome ?"
80048,"your question is still not clear to me but i'm under the impression that from one hand you are interested in the [ noncentral f-distribution ] ( url ) , but you have a strange notation ( $ -knf ^ 2 $ sounds like * "" minus "" $ knf ^ 2 $ * ) . see also the help of the f-distribution in r by typing ` ?"
80076,can you write down an expression for $ p ( a b ) $ ?
80091,"if your $ y $ is one-dimensional , then what would $ u ^ top y $ even mean ?"
80133,"if $ g ( t ) = sqrt { t } $ and $ x_n $ is a random variable taking on negative values with positive probability , what is meant by $ g ( x_n ) $ when $ x_n $ happens to have value less than $ 0 $ ?"
80078,what are those other variables in $ t $ which you are talking about ?
80145,about what errors do we talk here ?
80173,what is your model ?
80187,"if you've answered your own question , could you please post an answer here ?"
80177,"sure , why not . . . . ?"
80226,"such an approach can't work in general , though in many cases of practical interest it might yield a reasonable approximation . do they give any solid theoretical backing for this ?"
79919,""" platykurtic "" could mean many things for multivariate data . are you perhaps referring to just the * marginal * distributions ?"
79868,have you considered using the ipums instead of aggregated data ?
80271,how did you come up with $ alpha_1 $ and $ alpha_2 $ ?
80118,"keeping the data as they arrive minimises within-group differences at 0 . more generally , what exactly is your criterion ( please write down an equation ) ?"
80217,"in what respect should the "" couple of pcs "" be the best ?"
80279,"your question amounts to "" teach me to understand regression "" , which would take a book to answer . "" * . . . are the two variables highly correlated ?"
77538,"what kind of "" nonlinear correlation "" are you asking about ?"
77529,what form of nonlinear correlation are you asking about ?
80312,now i have no clue what you're even asking . what information do you want to show ?
80339,"site and sitesize look like they will be perfectly colinear - each site has one size , right ?"
80334,"to frame it in a non-statistical language : you want to specify $ n $ , $ n $ , and $ w $ and get all subsets $ s $ of $ { 1 , 2 , ldots n } $ such that there are exactly $ n $ elements in $ s $ and they sum to $ w $ . is that correct ?"
80365,"why shouldn't it be "" chose "" ?"
80360,how many observations ( rows ) do you have ?
80380,i don't understand the method of moments very well ; could it include weighted least squares estimation ?
80358,"i have a question at the previous step : how do we guarantee that the local maximum of $ l $ in $ s_n $ will obtain for a $ hat theta : hat theta in ( theta_0 -a , theta_0 a ) $ ?"
80444,"you can apply the same math that produces the 3-sigma rule . for a total range of 3 standard deviations , you're looking at the density within $ pm 1 . 5 sigma $ , which you can calculate to be about 0 . 87 ( url ) . so by the logic of the 3-sigma rule , 87 % of your data "" should "" lie in that range , and not 100 % of it . i didn't want to put this as an answer because it doesn't really answer the question . can you replicate the result with a different seed ?"
80467,"what do the residuals from the fit to the wider range look like when plotted against a , b and d ?"
80495,"i'm not sure why gaussian white noise would necessarily lead to negative values . for example , $ frac { dy } { dt } = alpha w_t y $ models a constant rate of growth with noise ( $ alpha $ is a positive constant , $ w_t $ is white noise ) . note that the noise is scaled by the value of $ y $ , preventing a negative growth rate when $ y = 0 $ and thus preventing negative concentrations . can you provide more details about your ode ?"
80342,"i didn't read your question attentively , so my comment may be a miss . but does your "" reparameterization "" adequately accounts for the fact that the dvs covariate ?"
80463,can you please check your links ( 404 error ) ?
80580,( 1 ) there was no for data analysis plan this study ?
80585,why do you suspect the survival probability has an $ e ^ { -t } $ functional form ?
80571,( 1 ) is wikipedia the source of your information ?
80626,the question is handsome but the drawing is indeed awful . the more sharp-kurtic-than-normal distribution is supposed to be heavier-tailed . but you didn't draw these tail regions ( which also should be coloured red ) . what their areas you suppose to add up to ?
80586,doesn't spss provide options to analyze cross-tab residuals ?
80710,"if you know this apriori , why don't you use an exogenous indicator variable for seasonality ?"
80648,hint : what is the solution when $ n = 1 $ ?
80783,"do you mean that you have observations of $ ( x_1 , x_2 , x_3 ) $ with possibly some of the values unobserved , or do you mean that you have three independent datasets of $ x_1 $ measurements , $ x_2 $ measurements , $ x_3 $ measurements ?"
80813,so you want to plot $ 1- hat s ( t ) $ instead of $ hat s ( t ) $ with c . i . but without censoring marks ?
80839,"'criteria' is plural . if there's only one , its a * criterion * . what form does your criterion take ?"
80898,what makes you think you * need * orthogonal regression ?
80887,"much depends on what you are trying to accomplish with this analysis : are you trying to make predictions about incomes of other families based on educational attainment and family size , or trying to make inferences about factors that are "" important "" in determining family income ?"
81032,""" _the noise e is modelled as a 0 mean gaussian with  as the precision_ "" . . . "" _the noise variance  also needs be inferred and is modelled using a gamma distribution_ "" . is $ phi $ the noise precision or variance ?"
81055,there is a mistake in the derivation of the distribution of $ y_1 $ . it should somewhat be related to the distribution of the $ x_i $ . can you find the error ?
81066,"just to make sure , is $ exp big { frac { theta ^ 2 } { sigma } big } $ correct ?"
81111,what boosting algorithm are you using ?
70070,what do your data look like ?
81091,"the phrase "" statistically prove the word is significant "" doesn't really mean anything . what null hypothesis do you wish to test , and against which alternative ?"
81153,it sounds like you're trying to optimize a weighting scheme to judge which region to prioritize targeting with corrective measures . you speak of risk and probability . . . of what ?
81158,another difference than that in holt's there are two parameters ?
81188,let's focus on the most fundamental issue : why have you chosen this formula for your index ?
81190,is your question about _significance testing_ or about _strength-of-association measure_ ?
81197,"welcome to our site ! to help us assist you , please try to be more specific about what information you need . to many readers , this description will be perfectly clear and requires no further explanation . what term ( s ) do you need help with ?"
81166,have you tried john fox's ` sem ` package ?
81246,where is your ` id ` variable ?
81239,( i ) which book ?
81275,have you checked the book by lecam and yang referenced in the paper ?
81285,"what do * you * mean by the "" smallest "" of two covariance matrices ?"
81343,do you have a value for the denominator ?
81387,"you are not seeking a "" distribution "" : the answer to this question is a set of samples of size $ 10 $ . if you would like a convenient way to * describe * such a set , why not re-express the data ?"
81386,"hmm . so is this empirical data , or simulated data ?"
81163,1 . does the graph show the aggregated / cumulative rate ?
81451,"i really cannot understand the description of the desired graphic . "" data points at the location ?"
81359,can you please call the tests out by name ?
81439,"jeremymiles : i do not fully agree . as long as the estimate is presented along with a confidence interval for the true or , then why hide the result ?"
81479,so . . . 22 binary independent variables and one continuous dependent variable ?
81396,"do you mean sparse as in "" lots of zeros "" or as in "" lots of missing values "" ?"
81497,"your last line makes the thrust of your question uncertain : because the t-test shows the * means * differ significantly , does that not put an end to the issue of whether the data could be drawn independently from a common distribution ?"
81519,are those generic keywords or are they specific to a certain domain ?
81526,"hi ndoogan , what is the structure of vector $ bf { p } $ ?"
81557,you parameter is never exactly zero ; why do you need to reject the obviously wrong ?
45374,are all of the items ( likert or yes / no ) intended to measure the same underlying construct ?
81601,"is there any problem rewriting your model in terms of $ alpha_0 = beta_0 ^ 2 $ and $ alpha_1 = beta_0 beta_1 $ , which * is * linear ?"
81613,how different are the variances ?
81622,you could study mean changes from pre to post or you could study % agree or strongly agree changes from pre to post for each question . is that what you want ?
81632,"for a start , what exactly is ` fourier1 ( 1 : length ( x ) , 4 , 1440 ) ` outputting ?"
81662,why does $ t $ have two subscripts ?
81680,"you should definately be learning the "" weights "" of the biases . i use quotes around weights as it is normally easier ( and quicker ) to use a bias vector than append a 1 to every input . that being said i find your question very confusing . i'm not sure why you would be stacking random vectors onto anything . are you talking about initialization ?"
81626,"what is "" the same area "" ?"
81727,how do the clusters compare to your reference labels ?
81737,"it might depend on what you mean by "" stronger "" . at least two senses are natural in this context--statistical significance and size of effect . the latter is usually more meaningful , because the former is largely an artifact of sample size and data variation . but how , then , are you measuring effect size when there is an * interaction * ?"
28509,are you sure that it works even for 2 classes ?
81657,"could you clarify--preferably in a quantitative way--how "" repulsion "" is supposed to work ?"
81578,"some more information would be appreciated if it's available ; how is f distributed , or do you have an expression for it ?"
81747,please clarify : in what sense $ z $ s are independent of $ x $ 's ?
81762,"at the end of c ) , shouldn't you square the derivative of $ g $ ?"
65705,welcome . can you print the two matrices of the distance in your question ?
81807,what did you want the pca to do ?
81819,"since the $ x_i $ are $ n $ -vectors , what do you mean by _the_ pearson correlation coefficient between $ x_i $ and $ x_j $ ?"
81721,"because your illustration involves multiple kinds of observations ( "" instances "" and "" aggregates "" as well as min , max , and "" avg "" ) , it is unclear what your data really look like . could you edit your question to provide a specific ( short ) example of your data ?"
81849,it doesn't make a lot of sense to me that sphericity is ok but homogeneity of variance is violated . can you elaborate on why you think so ?
81932,are those employment numbers based on a census or a weighted survey file ( ie a sample ) ?
81938,"this sounds more like a repeated measures model than a "" weighted "" model . have you consider using this instead of weights ( lmer package ) ?"
81291,why not ?
81951,"what is "" ritc "" ?"
81956,what are your results ?
78897,"one approach : what is the probability of being in an element $ ( u , u du ) times ( v , v dv ) $ before the restriction to the circle ?"
82079,please tell us more - what are your ivs ?
82095,"ttnphns , i think that's the correct answer , why not make it official ?"
82102,did you look at the order of the levels and verify they are the same ?
82139,why are you using a random forest instead of a logistic regression ?
82155,do you have the raw data ( not the means ) ?
82115,what is the meaning of $ u $ and $ i ( u ) $ ?
82228,i don't think your understanding regarding the estimates is correct . have you changed the contrast settings or are you using r's default ?
82292,"it is useful because , for example , it yields a shorter confidence interval about $ mu $ as compared to the frequentist approach ( or the noninformative bayesian approach ) . is it such usefulness you are interested in or do you expect something else ?"
82260,"i am curious where you read that anybody assumes the last thing that you stated ( $ o_i-e_i sim mathcal { n } ( 0 , sqrt { e_i } ) $ ) . that is not necessary : the $ chi ^ 2 $ statistic can have a $ chi ^ 2 $ distribution ( at least to an extremely good approximation ) without any of these standardized residuals having a normal distribution . the question you seem to want to ask is * how do these assumptions justify referring the $ chi ^ 2 $ statistic to a $ chi ^ 2 $ distribution ?"
82307,do the models indicated by the respective ` lambda . min ` for the different runs / seeds match - have similar included variables or coefs ?
82320,do you mean that the response to the question must lie between $ 0 $ and $ 1 $ ?
82328,why do you think anova wouldn't be suitable ?
82339,a hint : what happens to $ w $ in your last formula ?
82341,how about a ` qqplot ` to compare with a standard normal dist ?
82345,why did you categorize a continuous variable ?
82346,"yes . it's not only possible , but indeed highly likely . this is an utterly standard feature of significance tests . the main function of significance tests is , arguably , to avoid being fooled by chance-like fluctuations in small samples , but that is not your risk here . it is best to focus on confidence intervals for your parameters . ( edit : you already have this kind of comment and links to relevant questions , so why is this being asked again ?"
82382,"i do not see how correlations of the $ h ^ i $ would matter for your problem , but what can you tell us about correlation among the * noise * vectors $ n_i $ ?"
81993,"just a quick clarifying question - which "" angle "" are you coming at sufficiency from ?"
82312,"it's a good question . but let me ask you this , to provoke some reflection on the issue : if you are unwilling to estimate a sample size using a normal approximation , what method do you propose to use instead for estimating the sample size ?"
82447,"are these curves , or are you showing estimated density functions from data ?"
82462,why not to google ?
82495,"when $ x 0 $ they will have the usual bivariate normal density with an arbitrary correlation coefficient . when $ x le0 $ , are they still dependent ?"
82489,what kind of dlm do you want ?
82526,"could you tell us what you mean by a "" likelihood function of [ a ] distribution "" ?"
82527,"do want to ( a ) estimate a probability distribution for the set of matrices , ( b ) estimate a probability distribution for the individuals giving rise to any individual matrix , or ( c ) something else ?"
82536,"just realised something , are you sure all coeffs have a positive sign ?"
82554,"is this "" shaking "" an example of your actual application ( or at least a good physical model of it ) ?"
82582,what are you trying to find out ?
82594,more detail is needed before this question can be answered . what is your sample size ?
82598,is it possible to get ahold of your data somewhere so i can try it out ?
82667,could you tell us what exactly you are optimizing ?
82678,your second dimension ( x2 ) is exactly the same as x1 . why should that give more information and therefore a better model ?
82680,"what on earth does the question have to do with _normal_ distributions as you start off in your very first sentence , and why are you calculating z-scores at all ?"
82654,"what is a "" calibration interval "" in this context ?"
82698,maybe post the code ?
82701,"in both cases these are testing the hypothesis that the population from which the data are drawn has a normal distribution against non-normal alternatives ( more strictly for the j-b , against alternatives with skewness and kurtosis different from that of the normal ; it has low power against alternatives with similar skewness and kurtosis ) . what was the sample size ?"
82710,"mcnemar test is only for square frequency tables with rows / columns defined by the two variables with the same categories . classic mcnemar is for 2x2 table ; its extension mcnemar-bowker is for kxk table . your table is not appropriate for mcnemar . what is your hypothesis , what do you want to test ?"
82811,"yes , and they do ! let $ t = x $ . what is the * conditional * distribution of $ x $ given $ t $ ?"
82829,"this may be hard to answer at present . can you provide more details of your study , your data & your goals ?"
82835,which command takes hours ?
82840,could you please clarify what you are asking ?
82842,do you have the raw data that went into the averages ?
82857,"in what sense do you want to "" break this down into a probability or percentage "" ?"
82888,which estimates ?
82634,are your classes well balanced ?
82920,"well , let's try this : how would you characterize the times $ t1 $ and $ t2 $ that your algorithm finds ?"
82670,"i'm confused : $ n $ is a random variable , not a population parameter you might want to estimate . do you want to find its expected value ( the average ) ?"
82950,you want ` fish_class ` and ` reach ` to be nested with ` basin ` ?
83012,""" the p values "" means what ?"
83056,with only one test point you are bound to get extreme results ( $ 100 % $ or $ 0 % $ accuracy ) . do you see the same with a reasonable test set ?
83026,"i'm not an expert in this area , but is your matrix missing a value in the bottom left corner ?"
83064,are you sure that mcnemar's test is significant ?
83093,"i think we'd need to know a bit more about your application : what exactly does "" generate 3200 versions of the original data mean and why do you want to compare them ?"
83127,do you expect the measures to be correlated within an individual ?
83153,optimal in what sense ?
83161,"but , the number of possible orderings in a sequence of length $ n $ is $ n ! $ . of course , if you normalize by that , you get a correlation of - . 86 between order and order / ( length ! ) . what does order actually measure ?"
83186,"he doesn't have 4 data points , he has 12 . and the question has answers at the link . so , what is new about your question ?"
83049,hint : precisely * which * normal inverse cdf is evaluated by ` qnorm ` ?
83243,"because your anova makes no distinction between treatment and controls , it does not appear to address the scientific question on the table . because temperatures have a natural order , and that order can be expected on general principles to influence growth , what exactly are the temperatures involved here ( including that of the control ) ?"
83136,"quasi-related : [ when , if ever , will facebook contain more profiles of dead people than of living ones ?"
83225,why ?
83260,"your $ n $ is a third of a billion observations and you have 40k events . it's not remotely surprising your p-values are all zero , even though the model doesn't explain a lot of the variation ( & how is $ r ^ 2 $ defined here ?"
83270,"there is something strange about these formulations of your problem , because clearly they are not equivalent . for instance , about half the $ z_ { ( j ) } $ will be * negative * and in that range the ratios of order statistics will be less than unity , so the second formulation effectively ignores the first half of the gaps on average ! are you perhaps assuming in the second formulation that the $ z_j $ are * lognormal * ?"
83343,is experience equivalent to time here ?
83374,what is $ beta $ ?
83373,i'm guessing this is some kind of self-study ( you should tag it as such ) . what exactly is it you want ?
83418,"you lost me at "" standardize across sets . "" i get that you have two sets of data in the range $ ( 0 , 1 ] $ and presumably they are samples of two populations or processes , but how do you wish to compare them ?"
83337,"why not work with something like standard deviation , or since the mean is known to be zero , the root mean square , or just the mean absolute value ?"
83465,the answers will depend on the distribution of the y's . can you define what you mean by 'predictive power' ?
83477,"you should probably add the excel-tag , as it seems important to you . have you tried the add-on in excel called "" data analysis "" ?"
83469,"i think that i understand your data . you have three datasets . the first has two columns and five rows : college name and # advanced degrees awarded . there is one row for each college . the second summarizes data from your sample of students , allowing you to ask questions of the form "" how many degrees ( not just advanced degrees ) did student $ x $ earn from college $ y $ ?"
83498,"the expression "" * resists normalization if i try to standardize it * "" is rather curious . does it mean "" i tried , but couldn't manage to transform it to normality "" ?"
83507,"it is unusual , although certainly not impossible , for errors to be given as two distinct values . please explain in your question more precisely what those error values mean . how were they obtained ?"
83522,what made you choose to do boosting ?
83506,how far can you get with the suggestion i initially gave ?
83546,try taking something simple . perhaps start with a collection of bernoulli random variables with $ p = 0 . 9 $ . imagine you observe $ k $ 1's ( and $ n-k $ 0's ) ; what does the lhs work out to be ?
83574,"i think you've answered your own question baz . if we could do what you suggest , then why would we run the regression at all ?"
83611,can you expand on the statement that you were not able to incorporate the recommendation of including ` ( 1 subject_id ) ` ?
83157,"i have a fairly extensive answer concerning using simulations for power analyses in [ this thread ] ( url ) & gregsnow's answer there provides a more practical complement . there are a couple of other relevant cv threads that are linked in my answer . the key question is , can you write down the model you think holds in the real world ( ie the alternative hypothesis ) w / the requisite random intercept variances & covariances ?"
83554,could you draw what line you think you should get and why you think your line has smaller mse ?
83505,"could you clarify what "" maintaining the solar variability means "" ?"
83649,"for a general relationship between alpha and beta , did you take a look at url ?"
83687,are you going to office hours ?
83646,"the upvote means you asked a good question and asked it well . as far as answers go , i am confident you will see some good ones soon . in the meantime , it often is helpful to return to the definitions ( and you might even want to state your definitions in the question , because not everybody will have the same understanding of your symbols ) . what precisely does $ alpha $ mean ?"
83608,"i find the first part a bit unclear . are you saying that estimating the equation you stated in first differences and using the fixed effects estimator gives the same result , and now you wonder why that is ?"
82973,what hypothesis are you testing there ?
83750,* definitizing * ?
83756,how did you test whther your data is normally distributed ?
83746,"keeping in mind that seeing that your data looks "" somewhat logarithmic "" isn't particularly scientific , what do you mean by 'most scientifically correct' , exactly ?"
83773,would url be of any help ?
83779,gung i'm not so sure about that : couldn't this question alternatively be interpreted as asking whether the model expressed in the ` aov ` command is appropriate for the given data and stated objectives ?
83821,"what question are you find out from the data , exactly ?"
83860,i don't think there's much ( any ?
83576,what are x and y ?
83961,the question boils down to where do the p's come from . do they involve looking at the total observed count ?
84079,"i think the question needs some context to be answerable . as glen says , confidence intervals around a parameter estimate are often more useful than a test that the parameter's true value is exactly zero , but what kind of situations are you thinking of ?"
84034,have you considered any type of path analysis or structural equation modeling ?
84112,"cohen seems to have defined $ d $ not in terms of pooled standard deviation , but $ sigma $ . for example , see the table on p157 [ here ] ( url ) . given that you're using a definition that doesn't seem to be cohen's ( though doubtless based on it ) , can you point to ( or include ) exactly what the definition is ?"
84103,have you explored properly treating time as a continuous rather than categorical variable ?
84133,"out of curiosity , how do you model arma errors with nn or svm ?"
84205,two very similarly phrased questions in a very short period of time ; the other is [ here ] ( url ) . is this the same person twice ?
84209,"there are no responses from those who did not respond , so your question , as worded , makes no sense . do you mean "" is the proportion of people who answered = to that that did not answer ?"
84207,"i like your idea , it sounds interesting . i don't think i have ever seen anything like that , this is definitely not a standard approach . can you maybe show one of your figures , for the benefit of the community ?"
84235,where do these come from ?
84310,"can you post a small piece of your data or a reproducible example , that we can understand the structure of your data ?"
84315,"if you can type in the formula in jmp you don't have to create the model matrix yourself . in r to get the full interaction formula you would type : y ~ ( a b c ) ^ 2 ( which would also give you the 3-way interaction ) or y ~ a b c a : b for just the a : b interaction . you cannot just model a1 : b1 and a1 : b2 that would be a different factor ( d = 1 if a1 , 0 if not a1 ) . would you consider moving to r ?"
84319,"i know this doesn't answer your question , but robust standard errors ( huber-white or otherwise , check out the ` sandwich ` package for those ) won't do ?"
84342,what on earth does the word 'accurate' mean in this case ?
84323,"some more details would be nice , e . g . : what question are you trying to answer ?"
85374,if you simulate such short processes as $ n = 10 $ you will generally not get a stationary process . especially not if your ar ( 1 ) parameter is so large as it will take a few iterations for the process to forget it's previous states . why do you need to simulate such a short process ?
60839,"do you have the quality values per class at least , or do you only have a global measure only ?"
85402,would you know what is the minimum & maximum lengths of strings such as ` o o o x x o x ` you would encounter in your data ?
85438,how would it be possible for a truncated distribution to be conditionally normal at every $ x $ ?
84249,"when you say you fit a 'binary logistic curve' , what's the actual model ?"
85491,"could you clarify whether you're re-defining the predictors in a given data-set based on the observed relationship to the response of an original set of predictors , or just asking whether the model makes a priori sense ?"
85498,he did ?
85545,are a subset of the results going to be verified using pcr or some other method ?
83789,"the meaning of "" significant "" is usually not in question because a probability model and null hypothesis are implied by the context . not so here . the replication reveals effects of * measurement error * on the pca results . however , if you view your $ n $ points as being a single realization of some process , then "" significant "" might mean with respect to a null hypothesis like "" all components are equal . "" ( this issue is rarely discussed for pca because it's usually used as an * exploratory * rather than a confirmatory analysis . ) so : * what is your probability model and what hypothesis are you testing ?"
85563,what is the reason for the offset ( ) ?
85588,"is what you're applying the transform to on [ -1 , 1 ] or [ 0 , 1 ] . . . and why are you doing that ?"
84349,what parameters do you want to calculate the 2nd derivative with respect to ?
85638,jase $ mu ( x ) $ ?
85669,"may be of some use for you to incorporate the idea of "" conditional "" ?"
85693,"would you mind explaining what you mean by a "" construct "" and what it is intended to be used for ?"
85687,are you familiar with the [ probability integral transform ] ( url ) ?
85585,"for your small subsets , how many points are found in the time windows ?"
85723,"that's an application that i'm also looking into . if you could point me in the direction of any actual literature that supports testing for co-integration using log ratios i would greatly appreciate it . from everything i've read ( very reputable sources ) , the correct method is either engle-granger which uses log prices to find residuals then adf on those , or else johansen which is completely different . did you compare your co-integration selection against using engle-granger ?"
85744,is this homework or an example from a book ?
84277,what is $ sigma $ ?
85775,how many time steps are there in your data ?
85818,"when you work with counts , what population quantity are you calculating a standard deviation / interval for ?"
85830,it's difficult to know for sure what word to suggest without you explaining what it is you're referring to . are you talking about the money insurers pay to insured parties in the event of a successful claim ?
85844,what is the frequency of the classes and what cut-off do you use ?
85862,are you assuming distribution of $ epsilon_t $ identical ?
85896,which framework are you working within ( also what tools are you using ?
85945,"i'm unclear exactly what you did . was it : model 1 logit ( y ) ~ block 1 , model2 : logit ( y ) ~ block 1 block 2 ?"
85986,"do you know what leverage measures , in an intuitive sense ?"
81694,5 ) is this homework ?
86083,i'd reconsider your title . is having one variable with a high number of categories central to your question ?
86032,what does centering your x's first do to the correlation you're noticing ?
86129,can you flesh out the two opposing models ?
43529,"how , * exactly , * are the samples obtained and measured ?"
86123,what would be wrong with the regression of t on the series in s ?
86142,"what would be the problem with first finding the means exactly as you do now , and then fitting your constant / cubic function to the resulting curve ?"
85582,"confidence intervals are for frequentist and credible intervals for bayesian approach . "" why haven't i seen any publications which use it ?"
86181,are your variables really 0-1 _dummy_ or simply 0-1 _binary_ ?
85863,"i don't understand the effect sizes for the difference in gender between light and dark hair . gender is dichotomous , so what are those effect sizes supposed to represent ?"
86248,"you could simplify the model by excluding seasonal dummies , auto arima automatically fits seasonal models , unless you want to determine the effect of each month . are you open to other models ?"
86250,"you seem to equate "" the mean of this new matrix "" with "" the mean of the new gaussian , "" but they have nothing to do with each other . what do you really need to accomplish ?"
82473,what is the point of fitting a t distribution to data governed by a normal distribution ?
86224,cafe876 . i do not see how the bayesian nature of the modeling is specific to your point . is your question really specific to bayesian hierarchical model ?
86316,i am unclear what you mean by hypothesis ?
86235,"how would a * test * "" determine parameters "" ?"
86343,"to extent peterflom's point , you've presented the unconditional sample distribution of the response but for glms ( and regression models ) , the distributional assumption is conditional ( that is , at a given combination of the independent variables , the distribution hold ) . depending on the arrangement of the various x-variables , the marginal response might look quite different from the conditional one . [ also , why do you say the shape 'is likely to follow a poisson distribution' ?"
86351,"since your question is very broad -- "" how does one interpret a binomial regression ?"
85719,why do you think a linear regression is suitable to capture the relation between date and time ?
86380,"can you clarify what you are asking when you say "" seems like it shouldn't matter "" . what shouldn't matter ?"
83803,"why not logistic regression with flew / didn't fly as the response , & distance to nearest ship as the predictor ?"
86402,( 1 ) is this for some kind of study ?
86388,is $ f_ { z_i } $ the same as $ phi ( z_i ) $ ?
86323,"to supply a good answer we need a reasonable model of these data and , if it's to be more than a pure guess , that requires some understanding of the data . how are the "" necessary "" days in the hospital determined ?"
86348,"worth noting ( 1 ) that on the right pane you have ( low ) ( moderate ) dummy variable and not ( low ) ( high ) dummy variables . ( 2 ) my understanding is that jmp uses fairly odd coding strategy for dummy variables . looks like it has done "" reverse helmert "" coding ?"
86454,how much time it takes to build model one time ?
86456,"nickcox : yes , but i am not sure i understand your point . from how i understood the question , the scores * were * measured . or do you mean that in fact some continuous variables were measured and then rounded ?"
86480,"a priori , i don't see any reason to suspect an upper bound even exists . note that you haven't actually specified any concrete situation , you have a completely unspecified function of 5 unspecified variables . are your x variables bounded at all ?"
86355,can you modify your title / question accordingly ?
86499,this question appears to lack essential information . ( 1 ) what is the relationship between $ u_t $ and $ y_t $ ?
69972,"to clarify - in effect , you're testing for a difference in the spread of the two numbers between two groups ?"
86533,"the $ pi ( x ) $ you quote is neither a legitimate density function ( doesn't integrate to 1 ) , nor a legitimate distribution function ( since it exceeds 1 for part of the range of $ x $ ) . it would be easier to recommend something if that wasn't the case . incidentally , densities of the form $ ax ^ b $ ( with $ a $ such that they * do * integrate to 1 ) are very easy to sample from . is this for some subject ?"
86530,"i can't follow your question . what "" number of successes "" are you referring to ?"
86460,what would the standard deviation of the fluence be ?
86472,is this figure correct ?
86576,do you mean : you're throwing a die and flipping a coin . you then look at the sum of 'one's 'head's ?
86592,are you just using ols with a bunch of firm dummies for the first one and ols on the differenced data for the second ?
86508,"the file you point to gives a strong and significant result ( $ hat rho = -0 . 763 , p = . 00023 $ ) , which is contrary to your statement . which data do you consider to be the "" outliers "" and how did you select them ?"
86611,"if $ text { var } ( x_n ) to infty $ , what would $ omega $ be ?"
86637,why do you need a * correlation * ?
86641,regarding your question : are your independent variables correlated between each other ?
86580,could you please check the source of * definition one * ?
86691,""" optimal "" in what sense ?"
86621,can you say what you are going to use the model for ?
86733,"precisely how does $ f $ "" give "" a probability ?"
86718,those are hard questions to answer because there is not one fixed way to do it . what program are you using ?
86823,""" the expectation "" is not a statistic at all : $ bar x $ is a sample mean , not an expectation . do you know the definition of a sufficient statistic , and any ways to check for sufficiency ?"
86818,"i'm not sure i follow your comment about getting flat lines at 0 & 1 when you ran it in r . can you add the figure to your question , or include your code ?"
86866,"maybe it's me , but i don't understand what you mean by "" smooth values on a graph "" . which values do you want to smooth ?"
86908,did you choose a particular method in the cch function or did you leave as the default ` prentice ` ?
86914,how were the transects chosen ?
86940,* what quantity * using * what statistical procedure * are you talking about here ?
86947,""" the accuracy of classification is getting worse "" do you mean the training or testing accuracy ?"
86963,"this seems an odd thing to be doing . can you forget the code and more clearly explain what you're trying to do , in specific terms , and why you're trying to do it ?"
86972,"it's unclear what you mean by "" respect some boundaries . "" after all , the variable $ ( w_1 w_2 ) / 2 $ will lie between $ -1 $ and $ 1 $ ( and has a possibility of attaining either endpoint ) , but surely you thought of this obvious solution , so what are you really looking for ?"
86974,"is your standard deviation meant to be the standard deviation of the average , or the sum ?"
87021,what do you want to test ?
87028,"i also think this question contains more of a statistical matter than the usual "" how to do x with r "" as it seems the op needs some stats advice as well . user40494 would you care to expand on your question a bit ?"
82128,what is you prior for the level of the contamination ?
85815,couple questions : do you know the size of each subpopulation ?
83826,put the weights inside lm ( ) and take the r-squared from there ( why re-invent the wheel ?
87105,isn't there some model output available from r that would give you the significances of each variable ?
86830,be careful of the word 'normalize' . it generally doesn't mean 'transform to approximate normality' which is what i think you mean here . why would you attempt to do this to a dependent variable in regression ?
87107,what does $ m ( n ) $ represent here ?
87135,"while the question is legit when asked in a specific situation , it is to complex to be answered in general . what you are essentially looking for is a cookbook or a cheatsheet . in this regard , see this questions : [ machine learning cookbook / reference card / cheatsheet ?"
87113,"not sure i see how the distribution of $ p $ depends on $ n $ . as i read it , $ n $ is just the number of times you observe $ p ( x , y ) $ , but a rv doesn't change its distribution just because you sample it . am i missing something ?"
87157,"your orthography suggests you prefer to use "" . "" as a decimal separator instead of "" , "" . in your locale is it possible that the "" 0 . 75 "" argument is being parsed as "" 0 "" and "" 75 "" , with the latter ignored ?"
87166,how did you come up with -0 . 00037 for the covariance ?
87189,what are $ w $ and $ z $ here ?
87077,"1 . a polynomial model is a linear model , because it is linear in the coefficient . 2 . i am trying to understand your question . if the refrigeration system has been modified between the time r1 and r2 were used , then they are really not the 'same refrigeration system' ( line 1 ) , right ?"
87214,"the formula for iid errors is given at url although your question refers to the "" general "" linear model , the estimator you offer is * not * the one given by the glm--it is the ols estimator which is appropriate only for constant diagonal $ sigma_r $ . this calls into question what you are really looking for . could you make this a little clearer ?"
87223,"this expression for $ f $ does not denote a distribution . if it is intended to be a density for one , then it needs two more things to be sufficiently clear : first , it needs a constant of integration . more importantly , it needs a * domain * for $ t $ . are you perhaps trying to say that $ f ( t ) $ must be zero for $ t $ smaller than $ theta $ ?"
87241,"i suspect this question is not answerable in the non-parametric setting you state . are you willing to assume , say , that the variates are all normal ( but with unknown means and known variances ) ?"
87278,one approach for dealing with multicollinearity issues is to use a ridge regression or lasso available in the glmnet r package . considering that you're looking at multiple dependent variables that are correlated with each other suggests using structural equation modeling ( sem package in r ) . have you identified which variables ought to be influencing other variables according to principles of plant biology ?
87326,"( 1 ) "" lagged "" in what sense ?"
87341,did he make an argument to support this contention ?
87352,where did you come up with the squaring idea ?
87359,where did you get the idea to model the multivariate responses this way ?
87242,what did you try ?
87376,"a data set is a data set , you don't maximize the data set itself . am i right in thinking you have a set of z values , one for each combination of ( x , y ) which are given on a grid , and you wish to find the ( x , y ) pair where z is greatest ?"
87354,is this work for some subject ?
87416,what are * * y1 * * and * * y2 * * then ?
87445,can you be more specific regarding what you need help interpreting ?
87502,is this a sequence of independent readings or is it chronological / longitudinal ?
87541,"luca said : "" for example for a univariate gaussian when we actually observe that the variable takes on a certain value , shouldn't the conditional distribution be a point mass with zero variance ?"
87560,"regarding using bootstrap when the estimation method is dwls , have you tried it to see if it works ?"
87577,was it supposed to have been a trick question ?
87594,"you don't need a sample size ( in any case , what could you do with it ?"
87608,"perhaps read [ this ] ( url ) to give yourself some perspective . if you think there's a way of examining * every * potential model to find the "" best "" one , you're chasing a will-o'-the-wisp . why only look at linear relations & interactions ?"
87590,"questions about 'how to do this in r' are off-topic for cv ( see our [ help center ] ( url ) ) , but can be on-topic on [ stack overflow ] ( url ) . however , this question would need to be closed on so as well , because ( 1 ) it is not clear what you are asking about , & ( 2 ) there is no [ reproducible example ] ( url ) . can you edit this to clarify what help you need w / your code , & add some example data that reproduces your problem ?"
87651,i'm confused by the title . which values do you think are 'too good' ?
87711,have you tried looking at departmental websites for clinical psychology programs to see if they offer any summer short courses on psychometrics / scale development / factor analysis ?
87712,is this what you're asking ?
87721,"hi ahdee , please could you describe in greater detail which question you want to answer from your data , what your hypotheses are , what "" is about 50 % percent in each group "" , what are the bins , how were the data collected ?"
87744,"sds of 14 & 11 are not that much different to likely cause large problems . skew is typically a bigger deal , but 10 may not be too big given that even your 'smaller' group is very large . are the skews in the same direction ?"
87750,can you post a link to where these notes are coming from ?
87616,what does $ geom0 $ mean ?
87782,how many times do you measure the variable over the 60 second period ?
87800,""" * why does one report statistical power only when results are non significant ?"
87845,hi ellen and welcome to the site . what regression did you perform ?
87856,what do you want suggestions about ?
87886,perhaps you can tell us _where_ you found the statement about the sample mean and variance being independent in symmetric distributions ?
87885,can you explain what the ` std coefficient ` is ?
87920,"so , why is model comparison not sufficient to answer this ?"
87814,what is $ y $ ?
87910,what are coop ?
87981,sure . you refer to maximum and minimum . can i infer that your dataset is univariate ?
87988,"the wikipedia article on [ stochastic processes ] ( url ) provides a clear , succinct , non-mathematical answer on the first line and right next to it is a picture of data that are typically thought of as resulting from a process . have you investigated these materials ?"
87994,could you tell us what you intend to use this standard deviation for ?
87846,setting a diagonal element to infinity makes no sense : perhaps you meant zero ?
88012,"in your first example , if the dataset contains only one class , then what is the classifier supposed to classify ?"
88019,is there an ordering between 2 and 3 ?
88021,have you thought about an roc curve ?
88038,"maybe i'm misunderstanding your issue , but what about fitting a mixture model to your data , and comparing the "" non-zero part "" to the distribution of the non-bounded protein ?"
88066,""" rearranging "" $ hat mu $ does not seem relevant : you need to compute $ v ( hat mu ) $ ( not $ v ( mu ) $ , which is zero ) and $ i_1 ( mu ) $ in order to test the inequality . how far do you get when you do this ?"
85448,"your question is unclear , because you shift from asking if they are "" supposed to be symmetrical "" in the 1st sentence , to implying that they are not in sentence 2 & asking ( presumably ) why they aren't in sentence 3 . can you make this more consistent / clear ?"
88095,thanks . # 2 has higher median but lower iqr . which is pertinent here . possible that matters will seem clearer or simpler on square root or log scale . much depends on whether exact zeros are possible . are these counts or measurements ?
88083,"( 1 ) did you have the variables "" the wrong way around "" ?"
88082,"by "" a graph showing the weight of each value "" do you mean a histogram of each of the values 0-255 ?"
87615,i think some restrictions must be required before that could be so . what is the source for the statement ?
88183,misclassification probability of 0 . 00 means that you get 100 % classification accuracy on each of the 10 cross-validation folds ?
88185,is there anything wrong with just giving ` mice ` only the rows that you want imputed when you make the call to the function ?
88204,the solution depends on your assumptions about how zombies interact with people : the interpretation of the 30 % daily chance hinges on that . could you elaborate on how you would like that value of 30 % to be interpreted ?
88212,"( 1 ) if you're using this test set to pick the best performing model selection procedure for your data , you need another set of hold-out data to validate the procedure in which you pick the best performing model selection procedure . ( 2 ) this isn't cross-validation ( see leave-one-out or $ k $ -fold ) . ( 3 ) you say the mean-square errors differ "" only "" by 0 . 001 , as if we should be nodding in agreement that it's a tiny difference - are you remembering that it has units ?"
88165,are your datasets paired observations ?
88171,"confidence intervals , by definition , apply to * parameters * . "" r ( n ) "" ( whatever it might mean ) does not appear to be a parameter . are you perhaps asking for confidence intervals for $ sigma $ ( which appears to be the only parameter in the question ) ?"
88252,"it's a side-issue , but don't you need to move away from glm defaults to deal with non-normal data and non-constant variance ?"
88188,can you maybe link to such a paper for context ?
88186,"please explain what "" $ 25 times 2000 $ "" means : are these 25 subjects for which you have 2000 attributes or 2000 subjects with 25 attributes ?"
88153,"when i pointed out your criteria were subjective ( we can't tell you what is best for you unless we have some idea what you want to get ) , your response was to just use * different * subjective terms : "" * most likely to be useful * "" ( for what purpose ?"
88244,"is it that universities are intelligence factories , so scotland makes more per capita ; or that scotland needs plenty of good universities to use up all the smart people it has ?"
88297,are you saying the red curves are the variable-width gaussians and the green curve is their sum ?
87952,i gather this question is about interpreting spss output . can you post an image of the output at issue ?
88313,could this be a mixture of two distributions ?
88315,"did you not perform the cochran-mantel-haenszel test precisely because the evidence for an odds ratio different from one might be weak for each stratum considered individually , but strong for all considered together ?"
88361,how many predictors are you using ?
88426,welcome to cv . can you clarify your question ?
88447,"the correlations are significant , but are the differences between these correlations different ?"
88481,what $ 60 $ stands for ?
88482,why not doing it on the logit model directly ?
88508,this looks like routine bookwork . is this for some subject ?
88510,what do you mean by confidence interval for a joint distribution ?
88516,"i don't understand , from the description , your dataset . can you post a small sample of it ?"
88531,do you know the value of $ rho $ or not ?
88545,ladislav - was undoing my extensive corrections of the english and explanation of abbrevations and jargon deliberate or the side effect of a long edit ?
88568,"this seems the wrong way to go . as the same correlation could reflect different linear relations , and vice versa , you would be moving yet further from the data , and correlations really don't seem a natural measure to average . what is the scientific question underlying all this ?"
88628,i'm pretty sure whuber means exactly what was typed there . when you say 'nominator' do you mean 'numerator' ?
88676,do you know the form of $ f ( x ) $ ?
88323,what you do depends on the objectives of your data analysis . could you please describe those in your question ?
87481,what are you trying to accomplish by scoring your models this way ?
88722,"it looks like some of the t statistics are favorable ( ma1 , sar1 , v1 ) . also , could you add to the post some information on how autocorrelated the residuals are , such as the durbin-watson statistic ?"
88707,the lack of definition of variable in your question causes confusion . do you mean value ?
88774,do you expect that the samples all come from the same mean ( and that there is just noise in estimating each ) or do you expect the samples to have different means ?
88783,do you know which dots belong to which population ?
88850,"this looks like a homework question , and as such should bear the tag ` self-study ` . if that's the case , could you please add the tag ?"
88817,which cochran test are we talking about ?
88857,"i'm not sure what an "" adequation test "" is . it's not a term i've heard before , and a google search almost solely returns results written in french . is it the same as a peason's chi-squared test ?"
88900,is this ` ` block maxima'' ( e . g . annual maxima ) data ?
88899,"q2 . if you want only to partition ( somehow ) data , why use clustering at all ?"
88922,is it infeasible to transform your problem to use dummies standing for each possible combination of seven workers ?
89005,can you ( briefly ) explain what that code's doing ?
89018,"frank harrell when you say loadings , do you mean scores ?"
89044,are they interchangeable ?
81757,is this a homework problem ?
89089,"i'm not sure whether the two models are equivalent . can you be a little bit more specific about what you mean by "" two crossed factors that also allow heteroscedasticity "" ( e . g . write out explicit mathematical formulas for the statistical model you have in mind ) ?"
89104,what is that thing ?
89114,isn't there a statistical question lurking here about the appropriate way to code categorical variables for making [ some kind of as-yet unexplained ] comparisons ?
89127,the data already give you the peak hours . what exactly are you looking for that you don't already have ?
88633,"i am guessing that there were 30 aphids on a card , so the spike at the right represents "" $ ge 30 $ aphids would have been eaten but only 30 were available "" rather than "" 30 "" . is this right ?"
89186,are you familiar with the beta distribution ?
89225,you already * have * determined the distribution of the * data * : it is shown in your plot . what do you want to do with that distribution ?
89226,"are you asking for the name of the statistical test for this , or just a name for the descriptive data manipulation process you've described ?"
89086,"could you be a bit clearer about the "" explicit knowledge "" that imputation would ignore ?"
89246,"* many * probability distributions have power series expressions like this one . that does not mean they--or bessel functions--take much time at all to compute accurately . however , you have much more fundamental problems than that . first , $ n $ must be an even integer so that its values will be nonnegative . worse , the integral of $ i_n $ diverges and so cannot be rescaled to form a proper pdf . could you perhaps edit your question to explain why you think you have data described by a bessel function ?"
89305,perhaps i missed something . what analysis were you running ?
89158,maybe use a heat map ?
87975,"you question mixes up two things . i think you haven't digested our conversation over your [ previous ] ( url ) question . what you describe first is bayesian approach to classification ( not "" bayesian approach to lda "" ) . this approach can be used ( 1 ) with original variables as classifyers or ( 2 ) with discriminants obtained in lda as classifyers . what is fisher's approach then ?"
89340,please see the [ tag wiki info ] ( url ) . what have you tried ?
89341,could you please clarify 'follow the same shaped roc curves' ?
89361,we need to know what logit model you fitted . have you included both hour and hour ^ 2 ?
89366,"if your sampler is using rwmh , how is it gibbs ?"
89373,can you clarify 'epoch' ?
89376,"related : [ r vs sas , why is sas preferred by private companies ?"
89370,why isn't you're aic helping ?
89400,how would you propose to use the information about hawaiians in your analysis of income differences between californians and texans ?
89411,"this is a difficult ( and recurring ) question . i don't have good answers . but ( 1 ) time series is not the correct approach given too few measurements ( 2 ) you'd be much more successful if you include race , age , wbc , plt - if they have hb they had a cbc . ( 3 ) are the measurements iid ?"
89455,thanks for the editing . you've clarified it to the extent that ( a ) some people should now be able to recognize what you're doing ( b ) i'm now clear that they don't include me . is pure chance really a benchmark here ?
89471,"why do you say "" [ . . . ] i'm not entirely sure if this is the correct forum , or if cross validated would be more suitable "" ?"
89484,"are you asking for python code to get the standard errors , or for how the ses are computed ( mathematically / algorithmically ) so that you can do it yourself ?"
89529,"as you saw in my simple example , without that transaction id you don't even know how many transactions occurred and you have insufficient information about the missing values , so you wouldn't have a prayer of estimating the contribution of each type of component to the cost , much less obtaining an error estimate . your second data structure does not distinguish between * absence * of a component and * missing information * about it . shall we presume that "" na "" in your first data structure therefore means absence of a component and not lack of data ?"
89545,"for third question , you want to know a r method to find out estimates or statistical equation ?"
89599,"i don't think it's a fair comparison . as how the question is worded , it seems the first result from the regression for p1 is adjusted for p2 , p3 , and p4 . and the mann-whitney test only uses p1 . perhaps you can clarify ?"
89602,sorry i don't understand . what is your reasoning to get from 5 % of your large group hanging up to expecting 30 % of a smaller group to hang up ?
89460,are you trying to perform a network meta-analysis ?
89638,( 1 ) you can't tell a thing about correlations among * predictors * ( independent variables ) based on coefficients in a regression . are you perhaps asking about correlations between a predictor and a * response * variable ?
89661,"well , clearly $ n_1p_1-n_2p_2 $ is * due * to the four values of the $ n $ s and $ p $ s , but because it does not depend directly on the differences of the $ n $ s and the differences of the $ p $ s separately , it looks like you have been asked to do something that is impossible . perhaps there are additional assumptions or information you could share about these four values and what they mean that would help us arrive at useful suggestions ?"
89659,so if you don't care about consistency ( why would you not ?
88806,can you add that graph into your question ?
89985,"so you are saying that "" preventive maintenance "" both costs money and reduces the expected time to the next failure ?"
89986,do you have the race order available ?
89989,"the two-word phrase "" outlier sample "" is highly unusual--i'm sure i have never seen this . ( i can imagine several different ways in which someone unfamiliar with statistical terminology might come up with such a phrase . ) could you provide the context in which you read or heard this ?"
90149,"from what you have , from the algebra alone it looks like just $ y propto x ^ 2 $ . can you post the data or show a graph ?"
91160,"the first thing i would point out is if a transition has zero probability initially it will always remain zero , but maybe you know this . have you taken care to avoid numerical underflow issues ?"
91238,"logging is often used to reduce right-skewness , so it can be expected to increase left-skewness . the ` exp ( ) ` transformation is its inverse , but that is probably far too strong here . squaring is a milder alternative . you don't say what sample size ( s ) you have . it is not obvious that the main problem is really left skewness , rather than a few moderate outliers in the left tail in b1 . is there no science here to throw light on this ?"
91236,"possible duplicate of [ what , precisely , is a confidence interval ?"
92387,"when you say $ x * y $ and write "" product of distributions "" do you mean convolution of the densities ( which is suggested by "" $ * $ "" ) , or do you mean the distribution of the product of the * random variables * ( $ x , y $ ) ?"
93451,could you tell us * why * you want to dichotomize the factor scores ?
93844,"descriptive statistics do not need a least square method / linear regression line -they're just descriptive . just think : what would the "" squared deviations "" be in the case you describe , so that _least_ squares would come in and minimize ?"
94867,"okay , but that doesn't answer the question of what aim of the program really is , and what you're supposed to interpret the average as . it seems that the larger the overlap the larger the average . so what ?"
108894,"please edit this question so that the crucial information about the ordering makes sense and explain to us what it would mean for a variance to be "" given in comparison "" . since this question seems to ask about whether order of random variables has any implications for order of variances , please first take a look at the closely related question at url perhaps it already has the answers you seek ?"
109436,"if you select a subsamples $ n ^ * n $ , with yours algorithm can you classified the $ n-n ^ * $ observations not used in the agorithm ?"
110947,it depends on the model and on what these events are . could you edit this question to include some more information about that ?
136215,for whom are you doing the analysis ?
136738,what do you * do * know about these variables ?
141503,"i'm predicting air pollution with neural networks , and it works slightly better that simple linear regression . however rbf ( maybe because of some mistake ) net is not as good as mlp . additionally svm and nusvm is even better than mlp . in my case , your first approach gives me better results that the second one . i'm wondering whether you have a bug in second approach , because you use independent variable at the same time as predicted value - is it ok ?"
143460,"since ` b ` and ` c ` are factor variables , i'm not sure what your desired model is . can you write it down more clearly ( e . g . , with dummy encoding ) ?"
147690,you are talking about the left tail . do you know if it is a heavy tail or not ?
149823,are the $ v_1 $ and $ v_2 $ independent ?
155256,"what is the "" ab "" column ?"
155459,how many observations do you typically have per subgroup ?
158158,how are you adjusting $ r ^ 2 $ ( what is it being adjusted by / for ) ?
159842,"when you say you "" would like to know whether there is a significant difference within . . . groups , "" are you asking whether there are differences in the _rate of change_ of body weight among individuals placed on the same diet , or something else ?"
162050,have you tried googling adf test ?
168929,are you familiar with roc curves ?
170030,do you happen to know the standard deviation as well ?
170039,are you checking for / taking account of autocorrelations ?
176574,did you manually check whether there is no perfect multicollinearity between your variables ?
177400,what is your purpose ?
178504,"what do you mean by * "" systematic "" error ( from the network ) * ?"
184618,"tim ( since you are in the discussion already ) , isn't ruling out simultaneity targetted to ensuring that $ x_ { it } $ is not endogenous ( which would remove the whole problem of this post ) ?"
188883,$ bar x $ is not given but simply defined . have you tried the decomposition $ $ s = frac1 { 21 } sum_ { i = 1 } ^ { 21 } x_i ^ 2- bar x ^ 2 $ $ before computing the expectation ?
191162,"see also [ if a factor variable is to be dropped in model selection , should all levels be dropped simultaneously ?"
203002,"so you just want to average the estimated a parameters from a number of fits , but you want to take the ses into account , is that right ?"
204233,it's not clear why you would ever want to do this . why not just use normrand ( ) every time ?
213588,a higher degree polynomial ?
222840,i don't see anything wrong with what you have here . were you just unsure of your answer ?
228363,"what do you suppose the logs are "" only approximating "" ?"
235201,out of curiosity . . . how does weather affect cortisol outside of seasonality ?
236291,"it's not clear what you want to do . in your step 3 , do you mean that you want to scale the composite score or scale the individual z scores ?"
246738,are you sure the derivative with respect to b is defined ?
246773,"i'm voting to close this question as off-topic because i don't think this is answerable . optimization in this context means having a loss function to score alternative parameter choices . your question doesn't describe a loss function , your inputs , or your parameters , so i don't know how this could be answerable . ( stocks are the data , but what is your model ?"
251084,doesn't your function calculate y as a function of x ?
254639,"how many years as decimal , are you sure ?"
258489,what is a good probability ?
262117,"if you can tell us ( much ) more about your original data , you may well get a ( much ) more positive suggestion . how many predictors do you have ?"
262785,clearly there's * some * differences because the variance and the standard deviation are not the same . can you be more specific about what you're after ?
34827,"1 ) weighted version of euclidean distance is straightforward , see the [ formula ] ( url ) . 2 ) why do you think pearson r incorporates weights ?"
100257,why does your x-axis have the label ` y ^ 2 ` ?
268076,"is it actually possible to get true 0s & 100s , or are those rounded , eg ?"
10564,what's the sample size ?
272011,"peterflom maybe . but that would mean some random cutoffs for different distributions . no benchmark to against . how would you quantify exactly what is significant from random noise , and what isn't ?"
14819,"[ this ] ( url ) question is probably relevant , as is the fact that you can specify your own splitting criteria in ` rpart ` . see the discussion of the ` method ` argument in ` ?"
62519,how do [ graeco-latin squares ] ( url ) meet your definitions ?
272957,just how many categories are there ?
10539,do you know anything specific about the distributional properties of your stream ?
68339,are you not satisfied with did answer ?
142833,how much of the theory applies ?
24373,"i have a similar problem . if you use the statistical software r , you need the survey package . it seems that to statisticians , the term rake is used for ipf . there is a rake function in the survey package . this will result in non-integer weights for each record . i presume this can feed your population synthesiser ?"
32501,it is not really clear to me what you want to achieve with those weights . do you expect them to interact with the robust fitting procedure ?
28180,it sounds like this is soliciting opinion . what are your thoughts on whether this should be cw ?
169632,"please explain what you mean by "" but can't simply divide . "" isn't that precisely what $ z = x / y $ tells you to do ?"
232758,` a proof of the fact that . . . d is euclidean ` . but did you see there the link to [ this ] ( url ) ?
37729,if $ t_i = f ( x_i ) $ for a known function $ f $ then you can write down the distribution of $ t_i $ and the maximum likelihood estimator is derived in the usual way . but you have not precised what are the $ t_i $ ?
136774,plots are just a visual representation of data - to check if the * plots * differ you can just judge it by looking at them . * what * do you want to compare ?
175933,how long is a piece of string ?
120898,"i can see that you might want the geometric mean of two series , but why do you think you want the geometric sd of two series ?"
157797,"can you put a proper citation instead of "" zakkula govindarajulu , 1962 "" ?"
223012,your likelihood function is incorrect ( or perhaps you made a typo in writing up the mahjax / latex ) . what's the density of $ t $ ?
224891,did you try 'exact' intervals like e . g . clopper-pearson or sterne ?
135641,isn't this answer helpful : url ?
89840,"mpiktas' answer included r code . how does his ` pf - function ( q ) integrate ( df , -inf , q ) $ value ` not address the problem ?"
100408,are you only trying to infer these parameters ?
29361,"one difficulty with problems like this is that often several--or many--alternative solutions can be found , none of which is perfect . to make progress , you need to stipulate how to make trade-offs . in this case , could you tell us how to balance a poorer clustering of states against a potential improvement in achieving equality of total group values ?"
180741,1 . what is the source of the orange image ?
67521,why don't you work out the exact solution for the simplest case where the two algorithms differ--finding three nonnegative integers summing to $ 2 $ ?
54607,"have you thought of other options , such as referring those questions to a statistician ?"
96816,i agree with whuber . consider the case where $ a_i a $ 0 out of 10 times . what should be your estimated p-value ?
113602,does this question help ?
217843,i'm trying to understand your experiments . you have a voltage--current curve for each neurone ?
74775,does using this corrected formula not fix the discrepancy ?
199361,"could you be more specific about what an "" error "" is ?"
253447,"if you know that the sum of squares of residuals has expected value $ ( n-p ) sigma ^ 2 , $ where $ n $ is the number of observations and $ p $ is the rank of $ x , $ then you have that sum of squares divided by $ n-p $ as an unbiased estimator of $ sigma ^ 2 . $ is that what you're asking about ?"
203434,""" does the $ r ^ 2 $ in a model without a constant become $ r ^ 2_u $ ?"
198553,"i think this only works if you know how many yes and no's are there to begin with . in the monty hall problem we know there is 1 car and two goats . if you don't know how many goats or cars , but only a probability i'm not sure it works . perhaps try solving the monty hall problem with a probability of goat or car existing to gain some insight ?"
263957,do you have the numerator / denominator counts from which the rate was calculated ?
2067,"can you clarify the predicted variable , "" mean endorsement "" ?"
103128,this is all rather cryptic . what methods ?
52996,1 . the usual question : have you got the data for the parents' bmi ?
88825,""" linearity "" ( or lack thereof ) refers to the relationship between the predictors and the response , about which you have offered no direct relevant information . could you please amend your post to provide that ?"
114845,"note that these are not probability distributions , but really 16 separate ( presumably independent ?"
3814,does it extend to justifications received in response to an initial review ( where minor and / or major revisions were asked ) ?
61711,""" * a majority of the residuals 0 * "" of itself doesn't automatically imply bias ( it does if mean = median , for example ) ; it probably does in this case because we'd actually expect a majority 0 . what * is * the proportion of residuals 0 ?"
232223,"you have seem to have completely described the possible outcomes and how they are randomly generated , which is enough to define the probability distribution of the roll . so it sure can be modeled as a distribution , namely , the one you've just described . it's not a familiar named distribution , but obviously , only a few families of distributions have names . so what are you looking for ?"
88809,"i don't see how the confidence interval approach is that distinct from the binomial testing : if you believe your random variable to be binomially distributed you'd also construct a binomial c . i . - but that would throw you back to the same problem , woudn't it ?"
158119,what do you know about $ f $ ?
33812,are you in the social sciences or the natural sciences ?
95685,i can't follow your description . what are you going to mix these with ?
58516,"when you say $ x $ , you mean $ x_i $ , right ?"
204843,"clearly stop is a suboptimal procedure . i am surprised that this has escaped such an esteemed organization of scholars as the ass . to wit , why waste time looking at the data * at all * ?"
254594,* later tonight * never came ?
188359,"can you paste in your data or your output , so people have something to work with ?"
28042,is the definition of random taken on the other page the one you want ?
236620,are these arbitrary cdf and pdf ?
273590,have i understood this correctly ?
276978,do you mean you want to compute ` i ( a ; b c ) ` ?
11357,"zia : what do you mean by "" variance "" here ?"
100258,"i provided an answer to the final question , but whuber's comment make me wonder about your intent . can you clarify ?"
135268,"inference from record data . hmm , i don't really know this stuff , but a couple of pointers - there's a 2003 ( ?"
281266,so do you know the $ n_i $ and / or $ n $ before you draw the $ m $ people ?
288216,why not just take the top 10 % of cases by residual ?
24187,"could you elaborate on what "" interested in "" means ?"
294820,subtracting one mean from another when they have different sample sizes seems wrong ; i can't think of how that could have any meaning . why did you do that ?
294847,express each of the events * in words * and think what those are . . . 1 . what's the probability that a random variable is less than or equal to $ - infty $ ?
306280,you have not indicated your goal . do you want to check validity of instrument or else ?
309759,what have you tried ?
313132,why is it necessary to sum the variables ?
315401,do you have the data to calculate irr ?
315490,can you edit your post to include more context like the whole sentence in which it occurred ?
317962,could you point out any information that would indicate the answer is not $ 610 / 11 $ ?
317977,could you include graphs of the logged series and its acf / pacf ?
325199,why did you expect the results to be similar when you fitted completely different models ?
329391,"regardless of the number of potential responses in the answers , i don't see how it makes sense to compare a "" probably would "" type of measurement to a "" satisfied "" type of measurement . it would be like asking if the sky is bluer than a child is happy . what are you trying to determine about the responses to these questions ?"
331894,something seems to have gone dramatically wrong there as the model should have removed any linear pattern from the residuals . why did you tag this meta-analysis by the way ?
339399,"you said it yourself , the last line . what's your question ?"
341330,"welcome to cv . since you re new here , you may want to take our [ tour ] , which has information for new users . i would say that glm is more appropriate , but is there a specific reason that you consider using ols ?"
343378,"ignoring the math and statistics , how would you explain what you were trying to do to someone and what would success look like ?"
344876,you might as well say : i have 8 males and 4 females . does that bias my results to males ?
345089,"also , didn't you read the paper ?"
345215,are you using temporal difference learning ?
345630,could you more clearly state and signpost your hypothesis for question 1 ?
345865,why would you need a treshold ?
346012,is this a homework ?
346078,"i realise you state not very sophisticated , but we do need more information to understand what you need . are you wanting to determine if a short duration spike is different to before and after or are you wanting to see if a shift in local mean is significant , i . e . did the event have a lasting impact ?"
346177,can you strengthen this question ?
346221,are the $ x_i $ s correlated wit the $ y_i $ s ?
346317,why would you like to compare the means of datasets with different units ?
346378,do you want someone to solve this exercise for you ?
346399,"i don't understand . you have $ x sim bern ( x ) $ and $ y sim bern ( y ) $ , and then you end up with the distribution of $ ( x , y ) $ , that are the bernulli parameters ?"
346846,could you explain the purpose of the approximation and / or provide criteria for determining how good it is ?
346582,why do you need to select features at all ?
346182,this problem is unclear to me . how do you define 'failure of a machine' and how does it relate to the data $ mathbf { x } ( t ) $ ?
347234,"could you please explain what "" neutralize the 0 offsets "" means ?"
347266,"since almost surely this'll give you miserable results , what is the origin of your question ?"
347629,"why not analyze your data using the zero-one inflated beta regression mixed effects modeling using the glmmtmb package , for example ?"
348108,what does orthogonal mean in this case ?
348173,why would you test whether the marginal distribution of the dependent variables is normal ?
348438,"further , add some additional info , e . g . which r ` code ` did you use ?"
348529,why would you expect it to be better ?
348787,are you sure that the people belonging to certain disease statuses are close ( in proximity ) in your feature space ?
348807,is this an exact binomial test or are you using the normal approximation to the sample proportion ?
348848,did houston and new york rank the same foods ?
348923,thanks ! do i understand your data right that patient 14 receives a treatment in 2008 ( or 2009 ) ?
348928,could you edit your question to make it more clear ?
344789,could you explain why a test of correlation is necessary ?
345054,have you try to transform your data ( eg take a log of them ) and apply multiple regression on them ?
346416,i think you meant to use random intercepts in your title ?
346922,"so you are not interested in detecting outliers in clusters , but in filtering outliers out before running a clustering algorithm . right ?"
347307,please state your hypotheses . also indicate whether you have readings measuring systolic blood pressure ?
346980,""" which statistical test should i use ?"
347682,what analysis do you want to do ?
348824,i'm not sure your question can be answered without qualitative context . maybe provide a description of your observed variables and possibly a table of their loadings ?
348860,good enough for what ?
1478,could you give a couple of examples of what your code does ?
1856,"just to be clear : your question is about the size of the data , not about the setting , correct ?"
2432,"discontinuities at known x-values , or at unknown x-values ?"
2675,"a little bit more detail would be ideal to get the question . at least , how does your data look like , who are the subscribers , what do they have to do with average time , and how is 'average time in service' defined ?"
2904,"are betah , betam , betal also parameters ( i . e . things to estimate ) ?"
2950,kmeans ( ) ( you can find it by typping ?
3180,does this study involve only one disorder ( with low prevalence as i understand ) or are there multiple diagnoses assessed by multiple indicators ?
3526,perhaps [ this discussion ] ( url ) is relevant as -- it isn't often used because it is very conservative ( much like [ scheffe's method ] ( url ) ) ?
3636,"what are trying to do with the data , robert ?"
3965,"although these statements make no sense as given , they make perfect sense--and lead to an intriguing question--provided "" probability distribution "" is replaced by "" mean "" throughout . is this perhaps what you intend to ask ?"
4142,"could you clarify what it means for null hypotheses to be "" reversed "" ?"
4252,should this be tagged trimmed instead of truncated ?
4377,is d a parameter of the logistic regression or a predictor used in logistic regression ?
4383,"is this a validated scale , with known psychometrical properties ?"
4579,"the tag "" machine learning "" doesn't seem very appropriate there . maybe "" optimization "" or something like that ?"
4839,"are these measurements binary i . e . , 1 ( for yes ) , 0 ( for no ) ?"
5664,"please pay close attention to dmk38's comments , below . * who * is rating each speaker , and how much variability there is in each speakers' ratings make a difference . that 4 . 5-rated person has a higher mean than someone rated , say 4 . 3 , but depending on whether their audiences had significantly different personal grading criteria and how much variation in grades there was around each mean , there may be no real-life difference between the two . the numbers will look authoritative , since you ran them through a computer , but the question is : are they saying what you think they're saying ?"
5926,"who says they shouldn't be "" too strongly correlated "" , i . e . what's the source of that quote ?"
6078,"sorry to ask , but do you want to test trails and patients are independent ?"
6371,"since the markov chain you consider has some absorbing states ( and is irreducible , presumably ) , its stationary distribution is concentrated on these absorbing states . in other words , the stationary vector you computed should have exactly two non zero coordinates , one for each of the absorbing states . is this really what you have in mind ?"
6379,"do you want to test the null hypothesis that all the players have the same strength , or check the fit of a model of player strength ?"
6557,could you show an example image from an other package / software or give a more detailed description what you want to plot ?
6780,"according to [ wikipedia page ] ( url ) zipf's law has two parameters . number of the elements $ n $ and $ s $ the exponent . what is $ n $ in your case , 10 ?"
8088,is ` seq ` in your code a typo for ` sex ` ?
8436,did you try logistic transformation : $ y = log ( p / ( 1-p ) ) $ ?
8502,what kind of model is it ?
8625,"the answer is that you are summing the deviations of values around their mean and that sum is zero . but what , precisely , are $ x $ , $ m $ , and $ m_i $ ?"
8898,good first question ! i'm not convinced each person's three measurements on the same specimen can really be treated as independent though . did they know ( or were they likely to realise ) that the specimen was the same ?
9155,what do the arrows mean in the table headings ?
9306,what about those quantities you have mentioned : ( mean ) power during the period ; power in a high frequency band ?
9420,"out of curiosity , what would be the rationale for displaying a table this way ?"
9981,can you provide the citation or link to the text you quote ?
11322,aren't these just pearson correlation coefficients as reported on the [ tutorial ] ( url ) ?
11142,i think you are asking two very distinct questions here ; ( 1 ) what are other sites ?
11799,"what is $ dot x $ and $ tilde x $ , i . e . how are they related to $ x $ ?"
11895,"mark , say if there was such a representation , why would you want to use it ?"
11906,can you please write the title and author ( s ) of the paper you referred to above for inspiration ?
12570,how large ?
13090,can you please invest some time in better description of your data and overall clarifying ?
13178,what do you observe ?
13220,so are you * * really * * sure you want to have ` choicenum ` nested within ` subject ` ?
13504,what kind of data are these ?
13518,do you have anything in the way of training data ?
13914,"it's extremely difficult to measure the significance of results that are noted after the fact . what , precisely , would constitute a "" result "" ?"
14295,"perhaps i am missing something but why can't you determine , in r , which groups have frequencies of less than 5 % and then relabel them all as 'other' and re-calculate the frequencies ?"
14399,"it is not clear for me what do you want to achieve . do you want to simulate $ y_t $ with given fixed $ beta $ , or simulate $ y_t $ for fixed $ age $ and $ sex $ for given random $ beta $ ?"
14431,"as it is , $ log ( b ) $ appears on both sides of the regression equation and so is redundant - whatever coefficient appeared in front of $ log ( b ) $ would actually be 1 unit too small . also $ log ( a ) $ appears twice on the right hand side . is this what you intended ?"
14481,are you asking whether there's a simple formula to compute quantiles of a * mixture * of normal distributions ?
14546,"in that case maybe the terminology is "" proportion "" ?"
14713,why would you want to want to do something like this ?
14898,"maybe losing the plotting characters altogether and increasing the line width ( argument : lwd . takes positive real values ) would made it reasonable . how does this example x = ts ( rnorm ( 100 ) ) ; y = ts ( rnorm ( 100 ) ) ; plot ( x , col = 2 , ylim = c ( -4 , 4 ) , lwd = 4 ) ; lines ( y , col = 4 , lwd = 4 ) look ?"
15822,"first off , don't you want to compute the probability of the disease being present given a positive test result : p ( d t ) ?"
16141,"could you please clarify the question you would like to obtain from the community , and give more details on the process you are trying to model ( where binary outcomes come from , do you have a time series process ( polynomial ) , covariates to regress with ) ?"
17564,"be careful ! you are fitting a model without a constant term : it's a poor fit to these data . also : what does it mean for you to "" normalize "" the error variance ?"
17671,have you looked at the literature ?
17819,""" fitted values "" ?"
17967,stupid question -- can't you just partition the space into regions cut by those lines and count dots inside each ?
18381,can you add some details about this tma to better place it in ml context ?
18421,"something's missing here : because there's no stated connection between "" power "" ( whatever that might be ) and the counts , the problem seems identical to comparing two independent binomial observations . how is it intended to be different ?"
18860,"what "" rule "" are you citing in part i ?"
19055,"could you explain how you got to the "" this state "" displayed equation in your question ?"
19364,some questions for clarification : 1 . what is a . . b / b in 2 . ?
19460,did you mean $ h $ to be $ e [ h ] $ in the very last occurrence of it in your post ?
19506,weka does not have online apis . any particular reason why you want to do it over the internet ?
19932,hint : think about what's required for an anova effect to show up as statistically significant . the ratio of what to what must be large ?
20053,"sorry , but from your graph i cant's say * anything * . are those the revenues ?"
20732,"some additional clarity would be helpful . in paragraph 1 , '3 raters 3 times each' sounds like 9 tables , whereas in para 2 , ( a ) sounds like 3 tables . this makes a difference . also , what are these tables ( e . g . , rater said yes / no x actually yes / no , etc ) ?"
20712,what are you really trying to do ?
21076,what classification method are you using ?
21162,"yes , your equation is correct . as to $ r $ , you need to look at the specifications _given_ to you when you were told "" create a random variable $ y $ that is correlated with $ x $ "" . the statement _should_ have included a specification of $ r $ e . g . "" . . . that has correlation $ r = 0 . 8 $ with $ x $ "" . if your client / professor / boss / colleague did not say what value of $ r $ is desired , ask ! $ r $ should be between $ -1 $ and $ 1 $ . all else failing , set $ r = sqrt { 1-r ^ 2 } = 1 / sqrt { 2 } approx 0 . 7071 $ because _i_ said to do so . hey , if you can't trust something you read on the internet , what's the world coming to ?"
21288,"it sounds like you have a two-way table ( rows are "" populations "" and columns are values of $ y $ ) . what is the problem with standard methods of evaluating such tables , such as chi-square tests and permutation tests ( such as fisher's exact test ) ?"
21445,"hi there , could you add some more detail to your question . could you tell us more about your research ?"
21619,odds ratios and fisher's exact test are not the same thing . the function for using fisher's exact test in r is ` fisher . test ` . a description of how it computes the p-values is found in the help file ` ?
21815,"i'm a bit confused by your notation . is "" x1 , x2 . . . x ( n 1 ) "" referring to random variables or observations ?"
21872,are you uncertain of the method or just how to do the calculation in your software ?
22266,you appear to have a census of the person's number of publications . why do you wish to use statistics ?
22357,do you have a link for the first figure ?
22694,one doubt : i'm not quite sure what your title for the question is supposed to be getting at . can you explain briefly ?
22931,"hi there , do you mean that you are looking at the distributions of final scores for games ?"
22980,"so far , there is nothing about stats ( or probability for that matter ) in your question , because nothing is happening ! what exactly are you * doing * with all these buckets and balls ?"
23010,"[ get thee to a database ] ( url ) , why woulds't thou be a breeder of analytical sins ?"
23017,"it's not clear to me what you mean by "" specify the parameters "" ; aren't they part of the fitted model already ?"
23152,some text seems to have been deleted from the middle of this question . do you think you could restore it ?
23426,your link didn't bring up any specific question for me . can you give a brief description of the problem ?
23633,how much data have you got ?
23827,"it would help to define your notation a little more , even though many readers will be able to make educated guesses . what is $ a_t $ ?"
23860,i think it's an interesting question . my answer to your exact question and dataset is : does it matter ?
24054,what's your intended analysis using this data ?
24324,do the two sample comparisons use the same ` iv ` s ?
24618,are you sure your lsmeans statement is testing the same hypothesis as the t test ?
24828,what are you trying to do with this data ?
24840,do you have any thoughts about what kind of relationships might exist ?
25203,"hi there and welcome to the site . for your two seasonal components , do they have different periodicity , e . g . is one weekly and another monthly ?"
25216,"what do you mean by "" generated by randomization "" ?"
25254,could you give us a better explanation of the context of your question ?
25470,"why do your $ y_ { 0 , t } $ and $ y_ { t , 2t } $ have two subscripts ?"
26065,can you provide a little more information about your situation & setup ?
26100,"in order to cluster , you must first define what is "" similar "" . according to your edge-based directional features , can you tell us how two vectors from two different sets of features should be considered similar ?"
26360,is this homework ?
26505,"more details on the design would be helpful . 1 ) what is the nature of the pre & post test , in particular what is there distribution ( normal , ordinal , low mean count etc . ) . 2 ) is there an experimental intervention , or are you just interested in the growth for all groups from pre-test to post test ?"
26748,"if $ h_0 : mu = 52 $ and $ h_1 : mu geq 52 $ , then $ h_1 $ is true whenever $ h_0 $ is true ?"
26974,"you can fit a mixed model with lme ( ) in r or proc mixed in sas . i do not understand your last sentence , what is x_new and x ?"
26983,could you explain the mechanism by which some of the data became missing ?
27388,"hmm , interesting q . . . what's the distribution of the number of flips ?"
27402,"something to think about : what if $ x_1 = x_2 $ , or , even $ mathcal c ( x_1 ) = mathcal c ( x_2 ) $ where $ mathcal c ( cdot ) $ denotes the column space ?"
27540,do you average out the res from each cross-validation run ?
27617,so what is your question ?
27908,"two hints : 1 . remember to check by dimensionality consistency . ( eg . does the parameter have the same dimensionality of $ x $ , or its recyprocal . . . ?"
28449,what is your sample size ?
28593,didn't you miss anything ?
28869,why these two ?
28939,this looks about right : there's positive correlation among nearest neighbors . why not compute a correlogram to check the output ?
28980,1 . what do you know about the stochastic process generating the points ?
29134,"if i understand you right , you are going to create the needed amount of cases ( respondents ) filling the empty cells of the cross-classification . then , because these newly invented cases are missing on all the rest questions of the survey you plan to imput them from "" similar "" cases . but what on earth can be the background ( "" deck "" ) variables on the basis of which to establish similarity , all variables ( except country / age / sex / status ) being missing for that cases ?"
29241,"procrastinator , when you're playing poker against other players ( not the house ) , you could certainly have the odds in your favor if your skill greatly exceeds their's . the odds could even be so far in your favor so that they negate any 'rake' the site takes from the pot . how do you think professional poker players consistently make money ?"
29301,"did you mean independent or mutually exclusive . mutually eclusive means that they cannot both happen on the same draw . independent means that if a occurs it has no influence on whether or not b occurs . independent events could both happen on the same draw . so if they are mutually exclusive in your numerical example you would know that n is at least 61 . if they are independent and p ( a ) and p ( b ) are both 0 then they are not mutually exclusive and you only know that n is at least 45 . now n is a random variable . so what do you mean by "" how can i get n "" ?"
29356,"have you looked around our site , nicholas ?"
29406,"what do you mean by "" $ n ^ * $ "" ?"
29812,"three ideas : ( 1 ) how about comparing two groups ( aka conditions ) at a time , omitting the low-low group : gene 1 low risk vs gene 1 high risk ( considering only the gene 2 high risk conditions ) , and gene 2 low risk vs gene 2 high risk ( considering only the gene 1 high risk conditions ) ?"
29851,"a maximum $ r ^ 2 $ is attained when * all * variables are included . this is clearly the case because including a new variable cannot decrease $ r ^ 2 $ . indeed , in what sense do you mean "" local "" and "" global "" ?"
29853,what kind of confusion would you like ?
30042,"i think the question might be a bit broad . but in practice nns seem to be a lot more tunable with choice of nn structure , whereas svms have fewer parameters . there's two questions , if an nn were optimally set up for solving a problem how would it fare vs svm ?"
30045,"wait , $ h $ is the 'e'xplained variation and $ e $ is the 't'otal variation ?"
30051,"i don't understand , can't you use cross-validation for estimating the optimal ridge parameter ?"
30171,can you show us the original time series ?
30413,can you make your problem clearer ?
30513,what do you mean when you say that you want to test for correlation ?
30524,"welcome to our site ! to help us focus our replies , could you please tell us the * purpose * of the information display ?"
31200,do you really have 21 data points in total / s ?
31574,are you doing spearate tests for individual months ?
31703,i find this question difficult to understand . can you say more about what you want to do ?
31832,"let me ask you to clarify and detail your question . first , what is "" imbalance "" ?"
31933,"tangential remark : i've always thought that for many purposes and many algorithms 'scale-freeness' obfuscates cluster structure , due to the large pull exerted by hub nodes . it depends on the application , but i would usually look for a way to filter out hub nodes . have you considered algorithms like louvain ( which yields a tree ) , affinity propagation clustering and mcl ?"
31942,"what do you mean by "" save every dataset one by one ?"
32059,"if you want to make statements about the ratio $ x / u $ it would of course be much better to have the measurements $ iu epsilon_1 , iu epsilon_2 , ldots , jx delta_j $ rather than just binary variables ( as the latter only tell you that one is bigger than the other and not _how much bigger_ it is ) . with some of the parameters known , binary data might be sufficient though . am i correct to think that $ u $ is known ?"
32065,"you basically have to solve this numerically : you put in an estimate for $ ( x_0 , y_0 ) $ , and then solve for $ ( x_1 , y_1 ) $ , and repeat , until you're satisfied that your $ ( x_ { n-1 } , y_ { n-1 } ) $ is close enough to $ ( x_n , y_n ) $ , and use that value . as long as your estimate is in the right general direction ( maybe use the intersection average that the paper talks about earlier ?"
32741,regression involves fitting a linear model to real data which includes some random variation . are you really interested in fitting regression lines or just ploting lines like your graphs seem to indicate ?
32767,what is d meant to be ?
33235,"this does seem strange , for the reason you give . perhaps you could give us the paragraph before as well in case there's something we're missing ?"
33463,it seems that you are wondering how to identify outliers in regression problems . am i right ?
33520,""" i clustered related predictors together "" can you explain better what steps that involves ?"
33402,does $ y $ vary smoothly with $ x $ ?
33746,"it sounds a lot like you are dealing with a [ paired preference ] ( url ) ( comparison ) model , right ?"
34082,you think that log ( y ) has a poisson distribution ?
34225,i think you have some big troubles on you data . what hypothesis are you trying to test ?
34283,"the $ p $ -value of a test is actually the probability of obtaining a statistic at least as extreme as the one you've observed . so , assuming $ a $ and $ b $ are equally matched , what is the chance that $ a $ beats $ b $ $ 31 $ or more times in $ 50 $ matches ?"
34300,what makes you think a flat forecast function is incorrect ?
34362,what do you mean by error in lag . if you do crosscorrelation the highest lagged correlation might be taken as a measure of how one time series lags behind the other . but what are you looking for in this ?
34647,is this a homework question ?
34771,have you checked this [ paper ?
34867,"i am confused by the apparent contradiction between "" 1d "" ( one-dimensional ?"
34877,"asking for a name is reasonable because it gives you a way to look up properties and uses of the distribution . but , assuming it does not have a name , is there something in particular you would like to know about it , such as its moments , cumulants , or parameter estimators ?"
35208,"it's possible i just don't understand how you generated the above distance matrix , but what do you mean by "" the similarity between two sequences in % "" ?"
35231,in what way is the model significantly different ?
35237,are the two continuous-time market chains independent ?
35247,"the ad test can be applied for testing if a sample comes from a certain distribution $ f $ or if several samples come from the same distribution but it appears to me that the former is not available in this package . you could simulate from the distribution $ f $ and compare it with the data using ` adk . test ( data , simulations ) ` but it is not clear the required number of simulations for obtaining meaningful results ( i guess that as many as possible but i would not bet on this ) . are you interested on testing normallity ?"
35470,explain the context of your problem . are you looking for independence in a contingency table ?
35803,does the answer need to have confidence intervals ?
35823,is g $ ^ - $ ^ 1 $ monotonic non-decreasing ?
36084,"first , do the i read this correctly that you have $ n $ instances of this random variable $ u $ , and also that $ -n $ and $ n $ are the bounds of the uniform distribution that the $ u $ s are instances of ?"
36271,doesn't url answer your question ?
37388,what do you suppose happens when many of the correlations are * negative * or near zero ?
37453,why do you need to avoid zeros ?
37502,when you mention standard error are you talking about the standard deviation of the sample mean from lognormal data or for the difference in means from two samples from possibly different lognormal distirbutions ?
37505,where's the hierarchy ?
37694,i am hoping i can help you with this question but two things are very unclear to me . what do you mean by incomplete ?
37773,"perhaps a bit irrelevant , but why aren't you using roc analysis ?"
38104,"it is not clear exactly how much data you have on the companies . you just know in which "" window "" they fall , but not the actual revenues ?"
38180,first of all what are the p-values actually if some are near the border of 0 . 01 that matters . would you still get this conflict if you use 0 . 05 ?
38214,"that seems to be the answer , henry , care to make it official ?"
38258,"i am not sure i understand what you are asking , but one possible help is that 100 people are , presumably , a sample from some defined population of people . what is the population of coin flips ?"
38283,do you know anything about the arrival times to $ l_1 $ ?
38611,"think about what the parameter estimates mean in a linear regression . why do you suppose one is called "" intercept "" ?"
40715,"welcome to the site , ali . i don't understand how you are describing your groups . eg , what does "" 2 groups of 4 users . 4 groups of 3 users "" mean ?"
40790,"what do you mean , exactly , by "" more associated "" ?"
41019,"welcome to the site , dualinity . i appreciate your having read some of the prior threads 1st , & trying to work within the standards of se . i'm not sure i follow your question yet . you want advanced procedures that use the median , but advanced procedures to do what , exactly ?"
41404,you could simply have an extremely large n . or ( multi ) collinearity . hard to say . could you edit your question to tell us a little more about your dataset and what you are trying to achieve ?
41536,"what are a , b , y_hat ?"
41941,what research have you done into the standard methods of constructing such confidence intervals ?
43189,"hello , is your $ s_n $ supposed to be $ sum_ { i = 1 } ^ n ( y_i - mu ) ^ 2 $ ?"
43688,do you care to tell us how many independent samples ( cases ) you have ?
43928,"in order to answer this we would need to see the data or at least a more detailed description . have you plotted a histogram , qq-plot or summary statistics of them ?"
43994,so how did you test whether the estimates improved ?
44095,is this time series data ?
44973,"you refer to $ y $ mean in the later comments , but it is not mentioned elsewhere in your question . do you mean $ overline { y } $ , and where should it be ?"
45030,so a ) is there something in common between item 411 in category 15 and item 411 in category 35 ?
45202,"druss , could you provide page number references to the davidson and mackinnon book ?"
45203,maybe a mixed model with a random effect for household ?
45414,can you add a bit more detail to the question itself rather than putting a hyperlink with the question at the end of it ?
45794,"it may be helpful to provide more context on your study : what are those heuristics , what are the data ?"
45993,"am i right that totalphonecall is the only unknown , random variable ?"
46037,"naive bayes classifiers are often horribly uncalibrated , they tend to make very extreme predictions , even though they are simple / useful as a first or baseline implementation for a classification task . it's possibly you've messed something up , but i wouldn't be too worried about a naive bayes classifier sometimes being horribly off . what does your overall accuracy look like ?"
45762,it would help to make this question more specific . what functions are you concerned about ?
46280,"n a sample size and zeff is defined in eqn ( 2 . 41 ) , but where are v , z , and w defined ?"
46719,"in your second paragraph , why do you think that method misses the point of multiple imputation ?"
46891,what's about making a maximal vector containing all instances ?
46915,"sounds interesting , but because the random forest does not guarantee the same results each iteration , i'm not sure how this would guarantee a fixed encoding / decoding relationship to each party . it might be possible to use some kind of denoiser as mentioned on your link ?"
47393,what software / language are you using ?
47583,"i think this is quite a complex problem . the answer will depend on what you are willing to assume and what data you have . do you have a database of cities that are thriving vs . not , and past values of the variables you have ?"
47706,what is u ?
47857,could you attach a simple csv spreadsheet with sample data ?
48280,"although you list some goals , i am still not really clear what the point of your study is . is this just initial-phase exploratory work ?"
48384,"what precisely does "" $ pp ( lambda ) $ "" mean ?"
48744,"can you clarify -- the lines like "" x2 = 3 . 2 "" are the regression coefficients ?"
48656,what kind of limiting process are you using to define the integral ?
49108,"welcome to the site , jonna . are you * only * interested in how to get r to do this ?"
49169,"an explanation of your notation would help people understand what you're asking . what are "" r "" and "" [ k ] "" ?"
49263,how can one smoking status be regressed upon another ?
49280,explain to who ?
50339,"* * related * * : [ in non-negative matrix factorization , does the first n eigenvector have n greatest variance ?"
50341,"some clarification is needed here because the data structure is difficult to understand . what are these "" time outs "" ?"
51189,do you mean you have a single observation ?
51241,can you provide a sample copy of your output ?
51494,"please , check your question for lapses , it is misty a bit . you say each group is 26000 but then print 23000 . 0 . 33 and 0 . 39 also subsequently change , suddenly . are these values percents or proportions , after all ?"
52010,the data-sets are going to be used for supervised classification ?
52341,what * kind * of formula do you want ?
53325,do you mean the share frailty model ?
54498,"my understanding of "" loglinear model "" --which is pretty well aligned with the [ wikipedia definition ] ( url ) , albeit a bit more general--does not enable me to make sense of this question . could you please tell us what this term means to you ?"
55455,is drawing two times 5 valid ?
55609,aren't the $ y_i $ supposed to be * independent * ?
55900,what software are you going to use to run this test ?
55987,what is 'weird' about it ?
56440,what happens if you leave out just one of them ?
56634,the sampling distribution converges to normal although the distribution of w is not normal ?
56678,"you could search the site now , potentialscientist ; - ) . re peter's first point , you might try reading this thread : [ what-if-residuals-are-normally-distributed-but-y-is-not ] ( url ) , eg . in addition , your question is not entirely clear : by "" analyze "" , do you mean * interpret * ?"
56731,would a log-scale improve things ?
56935,is normality assumption on deviance residuals required in poisson regression ?
57323,"i think you might want to read about type i error rates and hypothesis testing in general . non-significant p-values are inconclusive and have anyway do not lead to a type i error . also , what is "" a better result "" ?"
57549,more information would help . my first guess : those are y = 0 values . is y a count-variable ?
57595,are you doing interpolating splines or smoothing / penalized splines or regression splines ?
57767,""" * the later seems to lose information that might be important * "" - are you able to clairfy how multinomial logistic regression is losing important information ?"
57944,welcome to the site ! is this for a class project ?
58046,have you noted that $ h ( t ) $ is the derivative of $ - log s ( t ) $ ?
58302,of what would you like the covariance matrix ?
58390,can you define sighting effort and how this influences the perceived number or likelihood of spotting a species ?
58709,"can you give details about your data set , i mean , your dependent variable $ y $ and independent variables $ x_1 $ and $ x_2 $ ?"
58861,could you be more specific about your model ?
58923,"welcome to the site , marco . i have no idea what you are asking . can you clarify your question ?"
59184,"hi ewan , welcome . could you be a bit more precise about your question ?"
59485,why is the variable spelled 'teatment' in the image but 'tratament' in the code ?
59728,"the question is "" is that distribution skewed toward small values ?"
59326,do you mean multiple linear regression ( or glms ) with more than one independent variable ?
60674,hi nate and welcome to the site . am i correct that the dependent variable ( outcome ) is the same in the all-species and in the old regression ?
60880,this question lacks the information needed to answer it : what precisely are the $ f_n $ ?
61270,so what's your question ?
61315,"with that range you're probably ok , but it would be worth looking more closely . ( the idea is that the variance of the counts is approximately proportional to the counts themselves , so when the spacing between the counts is of the same order of magnitude as their square roots , you cannot reliably order the counts . ) since your data amount to just four pairs of numbers , perhaps you could post them ?"
62013,why was it designed this way ?
62193,"i'm sorry but i have no idea what you are trying to do or what you need help with . what is the "" problem "" you have to solve ?"
62637,"normally one does not set out in a data analysis to compute a correlation coefficient : one has specific analytical objectives , such as to identify a relationship among variables , or make a prediction , or estimate something . computing a correlation coefficient is just a technique used to get you there . whether it should be computed at all , and if so how it should be computed , are questions best decided within that larger context . would you mind , then , editing your question to share some information about your objectives and what you hope to achieve with this calculation ?"
62743,what do you mean by single proportion ?
62981,"this sounds very odd in implying that pearson ( n ) and pearson ( n-1 ) are different . there aren't different formulas or ideas for pearson correlation . there are different formulas for standard deviation , but it's immaterial which you use for pearson correlation as identical terms cancel in numerator and denominator . this may sound like a minute detail , but it could be diagnostic of poor software . all you say is that is an "" add-in "" ( to what ?"
63219,"i am guessing someone who wins both his matches wins the three-way game , but what happens if everybody gets one win and one loss ?"
63837,"hi and welcome to the site , grantd71 ! i have tried to incorporate the equations into your question , please make sure that they are still correct . further : your data are displayed quite messy , could you please re-format them so that they are easier to read ?"
64226,"aaron , i don't know about "" never will "" handle corr / var structures -- i am interested in adding these features and don't think it would be * that * difficult -- but i would certainly say "" don't hold your breath "" . i'm not familiar enough with panel data to know what would be required for ` lmer ` to handle them . . . hong , can you add a brief explanation to the question that describes the necessary statistical properties in a little more detail , or gives pointers ?"
64333,"i didn't understand about the different sets of units - units of measurement or experimental units ( two groups of individuals with a , b , & c measured on each individual ) ?"
64368,"your terminology is perceived confusing . what you call ` samples ` is more apt to call "" cases "" , "" observations "" , "" data units "" or "" data points "" . given that , what is ` clusters of variables ` for you ?"
64431,have you considered applying _ [ jensen's inequality ] ( url ) ?
64632,without giving it much thought : have you normalized your data ?
64785,"fair enough , could you summarize the different methods you are wondering about , so that people don't have to read the pdf ?"
65244,"what do you mean by "" accuracy "" ?"
65361,can you say a little bit more about your question ?
65482,"i think this worded a bit too loosely , what you mean about correct ?"
65585,can you post the code ( or similar example ) that you used to get the output ?
65595,are you referring to the r [ circstats ] ( url ) package ?
65641,"but if you do not include other determinants for quality of life , for which there are a lot , then your statistical procedure is not even asymptotically correct ?"
66334,can you explain your example ?
66430,"although you already seem to understand the correlation / linear regression case , you may ( or may not ) still find it interesting to read my answer here : [ what is the difference between linear regression on y with x and x with y ?"
66875,the constants can * always * be accounted for--just do the integral ! here it's been done for you : where do you think all the gammas came from in the last equation ?
66950,"( 1 ) the related ( but not the same ) question at [ efficient online linear regresion ] ( url ) may offer some inspiration . btw , what is "" $ c_ { t-1 } $ "" ?"
67014,"as far as i know , 'glm ( ) ' and binomial family expects a binary response . your 'tot_users' seems to be continuous . is there some trick behind this ?"
67108,can you say where you read this ?
67114,did you have enough samples that aicc was not required ?
67386,what's that detail df = na in your output ?
67375,"your question is unclear . it sounds like you want your ` v ` to be a vector of random probabilities , ie they should be nonnegative and sum to 1 . is this correct ?"
67470,what if you make 'b' a factor as well ?
67558,can you provide an example ?
67841,what is your application purpose ?
67973,why should $ epsilon = hat x $ - x follow a gaussian distribution ?
67999,"just a quick thought : it seems to me that you loose control over time factors in the design you sketched . for example , if the effect differs between cluster a and b , is this natural variation or due to history effects ?"
68111,"when you say the "" percentile score "" of $ y_i $ , do you mean the proportion of the $ x $ s that are $ leq y_i $ ?"
68342,andre : tuberculosis ?
68417,aren't you integrating over $ mathbb { r } ^ p $ ?
68476,have you considered using gibbs sampling for each variable ?
68631,so . . . like a prediction interval for regression ?
68840,""" * i am told both regression coefficients cannot exceed 1 . * "" -- don't believe everything you're told . were they perhaps talking about standardized coefficients ?"
68931,are the parameters for the $ t_i $ the same ?
69058,can you compute the likelihood if convergence has not been achieved ?
69134,do you intend that x and y be independent ?
69140,have you tried looking at the definition of the moment generating function ?
69217,"are you sure that this plot represents training set errors , but not validation or test set ?"
69369,what variables are these ?
69714,"i gather your main effects were non-significant , was the global f significant ?"
69835,what statistic is it you want to bootstrap exactly - are you wanting to bootstrap the entire 10x10 correlation matrix between the two 10-column sets ?
69977,"the answer must depend on the distribution of iq scores in the population , which presumably you don't know ( otherwise why are you sampling ?"
70331,can you explain what hierarchical cluster analysis approach you are doing in sas ?
70603,so is $ r $ known ?
71038,"longitudinal data analysis is a broad field . to give a good answer to this question , more info about what effect you expect time to have is necessary . without this , it's not clear whether the answers you've received are good or not * ( this is why it's good to clarify the question before , not after , you answer . . . ) * . i know you've said price decreases over time but , is there more to it ?"
71054,could you please give a reference where you read that ?
71236,"why do you want to compare the correlation matrices , and not apply a suitable tool to the 600x50 matrix with the population membership as the dependent variable ?"
71311,why two-way ?
71759,do you know the numbers of females and males that produced these ratios ?
71970,"it is not very clear what you mean by "" estimating "" here . given the rest correlations , the unknown correlation may usually _vary_ within some bounds ; the bounds being dependent on the rest correlations . is your question about those bounds ?"
72169,is this homework or self-study ?
72295,your question doesn't match your title . what are y and x ?
72472,"whether it "" makes sense "" or not may depend on the costs and constraints on your data collection process . conceivably , it is easy to collect lots of data along individual lines but expensive to set up each line : such a circumstance would suggest an approach like this one . what is optimal , though , depends on details of the costs and the specific constraints . could you perhaps share this kind of information with us or , more generally , explain why you are contemplating such an approach ?"
72721,"it would help to clarify by defining explicitly and in mathematical terms what $ y $ is . "" payback rate "" is a very general term . is it measured as a ratio of monetary values ?"
73090,"welcome to the site , alexhli . if this question were * only * searching for a function or library to do this in python , it would be off-topic for cv ( see our [ help page ] ( url ) ) . however , it's not clear to me whether that's what you are asking ( eg , "" * preferably * in python "" ) . if you have a substantive statistical question about these methods beyond looking for a function , would you edit to clarify it ?"
73238,i would also note that the ` ?
73599,what are your initial parameter estimates ?
74021,"thanks . this is still not too clear . please * explicitly * identify the function you want to check , the variables / arguments you are testing the sensitivity of , and what type of uncertainty are you modeling ( percentage error or absolute errors ?"
74103,is this homework or some sort of assignment ?
74085,"either site , i think , is fine . so long as you don't cross post ( as in post an active version to both sites at once ) . i would be happy to migrate it to stats for you if that is what you want , but why not let it hang here for a couple days at least to see if you get a good answer ?"
74340,could you share with us the * purpose * of this fitting exercise ?
74648,"is $ b $ under "" * * notation * * "" supposed to be the same as $ u $ under "" * * question * * "" ( etc ) ?"
74916,i think there's not really enough information here to give suitable answers . do you have some data ?
74926,"so , you want to choose 10 out of 600 locations and get a total that is "" sort of stable "" . but what do you mean by "" sort of stable "" ?"
75023,have you calculated $ e [ x y ] $ ?
75045,"to compute a precision-recall curve , you need to have for each data point of your training set the probability of belonging in the positive class . where are these probabilities stored ?"
76377,does the model have a constant term ?
76738,"what are n , n , and m ?"
76761,which version of r is this ?
76855,"what * do * you know , or can reasonably assume , about how the samples were taken ?"
77095,"are you saying that you have measured 15 different variables ( yielding 15 distributions ) in two different populations , and you are looking for "" overall "" difference ?"
77240,there are many questions here . what is your response variable exactly - counts of the numbers of fish species or something else ( e . g . abundance for individual species ) ?
77317,5k is very specific . what is your population & your sample ?
77513,what is it you're interested in ?
78093,"i don't know , but you have some very large coefficients there with enormous standard errors . [ separation ] ( url ) ?"
79124,"i would like to help , but i am not sure i understand the type of data that you have . can you post ( a subset of ) your data ?"
79138,did you have a particular method in mind and if so could you post a link ?
79259,"what are "" y "" and "" x "" ?"
79385,"by the way , what is wrong with using the pca approach ?"
79391,"is the form of $ f $ known ( up to some parameter-values , which are to be estimated from the data ) , or unknown ?"
79380,"first , your "" hypothesis "" is non-scientific in that it is vague and undefined and therefore is not subject to statistical testing . please explain to us how you would * quantify * "" similar . "" second , it is ( almost ) impossible to perform a test based on a single observation : do you have multiple observations of the same type to compare to the target ?"
79457,"( 1 ) probabilities depends on * counts * , not proportions . ( 2 ) probabilities require some kind of model for variation . what is your model ?"
80039,"your characterization of statistical methodology "" before the bootstrap existed "" is unclear and does not seem to correspond to anything that really occurred . this makes your question difficult to understand and perhaps impossible to answer . could you explain what you are talking about or at least provide a reference to it ?"
80215,"this question is unanswerable without information about how the list is constructed and what you mean by "" encounter . "" for instance , are you asking about the frequency of a particular substring within a string ?"
80789,"in what way 1 , 2 and 3 differ from each other ?"
80880,can you clarify your second question ?
80910,why would you not use a 'draw a card' model rather than a 'flip a coin' model for the assignment to treatment ( which thereby guarantees equal assignment ) ?
80921,do you assume each user has one profile and the total number of these is known ?
80923,please list the models that you are running . which variables are in each ?
80957,does the percentage of failures for a particular test converge to some number as the number of tests increase ?
81191,"i suspect there is a misunderstanding here : "" white "" is the name of an econometrician ( not the name of the color "" white "" used metaphorically in other contexts as in "" whitening the series "" ) , and "" white standard errors "" refer to the square roots of the variances of the estimated betas -not to some transformed residuals . so you don't need to "" further correct "" anything here . as the text says , the diagonal elements of this expression _are_ the "" corrected "" ( heteroskedasicity robust ) variances of the estimates , so you use them instead in t-tests etc . does this help ?"
81427,"is [ this ( pdf ) ] ( url ) , the raftery paper you are referring to ?"
81459,"any additional info available about when the zeros occurred in the sequence of 20 billion presses , or whether either number is displayed by default ( i . e . , does the button display something that doesn't appear otherwise , or does it change the display only sometimes ) , or whether the relationship between the button and the display is causal ( i . e . , does the button actually affect the display ) ?"
81693,are interventions 1 & 2 different experimental conditions to which the students were randomly assigned ?
81834,"welcome to our site , kaly . i'm sure you will get some good answers shortly to help you characterize these data , but in the meantime you might consider explaining * why * you want a name for the distribution . how will that help advance your analysis ?"
81954,` what is the direct way to get ssb ?
82216,"` thus , i have a statistically significant moderation term ( c a ) , but the main term ( a ) has not been included in the model . ` what spss command you use ?"
82442,does the definition of [ multivariate outlier ] ( url ) suit your purpose ?
82630,"it is unclear what "" the iv is measured slightly differently across studies "" means ( can you give an example , how many categories , etc . ) . can you dichotomize your iv ?"
82625,do you know how the two samples were drawn from the population at the two time points ?
82731,if your goal is to find out which region your brand is doing better ( selling more ) then why are you comparing last month to last year ?
83068,( 1 ) what's a 'template' ?
83584,what is $ hat { y } $ ?
83712,"you should use anova ( analysis of variance ) , or its non-parametric equivalent according to variable distribution . can you tell more about your data , or post it here ?"
83845,"try applying little's law : $ l = lambda w $ . you know $ lambda $ , and all you need is $ l $ . can you get that ?"
85905,"is your question to find the proportion of area in overlap ( as with the link you give ) , or to find out something else ?"
86215,have you tried to use the robustified z-scores ?
86256,"could you clarify what you mean by "" account for the mean squared error ?"
86453,"i don't follow your study or analysis . what is your response variable , where someone touched the screen ?"
86785,( 1 ) which parameterization of which specific 'skew-normal' ?
87048,"it seems that you are saying you know how to generate values of $ x- theta $ and you wish to have a set of values of $ x $ instead . in other words , given any realization $ x_i- theta $ you need a formula for $ x_i $ in terms of $ x_i- theta $ and $ theta $ . is this correct ?"
87144,welcome to our site ! is your question about what this projection means ( mathematically ) or about how to compute the dot products in ` r ` ?
87740,"i've left your "" not rejected "" in respect of p-values 0 . 05 . what makes you think wilcoxon compares means ?"
87825,"by "" . . . and * it * is also a ( nonlinear ) function of age and gender . . . "" , i assume you mean that the best estimate of the estimated baseline value is a function of age & gender , not that x is a function of age & gender . is that right ?"
88158,"whuber i agree with user39531 , this is not a duplicate . however user39531 , could you make your question clearer ?"
88151,"could you please explain what you have in mind by "" using a gaussian process "" and how that would differ from multiple regression ?"
88868,"are the middles of the circles within the square , or the whole circles ?"
89000,"i suspect that in the terminology used in statistics you mean "" observation "" when you say "" variable "" . multiple variables would mean that we take a look at a product and record it's price , weight , colour , etc . each of these would be called a variable . i suspect you mean that you looked at multiple products or one products over multiple times ( i . e . multiple observations ) and you want to consider one characteristic ( i . e . one variable ) : it's price . is that correct ?"
89133,do you have the sample size ?
92654,"are you referring to the joint density of $ { x_1 , x_2 , x_3 } $ ?"
97258,"its difficult for us to figure out what you did wrong when we don't know what you are trying to do . would you care to elaborate , or perhaps provide a link to what you are trying to show ?"
111785,"what do you know , or assume , about the noise ?"
118162,can you describe the data setup better ( eg show some rows of the data ) ?
133241,"could you explain what you mean by "" apply the transform $ f_ lambda ( x ) $ obtain a covariance matrix "" ?"
175672,any particular sort of models ?
200860,- is the expression for $ p_m $ that you have provided an * estimate * of $ p_m $ given data $ { d_m } _ { m = 1 } ^ n $ ?
218288,"could you explain what you mean "" do with this "" ?"
254597,there is a bouquet of questions to your case . 1 ) were you doing k-means on the initial data or the two principal components you show ?
261340,"what do you mean by "" fraction "" in this context ?"
280900,what is your data and what do you want to forecast ?
345765,"are the size of teams fixed , or of arbitrary size ?"
346464,replace the softmax layer with a linear activation ?
347421,does this answer your question ?
348293,"what do you know about the distributions for r1 , r2 and r3 besides their sample histogram ?"
348519,what are the sizes of the steps ?
348901,how many groups do you have ?
349233,"what do you mean by "" checkers and chess is not a problem for computers , go also . . "" ?"
89422,there are many threads here on forecasting that can help you . have you looked at any of them ?
89745,are variables produced by multiplying random variables actually mixtures ?
89747,what is the purpose of your document and who are the audiences ?
89788,"you can't have two distributions for $ lambda $ in the same expression , $ p ( lambda ) $ and $ p ( lambda tau ) $ . maybe you meant to write $ p ( lambda w , tau ) propto p ( tau ) p ( lambda tau ) p ( w lambda ) $ ?"
89793,have you ever regressed anything against a date ?
89797,i've re-read your question and i'm very confused . what does z x mean . does that mean a linear regression model with x as a predictor and z as the response ?
89810,how is it that you ran this model as both ols and as a logistic regression ?
89613,"what do you mean by "" vertex distribution ?"
89841,common usage would have lower case for density functions and upper case for cdfs . why are you setting derivatives to be equal ?
89618,"because you seem to have defined $ hat theta_i = exp ( hat eta_i ) , $ aren't your two calculations identical ?"
89161,"ok , if you * know * there is an upper boundary , that's fine--but it doesn't seem highly relevant to your question about conditional variance . your concept of identifying a "" conditional variance "" within * individual values * seems misguided to me , perhaps because i might have a different understanding of this term than you intended . could you please edit your question to clarify what this value is supposed to mean ?"
89714,why are you using a nb model for a response variable that is not a count ?
89862,does [ this ] ( url ) help with figuring out what they are ?
89536,"could you ( via interpolation ) put a fixed number of points on each polyline ( somewhere in the region of say 100 to 1000 ) , and then compute some robust "" typical value ) for the first such point , the second such point and so on ?"
89722,there's no assumption in ols about the distribution on the predictors . if you have actual zeroes . . . don't take logs . indeed even the possibility suggests taking logs is possibly not the way to go . is the distribution of z more variable as the mean gets larger ?
90004,world of warcraft eh ?
90045,"it depends on how you simulate the matrix . your matrices do not appear to be simulated randomly , nor according to any clear rule , so it would be impossible to answer that question . what , then , is the question you really want to ask ?"
81552,your question is about how to compare models with the aics have values fairly close together . high or low is irrelevant ( and can change simply by changing the units the data are expressed in ) . so why put those words back ?
89475,"i find the illustration confusing because of the huge lie factor built into it : the successive levels of the "" funnel "" use different scales that change irregularly . thus the widths of the bands are * not * determined by the absolute numbers in each--at least not in any easily understood or visualized way . so what are you asking : whether there are better ways to visualize such data or how to create this graphic in python ?"
90163,what are your ` doctor ` and ` cluster_gr ` variables ?
90203,"although i don't read german , i second nickcox's suggestion . the reference ( including page # ) is needed at a minimum . in addition , an excerpt might be nice . on a different note , are you sure that the denominator isn't square-rooted ( ie , $ sqrt { 1- { rm corr } ( x , y ) ^ 2 } $ ) ?"
90216,""" * which i assume is some sort of gamma distribution . * "" - you're observing data values over time , and those aren't displayed as a density . on what basis do you say "" gamma distribution "" ?"
90248,"there are a number of ways to go here and it depends on the kind of question you want to ask . do you want to know if the mean savings changed , the median savings changed , or the probability of saving changed ?"
90263,why are you doing the univariate analysis ?
90309,""" i want to know what choice people usually make , and why . "" choice as far as what ?"
90325,"you should include the sample in your question . as whuber said , the likelihood is trivially zero for both parameter values . . . which simply means neither parameter value can have produced the values $ ( 0 , 1 , 2 ) $ ( but neither conditional distribution seems to sum to 1 either . is something missing ?"
90357,"you've got , say , people who eat 1 hamburger a month with normal blood cholesterol , people who eat 5 hamburgers a day with high blood cholesterol ; but no info . on all the people who ate 5 a day & dropped dead of heart attacks when their cholesterol levels went through the roof : & you're worried that you're therefore under-estimating the effect of hamburger-eating on cholesterol ?"
90373,""" chapter 5 "" of what ?"
90392,how is ` result ` coded ?
90391,"when you say you know the means and standard deviations , do you not have the three original values for each treatment ?"
90396,do you know the standard error of the instrument / method ?
90344,does [ this paper ] ( url ) help at all ?
90439,is there a reason you can't just use the imputed x as the variable ?
90444,""" best estimate "" in what sense - what is being optimized ?"
89643,do you know about stan ?
90323,"what $ p $ , $ d $ , and $ q $ are you using ?"
90511,did you look at ` ?
90494,"whuber , maybe i'm missing something but assuming $ p_a , p_b $ are known parameters wouldn't it suffice to look at the likelihood ratio , $ dfrac { p ( gamma_1 p_a ) p ( gamma_2 p_b ) } { p ( gamma_2 p_a ) p ( gamma_1 p_b ) } ; $ ?"
90504,i could use a little clarification . am i correct that $ lambda $ is a parameter of the prior distribution ?
90547,url with equal $ p $ ?
90565,why do you want to do a regression method ?
90499,"is that any different from having censored data , where all you know for the $ n-k $ atoms that didn't decay is that their decay time is greater than $ t_ { mathrm { max } } $ ?"
90609,"john , i suspect the real issue concerns the context . it is rare that people will dedicate resources to learning only one thing at a time : they want to make the most of their data , for good reason . that means that each dataset will be used for multiple tests . moreover , sometimes the tests are * post hoc * : they were inspired by patterns seen in the data . in such cases the tests do not actually have the desired 95 % ( or whatever ) confidence and replication is essential . so : what precisely do you mean by "" experiment "" ?"
90484,"it doesn't , except under a broad interpretation of "" fourier basis . "" do you think you could focus this question and make it more generally answerable by stating what you mean by "" translation-invariant , "" "" signal , "" and "" fourier basis "" ?"
90644,""" * i am bothered with this huge difference in sample sizes * "" -- why is this bothersome to you ?"
90701,it is safe to make the presumption that breeds between species have nothing to do with each other ?
90711,"saying a step-wise regression "" showed that only two iv can predict the dv "" suggests you don't understand how it works . if two ivs are strongly correlated , & either predicts the dv about equally well , a stepwise procedure can remove one quite arbitrarily . what's the problem with using the full 8-iv model ?"
90722,what are the anovas & kruskal-wallis tests here ?
90744,"the phrase "" * reciprocal of this probabilities * "" is unclear . what is it you want ?"
90735,are ` scorea ` & ` scoreb ` continuous variables ?
90659,your tables don't make sense : how did you choose the point at which you compute those performance values ?
90675,"you should also clarify how your model & hypotheses are describing the problem . define $ h_0 $ & $ y $ & $ n $ properly . if $ sum y $ 's the sum of errors over 31 newspapers , & $ h_0 $ concerns the mean no . errors per paper then how do the two relate ?"
69831,"what exactly do you mean by "" cross-validating the confidence limits "" ?"
90896,"if you have the [ * parameters * ] ( url ) of the two distributions , you know immediately whether one of the * parameters * is greater than the other - it's a fixed quantity . do you mean that ( given the two distributions ) you need the probability that an observation from one distribution is greater than an observation from the other ?"
90926,"logistic regression , why ?"
90907,"just to be clear , you're saying that it does converge , but it takes an unusually large number of iterations , right ?"
90939,"tyro ( leaving aside any question of how to do the fitting at all ) when $ p n-2 $ , what residual sum of squares do you have ?"
90953,it is pretty hard to not fit the bernoulli distribution unless you have correlated observations . what about the fit do you suspect is inadequate ?
90984,"i don't think "" is $ r ^ 2 $ high enough ?"
91054,what model do you have in mind here for how the observed values for the same individual are related ?
51876,why did you consider absolute values if you are interested in the dispersion of the response distribution on the original scale ?
91083,can we assume that $ prod_i ^ i y_i prod_i ^ i x_i $ ?
64779,"this appears to be a duplicate question , see my answer to a previous question here url . can you explain how your question differs from the earlier one ?"
91134,"your issue seems to be calling * exactly * for anova , especially since you seem to be interested more in causal relationships than in , e . g . , prediction . what do you mean by "" this approach does not test whether the variables are dependend on each other "" ?"
91171,"hmm . that's kinda a strange request but . . binomial gives integers so with fixed n , you can't always find a set of integers that will exactly hit a mean , say pi . now , if that mean is from another binomial than you can obviously but perhaps not in a different way . my guess is that you may not have to do this . what's the purpose ?"
91127,i still don't understand your question . what are you trying to get at ?
90948,"how about substracting one from other , and then plot that above and below the zero axis . i'm wondering what sorts of information you want to emphasize . when you say that series 2 is more to the right , maybe you are comparing means ?"
91201,"are you defining "" relatedness "" by a correlation cut-off ( e . g . 0 . 4 or 0 . 7 ) or using clustering algorithms or a pre-specified knowledge based linkage of like-industries ?"
91215,are there only 4 categorical variables in your model ?
82847,how are you using the weights ?
90545,why not use ` princomp ` ?
91226,what would make you even take a glance at a $ p $ -value when deciding what to do with a study when including in a meta-analysis ?
38696,do you just want to make graphs to look at these relationships ?
91241,why use a t-interval for this problem ?
73507,"are you * only * interested in whether the proportion of people who chose item 2 , given that they chose item 1 , differs by age category ?"
91246,what are you measuring with ~ 30 orders of magnitude precision ?
91247,what are you trying to compare ?
91290,does this page : url suit what you need ?
90425,"in the mle , $ hat { a } _ { i } = 1 - frac { d_ { i } } { m_ { i } } $ , what is $ m_ { i } $ ?"
91184,start with ` predict ` ( i . e . ` ?
91008,i'm curious where the distribution comes in here . is $ x_i $ a random variable and possibky different for each $ i $ or a realisation and thus a real number ?
91324,""" * i feed in a list of numbers and it tells me whether or not the numbers are normally distributed * "" -- no hypothesis test can tell you if data * is * normally distributed . it can sometimes tell you if it is reasonably clearly not , but failure to reject doesn't say the null is actually true - it almost certainly isn't ( except in some very limited circumstances ) . . . . why do you want to test normality ?"
90931,can you more clearly explain the situation please ?
91366,is the posterior a proper distribution ?
91309,can i suggest you make your second question into a separate question ?
91419,"no ; i am suggesting that you simulate drawing two curves repeatedly using the same methods . see url for the flavour . warnings : i can't see any scope for a plug-in or off-the-shelf test if the question is just "" i have two curves : are they genuinely different ?"
91422,"as nick says in his answer , could you post more of your code ?"
91442,"what do you mean by "" big mismatch "" ?"
91468,"also , since presumably the goal is to measure if there is an impact of training on test scores - having the post-test have the same questions as the pre-test will cloud the interpretation ( is it really the training that improved scores or familiarity with the test ?"
91473,scortchi perhaps you could elaborate on why you feel this way ?
90702,"wouldn't it make more sense to have log ( n_ij ) as the offset term ( i . e . , the realized value of the population ) not the expected value mu_ij ?"
91506,is anything known about the dependence in the series on which the moving standard deviation is computed ?
91511,"rrpp are you referring to a standard $ uniform ( 0 , 1 ) $ , or a general $ uniform ( a , b ) $ ?"
91537,how about [ beta ] ( url ) with $ alpha = beta = 0 . 5 $ ?
91554,what is your basis for assuming entropy is positive ?
91375,"maybe i'm not seeing something , but why does "" averages of the cumulative sums "" make sense to you ?"
91597,"add 20 values of $ y $ , where 10 are $ 0 $ and 10 are $ 1 $ . can you divide this by 20 ?"
91605,you might be interested in reading this old thread : [ is there an r equivalent of sas proc freq ?
91632,"in the last paragraph , you state that your hypothesis was that students in the experimental group would perform better in the * * pre-test * * than students in the control group . did you mean * * post-test * * ?"
91682,"you already told us how to do that : $ hat { beta } mathbf { a } z $ , so what is the problem ?"
91747,"what does it mean to show that "" there are more a's than b's in y . . . even after controlling for x "" ?"
91736,can you assume that $ a $ and $ g $ are ( at least approximately ) independent ( not just uncorrelated ) ?
91752,"just to clarify : how many $ x_i $ do you have , and how rare are the non-zero $ x_i $ typically ?"
91785,possible duplicate of [ how often do you have to roll a 6-sided dice to obtain every number at least once ?
91796,"when you say that your independent variables are not categorical ( "" built around categories "" ) , do you mean that they are continuous ?"
91813,"some clarifications are needed regarding the structure of the data ( for each stock separately ) : a ) do you look at signals of period $ t $ in connection to returns in period $ t 1 $ , or signals at period $ t $ and returns also at period $ t $ ( because , say the sequential relation happens in the same time period given how you data is temporally grouped -e . g . you look at days and the signal happens at the beginning of the day , the return at the end of the day ) b ) in each period , does either a positive or a negative signal occurs , or both may occur ?"
91842,possible duplicate of [ how to report a svm model to a 3rd party after cross-validation ?
91885,"sorry , why use so many iterations ?"
91898,are you trying to implement irls ?
91897,you seem to have dropped an $ r $ from step 1 to step 2 . . . also is $ t $ supposed to be inside of the probability statement ?
91936,"it depends on the definition of "" street . "" would you count a contiguous set of polylines with the same street name as a single street or as multiple streets ?"
38476,have you looked at a latent class model ?
91930,it depends on how you suppose $ y $ might depend on $ x_3 $ . could you tell us more about what these variables mean and how they have been measured ?
91955,is your question about statistics or about programming in java ?
91969,"consider : what events ( situations ) are included in "" at least seven females "" ?"
91975,what hinges on what you call it ?
92004,could you explain why you need to invert this matrix ?
3466,"when you say "" condition "" , do you mean group assignment ?"
48835,is this aic on aic ?
92063,are these animated or taken from a still position ?
92062,"if it's not a big secret , what are the values ?"
92076,"on what do you base your statement that the plot "" shows signs "" of significance ?"
92077,"your question asks how to get started . unless you can articulate a more specific problem or description of where you are stuck , i would recommend reading the r documentation for random number generation functions : ` ?"
92085,""" * i would like to compare these two sets of data samples and determine whether the null hypothesis holds . * "" -- but you haven't stated one , nor alternatives you want power against . what is it you want to test for ?"
92101,why do you normalize the values to be $ in [ 0 ; 1 ] $ ?
92109,"you had 10 ` x ` variables and 11 groups . hence , you extracted min ( 10 , 11-1 ) = 10 discriminants ` ld ` . it looks like "" group means "" are indeed themselves . why not ?"
92147,"i don't have matlab in front of me , but except for some really basic functions , probably written just as c calls , you can examine code for functions in matlab . op might do that- it will probably also list references for where the used formula comes from . in addition to the matlab community , i frequently had success with just googling my matlab question . the product is sufficiently used that this can work . finally a stupid guess- might it have something to do with putting in / taking out means of the data ?"
92174,you should start with looking at the data . maybe you could show some graphs ?
92209,""" * i can't get a confidence interval for the population mean , because i can't calculate the standard deviation of a single sample mean . * "" -- you can't ?"
92221,"` b ` seems to have a less-than-tiny effect size at least . i don't see any harm in reporting these effects if they're of interest . with a sample size this tremendous , you can get some pretty sharp confidence intervals on those estimates . that's gotta be worth something , right ?"
91814,"i find the description confusing on two counts : ( 1 ) it would seem that if an attacker has a 60 % chance of winning , then a defender would only have a 100-60 % = 40 % chance of winning , not 70 % . what is wrong with this understanding of the situation ?"
92241,what is the goal here ?
66227,""" tractable "" is a function of your hardware as much as it's a function of your data . will you be running this on conventional hardware ?"
92271,"i'm confused by "" there are 2 possible actions : a user can click on the ad or a user can not click on the ad . "" if you're trying to decide which ad to show , shouldn't the ads be the actions ?"
92288,"if you know the parameters already , you have the whole population distribution already specified . what would you need standard errors of sampling distributions for ?"
76165,your question is not clear . are you experiencing a confusion between a confidence interval and a prediction interval ?
92223,is there public documentation on ` rxdforest ` ?
92317,is preferred distance ordinal or nominal ?
92335,is this a [ tag : self-study ] question ?
92351,just curious : what's the problem with too-perfect data ?
92255,could you edit the clarifying information into your question ?
92374,"there's no point testing ; every test of any use at all , a any reasonable significance level will clearly reject . whatever guide you're reading has misled you . what do you mean by 'reliable' exactly . what 'limitation' of the shapiro-wilk do you refer to ?"
92397,"saying 0 . 39 cophenetic r is "" poor "" is just because fear has big eyes . your clustering structure isnt' too strong this time . so what ?"
92427,"as a first , easy step , i suggest jittering q [ , 1 ] . i also suggest a univariate look at both , but especially q [ , 2 ] . finally , can you tell us what these variables are ?"
92443,can you explain more about your analysis ?
92391,""" meow "" ?"
92498,not sure i understand . did you give new ` x ` values to the ` predict ( ) ` function as the second argument ?
92544,did you try anything at all ?
92579,"what appears at the channel output is determined by the distribution of the input and the channel transition probabilities . however , the channel capacity is determined by the channel transition probabilities alone . are you sure you are not being asked what rate of transmission is achievable given that the input is constrained to be such that the channel output distribution is as given ?"
44798,"you state that "" there are no residuals over data points where i'd like to make a prediction "" . is your ultimate goal to make a predictive model / to use this in the future to make guesses about $ y $ when you know $ x $ ?"
23783,how large is your data ?
92657,"this seems to be backwards . you don't decide your hypothesis * after * you've done the experiment , you do that * before * . it is your hypothesis that guides everything from experimental design to making inference after you've collected data from the experiment . the question still remains , * what is your hypothesis ?"
92627,"i don't quite follow your question . the expected value of a [ poisson distribution ] ( url ) is $ lambda $ , the mean . that doesn't have anything to do w / r . if you have expected & observed values , you can do a chi-squared test manually in r ; i show how to do that here : [ what is wrong with this chi-squared calculation ?"
92736,"i may have misunderstood your data in my response . i now think i was led astray by the word "" initial "" . do these numbers represent final outcomes ?"
92709,why do you need the residuals to be normal ?
92779,non-normality of variables doesn't preclude them from pca . so why did you decide to use nmds and how did it help ?
92814,how many different terms does the union of your sets contain ?
92821,"you need to do panel-data econometrics while being "" new "" to econometrics ?"
92838,if you have a fixed effects model : why do you apply a package explicitly written for models with random effects ?
92760,your new code is mysterious . are you trying to roll your own linear congruence pseudo random number generator ?
92720,correlation with what ?
92935,that fit looks terrible ; it's always below the data - how did you get that fit ?
92776,"` rnorm ( 15 ) ` ( you don't need the "" 0 , 1 "" since those are the defaults ) gives you a sample of size 15 . you need the median of that sample , right ?"
92737,"i guess that in the second case you have a more sophisticated random effects structure than you expect , specifically some correlations among the random effects that explain variance . those effect help to achieve more accurate estimations of the fixed effects , hence the differences . can you post the random effects output of all the models ( i . e . , the upper part of summary ) so that we can confirm that ?"
92686,"can we see what it this "" intersection "" property ?"
92975,"remember where these conditions come from : $ y $ is the quantile of order statistic $ j $ and $ y z $ is the quantile of order statistic $ k $ with $ k gt j $ . thus $ y $ , being a quantile , cannot be less than $ 0 $ ; $ y z $ , also being a quantile , cannot exceed $ 1 $ ; and $ z ge 0 $ . therefore $ y $ must be integrated from $ 0 $ to $ 1-z $ under the assumption $ 0 le z le 1 $ . when you are integrating over $ y $ , $ z $ is a constant--and this gets us back to your question . what is confusing about the presence of a constant in an integrand ?"
92972,you can compute a confidence interval of most things by bootstrapping . does that help ?
92982,is this a homework problem ?
93007,over-dispersion is something to watch out for - is the spread of proportions for different participants unexpectedly large within each condition ?
93009,"as a slight aside , what is the value to you of fitting a smooth distribution as opposed to using nonparametric or semiparametric methods ?"
93045,"are all of the datasets simulated in similar fashion , and might you share a representative portion of the code ?"
93062,why not just include ` side ` as another factor in your anova ?
92923,it sounds like you want to solve problems induced by two rather uncommon steps ( splitting and size matching ) . thus the question : why not running a single logistic regresdion on the full sample ?
49011,""" it includes non-parametric statistical models "" is what gives that impression . references on definitions of the terms ?"
93229,are these functions from some parametric distribution ?
93263,"i don't think this is an appropriate way to test what it sounds like you're interested in - for a couple of reasons . rather than ask how to implement some solution to the problem , why not ask the assembled experts about your underlying problem ?"
68247,"avoiding phrases like "" statistical significance percentage "" and undefined terms like 'better' ( what the heck does better mean here ?"
93280,"( 1 ) what's your model to be used for , & what's the goal of selection ?"
93161,how many number of items included in that question / construct ?
93289,so . . . conditional probability ?
93316,heard of the delta method ?
93343,"i assume you mean "" sample mean "" $ bar { x } $ as opposed to the population mean ?"
93363,do you have multiple measures of each variable over time ?
82497,"i can't follow your code ( i'm not r user and i'd prefer to see actual _data and results values_ rather than unexplained pictures and unexplained code ) , sorry . what do your plots plot ?"
93539,"what do you mean by "" instruments' ?"
93560,can you please provide an output of the two ?
93614,did you look at the code ?
64744,what are you estimating when you weight individuals' scores with weights derived at a group level ?
93601,can you say any more about what r packages / functions you actually used to get these results ?
93099,szabolcs : have you thought of gradient free methods like sim . anneal and / or genetic algorithms ?
92625,why would you want that ?
93672,"my first question , would be , what tool would you prefer to use to do a linear regression ?"
93645,when you say 'test the preference' what do you mean exactly ?
93689,there are only 8 combinations of 3 variables that don't involve transformations or powers . i think i am misunderstanding what you did . can you give some examples of the 400 ?
93680,"another aspect is the number of categories . without reference , i think there is some simulation research that has shown likert scales with more than 5 categories can often be treated as continuous . if i remember the reference , i will post it below . nevertheless , can you explain your major reason why you do not want to model the outcome variable by ordinal regression such as proportional odds models ?"
93700,is it possible that only discrete distributions of the one parameter exponential family are stochastically increasing ?
61446,why chernoff bound rather than exact computation ?
93797,is this a homework problem ?
93853,about leverage : try to imagine how the regression line would look like . then remove one point at a time and draw the regression line again . does the fitted line move a lot ?
93874,"if the issue is the fact that your data can have negative values , well can't just shift it to the right ?"
93882,"would the value of 1 , 000 , 000 occur 1 , 000 , 000 times ?"
93892,do you know what degrees of freedom you want to use for the t statistics that you see in summary ( m4 ) ?
93781,it sounds like you are looking for item fit statistics for detecting potential misfit . is this what you are after ?
61325,"i suspect there is no state of the art approach to the problem of estimating a response at a specific time . the reason is that gee estimates a population average given a covariance structure . if many drop out prior to time $ t $ , the ( unweighted ) gee assumes that fraction is not part of the population . weighting could upweight other clusters who are like those who drop out , but i echo the concern over consistency issues ( infinite weights ) . have you considered marginalizing a mixed model or predictive models with a bootstrap instead ?"
92481,i really can't follow this . can you state what you are trying to do more plainly & w / o the jargon that you might expect statisticians want to hear ?
81937,what are the triplets ?
93971,"what do you mean by "" qqplot seems to be significant only after ~ 1k points "" ?"
93610,"this ends up being a faq , see [ in linear regression , when is it appropriate to use the log of an independent variable instead of the actual values ?"
94016,"if your aim is actually prediction , hypothesis tests would seem to be the wrong tool altogether . wouldn't out-of-sample predictive ability be a way to identify a good predictive model , suggesting sample splitting / cross validation and like approaches ?"
94017,it is unclear what you are testing in the second line . exactly what is being compared to what ?
94047,"when you say that there is parameter $ a $ , do you actually mean that there are $ k $ separate parameters $ a_1 , ldots , a_k $ ?"
94083,hint : think through the statistical procedure to determine statistical significance of coefficients . what is the coefficient estimate compared against ?
94087,"* data * doesn't have a p-value . a p-value is associated with the test statistic in a particular * hypothesis test * . so start by working out which particular hypothesis and alternative you might be dealing with and which hypothesis test goes with it . it looks like a one-sample test of means might be required , but it's not at * all * clear what the hypothesized mean might be . did you leave information out ?"
94020,"your impression that it's quadratic is driven almost entirely by a single point ( cover that point , the relationship looks linear ) . you're very reliant on that one point being representative of firms with high roe ( what if there's something that makes it atypical ?"
94136,did you read this in a paper about deep learning ?
94141,"since the normal is continuous , specifying 'discrete' already means it can't be normal . it is * not * a general property of the poisson that $ p ( x 0 ) = p ( x 1 x 0 ) $ ( you may be partially confusing it with the geometric ?"
94150,"there really isn't a clear question here . although you ask for a reason why you cannot "" perform pearson correlation , "" you actually have done so , as evidenced after "" obtained the following result . "" from the comments it sounds like you should change the entire text of your question to read "" why is the pearson correlation $ pm 1 $ when only two distinct data values are available ?"
94162,"can you make more precise predictions than "" larger "" ?"
94192,an unbiased estimate of what ?
94201,use a * mathematical * definition of independence to resolve questions like this one . what definition do you know ?
94216,"this may be a moot point , but why did you use excel to create the q-q plot , instead of using r's qqplot ( ) ?"
94239,"in what sense are you going to "" estimate "" the random variable $ alpha $ , by maximizing some objective function that includes it ?"
80824,. . . which is what and does what ?
94424,"ok , so what are the replicates for each subspecies , different days , different sites ?"
94425,"your title seems inconsistent with the body of your post . do you want the question in the title answered , or the much more specific ones in the body of the post ?"
94442,which test of independence are you running ?
94454,"what do you mean by "" dendogram structure "" ?"
94473,"but i think the answers to that question answers your question here . anyhow , it is unclear what sort of answer you are after . can you please explain what is unsatisfactory with the already given answers ?"
94040,do you really need the notion of a latent class ?
94477,what * exactly * are you trying to do ?
94495,is this a homework question ?
94526,i'm a little confused by your problem . are you sure you don't want latent class analysis instead of cfa ?
94530,""" * but looking at the p-value i fail to reject the alternative hypothesis that that my sample is log-normally distributed * "" -- this doesn't make sense . for starters , wasn't your null that it was lognormal ?"
94539,how do the probability values arise ?
94570,"your title question seems quite different from the two questions in the body of your text . the title question is easily answered ( yes ) . can you clarify what is intended by "" statistically identify "" ?"
94609,"when two objects have no features in common , how would you propose to assess their similarity ?"
94621,"what have you tried , what have you looked into ?"
93530,"yes , that's what i meant . is your interest in identifying each one that's significantly different , or just that some are in fact different from others ?"
45696,might it be a case of overfitting ?
94248,any particular reason you're not using the standard pearson or deviance residuals ?
94689,"nick i don't agree - software specific questions have always been on topic , as long as there's a statistical element to the question ( "" what are the steps to get lambda ?"
94649,this seems like an algorithmic question and would get more exposure and possible ideas if it were moved over to so ?
94721,"you need to undertake an analysis of this expansion , because you have assumed incorrectly that the ( infinite ) sum has converged once its terms are sufficiently small . half the time that is not the case . there are other subtle errors embedded in this code . for instance it can fail in calculating ` gamma ` and ` factorial ` . it is also inefficient : by directly emulating the mathematical formulas , it performs far more calculation than needed . since this effort is a self-study exercise , why don't you refer to a good numerical analysis text ?"
94796,"glen_b hmmm , the ( 1 / 2 ) might be a mistake . the 1st-derivative has a $ beta_j $ at the end , so evaluated at $ beta_ { j0 } $ we get $ beta_ { j0 } cdot ( beta_j - beta_ { j0 } ) $ and then they use $ beta_j approx beta_ { j0 } $ to get the difference of squares . but then again , why $ beta_ { j0 } cdot beta_j = beta_j ^ 2 $ ?"
94843,"that edit isn't an improvement . what makes the distribution "" nonparametric "" ?"
94857,are you looking for something more sophisticated than just replacing those entries with 0 ( or some value you know to be the smallest possible measure ) ?
30942,"joeking , i'm actually not sure what ` mcmcglmm ` is doing so i can't answer your question . is it fitting your model in a bayesian setting ?"
94885,polygeo is it really necessary to have a software platform in mind in order to understand and answer this question ?
94914,"with a table like that , where the p-value is bigger than the largest available significance level ?"
94938,what do you mean by predictive quasi-normal log-likelihood ?
94947,"let at least one of $ alpha , beta to infty $ . e . g . let $ alpha = beta $ and let them both $ to infty $ . what happens to the variance ?"
74295,"not familiar with mahout , but does it seem plausible that a unit change in ` cs ` changes the odds of ` anw ` by a factor of 300 million ?"
95002,independent random variables ?
95013,what's the point of this ?
95015,""" qualitatively different "" is basically "" is this different enough to matter ?"
95058,what is you data at the moment at what it should be ?
95081,"let me make sure i have this right : you have a function $ f ( threshold , s , t ) $ that you'd like to maximize , is that right ?"
95094,"what is "" the study "" to which you refer ?"
41274,"i think i get the gist , but the specific question is unclear . are you asking for the chance that this process reaches $ 4 $ * at least once * in $ 10 $ steps ?"
95065,why don't you just measure column-wise ?
95145,"clustering is clustering , unsuperwised method ; regression tree is classification , superwised method . why to expect them to agree ?"
95054,what statistics do you want exactly ?
95169,how much data ?
95172,can you give an example of what kind of interval you mean ?
95061,can you provide us your sample data ?
95351,"so you have a clients table with client name and attributes ( e . g . sector ) and then you have a products table with product name / code and atttributes ( e . g . colour , size , type , etc . ) , is that correct ?"
95359,can you explain why you are using a normal distribution ?
95383,"you provided no context , especially with regard why it is relevant to cascade sets of predictors . how many regression courses have you taken ?"
95364,"are the subjects grouped according to how many times items are presented ( so in group 1 , everyone gets 3 presentations per day for 4 days ?"
95416,"to further alecospapadopoulos' comment , what do you mean by "" the white correction "" ?"
17685,can you distinguish the items or just their colors ?
95466,the first word of the quoted question should be not ` students ` but . . . ?
95477,"the adjectives "" parametric "" and "" nonparametric "" don't apply to data . can you explain what you mean without any technical terms ?"
95475,what article ( s ) do you refer to ?
71754,"what are ` a ` , ` b ` , ` c ` in ` j ` ?"
95516,could you please edit your question to clarify your objective ?
95517,"what problem , precisely , do you encounter in fitting this model with ` nls ` ?"
95514,are you sure you're reseting the seed * every time * you run the sampler ?
95522,"can you add details : what data you simulate , how do you perform the gibbs sampling and what the results look like ?"
95603,"are you asking for a name for it , or a functional form for the density ?"
95407,"what do you mean exactly by "" purchase decision which will be my dependent variable but it does not exist as it is in data "" ?"
95677,"it * seems * that you ask a simple question , but it is couched in highly technical language . that language would suggest your question ought to be read with great care and caution to make sure every aspect is correctly interpreted , in order to appreciate any unexpected subtleties . in particular , exactly what is "" $ f_ { nj } $ , "" how does it differ from "" $ f $ , "" and why are you using pairs of subscripts on it , including one ( $ n $ ) which seems to be fixed ?"
95681,"see the fisher-tippett-gnedenko theorem at url for instance . its conditions raise the question , what exactly do you mean by a distribution not "" known "" ?"
95688,why do you need 8 rather than say 6 digits ?
95643,"would any part of your question change if you were to interpret the "" coin "" as a metaphor for some binary process about which you had no prior knowledge ?"
95742,do you assume that everyone who would fail both post tests would fail the review ?
95751,is this a question at all ?
95752,are you especially interested in if you have a complex root ?
95741,"what is the topic of this course , and is it introductory-level ?"
95484,"i am not so sure if i understood properly , can we consider the decision support system as a prediction model ?"
95807,do you mean the values after imputation ?
95809,"are the responses independent from year to year , or do you have responses on the same individuals for each of the 5 years ?"
95818,to clarify . you are using [ scikit learn ] ( url ) ?
95847,"for the mle , certainly $ lambda $ is a constant : * but what value does it have ?"
95908,"your question is kind of vague ( and the edit makes it also very broad ) . further , what's "" source stream characterization "" ?"
95831,"so just so i am clear with what you are asking , you are attempting to compare the emmissions of people and you want to correct for differences in the variables people , area , and gdp ?"
95958,"what exactly do you mean by "" error for linear regression "" ?"
95939,you posted a question relating to your use of ` poly ` without typing ` ?
95956,how do is it possible that bernoulli deviates have a mean of 12 ?
95963,do you know the sample sizes of sets $ a $ and $ b $ ?
95957,can you clarify what you mean by multivariate regression ?
95995,"1 i have the same question yet slightly different . i was wondering if one needs to simulate a trend anyway , if one assumes a specific difference after e . g . 10 years . simulation of glm trends takes ages ! a quick binomial proportion test could be just as fine , but from your findings it seems they differ strongly . maybe due to the possible variation along the trendline ?"
96027,tim can you attach your data to the question ?
96038,"what do you mean "" analyze the clusters "" ?"
95432,can you clarify why you believe regression models are necessarily * stateless * ?
96082,what are the explanatory variables ?
96055,"what do you mean by 'of the posterior' in 'suppose also that the random variables $ x_1 , x_2 , ldots , x_n $ of the posterior are mutually independent' . do you mean that you are assuming the conclusion ?"
96105,"homoscedasticity means equal variances . i would expect whenever homogeneity is mentioned in a statistical context , it would also imply that something is constant on average , but quite what would depend on context . as you don't explain the doubt ( "" perhaps "" ?"
96120,"i do not quite follow your comment about using chi-squared tests for interactions . i gather your data are appropriate for a logistic regression & you can use tests w / chi-squared distributions in lr , can you clarify your comment ?"
96026,"( 1 ) i don't know , but hoping to prompt someone to give answer related to your split sample / test set ( 2 ) i'd train on whole calibration set . the validation was to validate the process and not the model , and to estimate optimism . ( 3 ) is your test set large enough ?"
96164,it depends on how the removal occurs : are you saying each user is removed independently with probability $ 1 / 3 $ or that literally every third user is systematically removed ?
96012,is the change a spike ( a one time thing ) or a level shift ( so the mean is now at a different level ) ?
96167,"the title phrase "" decrease by less than 100 "" is misleading . i suggest "" decreases by more than 100 "" is actually the correct expression . consider answering "" * how many points of decrease is shown in the image ?"
96144,are you asking about the applicability of these tests when residuals have strong correlations or are you just concerned about the ( very slight and inconsequential ) negative correlation arising from the least squares estimation procedure ?
96228,"for the sake of clarity , what you are saying is not that the clusters that come from different algorithms overlap ( which is to be expected ) , but that you are using algorithms designed to produce overlapping clusters ( eg clumping ) . is that right ?"
96190,woman are less likely to say yes than man ?
96314,""" * the first p-value 0 . 06 , is this the probability that they are equal , or that they are not equal ?"
96350,what programming language is your code sample ?
96145,"there are several completely different results known as "" cramer's theorem "" ( or "" cramr's theorem "" ) . to which one do you refer ?"
96250,"when you you say "" study each group "" are you thinking about something like a multiple regression model , or are you thinking of something else ?"
96415,what is your observation ?
96325,"atom coordinates are multidimensional , right ?"
96479,why only 17 measurements ?
96501,what does an roc curve have to do with it ?
96507,isn't it auto . arima ( ) ?
96371,"some context and clarification would improve this question . ( 1 ) * in what context * do these ( hypothetical ) intro texts assert the mean is to be preferred , and for what purpose ?"
96571,it is not clear which transformation you have in mind . is it standard score ?
96576,there are questions for you that are not so far about imputation . are you doing 280 1 fas ?
96613,"in your question , you state "" we should be able to make a prediction . . . of the * independent * variable based on knowing the * dependent * variable "" . usually , we think of our model as predicting the * dependent * variable based on the * independent * variable . was that a typo , or are you asking about reverse regression ?"
96617,"first , let me say that implementation is really nice ! i'm a bit confused about the algorithm , though . how exactly did you add all those probabilities and not go over 1 ?"
96619,"if you want to get the attention of someone who has commented you need to put in front of their name , like so : * glen_b why is the variance constant ?"
96621,is this question about customers or websites ?
96612,where do these data come from ?
96633,"apart from the target scores , what else is available ?"
57468,i assume you have declared your matrix as sparse in matlab . is your $ a $ square ?
96683,"is the question of interest "" is the new one better , no matter by how tiny an amount , as long as it's more than could be explained as random variation ?"
96604,"can you give a citation or two for "" the law of uncertainty propagation ?"
96708,notice that your density function is an average of density functions of gaussians with standard deviation $ h $ and different centers . does that clarify why you're using this formula ?
96737,how do the effect sizes compare ?
96749,"the algorithm described in the last paragraph will , with rare exceptions , terminate only when each cluster has one or two points : that's about the only way a cluster can look perfectly "" normally distributed . "" if instead you allow for slight deviations from normality * it is not appropriate to use the p-value of a hypothesis test for such a measure * ( except in the very special case when all clusters have the same counts ) . this leaves you with a bunch of problems but , as of yet , no clearly articulated question . * what exactly are you trying to accomplish in the end ?"
96794,"when you say that there is a 1 % fitted difference , do you mean that the predicted probability increases by 1 % ?"
96759,possible duplicate of [ is common factor analysis ever performed using the covariance matrix ?
96832,"it is not clear what you mean by "" model "" and "" estimation . "" do you have any data ?"
96907,there are several [ references and links listed on the wikipedia page ] ( url ) . are none of those what you are looking for ?
96946,"( 1 ) the likelihood is seen a function of the parameters conditional on the ( fixed ) data . your prior and posterior are distributions over the parameters . in some cases of conjugacy , the likelihood can be seen as a distribution over the parameters of the same form . ( 2 ) i am not sure what you mean here . what sampling are you referring to ?"
97016,"please tell us what you mean by the "" order "" of a statistic . do you mean its asymptotic behavior as $ n $ increases ?"
97030,"your predictors $ x_1 , x_2 $ are ordinal , but how is your outcome measured ?"
96999,"he doesn't advise that at all : "" if collecting zeros were costless , we should collect as many as we can get , since more data are always better . "" if you've already * got * the data then what's the extra cost of using all of it ?"
96809,"what is a "" use case "" ?"
97078,what is a model you are fitting ?
97116,"ok , in that case , would it be safe to say that you would like the metric to give equivalent results for cases 4 and 5 , because there is no 1 : 1 from specimen_type to gene position . also , is the kind of specimen always a binary variable ( black or grey ) ?"
97123,do you actually have distributions of score data ?
97144,"just a thought : are the tasks of uniform difficulty , or are they all different difficulties ?"
97180,"please carefully note the import of "" as if "" in the final sentence . the intent of my comment is * exactly * in accordance with your comment of "" doesn't change the fitted coefficients "" . it's a way of seeing both the coefficients and the sum of squares in a single framework . i am talking about type i sum of squares , since that's what you asked about . is your final sentence there an additional question or an attempt to clarify your question ?"
63003,what exactly are you predicting ?
38844,"there are many alternatives , even within ` pairwise . t . test ` . type ?"
97280,"given $ theta $ , what is the probability of seeing $ x $ out of $ n $ heads ?"
96377,"from your description , i'm guessing you mean that corruption is your * dependent * variable , and i'm guessing that it is ordinal as well at press freedom & democracy . is that right ?"
97249,can you post your data ?
97234,"number of m & m's is a ratio scale , so anova is tenable as to scale . are you asking if you can add handedness as a factor to the anova ?"
97342,p-random ?
97062,is f a function ?
97384,why not just excluding the actual missing data ?
97398,"ok , but did you notice that one is using z-test and the other one is using the t-test ?"
97408,how do the two differ ?
97381,"let me clarify , what do you expect to be in s at the end of this ?"
97165,what does the last sentence mean ?
97453,"honestly , i did not quite understand what are "" structural variables "" - you didn't give definition or characterization . also , think - do you really need clustering . maybe you need just binning ( categorization by hand ) ?"
97471,this question doesn't seem so bad to me . a value that tiny for the determinant strikes me as suspect to to a * very near * ill-conditioned correlation matrix as the input for ` factor ` . so you might reorient the question to something along the lines ` the determinant of my correlation matrix is * really * tiny - should i be worried about the results of factor analysis ?
97109,"a special case of this situation is when there is a single * constant * covariate . if i understand your plot correctly , in this case your question seems to amount to "" is it possible for the mean of a dataset to be less than its 10th percentile or greater than its 90th percentile ?"
97508,"have you tried to write the equation for $ y_t $ by substituting for the analogous expression for $ y_ { t-1 } $ and then go on , recursively backwards ?"
97543,1 ) looks like a request for code . 2 ) implies that your regression is a very poor fit . what kind of advice do you think we can give ?
97456,do you know for a fact that it's linear and then changes ?
97625,are you aware of any papers that fit probability models to music frequencies ?
97684,"shouldn't $ p ( a_1 cup a_2 ) * p ( a_3 cup a_4 ) $ be $ p ( ( a_1 cup a_2 ) cap ( a_3 cup a_4 ) ) $ , since your events are non-mutually exclusive ?"
97582,"what do you mean by "" scaling the ordinal response "" ?"
97690,have you put some numbers through and observed whether the results are different for the two formulas ?
97392,what do you do with volatility ?
97717,"is the intervention at the cluster level , or the individual level ?"
97722,"although i can find plenty of annotated outputs of spss binary logistic regression on the web , * none * of them directly provide confidence intervals , but they all report standard errors ( from which cis are easily computed ) , including for the constant term . do you think you could document the behavior you are asking about by means of a reproducible example ?"
97734,"i am wondering if any they have shown any additional tests for reliability or determining strength of agreement , like concordance correlation coefficient , interclass correlation coefficient etc ?"
97774,do you want to first correct your code ?
97882,is this not simply an artifact of discreteness ?
97896,what hypothesis ?
98956,"if $ boldsymbol n $ is a vector-valued random variable for the outcomes of $ 100 $ trials , the relevant distribution of $ n $ is multinomial with $ n = 100 $ and $ k = 3 $ possible outcomes per trial , with probabilities of outcome $ j $ equal to $ p_j $ , so $ n_1 n_2 n_3 = 100 $ and the pmf is $ $ pr [ boldsymbol n = ( n_1 , n_2 , n_3 ) ] = frac { 100 ! } { n_1 ! , n_2 ! , n_3 ! } p_1 ^ { n_1 } p_2 ^ { n_2 } p_3 ^ { n_3 } . $ $ under the null hypothesis , what is the probability of observing $ boldsymbol n = ( n_1 , n_2 , n_3 ) $ ?"
97845,"i'd suggest , if at all possible , to avoid including code that deletes all variables ( ` rm ( list = ls ( ) ) ` ) , especially not without any warning . someone may copy-paste your code into an open session of r where they have some variables already ( but none called ` x ` , ` y ` , ` df ` or ` spline1 ` ) and miss that your code wipes out their work . is it kinda dumb for them to do that ?"
98976,"it isn't clear to me what is going on here . what do "" networks "" have to do w / anything ?"
99036,i think it is critical whether $ x $ and $ y $ are dependent or independent . it is not clear from the question . are they independently distributed ?
99047,what is ` lda ` and ` predict ( ) ` and what does ` cv = true ` mean ?
99053,what model / hypothesis do you want to fit / test ?
99088,what are you going to use this measurement for ?
99080,did you read the [ wikipedia article ] ( url ) on mcnemar's test ?
99094,"covariance is natural for variables without inherent origin . we then compute mean as the origin ( mean have nice properties not relating to the theme of association , so it is typically chosen ) . if the origin is inherent and is meaningful , it is reasonable to stick to it , then "" covariance "" ( co-outburst ) won't be symmetric , but who cares ?"
99106,could you please add the research question to your ( interesting ) setting ?
99085,"as this is a self-study question , could you please add the [ ` self-study ` ] ( url ) tag ?"
99117,yakkanomica : what would the caveat warn of ?
99083,how many time periods do you have ?
99148,if you have 80 values and 80 conditions there is little or nothing you can do . is that a typo ?
99158,why is it a problem if some variables have high kurtosis ?
99168,"please , clarify for me . is x1 a group of training examples with positive labels , and x2 a group with negative labels , and x3 a group with mixed labels ?"
99086,could you give a complete reference please ?
97346,how are you identifying which windows to use to put into the anova ?
99170,"when there are no ties in the dataset , how many values $ x_i $ exceed the median ( and therefore the residuals $ x_i- text { med } { x_j } $ have signs of $ 1 $ ) , how many values equal it ( whose residuals thus have signs of $ 0 $ ) , and how many values are less than it ( whose residuals thus have signs of $ -1 $ ) ?"
99228,do you have a small numerical example ?
99267,have you tried centering ` ii ` ?
99145,"you're correct that you'd reject the null for sufficiently small values , since that would indicate the likelihood for the null was unusually low if the null were actually true , indicating the ratio is smaller than it would be expected to ordinarily be . can you write a rejection rule and manipulate it - pull constants out , transform , etc ) , so you're only dealing with a comparison of some simple statistic , $ t ( mathbf { x } ) $ with some other constant , say , where $ t $ will have some known distribution ?"
99324,i've written simulations in r for random effects meta-analysis . would it be possible to do that ?
99336,"i am not sure whether or not i agree , but to be more sure i need to know what you mean by "" functional form "" : ( 1 ) simply that the effect of $ x $ on $ y $ is linear ( i . e . that $ y = b ax e $ for * some * values of $ b $ and $ a $ ) ?"
99347,do you really want to cluster your data based on text similarities of people names ?
99356,"you say you "" know "" the subgroups exist and then you say you want to "" find out "" if they do . do you mean you want to find which subjects go into which cluster ?"
99371,"if size is a problem , you don't necessarily have to use the data in a given set . generally speaking , data set providers don't provide hypothesized relations ; that's up to you to implement . have you tried getting a proper book on cognitive diagnonsis modeling ?"
99398,do you mean one only has 20 cases and the other one has 40 cases ?
99415,why not add an interaction term and run a multiple logistic regression ?
99442,a logit regression ?
99376,"your question asks to "" plot the extra info below in circle . "" because your needs are clear to you , i am confident it will be no trouble to explain how a p-value should be plotted . in your example it is given as "" 0 . 100 "" . exactly what graphical elements would you like to see added to this normal probability plot to represent this quantity ?"
99469,see ` lme4 : : : ranef . mermod ` and url to start ?
99473,is the simulation deterministic or stochastic ?
99558,i find your reasoning hard to follow . you are searching the correlation between which parameters ?
99543,"is there some reason the obvious answer "" asses a classifier using these features "" isn't applicable ?"
99572,is your dataset cross-sectional ?
99586,can you clarify your question / the thinking behind it ?
99589,"solving this will require some thought about your assumptions . it is plausible that after falling on one step , a person's chance of falling on the next step might increase . to address that you will need to assume some quantitative relationship--or have data . on the other hand , perhaps this question is just a metaphor for some other kind of event in which the probabilities are * independent . * which interpretation do you need addressed ?"
99599,"it's not clear what your question is , because you say you have been doing regression . this problem presents several difficulties , such as reporting data in two-year intervals ( which conflicts with the statement that these are "" annual installations "" ) and the vague and confusing note at the end . where exactly are you looking for help ?"
97796,"might you consider a two-sample anderson-darling like statistic ( rather than kolmogorov-smirnov , because it puts more emphasis on the tail , where your interest seems to lie ) -- that is , to look at the difference in distribution between a blank image and the other image without specifying the distribution of either ?"
99667,just an idea : what about adding a classifier to predict whether a given question is english or italian ?
99659,"what is the meaning of $ i = [ 0 , 100 ] $ ?"
99729,"is the response variable "" connections "" a binary outcome ( 1 if connection occurs and 0 if not ) ?"
99370,"i'd say that $ cov_ { school } $ a ) is not the covariance between students within the same school , but one of the _correlation_ coefficients between the random terms , b ) it should be $ sigma ^ 2_3 / ( sigma ^ 2_1 sigma ^ 2_2 sigma ^ 2_3 ) $ . am i wrong ?"
99754,"you didn't make it clear in your question if the number of predictors is finite / small . in the cars example it is , right ?"
99775,does ar1 even make sense if your time variable is a factor ?
99796,"that's pretty close , but perhaps not quite solid . try letting $ s t $ ( without loss of generality ) and think about $ text { cov } ( y_t , y_ { t-1 } ) - text { cov } ( y_s , y_ { s-1 } ) $ . can you show it's necessarily positive ?"
99865,are you interested in mean $ given or proportion of donors who resume giving ?
99909,can you provide the code how you fit the conditional logit ?
99946,is all that white space necessary on the image ?
100067,isn't a hidden markov model a very general class of models ?
99932,could you not stratify your model based on your time interaction ?
100085,does it make sense to think that non-dyslexic people have an easier time reading the more obscure the font is ?
100093,"although i formatted this question for readability , it is still incomprehensible . neither of the code sections looks like valid code or output--pieces evidently have been stripped out of them . how are we supposed to be comparing the results ?"
100154,"first , robpca found 25660 outliers , not 4000 as you claim . this makes me suspect you don't really understand what you are doing . concerning the error message you get : do you understand it ?"
100183,"have you got any way of comparing the characteristics of the different offers , like variables that describe their features ?"
100029,can you give a concrete example of what you're interested in ?
100245,"sorry no clear to me . you have different datasets df1 , df2 , . . ?"
100251,"the hard part is determining what constitutes a "" communication pattern "" and how to evaluate how similar two such patterns are . what do you propose for this ?"
100284,you want ` svychisq ` not ` chisq . test ` -- see examples at the bottom of ` ?
100282,can you assume that the missing data is mar ( in the terminology of rubin ( 1976 ) ) ?
100358,have you stored a and b as factors ?
100378,although it's not clear what $ x $ and $ y $ are--perhaps they are dimensions of rectangles that approximate the rois ?
99587,is this a self-study question ?
100417,[ what is meant by a random variable ?
100434,are you asking about estimating central tendency from your sample by taking the mean or median of responses to a single item from all respondents ?
100464,so you deleted those observations that had less than 3 of the 10 iv ?
100463,"we need more details . first , $ alpha $ here need not be a probability ( the acceptance ratio is a better term since the numerator can be larger than the denominator ) . next , is the score a posterior density ?"
100467,what probability rules did you use to arrive at your first calculation ?
100509,what statistical analysis package are you using ?
100385,i do not follow you . what are your data : are they the $ n 1 $ values of the $ x_i $ or are they the * single * value of $ y $ that is mentioned ?
100510,are you somewhat familiar with moment generating / characteristic functions ?
100553,are you asking what happens if the most probable value is * sampled * or are you asking what would happen if we always just take the mode of the conditional distribution at that step ?
90363,"looks like a clt thing to me too . maybe it is already obvious to you , but as theta- infinity what happens to n ?"
100478,""" * does it mean these two distributions are different with a 95 % of confidence ?"
100670,anova is regression . i don't understand your question . maybe you're confused why the two outputs differ ?
99652,"the graphic suggests you are expecting the points to be ordered from d through a along the stress axis . ( if you were not , then you would have placed point b approximately at ( 3 , 27 ) and d around ( 2 . 2 , 36 ) . ) is such an ordering of the deformation points a constraint you wish to impose on the estimates ?"
100752,i'm not sure if i fully understand your question : do you want to get the fitted parameters from the paper or do you want to fit the parameters of a weibull distribution on a dataset of your own ?
100781,by 'simulating from a state space model' do you mean simply adding additive independent observation error ?
100645,is it 0 . 01 % or 0 . 10 % ?
100810,"as you say in your question , one simple ( and pretty general ) way to approximate expectations is via monte carlo methods . it is not harmed by high dimensionality . when you say "" i don't think it will be efficient and accurate enough . "" can you be more explicit about what you think the specific problem is ?"
100840,"mcnemar would test that the 2x2 frequency table is symmetric , that is , that the number of people having the desease before but not after equals the number of people having the desease after but not before . the test is blind to people having the desease both before and after . so what do you want to test ?"
100832,your question is very unclear . can you please edit your answer to make it explicit exactly what you're asking please ?
100855,what specific step are you struggling with ?
100865,who said that having 120 cases for 50 cases is bad ?
100894,"you need more information in order to answer this question . what , exactly , does it mean to "" have "" two variables ?"
100935,"it is typically * not * "" necessary to 'transform' the feature vectors before running some sort of regression "" , see here : [ when should you center and when should you standardize ?"
100829,this is a confusing description . can you please be more specific ?
100979,do you have some specific examples in mind ?
100993,what's $ w $ ?
101013,what does the intercept refer to ?
101008,there is so very little to be done to answer this question that one hardly knows what to write in response . perhaps you could help us out by explaining the point of this exercise : what is it helping you to learn ?
101023,try defining what the marginal pdf * is * . what does it tell you ?
101016,"if you are satisfied with the continuous and binary variables , why not convert your categorical variables to binary variables ?"
101029,"how would you define "" the main effect of b "" , knowing that there's an interaction between a & b ?"
100920,"when you say categorical , do you mean ordinal or nominal ?"
100673,"shouldn't the question title be "" what can't be expressed as a linear model ?"
101059,"it might be worth noticing that the relatively large values in the first dimension dominate the cosine similarity scores . this implies that the points most dissimilar to both ` point1 ` ( first component is 100 ) and ` point7 ` ( first component is 20 ) necessarily will have first components as close as possible to ( 100 20 ) / 2 = 60 . the best candidates are ` point2 ` and ` point5 ` but definitely not ` point4 ` ( which coincides with ` point7 ` ! ) . this naturally raises the prior question ( which ought to be settled before we go on ) , * what is your similarity measure trying to represent ?"
101076,how about a link to the thing you want us to tell you how to use ?
101121,"michael , what is the goal of this analysis ?"
101165,what are you trying to find out ?
82837,how large is your dataset ?
101203,"since 'normalize' is used to mean several different things in contexts like this , precisely what do you mean by "" normalize "" ?"
101243,why is that a problem ?
101265,"how many values of break do you have within each state , i . e . , the cross table of break and state w . r . t yield ?"
101257,which sign do the resulting parameters have for each variable ?
101291,are you planning on using cointegration for pairs trading ?
101335,"interesting . is a given point classified based on the nearest centroid , or the multivariate gaussian with largest density for the point ?"
15287,what software are you using ?
101358,"there is an awful lot here , can you focus your question somewhat ?"
101401,"( 1 ) as you're expecting the coefficients to change somewhat , why * wouldn't * you expect some small positive coefficients to become small negative ones , or some barely significant coefficients to become nearly significant , even if the changes in magnitude are quite small ?"
101120,do you understand the concept of double / nested cross validation ?
101420,correspondence analysis is an analysis of contingency table ( such as frequency cross-table ) . what is the dimensionality of your table ?
101477,i don't suppose $ bar x_ { 1 & 2 } $ are mean counts of poisson-distributed variables . . . ?
101543,what did you end up doing ?
101586,"i think this is an interesting question . by "" circle "" do you mean something like a modular integer space , or a continuous analog ?"
101407,"if the * * lower * * quartile is already 1 , then how it is readable from these plots that more than 75 % of the values are at the right-hand edge ?"
102618,"i'm trying to add formula-formatting to your equations using latex , but i can't figure out the very last one . . . there must be a mistake in it , right ?"
102628,how did you try fitting these distributions ?
102646,"do you have any examples of such empirical proofs of "" satisfaction "" ?"
101300,do you know the distribution of each of the $ x_i $ ?
102667,what is your outcome variable of interest ?
102660,the exact format of t-tables varies a bit from one table to another . can you print what the n = 8 row looks like ?
102692,what things were you looking for it to explain ?
102704,"you are missing 4 ) add the desired mean of the distribution ( provided that in part 2 'width 1' = standard deviation 1 and mean is 0 ) . if this does not fix the issue , can you add the results ( e . g . , some plot ) and information about why they are not consistent with what you expect ?"
99690,further hint - the standard error of the mean of a sample is $ sigma / sqrt { n } $ . so your sample mean is 5 standard errors from the population mean . how likely is that for a random sample ?
102812,"not accounting for the clustering variables means you will be more confident of your results than you should be . not accounting for the weights completely strips the generalizability . if you are not making representative claims , what then are you making claims of ?"
102820,"when you say you're "" using $ r ^ 2 $ "" , could you explain how you're using it ?"
102802,nick cox gave you pretty good advice on your last question - so i'm unsure what else you expect . for the last chart it would be better to make a set of small multiple histograms instead of dodging ( ?
102829,"you can truncate the domain of your density function where it becomes negative . however , would every other scientist take the same fitting density for your data ?"
102857,could you please be more specific about your data ?
102881,"this can be very tricky because it can cause complex patterns of non-identifiability in the parameters $ mu $ and $ sigma $ . a * very * simple example is $ g ( x ) = x ^ 2 $ , for which the sign of $ mu $ cannot be determined . because of this it is rare to formulate models using non-invertible $ g $ . do you have a particular $ g $ in mind ?"
102921,i'll write an answer . are the $ x_i $ independent ?
102620,"this seems rather like routine bookwork ; it's fairly easy to get the covariance out ( and from there , the correlation ) . is this for some subject ?"
102983,are the $ x_i $ independent from each others ?
102984,"` but i need it for unsupervised clustering , instead of supervised classification ` this key phrase alone is too brief and doesn't expain clearly what you want . above it you described what seems to me to be a decision tree . can you now give a similar passage about the algo you want ?"
103046,how was that interval of 15 ms found ?
103126,* * hint * * : your code appears to be comparing the two using * in-sample * mean-squared error . why wouldn't ols be winning that contest ?
103111,what's the context ?
103132,what do you know about the * joint * distribution of $ s_1 $ and $ s_2 $ ?
102720,user2157668 : good . does it solve your problem ?
103217,are the categories ordered or nominal ?
103176,"do you mean "" ergodic "" in the sense of the mcmc methods used to tackle bayesian problems or something related to a particular stochastic process in the real world ?"
103230,"since you're using $ theta_i $ to be equivalent to the $ i $ th mdoel , then $ p ( theta_i ) $ is just the prior probability of model $ i $ : $ p ( m_i ) $ . those model priors are up to you , but you must have $ sum_i p ( m_i ) = 1 $ . they represent your prior belief about the models before looking at the data . is this not what you're asking about ?"
97784,how big is $ n $ ?
103261,have you tried google ?
103258,are you looking for a proof that q1 and q2 converge to the true quantiles as the number of examples increase in a manner similar to the markov chain analysis in the slides you linked ?
103276,"i don't understand what the "" i . e . not model accuracy "" is doing in 2 . it doesn't seem related to anything . can you clarify or delete that ?"
103292,which tukey post-hoc btw ?
103314,"assume that in reality the observations $ y_1 = 1 $ and $ y_2 = 0 $ are the same physical entity ( although we don't know it ) . alongside the $ y $ 's there have to be some observed vector of explanatory variables , $ mathbf x_1 $ and $ mathbf x_2 $ . the clarification i need : are $ mathbf x_1 $ and $ mathbf x_2 $ identical ?"
103331,"it's not clear to me exactly what "" repeated measures analysis in spss "" you ran . a univariate or multivariate model ?"
103379,is the year assumed to be cyclic ?
103387,"likelihood is not the same as probability . the probability of getting $ k $ heads in $ 10 $ independent tosses of a coin that turns up heads with probability $ p $ is $ binom { 10 } { k } p ^ k ( 1-p ) ^ { 10-k } $ . the _likelihood function_ of $ p $ is $ binom { 10 } { k } p ^ k ( 1-p ) ^ { 10-k } $ where $ p $ is the variable and $ k $ is the number of heads that have been observed ; that is , the data . in your case , the likelihood function of $ p $ is $ p ^ { 10 } , 0 leq p leq 1 $ , which has a maximum value at $ p = 1 $ . to estimate $ p $ via bayes' theorem , you need to describe what you know about $ p $ . are the other $ 9 , 999 $ coins fair ?"
103340,"can we please see the parameter tables and the g-side variance-covariance estimates ( in r , ` coef ( summary ( m3 . glmm ) ) ` and ` varcorr ( m3 . glmm ) ` ) for both fits ?"
103413,from which package ?
103437,how many months of data have you got ?
103450,the 2 questions numbered 2 in both surveys are identical . is there a reason you are concerned that comparing the means for these 2 questions might be misleading or inappropriate in some way ?
103461,how large is your training dataset in number of samples ?
103483,"are these "" certainties "" confidence or credibility intervals ?"
103570,for clarity - you are simply asking about how to * present * the results of the accuracy in a table ?
103586,"so you're saying you don't care about what the values of $ b $ are--it's ok if they are limited to at most $ 2 ^ n-1 $ discrete vectors--provided that $ mu ( b ) $ has a uniform distribution on $ { 1 , 2 , ldots , n } $ ?"
103598,"from the documentation , i gather ` occupation ` is categorical , thus your model appears to be misspecified . what is ` logsigma ` ?"
103602,"i don't quite follow your question . why wouldn't eg * the median * be an acceptable answer to "" a distribution and a statistic , where the bootstrap estimate is actually more accurate . . . "" ?"
103606,what's your regression equation ?
103456,let $ z_i = frac { _1 } { ^ n } x_iy_i $ . ( i ) isn't $ z_i $ independent of $ z_ { j neq i } $ ?
103656,"i'm not sure i understand what you're discussing , since a set $ l $ isn't a random variable . if i have $ l = { 1 , 2 , 4 , 17 , 190 } $ what makes $ l $ uniformly distributed - rather than ( say ) merely equispaced ?"
103573,"kudos on the detailed description . for me what is unclear is the * question you want to answer * . for example , some of your data are survival / event history data ( the duration until subject moved , for example ) . so are you interested in changes in hazard function ?"
103657,is anything known about the error term ?
37589,"this question is extraordinarily broad . unless the scope is narrowed and some more context added , it is very likely to end up closed . without meaning to sound unnecessarily harsh , it is akin to asking : "" what are some examples of flowers that are not red ?"
103714,"perhaps if you give more detail you might get more useful replies . for example , you seem to presume a relationship between the tasks and aptitude . what is this relationship ?"
103356,how do you want to handle data outside min and max ?
103755,"it's a little unclear what models you're actually fitting . "" grouping "" the response or the predictor ( s ) ?"
103741,"if you want the pca , why not call ` [ coeff , score ] = princomp ( x ) ` ( see [ here ] ( url ) ) directly ?"
103797,ttnphns : are you sure you gave the link you wanted to give ?
103865,"by adf , do you mean [ augmented dickey fuller ] ( url ) ?"
103882,"that is very cool , i have not encountered it , but i solves an issue in some data i am interested in gathering . can you give an example or some more background to this 'range normalization' ?"
9850,"please tell what you mean by "" a set of marks . "" how many variables do you have with which to characterize the clusters ?"
103966,is ''education' ordered ?
103983,why ?
103459,"also , do you intend to do model selection to reduce the number of covariates ?"
103998,need more information please . what is your random-effects specification in the model formula ( please specify whether variables appearing in it are numeric or categorical predictors ) . what is the ` v ` function ?
104000,perhaps you can clarify a bit : ( a ) what is the relationship between players' ratings and expected winning of a match ?
104015,are you interested in something like an upper confidence bound ?
40967,these are certainly the standard methods - what makes you think there could be something better ?
104039,"do your 30 , 000 sets have possibly different $ mathbb { e } x $ etc . , or are they the same ?"
104049,"consider these questions : ( 1 ) if someone else were to independently sample $ 500 $ members of the control population , would they likely have observed exactly $ 235 $ successes ?"
104061,can you describe the data more clearly ?
102892,what is the sample size for the smaller of the two outcome categories ?
104079,"how about adding ` mu_y [ i ] - ifelse ( mu [ i ] = 0 , mu [ i ] , z [ i ] ) ` and changing the stochastic node for ` y ` to ` y [ i ] ~ dnorm ( mu_y [ i ] , tau ) ` ?"
103981,why do you want to use cross validation for feature selection ?
103774,"is your specific goal to use bfgs , and write it yourself ?"
104119,it seems to me multiple classification methods are tangential to the problem at hand . can we assume we have one classifier ?
104135,what does your model look like ?
104121,"let me get this straight . you have 60 pacients , each was measured three times . what variable ( s ) was measured ?"
102610,what data have you got ?
104188,does the closely related thread at [ cdf raised to a power ] ( url ) help ?
104208,"to clarify . . . idf refers to inverse document frequency , correct ?"
104212,"first you say you want to estimate the parameters , but then you sound as if you know them ?"
104202,"forget about the extra variables and work through this problem with just one independent variable , such as ` educ ` . now you can draw scatterplots showing what is going on . you should find that the change in units of $ w $ merely translates the entire scatterplot up or down by some constant amount . what does that do to the slope of any line that is fit to the points ?"
104229,i think this problem isn't entirely well defined . it is entirely possible that your test results could be tied between different distribution families . furthermore it may be hard to tell a multi-modal distribution from a single modal distribution in general for smaller sample sizes . is there a particular reason why the distribution is so important ?
104248,hint : what is the interpretation of the combinatorial term in the first density you have provided ?
104255,"can you clarify what you mean by "" predict into the future "" ?"
104308,"you're treating the $ p_i $ as known , or estimated with uncertainty ?"
104258,is your time series a stationary process ?
104373,"you'll need to say more to clarify what you mean by "" outlier "" in this context for this question to be answerable . i wonder if you are thinking about noise points in debscan clustering ?"
104417,"your example appears to be a collection of results of hypothesis tests , but the nature of those tests is not apparent . for instance , "" less likely to be a homeowner "" compared to what ?"
104437,"this question is difficult because the notation doesn't make sense . presumably , $ h = g $ . ( if not , what is $ h $ ?"
104443,"you're welcome . by the way , my vote is exotic lady = 1 and old lady = 0 . i will be very amused to see a young lady wearing bikini while spreading jam on a toast ( why is she doing that ?"
104264,did you check the 0-1 normalized version ( cramr's v ) ?
104532,do you have the total population for each pixel ?
104530,where did you see the formula ?
104341,how many time points ?
104567,it's usually customary to do * both * . and what do you mean by a logarithm variable ?
96614,"data is data . the adjectives 'parametric' and 'nonparametric' apply to models or methodologies , not to data . do you simply mean 'not normal' when you say 'nonparametric' , or do you intend to imply something more than that ?"
104601,what about defining the widths of bins logarithmically ?
104604,"could you help us make sense of the apparent contradiction between the assertions that "" the data represent the entire population "" and "" events are drawn from a differently behaving population "" ?"
104624,can you edit the question to contain also the calculations you made by hand to match the textbook result ?
104713,why do you think its useless ?
104637,on your first paragraph : your description seems at odds with your terminology - it sounds right skew ( positively skew ) - can you show your distribution ?
104652,"beware applying calculations that apply to events specified in advance to something observed * post hoc * . that is , if you see something that may be unlikely and say "" what are the chances of * that * ?"
104759,"why transform , rather than do something that doesn't require normality ?"
104633,if the domain is bounded the mean and variance ( indeed all the moments ) must be finite . how confident are you that any known distributions exist that satisfy all the conditions ?
104789,"yes , maybe could you further elaborate what you want to test , and in which setting ?"
104816,by 'hard' do you mean 'hardness' ?
104819,large data is many objects to cluster or many features ( dimensionality ) ?
104569,"could you perhaps give an example of your data , or something with the same structure ?"
104859,"if you only wanted to know how to do this in r , this question would be off-topic for cv ( see our [ help center ] ( url ) ) . however , i suspect there is a good deal of real statistical information that you may need . eg , comparing aucs is not generally the best approach & you wouldn't use a t-test to do it . can you say more about your situation , your data & your goals ?"
104858,"just to clarify : you are not looking for the * distribution * of each group's individual maximum times , right ?"
104888,what are ` single . sales ` ?
104928,is your outcome continuous or categorical ?
104929,"i re-read your post and , again , i think i'm misunderstanding you . you're just looking for pairwise correlations , e . g . the correlation between p4 and p5 , so forget regression . could you maybe clarify what you mean by "" local "" and "" global "" ?"
104996,"what does "" cor ( xu , xv , yu , yv ) "" mean ?"
105014,"can you tell us your application , that is , your context , what is the applied problem you are trying to solve ?"
104974,which clustering algorithm did you used ( from your words it looks like a k-means ) ?
105042,"i don't think this is a question of dishonesty , but the completeness . the analysis isn't complete unless you say whether your results were significant . a reader ( most of whom aren't statisticians ) ultimately wants to know the significance of results . if we don't set a universally agreed-upon boundary , how is the reader supposed to interpret the results ?"
105071,""" i think there many other superior approaches for this purpose "" - like what ?"
105070,"the nature of your study isn't very clear . it would help if you can say more about your situation , your data , and your goals . what do the numbers listed in the r-fiddle represent ?"
105109,was that homework or solving textbook exercises ?
105094,""" * because it will be significant if i have a larger sample size * "" - with a continuous outcome , there will always be * some * estimated non-zero effect size . . . so you could * always * come to the same conclusion as you just did . does an argument that says "" my hypothesis is always supported "" make sense ?"
105135,"out of curiosity , what does this product operation model ?"
105149,"what do you mean "" converge to the same $ beta $ "" ?"
105152,why not start in excel ?
103190,"it depends on what you want to do with the symmetrized y . for example , do you need an estimate of scale of the symmetrized y ?"
105214,"doing all subsequent linear analyses , including reliability , is logical on the transformed variables only . but i'm not in your shoes to recommend categorically , and you describe your situation too laconically . your points 3 , 4 , 6 - sorry , i didn't understand them well enough . maybe you rewrite them in more detail ?"
105255,what preparation have you undertaken in the study of statistics ?
105273,why do you ` decompose ` revenueseasonallyadjusted again ?
105393,it's not clear to me why there are two classifiers being used . if data in are in the format ` y_i x_i1 x_i2 . . . x_i100 ` then what is the justification for using one model to predict a ` 0 ` case and another model to predict a ` 1 ` case ?
105376,"your question still doesn't contain a question . even in your response in comments , you still only made statements . if possible , can you express what you want in the form of a question , and edit your question to contain it ?"
105430,"how was temperature measaured , and , more importantly , how was it calculated ?"
105460,why not choose a limit as cut-off ( if your aim is information loss ) ?
105325,"i don't follow : by definition the values of a cdf are probabilities . of course you can multiply them . your question , stripped of distracting material , says "" i know the probabilities of two independent events . how do i find the probability of their intersection "" ?"
105504,what model do you use for this ?
105506,"with an ordinal esponse variable with values from 1 . . . 7 , a linear model coud work . your residuals are a bit skewed , though . did you try an ordinal regression model ?"
105527,how many people have 0 . 7105428815 friends and equally many followers ?
105530,do you not like the idea of blocking from a theoretical or practical point of view ?
105552,"could you elaborate on what you understand "" $ binom { n } { n ( x 1 ) / 2 } $ "" to be ?"
105556,are your observations out of sync ?
105602,could you also clarify - this is bernoulli-model naive bayes ?
105598,should the inequality sign be $ $ in your second inequality ?
105643,"by appropriate way , do you mean you want to make assumptions about the distribution of "" errors "" and perform some kind of hyothesis testing ?"
105681,"anova is definitely a bad choice , as your data are ordinal , not nominal . collapsing the 5 ratings into 3 also wastes information . it's difficult to answer without information about the structure of the questionnaires . do you assume each is unidimensional , or do you really want to treat each item as a separate construct ?"
105704,would you please clarify what specific topics you are hoping to find in your ideal book ?
105723,which two are you attempting to correlate ( and why not just calculate that correlation ) ?
105693,"it might be illuminating to turn your question around : could you explain the reasoning that would support "" generalization "" from a sample of voluntary patients ?"
105728,your question implies you * know * all the $ sigma_i $ . is that really the case or are you * estimating * them ?
105727,what's g ?
105717,"hi and welcome to the site . i really don't know what you mean by "" estimated arithmetic mean "" . the arithmetic mean of the given numbers is $ 0 . 088 $ , as you say . what exactly do you want to calculate ?"
105817,this has come up a few times lately . gary king has done some work on this exact subject . maybe it'll help ?
105825,"1 . your model omits an error term . if there's no error ( observed data exactly equals your no-error rhs ) , significance can't even come into it . 2 . do you account for the serial correlation in your model ?"
105829,"please explain your question of interest in words , without any reference to ranks , names of tests or indeed any jargon at all ( especially not statistical jargon ) . what are you trying to do ?"
105759,"missanita , can you amplify on precisely what you mean by "" the individual group level ?"
105878,"i'm sorry but i think you have to clarify whether you want to test if there is a pair of groups among which a difference is found , or if there is a difference simultaneously among the groups as a whole . moreover , what is the nature of the data in each entry ?"
105911,"can you amplify your question ( by editing it : the edit link is in the lower left ) , by describing : ( 1 ) the * numerical values * taken by 'lead source' and your demographic variables ; ( 2 ) the * study design * that produced these measurements ; and ( 3 ) the * causal model * informing your hypotheses ?"
105891,"hi fredd and welcome to the site . your question seems off-topic here because it's only about some code . it would be good , though , if you provided some more information about your problem : what statistical problem do you want to solve ?"
105867,"hi psychokwak . there is something , i don't unterstand from your question : i assume that you chose your $ lambda $ for the box-cox transformation with respect to some model ( e . g . regression ) ?"
105962,"what exactly is your dependent / response variable , & what are your explanatory / independent variables here ?"
105950,what is word_shape ?
106036,some issues that it appears need clarification / clean up : 1 ) are the two error terms independent ?
106045,could you clarify what the numerator and denominator are in your response variable ?
106064,"1 . the two variables you gave in your data ( wavelength , acdom ) do not match the two variables in your model ( st0104 , wavelength ) . $ , $ 2 . the $ y $ variable in the data that you have supplied is discrete . indeed , it appears to be integers between 31 and 35 , all scaled by a constant . what is it ?"
106074,"hi mfernan5 , i guess i need a little help understanding your research question . if the question is pre / post changes in scoring , i am not sure why differences in teacher student cohorts is important . you say some groups of students did drastically different ; does this mean they changed on the pre / post less than the other groups , or that their pre-scores were lower ?"
106082,can you give more details on the actual problem ?
106090,what hypothesis are you testing ?
106111,what do you want to illustrate with your example ?
106110,"i still haven't a clue what you're asking . how do you measure how much movement is to the "" left "" or "" right "" ?"
106152,what do you mean by ` excel-based method ` ?
106177,by 'predicts' do you mean 'is one of the causes of' ?
106185,"could you clarify the question . you have two outputs , 1 & 0 , so why isn't any combination that outputs 1 "" best "" ?"
106197,"the matrix inversion lemma in the form you use it relies on the matrix $ mathbf x $ being invertible . intuitively , i would guess that you can extend it to non-invertible ( positive-semidifenite ?"
105003,if all models have the same parameters and structure why are you using aic in the first place ?
106227,"the degrees of freedoms suggest that f1 is an interval scaled variable and not a factor with three levels . is this intended or did you mean something like "" lm ( data ~ factor ( f1 ) * factor ( f2 ) ) "" ?"
106230,"i have caused your $ tex $ formatting to appear correctly , but i confess i still do not understand the question . you appear to write down some likelihood functions . but what is the "" same issue "" to which you refer and what do see is "" changing "" ?"
106259,which paper are you referring to ?
106135,"again , you're saying 'dampen * the * forecast' as if you already have one , but without specifying a model to try to apply some kind of dampening to . are you seeking to have some mechanical process that simply 'flattens out' any sequence of numbers ?"
106275,i'm tempted to put a bounty on that question for a real answer . or maybe community wiki would be more appropriate ?
106290,"what do you mean by "" always "" , i . e . how many parameter settings , how data sets have you checked ?"
106356,wouldn't that be $ 0 . 60 ^ { 2 } = 0 . 36 $ % ?
106354,i like the question : can you say more about the * kind * of data other than that they are non-negative ?
106370,have you tried fitting using multiple nonlinear least squares regression ?
106373,"this question seems under-specified to me . bounded loss is assumed so that mcdiarmid s inequality holds when concentrating the sample risk . unbounded losses are too hard in the sense that you can use the example from no free lunch theorem to create an unlearnable problem . when you say "" finite moments or possibly subgaussian , "" are you referring to your losses ?"
106383,the manual page for ` ks . test ` documents an optional parameter ` alternative ` that specifies the kind of test . why don't you use it and see what the answer is ?
106367,could you clarify who ' * they * ' are and include examples of what they say ?
107444,are you sure those correlations are a problem ?
104194,"( 1 ) the best approach to imputation depends on the proportion & pattern of missing values , the relationships between the variables , & what assumptions you're prepared to make about the reasons for missing values . ( 2 ) any single imputation method can be used to provide input to lasso ; the difficulty's in assessing how imputation affects the results . i don't know how to combine multiple imputation with lasso ( doubtless someone does ) , but an informal comparison of results from different imputation runs ( are the same predictors usually selected ?"
107571,are zones in some order ?
107574,the number sounds familiar . . . by any chance a dataset about ethnic conflict ?
107529,could you give a reference where that assertion is claimed ?
107581,what about kendall's concordance coefficient ?
107586,what type of observations do you have ?
107530,you're looking to do single rather than multiple imputation ?
107655,"could you tell us precisely where the robbins paper discusses "" 100 % confidence intervals "" ?"
107661,"you need to tell us more clearly what "" drawing $ k $ cards "" means . it is not evident what event that refers to . how many cards are being drawn ?"
107653,are you sure this is the best stack exchange site for your question ?
107720,"hi zhao qi , welcome to cv . your question leaves a lot of details open . can you give examples of how your variables are coded under the various conditions your describe ?"
107769,"there are definitely problems with some of the topics you raise ( for me , that delta function is the worst ) . one thing that isn't clear though is this : what is your question ?"
107786,1 . is this perhaps homework ?
107729,how large is your sample size ?
107810,"alexis , no , i disagreethis is not a duplicate question . , can you clarify where in your previous answer address the question of probability of survival curve dropping to zero ?"
107798,why do you want to detect outliers ?
107850,are you certain you have an intercept term ?
107898,""" * why not * . . . ?"
107895,it is a difficult question . of course you can use bonferroni-holm . but is it smart ?
107909,do you know the total number of mines in the game or not ?
108043,what do you obtain when $ 1 b b ^ 2 cdots $ is multiplied by $ 1-b $ ?
107947,what hypothesis do you wish to test ?
108060,what is your basis for saying the f value is 'too high' ?
108085,"just out of curiosity , when you say "" i have found that linear svm performs much better on my training set than logistic regression "" , are you sure they're using the exact same features ?"
108092,it will be hard for someone to help you without more information . what do your axes represent ?
108171,are these predictors truly binary or are you dichotomizing them ?
108175,"you seem to conflate "" meaningful difference "" with "" statistically significant difference "" but they are not the same . a small difference can be statistically significant but not meaningful . in your example , is a score of 40 meaningfully different than a score of 41 ?"
108194,what is the subscript $ m $ referring to ?
108206,"i suppose that the most obvious way is like this . a 2-class classifier gives , for each case , a probability ` p ` of belonging to this class and the probability ` 1-p ` of belonging to the other class . with , say , 4 classes you have 6 classifiers and hence 12 propabilities . each class has 3 probability values ( 3 "" attempts "" were made to classify to each class ) . you might average the 3 probabilities in one ( arithmetic or possibly geometric mean ?"
108215,con you please add some more details ?
108239,"the term "" interaction "" has a specific meaning in statistics , which does not seem related to what you are talking about . can you clarify what you mean by the term & what you are after exactly ?"
60601,there are a number of possibilities . do we know anything further about them ?
108267,you have to use knowledge to define the bricks - why shouldn't the response be high for odd values of a predictor & low for even values ?
107944,"by definition , a "" permutation "" is a * rearrangement * of the set . therefore every permutation selected ( out of the set of all possible permutations ) will include every particular number . if you really meant to refer to * sample * of size $ 100 $ with replacement and that $ 50 $ such samples are independently drawn , then please edit the question to make that as clear as possible . otherwise , what do you mean ?"
108437,what is frequency and what is your likert scale measuring ?
108440,"because a p-value of $ 0 . 6 $ is about as non-significant as you can get , i wonder whether you mistyped this number . i don't completely follow your question , either : are you implying you believe an estimated autocorrelation of $ 0 . 2 $ at the state level would be incompatible with one of $ 0 . 8 $ at the county level ?"
108332,where did you encounter such a criterion ?
108457,"( 1 ) are you sure you mean * confidence interval * , rather than say a tolerance interval or a prediction interval , or some other interval ?"
108355,one thing is not clear to me : are you trying to determine the network structure or just its parameters ?
108449,so : how about you edit your post ( the edit link is at the lower left ) to ask an actual question ( you originally put question marks at the end of declarative statements ) . this is a question and answer site : can you improve by asking an actual question in the body of your text ?
108540,how can such a question be answered without a definition of 'reliable' ?
108529,for question 2 ) : i've never heard of using the standard error of the estimates for model comparison . what you want to do with the data ?
108580,this seems to be a pretty broad question . are you able to focus on some specific questions ?
108582,is there a way to infer the score from likelihood in your model ?
108599,"probably i miss something , but if the reward for every potential action is known , then why do you need multi-armed bandits ?"
108602,"why * not * approach this via regression , in which case the answer is very straight-forward ?"
105540,means of * what * ?
108666,have you considered using kalman filtering ?
108668,"if i get you right , you're saying that the error term always moves with $ x $ , so getting the linear coefficient on $ x $ will ignore the correlated effects in the error term . it is true that observational variations in $ x $ will change $ y $ through $ epsilon $ as well as $ x $ . the interpretation of the iv however is generally "" what would happen if someone went and set some policy that exogenously changed $ x $ and only $ x $ ?"
108725,"there would seem to be no issue of "" mathematical "" correctness : euclidean distance is a * bona fide * distance . aren't you rather concerned about whether using it is * appropriate * for your analysis ?"
108743,what kind of unsupervised learning algorithm are you using ?
108751,when you say 'compare' can you be more specific about the question you're trying to address ?
108201,it would maybe help if you briefly describe how the multiple records for each subject were created . are these repated measures of the the same 'concept' ?
108770,some amount of correlation among predictors is normal in multiple regression . how strong are they in your case ?
108676,the notation is unclear on your specific question . how is x defined ?
108807,what is your null hypothesis ?
108860,can you provide a simple example w / data for time-series a & b that would demonstrate what you mean ?
108861,why are you performing * * both * * anova and friedman tests ?
108878,"the issue might best be thought of in terms of * power * rather than p-values , which are not predictable . the power to discriminate differences increases with the numbers of trials and decreases with the numbers of proportions within each subject . what is unclear to me is why this is a problem . are you perhaps asking how to conduct the tests * properly * ?"
108877,how much data have you got ?
108847,it would be interesting to know what your client intends to * do * with these statistics . will they be used for formal testing ?
108896,are you sure you copied the question statement accurately ?
108909,"( i ) when you say "" i couldn't find anything "" what did you try ?"
108918,heya ! welcome and nice first question . is there any way you can edit the title to give a teeny bit more idea about the content of your question ?
108474,have you considered a bootstrap ?
108859,"but if they're very similar , why would you bother changing from spearman - the only times you'd consider using it you'll get essentially the same answer using spearman , so there'd be no obvious loss by simply always using spearman . what information would you gain by switching ?"
108957,"what exactly do you mean by "" the correlation amongst a set of individual correlations "" , & "" the overall correlation "" ?"
108958,"is your table the means of the data ( which is what "" means "" suggests ) or the means of the ranks of the data ?"
109018,which 2004 paper are you referring to ?
108974,"it might just be me , but i can't discern if your sample data are supposed to correspond to the visualization concept as you've laid it out . are the rows organized by ` itemid ` ?"
108343,the precision is 70 % on the test set ?
109047,are you data * paired * ?
108873,"welcome to our site , russ ! because we support mathjax it has been possible to mark up your post to make it a little more readable . if you choose to apply any other edits , just enclose any $ tex $ markup between dollar signs $ $ $ . ( btw , your title initially brought to mind the kind of job an out-of-work statistician might take on . "" q : what are you doing to get by ?"
109068,this does not appear to be a chi-squared statistic . the correct statistic uses the * model * value to estimate a * variance * in the denominator . wouldn't it be more constructive to explain what you are trying to accomplish instead of asking us to fix a procedure that looks so completely broken to begin with ?
109180,"multiple-choice tests usally yield an overall score , after which the individual item data are largely or completely ignored . you seem to be asking about individual items . are you interested in an overall score or individual items ?"
105906,". . . and it's not just the df . the paired t-test gives you a t-statistic of -1 . 3394 , while ` lmer ` gives you a t-statistic of 2 . 302331 . can you post data somewhere ?"
109237,what sort of function is $ m_i ( t ) $ ?
109235,have you obtained explicit formulas for the marginal distributions ?
109254,"if there is only 1 winner then the chances of a person with n tickets winning is n / 5000 . or , are you asking "" what is the chance that the person who wins will have n tickets ?"
109257,is there a reason not to include all cases and fit a mixed model using neighborhood as a random effect ( in lieu of pairing ) ?
109266,the error is likely at your side . did you read the documentation of hclust ?
109251,could you give us the full model specification and what you mean by 'basically know the variance' and 'approximately normal priors' ?
109299,try the decompose ( ) function in r ?
109295,"isn't * * $ z $ * * a design matrix , and not a matrix that's estimated ?"
109206,"i might be missing something here , but could you just correlate the counts from the two devices , and use that ( $ r $ ) as an indicator of how well they match , or badly they mismatch ?"
109341,"you can invent any formula you like . whether it means anything or is useful for any purpose is a different matter . what is this "" non-normalized information entropy "" intended to reveal about the data ?"
109371,not everyone can access the article you posted . would you mind including their specification for the ratio ?
109432,are you derivating with respect to the sample size $ n $ ?
109487,which method do you think gives the most information ?
109521,"i'm not sure i understand your distinction . . . why wouldn't "" out-of-time "" testing simply be another name for out-of-sample testing for time series ?"
109568,what book are you referring to ?
109586,i do not see how the probabilities play a role in your question . could you edit your question to explain where they come from and what you plan to do with it ?
109355,"you mention that you are doing a "" finite distribute lag linear model "" . has an "" infinite "" dlnm ever been proposed ?"
109625,what's your model ?
109647,"what do you exactly mean with "" different "" and "" how different "" ?"
109351,"most such * ad hoc * statistical procedures perform poorly compared to extant , well-known ones . what have you done to verify that this procedure has any useful properties ?"
109704,let's start from the output of the boxplot . can you explain why you don't like it ?
109726,have you considered first a simple correlation analysis ?
109743,"what exactly does your notation "" $ mathcal { n } ( x_i ; x_ { i-1 } , 1 ) $ "" mean ?"
109754,isn't fifteen minutes a little soon to declare the question dead ?
109791,"is your question about which model is correct , or is it why you get nan ?"
109803,what are the numbers in the cells of the table ?
109284,"do you have the same number of subjects in different groups ( particular age particular gender ) , or substantially different ?"
109878,"any common latent factors here , or do you really only have one likert rating per construct ?"
109890,"re the "" does not apply "" option : are you suggesting you would impute values where the respondents say they are not even applicable ?"
109892,why don't you try a var ( p ) model ?
109894,do you need to predict the colors of * your * objects only or is your intention to predict the colors of objects not yet listed in your dataset ?
65121,"welcome to the site , patricia89 . do you mean the test of overid restrictions for instrumental variables in linear regression , or in more general gmm context ?"
108923,"did you read url paragraph "" kappa maximum "" ?"
109804,"what would you consider "" normal "" ?"
109922,what exactly do you need the sampling distribution of the mean for ?
109988,"you recoded your ` fa ` as a factor in your ` lm ` call . from what you write , ` fa ` should be a numerical measurement , shouldn't it ?"
110006,are you interested in whether there is a relationship between bmi and each of the many attributes ?
49455,"the above code runs fine for me with ` caret_5 . 15-052 ` , ` glmnet_1 . 8-5 ` , ` matrix_1 . 0-10 ` and ` r-2 . 15 . 2 ` on windows . i will try on my mac later this evening . i just copied and pasted it into a fresh r session . are you doing the same ?"
107549,could you make your title more explicit and descriptive ?
109708,generally better to give a reasonably complete reference to save ambiguity . you mean the 2008 book by piet de jong and gillian heller ?
110049,is this a home work ?
110156,"the nugget is the measurement error , if the error is zero , then what you observed is the real value . in the cross validation , you delete your station from the observed one ( adding na ) and then you predict the process on that station , in this case you shouldn't have the error ( is it ?"
110192,can you post an example image ?
110198,it might help if you add some context to this question . why do you want to do this anyway ?
110202,what results were you expecting ?
110261,what are you trying to predict ?
110092,how did you get the clusters ?
110368,( 1 ) are the data paired ?
110357,"i am really confused about what the data look like . the problem describes $ n $ random variables $ x_i $ but later talks about a * distribution * of $ n $ , as if the number of random variables were itself a random variable . could you perhaps provide a small illustration or amplify your description of the data ?"
110340,"can you edit your question ( hitting the "" edit "" link in lower left ) to share more details about your full model ( i . e . what the predictors are , how they are coded , the sample size , etc . ) ?"
110399,what is the logic on which you based your function ?
110405,what exactly does this distribution describe ?
110411,are you familiar with bayesian inference ?
110476,"you mean * apart * from misspecification of functional forms , link functions , error distributions , heteroskadastic form and unobserved variables ?"
110201,"since you have a control group , i would suggest doing a simple t-test by summing the post intervention sales of affected group and comparing it to the control group . if the size of the group varies , then i simply suggest to see if there is an increase in difference between pre and post . just looking at the data , i can say that there is a huge difference between control and affected group . what happened in jan / 14 and may / 14 in the affected group ?"
110416,"out of curiosity , what kind of question are you trying to answer with this ?"
110559,what is the nature of your items and response variable ?
110587,"a markov chain might be an appropriate model , but--crucially--the operational meaning of the "" na "" values must be understood . it seems they are not the same as missing values . perhaps you could explain what the underlying data really are and how your series actually is derived from them ?"
110622,you are looking for a formal test of the existence of 9 distinct clusters when data are assessed in 2 dimensions . is that right ?
110673,can you explain how the first integral ( the expected probability ) is obtained ?
110719,what error do you get from rsem ?
110666,why not just one $ boldsymbol { x beta } $ ?
109578,and you don't know when the intermediate observations are ?
110774,"what specifically do you mean by "" plot is not looking good "" ?"
110755,"so that we can understand what you are asking , please include either a quantitative definition of "" inflation "" or "" inflammation "" [ * sic * ] in this question or else provide a more precise explanation of what exactly this is supposed to measure . are you perhaps trying to quantify the degree to which an empirical univariate distribution departs from a prespecified theoretical distribution ?"
110786,what's your model fit like ?
110797,the question sounds vague for me . your demonstration is only one situation . are you claiming this behavior always occurs for any second-order polynomial ?
110801,"what does "" scientific proof "" mean in this context ?"
110842,what represents a count of zero then ?
110956,"is this under "" real world "" assumptions or is it a word problem ?"
47318,what exactly is your analysis goal here ?
110999,"could you give the context in which you heard the term "" * * test error * * "" ?"
111001,"by the last sentence , do you mean that your hole data-set is given by 3-5 test results ?"
111021,"maybe the difference between "" green "" and "" yellow "" ( or any other non-identical pair ) can be taken as 1 , as opposed to 0 in case of identical pairs ?"
111027,do you mean that in the 1st data set there are only positive labels and no negatives at all ?
111041,the support of $ y ^ * $ matters here . what is it ?
111034,can you give a full citation ?
110924,do you wish to test the hypothesis that the distributions of finishing times in each race are the same or that the distributions of each * athlete's * finishing times are the same ?
110969,it isn't quite clear what you have done exactly . did you call the ` glm ` function from the ` stats ` package and pass its result to ` confusionmatrix ` ?
111103,please give a [ reproducible example ] ( url ) . i recommend that you read ` ?
111128,are you building these models for the purposes of inference or prediction ?
111140,ttnphns : why do you think that the variance of noise components should decrease linearly ?
110971,did you intend to include some kind of more complete reference or link on [ 2 ] ?
86734,"while there's * some * connections ( e . g . relating to fisher information ) , i wouldn't say it's a strong relationship . was any reason given for this advice ?"
111189,"if your hypothesis of interest is truly to compare "" mood between the three groups to see if they differ "" then a simple average might be all you need . but think carefully about the kinds of * specific * questions you would like to address ( * before * looking at your data ) . why did you collect 30 measurements per subject ?"
111175,"whuber . i'm not sure this is a duplicate of "" how can adding a 2nd iv make the 1st iv significant ?"
111209,"i do not understand the question . i believe you have tried indicate that the log-likelihood cannot be differentiated with respect to $ mu $ at any of the points in the set $ { x_j } $ , so assuming differentiability everywhere cannot legitimately be "" justified . "" could you clarify what you are asking ?"
111235,"correlations are not "" being changed "" . why would you expect that the partial correlations would be similar to the ordinary correlations ?"
111341,do you know the size of the sample from which this parblot was obtained ?
111352,why is this an issue at all ?
111355,would you know how to do it if you got only two categories instead of four ?
111402,please check the first line of your quoted question . is there something missing after $ beta ^ t $ ?
111421,"andrej , is your question ( "" how to add projection points to the perpendicular line "" ) about mathematics ( how to compute the coordinates of the projection points ) or about programming ( how to do it in r using lda ( ) function , how to plot it , etc . ) ?"
111448,"a general formula will be hard to come by and impossible to write down unless you make some quantitative assumptions about how the $ p_n $ vary with $ n $ . did you perhaps intend that the $ p_n $ be constant , as suggested in the example ?"
111451,how are you calculating the shrinkage parameter of the ridge regression ?
111462,maybe the loss function depends on the task the algorithm is used for ?
111466,in what sense do you have a measured value and a known true value ?
111470,"what's "" lag dependent variable "" ?"
111455,"is the ` correlation ` variable the correlation between sales and profit , or the period between months ?"
111475,"so that everyone will understand you correctly , could you please include an explanation of what you mean by "" calculating the top y "" or the "" top x "" ?"
111482,"please explain what would be "" right "" for your sample . perhaps you could post a sample figure ?"
107542,are all 94 districts in your data ?
111484,'log linear models' is a term used to represent several different things . can you give some clarifying context ?
111638,do you have one measure per person ?
111644,what precisely are you averaging ?
111659,how do you determine the counts ?
108815,does the measurement model specify that those factors should not correlate ?
111569,"not sure i follow the design description , but are there perhaps as many levels of ` big * letter ` as ` item ` s ?"
97884,what is $ epsilon $ in this case ?
111757,"are the six sensors measuring the same thing ( one person's temperature ) , similar things ( temperature of 6 people ) , or totally different things ( height , weight , temperature ) ?"
111768,""" is sampling a proper technique here ?"
111745,"you should use an ordinal glm instead of a multinomial model , because your response variable is clearly ordered , but a multinomial model fails to take advantage of this info ( see [ when do we use multinomial regression and poisson regression ?"
111788,"are all of these "" words "" compose of the same set of letters ?"
111795,looks promising so far . so what needs to go in your $ 1- phi ( ) $ expression to make it come out . 001 ?
111821,"i have the impression that the data simply do not conform to the model , e . g . , you have some extremely high correlations between the factors . try to look at a standardized solution to get correlations instead of covariances ( and at standardized loadings , too ) . maybe you want to collapse some factors ?"
111842,"when you say "" error distributions "" -- are these some form of residuals from some model-fit ?"
111856,is it * really * better ?
111815,"hi . i think your model is equivalent to ` gls ( value ~ group * time , data = dat , correlation = corsymm ( form = ~ 1 subject ) ` . could you check ?"
111901,"put box 1 on the left , and it will be clearer . are there any correlations ?"
111908,"wtt if they all have equal values of the cost function , in what * other * sense do you mean 'best' ?"
111995,"are the conditions always given in the same order , or are they randomized ?"
111515,i am a bit confused with your notation . specifically $ mathbf { t } _x $ vs $ mathbf { t } _x $ and $ t_x $ . perhaps standard ( statistical ) notation like $ x_t $ or $ x_ { it } $ will help ?
112003,"i think you are losing "" system "" along the way . do ` time1 ` and ` time 2 ` refer to time on system 1 and 2 , respectively ?"
112021,"in an economic sense , $ y equiv x $ , at least if $ y $ is * total * consumption . even if $ y $ is partial consumption , i would be worried about endogeneity resulting from * simultaneity * . is there an instrument you could use instead of income ?"
112027,what are your research questions ?
111910,"given you flag a data-point as an outlier because it does not conform with some criterion ` a ` , why would you try to judge the goodness of your model , which was designed / trained using data that follow ` a ` , to estimate against a value that does not follow that criterion ?"
112042,"are you doing logistic regression , or linear regression , or something else ?"
112073,"can you tell us more about your situation , your data , your models , & your goals here ?"
112079,"it * could * make sense in some situations . i'm just mentioning possibilities . you're better placed to work out what does make sense . is it really the case that values like $ ( 10 ^ { 10000 } , 10 ^ { -4000 } ) $ would be * just * as likely as $ ( 10 ^ 6 , 10 ^ 5 , 10 ^ { -2 } ) $ ?"
112029,what is the model that this comes from ?
112133,"i think the se system may not let you delete your question once there is an upvoted answer . i'm not sure i follow your question , though . are you just wondering how to do a one-sample t-test in r ?"
110535,you're looking for a book with * all * of these in one place ?
112171,""" what does it mean to normalized a degenerate distribution function , please ?"
112187,"i'm assuming that you're after prediction , rather than inference ?"
112220,this seems like a tedious approach . is there a reason you're not using a higher-level mixed-model-fitting function such as ` lmer ` in the * * lme4 * * package ?
112210,"batool , if it's possible . do you have reasons to think that a feature or two will hold most of the predictive power ?"
94137,the nature of your data is a bit uncler from your description . what is a relevant spatial unit of your analysis ?
112273,is [ this ] ( url ) helpful ?
112328,"what do you mean by a "" strong effect on . . . power "" ?"
112330,"why are you trying to apply ` manova ` , which is explicitly for multiple responses , to a variable that represents just a * single * response ?"
112369,please spell out pnl . what does that stand for ?
111771,did you enter all that latex by hand ?
112380,it's treating cylinders as a categorical variable ( should it be ?
112374,"for the 2 scores per phase , are they taken at different time or just repeated measurement ( i . e . the second one is taken immediately after the first one ) ?"
112399,"so to clarify , you want to sample to obtain a reasonable , smaller dataset that in some way represents the original one ?"
112408,"inverse reaction times ( speeds ) may be a better target , but either way i'd be inclined to consider glms for times or speeds . with the individual variability , you might even do better on a log scale , but then i'd be looking at a mixed model ( perhaps random intercepts in the logs ?"
112414,""" it is said "" . . . * by whom * , and * where * ?"
109390,are you sampling without replacement ?
112430,"are you restricted to frequentist tests , or open to bayesian methods ?"
112481,"models cannot be plotted ; when you ` plot ( lm ) ` you are actually plotting residuals against fitted values , etc . what are you trying to plot ?"
112512,"well , the markov assumptions let us show that the first equation is blue , or the * best * linear unbiased estimator . in this case "" best "" is determined by having the smallest standard errors of all possible estimators . is that not an adequate statistic ?"
112476,"although i think i have a conventional understanding of most of the words in this question , i'm unsure what it's getting after . could you state a little more precisely what you mean by "" sampling "" and what exactly would be "" optimized "" ?"
112581,"could you elaborate your hypothesis , e . g . by a formula ?"
112614,"by definition a beta distribution has bounds $ 0 $ and $ 1 $ , so apparently you are referring to a scaled , recentered beta . no matter : what is of import is how you obtained the numbers $ p_1 , p_2 , x_1 , x_2 $ . are these given theoretically ( that is , * exactly * ) , or have one or more of them been measured with some possibility of error ?"
112631,"you need to differentiate between missing vs censored . i assume you actually mean missing - in which case , you only had 2 % of your dataset before imputation ?"
112637,about how many individual cells are subjected to each of the 6 treatments ?
112642,"( 1 ) what do you mean by "" cv "" ?"
112692,"what is the "" mgf technique "" ?"
112751,"read starts only once per observation , so $ p_ { n = 1 } ( x_i = 1 x_j = 1 , j neq i ) = 0 $ , right ?"
112640,could you please give a reference about your claim that a paired t test is equivalent to a fixed subject effect model ?
112814,do you know thwe variances -- or the ratio of the variances ?
112827,"could you show us a simple example where the "" analytic "" and "" sample "" variance formulas actually give different numbers ?"
112864,is it always an exact polynomial with no error ?
112887,i would say that 20 observations is not so much for time series analysis . how about using some form of panel regression ?
112913,one hot encoding ?
112919,"thank you for including the text description . unfortunately it does not resolve the issue . that description basically says to find the lag at which the cross-correlation is maximized , as described at url url and elsewhere on this site . it does not explain why $ x_ { start } $ , . . . , $ y_ { stop } $ are used instead of the full dimensions of each vector . perhaps the authors use zero as an indicator of no data at all ( and then forget that fact in their formulas ) ?"
112219,"why do you need to test variance specifically , rather than using one of the enormous number of model selection techniques that already exist ?"
14351,"in the sentence "" i want to model the two time series as to predict a future values of $ x $ "" , what is $ x $ ?"
112942,some basic questions : do you know how many people responded for each city ?
67827,"the [ caret package ] ( url ) comes with a series of vignettes ( and a jss paper ) that cover most of your questions . could you indicate what precisely you mean by "" derive some inference on the effect of particular variables ?"
113011,is $ pi $ a parameter ?
113043,you'll need to write a family and link-glm object . check out ?
113071,what does the standard error refer to ?
112712,can you give more detail ?
113171,principal components analysis ?
113173,what is your goal in fitting the regression model ?
113186,are you * really * using only 10 test instances ?
113202,have you scaled the data before to perform lasso ?
112811,my prior leads me to believe this probably can be done . can you add more detail ?
112191,what's non-classical about mcmc to evaluate an integral ?
113249,are you sure about this expression ?
113280,"when you say "" the other people who survived indefinitely were not included in the dataset "" do you mean even the knowledge of how many there were is not included ?"
113231,"this seems like a sample-size problem . i tried to add that tag , but it didn't take . maybe you want to try ?"
113162,"what do you mean by "" random fixed factor "" ?"
113314,""" simple linear regression "" does not entail an "" enter "" method so far as i know . are you doing something stepwise ?"
113507,"what do you mean by "" model the data with points "" ?"
113526,you still have not said * why * you want to have your measure of elapsed time . do you need to estimate the total machine time you are paying for ?
105578,"dies the "" q "" stand for "" quantum "" here , or is it genre jargon ?"
113598,why would you do that ?
113633,"what do you mean by "" how much fit "" ?"
113642,why go roundabout ?
113644,why don't you run cross validation and see what model gives better prediction ?
113670,when is the decision to assign treatment a or b is made ?
113681,"what is key is exactly how you measured performance in terms of bias , precision , confidence interval coverage , bias-corrected predictive discrimination ( using the bootstrap or cross-validation ) , etc . what approach did you use ?"
113801,this is exactly what is done in random forests . have you looked at that literature ?
113805,it depends on what you mean by 'compare' . what is the actual question you wish to answer ?
113790,welcome faisal . i think we need some more info . what type of hypothesis are you interested in ?
113831,"i took the liberty of formatting your equations with the $ latex $ markup features that the site supports . please ensure it still says what you want it to . also , you say you "" need to derive "" , is this for a class assignment ?"
113888,"plus , you have $ 2 times365 = 730 $ observations , so the df do not exceed the amount of data you have . the pooled $ t $ test will have 728 df , and since your sattethwaite df are so much smaller , it suggests that there is a huge disparity between the sample variances . if so , you should not use the pooled $ t $ anyway . i also wonder , given the familiarity of the number 365 and the equal sample sizes , is this really a paired-data situation ?"
113894,"it might be useful to consider the question "" for what purpose does the mean need to be stable ?"
113836,"how about "" ensemble "" ?"
113921,"a t-test isn't really suitable here ( you mentioned it in your original tags ) . you probably want a chi-squared test for homogeneity of proportions ( which will be equivalent to a test of independence because of the conditioning on both margins in the chi-square ) . this looks like routine bookwork -- is this for some class , or other form of study ( even on your own ) ?"
113925,"when you say "" had a negative regression "" do you mean "" had a negative coefficient "" ?"
113910,""" trying to find often repeated cases and such "" seems like a very limited and vague objective . could you be a little more expansive about what kinds of "" relationships "" you are looking at and what the project aims to accomplish ?"
113941,do i get it right you are trying to fix the output instead of the underlying model ?
113879,"can you say anything about the positive noise , other than it's positive ?"
113965,"on a different level , it is not clear how seriously to take linear models for cell counts . even if counts ( meaning concentrations ?"
113968,is this sincere ?
114038,what kind of convergence ?
114040,why don't you use the very good ` ordinal ` package . . . ?
114027,"it is very tempting to only answer "" what's the point of testing [ in general ] if one can't accept the null hypothesis ?"
114068,"are values of _z_ missing for all individuals , or only for some ?"
114095,how are you going to find the probability distribution of y given x ?
114110,what do you mean by the kolmogorov distribution here ?
114081,"sure--that's a routine procedure to maximize the pdf given its functional form , as taught in calculus . what hong ooi is alluding to , though , is that since your question mentions * data * , then those parameters apparently were estimated from the data and therefore are uncertain . the questions of statistical interest become ( 1 ) how does that uncertainty translate into uncertainty about the location of the mode and ( 2 ) why are you estimating a mode in the first place ?"
114045,what's the difficulty ?
114210,what distinction you are trying to make between a lag-one autocorrelation coefficient at step size $ h $ and a lag- $ h $ autocorrelation coefficient ?
114239,"do you have any evidence that the last 215 of those 275 aren't just artifacts from measurement variability ( "" noise "" ) ?"
114301,are you talking about a t-test ?
114329,could you please clarify whether you have more than one measurement of a1 and a2 for each of the soils ?
114203,are you saying that you measure the value of $ y ( t ) $ at evenly spaced times $ t $ covering a duration of $ 2 pi / omega $ ( one period of the wave ) ?
114388,error bars representing what ?
114351,can you either write or give a link to the exact for of the negative binomial you are using ?
114368,"given your explanation , in what respect does it differ from performing the standard factoring on the variables $ x $ , each averaged across the rm-levels ( that is , inside each individual ) ?"
114422,can you show * exactly * what you did to get a value greater than one ?
114437,"perhaps i'm missing the point of the question , but just curious--why not just run the regression on y3 as well and see what those coefficients are in their own right ?"
114466,do you mean ` polr ` from the package ` mass ` ?
114496,interesting question . i don't see a way to do it from the data you have . is it possible to do more than one such treatment ( at different levels from the first ) in each so the assumptions used in the calculation might be checked on the second set ?
113868,"if your rng function does not initialize weights , what does it do ?"
99334,how * big * is your big data ?
114564,"consider an extreme case of correlation . suppose all the errors were perfectly positively correlated . in other words , somebody had generated a * single * random number and added it to all the response values . how certain would you be of ( say ) the intercept in the regression ?"
114658,"the first of those questions doesn't make sense as phrased ( since , for example probability is related to interval length ; you can get better probability by waiting longer ) . can you clarify what you mean ?"
112651,did it help you to figure out what the issues were ?
114607,"it is often impossible to draw such a diagram when using circles . consider , for instance , $ a = b = c = 2 $ , $ a cap b = b cap c = 1 $ , and $ a cap b cap c = 0 $ . what kinds of shapes do you want to use then ?"
114695,"in your account i do not see any mention of actual measurements of reading ability . how , then , do you propose to draw any conclusions about reading ability at all ?"
114718,"i'm afraid that might confuse the issue , because standardization * by definition * divides values by one standard deviation , not two . are you now asking about how to convert a slope from one set of units of measurement to another ?"
114725,"let's try a role reversal : you're in a seminar , or reviewing a paper , or examining a thesis , and the other person says "" i chose such-and-such link because it gave the best fit , and nothing else really matters "" . do you think "" fine by me "" ?"
114752,"for the uninitiated , what is stl ?"
114807,"what's "" whew "" mean ?"
114842,"this seems like a duplicate of url ( currently unanswered , alas ) , but perhaps the conversation in the comments there might help get you started ?"
114852,"uh , three of the values in the top plot ( x = 4 , 39 , 59 ) are clearly negative . how can residual value be * negative * ?"
114848,are the y-axis values in your plots averaged across the 100 data sets ?
114859,i doubt what you are doing is the best way to go . although written in the context of testing if a distribution is normal ( instead of maxwell ) you should read the following thread : [ is normality testing 'essentially useless' ?
114787,what's the actual question ?
114911,could you give us some background that explains why you would expect the two plots to be similar ?
114937,it depends on what matters for you . perhaps mean square error ?
114959,"obviously you have accomplished ( 3 ) : the points are labeled by color in the right hand plot . what , then , is your question ?"
114974,what exactly is your problem ?
114978,"there is too little information here to say much , and thats why you get no responses so far . tell us more ! maybe a logistic regression with a dummy for repeat customer ?"
114982,for count and continuous data can't you explicitly construct a family of distributions with free mean and variance parameters and conclude existence of a distribution with a chosen variance function that way ?
114987,"i believe the answer might depend on what you believe to be "" meaningful . "" in the sense of * potentially providing information about the data , * the median and iqr are indeed meaningful for binary variables : when the iqr is zero , you know that at least three-quarters of the data equal the median . it is unclear in what sense such information would be "" practically meaningless "" to you . perhaps , then , you could edit the question to provide some guidance considering how we are to understand "" meaningful "" ?"
115019,are all of your class 0 observations at x ~ = 75 ?
115041,"i am surprised that a correlation calculation returns zero , because the correlation in that case is actually undefined . regardless , your question seems to be saying ( 1 ) "" i want to use correlation to assess similarity , "" ( 2 ) "" but i disagree that correlation is a correct way to assess similarity . "" what , then , do you expect in the form of an answer ?"
115070,have you had a look at the [ meta analysis task view ] ( url ) ?
115142,table 4 of the cited article provides the mle and standard errors for the data set quoted here . do you want to know how find the mle and standard errors in general ?
115145,i'm not entirely sure what you're asking . are you trying to find a correlation between demographic factors and an assigned number ?
115158,can you show the summary output ?
115172,"assuming that npm means the binomial coefficient $ binom { n } { m } $ , 25p6 is the number of subsets of size 6 that can be chosen from 10 15 = 25 people , but this includes subsets of size 6 chosen from just _one_ shift , does it not ?"
115182,what do you mean by over- and under-estimation ?
115219,can you explain what the actual research question is ?
115281,what kind of model are you fitting that doesn't have an ` aic ` or ` loglik ` method in r ?
115270,"the second and third bullet points make sense only for * numbers * , not arrays , because arrays can have various signs . what is the "" one exception "" to which you refer ?"
115287,what kind of analysis did you do ?
113980,what does the ` group task ` mean in the equation ?
115348,"i don't really follow your algorithm . why not just assign numbers from 1-52 for the different cards & randomly shuffle their order . then the 1st 13 were 'assigned' to player 1 , etc ?"
114680,"given that you have * data * , could you explain what you mean by the test not being "" statistical "" ?"
115376,"do you want to * forecast * the value for a specific video , or just be able to say 'the videos on this channel average x views in their 1st 30 days' ?"
115421,"plus , how would you visualize multi-dimensional * points * ?"
115269,i think it would help if you gave the actual problem you are trying to solve . basically clustering will find things based on a distance measure . . . but are all coefficients in your vector equally important in determining the true group ?
93845,"further checking if i understand the additional normalization snippet : what's the role of ` temprepmat ( kk , kk ) = -1 ` line ?"
115506,may be ou could hold out 12 months of data and see which gives better prediction and pick the model that gives best accuracy ?
115483,what is the naive estimator ?
115556,"repeated measures are multiple measures taken on the same experimental unit . your experimental unit here is a subject at a particular period , rather than just a subject . if it was the later then it would be a repeated measure design . but since treatment changes from period to period , the exp . unit is the former one so i think a crossover design is the correct description . perhaps you can search for crossover design and see how people analyse it ?"
115647,( 1 ) are you using just frequency and order as features ?
115649,just to clarify : did the surveyors try to identify * * every * * hot spot in a selected tract ?
105066,could you provide more details ?
115789,the constant variance assumption of the model you fitted is clearly false . does this not concern you ?
115802,"sem represents the expected error in your sample mean value versus the population mean ; it depends on the number of observations . the mad , like the standard deviation , represents the variation of the population about the median / mean , independent of the number of observations . which type of information do you wish to display ?"
115777,"assuming you don't mean the whole population , my question is * why ?"
112896,"could you please explain what the "" original curve "" in the bottom plot represents ?"
115785,"what kind of variable is data $ cond , factor or quantitative variable ?"
115815,"what's the "" length of the burst "" ?"
111915,"ok , so something more informed might be helpful . what is ` variable ` ?"
115885,it is really easy to calculate a bayesian credible interval for the measure you are looking for . would that be of interest ?
115904,"it's not clear how far your problem is about writing good code or solving a statistical problem . a problem can be both , but questions focusing on code are usually off-topic here . on the statistical side at least two questions are crucial : do your values actually include zero ( "" non-negative "" implies that is possible ) ?"
115936,"as usually defined , [ f-distributions ] ( url ) are * not * symmetric . what is the density of the distribution you intend ?"
115947,this line : ` sample_mean = sum ( sample1 sample2 ) ` . did you want to divide by sample size ?
115955,how is consumer satisfaction coded ?
115962,"how did a factor of $ ( 1- theta ) ^ { -n } $ appear in the likelihood when $ ( 1 theta ) ^ { -1 } $ appears in $ f $ ( as it must , to normalize it ) ?"
115939,what are y1 and y2 ?
115929,do you mean ` survreg ` ?
116037,"the answer is the same as in the previous question you asked : url so , what did you not understand about the previous answer ?"
112900,are you imagining two sets of samples populating the same space ( i . e . having the same features ) ?
114016,"what do the values of ` data [ , 2 ] ` and ` data [ , 3 ] ` look like ?"
116135,is your input matrix certain to be symmetric ?
116168,""" * i'd like to find the value of x where the difference in means of the two groups . . . is most significant . * "" -- to what purpose ?"
116249,"can you point to an example ( or even better , multiple examples ) of this phrase being used within context ?"
116294,why do you need to test the equality of means ?
116323,biased in what sense ?
116325,"can you say something about what you mean by "" analytical "" versus "" predictive "" work ?"
116334,what kind of explanation are you looking for ?
116338,"if someone always raises , then they are giving up the advantage of bluffing . how many people are assumed to be in the game ?"
116427,your question is rather unclear . can you explain / clarify further ?
116389,"so , which part of the question is about lof ?"
111869,do you have any a priori hypothesis about the relative strength of different approaches ( e . g . approach1 approach2 approach3 ) ?
116484,"what is it about being one standard deviation above the mean that really makes it count as "" engaged "" ?"
116510,don't suppose you can explain what the data is ?
116560,"what do you mean by "" the correct coefficients "" ?"
116309,"you are right that a variance function won't do anything about the non-normality . a transformation * might * fix both problems if you are lucky - so that's what i'd suggest . is $ a $ a positive measurement , so that $ log a $ , $ sqrt a $ , etc . would make sense ?"
116585,"is your question : ` how to define tp , fp , tn , fn ?"
116692,are you able to be more specific about where your difficulties lie ?
116700,"just using the em algorithm would be fine here , as you say you want a parameter estimate . also , is the maximisation "" easy "" if you observed the $ z ( n ) $ instead of $ x ( n ) $ ?"
116719,do i understand correctly that you want a method that can discover that the unlabeled data are concentrated on two parallel ( ?
116661,"often , by "" multivariate "" mr , people mean a single model w / 3 different y variables on the left hand side . you say you have an r squared for "" each of these models "" . do you simply have 3 univariate mr models , or something else ?"
116527,your formulations are unclear . what is ` average within-cluster distance ` : are there meant distances between points or between a point and the centroid ( the mean ) ?
116799,"andy , true , but this is a very generic comment . can you advise how to construct graphs that would be useful for answering this question ?"
116530,more semantics idea : oldest male with the fall-back on oldest female if no male ?
116867,do the 3 symptoms always = 100 % ( there is no symptom-free skin ) ?
116883,why are you considering that the posterior inference is invalidated by such a beta ?
116501,what you really have are _four_ random variables ?
116942,do you mean newton-raphson or newtons method ?
116994,can you expand on what you mean by clustering ?
117022,"it's not clear what you mean by the expression "" * show my participants are similar to a pre and post intervention * "" . what did you test in your t-test ?"
117031,"your dependent , endogenous and instrumental variables are all binary or continuous ?"
116339,can you tell us more about the data ?
116910,how many features you have ?
116980,that doesn't look all that much like a truncated normal to me . you should use more bins in your histogram . why would they be restricted to be smaller than 1 ?
104938,how do you define $ p ( ( x mid y ) mid ( z mid y ) ) $ ?
117102,the huge negative intercept suggests that the range of the independent variable in your data set starts far above zero -- are you for example using time in days or hours from the beginning of the common era ?
117111,are you looking for another answer ?
117142,"unless you have fairly large samples at each $ x $ , you have to make some assumptions . how does y relate to x ?"
117200,"what exactly would it mean for "" the grades of one subject [ to affect ] the grades for other subjects "" ?"
117217,"a histogram isn't piecewise first order , it's a step function ( zeroth order ) . are you conflating frequency polygon with histogram ?"
117204,could you explain why you are considering regression solutions when the only predictor is dichotomous ?
117073,"sorry , but , you see some correlation ( e . g . , by plotting the first v / s the second principal component ) or you measured it by some way ( e . g . , computed the correlation coefficient and / or the covariance between the variables ) ?"
117140,"sixty observations is not that bad but as you already know that the civil war changed the pattern of the series , why not include this event as an intervention and use the entire sample ?"
117329,what happens if you replace ` gbmfit ` with ` gbmfit $ finalmodel ` in your call to ` plot . gbm ` ?
117355,this question is a little puzzling because computing a cdf would seem to be unrelated to whether the distribution is skewed or not . are you contemplating some particular form in which the distribution is provided to you ?
117369,"if you set $ lambda $ in the second formulation equal to $ 1 / ( 2n ) $ times the $ lambda $ in the first formulation , then the objective function in the second formulation is $ 1 / ( 2n ) $ times the objective function in the first formulation . in effect , you have merely changed the units of measurement of the loss . how do you suppose that would change the optimal values of $ beta $ ?"
117387,is the intercept also significant ?
59260,"seriously , is this a stack overflow sokal affair ?"
117413,"in your picture , i can se some parallels with genetic sequences . have you tried any genetic clustering algorithms ?"
117319,"i cannot match the code you present to available documentation of the "" sfa "" for r . what is the stochastic specification ?"
117449,what makes you think that using 'nlme' would give you non-zero estimates for those variance components if you were to fit the same model ?
117433,"the sample means are obviously different , but "" very "" compared to what ?"
117450,where do you perceive a contradiction ?
117462,"could you provide more information , specifically the context or applications you are interested in ?"
117370,i'm not sure i understood your question so here it is just a comment . there may be more than one model that performs reasonable well for a finite sample of data . why wouldn't you settle the issue by comparing the mean square error and the aicc of the models or testing the significance of each parameter ?
117477,"why would you want one , if we may ask ?"
117532,"what exactly do you mean by "" treating $ theta $ as a vector "" ?"
117554,"what do you mean by "" coefficient "" ?"
117451,"since there are an infinite number of these functions , how are you going to assign prior probabilities to them ?"
117438,"it is unclear what you want to prove in the second question , because the chinese quotation is often taken as the * definition * of absolutely continuous . what definition are you starting from ?"
117495,"( the example you point to on se does not seem to conform to your characterization : there , site proposals are ordered by * recency * , not by "" highest voted to the lowest . "" and that's not a survey , anyway . ) what do you mean by "" individual score "" and "" favorite requests "" ?"
117621,"could you elaborate on what you mean by "" preserve "" ?"
117645,"a quadratic model * to log-log transformed data seems to do okay , but your models really should come from theoretical considerations . $ quad $ ( * if you had more data , you might be able to support a cubic ) . if you really have no theoretical basis , and you have enough data ( is that all you have ?"
117628,where did this formula come from ?
117652,what do you mean ?
117664,how about checking if the kkt conditions are fulfilled ?
117724,why downsampling ( via agregation ) should take extremely long ?
117762,i am having trouble reconciling your title with the question . are you perhaps mistaking $ r ^ 2 $ for effect size ?
117775,what is your factor ?
117780,"so you ( 1 ) have an information like k1 ( beta ( 1 , 1 ) ) , or ( 2 ) have no any additional information ?"
117781,"first , please show how a correspondence matrix of yours looks like . second , what are these plots and how to understand them ?"
117782,"could you expand a little on what you mean by "" not quite accurate "" ?"
117804,what data do you have ?
117767,"suppose there are 3 customers ( a , b , c ) and you can ask each one twice . in what order you ask them : a , b , c , a , b , c ?"
117799,could you be a little more specific about what you need explained ?
117757,"if you write $ y_i = x_i ^ 2 $ then the expression you ask about is $ bar y $ and so , apart from notation , it doesn't seem to be anything different from the previous limit which you say you understand . that makes it difficult to gauge your question : perhaps you have already answered it ; perhaps it asks about how to compute limits of sequence of random variables quite generally ( and therefore would be far too broad and difficult to address adequately in a forum like this ) . could you edit this question to make it more specific ?"
117791,those data sure look a little screwy . can you say more about what they are & where they come from ?
117865,how exactly were speeds measured ?
117873,"if you know how many outliers you have ( 200 , though i don't know how you could know that ) and you have some definite criterion for what makes an observation more outlying than another , then you simply order the observations by that criterion and take the 200 largest ones . so what do you mean by 'outlier' ?"
117882,"are you simply asking for online updating of ordinary parameter estimates ( add an observation , update a parameter estimate ) , or are you actually asking for a bayesian approach to this problem ( updating posterior distributions of parameters , given some prior ) ?"
117945,this expectation is merely that of the squared component of $ x $ in the direction $ v $ . it cannot be computed without additional assumptions on the distribution of $ x $ . * * what are those assumptions ?
117972,why does the biomarker have to be dichotomized ?
118008,"what is ` lda ` , moose ?"
118007,"are you going , in the 2nd paragraph , to treat columns of the correlation matrix as if data variables , like columns of x ?"
118033,""" best "" for what purpose ?"
118109,"thank you for adding the tag . please read the wiki to understand the process . the question asks about the "" empirical rule "" . did they give you any rule about the normal distribution ?"
118131,difference in what ?
117953,"when you want to forecast the next 1 minute , 5 minutes , etc , what kind of forecast do you need ?"
118173,"$ s $ is not integer-valued , so how is $ sum_ { j = 1 } ^ s $ defined ?"
118226,"1 . "" * this values are not a sample , but my entire universe * "" . . . then significance tests make no sense . if you have the population , you can see at a glance if it's actually uniform . $ quad $ 2 . "" * most of the data ( 80 % ) have the same value * "" -- then how on earth could it be uniform ?"
118258,i'm not an expert but i'm curious : how can you apply a markov chain to this case if you don't know the probability of a person to take a specific transportation method at each step ( day ) ?
118302,are you asking about how to detect outliers ?
118276,"abundance as percent is at best roughly normal , if only because of the bounded scale . environmental variables [ in statistical terminology * * not * * parameters ] are more commonly right-skewed than normal . but we can't be sure and you can't be sure whether transforming some or even all of your data is needed . you are likely to be asked , at a minimum , whether you considered transformation so the simplest advice is to consider analyses based on untransformed and transformed data and see which helps more . in any case , why presume that each variable must be transformed in the same way ?"
118313,do you mean binomial or multinomial ?
118327,"exactly what do you mean by "" usually high vifs "" ?"
118345,"if you have the whole distribution , why would you need to estimate the parameters ?"
118367,"the evident limits in the upper plot are due to the constraint that gpa lie between $ 0 $ and $ 4 $ ( or $ 60 $ and $ 100 $ or whatever the limits are ) . that phenomenon will be difficult to remove , so concentrate on other issues first . one interesting one may be interactions . how many binary variables do you have ?"
118172,( 1 ) in what precise way is the computation failing ( error message ?
118427,"did you look into chapter 1 of brian ripley : "" stochastis simulation "" ?"
118429,why not use an outlier detection algorithm ?
118454,"i really do not think anyone is going to read your code and debug it . however , here are two common pitfalls : ( i ) have you checked your derivatives with finite differences ?"
118459,"despite the graphical illustration ( thank you ! ) it still is unclear what you mean by "" align . "" does that mean perhaps subtracting a constant from all "" value "" s in one dataset ?"
118488,"i'm totally unfamiliar with betting on horse races . in a pari-mutuel , do the bettors know how much has already been wagered on each horse ?"
118510,""" best "" in what sense ?"
118511,"i would like to suggest the answer will depend on additional assumptions you make . if there were such a procedure , then what would prevent you from taking your subgroup , throwing in billions of data from other datasets , and applying the procedure to the collective dataset to get "" more information "" about the subgroup ?"
118513,what criteria do you use to put strings into each bucket ?
118567,closely related : url and url ( which is * exactly * your question but it concerns converting * averages * computed from one scale to averages relative to the other ) . but why do you need to perform a conversion at all ?
118615,might help to make this of more general interest by explaining what the sap is * for * - who reads it ?
118651,don't parameters just take you from a general case or a family of cases to a particular one ?
118653,may be genetic algorithm or simulated annealing ?
118655,what is your question ?
118704,do you consider all three human experts equally good ?
118680,what is the probability that someone will do your homework for you ?
119760,"your process is a brownian motion ( typo in $ mathrm { min } ( t_1 . t_2 ) $ , you mean $ mathrm { min } ( t_1 , t_2 ) $ right ?"
119765,$ d $ is a difference of cdfs ( cdfs give probabilities ) . the p-value is also a ( conditional ) probability . are you unfamiliar with how p-values relate to hypothesis testing ?
119797,"aleksandr blekh - the op is using a dataset provided by scikit-learn . the page on which the dataset appears mentions "" if you use the software , please consider citing scikit-learn "" . why would you not cite scikit-learn then ?"
119848,can you use size of the stores as an independent variable ?
119869,"you haven't really asked a question here . to get meaningful answers , you should state what your goal is . in other words , how would you evaluate whether an answer is good or not ?"
119924,"hi , what is the methods that you are using to come up with propensity score probabilisties ?"
119945,"you refer to group sizes , is your dependent variable binary or are you trying for a variant of ancova ?"
119946,can you confirm that $ t ( t ) $ observed ?
119943,what is the observed $ x $ ?
118634,"btw , pubmed's database can be queried automatically to look for papers regarding "" exploratory data analysis "" . the url should have the format : http : / / www . ncbi . nlm . nih . gov / pubmed / ?"
120085,"k-means clustering in its classic sense is only for cases x features dataset ; and make use ( indirectly ) of euclidean distances , not cosines or such . however , cosines are related to euclidean distances . plese read url what exactly do you need to do and what is at your disposal ?"
120097,for what survey ?
120129,these functions in the figure are random or not ?
120132,"you are in fact thinking about a regression model where the number of red eyes determines height ( or vice versa ) . this way , you would also model nolens volens how tall you expect a woman with only one eye ( e . g . due to an accident ) to be ?"
120134,"what's "" the other way round "" ?"
119894,"what does "" band "" ( & / or "" re-band "" ) mean ?"
120194,"you seem to be asking a different question . are you sure you really want a multivariate analog of a median , then ?"
120210,what kind of differences between the fractions are important to you ?
120221,"when you say "" what are their parameters ?"
120067,"what do you mean by "" how do i interpret this "" ?"
120110,"what does this plot look like in * polar coordinates * $ ( r , theta ) $ ?"
120288,"it's hard to say . can you say more about your data , etc ?"
120303,"you lost me at the very first line , which is neither the sample correlation nor a covariance . ( it is a sample raw second moment . ) are you sure this is the expression you want to analyze ?"
120328,have you tried looking at the r code ?
120237,"are you saying that your dv can only take the values ` -2 , -1 , 0 , 1 , 2 ` ?"
120388,this question doesn't seem to have much to do with java . i'll replace the tag with a relevant one ( ` probability ` ) . your question is very unclear . please edit to explain what you mean more clearly . how many attempts are there . is the 0 . 4 the chance to win at least once over several trials ?
120304,"what does "" 2-pl "" mean ?"
120431,"i don't understand you choice of split 9 : 1 , why 9 : 1 ?"
120485,maybe when you random do you mean random generate from a discrete uniform distribution ?
120457,how are you going to use these results ?
120500,"what does "" important "" mean ?"
120513,in ` r ` ( which is not a speed demon ) this calculation takes a little over two minutes without using sparse matrix operations . what kind of timing are you looking for ?
120521,what are you trying to do with multiple imputation generally ?
120566,is this an attempt at latex ?
120589,"when you say "" holding the burn treatment at their mean value "" do you mean "" at the overall mean across both vegetation types "" or "" at the mean value within vegetation type "" ?"
120671,what does svr stand for ?
120687,can you please provide more context ?
120678,"( ctd ) . . . ( for example , it might be that it actually goes to something different from - but very , very close to - normal ; how would you know ?"
120751,looks like your dependent / explained / left-hand-side / $ y $ -variable has only 5 categories . is that correct ?
120766,is above your entire data or is this just a sample of the data ?
120780,( ctd ) . . . i believe $ alpha = 3 / 8 $ was suggested for normal quantiles because it gave something near to expected quantiles in that case . what properties do you want ?
117783,you need to clearly specify your data . what is the meaning of * long_term * . how many categories does it have ?
120822,you might have over-generalized your problem to the point where a good answer would have to cover most of statistics and data mining . why don't you just ask the question you actually have ?
120884,what do you want to do with these data after preliminary analysis ?
120928,your question isn't quite clear . are you simply asking 'how does the gower distance calculate the difference between binary variables' ?
120946,i don't see 2 different models lurking in your data . can you clarify what you are referring to / why you think so ?
120964,why would you want to treat * side * as a random factor given that there are two and only two levels of the factor ?
120981,"* if * the bootstrap samples have exactly the desired coverage probability ( and are independent ) , the correct answer is indeed $ 0 . 95 ^ { 500 } $ ( which should be - very roughly - about $ e ^ { -25 } $ ) . ( in practice the bootstrap coverage is often quite some distance from the nominal coverage , however . ) why do you find that result surprising ?"
109846,"if "" p "" is the number of regressors _including_ the constant term usually to be found in a regression setup , then this formula is wrong . the last formula is correct only if we assume that the regressors are deterministic . exactly what is contained in this book you study ?"
121068,thank you . it looks like you are asking people to offer opinions about changes in weight within some undescribed experiment . by providing no information about that experiment ( is it a force feeding of mice ?
121071,"it makes perfect sense and is the basis for many outlier-detection techniques . but rather than inventing your own method , which might or might not work ( and the latter is far more likely even with methods newly invented by statisticians , which is why they need careful study ) , why don't you use one that has been theoretically checked and empirically tested ?"
120974,what is your purpose in comparing the curves ?
121102,or do you mean compare the means of the pcs ?
121092,"what does "" var $ ( theta ) $ "" mean when $ theta $ is a * parameter * ?"
121115,"on what basis do you say "" the sample size is way too huge "" ?"
121119,"have you read kruschke's [ "" how to report a bayesian analysis : teaching why "" ] ( url ) ?"
121070,"fixed . the idea was that once you paste it in , then as i said above , you ( i ) * select it * , ( ii ) * then press the { } button * . exactly as you would a code-block . how did you format your code ?"
121143,what's your question ?
121162,"the question is unclear . first you mention ols regression . it then dissapears . next , ` advantage . . . svd over pca ` - svd and pca cannot be compared as a mathematical operation and data analytical method . can your question be something about [ ways to do pca ] ( url ) ?"
121190,"it is hard to imagine how there could be such a reference--at least one with any credibility--because "" reasonably accurate "" is vague and * ought * to vary with circumstances , such as the magnitude of the consequences of out-of-control manufacturing runs . wouldn't you be better off knowing how the expected number of defective units is related , * quantitatively * , to the accuracy of estimates based on samples ?"
121209,is this [ self study ] ( url ) ?
121208,can you clarify the following : do you consider f bad ?
121215,are you asking to solve the problem allowing the unknown covariances to be any values consistent with [ mathematical restrictions on covariances ] ( url ) ?
121221,"it seems like you have a question about statistical methodologies rather than a specific programming question . as such , your question is a better fit for [ stats . se ] . but basically the two methods are complexly different . ` lm ( ) ` does a least-squares regression fit and ` line ( ) ` does a tukey "" robust "" line fit which basically divides the data and does a regression on the medians of the different groups . see the reference in the ` ?"
121222,how many observations per student do you have ( 1 or more than 1 ) ?
121199,lowtech could you be a little more explicit about what connection probit regression might have with this question ?
121261,how would you identify the $ mu_i $ otherwise ?
121176,can you rephrase your question to clearly specify what you want to test ?
120603,"if the null is true , the p-value should be essentially uniform ( not quite , because of the discreteness ) - i . e . sometimes high , but not always . i have little desire to examine your code ( indeed , this is the wrong group if that's what you're after ) , so you should make your question more statistical . what is your basis ( i . e . show pictures or other summaries of results plus the reasoning that was used ) for saying you get different results when using var and sd ?"
121336,your reasoning is pretty good . : - ) what is your friend's argument ?
121358,umm . . . isn't that the * definition * ?
121186,what does the contingency table of host * vs * parasite look like ?
121368,what part of the description in the paper are you having difficulty understanding ?
121293,what is the exact question you are trying to answer ?
121418,"i don't understand the prototype part of this . do you have 3 groups with your prototype and 3 without , or do you have 2 measures on each subject , or what ?"
74351,"please , say ( in the question ) what is "" paa "" and what is "" gmm "" ( gaussian mixture model or another ?"
121468,"it is difficult to advise . do you want to predict what are the top 100 values ( e . g . scores on some measure ) or is it crucial to predict which they are ( e . g . some name or descriptive text ) . in what sense are you trying to predict , including whether there is a time element to this ?"
121496,"x can't just be 'independent' . independence is a property of a set of random variables . you can use independence of x and y ( notice that that is independence with respect to both the variables ) to say that e [ xy ] = e [ x ] e [ y ] . but it doesn't make sense to say that x is "" independent "" because the natural next question would be "" independent of what ?"
121424,"your dependent variable is linear , while independent variables are circular ?"
121509,"what is "" the book by a . field "" ?"
121510,this reads a bit like a rather routine textbook question ; is this for some subject ?
121555,how are you dealing with the dependence in the data ?
121579,"where is this "" jump "" whereof you speak ?"
121592,"it really does depends on the data and the decision . any way , what does "" inaccuracy "" mean here ?"
121600,couldn't you simply bootstrap this ?
35940,"this is easy to do in r . 1st question : am i correct that you want 75 % of all cases to be { var1 = . 03 , var2 = 0 } & 25 % for all other combos , & not 3 units there for every 1 unit in each of the other combos ( ie , 37 . 5 % ) ?"
121431,"what do you mean by "" gives an indeterminate mean and sd "" ?"
121539,"how do you understand "" shape "" ?"
121638,"when you say "" sent out to a population "" . . . do you mean he population about which you wish to make inference ?"
121589,"i'm sure i'm missing something , but why not treat all groups as one big sample , compute the mean and the sd ( correcting for finite sample size ) , and then look for outliers ( correcting for sample size in each group ) ?"
121691,"i think this question could be rephrased to be more appropriate for this site . maybe something simple like "" what distinguishes biostats from 'vanilla' stats ?"
121659,"my concern is , why are you using a single model ?"
121651,statastic : . . . or is then there something off with your model ?
121662,"the initial statement is false in general ( it's false for two separate reasons ) . what is your source ( your link is missing ) , and what does it actually say ?"
121781,"the pr curve is fragile , and not well-defined ( at 0 recall , the precision is not defined ) . maybe something like classic average precision is the better choice ?"
121782,"looking at the year parameter estimates , they're all about the same except for 1997 , 1998 , 2006 and 2007 . you could estimate coefficients for just those years ( recoding ` data $ strange_years - factor ( ifelse ( as . character ( data $ year ) % in % c ( "" 1997 "" , "" 1998 "" , "" 2006 "" , "" 2007 "" ) , as . character ( data $ year ) , "" normal year "" ) ) ` ) . how many observations do you have per year ?"
121796,"your information does not seem internally consistent , unless i misread the graphs or the notation . the first illustration shows no connection between $ a $ and $ c $ , yet your formula includes a term "" $ p_ { ac } $ "" which seems to imply those nodes * are * directly connected with an edge that has probability $ p_ { ac } $ of failing . you cannot use this notation to refer both to the probability of a single edge failing * and * to the probability of a path failing , because some nodes connected by single edges are connected by other paths , too . so what exactly does this notation mean ?"
121810,what does a q-q plot of the anova residuals look like ?
121811,"i do not understand what the difficulty is : just because the lines appear to have small slopes does not change the formula for finding their intersection ! ( in fact , the "" $ times 10 ^ 4 $ "" in the upper left corner suggests most of these lines have enormous slopes . ) what is the connection between this problem and the focus of our site , which is statistics , data analysis , and machine learning ?"
121882,"ludo , can you post your dataset ?"
121922,what does the definition say when $ h = t-1 $ and $ n = 1 h $ ?
120415,you may find these threads helpful as well : [ pca on correlation or covariance ?
121161,try ` set . seed ( 10 ) ` before you train ?
121971,is it possible for a person to spend part of a dollar ?
121994,as you are a psychologist i am really interested to know which journal you are talking about . did the reviewers demand it or are you preemptively trying to avoid criticism ?
106170,what are you regressing exactly ?
122015,"why not try regression , and predict the missing values based on a generalized hypothesis ?"
121997,"your formula for $ p ( theta ) $ does not give a probability distribution for $ theta in [ 0 , 1 ] $ . perhaps $ theta $ is supposed to be restricted to a narrower interval ?"
122039,"can you put a reference to a paper or such showing what you mean by "" elastic net "" ?"
122055,"often these vifs , large as they are , would not be a huge concern ( such as in a cross-validated predictive setting ) , but since your model was derived via stepwise regression they call into question the choice of variables . rather than going further , as requested , would you consider starting over with a better technique of variable selection ?"
114088,have you tried k-k-fold cross validation to determine the best k ?
122094,"when you say "" does the central limit theorem apply "" . . . but it's not clear what you're trying to apply it to . note that the central limit theorem talks about the distribution of standardized averages when $ lim_ { n to infty } $ , not something you might notice when $ n = 7 $ . what is the limiting process you're considering ?"
122113,"when there are just two variables and $ r $ is negative , you have no hope of creating a * nonnegative * $ r ^ 2 $ from its sum , do you ?"
122061,( 1 ) are you referring to random forests ?
116655,how do you know you have a multicollinearity problem ?
122213,what do you call ` inferences ` in this context and why only differences in inference interest you ?
122240,do you mean if there is a difference in two y values at a given x ?
122328,"for your first question , suppose a random variable $ x $ has mean 0 . what is the relationship between the variance and $ e [ x ^ 2 ] ?"
122331,could you be more clear ?
122372,consider : what are $ f ( -2 ) $ and $ f ( 2 ) $ ?
122380,""" * how could i improve this code substantially ?"
122390,many useful estimators are biased . why would unbiasedness be such a big deal ?
122396,are you sure you're getting the right statistic ?
122421,""" much master "" ?"
122475,"where did you "" come across "" this problem ?"
122471,what data did your first plot come from ?
122482,"are you asking about programming , or are you looking for specific statistics help ?"
122447,what is linex loss ?
122512,how many bins do you have and what is your sample size ?
122525,"when i fit models like yours with random data , i obtain plenty of spuriously "" significant "" variables ( depending on the threshold one uses for significance ) . that sounds like overfitting to me--but is it what * you * mean ?"
122533,"define "" good results "" , please . if you run in multiple times , does it work every time ?"
122541,are you sure you don't mean 'sample mean -2 / 3' for the method-of-moments estimator ( mme ) ?
122539,have you plotted the data & the model fit ?
122546,"are these being tasted , or are people just stating what they think without tasting ?"
122478,what does split-file mean ?
122553,"much about this question is unclear . because the mean is not invariant under data transformations , it is not apparent what distinction you are trying to make in the first paragraph . also , since you refer both to a "" posterior "" and a "" prior , "" presumably you are already adopting a "" bayesian approach . "" how , then , could it possibly become "" more bayesian "" ?"
122584,are $ a_0 $ and $ a_1 $ some constants ?
122283,"would you mind explaining or posting a link to an explanation of the distinction you are making here : * "" do the additional accusations change the likelihood that the first accusation is false ?"
122646,and what is $ n $ and $ p $ ?
122654,it would be helpful if you could describe your data in more detail . how many ecotypes do you have ?
122799,have you checked rpart . control default settings ?
122805,looks to me that you are looking for [ concordance ] ( url ) ( and [ inter-rater reliability ] ( url ) more generally ) ?
122668,what about skew ?
122692,is $ y $ continuous ?
122849,"masfenix , please de-cipher all the acronyms in your question . pca , mca , mfa . . . otherwise , how can a reader know what they mean ?"
122807,you only observe a single $ y_n $ ?
122717,what does ` set_sum_contrasts ( ) ` do ?
122929,"for monotonic prediction function , this should be straightforward . non-monotonic functions do not necessarily have a single solution for x = { y-a } / b . what do you mean by statistically sound ?"
122983,"oh , i forgot to check . . are the $ h_i $ meant to be independent of each other ?"
122678,how many observations you have ?
123040,"please note that with pca , too , you often won't get as "" good "" results as you happend to get . clustering on many features and then projecting the clusters in the subspace of just few first pcs may well show a picture like you obtained here for t-sne , - unless those pcs grab almost all the variability . did you compare - what portion of the variability is captured by your first 3 pcs and your first 3 t-sne-dimensions ?"
123069,"can you please provide the reference related to the "" desired result "" ?"
123071,is there a reason you aren't simply using standard regression methods ?
123137,what reconstruction error are you using ?
115883,do you want to create a language with the same bigram or just a sequence of words without actual meaning ?
123202,the more fundamental question is : is there uncertainty in these measurements ?
123215,could you please state the book from which this exercise is taken ?
123106,have you considered the wilcoxon test ?
123171,"for those of us who want to help but don't use r , could you post the graphs you're seeing ?"
123255,"so , what do you think ?"
123264,is this homework ?
123262,""" in some papers , it has been mentioned that there is two way to obtain direction which is random and fixed direction . "" "" in the literature it has been suggested that another possibility is taking p times a direction through 2 randomly chosen observations . "" can you cite your sources for those statements ?"
123318,imagine $ n = 2 $ points in 2d or in 3d . what is the dimensionality of the manifold that these points are occupying ?
123248,are the parameters of the beta distribution known ?
123330,"it doesn't really make sense to talk about the correlation between more than two random variables . for example , what is the correlation that the r would be measuring in multiple regression ?"
123265,"your model description is incomplete : how are x , a , and b related in a joint probabilistic model ?"
123333,adrian binomial is for sampling with replacement . it would give an approximate calculation for very large numbers of both kinds of marble in the urn . . . but how many marbles are we talking about ?
123359,why not tranform the data prior to standardizing it ?
123123,"the only question that appears in all this is # 1 , whose answer you obviously already know . what do you really want to ask ?"
123436,"by 'normalize' do you mean "" transform a variable to appear close to normal "" ?"
123465,hint : how is the density curve computed ?
123499,so are the using this process to generate more data to add to their sample . . . or what exactly ?
123555,can you explain further ?
123566,""" effect sizes "" are measures of something . what are you trying to measure ?"
123576,"looks like you have a cyclical pattern with a length of 69 in your data , do you know why this would be the case ?"
123621,what is your question ?
123615,"one of your considerations should be what the data represent relative to the conclusions you would like to draw . if "" here "" means * within these data , * then obviously there is a relationship--albeit weak--and you can quantify it by computing proportions within your table . if "" here "" means some larger population the data are intended to represent , then how were the data obtained ?"
123626,"by "" hedges' d "" , do you mean [ cohen's $ d $ ] ( url ) or [ hedges' $ g $ ] ( url ) ?"
123723,"since the same function name can be defined in more than one package , you should specify which package's ` forecast ` function you use ( presumably ` forecast : : forecast ` ) . where in your code did you call ` forecast ` ?"
123697,i am confused . what is the difference between au-roc and au-pr in your definition ?
123755,don't you need a class statement ?
123703,"have you considered ` plogis ( predict ( fitted , newdata = . . . , re . form = . . . ) ) ` ( see ` ?"
123789,"beware of different uses of the same word or phrase in different disciplines . in a physical system "" degrees of freedom "" is used in the same sense that "" number of identifiable parameters "" would be used in a statistical model . ( technically , it's the dimension of a real manifold whose points correspond to "" states "" of a system under investigation . ) although the concepts are related , they are not exactly the same . i suspect the thread at url may answer this question . does that help ?"
123814,i want to suggest hierarchical bayesian modelling . are each cohort the same size ?
123895,how are you using this for outlier detection ?
123865,"please do not alter your post in order to respond directly to comments ( unless the alterations reflect improvements to the question itself ) : instead , post comments here . i have rolled your post back to its original version . you attempted to say that you are interested in "" representativeness , "" but that's a completely different issue than the questions you originally raised about sample size and population size . would you care to clarify this ?"
123905,"okay , but as it stands i would expect some quick answers along the lines of "" why aren't you using least squares ?"
123924,"there is only one distribution that models the rolls * correctly * : it is the one you employed in ` r ` . there should be no mystery why using other distributions gives other ( wrong ) answers ! is your question about how to implement that distribution in excel , then ?"
123930,"i believe the domain , although not convex , is the union of two convex regions : one for each sign of $ x_2 $ . ( each is a cartesian product $ f times mathbb { r } $ where $ f $ is one nappe of a cone . ) why not , then , solve the problem separately for $ x_2 ge 0 $ and $ x_2 le 0 $ ?"
123356,do the models include site effects ( either fixed or random ) ?
123967,"although you discuss goodness of fit , it sounds like what you really want to do is the fitting itself--that is , to estimate the 3d means and covariance matrices . would this in fact be the case ?"
123953,"i believe the answer will vary depending on the precise meaning of "" positively associated . "" what exactly do * you * mean by this ?"
123848,"also , how can you run a simulation ( or make a plot ) without specifying a value for $ c $ ?"
123662,where did you get these formulas from ?
123995,why do you want normality ?
123666,uhm . . . is there anything useful in say [ hamilton ] ( url ) ?
124004,"chamberlainfoncha : but what is "" predicted value "" in lda ?"
124000,what book are you using ?
124037,is there some reason why you think that the confidence intervals shouldn't be trustworthy ?
124040,"is your goal to interpret the effects of these variables , or to use them to predict another variable ?"
123692,"have you looked more closely at the data for cases that had events around the "" suspicious "" times ( approx . times 150 to 600 ) ?"
123969,"cosmetic , but never say that you have a simple question . it's unnecessary if you're right that it's simple , yet puzzling if you're wrong . also , although people won't usually say so , it invites the rhetorical response that if that's simple , why are you asking ?"
124058,what substantive question would such a conclusion answer ?
124061,"i don't think your mc . pvalue function does anything meaningful . ( by the way , the variable cnt is not defined -- you mean count , right ?"
124059,two spikes will remain two spikes with any monotonic transformation . the good news is that regression does not require any marginal distribution to be normal . the bad news is that regression may not be a good method if the response variable has this kind of distribution . but why do you call this dichotomous ?
124074,"when you "" register "" that $ x_i = l $ , do you also record the fact that the object was longer than the ruler ?"
124081,the title is much more general than the example . do you want the full generality of the title or something much more like the specifics of the example ?
124210,so you're saying that the * * f-statistic * * for your model is * insignificant * ?
124225,"no , you should not use the poisson distribution or any other distribution with a fancy name that you find listed in your book . instead , the player should ponder the fact that ( assuming that the various attempts at making a basket are _independent_ ) the probability of missing on each and every one of $ n $ attempts is $ left ( frac 14 right ) ^ n $ which decreases towards $ 0 $ as $ n to infty $ . how large must $ n $ be so that this probability is smaller than $ 0 . 01 $ ?"
124362,most likely it will not be possible without the prior . what is your $ h_0 $ and $ h_1 $ ?
124354,what are your variables ?
124365,"in his blog post , rob notes where this benchmark comes from : "" these thresh olds are the best per form ing meth ods in the analy sis of these data described in athana sopou los et al ( 2010 ) . "" have you looked at the athanosopoulos paper ?"
124377,"can you give some references , and then describe one of those analyses more in detail ?"
124395,some clarification of how you think the clt would be applied would help us understand what this question is really asking . since the clt is an assertion about sequences of ever-larger samples--which are obviously impossible when sampling without replacement from a finite population--then precisely * what * sequences do you have in mind ?
124452,"although we can make educated guesses about what the notation might mean , please supply some context to help us out . where does this question come from ?"
124406,"is there some reason why you need to examine the ` 2 ^ 30 ` possibilities in parallel , as the question seems to suggest , rather than examine the 30 variables serially with a procedure like the lasso ?"
124363,"this is weird . different kernel width can certainly influence the kpca results quite a lot ( and there are some techniques to select a reasonable width ) , but i don't understand how one can have "" non-decaying "" spectrum simply by varying the kernel width . do you maybe want to update your question with some figures illustrating the situation ?"
124515,what precisely do you mean by 'linear regression model of the type . . . ' ?
124525,does it matter if the intercept moves around a bit ?
124561,how to handle missing data can depend on what model / analysis you use . are you going to fit a survival analysis ?
124565,where did these predictions come from ?
105557,can you provide a specific example of a problem you would like to solve ?
124581,don't you need to define a study question to answer this ?
124614,what do you mean by weight ?
124212,"no real data will be perfectly normal / lognormal / . . . , and with enough observations you can detect even trivial deviations from it . a goodness of fit test doesn't answer the question you need answered ( "" is a lognormal model reasonable for my purposes ?"
124634,i believe the answer to this question depends on what working covariance structure you are using . can you clarify that ?
124649,"are you after a single test for differences , or do you want to test each source for a difference ?"
124192,do i understand correctly that you want to select $ k $ out of $ 300 $ samples in $ 100 : 000 $ -dimensional space that would have maximal total variance ( i . e . maximal trace of the covariance matrix ) ?
10121,"richard , thanks for your question . unfortunately , the method you describe above will * not * produce entries that are normally distributed . the diagonals are 1 with probability one and the off-diagonals are bounded between $ -1 $ and $ 1 $ . now , the * rescaled * entries will converge asymptotically to a normal distribution centered around zero . can you give us more information about the problem you're actually trying to solve ?"
124675,"a way of seeing this is to take it to the limit . what if you would draw 100 , 000 observations or 1 , 000 , 000 ?"
124560,"your formula for $ lambda_k $ cannot be right , because multiplying $ c $ by $ sigma ^ 2 $ must * multiply * all eigenvalues by $ sigma ^ 2 $ rather than adding $ sigma ^ 2 $ to them . apart from correcting that error , where exactly do you need help ?"
124701,"if you are only asking how to use r , this question would be off-topic for cv . it might be a good question for the r-help-listserv . can you clarify ?"
124702,"can you elaborate a bit more . collinearity problems that mean that the model won't converge , that the standard errors are too high , or that you don't like the estimates ?"
124697,what sort of variable has 10k categories ?
124714,glad to see that you have read principles of forecasting by armstrong . autocorrelation can be used to build forecasting models or to assess forecasting model by examining the residual auto correlation to see if the forecasting model is adequate in capturing all the information in your data ?
124718,"this is so vague that i am not sure what you are really asking , but it seems to focus on how to compute pdfs of transformed random variables . for information on that , please [ search our site ] ( url ) . at the end , exactly what do you mean by "" . . . the gaussian pdf is not integrable "" ?"
124719,for each study unit ( gene ?
124728,"can you obtain some measure of * variability * of the scores within each college , such as the quartiles ?"
124746,"keeping the values in sorted order $ x_ { [ 1 ] } le x_ { [ 2 ] } le cdots le x_ { [ n ] } $ requires only $ o ( log ( n ) ) $ effort for each value and finding $ i $ for which $ x_ { [ i ] } lt x le x_ { [ i 1 ] } $ for any $ x $ also takes only $ o ( log ( n ) ) $ effort . at that point there are all kinds of ways to estimate the pdf at $ x $ , if you even need it : perhaps you only need the cdf , which can be estimated by interpolating between $ i / n $ and $ ( i 1 ) / n $ ?"
124798,"have you made new , shorter , more specific questions yet ?"
124828,are they normal ?
124831,"by white noise test , you mean ljung-box test or its variants ?"
124852,what makes you think your test results might be misleading you ?
124863,"you will most likely have * very * little power . can you say more about your data , the distribution in question , and the manner of deviation from the distribution that you care about detecting ?"
124725,are you asking for code for some software ?
124856,"have you tried something like ` chisq . test ( a_and_b , simulate . p . value = true , b = 1e5 ) ` ?"
66300,"you are right , which is why i did not post my comment as an answer . but what kinds of situations are there where the alternatives vary so radically from the null in * both * directions , except due to chance alone ?"
124816,to my eye some values of your variable appear negative : is that right ?
124990,what's wrong with 6 multiple regressions ?
124999,please tell us the * purpose * of the sampling . what will you do with the sample results ?
125033,what exactly is your question ?
124936,"note that your proposed method to sample from the positive mixture is incorrect , because in any random sample it is more likely than not that one of the mixture components is represented * more * than the other . just consider the problem you run into for a sample size that is an odd number ! are you sure you are not confusing mixtures with * linear combinations * of random variables ?"
125077,"if you want to recover the full regression equation , do you know the means and standard deviations for your variables ?"
125086,do you have a physical model of the hopping ?
125130,"the case where there a multiple categorical predictors is fundamentally different from the case with a single categorical predictor ( in the linked question ) . can you show us a simple reproducible example , and can you show us what sas produces ?"
125097,i see no linear regression in your display . are you taking derivatives of the red curve ?
125139,what do you mean by 'define the area' ?
48360,"alex , what you mean by "" regularized regression "" ?"
125274,"can you clarify your question and precisely what you mean by "" bound the estimation error "" ?"
125292,"i think i was saying actual as independent : ) , just a convention , though . but what exactly are you trying to do ?"
125316,""" spatial correlation "" means that , even when all of the gaussian parameters $ ( mu , sigma ) $ are known , the measurement at one pixel is related to the measurement at another pixel . can you explain how this is possible ?"
125318,"i can recommend numerous papers once i determine your problem setting and assumptions . do you want the destination to be a known "" place "" ; i . e . , a discrete location like "" home "" , or "" work "" , or can it be an arbitrary physical location ?"
125258,can you say a little about how your plots were made ?
125345,"what do you mean by a "" noise-only realization "" ?"
125340,did your experiments have any controls ( a randomly selected group that was given a different intervention for comparison ) ?
125358,"the equality is false in general , and it's incorrect in several different ways at once . you're trying to produce an * estimate * , so the left hand side should not be $ sigma $ . the scaling factor won't do what you need . what properties do you seek for an estimator of $ sigma $ to have ?"
104234,what do you mean by 'theoretically correct' in that context ?
125426,it depends : there are many ways in which a variable can be non-normal and some test are more sensitive to one type of deviation and others more sensitive to other types of deviations . why do you want to test for normality ?
125362,can you explain what slentry = 0 . 025 and slstay = 0 . 025 means ?
125434,did you look to see if one implies the other ?
125479,is this a problem for a class ?
125477,"i find the quoted question confusing . did you mean to type "" * in order to * * * * find * * * * 5 useable items * "" ?"
125424,why are you doing clustering before classification ?
125487,have you considered some sort of glm ?
123327,"it appears that you could rephrase your question as "" for given $ alpha $ and $ beta $ does there exist a vector $ mathbf { a } in mathbb { r } ^ { 3 } $ such that $ ( 1 alpha ) y - x beta y ^ 3 = mathbf { a } c $ , where $ c = left [ x , y , y ^ 3 right ] ^ t $ . "" is that right ?"
125518,""" data "" isn't significant or not . what questions do you seek to answer with the data ?"
125523,the usual approach is to fit a model in your predictors and let the data tell you whether coefficients are positive or negative . why would you want anything else ?
125467,"where you write "" is actually the sum of , "" does that mean you expect the coefficient of ` mixed ` in this model to be the sum of the coefficients of ` piano ` and ` guitar ` ?"
125587,isn't y-axis the number of collisions ?
125616,"what exactly is a "" cross-section average of variance "" ?"
125628,will have to come back to the post-hoc thing : ) - this one is not meaningful . effect slices week * strain ( ?
125655,how is your image related to the question ?
116324,do you want to cluster customers or variables ?
125722,your question seems to be not quite clear . ` method that allows me to assess how well method b measures the size and position of the potatoes ` . of the _entire_ cloud of the potatoes or of _each_ individual potato ?
125764,"olr is a form of glm . in light of that fact , what choice are you talking about ?"
125756,what do you use to run rf ?
125779,"you should specify a null and an alternative , and a test statistic . this reads like a textbook-type question . is this for some class ?"
125832,"can you provide the exact reference ( edition , chapter , page ) ?"
125866,both [ the wikipedia article ] ( url ) and [ breiman's original article ] ( url ) are freely available . have you read them both ?
125928,""" generated "" in what sense ?"
125957,interesting question . might this belong on data science ?
125975,is this for a course ?
125955,forecaster could you provide links for those articles ?
125972,what do you want to test ?
125795,is the $ sigma ^ 2 $ you are talking about in the ar model the variance of the white noise ?
126002,do you have complete data at all time points ?
125988,what are $ lambda $ and $ theta $ ?
126001,what does the data look like ?
126093,what hypothesis do you wish to test ?
126101,"( 1 ) is it possible that "" no delay "" really means "" less than three minute delay "" ?"
126117,"was the p-value "" 9 . 555 "" followed by something like "" e-6 "" ?"
126063,"is the response variable time to make the decision , some binomial decision outcome , a multi-categorical ( multinomial ) decision outcome , or something else ?"
126136,"this kind of things happen when your model is heavily overfitting , ` na ` 's in your output could also suggest that . have you checked for overfitting ?"
5453,how do you get that $ dr_t = frac { 1 } { 2 } v $ ?
126111,"when you say "" a linear effects model "" do you mean a linear mixed effects model ?"
126165,linear modeling of what ?
126174,is this for a course ?
126176,kendall correlation uses just very simple operations - what is your problem with sample size ?
126180,doesn't ` geor ` itself support interactive variography ?
126236,what variable are you trying to create a probability distribution function for ?
126239,"a normal distribution of what , exactly ?"
125464,"i'm sorry , i got a little lost in all that . what exactly is it you want to do ?"
126258,can you map these manually ?
126264,what does map stand for ?
126269,"plotting against identifier will even at best only help if the identifier is informative . you don't tell us anything about your identifiers but in many datasets the identifiers are essentially arbitrary . isn't the focus of comparison whether the classifiers agree or disagree , generally , and specifically given what data were used ?"
126275,"was "" single good joke "" an iv ( instrumental variable ; as you state ) or just a simple regressor in your original regression ?"
126220,"( 1 ) could you elaborate on what is meant by "" probabilistic severity degree "" ?"
126139,are the $ x_i $ ' independent ?
126335,* now i would like to prove algebraically that we can estimate $ beta_2 $ using these two different approaches . * what exactly do you mean by that ?
126337,what attempts have you made at solving this problem ?
126338,"can you say more about your situation , your data , your model & your goals here ?"
126396,"what do you mean by "" i feel this is normal "" ?"
126392,do you have the denominators ?
126408,"just a quick fictional idea : can the _sequential_ nature of the k-means version you apply be the cause of your problem . did you try to use standard ( i . e . means update after all the objects get reassigned ) k-means , to see ?"
126421,"many distributions have differing ( but equivalent ) parameterizations : to be sure of what you are doing , you * must * consult the documentation . very few readers will have access to both minitab and spss , so please tell us : what do the help manuals for minitab , spss , and ` r ` tell you about how they parameterize this lognormal distribution ?"
126461,"the marginal mean is the sample mean . to get the sample standard deviation , why not just multiply the standard error by the square root of the sample size for that group ?"
126468,do you know what [ orthogonal polynomials ] ( url ) are ?
126484,doesn't the thread at url address this question ?
126499,what distribution are you investigating ?
126505,"the fourth line needs a negative sign . the last line makes little sense : what is $ theta $ doing , subtracted off like that ?"
126613,"after writing an answer i noticed that i'd read "" e ( y x ) be a nonlinear function of x "" instead of "" of x "" - was my misreading actually the meaning that was intended ?"
126652,you're saying you have two cdfs which are completely different and then asking how to compare them . that raises the question of * what is this comparison intended to show * ?
126655,can you provide your r code ?
126672,what is the assumed relation between the two error terms ?
126650,is your point that the coefficient for $ x_2 $ has to be equal to the square of the coefficient for $ x_1 $ ?
126511,i don't understand what that means . what do you mean by performance ?
126695,does the zero correspond to censoring or a corner solution ?
126709,"usually a very high number of support vectors indicates you are overfitting . i am going to guess your kernel matrix looks like the unit matrix . this is caused by using a too low bandwidth for the rbf kernel ( e . g . low $ sigma $ or high $ gamma $ , depending on your parameterization ) . what is your cross-validation performance ?"
126577,"the fallacy here can be seen by considering why you don't interpolate to monthly , daily , hourly . . . data . the sample size would increase , which is good , right ?"
126747,"you say observations are boat-delivery-day , but did xtset for just boat-day , that leaves out delivery . can you have more than 1 delivery per boat-day , or is boat-delivery-day = boat-day ?"
125414,"you have only one region whose share on urban and farm areas you measure , right ?"
126738,"please add the new information into your question by clicking the gray "" edit "" to its lower left ( be sure to use our formatting options ) . i'm not sure how good of an answer you'll get to this on so , b / c there are 2 components here : how can this be done , & how can that solution be implemented in r ?"
126786,was the residual standard error estimate with a degree of freedom correction ?
120833,"you ask , "" does annual precipitation predict tree height , or the other way around ?"
126773,"can you clarify if you are asking for ` r ` code , or if you are asking about the underlying issue ?"
126803,don't the mccullagh & nelder glm book cited in tim's link and the appendices in king et al's paper contain the proofs ?
126768,how badly do the values match up ?
126807,"what would it mean for that sub-population to be "" significant "" in your situation ?"
126810,can't you include habitat type in your pca ?
126822,could you provide a link to a paper ?
126907,"can't post this as a comment , but perhaps you can provide little more detail . for example , is the wind direction data a series of observations over a day , week , or month ?"
126930,"hax - what do you precisely mean by "" correlate "" there ?"
126961,"on cv , how to do things in r is off-topic , but how to analyse the data is on . specifying poisson seems to make more sense given that the data are clearly discrete ; but if these are counts then the upper limit of 5 seems hard ; is that a theoretical maximum ?"
126944,i don't really see a triangle here . what makes you think you have heteroscedasticity ?
126975,what are you trying to show about your data ?
126998,"is "" height "" , referring to height of people ?"
126905,are all the the values non-negative ( or non-positive ) ?
127080,removing zeros doesn't sound right . can you provide more info on the subject of measurements ?
127101,is $ y_t $ a scalar or a vector ?
126885,"spss displays you the matrix of the coefficients $ bf b $ and also saves ( standardized ) scores as new variables , appending them to the dataset of original variables $ bf x $ . the op - i think - standardized $ bf x $ and then multuplied , $ bf xb $ . and , voila , it's what spss appended to the dataset ! so , the op's question is that wow ! following by "" how $ bf b $ was computed ?"
126991,"you might be best to stick to one problem in a question . when you say "" $  $ is the stationary excitation input of white bernoulli distribution "" , do you mean $ eta stackrel { text { iid } } { sim } text { bernoulli } ( p ) $ ?"
127180,"do you really mean to characterize "" intractable "" as "" you can directly calculate the likelihood "" ?"
126864,"also , i cannot help asking : your profile says you are a startup founder ; is it a startup working with millipedes ?"
61464,please make it more clear : 1 ) ` vectors x and y ` is that two variables ( columns of data ) or two cases ( rows ) ; given that we're going to perform the analyses of variables . 2 ) ` x and y are the same ` did you want to say that x = y or any other way round ?
127222,"do you mean "" shapley "" ?"
127197,of possible interest : [ is normality testing 'essentially useless' ?
127254,what are the features in your case ?
127227,in what way do you expect the experiments to alter $ y $ ?
126723,"hello . not clear to me . do you mean they are two type of observations in your data , either a $ 0 / 1 $ variable assumed to be generated from a bernoulli distribuion or a continuous variable assumed to be generated from a gaussian distribution ?"
127331,""" most efficient "" can be measured in several contrasting ways . presumably you mean in terms of amount of computation , but even then do you mean in terms of the worst-case situation or perhaps an average over some kind of ensemble of possible inputs ?"
127399,"are you planning to add the three [ 0 , 1 ] variables into a composite index ?"
127393,"clearly if you have unequal numbers , not all points can be paired . do you have data where there are some in each group ( before / after ) that are unpaired with an observation in the other ?"
127428,a typo . i mean $ x_ { ( n ) } $ . your complaint about $ x_ { ( n ) } $ was that it was biased ( my reaction would be 'so ?
127409,"you say you're trying to simulate a fitted glm "" * without * using basic math functions , * not * using the simulate ( ) and predict ( ) functions "" - so if you're neither using basic math nor the inbuilt functions . . . how * are * you doing it ?"
127465,"are you really asking "" what _is_ the variance of the sample mean , or of any other statistic , and where and how are they useful "" ?"
127479,"this is surprising , interesting , and slightly worrying . will take a look when i have a chance . presumably these differences do * not * affect the profile likelihood confidence intervals ?"
97705,what is your forecast cost function ?
127503,why only two degrees of freedom ?
127498,"do you mean "" b * price advertising "" or "" b * ( price advertising ) "" ?"
127446,what does it mean for a feature vector to have -1 labels ?
127567,there were broad career questions posted here before . did you look at them ?
127570,"he does not seem to use the words "" marginal "" and "" conditional "" in the statistical sense ?"
127577,your terminology is strange . are you perhaps describing * tolerance intervals * ?
128624,"are you sure you mean "" multivariate "" regression ?"
128671,are you sure you are not talking about pca ?
128667,"there are some statistical issues that ought to be addressed before one goes blindly about implementing a solution ( as seems to be suggested by previous comments ) . most importantly , almost all data are uncertain . what is the nature of the uncertainties in your data ?"
128676,"depending on the available covariates , i think there will be problems justifying matching on your four groups ( did you leave out treated both t-1 ` and ` t ` or is my conception of the problem incorrect ?"
128729,"welcome , gemini ! you should probably fill us all in with some more details : what software are you using ?"
128736,i am not sure i understand this right - but i have the impression that there are some additional pieces that will help clarify . are you aggregating a series of individual scores ( and weights ) into a grand total ?
92690,"for each of the measurements , do you know the ordering ?"
128876,how many observations per student do you have ?
128883,are you sure you use the term correlation properly ?
128666,your model does not make sense as described . how do you come up directly with a pdf on $ epsilon ^ s $ rather than $ epsilon $ ?
128893,"the calculations to compute $ ( ( s 1 / s t 1 / t ) / 4 ) ^ n $ and expand it out as monomials in $ s , t $ are identical to the ones you are making . you can therefore let algebra do your work for you . setting $ n = 3 $ in that expression shows that the coefficient of $ s $ ( which corresponds to a net $ 1 $ move right and $ 0 $ moves up or down ) is $ 9 / 64 $ , which is considerably larger than anything shown in your diagram . can you find the nine distinct paths to which that corresponds ?"
128904,"when you say "" i am asked to comment on them "" -- is this for some class ?"
128947,what * is * a cluster then to you ?
127235,does the policy 'kick-in' at a certain known time ?
128963,* i either received an error or could not figure out how to use the fits * what errors ?
128999,whether an approximation succeeds depends on what you are using it for . what is your intended application ?
129081,"were these real data , or simulated data ?"
129102,don't number of hatch eggs and total clutch size suggest a generalized linear model ?
128796,are you saying the column headings represent an * ordered * category ?
129091,can you say a little more about the nature of your data ?
129127,how exactly will you rank ties ?
129068,should there be a bar over the $ x_n $ in the definition of hodge's estimator ?
129166,"sorry , what's the question ?"
129177,are you new to calculus in general ?
129136,"in respect of $ v $ , can you compute either $ text { var } ( hat { p } ^ 2 ) $ or $ e ( hat { p } ^ 4 ) $ or some other quantity which is a function of $ e ( hat { p } ^ 4 ) $ and lower order moments ( like , say , the fourth factorial moment ) ?"
129194,please add to your question why you are doing this ?
129206,are you sure that counting black pixels is a good way to solve your problem ?
129224,why don't you use r's ` ` simcomp ` ` package with tukey contrasts ?
129137,1 to andyjones . what do you want to do with the inverse ?
116881,"kmo isn't needed for pca , actually , it is for factor analysis ( [ see ] ( url ) and a link therein ) . bartlett's test - hard to say what was wrong without having data ( you could show your data , btw ) . this test is for large sample from normal population ( e . g . [ see ] ( url ) ) . this test is mainly for factor analysis . what might be a reason to use it in the context of pca as long as pca is seen as just a data reduction transformation ?"
129253,"so in short , out of sample prediction is poor . what makes you think that this just isn't due to there being little signal available in your data ?"
129262,"might the groups be different sizes , or will it always be 5 vs 5 ?"
127596,crf ?
129291,1 . add the self-study tag . 2 . should the last equation be $ alpha ^ ast_ { t 1 } = ldots $ instead of $ alpha_ { t 1 } = ldots $ ?
129342,"doesn't the answer lie here : * i decide to use a garch ( 1 , 1 ) model with a * * * * skew * * * - * student distribution * ?"
129337,"out of curosity , what is the application you have for this model ?"
121522,aren't you transforming all your documents in your training set before training ?
129296,are you sure that all mutations of the same gene have the same effect ?
129397,what you call profile of person ?
129386,are you using gaussian copula ?
114214,how are you identifying those blue points ?
129298,"14 . 25199-0 . 59877 * 27 . 150 = -2 . 005 , why do you say it doesn't work ?"
129445,"yes you can , why not ?"
129512,"the table under "" classifications "" in this post makes it seem like the series are * already * classified . what exactly is your input and what is the desired output from an answer to your question ?"
129510,in any software ?
129584,"hi , welcome to the site . the linked document talks about multiplying gaussian probability density functions while your notation in the questions sounds like you are asking about products of gaussian random variables ( which will not be gaussian ) . 1 . do you understand the difference ?"
129611,hint : are the switches being selected with or without replacement ?
129525,"maybe i am being a little dense right now , but i don't see how you arrive at the conclusion that you have an argument that would allow you to omit variables for ols that wouldn't also apply to logistic regression . how does the argument work for one and fail for the other ?"
129654,why don't you show your mixed-effect model specification here ?
129574,do you mean risk ?
129740,is there a specific reason for why you use ` fitdistrplus ` package instead of ` mass ` package ( ` fitdistr ( ) ` ) ?
127247,"what do you mean by "" a more extreme function "" ?"
129856,can you provide some context ?
129647,unclear what you are asking . are you asking how to compute a score for each person for each factor ?
129878,"is the ` marker ` in your formulas the "" metabolic marker "" or the "" stress marker "" ?"
129797,is function ` ` f ` ` known ?
129821,"please explain what you mean by a "" higher order cross-moment matrix . "" most moments cannot be placed naturally into ( two dimensional ) matrices . for instance , the third central moments of a vector-valued random variable $ mathbf { x } = ( x_1 , ldots , x_n ) $ with mean $ ( mu_1 , ldots , mu_n ) $ are of the form $ mathbb { e } ( ( x_i- mu_i ) ^ 3 ) $ , $ mathbb { e } ( ( x_i- mu_i ) ^ 2 ( x_j- mu_j ) ) $ ( for $ i ne j $ ) and $ mathbb { e } ( ( x_i- mu_i ) ( x_j- mu_j ) ( x_k- mu_k ) ) $ ( for $ i ne j ne k $ ) . exactly how would you arrange those into a matrix ?"
129928,"if you want to be able to specify correlation between a continuous and an ordinal variable , can you define what you mean by correlation in that case ?"
130005,i'm a bit confused . you need mi on what ?
130021,"because "" functional "" means different things in various branches of math , stats , ( and physics ) , could you please provide a definition of what you mean by a "" scale functional "" ?"
130041,"welcome to the site , leslie . do you know much about maximum likelihood estimation , in general ?"
129722,"( 1 . ) is simple : use [ bayesian linear regression ] ( url ) . ( 2 . ) is more tricky , because significance testing isn't a bayesian thing . the only thing you can do is compare the probability of different models , and $ text { car } = 0 $ isn't the basis of a model because $ text { car } $ isn't a model parameter . what's the purpose of the $ text { car } $ ?"
130018,do you mean $ x_ { i 5 } $ ?
130075,how did you obtain $ 3 / 4 $ ?
130167,"frankharrell , do you mean you need 96 instances of the lesser of the two events ?"
130169,"if we just look at the 9 observations you listed , your forecast is indeed poor , and a naive model would work better . but there may be a lot more to the series we're not seeing -- for example , these may be off-season forecasts , where the mean forecast and actual may both be , say , 2000 . how do you subjectively feel about the quality of these forecasts ?"
130181,"yes , indeed : exactly what do * you * mean by "" stochastic variability "" ?"
129973,"you lost me at the second sentence . the first refers to a specific person , whereas the second asks how to estimate their "" demographic distribution "" . how does an individual have a demographic distribution ?"
130197,wouldn't that just be the standard deviation of your fourth column ?
130227,did you read any literature on var ?
130248,are you familiar with bayesian inference ?
130254,what can you say about the likely errors in your measurements of $ y $ and $ x $ ?
130256,"the outliers affect the estimates of all the parameters , which complicates the analysis somewhat . are the data available somewhere so we can try to reproduce your results ?"
130277,do you really need all the data ?
130249,why would similarity of mean suggest that y approximates x ?
130401,"dimitriy , did you find a better answer or a paper on this topic ?"
130383,i think that your question should be more specific . what specific problem is it that you are trying to solve ?
31920,can you give more indication on the context in which such measure might be used ?
130460,"define 'prefer' . . . is that just "" answers * 'yes' * "" ?"
130490,"i don't think there's enough information in what you've quoted to be completely certain . one might make quite reasonable * guesses * at exactly what they did based on that description , but it could happen that the specific details may not be identical to what they actually did in one or more ways . the way to be certain about exactly what calculations were done would be to ask the authors . if reasonable guesses are sufficient , then you'll probably get decent answers for that . did the article come with supplementary information ?"
130209,` i don't fully understand one thing : how does olr handle a continuous dv ?
130525,but how many predictors do you have ?
130528,"do you expect a linear relationship between your dependent and independent variables , the amount of beginning material * x * and sequenced dna * y * ?"
130559,"small detail , but are you switching from ` idcourse ` to ` courseid ` between your data description and your model description ?"
130562,1 i have been wondering about that myself every time i saw it mentioned here on cv . why don't you post this example in the linked discussion on maths . se ?
130579,"i agree with jeremy : after you correctly used only 2 components for both fa and pca , results became very similar . condorcet-bach , do you consider the issue settled ?"
91990,"` regress the scores on my dependent variable ` not clear enough so far . are you regressing the "" dependent variable "" on the components ?"
130637,why don't you treat data handling errors are the part of measurement errors and deal with them accordingly ?
130657,"for example , what link function do you have ?"
129989,"i'm afraid i just cannot connect the dots between the start and end of this question in any meaningful way . could you be more specific--perhaps with an example--about what it means , precisely , for data that are "" generated by an underlying gaussian distribution "" to have "" categorical dimensions "" ?"
130688,""" * data which obey this rule : 164 * "" . . . * what does this mean * ?"
130719,under what circumstances does your current algorithm not work ?
130604,"xtzx in your scenario , how are you deciding which cases are rejected ?"
130828,what exactly was the argument for why call price is causing endogeneity ?
130786,i've never heard of uplift modeling . any links or references ?
130861,"good question ! i think two-parameter specification of bernoulli random variable is rather unfortunate example , because without the constraint , $ p ( left . x right theta_1 , theta_0 ) = theta_1 ^ { x } theta_0 ^ { 1-x } $ is no longer bound to be density . can you reproduce your observation for curved exponential family , for instance ?"
130895,what disadvantages do splits have that ca will resolve ?
130908,don't the ties kind of mess-up the possibility of using one of these categorical-response models ?
130979,"however , the question isn't quite clear to me . 1st , in the last line , should "" y "" be something else ( z , perhaps ) ?"
130984,"when you write "" the book "" , could you indicate which book it is ?"
130998,"you need to edit your displayed equation a little . is that $ frac 1n $ exponent applicable only to that $ 1 $ in the numerator the way it looks now , or did you want it to apply to the whole $ frac 12 $ ?"
131024,"this is only an ` r ` command to fit a model . it is not a "" test "" in any established sense of the term . perhaps you could supply more details or some context to help readers understand what you want to know ?"
131037,"im afraid , your understanding of the p value is not generally correct , which may be where the question originates . for the actual question , what null hypothesis about the correlation for which you need to understand p do you have in mind ?"
131054,what do you mean by unit root stationarity ?
131068,"sounds like it should be straightforward enough . basically , you want to set up a process that could be called rolling forecasts or dynamic forecasts ( although i leave these undefined for the time being and trust you understand the gist of it ) . as khashaa asks , what's the question ?"
130999,"what is the meaning of the subscript "" $ i $ "" ?"
131104,can you add the relevant context here ?
131123,to state the obvious : model selection based on $ p $ -values is a bad idea and it should be avoided . the fact you calculate $ p $ -values on a mixed-effects model make this choice even more questionable . how did you get these $ p $ -values ?
131142,"when you say "" good data separation "" , what exactly are you referring to ?"
131148,"perhaps , consider using the ` ur . df ( ) ` function from the ` urca ` package , instead ?"
130996,"i have a similar question , only i'm doing plain old ols and seeing some vifs that are equaling exactly 0 . have you found any additional info on this elsewhere ?"
131191,"i wouldn't think of this in terms of latent classes . if your response were numeric , i would treat this as a clustering question . is the bivariate distribution of the ratings bi-modal or unimodal ?"
130978,"just a question : when ` p [ n ] ` is = 1 . 0 , what is ` y [ n ] ` ?"
130666,how is the pianka index calculated ?
131229,what does the reference say ?
131230,which is mathematically equivalent to which ?
131240,rank according to which overall criterion ?
131241,here is the original post : url why do you copy-paste it here ?
131207,are you sure it is [ ols ] ( url ) and not just a linear regression . . ?
131269,"what do you mean by "" my empirical result satisfies the null "" ?"
131285,what's * academic point of view * ?
131295,"it is hard to determine what you are asking . could you elaborate on ( 1 ) what would constitute a "" phenomenon or principle "" in this context ( especially since the two words refer to such different things ) and ( 2 ) exactly why you believe "" modeling volatility "" has an oxymoronic character to it ?"
131309,there was a question with almost exactly the same title . did you search se ?
131343,what to you plan to do with the subsample ?
131350,( 1 ) what do these values represent ?
131351,what does that sum represent ?
131390,what would justify your assumption that the vaccine could not possibly do any harm ?
131396,why not show results as well as sketch them ?
131386,"i would like to suggest that you invert how you are thinking about this problem . rather than starting with some mathematical formula , like the pearson correlation , and asking how well it might work , why not think hard about what you really mean by "" like-minded "" and develop a quantitative way to measure that ?"
131190,"could you show your obtained results -- n , standardized and unstandardized coefficients , standard errors , and p-values . also , have you checked your predictors for collinearity ?"
131447,in what way is this a multiple regression problem ?
131446,did you try reading the paper ?
131426,"you haven't provided enough information . what is the underlying time frequency on which you would be calculating returns ( your step 1 ) , and what is the return period you would be calculating ?"
130661,don't you want the sums to run over j instead of i ?
131463,just a comment : how the essays are going to be rated ?
131490,"one normally would not think of these as "" clusters "" or "" partitions "" , which are typically * disjoint * ( or nearly disjoint ) subsets . are you just trying to separate the data into two subsets with comparable first and second moments ?"
129402,"i welcome the attempt , but a ) evidently doesn't exist , else why are there competing solutions , or why isn't this evident in the literature you are reading ?"
131065,whuber : the quote in the op says that there is a non-zero difference in mean male and mean female brain size . you suggested to consider a case of perfect $ rho = 1 $ correlation between brain size and iq ( didn't you ?
132535,do you mean that the software is instructed to estimate covariances between factors ( latent variables ) ?
132588,what are you working on ?
132596,have you taken a look at the actual statement of the adaboost algorithm ?
132601,we need a little bit more information / clarification please . are there 9 = 900 / 100 distinct treatments ?
132602,"the two key questions your description does not answer are ( 1 ) how strong is the effect ( that is , how much slower do the agents become as a function of proportion of priority tickets processed ) and ( 2 ) how significant is it ( that is , to what extent could it be explained by chance variations ) . although you say the orderings are about the same , when you repeat the analysis with new data , is it always the same agents who are the slowest or not ?"
132621,have you thought about trying to represent some of these features graphically ?
131304,"as technology evolves , that 25 s tolerance might soon look inadequate . why not just introduce random variation in the timing of the string-comparison function itself ?"
132566,"i am puzzled by what you call an * item * ( a question with multiple response options ) or a * scale * ( usually composed of several items with identical or different response options , and for which we can derive a total weighted or unweighted score ) . could you clarify ?"
132639,what generative model you are trying ?
132667,not everybody here is familiar with vegetation research . please formulate your question such that it is clear for as many people as possible . what exactly is your data ?
132682,what would you apply the ks test to ?
132694,have you considered a _gamma_ or _weibull_ distributions ?
132743,"what "" robust option "" ?"
132759,do you mean $ displaystyle dfrac { d } { dt } left [ int_t ^ infty xf ( x ) ~ dx right ] $ ?
132784,can you derive the characteristic or the moment generating function of $ y_n $ ?
132723,"please try to avoid asking questions which could just have "" yes "" or "" no "" as answers ; can you possibly edit to phrase your question in a way that invites a more expansive response ?"
132836,what is the response exactly ?
132849,"wouldn't exploring * where * the differences exist be of more interest than measuring "" how close "" they are to being random ?"
132848,interesting problem . it's likely the best solutions will take into account the reasons you are doing this experiment . what are your ultimate objectives ?
132887,where does the author do this : $ { p } _ { t t-1 } $ $ = text { e } left [ text { cov } left ( { x } _t- hat { { x } } _ { t t-1 } right ) right ] $ $ = text { e } left [ left ( x_t- hat { x } _ { t t-1 } right ) left ( x_t- hat { x } _ { t t-1 } right ) ^ t right ] $ ?
132845,"plot the residuals . for that matter , plot ` x ` : does it look stationary ?"
132942,how much data do you have ?
132946,do you have a substantive question that you hope the data can help answer ?
132990,what analysis in which software have you planned ?
132851,is this for some subject ?
58001,what do you want to plot ?
133077,bravais-pearson is a new one on me . i take it this is another case of pearson getting credit when someone else was there first ?
133105,what is your question ?
133129,"i got lost near the beginning , because $ sigma $ does not seem to be a "" standard deviation "" at all . are you simply asking for a family of distributions that can be parameterized by their $ 0 . 16 , 0 . 50 , $ and $ 0 . 84 $ quantiles ?"
133146,"you have to come up with a sigma-algebra , url which is a set that is characterized by certain properties . have you looked them up ?"
133149,is that a dilemma really ?
81715,i assume $ x $ and $ m $ are matrices ?
133214,is this the same study you ask about in [ your previous question ] ( url ) ?
133137,can you explain in more detail why are you not happy with pca / fa approaches ?
133245,is the intervention being applied at the village level ?
133232,"in many situations what you seek can be deduced mathematically from the formula of the "" measure . "" this provides many advantages over an empirical study like the one you propose , because it provides insight going beyond just this dataset and can explain * why * it behaves as it does . could you disclose what your measure is ?"
133261,"the answers to your question might depend on precisely what you mean by "" prediction error . "" how are you computing that ?"
133297,"i can't tell , are you also asking how an anova works ?"
133347,"so you are saying that from the $ n $ random variables of which you have a measurement , say $ n_1 n $ observations represent "" finalized "" life-lengths ( because , the associated random variables were "" dead "" at measurement time ) , while the rest $ n_2 n $ observations are survival lengths of random variables that were "" still alive "" at measurement time ?"
133369,you could change the scale of $ x $ axis from km to mm but what would that amount to ?
133377,"do i understand you correctly that you want to know whether the number of errors per day is really ( i . e . , in the "" population "" of all possible runs on every day ) equal and whether this imbalance you see here is merely sampling variability ?"
133412,"i am sorry but i cannot understand what you want to do . can you please clarify what you mean by "" * the autocorrelation is stable * "" ?"
133419,do you have enough data for a simple 50 / 50 test / training data split ?
133316,of course you can compute the sd--you did in your question . what we are missing is a purpose : what are you hoping to * do * with your calculation of entropy or sd ?
133444,in what sense are your data not normal ?
133433,""" how fast $ h to 0 $ and $ n to infty $ "" makes no sense in light of the definitions of convergence and $ o ( ) $ . what exactly do you mean by "" discuss "" the convergence once you have given it in $ o ( ) $ form ?"
133305,"gung i think there is a statistical question here . the o . p . has not asked how to do something in ` r ` , nor specifically * how * ` r ` works , but rather * why * it works as it does . what would be the need to retain unused levels ?"
133496,are you asking to explain mathematically how cca works ?
133472,the term 'weibull analysis' is a little ambiguous . do you want to estimate lifetime distributions in the presence of censoring by fitting weibull-type regression models ?
133441,what specifically is your alternative hypothesis and what connection does it have with your data ?
133494,do you perhaps have complete separation anywhere ?
133451,what does the green and what do the orange / brownish lines show ?
133406,it's hard for someone who doesn't use this software to be clear whether you have ( 1 ) a general statistical question or ( 2 ) a question specific to the software . which is it ?
133553,"between the start and end of your question you changed the formulation of the model : you converted "" $ y_i sim n ( beta ^ tx_i , sigma ^ 2 / w_i ) $ "" into "" $ y_i = beta ^ t x_i epsilon_i $ "" . * that changed the model . * ( the role played by $ epsilon_i $ in the latter is replaced by the distributional assumptions on $ y_i $ in the former . ) so basically it looks like you're telling us "" the paper assumes this , but i assume something else , so why doesn't the paper deal with my assumption ?"
133611,"are these trends over time ( eg , price of a stock tomorrow given the prices over the past month ) , or future values for different units based on the relationship observed in the past ( eg , height of a son given father's height given the typical relationship b / t father-son heights we've seen before ) ?"
133578,can you give the referecen please ?
133616,"one might try to assume the $ x_i $ are independent and $ d $ is continuous , but even this will not suffice . take , for instance , * negative * random variables and let $ n $ be any odd number . then the product $ x_1 cdots x_ { n-1 } $ must be positive , whence $ pr ( x_n gt x_1 cdots x_ { n-1 } ) = 0 $ . is it possible you meant something other than a product where you wrote "" $ x_1 ldots x_ { n-1 } $ "" ?"
133625,"please state that in your question . when you do , please also explain the relationship between ` einkommen ` and the model : is it a covariate ?"
90134,is there any reason why you want to do this with gradient descent ?
133667,"i was going to suggest minimum description length , but if i understand you correctly , you're looking for a measure of complexity of a function * regardless of the observed data * ?"
133681,""" i would like to find $ x ^ 2 $ , $ x ^ 3 $ , "" -- you can't mean what you say . do you mean you want to find * the distribution of $ x ^ 2 $ * ( and so on ) ?"
133682,why are you not looking at the code ?
133656,a good question . but did you try to look for the answers on this site ?
133688,"i don't understand why this is not a duplicate of "" pca and train / test split "" . can you please clarify your confusion ?"
133733,"could you not just resample the data , weighted by the adaboost coefficients , and then build your decision trees in the normal fashion using whatever metric you like to choose the splits ?"
133736,what are your rings ?
133749,"could you explicit what you mean by a "" parametric model that does not have a closed-form solution "" ?"
133756,"you can factor analyze a correlation matrix , without the raw data . it's not absolutely clear to me what your goal is , so i'm not sure why this wouldn't work - can you elaborate ?"
133728,can you clarify what you're question is about ?
133630,"that's where it all gets harder : ) if you don't expect to be able to find the whole distribution , does that mean you are happy to find the answer purely computationally ?"
133608,"i'm confused . if it's just a 2x2 table , there are only 2 proportions , so only one pair of them to compare . what am i missing ?"
133804,is there a particular reason you have chosen to use logistic regression ?
133784,"according to the notation and terminology , we are supposed to understand "" $ l_z ( t ) $ "" as mapping any $ f $ into the * number * $ l_z ( t ) [ f ] = p_f ( z-z le t ) $ ( that's what "" functionals "" do , after all ) . but then what could "" $ l_z ^ { -1 } ( q ) $ "" possibly mean ?"
133838,for what purpose are you trying to summarize the data ?
133843,can you relate $ t_n $ to an empirical average ?
133867,"i don't really understand point 2 , even after looking at the link you provide . what 'length' variable ?"
133871,"i noticed that your observed counts don't match between the first and 2nd table ( 50 , 39 vs . 51 , 41 ) . also , shouldn't expected proportions be much small because they are out of 60 , 000 and 50 , 000 ?"
133876,do you also think that replicating a selected portion of the data in an ordinary least-squares regression ought to leave it unchanged ?
133900,what is the sample size of the data for each sample ?
133952,"there are many ways to solve this problem . to keep it focused , could you tell us what steps have you taken toward trying to answer this question yourself ?"
133910,this question isn't very clear . can you post your data ?
134006,"i gather you have 2 conditions . how many groups , & individuals per group , do you have ?"
133936,"please tell us what a "" list "" is . for instance ( in light of your use of the [ tag : subset ] tag ) would "" { dcba } "" and "" { acdb } "" be considered the same or different lists ?"
134059,"what do you mean by "" distribution being larger "" ?"
133968,can you give us a reproducible example please ?
134104,"there is a mathematical reason - dividing the ( centered ) data by the sd for each variable produces a transformed data set whose covariance matrix is simply the correlation matrix of the original ( centered ) data . after that , we're on correlation vs covariance matrix territory again . are you seeking proof of how normalizing the data turns the covariance matrix into a correlation matrix ?"
134081,the model fit fine for me . can you add your sessioninfo ( ) ?
134164,"what is the purpose of this "" resampling "" ?"
134015,"what is the periodicity of your data ( yearly , monthly , daily , . . . ) ?"
134190,how's $ n $ going to $ infty $ with $ k $ ?
134194,"what is "" amostral unity "" ?"
134229,"whuber : it is clearly non-standard ( which is probably mentioned somewhere in the book ) , but not unintuitive . do you think it is wrong mathematically ?"
134202,"you could , but it begs a deeper question : why are you doing this ?"
133893,why is the standard deviation of those numbers important to you ?
134324,"if you're talking about analyzing your time series data at group level , don't you think that clustering might be helpful ?"
134251,"* "" i want to determine which variables and / or interactions have the largest impact on the model r2 one way to do this is to extract the principal components "" * -- i am not familiar with this use of pca . how can principal components be used for this purpose ?"
134005,"do you believe that these errors will bias the means , or just add noise ( w / mean 0 ) to the observations . also , for the sake of clarity , you believe that the effect of these errors will not change the relationship b / t p , t , & s & ca , is that correct ?"
134301,can you clarify what your question is here ?
134348,"it won't be the data , the data are what they are ; with the one exception of possible insufficient sample size . keep in mind maximum likelihood ( which i assume is the estimation being used ) has sample size guidelines for proper convergence . if you have 4 factors and they are all allowed to be correlated you can be looking at a lot of parameters to estimate . can you update your post with the sample size and number of items . also , were any of the variances negative ?"
134374,"what exactly are your data , percentages , & what exactly do you mean by "" normalize "" ?"
134394,"the only thing i can think of after a * brief * look at the code is that the translation from the internal ` theta ` parameters to the estimated variance-covariance matrix via ` varcorr ` is not working properly / as expected ( in general , one can't rely on the standard accessor methods working normally if the internal structure of the model is very different from what's expected ) . is there a scaling factor missing ?"
134410,i do not understand the relevance of the fisher information for just one of the groups . isn't the problem perfectly symmetrical in the groups ?
134416,what is $ n $ in $ f ( v ) = frac { 1 } { sqrt { 2 pi sigma_v ^ 2 } } exp ( frac { -v ^ 2 ( n ) } { 2 sigma ^ 2_v } ) $ ?
134438,i think you mean that mode change is your dv not iv ?
134444,"no . my idea is the following . per your description , the distribution , related to the "" no signal "" situation , is simple gaussian , hence there is no mixture . alternatively , you can consider situation with signal presence as a mixture distribution : the original gaussian and one or more other distributions . therefore , i think that , by differentiating situations with mixture and without ( that's _the criteria_ ) , you can detect the presence of the signal . does it make any sense ?"
134463,"i would suggest to narrow down the question and emphasise its statistical aspect , rather than r issues . are you trying to calibrate an item bank , perform some test equating ?"
134474,what problem do you have in implementing second part in stan if you already have implemented the first one ?
134517,"can you afford it to be algebra-based , at least ?"
134535,"what is the "" species "" here ?"
134547,"what does "" iv "" stand for ?"
134566,what are the possible values of the angle ?
70580,"how do you define "" pca accuracy "" ?"
134574,is this a question from a course or textbook ?
134589,can you say more about what your data * are * ?
134154,"there are an infinite number of nonlinear functions so you've asked for an ( uncountable ) infinity of formulas . i think you need to narrow things down in some fashion . can you ask a different form of question , perhaps ?"
134132,how are you parameterizing the loglogistic ?
134593,"are 1000 random samples drawn from a single component more "" information rich "" than 1000 samples drawn from a 2-component mixture ?"
134628,"this could be software-related . can you share the platform / code & data that you are using for this analysis , so that we can replicate these numbers ?"
134647,might help to consider an alternative experiment in which one sample of monkeys had all the neurons cut & another sample none . could that be construed as a paired t-test ?
134466,could you add the code that creates the required dataset without aggregating over ` ` block ` ` ?
134689,"there really isn't enough information here to help you--there are infinitely many ways to do this . is there anything you can say to help us understand ( quantitatively , not just qualitatively ) how the "" aggressiveness "" is supposed to be related to the 2014 totals and the 2013-2014 changes ?"
134694,"you are aware that ` cv . glmnet ` is performing 10-fold cross validation , right ?"
134644,how much data do you have ?
134656,"since the plot seems to show densities , how are they estimated ?"
133969,"can you add a ( hopefully ) simple phrasing of your question , in mathematical terms ?"
134808,"what might be "" best "" depends on your needs ( such as the uses to which the display or displays will be put ) , the preferences of your audience and various other things we have no way to judge . we may be able to suggest some good visualizations , but how could we know if they're 'best' for your needs ?"
134819,"i am voting to close this question on the grounds that the answers will be primarily opinion-based , though "" too broad "" or "" unclear what you are asking "" are also applicable grounds . indeed , _how_ will the op use any answers ?"
134828,"agree with gung that your biggest worry here should be multicollinearity if you're worried about validity . however having correlated predictors is a problem when it comes to interpretating your results . depending on how the model was run , the variance explained by predictors would be the same , but one may appear to be non-significant . moreover , one predictor will take variance from another predictor which transforms it into some unknown ( e . g . what is waist size representing when corrected for weight ?"
134857,do you have a link to the presentation ?
134878,"if the assumptions are correct , using nonlinear least squares for the transformed fit is maximum likelihood , which generally should perform quite well . however there might be convergence issues . can you show win more detail what the problem is that you say is occuring ?"
132556,what's the inverse of the normal cdf ?
134901,"that is still very broad . although we could just give you a list of many commonly used distributional forms , these are readily combined into infinitely more in myriad ways , such as with mixtures . this process can still lead to closed formulas and can be described in a "" generative "" form . you therefore seem to be asking about how to address a large nebulous class of problems . why not tell us about the specific problem you actually have so that people can suggest effective choices of distributional model for it ?"
134579,""" number of units "" would be discrete and non-negative ( in fact , a count ) . you'd expect the response to be both right skew and heteroskedastic ; in some situations the log you tried might work okay , but in many cases it won't . you might be better off investigating glms , perhaps a negative binomial model ( possibly with log-link ) . [ the appearance of this plot may be due to other aspects of model inadequacy . what were other displays like , such as residuals vs fitted ?"
134938,are the six likert-type items designed to measure the same underlying dimension / construct ?
134983,"your measurement is $ x_i $ , or some function _evaluated in_ $ x_i $ ?"
134989,could you clarify your last sentence / question ?
134999,"simple calculation will tell you if the observed value is less than a fixed value . your null hypothesis assumes the population mean has a certain value ( 5 ) and then your analysis yields the probability of seeing a result as extreme as in the data based on chance , assuming the null is true . or perhaps you have a deeper question . if so , in what way do you see a "" hypothesised population "" as different from a "" fixed value "" ?"
135006,what would the $ h_ { 0 } $ of this test mean substantively speaking ?
135032,it is impossible to answer your question without us knowing what the objectives are of your analysis . could you elaborate on these ?
135008,"from the qq plot , the single outlier ( large negative residual ) seems to be the main cause of the kurtosis . so i'd ignore the kurtosis and think about that instead . aside from that point , the rest look reasonable -- but you can't properly judge this issue ( is it really a problem ?"
135011,are you only looking for code / packages ?
135052,t-tests would not be suitable . you could do pairwise goodness of fit tests ( proportions tests ) . what differing opinions did you find ?
135069,"please , could you link the paper and / or some explanation of eer ?"
135101,have you thought about an ordered probit or logit ?
135040,you should carefully define the terms you use . what do $ m $ and $ mu $ represent ?
134976,are these $ q_i $ estimated from data or theoretically known ?
135152,did you ask at statalist . org ?
135162,""" is there any other test that could be carried out to check the similarity of the two data sets ?"
135135,"have i understood correctly , that you want a model which can forecast sales for any given individual event ?"
134890,relevant [ why does frequentist hypothesis testing become biased towards rejecting the null hypothesis with sufficiently large samples ?
135212,"could you be more precise with defining "" smoothing the crap "" ?"
135199,"it sounds like you might be looking for a way to compare concordance statistics . for example , you want to compare kendall's tau ( y , x1 ) versus kendall's tau ( y , x2 ) . is that right ?"
135201,"you know the sample size , presumably ?"
135221,what or who are the nfl and the patriots ?
135276,what do you mean by streaming value ?
135236,"how do your data look like , what the variables ?"
135149,how * exactly * was your model chosen ?
135280,"i don't really understand your step # 5 . when you project your probe image onto cca subspace , you get a vector of length $ 297 $ ( according to your matlab output ) . when you project each gallery image onto the cca subspace , you also get a vector of length $ 297 $ . how are you then going to compute the similarity score ?"
135275,can you post some sample data ?
133511,why not use [ importance weights ] ( url ) ?
135378,"you don't actually "" sum trees "" -- the pseudocode you have there clearly indicates what you do sum . are you clear on what $ f $ and $ f ^ b $ are ?"
135359,immediately - means that you want train you network in one iteration ( epoch ) ?
135384,"do you know when the switches occur , or not ?"
135395,can you clarify what you do & don't understand here ?
135292,"i'm not sure that i understand your question ( fit the country level model , then the mlm ?"
135445,why would you need to sum the means ?
134563,"of course you can carry out these calculations . whether they are "" correct "" depends on what you will do with the results ! what purpose do you have in mind ?"
135482,"while you want to find an interval that locates the true underlying parameter with a high probability . wouldn't be terrible if your procedure worked really well ( in terms of needing 10 data points to get there ) if the true parameter value was 2 , and worked really poorly ( needing 1000 data points ) when the parameter value was 3 ?"
135490,"xi'an , the op seems to be asking how to derive the prior , but i don't see any derivations at the linked thread . am i missing something ?"
135519,"although your title refers to a "" sum , "" the question does not appear to . how exactly are you "" combining "" the distributions ?"
135550,"please help me understand the form of your data . what are the "" categorical variables "" ?"
135573,"since you have probably handed in your thesis by now , would you care to answer this question yourself ?"
38838,"question 1 is not really a question . do you mean something like "" what is the probability that half or more of the claims have been padded ?"
135592,"formatting help is available from a little "" ?"
135621,that doesn't make sense . simple linear regression assuming a single response value and essentially does a least-squares fit on the regressors . do you want to independently model each value in the response vector ?
135654,"the survey seems fatally flawed to me , due to the way in which the original question was phrased : "" for your family , is having more boys than girls preferred ?"
135688,have you tried to run it ?
135693,"what , precisely , do you mean by the "" resulting distribution "" ?"
135702,"i am certain that this very gelman quotation has been discussed before on this site - off-hand i can't remember where , though perhaps the site search function can track it down . edit : try [ why is a bayesian not allowed to look at the residuals ?"
135707,could you elaborate on why you think the distance must be narrower on the right side ( larger independent values ) than on the left ?
135706,are you sure that it's not ` pricenorm inc ` ?
135795,"this is pretty sparse , can you add some context ?"
135830,"( nb , i edited to your $ latex $ ; please ensure it still says what you want it to say . ) we'll need more information here to be able to answer this . are you looking to have a certain amount of statistical power ?"
135880,are you working with a programming language ?
135926,"while $ ( x_ { ( 3 ) } , x_ { ( 10 ) } ) $ might indeed constitute a ci for the median , it doesn't seem to be related to the signed rank statistic . if anything , it's connected to the * sign test * . please clarify your question . how does the question arise ?"
136022,"just to understand it better : you're classifying words , not texts , is is right ?"
136003,in which sense is your problem related to a posterior distribution if you sample both $ theta $ and the $ x_i $ 's ?
136004,why do you say ` x3 ` is definitely showing instability ?
32174,"hint : what happens when you consider the * smallest * eigenvalue first , rather than the largest one ?"
126419,what is it you want to display * about * these data ?
136087,"in a non-mixed effects model , the 'variance explained' is $ r ^ 2 $ . are you asking about the analog of $ r ^ 2 $ for lmms , & how to get a standard error for $ r ^ 2 $ ?"
136099,"you say , "" for example "" . that implies that you may want to do more than one statistical test ( for various strings ) . if so , how many such tests do you envision ?"
136105,can you clarify the context you heard this ?
136160,is there is no documentation ?
136094,should you not avoid '-1' so that intercept is also included ?
136157,are your x variables categorical ?
136240,"i believe with regularization there is a trade of bias for variance error . if $ lambda $ is small , bias error is small but variance error is large . as it increases , variance error should decrease while bias error increases . i don't think the goal of regularization is to have a "" consistent "" estimator ( do you mean * unbiased * by this ?"
136269,""" measurement doesn't go below zero "" because values below zero are not possible , were nor observed , or your measurement instrument does not allow negative values ?"
136280,what makes you think dummies have to be treated differently ?
136279,"you're not talking about something called "" the inverse beta distribution "" ( in fact the "" inverse beta distribution "" would be a shifted beta prime distribution ) . instead you seem to be talking about the inverse of the cdf of a beta distribution , also called the quantile function of the beta distribution . [ when you say "" turns out to be a beta distribution "" , where is the derivation for this ?"
136300,"that's 11 rows . the lack of replicates is problematic as there's no way to tell apart extra-poisson variation between plots & differences between cell means from a saturated model . it's not a matter of valid / invalid but of how happy you are having to rely on assumptions you can't check . also , how are the plots laid out physically ?"
136323,"are you asking about how best to present your data in text , in a table , or in a figure ?"
136317,"welcome to cross validated ! it'd be more useful to explain & / or illustrate your calculations than to show us a lot of numbers . anyway , if 5 out of 10 widgets sold were a one day , & 5 out of 100 the next day , what results would you get for the mean & standard deviation of the counts & the proportions ?"
136340,is that a homework question ?
136247,"what do you mean by "" lower and upper limit of the normal random variable "" ?"
136402,which paper ?
136416,interesting . but we probably can't help you without the actual data . try cutting your problem down to isolate the issue . does the problem persist if you cut your xls down to just two shops ?
136257,what is your definition of smaller ?
136309,are you limited to a specific type ( or a set of types ) of clustering or you can consider alternatives ?
135178,"i have trouble understanding what "" relevant "" means . can you describe the process a little bit ( background is sometimes also helpful ) ?"
136462,"umm , where do you find $ x_t $ in an arma ( 1 , 1 ) model ?"
136456,"defining the "" joint sufficient statistics "" does not tell about the joint distribution . is it still an exponential family with natural sufficient statistics $ t ( x , y ) $ ?"
136485,"'cause' is actually a very difficult thing to establish . association is usually what you get out of statistical analysis . consider , for example that you're examining relationships between $ y_t $ and $ x_ { t-k } $ and discover that a shift in $ x $ always seems to be followed ( about $ k $ periods later ) by a shift in $ y $ . does a shift in $ x $ cause a shift in $ y $ ?"
136445,why are the body areas not independent ?
136490,"what do you mean by "" the adjusted dateset ?"
136505,"the discussion and links [ here ] ( url ) are fairly directly relevant . also see yule ( 1926 ) "" why do we sometimes get nonsense-correlations between time-series ?"
136525,how could there be a true value if the model itself is wrong ?
136534,"sampling is * with replacement * . if your data are $ { 1 , 2 , 3 } $ one psuedo-sample might be { 1 , 2 , 1 } , the next might be { 3 , 1 , 1 } and the one after that could be { 2 , 2 , 2 } . the probability ( with no ties in the data ) of getting the sample back with large n is very small $ : $ possible duplicate [ here ] ( url ) ?"
136529,are you asking about the convergence in probability of a point estimate with respect to the population parameter ?
136539,"what's a "" fdv "" ?"
115610,"you can't tell that your data * are * normally distributed . but in any case , ( a ) what exactly assumed to be normal for this analysis , ( b ) where is that assumption used , and ( c ) why would a test ( per your title ) be the best way of deciding whether your data were suitable rather than some diagnostic check say ?"
136595,"the question seems ill-posed . i take your word that ms excel has a function called ` correl ( ) ` that calculates pearson correlation . but the real issue seems to be is this the right quantity to calculate to summarize the effect of a discount . the answer will be no , regardless , but saying what you should do instead is much more problematic . for a start , what your data are precisely is not clear to me . for a second , how can you disentangle the effect of a discount from other influences on sales ?"
71816,do you mean you want standardized parameter estimates ?
136487,"normally in this context "" $ rho $ "" is a * correlation * , which must lie between $ -1 $ and $ 1 $ . obviously it is not , because you claim it is $ 2 $ . what exactly does it mean then ?"
136523,"what would your intuition tell you if $ u $ had _non-uniform_ density $ 0 . 02u , u in ( 0 , 10 ) $ ?"
136646,"what is "" random "" ?"
612,"hello roman ! i have been reviewing this old thread , and i am surprised that you marked brett's answer as accepted . you were asking whether pca rotation is still pca , or is it fa ; brett's answer does not say a single word about rotations ! neither does it mention the ` principal ` function that you asked about . if his answer did indeed answer your question , then perhaps your question is not adequately formulated ; would you consider editing ?"
136768,you changed your example while i was commenting . what you are showing me is not nearly so simple as the graph you first showed . how can you show lags up to 800 if time only goes up to 70 ?
135785,why do you want to find this optimal division ?
136777,"could you elaborate a little bit more , because it is not clear what you are asking . . ?"
136787,"is there any constraints on ` am ` , e . g . should am * be psd ?"
136807,"if $ l $ and $ x $ commute , then that's the case . see math . so for [ when is matrix multiplication commutative ?"
136815,what we need to know is if x1 & x2 are uncorrelated . also what are these ?
136843,what would be the purpose of the plot ?
136833,could you describe the statistical model more formally ?
136862,"corrections : fields medal , not field's ; kolmogorov not kolomogorov . the bodies that award these medals tend not to include _any_ statisticians , so what is surprising ?"
136911,what is ` decision tree matrix ` ?
136898,do you have a real use case for this ?
136926,what's the p-value ?
136870,what arguments to * they * bring to bear on their postion ?
136959,was the result 'significant' ?
136976,what kind of progress have you made towards a solution ?
136998,"a factor is not a number at all--it just indicates a category . with two factors there is only one way to assign numbers to the factors ( up to location and scale , both of which are normalized by pca ) , but with more than two there is no unique way . what are you hoping pca with factors ( whatever that might possibly mean ) is going to do for you , then ?"
137030,"what precisely do you mean by "" shift the data "" ?"
137031,"sorry , do you want an interval that contains 95 % of student's mean heights for the year ?"
137039,"this is indeed a bit high even for an "" individual testing "" questionnaire . do the usual alpha ( based on covariances ) and standardized alpha ( based on correlations ) differ much in your example ?"
136994,"the statement of your question is confusing because "" censoring "" and "" truncation "" are distinctly different things . are you perhaps trying to use both words synonymously ?"
137048,couldn't you simply generate some data ( so you'd know the parameters in advance ) and check how well does the two software work for them ?
137098,"starting with your reference to "" sufficient statistics "" this question is very confusing . the only sufficient statistics that are relevant would be those for the exponential family , not for a gaussian family . and what do you mean by "" the gaussian sufficient statistic $ x_i $ "" ?"
137009,"cross-posted on so and closed there . url please don't cross-post ! unfortunately in my view this question fits neither forum well . so expects code-specific questions , not open-ended requests for code . cv expects specific statistical questions . requests for code are off-topic here ; there is also a flavour of asking for references . there may be scope for increasing the statistical element of this question . is "" e . g . "" intended by "" i . e . "" ?"
137145,"by "" sampling distribution of the one-year mean return "" do you just mean "" distribution of the one-year mean return "" ?"
137160,"there is no way to answer this question objectively because you haven't told us what the "" similarity "" is supposed to model in the real world . how are we to determine how a "" score "" is "" appropriate "" ?"
137191,"the tag descriptions make them seem the same , unfortunately . i'd have said they were * quite * different ; one is for questions related to a model ( a noun ) , while the other is for questions related to the process of * modelling * - of arriving at a model ( a verb ) . the destination and the journey are different ! [ however , if your question is mainly about possible tag overlap it belongs on meta . stats . stackexchange . ] i can't figure out what the rest of your question is even asking . can you clarify ?"
137195,could you expand on why you were advised to exclude subjects without exposure to resource conflicts ?
137120,"it would be helpful if you described , in plain english , as opposed to through r code , what two methods you are trying to use . how can we validate what you've computed if we don't know what method you are trying to use to compute ?"
137138,it is not clear what you are asking . what do you do with frequentionist regression ?
137330,what makes you confident that this is true in the general case ?
137345,"by "" beta "" , do you mean * standardized * coefficients ?"
137344,"shiver , i am not sure if i got the mathjax for your equations correct . particularly , in the equation for $ alpha_ { t } $ ( 1 ) should "" $ mu_ { 1 } alpha_ { t-1 } $ "" be "" $ mu_ { 1 } alpha_ { t-1 } $ "" ; and ( 2 ) should "" 2 "" belong somewhere else ( like in a subscript ) ?"
137370,have you seen those lectures : url and url ?
137424,what are the form of your independent variables ?
137428,"i wrote four equalities . which one "" doesn't hold "" ?"
137437,"an autoregressive ( ar ) model is a time series model and the kalman filter is an algorithm with several applications . they are not the same kind of tool or method , i don't see a straightforward way to compare them . _what is the kalman filter benefit for parameter estimation ?"
48427,"are you just wondering about the level of correlation / agreement between the survey & the evaluation , or do you think of the eval as the 'gold standard' , & want to determine how accurate the student's self-perceptions are ?"
137560,an outlier would be someone who you don't believe is really part of the dataset you wish to analyze . do you think that 3 . 29 sd from the mean makes them no longer male ?
137449,"i would recommend you abandon this effort to formulate your question abstractly . it sounds like you want to learn something from an image . so , tell us about your image ( what does it represent ?"
35374,what were your results when you did the regression ?
137544,"random effects and ols have basically the same assumptions for giving you consistent estimates . if the hausman test rejects random effects that means that also ols is likely to be inconsistent . if you want to account for clustering in your standard errors the individual dummies won't help ( and yes , it would be a fixed effects regression ) . these dummies give you individual specific intercepts but they do not account for clustering of the errors within individual - and this is what you wanted , right ?"
137598,"in what sense will those substitutions "" not do it "" ?"
126244,can you post the plots ?
137611,can you show an example of what the data look like ?
136518,"i really don't follow your situation . what is x here , a vector ?"
137650,by 'empirical test' do you mean 'hypothesis test' or something else ?
57342,there surely is - if you define 'importance' . suitable scaling of the estimated coefficients ?
137664,"are you looking for a "" philosophical "" answer to what we mean by the notation "" p ( a b ) "" ?"
137737,you have many rows with the same ` group ` id ; are the rows independent ?
137768,did you try to vary regularization parameter ?
137794,"1 ) that should be in your question , but the second option would work by using all 12 each time ( as long as you have enough data to support so many predictors ) . 2 ) again , such detail should be in your question -- how are we to guess such details ?"
89382,which open mooc course is that ?
82480,"i might have missed something , but the sum of $ n $ * * independent * * bernoulli trials is the binomial distribution . are you saying that your simulation for independent trials has that correlation , or that you want to construct a simulation to have the specified correlation ?"
137815,what exactly is your problem with this table ?
137841,"this sounds like an exploratory exercise rather than a confirmatory one . why not , then , start simply by measuring the variances of $ y $ and comparing them to $ x $ , perhaps with a scatterplot ?"
94731,"what do you mean by median ( a / b ) . a = set of data and b = set of data , so how do you divide one set by another ?"
137856,do you have female child in the model ( s ) ?
72339,"since you are right with your suspicion , why not answer your question yourself ?"
137897,"you have good key words for a literature search there . beyond that , the scope for addressing directly what you find boring , tedious or irrelevant is minimal and explaining why you are wrong would be difficult ; where are we supposed to start ?"
137939,"sorry but for me this question is more about airline traveling then statistics and so i would consider it a bit off-topic in here . if not , what is the * statistical * problem behind your question ?"
138029,what do you mean by * information theoretic model selection * ?
137711,"one way to break it down quite easily is to ignore the overall actual probability , and break it down into something simpler . each time you fly , there is a chance of crashing . assuming that flying more often is also associated with other correlates of crashing ( e . g . , flight length , taking off / landing ) , i think it is very safe to assume that a person who flies more is more likely to die in a plane crash . if someone was to fly 10 , 000 times in their lifetime , and another only once , who would you bet is more likely do die in a plane crash ?"
50745,"hmm , my first impulse : isn't there a wikipedia entry on this ?"
21419,what's the outcome you measured ?
138102,how about hypergeometric test ?
138140,zslice : why don't you estimate a constant elasticity function : $ y = beta_1 x ^ { beta_2 } $ or equivalently $ log ( y ) = log ( beta_1 ) beta_2 log ( x ) $ ?
135180,with difficulty . even finding a closed-form for the pdf of $ x w $ is a tough nut . how large is $ p $ ?
138095,"when you say "" different data collection schedules for each worker "" do you mean something like one worker is tested weekly and another only monthly , or something like each worker is tested every 6 weeks but on staggered schedules , or something like each worker is tested based on suspected exposure or based on previous test values ?"
138230,it appearst that the genetic matching has created att weights . is there an option to change to ate ?
138096,"you may have more important issues to deal with first . usually with transect sampling you will need to account for the fact that detectability wanes with distance from the transect . your assumptions about that detectability will likely have a stronger effect on the results than any other consideration , such as spatial correlation . many of your questions cannot be answered at all , though , because you haven't explained what you are attempting to do with these data . describing them ?"
138276,thanks . can you clarify these now ?
138321,"by "" p-value "" do you simply mean "" probability "" here ?"
69352,user17748 : how so ?
138371,what is your question ?
138272,the z test tests the difference between two means given that you know the variances . why not t ?
138424,"just to clarify , you are using glm ( ) , and you are interacting the two predictors on purpose ?"
138540,what exactly is your question ?
138570,do you mean that you want to use the same the main effects estimates for all the models ?
138595,"sounds like an interesting question . by "" the time when butterflies are coming and . . . leaving "" do you mean time of day ?"
137463,i'm a bit confused about your notation / set-up . where are the coefficients to be estimated ?
138651,"are you referring to estimates for situations where data collection is incomplete in certain or variable regions of the range of data , so called truncated or censored data ?"
134415,did you read the note in ` ?
138693,"a couple of clarifying questions : 1 ) is your "" standard desktop computer "" multicore ; 2 ) can you use cloud ( i . e . , aws ) to parallelize the processing ; 3 ) do you have freedom of what language / environment to use ( r , python , etc . ) ?"
138694,whats your sample size ?
138811,"what is it you're trying to achieve , exactly ?"
138827,"are you interested in whether the dx for 2013 is independent of the dx for 2014 , or if the two years agree ?"
138843,"there might be more facts to exploit : 1 ) your data seem to have a finite range . also , you seem to get many ( independent ) individuals for each rule , so you can assume normality for the means . 2 ) if you can afford to compute also $ sum x_i ^ 2 $ , you can exceptionally estimate the variances for each rule and prob by the non-stable formula $ sum x_i ^ 2 - ( sum x_i ) ^ 2 $ . 3 ) rules als prob can be considered as crossed factors , right ?"
138855,"for simulating correlated $ chi ^ 2 ( 1 ) $ variates , why not just square a bivariate normal distribution ?"
138860,"i'd suggest changing title to "" is using correlation matrix to select predictors for regression correct ?"
138950,what algorithm do you have in mind ?
138991,"i'm a bit confused about your setup . why would the sets $ left { p 7 . 37 , t 31 . 1 right } $ and $ left { p geq 7 . 37 , t geq 31 . 1 right } $ partition your data into two ?"
138910,can you tell us why you want to compare these distributions / what kind of conclusions you are trying to draw ?
138999,what is the 1 . 5 % ?
138940,"your histogram is badly screwed up . you only have integer age , right ?"
138938,"units analysis provides some insight . weights are unitless , whence your first formula has units that are the reciprocals of the units of the $ x_i $ . the second formula ( after you fix the errors in your formulas for $ sigma_e $ ) will have units that are ratios of those of the $ y_i $ to those of the $ x_i $ . which of those actually is a * slope * ?"
139110,if you can frame your question clearly as a statistical one ( rather than simply 'what commands do i need to do x' ?
139084,re last question : why do you think $ mathbb { e } ( y_i mid d_i = 1 ) = mathbb { e } ( y_i ( 1 ) mid d_i = 1 ) $ does not hold ?
139154,you didn't get the answer yest probably because it is not really clear what is your data and what kind of problems do you get . could you provide a boarder description and a an example of your data and results you get ?
139066,why can't you put a prior on a latent variable ?
139194,"you could read to source code for ` mass : : mvrnorm ` for more details , preferrably from the tarball as it will contain any comments in the source : url plus look at the help for ` ?"
139108,"maybe you can comment on the motivation of this exercise . just guessing here , but maybe you have some sort of contingency table that you are trying to adjust to match observed margins ?"
139291,"a powerful exploratory technique is to plot the ( habitat , conductivity ) pairs in the order they are encountered along the stream flow . connect them with line segments to visualize the sequence . color or shade those segments to differentiate locations along the stream . show this plot along with graphs of ( location , habitat ) and ( location , conductivity ) ( overlaid if possible ) . any relatively sudden breaks should be evident in one or both of these plots . see the last two figures in my answer at url for an illustration . btw , how do you measure "" diversity "" ?"
139295,"luca you don't seem to actually ask question here , just make statements . what exactly do you need ?"
139363,is $ epsilon $ multivariate normal ?
139409,could you perhaps explain more : what data you have ; whether you have the independent time series or not ; whether each dependent time series is a superposition of the same set of independent time series or not ?
139290,"to add to this question - what possible "" strong descriptive statistics "" would be available , aside from bayesian ones ?"
139539,how do you define the conditional moment of the empirical distribution when $ x lt min ( x_i ) $ ?
139384,homework ?
139593,how many straight lines can you put through a single point ?
139572,""" it has been suggested "" : by whom and where ?"
139623,how do you try to simulate a wiener process ?
139558,none of them will reliably detect outliers . can you explain why do you want to re-invent the wheel ?
139635,are you tossing the same coin always ?
139648,"by your "" subsequences $ x_ { tj } , y_ { tj } $ "" , are you referring to lagged serieses at some lag $ x_ { ( t l ) -t } , y_ { ( t l ) -t } $ ?"
139659,your observations in the second paragraph bring you to a fundamental point : what would it mean to test a quantity that is undefined in the population ?
139666,"suppose one really successful criminal gets around and not only robs every bank , but robs some of the them again . other criminals may commit robberies , too , over some ( perhaps long ) period of time , leading ( say ) to 50 robberies of 10 banks . what sense would you make of the assertion that "" the probability of having a bank robbed is 5 = 50 / 10 "" ?"
139656,"all probability questions , to be answerable , require a probability distribution over some well-defined set to be specified . exactly what is your "" class of statistically better models "" and what probability distribution are you assuming for it ?"
139690,"forget about integration for a moment . you know all these distributions are normal or bivariate normal , so it remains only to find their parameters . for ( a ) , what are the mean and variance of $ y_1 $ ?"
139739,what are the bars above and below the points ?
139754,thank you . is the assumption behind this question that a machine can break down once per week or not at all ?
139385,"are you aware that the word "" significant "" cannot appear in hypotheses , at least not in its usual meaning ?"
139388,"by error level , are you referring to standard error or prediction error ?"
139773,"1 ) * "" i know i have to reflect the data before i transform it "" * . . . from where does this knowledge arise ?"
139908,"the "" most rigorous "" approaches are not going to be the most intuitively transparent approaches . which do you prefer , ease of understanding by statistical novices , or statistical rigor ?"
139928,do you mean simple regression or multiple regression ?
139481,so you want to test exponential against the alternative of something that's typically smaller ( but of unknown shape ) ?
139938,do you understand what a p-value is ?
139971,restrictions such as $ b_1 b_2 b_3 = 0 $ often improve out of sample performance ?
139981,"can you clarify what you mean by "" document "" here ?"
139969,what do you mean 'implementing them verbatim' ?
140032,"sorry , i couldn't quite follow . what is the actual question then ?"
139765,could you tell us what this separation point is supposed to mean ?
140055,"you don't seem to need lda at all ! why don't you simply run an anova for each of your predictor variables , and look at the f statistic for each of them ?"
140056,can you figure out the square root of $ lambda ^ { -1 } $ ?
140075,"when you say "" find a representative distribution "" do you mean that you want to find a well-known probability density function that describes your distributions ?"
140082,how many parameters in each model ?
140077,the q & a format is not a suitable way to * teach * you gibbs sampling ; we need specific questions . do you understand what gibbs sampling consists of ?
140114,"could you elaborate on what it means to "" have an online panel "" ?"
140183,you showed r syntax you did but did not show the spss syntax . why so ?
139730,what about replacing all _user identifiable information_ with dummy values ( or using a specific _coding scheme_ ) ?
140147,"you only mentioned seasonality and random walk , so i based my answer on that . what is random walk in your case ?"
140254,do you have any references ?
139960,"on your first question , it's like asking "" when i have 2 things and 3 things , and i put them all into a bucket , is 2 being added to 3 or is 3 being added to 2 ?"
140140,are you sure you really need all those interactions ?
140346,what is your question ?
140350,"when you "" generate test data "" do you need to keep the matrix $ x $ fixed or are you allowed to vary its components ?"
140354,"could you clarify what it is that you mean by "" explicit formula to access to what extent it makes sense "" ?"
140163,"if you're looking at trying to forecast groups of commodities , such as various types of metal ( steel a , steel b , steel c , etc . ) , then it might be worth testing for the existence of cointegration . for example , something like this : [ do steel prices move together ?"
140422,"there are two parts of the problem . first , choosing a model for stock returns . second , implementing that in ` r ` . do you have any ideas for the first part ?"
139861,"i had intended to look at the data , but you removed the link . can you add that back in ?"
140466,"could you be more specific what you mean by "" granularity "" ?"
140371,is this from a course or a textbook ?
140505,how does the model perform on the test set ?
140509,"other than the small p-values , what makes you think your model fits well ?"
140508,"the dv need not be normal , only the residuals . did you test the dv itself , or the residuals of a model ?"
140536,what is it about the wikipedia page [ here ] ( url ) that is not clear ?
140563,"are the measurements you are taking on the same outcome variable measured multiple times ( e . g . subject weight measured 5 times ) or are they different measures on a subject ( e . g . weight , height , blood pressure , etc . ) ?"
140564,do you know how to compute the expectation of $ y_1 $ ?
113692,perhaps the second part i . e . the my guess on how to perform such a test is not important and can be removed . main question is : is there a standard test ready for use in r ?
140552,which formula are you using now ( that didn't work ) ?
140605,how did you estimate your non-linear models ?
138202,"it is impossible to opine on the validity of "" a logistic regression "" without knowing the details . what would the independent and dependent variables be ?"
140561,"your title asks for "" the best method "" . in order to clearly identify something as best we'd need some * criterion * on which it's possible to measure "" better "" . or are you really just seeking a suggestion of how to deal with the problem you describe in the body ?"
140700,what happens to logistic regression when there exists a line that perfectly separates the two classes ?
140702,are you leaning toward any methods ?
140713,"your model , as given ( "" $ y = -0 . 5141 0 . 5377x $ "" ) , does not involve logarithms at all ! what is really going on here ?"
140754,why do you say * there is no reason to use them * ?
140772,you control variables are at the household level or at the group ( treatment or control ) level ?
140791,"please be specific . your original variables are discrete , from 1 to 7 points . components are continuous . how do you imagine the final result you are after ?"
140803,should your question read mase instead of mape ?
140807,what are you doing all that for ?
140740,"i must agree with the first comment by glen_b . however , even if we cannot tell you what to hypothesize , it could be beneficial for you to learn more about both options . see , for example , [ here ] ( url ) ( sections "" when is a one-tailed test appropriate ?"
140785,how many tests were given ?
140836,"in the title you have * closed form expression for autocovariance * but in the body * closed-form expression of the "" random walk with drift "" model * . what are you really after ?"
139440,"for several reasons it appears this is a non-problem . first , your residuals will appear uniform : look at a histogram for a huge number of groups to see this . second , the normality of the residuals is of little importance for most analyses ; what matters is the approximate normality of sampling distributions . what special aspect of your application , then , causes you to suppose there is any real problem ?"
140544,"see also [ "" when does lasso fail ?"
140908,what's the main reason for splitting into categories ?
137854,"i'm not sure i understand why the averages are needed at all . if the goal is to reach a target , i would suggest that you look annually at distance from the target or the difference from baseline . but , perhaps the targets are defined on a multi-year basis or the underlying process takes a while to change ?"
140947,the typical approach is to use economic theory to guide our model building ( depending on data availability ) rather than empirical tests . what you are essentially asking is : which variables should be in my model ?
140965,"what are the "" different conclusions "" that $ r ^ 2 $ and aic lead you to ?"
140622,"this is way to broad . can you explain your research motives , hypothesis , . . . in terms of the application ?"
141001,what's your question ?
140994,how is response surface methodology rbf ?
141057,what is the range of the response in the training data ?
141133,"i held off writing a more complete answer because it's a little unclear to me what your data and analysis goal are . let $ v $ be a deterministic mapping $ v : { 1 , dots , l } rightarrow { 0 , 1 } $ , and you observe $ v n $ where $ n sim gaussian ( 0 , 1 ) $ and want to recover $ v $ , correct ?"
141182,"as asked , this is a pure programming question , which we can migrate to [ so ] for you . i wonder whether that would be a disservice , though , because when code just "" spits out some p values "" it is * guaranteed * they will be deceptive without further adjustment . i would like to suggest that before you ask a coding question , you consider asking the relevant statistical questions , such as "" is this procedure meaningful ?"
141210,"you mean metrics like precision , sensitivity , specificity ?"
141024,"do you mean different temporal segments ( eg , 10 / 2013 - 5 / 2014 ; 6 / 2014 - 1 / 2015 , etc ) or different seasonal components ( eg , weekly patterns , & annual patterns , etc ) ?"
141192,is the order of observations meaningful ?
141241,"* yes * , you can add polynomial terms ( eg , squared terms ) to see if the relationship is curvilinear , & * yes * , the resulting model is still a 'linear regression model' in the technical sense of the term . if may help to read my answer here : [ why is polynomial regression considered a special case of multiple linear regression ?"
141226,are you conflating association with causation here ?
141270,"do you know the correlations between ` u ` , ` v ` , ` w ` , and ` y ` in the original dataset ?"
141283,what are the topics of your course ?
141141,a bayesian analysis questiob with a ` p-value ` tag ?
141303,"how are we to judge what an unspecified "" someone "" might do ?"
141313,"do you have 100 , 000 items a user can choose from or do you have 100 , 000 items in training set , and the number items a user can choose from is much smaller ?"
141390,"are you interested in what * individual * traders do ( eg , 'does trader 1 close his position earlier . . . ?"
141413,can you provide more details on how your results are expected to be depedent on time and why the sampling intervals are not equal ?
141407,when does any statistic converge to its asymptotic distribution ?
141456,there are a lot of things to consider and also related to your other question . for some reason you can't use x1 but somehow you have equation 3 . are you assuming that it has been given to you ?
141462,did you use the same value for the random seed for both models ?
141423,can you post the graph of your decomposition ?
76875,did you try to read url topics here on mcnemar test ?
141522,ericcoding i misunderstood the question . why not just compute the medoid in each cluster ?
141395,1 ) i doubt the series is actually stationary . can you plot it ?
141539,( i ) you really don't know how to get a pdf from a cdf ?
141556,why did you use a * z * test ?
141309,jtd : what multicollinearity assumption ?
141610,` assign meaning to the nature of the identified clusters . this is subjective ` why subjective ?
141630,what happens when you re-run these analyses with different seeds ?
141605,"in that case i apologize for not understanding your question at all . stripped of some distracting and irrelevant details , it asks ( in bold ) "" if my estimate of the true ( but unknown value ) of a model parameter $ beta_1 $ is nonzero , is the true value of $ beta_1 $ zero or not and why ?"
141607,can you describe the setting in a more precise manner ?
141635,"what do you call "" positive "" and "" negative "" items in your question ?"
141646,the first link declines opening . do you have the full article which you can share ?
141674,are you sure that everything you think is a factor is ?
141675,is this for a homework assignment ?
141524,so what's the problem ?
141724,"as described , this problem is too hard for a computer to solve . in the android example , how would a computer get the names "" type "" , "" version "" , and "" codename "" ?"
141679,why not just ignore the independent variable ?
141746,what do you want to do with the models ?
141744,what do you mean that you cannot represent the entities ?
141769,did you want to run some test ?
141844,could you post a reproducible example ?
141864,you are correct : there is no mathematical reason to suppose the top $ k $ pcs of $ x $ have any predictive power--just as there is no mathematical reason generally to suppose that any set of covariates $ x $ has any relationship at all to a given $ y $ . it seems you might be referring to some statement you have encountered : exactly what does it say and who said it ?
141279,i think for the equivalence tests you mean $ h ^ { j } _ { 0 } : mu ^ { j } _ { 1 } - mu_ { 2 } ^ { j } ge delta $ ?
141927,"as ocram hints , doubling the mean is one way to go here . why insist on the method of moments ?"
141957,are you testing the differing proportions between groups or the differing revenue ?
141975,"can you just do linear / logistic / etc regression , depending on the nature of your $ b $ variable , without an intercept term ?"
141884,why did you roll the edits back ?
141990,have you tested your gamma function by itself ?
141997,what would you do when predicting a value from a distribution that has no mean at all ?
142060,is there any statistical aspect to this problem ?
142097,what is your model ?
142156,can you post your 8 values ?
142132,what is the connection between the two matrices ?
141683,why are you checking whether your explanatory variables are normal ?
142175,"what does "" representative of . . . "" mean in this context ?"
142211,this seems rather like routine bookwork . how does the question arise ?
142218,"rather than trying to fix up this * ad hoc * two-step approach ( which will be complicated and perhaps not be worth the effort , since its statistical properties are unknown ) , why not select a suitable estimation procedure for $ ( beta , h ) $ --maximum likelihood might work well--and apply it directly ?"
142271,how did you arrive at this equation to begin with ?
142302,"do you have ( access to ) johansen's book on cointegration ( "" likelihood-based inference . . . "" ) ?"
141483,why do you talk about 'boosting classifier' ?
142134,is the variable continuous other than at 0 ?
142474,"before anyone can give you a sensical answer , i think we'll need a better understanding of what it is you are wanting to do and about the data you are looking at . can you describe what each of the columns are and what your objectives are a bit more ?"
139456,"thank you . i am missing the thought , otherwise not explicitly expressed , that connects "" . . . also needs to know $ x $ "" and "" . . . since $ x $ is fixed . . . . "" within that gap , you appear to acknowledge that you * do * know $ x $ --so what's the problem ?"
142537,"just to be clear , there are three exhaustive x categories and three exhaustive e categories ?"
142536,"i am not sure what this supposed to mean . if $ n $ is very very large , then wishart random matrices $ s $ will be very close to $ sigma $ , right ?"
142527,ecerythingabou about this is confusing . how are either the pmf * or * the cdf positive for outcome 1 ?
142522,"if $ t_2 $ is minimal sufficient and $ t_1 $ sufficient , what does this tell you of the connections between those two statistics ?"
142584,"notice that $ ( x y ) ^ 2 / ( x ^ 2 y ^ 2 ) $ will be greater than 1 when $ x $ and $ y $ are both of the same sign . which means that $ 1- ( x y ) ^ 2 / ( x ^ 2 y ^ 2 ) $ will be negative then , which is going to make it hard to take logs if you want $ w $ to be real . are you sure the function is correct ?"
142377,"just curious , is gdp considered to be i ( 0 ) ?"
142586,"if you do training as in * training and validation * , you have to specify the loss function . just specify one that suits you . is that what you mean by * to penalize the linear regression model * ?"
142609,and that is different than the sidak correction how ?
142610,"be aware the questions about code are generally off-topic here . this one is borderline , imo , as there is a statistical question behind the code . it would help however , if you could make the * statistical * aspect of your q more prominent . it might also help ( ironically ) if you could provide the full code , eg what proc is that ?"
142533,a p-value without a hypothesis is inherently flawed . what does a p-value even mean when you don't have a hypothesis ?
142625,"i have been unable to ascertain what the question is . could you please be more specific about what characteristic of "" the above situation "" you wish to ask about ?"
142654,could you clarify - what is locnum ?
142668,"you seem to be using "" data "" and "" parameters "" in an unconventional way . in particular , what exactly do you mean by "" only parameters "" ?"
142565,what's about the complexity of the asymmetric eigen-problem ( point 5 ) ?
142676,"try some more principled method , like lasso ?"
142692,are you sure that lasso is the right tool for this ?
142714,can this be a related question ?
142634,are you sure the variance of $ kappa $ is $ sigma ^ 2_c ( 1- rho ^ 2 ) $ ?
142722,is your task to match every respondent of a sample with a similar respondent from another sample or pool of respondents ?
142516,"you should not project original data onto the eigenvectors , this does not make a lot of sense to me . usually in pca you project the same data that you computed the covariance matrix of , i . e . you project centered and standardized data . regarding the difference in values : perhaps the report did not use standardized data , i . e . did not divide by the standard deviations ?"
142770,are you sure it says in the assignment that the remaining lifetime of the components depends on what happens with the other components ?
142767,"welcome to the site , ramseyl . can you clarify your question ?"
142787,what classifier are you using ?
142797,"i think it would help to describe clearly what variables you have , and what is the purpose of the analysis . i thought you had 10 variables ( dichotomous ) at first but then it reduced to two variables ?"
142860,"could you explain what you mean by "" low statistics "" ?"
142876,can you be more exact in the beginning of your question ?
142914,this model is unidentifiable . you * might * want ` response ~ 1 fixed . a * fixed . b ( 0 cov fixed . a ) ` . . . ?
142746,"could you please write the variables of our problem from the beginning , and your e and m equations ?"
142938,is this school work ?
142935,it seems you are posting a lot of what looks like school work ?
142922,"thanks for adding the tag , but the first three items under "" asking about self-study questions "" at the indicated link suggest you need to give your own thoughts on / attempts at solving it ( which may require you to open a textbook or look at some notes ) and you'd need to identify a specific issue you need help with . ( you should also identify how this problem arises as indicated there -- e . g . is this for some class ?"
121852,it is not clear to me why one would assert that nonparametric tests ( rank sum or sign rank ) would require symmetry ?
142972,i'm not able to see any plots here . could you please include them ?
142994,"if you don't have any data on x2 , how are you going to work with it ?"
143004,"when you say "" parameters "" i think you mean variables , but even if that's right what do you mean by combining variables ?"
142484,might your $ r ^ 2 $ have been $ 0 . 14 $ ?
143059,whuber : is this your particular approach or is it forum policy to answer questions like this with a hint rather than a full answer ?
143094,when you say 'test' do you mean 'assess' ( as in 'how far from gamma does this seem to be ?
143103,are you sure you have that right ?
143073,"why do you expect that errors should be normally distributed , whether or not the other checks you mention look good ?"
143120,"have you thought about encoding certain value with one output , and sign ( greater , less , equal ) with another output ?"
143121,are you allowed to use delta method ?
143123,on what basis do you assert they have gamma distributions ?
143129,it is not really clear what you are asking . with first forecast you got positive values ( 39 . 99787 ) with a broad forecast interval due to the very small sample size . with forecasting values on log scale you got forecasts on log scale ( 3 . 688805 ) that transformed give you similar results ( exp ( 3 . 688805 ) = 39 . 99702 ) . where is the problem ?
143133,in what sense do you think the model works ?
143144,"so ` coperson ` is an indicator , ` i ( coscore 0 ) ` ?"
143156,"to clarify , the dna may be represented as { atcggatcaagctt . . . . ( 20 such characters ) } and protein as { 1 , 38 , -705 , 50 , 986 , -5 , 7 , -890 , . . . ( 100 such numbers ) } { 1 of 69 categories } ?"
143145,you want them to converge to what ?
143164,first thing that comes to my mind is : how did you compute bootstrap ?
143061,is there a reason you have 100 of these matrices ?
141778,can you paste in the output you are referring to ?
143196,""" converting categorical to numeric variables "" : [ optimal scaling ] ( url ) and gifi methods ?"
143246,"take something simpler than pls , e . g . pca . do you know why eigenvectors in pca are constrained to unit length ?"
143264,why not just calculate the significance of the difference between two odds ratios directly ?
142898,how do you get the first integral ?
143316,"can you clarify if you are just asking if your code is right / how to correctly represent your situation in the code , or if you are asking about the statistical issues in this situation ?"
143364,i have trouble understanding why the bags play any role as such in your problem . in which sense does the problem differ from an hypergeometric model ?
143402,quickbeam2k1 was smola's book worth reading ?
143098,you say that the lag parameter is around . 18 . did you learn the lag-parameter ?
143449,"not to overdo it with semantics , but what does "" best "" mean to you ?"
143495,"the $ chi ^ 2 $ statistic is not appropriate for these data : that formula applies to * counts * $ o_i $ . by "" fit a dipole "" are you trying to find a mean axis for a set of directions or are you actually assuming the distribution on the sphere is given by a spherical harmonic function ?"
64010,what are you trying to do or show exactly ?
143438,"surely these are nothing more than reasonable rules-of-thumb , and therefore a discrepancy is of no theoretical import . is there more to it than that ?"
143532,"could you precise what kind of "" conforming with the model "" do you expect ?"
143448,stein's quoted paradox is a precise fact about a multivariate gaussian distribution . i don't understand what kind of relationship with a theory do you expect ?
143597,could you explain the basis of your concern about the distinction ?
143619,"let me see if i understand what you are doing . you run a simple regression of gnp on s & p500 and housing price . you obtain the residuals and build a garch model for them . the first time it is just garch ( 1 , 1 ) ; the second time it is garch ( 1 , 1 ) plus exogenous regressors s & p500 and housing price . is that right ?"
141552,is this a pointwise prediction interval ?
143631,"it's not clear what function "" bell shaped "" serves in your question . a normal density has a bell shape ( but one can have a distinctly-bell shaped density that's non normal ) . if you removed it , so the question just said "" normal distribution "" , would that change the intent of the question ?"
143670,your last sentence seems to suggest that you want at least one point in each bin regardless of how small the probability for the bin is ?
143699,"why do you expect that clusters , based on similarities among cases , should end up having similar numbers of members ?"
143708,is there a reason the learning algorithm must be an svm and not one which naturally outputs probabilities ?
64245,"the high "" viewed "" figure for this question suggests this is high in search engine results ( it's certainly first page for google in "" omitted variable bias multiple variables "" or "" omitted variable bias more than one variables "" ) ; i wonder if those viewers are getting quite what they expected with this question , given that the bias in the paper wasn't actually ovb ?"
143707,"your interest seems to be in the relation of trade duration ( ` endtime ` - ` starttime ` ) to a measure of trade gain , while taking variability among traders into account . is there some reason why you can't simply use the trade duration as your outcome variable ?"
143726,"in $ operatorname { e } ( epsilon epsilon' ) = sigma ^ 2 $ , is the left hand side a matrix and the right hand side a scalar ?"
143763,it's hard to say w / o more information . i suspect you are confusing testing fes vs res . can you quote more of the text here ?
143617,"some things to think about : if a transformation did * not * change the results , why would anyone want to apply it in the first place ?"
143795,to show an empirical distribution of sample means you need multiple samples to take means of . if you want to show a tendency to look more normal you need multiple samples at each of progressively larger sample sizes . a single average is no use at all ( what's its distribution ?
143347,"this is pretty hard to read , at least on my phone . consider some line breaks ?"
140260,"it is a little unclear what you are trying to do . first , what do you mean that the * index * $ t $ "" is a continuous function "" ?"
143843,"a few comments and questions : ( 1 ) i can't quite tell how many observations you have per subject ( the total number of obs . is approx ( # subject ) * ( # items ) , suggesting each subject receives all items , but then i'm not sure how the treatments are allocated within subjects -- a little more info about your design ?"
143848,"the results are going to vary based on n , n , m , etc . do you want to narrow this down ?"
143477,alexi why don't you want to use bayesian prior ?
143901,why do you think you need the test to be nonparametric ?
143853,are you sure the relationship between power and temperature is linear ?
143914,"is correlation analysis appropriate for your data , in the first place ?"
143915,"in your first scenario , how do you understand the symbol $ text { pr } ( e ) $ ?"
143775,"do i understand correctly that you have 10 yes / no measurements from each of 5 different types of rocks , & you want to know if the proportion yes differs ?"
143931,"if i understand correctly , the prior on labels is flat : fifty fifty and the question is how many training examples are needed for an error to be below 1 / 2- $ epsilon $ . is an error of 1 / 2 a random classifier ?"
143937,i'm not sure what you are asking . do you want to know what that sentence is saying or do you want an explanation of why it is true ?
143672,"in the question , what is your definition of "" same subset "" ?"
143965,why are you looking for such a test ?
143974,"so that we can objectively determine what "" best "" means , could you explain the sense in which the classes "" match "" data ?"
143976,alpha ?
144005,which software package / random number generator are you using ?
123324,why not use the full text instead of only the abstract ?
37807,is this a homework problem ?
144033,"could you clarify what you mean by "" mle $ hat { beta } $ of $ p ( x 1 ) $ "" ?"
144022,"these look like time series rather than distributions . if they are distributions , they're multimodal and kurtosis would be of little use . how does the information plotted here arise ?"
144054,consider adding the ` self-study ` tag ?
143245,power will depend on many things which is why there wouldn't be a built in for the two sample test . you can simulate for given situations . so : power given what assumptions about the situation ?
144104,hint : $ p ( text { at least once in } ~ n ~ text { tries } ) = 1-p ( text { never in } ~ n ~ text { tries } ) = ( 1- ( 1-p ) ^ n ) $ . can you think of any way of solving $ $ 0 . 9 = 1 - ( 1-0 . 0002 ) ^ n $ $ for $ n $ ?
144096,"can you provide the head command of your data , or do a str ?"
144112,better to give full references ; there are lots of books with similar titles . are you after more theoretical or more applied works ?
144120,"skm , not even worth an upvote ?"
144136,"is it possible that the difference could be because the alpha , beta , gama , phi and omega values are updated at every horizon instead of being static ?"
144115,what's an mlp ?
144135,"just checking whether this is self study ( e . g . , homework ) ?"
144289,"do people who don't know the answer still have a certain probability of answer the question correctly ( i . e . , in a multiple choice question , they simply guess ) ?"
137027,do you have a number of variables in the two sets or just two variables ?
144291,"the likelihood , when applied to the parameter $ theta $ , is supposed to be a * number , * but on the right hand side of your equation you have written a * function * ( namely , a multiple of $ mathbb { i } _ { ( 0 , theta ) } $ ) . that can't possibly be correct , can it ?"
144303,"your question is a little confusing in the last sentence . there may be a missing word , or perhaps more than one , and the form of the question ( assuming i guess its meaning correctly at all ) seems to contradict the immediately preceding point . can you edit to clarify what you're asking there ?"
144158,what output does ` str ( x ) ` yield ?
144041,"censoring : "" we have had an observation in that region somewhere but we don't know what it is "" . truncation : "" observation ?"
144357,you only have two time periods ?
144358,what exactly bothers you ?
144390,"data sets with discrete measures such as "" treatment group "" usually hesitate to look normal . this is no tragedy though . to understand your question a bit better : how would you analyze your research question ( = ?"
144138,"i like that you've tried checking the reasonableness of your answer by simulation . your problem is that you * know * you've made an error , but can't see quite where . have you considered that you can check * each stage * of your method , to troubleshoot where the error lies ?"
144403,can you show us some data and explain little bit more by what you mean with ` ` degree of separation / similarity between rows'' ?
144423,"regarding * am i doing this the right way if i use the following comand in r * : yes , you are doing it right . regarding * is the result the same as taking the first difference of each variable ?"
144415,"your first formula isn't an equation at all and the second one is not a matrix formula , so it is difficult to determine what you are asking . probably there are typographical errors : could you please edit the post to fix them ?"
144477,can you provide the sizes of training and testing sets you are using in your experiment ?
144527,"welcome to cross validated ! what exactly does "" localization "" of an english text mean in this context ?"
144365,"that is quite a long wikipedia article . since , in addition , these are subject to change , would you mind citing the passage causing confusion ?"
144556,"are the parameters of this "" normal distribution "" known or not ?"
144515,"when you write $ n = o ( 10 ) $ , how does that relate to url could you just state plainly typical sample sizes as they affect what is practical here ?"
144508,"re ( 5 ) : what you call "" loadings "" are actually not loadings , but eigenvectors of the covariance matrix , aka principal directions , aka principal axes . "" loadings "" are eigenvectors multiplied by square roots of their eigenvalues , i . e . by square roots of the proportion of explained variance . loadings have many nice properties and are useful for interpretation , see e . g . this thread : [ loadings vs eigenvectors in pca : when to use one or another ?"
144612,"how long was the "" washout "" period between treatments ?"
144598,asking for code / packages is off-topic here . did you try [ googling it ] ( url ) ?
144697,do you mean include class variable as a feature in the dataset ?
144682,"this is a bit sparse . can you say a bit more about your situation , your data & your goals here ?"
144737,"hi lin , interesting . now , the first thing i'd recommend you do before computing anything is to plot the data , simple scatterplots for each pair of variables , have a look at ` plotmatrix ` in matlab . secondly , yes , using pca you can solve the problem of correlated independent variables , but then you would have percent explained variance not for your original variables , but for the principal variates how would that help you ?"
144589,is this a true experiment ?
144799,can you mathematically specify the model that you are stating ?
144826,are you familiar with errors-in-variables models ?
144847,"are you asking whether $ e ( y_t ) = 0 $ always and for finite $ t $ also , or whether it converges to zero as $ t $ goes to infinity ?"
144848,is this from a course or textbook ?
144568,"so which of the several possible meanings of "" distribution "" do you intend in that context ?"
144925,welcome to this site ! what is the question ?
144953,presumably you mean $ beta_1 x_1 $ and $ beta_1 log ( x_1 ) $ ?
144954,""" how well "" doesn't seem to be something that should be the subject of a statistical test . what are you trying to achieve ?"
144684,1 . do you have any information about the $ mu_x $ and $ sigma_x $ ?
144975,"more samples generally leads to better density estimation , and a more accurate representation of variance . do you have more details of the exact procedure you are implementing and nature of your data ?"
145024,is this a question from a course or textbook ?
145046,if you give more information about what kind of data it is ( are the $ o_i $ counts ?
145062,have you thought about using an [ elliptical confidence region ] ( url ) ?
145014,when taking the sample how is it decided which $ theta $ is used ?
124438,"having just answered a similar mle question today , may i direct you towards [ that solution ] ( url ) for some ideas ?"
145128,why not keep b as continuous variable and then compare with different levels of a ?
145166,could you provide some context ?
144913,"please elaborate & clarify your post . eg , is it a question ?"
145193,what are you asking ?
144956,are you asking a general question -- * how to compute the density of a transformation of dependent variables * ( where the joint distribution is presumably completely specified ) ?
145206,"the data you are using may be oversimplified . if one customer bought item a , then item b , then item a , is he counted as a returning customet twice ?"
145207,"you need to explain how you are estimating the fes . are you just putting in dummies for region and time into an ols specification , and maybe clustering the errors ?"
145231,no doubt you * can * ( who could stop you ?
145250,"it is hard to know how to analyze any data , categorical or not , without knowing what your goals are . what is it you would like to learn from these data ?"
145287,"multinomial , perhaps ?"
145302,why would you want to do that ?
145309,can you explain why do you want this ?
145167,is this cross-validated accuracy ?
144616,the question isn't clear so far . what purpose did you do cluster analysis for ?
145367,"i suppose you could do it , but i'm not sure what the advantage is . you are only changing the presentation of the output , not anything substantive . a more important question is what this "" accuracy "" is . do you have a number of 'trials' of some sort that were 'successful' or not ?"
145385,"any chance these "" clusters "" have 1 element each ?"
145398,are you using a polynomial model by chance ?
145430,are you assuming all the coins have the same probability of landing heads ?
145431,"what is important in your comparison : vector lengths , vector directions or both ?"
145433,"glen_b , the link only talks about why the ci curves , not whether it represents the 95 % confidence interval . in fact , if the tails are wider but the center is tighter , you could still maintain the 95 % confidence interval . . . it's just that it wouldn't be spread evenly over the data points . . . do you agree ?"
145478,possible duplicate of [ independence of a variable ?
145490,"i assume that you constrain $ f_t 0 $ , right ?"
145494,what is iv and dv here ?
145481,$ 0 $ ?
145519,"i know a lot of folks here don't like it , but have you tried a stepwise regression procedure ?"
145549,have you tried solving a simpler problem ?
145436,can you post your data ?
145614,are the calls really poisson distributed ?
145630,is this migrateable ?
145659,why would you want to do it by hand rather then using an existing software ?
145664,what is your dataset s ?
145672,do you know the correlation between the $ x_i $ ?
145676,is the censoring threshold the same for both groups ?
145699,"have you read the following : [ this ] ( url ) , [ this ] ( url ) , [ this ] ( url ) , [ this ] ( url ) , and [ this ] ( url ) ?"
145711,re whuber's first comment : would the 'smallest family that is closed under linear combinations [ containing the spanning family ] ' be representable by a fixed number of parameters with a continuous mapping from the parameter space $ mathbf { r } ^ d $ to the distributions ) ?
145750,can you impute the values ?
145753,"you'll want to assess whether your estimates are biased and have less variance over repeated sampling . but a question i have is do you consider the first method the "" gold standard "" that you'd like to compare to ?"
145778,what about trying dimensionality reduction ?
145773,what do you mean by a formal proof ?
145693,"what exactly do you mean with "" linear blending "" and "" what predictions "" ?"
145858,please keep in mind that the balanced tree of depth 100 would have around 2 * * 100 = 1 . 27e30 leaves . this is much larger than number of points in your data set . therefore such depth makes no sense to me . i am interested - what is your optimal depth ?
145799,"i don't know r that well , so i cannot see whether your code is correct . but you should check what your parameter estimates are . can you write them down for us ?"
145897,"in the last paragraph , shouldn't you use $ hat f $ in place of $ f $ ?"
145913,what is mcl ?
145914,yes this is the weak lln . so is your question related to a misunderstanding of the weak lln ?
145928,what values exactly did you standardize ?
145941,"i doubt this question is answerable in its current ( vague ) form . what are m & ir , eg ?"
145956,what are all these notations ?
141754,"wow ! i did not expect such a massive thread when i asked for comments : ) thank you . 1 for starting an interesting discussion . while i am still digesting your answer , let me clarify : by saying that i gave an answer "" departing "" from your comment do you mean that i extended it or that i opposed it ?"
145978,"haven't done this myself but i tink a very common method ( and logical ) is : bayes optimal classifier . you will have fitted five models for each airline , right ?"
146008,are you also fitting an intercept ?
146030,"first , i think you should rethink your experimental design . what you are calling a split-plot design looks to me more like a split-block design . besides that , i could not understand this challenge you exposed : what is the factor that makes the two measures in the same subplot not to be replicates ?"
146097,your correlations are bounded whereas a gaussian ( normal ) isn't . looking bell-shaped isn't sufficient to define a normal distribution . why not just focus on identifying a change in slope ?
146093,"for "" educational "" , do you mean "" on campus "" address ?"
146114,how did you get $ p ( s geq 2 text { in 2 rolls } ) $ ?
146127,a key question is why you want to combine the data ?
145962,"i don't see an answerable question here . as far as i can tell , you are explicitly asking "" is it a lucky coincidence that the correction factor for the unbiased sample variance is so simple ?"
146015,you must be doing something wrong . how are you computing rotated scores ?
146149,there are only 1 % in one group and 99 % in the other group . this could affect the choice of method to be used . why do you not analyse revenue as a continuous variable ?
146108,what's a 'p-value for similarity' ?
146192,"it would seem your concern is about obtaining a good estimate of the distribution , but "" similar representation "" implies neither accurate nor unbiased . are you sure this is the question you need to be asking ?"
146227,"in monte-carlo , aren't you supposed to average those paths and arrive at the expectation ?"
146226,there's not enough information here . what is known about the $ x $ and $ y $ variables ?
146247,why can't you use just r to do it ?
146253,do all of the loadings have the same sign ?
146258,"it's not the observed counts that are relevant , but the expected . what hypothesis are you testing ?"
146268,what software are you using ?
146150,what do you mean by wrong ?
146254,do you have a data example ?
146296,what other information do you have about the users ?
146335,you will need information about $ e [ x ^ 2 ] $ . is there anything in the original problem statement that can help you figure out that value ?
146228,$ u_2 $ = e [ x ] ?
146221,"it all depends on what your "" vector space model "" does with these distances . could you be more specific about what the model does ?"
146354,"docconcoct -- ok , well , look at ` summary ( ) ` of the result . are there any ` na ` values -- meaning things that can't be estimated ?"
146374,"( 1 ) what is a "" mel "" ?"
146402,is this a self-study question ?
146444,are the distributions of all the variables different or are some the same ?
146425,self-study ?
146520,is this time series data i assume ?
146533,statsstudent would this question be valid if i asked about describing relations between variables in other language than english ?
146603,( 1 ) you may want to add self-study tag ( 2 ) is linear regression appropriate for percentage data ?
146639,"what do you mean by "" low end , median , and high end ranges "" ?"
146666,"why do you say "" the standard errors of the coefficients does not necessarily seems to incorporate the information on how rare a particular feature is "" ?"
146664,"hi , and welcome to crossvalidated ! could you please [ edit your question ] ( url ) to indicate what time granularity you have ( daily ?"
146700,are you familiar with [ contingency tables ] ( url ) ?
146625,"what exactly do you mean by "" rebalancing "" ?"
146743,"it's going to be messy . ( by working out special cases $ theta = 1 , 2 , 3 , $ etc . it will become apparent no general closed form is possible . ) could you tell us why you need a formula for the joint pdf ?"
146757,"oh , ok . what do you mean by 'it didn't work' ?"
144745,very interesting problem can you please post the data and also please share the source for this data set ?
146789,"the statistics you report are in conflict with one another . the estimated mean difference of $ 0 . 087- 0 . 12 = -0 . 033 $ would ordinarily be exactly midway between the two confidence limits , but it is not . please check your calculations . but regardless--since the difference in means is negative , why would it be in the least strange to have a negative confidence limit ?"
146802,"you say "" i would have expected that if the 95 % confidence intervals overlap , as they clearly do for z_x = 1 . 5 . . . "" -- are you basing this on the confidence bands overlapping in the graph , or on some other information ?"
146822,"as far as i understand , a * * closed form * * for _kl divergence_ exists only for gaussians or mixtures of gaussians . can you use numerical approximation ?"
146815,"also , could you please provide a reference for the claim that these two statistics are equal ?"
146852,i'm not entirely sure i understand your question ( how can you assess the weight of an object based on part of it ?
146850,it is not clear for me what is your data and what you want to do with it ?
146494,some common interrater reliability measures for continuous data are the [ intraclass correlation coefficient ] ( url ) and [ lin's concordance coefficient ] ( url ) . i am unaware of a concordance measure specifically for time series though . are the readings paired at all ?
146853,just a shot : is $ x $ standardized ?
147019,do you mean the test [ here on page 5 ] ( url ) ?
147036,what is x ?
147076,does ` y ` contain 0 / 1 only ?
147080,this will probably be hard to answer in its present state . can you say more about your data ?
147090,can you cite & / or link to where you got this formula ?
147087,"can you add something about your data ( eg , a basic plot ) ?"
147147,what study ?
147265,"is this for some subject , such as an exercise , assignment or similar ?"
147284,are these measurements of the same thing repeatedly over time ?
147306,"your question sounds like a concern with the * projectability * of the segmentation based on the full information available from the survey to external data based on the typically incomplete and poor quality information ( e . g . , a few demographic factors ) available from large vendors such as experian . this is an important question to answer in doing any segmentation , i . e . , does it project to external data ?"
147312,"i'm not sure i understand what you mean by "" large problems "" . also , how did you quantify the solution quality ?"
147253,how does one decide whether to use the normal or the t distribution ?
147405,possible duplicate of [ do i need to drop variables that are collinear before running kmeans ?
147423,exactly which time series model do you have in mind ?
147484,""" find significant interaction "" is not a proper hypothesis . maybe you meant "" there is an interaction "" ?"
147507,"hey matt , can you describe your dataset better and what terms like "" turnover frequency "" are ?"
147513,"for example , when there are two parameters , one being the nuisance parameter and the other being the parameter of interest , i use the term * marginal likelihood * for the likelihood integrated over the conditional prior distribution of the nuisance parameter given the parameter of interest . what have you seen exactly ?"
146223,"your post is very unclear . what are the numbers in "" response "" and how were they obtained ?"
137634,why is this condidered off-topic ?
147581,"* in order to avoid over-fitting i would actually want to use as many samples as possible * is that what you mean , or is it a typo ?"
147573,could you elaborate on how the ratings are conducted ?
147460,"( 1 ) is this question related to a course , homework , in any way ?"
147647,"i am not sure i buy this whole $ c_ { 1 } c_ { 2 } 0 $ thing , since $ x $ and $ y $ are both $ sim text { i . i . d . } mathcal { u } ( 0 , 1 ) $ , this makes the ordering of $ c_ { 1 } $ and $ c_ { 2 } $ arbitrary , right ?"
147654,what you describe sounds rather counter-intuitive indeed . can you please give us an actual numerical example ?
147665,"you wrote "" i have found correlation between jan'11 market price with jan'11 , feb'11 and march'11 future contract prices separately . "" so that's 3 correlation coefficients right there ?"
147675,"so , i dig the fact that you collected a lot of data . but why would you want to cherry pick variables to show that two groups are different ?"
147671,what do the points on the right plot represent ?
147488,"your notation may confuse people , because ordinarily "" $ ( mu_1 , mu_2 ) $ "" would be understood to refer to ( assumed ) sample means ( which may be relevant here ) , rather than sample sizes . the power and sample size calculations will depend on what test you elect to apply , so perhaps you could edit this post to include that information ?"
147725,"i don't fully understand the question , i'm afraid . if you check every single item , there is no need for a statistical test . a statistical test would be of help if you sampled some items from the process . also , what does the increase in produced items have to do with the number of faulty items ?"
147638,"list price , out of pocket price---can you explain ?"
147747,"your calculations appear to estimate $ mathbb { e } ( pn - x ) $ for a binomial $ ( n , p ) $ variate $ x $ . that would be a mean absolute deviation from the mean . is this what you are looking for ?"
147753,""" test is higher because there is a further treatment with majority voting in a group of elements "" can you elaborate on that a bit ?"
147770,random effect without grouping = residual - isn't it . . ?
147795,what is the question ?
147794,are all 23 of the questions assumed to be measuring the same construct ?
147819,"since your objective is * description , * it is difficult to see why you would be concerned with correcting for multiple hypothesis testing . you can overcome the objection to effect size ( it is not robust ) by using a robust estimator , such as theil-sen . there is such an admixture of competing concerns expressed in this question ( which , in itself , is understandable ) that one is left wondering what , precisely , you mean by "" descriptive statistics . "" perhaps you could elaborate on that ?"
147840,"good question ! apparently , the ordering of the eigenvectors in ` xx vorg ` is different from what you expect . maybe there is a reason for it ?"
144906,duplicate of [ this ] ( url ) ?
147885,possible duplicate of [ a probability distribution value exceeding 1 is ok ?
147907,"thank you , but i do not see how my comments actually answer your question , which currently is "" what do you call it when you reduce the probability that a hazard will occur from an uncertain event ?"
147915,"maybe i'm misunderstanding , but it seems that your 'case' cases have higher 'memory' ratings than your control group ?"
147856,"in ` logcondfxn ` , why do you write ` gamma - beta * x [ z = = 1 ] - tau ` and ` gamma - beta * x [ z = = 0 ] ` instead of ` gamma beta * x [ z = = 1 ] tau ` and ` gamma beta * x [ z = = 0 ] ` ?"
147821,"you'll probably want to learn a noise model based on your dataset , then use that to get confidence scores . what do the documents and the modifications look like ?"
148014,do you think your own post is a duplicate ?
147998,"the paper is quite a tough read for me . but note that standard pca is a special case of kernel pca , where the kernel function is simply a dot product . so it seems that you can directly apply all theorems from shawe-taylor et al . to the standard pca case . would this be enough for you ?"
148044,michael it seems you get -1's because your question is not really clear and it is hard to understand it . the main problem is : why do you want to weight your prior ?
148048,are you assuming independence ?
148101,what are the values in the second column of the matrix ` outliers ` ?
148046,what exactly do you want to correlate w / what ?
147925,"these posts cover various aspects of your problem , including dealing with multi-way tables . if you know what contingency tables are and how to calculate $ chi ^ 2 $ , then there are only two other aspects to your question : ( 1 ) computing the degrees of freedom , which presumably you also know ( because that's part of understanding contingency tables ) and ( 2 ) using the $ chi ^ 2 $ distribution to test homogeneity . in your edit you now refer to "" two "" contingency tables . could you elaborate on that and explain precisely what it means for * two * tables to be "" homogeneous "" ?"
148227,what is your final goal ?
148350,what is fd ?
148380,"what is the response variable ( outcome , dependent variable ) here ?"
148371,1 ) all the observations from the third to the twelfth season are zeros . this is the main source of non-normality . the box-cox transformation is not the way to deal with this situation . 2 ) what is the purpose of your analysis ?
148384,"do you really want to predict the * right * hand as a function of the * left * hand , or do you just want to see if the two hands are correlated ?"
148317,( 1 ) as you correctly recognise because the instrument of examination ( eg . the test used ) changes over time you are having two distinct dependent variables . lamping them together is wrong because you might have completely different rationale as well as error structures behind two . can you please give more information about you $ x $ ?
148404,are you sure that you need both the extreme sentences and the more minor sentences in the same model ?
148437,"could you explain in what sense either of these estimators "" rely on gaussian distributions "" and exactly what a "" non-parametric variogram "" would be ?"
16753,"just to clarify ( there seems to be some confusion in the answers below ) , you have a regression problem where you trying to predict y ( a real number ) given a multivariate x . . . . and you are interested in using a kernel regression approach , correct ?"
148460,are you asking what other test statistics are t-distributed ?
148391,as far as i can see you didn't really deal with * what 'goodness' is for your purposes * . what would make a fitted model better for you ?
147978,"i suppose you measure the proportion in some number ( say $ n $ ) of small samples , giving variables $ x_1 , dots , x_n $ ?"
148533,"what are $ { mbox { dn ] _1 , ldots , mbox { dn ] _ { 30 } } $ ?"
148565,can you link to the [ so ] thread w / the complete code ?
148679,"what formal hypothesis were you testing with a t-test and how does it relate to a notion about whether they're unrelated or "" closely related "" ?"
148192,becko are you using linux ?
148692,"you're free to call your data whatever you like , especially for "" internal bookkeeping . "" if you're looking for something "" better , "" then it would seem you have some additional purpose in mind . could you please explain what this purpose might be , so that we can understand what you mean by "" better "" ?"
148603,where does the formula for fdr in terms of $ alpha $ and $ beta $ come from ?
148764,your plot makes it impossible to distinguish point colors reliably . why don't you make some sets of side-by-side boxplots for each hour so you can see what's going on in your data ?
148837,"consistency ( to a lesser extent the same is true for replication ) is a widely , maybe overused , word in science . what do you precisely mean by consistency ?"
148848,do you know the population size ?
148855,"1 : i am unable to find a rigorous definition of a "" mean-reverting process . "" i can't even find an unambiguous one . for instance , an authority ( the [ nasdaq ] ( url ) ) states it's "" the idea that stock prices revert to a long term level . hence , if there is a shock in prices ( unexpected jump , either up or down ) , prices will return or revert eventually to the level before the shock . "" is the return exact or probabilistic ?"
148833,"is variance close to expectation , or much higher ?"
148881,"if your $ x_ { t , g } $ is measured with error , wouldn't $ b_1 $ be biased no matter how hard you try to correct for clustering ?"
148892,"are you equating "" holdout "" with "" control "" ?"
148926,"could you elaborate on what a "" turnover "" is and what you understand a "" random walk model "" to be ?"
148927,"these are good things to wonder about . however , many of them lead to non-questions in the sense that most data have no inherent type : your * model * of the data determines what type they have and you are allowed to contemplate different models using different types . that leaves me scanning through your post to identify any substantial question . would it be the first one about estimating a density ?"
148988,what's your outcome ?
148983,( 1 ) you're not actually adding the * distributions * in your line of symbols there . you're showing the distribution that comes from adding * random variables * -- and your formula only works when they're independent . ( 2 ) how are you doing the product ?
148997,"you mean something along the lines of ` hist ( rpois ( 500 , lambda = 0 . 5 ) ) ` ?"
149034,"would you mind posting a small part of data , say data per minute for 23 hours ?"
149110,related : [ what is a complete list of the usual assumptions for linear regression ?
25424,what is your objective ?
149122,what kind of analysis are you doing ?
148801,can you give the expression of the likelihood function or explain from which model or distribution the data come from ?
149191,should the excursions with length $ 8 $ or $ 9 $ weeks be filtered out so that the signal would be nearly here piecewise constant with level $ approx 3 $ for time $ le 75 $ and $ 5 $ after ?
149209,is your intention to learn about linear mixed models or to understand the relationships between water quality scores and land use ?
148265,what is the percentage of users that you are able to identify gender ?
149252,what are the prior distributions that you are sampling from ?
149269,"what is "" nps "" ?"
149362,"ryan , could you give a little more detail on what you envision your sem looking like ?"
148184,"do each of your 4 methods give you a predicted probability for anm1 , eg ?"
149422,i can't reach to the paper . does feature extraction is something related with pca ?
149091,"have you tried the vgam package , something like ` vgam ( y ~ factors , family = tobit ( lower = 0 ) ) ` ?"
149516,do you have any distributional assumption for $ y_t $ ?
149547,i'd expect each time series to be scaled separately . why do otherwise ?
149607,"what do you mean by "" dependent variable is spread over 4 columns "" ?"
149611,did you try to plot the un-normalised samples ?
149615,"by "" regular "" do you mean "" stationary "" ?"
149513,"hint : if you * know * how to find a maximum from function $ f $ , then what for do you need to sample from it "" to find maximum "" . . ?"
149672,"just a suggestion , but shouldn't you be able to write the series as a matrix ?"
149665,s-w tells you there's evidence for non-normality but how are you going to use that signal to improve your model ?
149690,"you should present more details of your solution that didnt work---and , what that means ?"
149711,i'm confused . why should i offer a bonus at all if it won't affect the probability of capture ?
148823,"this is unclear in several senses . ( 1 ) if you want to exclude 99 . 999 % of values , then your interval includes 0 . 001 % of values . that is a very narrow interval . do you mean * * exclude * * ?"
149766,"are you interested in statistical techniques for the imputation of missing data * per se * , or just coding issues ?"
34972,which package / toolbox / program are you using ?
33906,what was the type and style of those extra features ?
149825,why doesn't that seem right ?
149791,""" it should technically go down and then increase "" -- why is that ?"
149847,"the answer you link to suggests estimating a correlation ( between sample & theoretical quantiles ) rather than performing a test - i'm not quite sure how it doesn't already answer your question . indeed , aren't the k-s test statistic values you've calculated already telling you in one sense how close the empirical distribution is to the theoretical ?"
149869,what language / tools are you using ?
149884,is this a question from a course or textbook ?
149897,can you post the 2 scatterplots ?
149773,"you should edit your post to be more specific . define what "" model misspecification "" means to you . what problem are you thinking about that has led you to this investigation ?"
149933,` how to use this ` . isn't it that ` t ` to plug into student's distribution with ` n-2 ` df ?
151015,the philosophy literature on this ( and you're in it up to your neck with your question ) distinguishes between causal laws and causal mechanisms underlying phenomena ( observational correlations ) . are you asking about laws or mechanisms vs * no * underlying structures ( anti-realism / skepticism ) or about laws ( regularities ) vs mechanisms ( stable decomposable structures ) ?
151046,are you having a trouble understanding how to program this or how to calculate the confidence interval mathematically or both ?
151068,do you know how many people rode the ferry ?
151109,can you provide an example of your example ( i . e . a link or citation ) ?
151118,"what do you mean by "" no one has done this before "" ?"
151132,""" i now want to run a post-hoc test to see which levels ( cem1 , cem2 , or cem3 ) are significant "" * significant * in * * what * * sense ?"
151140,can't you check it by running e . g . ` anova ( tear ~ rate ) ` and then checking ` summary . aov ` of the outcome ?
151133,what is field ( 2014 ) ?
151073,can you clarify whether you're interested in variable selection * before * fitting a ( final ) model or in apportionment of predictive power among predictors * after * fitting a model ?
151192,could you add your dataset as well ?
151017,"it depends * heavily * on the nature of the data ( for instance , distances and angles typically have very different behavior and the analyses of them proceed differently ) , the statistical nature of the "" noise , "" and on why you're doing this at all . could you edit your post to provide some of this contextual information ?"
151200,"( comment to voters : ) issues like "" * the problem is that i'm not sure whether the output i get is statistically sound * "" clearly indicate that this is not simply a * coding * question . ( if you disagree , could you please explain to me how that * doesn't * require statistical expertise to answer ?"
151243,""" best "" is really not defined here . all your suggestions make sense . best for your purpose likely exists though . can you provide more details of your goal / investigation ?"
151270,"i'm unclear on this . . . if it's constant under one of the groups , in what sense is it continuous in that group ?"
151216,"wouldn't the fact that many publications , researchers or even entire fields treat assumptions casually suggest we don't care * enough * ?"
151297,are you just asking for code / how to get python to do this ?
151307,why did they use * multinomial * logistic regression ?
151311,that the tradition is uncorrelated with wages is based on theory or observation ?
151349,"how do you define "" similar "" here ?"
151381,"as i read in the past , you have to look at the p-value of f-statistics rather than at r-squared value . the error is normally distributed in a very nice way but , of course , you can check it using , for example , kolmogorov-smirnov test . it is not real dataset , isn't it ?"
151387,are you simply trying to detect the three patterns you have outlined ?
149706,what is size and sampling frequency of historical data ?
151392,""" * paper citation data are said to be log-normal at their core * "" -- said by * whom * ?"
151397,why there are 4 columns of data for each forecasting method ?
50376,"this looks like a standard problem set for students . is this homework , or otherwise related to coursework or a question from a text or test ?"
151405,"the meaning of your notation is obscure . presumably "" $ p $ "" by itself means "" probability of "" ; evidently the "" $ p_i $ "" are numbers in the range $ [ 0 , 1 ] $ ; and likely the value of "" $ text { friends } $ "" is logical . but how are these related to "" people "" ?"
151409,if you already have v ( g ) how are you going to maximize the correlation ?
151434,"auc is used for methods that enable prediction , while correlation describes strength of relation between two variables , so it is not really clear what you are asking . . ?"
151440,hint : can you solve this problem for the case $ n = 1 $ ?
151461,"i can spot two issues with your question . the first being that the outcome of logistic regression is in the range 0 , 1 , not necessarily the predictors . if profit is predicted , then you would need ( non- ) linear regression . second , if you would take out option 2 , how would you know how p ( option1 ) or p ( option3 ) are affected ?"
151436,"as a function of $ beta $ this will usually * not * be a quadratic form . since you don't tell us how $ v $ and $ a $ depend on $ beta $ , you are basically asking how to minimize almost * any * function of any vector . obviously that's too broad to handle , but perhaps you could edit this question to narrow it down to something answerable ?"
151482,"it is unclear what you are trying to do . could you provide a small example , and illustration , or describe your models rigorously in mathematical notation ?"
151604,"the aside in your quote ( * [ they must mean that the square root of the variance is $ sqrt { ( n - 3 ) } $ , not $ 1 / sqrt { ( n - 3 ) } $ ] * ) -- is that * your * comment or is it in the original document that you're quoting ?"
151630,it will be helpful if you can give some details about your data . what is the sample size ?
151631,i presume that your available data is only a time-series sample on $ y $ 's ?
151452,terms are ( unfortunately ) used differently by different people & in different contexts . can you link to / provide an example where people are distinguishing between them ?
151663,closely related : [ how to choose between t-test or non-parametric test e . g . wilcoxon in small samples ?
151683,how do you justify $ mathbb { e } [ y x = x ] = w ^ tx $ when the rhs can get negative ?
151652,"have you tried employing an alternative arima modelling strategy - namely , a box-jenkins approach ?"
151668,can you say more about your design ?
151721,are you asking for help with the code ?
151751,your words * success * and * trial * make sense for a binomial distribution but are unclear in the poisson process context . does * trial * here stand for a unit of time and * success * stand for an arrival of the process ?
151773,"how to handle outliers depends strongly on whether the outliers are extreme values or mistakes such as miscoded observations or misplaces decimals . the small cluster of extreme outliers probably has some explanation that is not in your model . are they , for example , mini-mental state results from unconscious patients ?"
151488,"by solve do you mean obtain the posterior distribution , do bayesian inference , or get a map estimate ?"
151831,interesting question . could you elaborate on the second paragraph and explain the scheme of actions in more detail ?
151846,what is the application ?
151841,"it seems like this is a table of ( originally continuous ) data collapsed into intervals , and what is wanted is an estimation of the model based * * on the original variables * * before it was collapsed into intervals ?"
151698,"this is way too broad to be answerable . what is your model , what variable do you think is endogenous and why ?"
151871,"am i missing something , or do you only have 8 data points ?"
100963,"i am not an expert on cfa , but i am wondering what do you mean that the "" model fit was better "" ?"
151915,"general advise would be : are there any variables that are constants , are factor variables declared as such , does parameter standardization help ?"
151916,"i'm pretty sure this one has been answered a number of times before . is this one where you can assume the variability is the same for both , or not ?"
151931,can you clarify a couple of things ?
151890,can you give the output of summary ( m2 ) ?
151996,[ why not both ?
152009,who said order matters ?
152013,"how about ` predict ( lreg02 , dftest , type = "" response "" ) ` ?"
152068,do you wan't build nn classifier which return probability that the input vector classified to a and b ?
41259,how much memory do you have ?
110826,what do you mean exactly by dependent and independent ?
152134,"asking if the sample's random is short for "" was it obtained by [ ( simple ) random sampling ] ( url ) ?"
152177,can you describe the response a little more ?
152261,is it weekly or monthly data or just two years ?
152269,` run-of-the-mill hierarchical clustering algorithm ` which algorithm ?
151928,"whuber but there's clearly a pattern of alternating peaks and troughs . maybe the op should really be asking "" what is this pattern , and is it quantifiable ?"
152087,take a look at the entries in ` expect ` . there likely are some zeros there . could you confirm that ?
152375,"could you please be more explicit about what "" similar "" means ?"
152379,can you provide the entire model that was fit ?
152407,hint : what is the probability that there is no mistake ?
152402,mugen the mean here is known . why would bessel's correction be needed ?
152408,"i answered , but it occurs to me that i may have misinterpreted your question . clarification : is the situation that your point source is one * or the other * gaussian , but not both , you know the means and variances already , and you want to know with respect to what gaussian your point source is coming from ?"
108367,is this homework ?
152474,why doesn't it work ?
152200,whether there is bias or not depends on * how * you are fitting the distribution . could you edit this post to include a description of that ?
152541,"upon rescaling the random variables according to the coefficients , the linear combination is just a sum , which places you right back into a classical clt setting . however , the phrase "" depend . . . on a single random variable "" raises questions about precisely what you are asking . are the coefficients of the linear combination themselves random variables or not ?"
152542,what is your final aim ?
152539,"now the formula makes no sense because the summation is gone but the bound subscript "" $ i $ "" remains . the angle brackets ( presumably denoting expectations ?"
152548,"for vectors , each dimension usually means something and it wouldn't make sense to subtract the first dimension of one vector from the second dimension of a different vector ( i . e . $ x_1 - y_2 $ ) . in this case , is there anything wrong subtracting the first sample of one matrix from the second sample of a different matrix ?"
152401,it is unclear what you are trying to do . are you fitting univariate distributions ?
152503,i didn't understand a few things ; 1- ) why do you need a feature scaling in k-means ?
152607,there are some difficulties with a 2-d ks test . how exactly does your code work ?
152356,"hi jeff . i think i understand your question , but would it be possible to get a little more detail ?"
152626,"could you elaborate on what you mean by "" chi-square for trend "" and "" linear-by-linear association "" ?"
152644,did you take a look at one of the simplest algorithms like cusum ?
152655,can you describe exactly what a gps trajectory is ?
151657,which model is chosen if you use automatic model identification ?
152567,can you define the notation without requiring us to go read the book ?
152619,"by "" exactly opposite "" , do you mean that the values are the same but the signs flip ?"
152703,what's the distribution of $ t / tau $ ?
152700,"re 1 , "" representative "" of what ?"
152724,consider a simpler problem . what if there were only * * 2 * * people ?
148240,"how did you do the matching , i . e . what did you match on ?"
152758,"so the outcome is essentially whether each person answered zero , one , two or three questions correctly ?"
152785,"would it be okay for you to estimate a distance between the distributions , instead of a hypothesis test ?"
152787,"when testing strategy a vs . b , are they only playing against each other ?"
152801,does this help ?
152794,"yes you can . but since you ask , why do you think that you can't ?"
152831,"hmm , actually i'm sorry to say that i'm having trouble passing the ` lower ` and ` upper ` arguments to ` optim ` via ` arima ` . . . if forgot that those arguments are in the control list , but are separate . i fiddled with it a bit , but i couldn't get it . also , is there any chance you could provide an example data set / simulated data code that demonstrates the problem ?"
152857,in what context is this ?
152885,"it is generally considered incorrect to use , with binary data , methods which compute centroids of clusters ( ward , centroid , median and some other ) - read this [ reminder list ] ( url ) , please . ( though opposite opinion isn't necessary a heresy : the question is discussable . ) use single , complete , average methods . ( between-group ) average linkage ( upgma ) is the most "" universal "" clustering method . where did you read that ward is "" the best "" ?"
152879,` that centering does not preserve the cosine similarity between documents ` [ true ] ( url ) . you'll get correlation coefficient then . ` without centering the principal directions of lsi are meaningless ` why necessarily so ?
152848,can you tell us in which setting this dataset arises ?
152944,what does the clt say ?
152846,"to decide among these approaches--or any approach , for that matter--you need to consider the nature of the data and how you will model variation between them and your model . the two approaches are * profoundly * different in that regard . so , could you edit this question to elaborate on the nature of your data--explain what the $ x_i , z_i , $ and $ w_i $ are--as well as your intended utilization of the results ?"
152971,"you mean , you trying to come up with a feature set that will work for all three models ?"
152921,mah765 -- what's rse ?
153027,"what "" curves "" are you talking about ?"
153057,"you seem to be conflating the ideas of standard deviation and error , or do you mean 'standard error' ?"
153075,"side stepping the question , but is the observed likelihood function tractable ?"
153068,"what is to be gained from reducing the number of observations , if you already have all 937 observations ?"
152394,can you add the line code you're using with the ` flexsurvreg ( ) ` function ?
153054,"note that you evidently standardized your _consumption_ variable , too , given that $ beta_0 $ disappeared . so in that standardized model , each regression coefficient has units : change in standard deviation ( sd ) units of _consumption_ per 1 sd change of the independent variable . are those really the units that best get at what you want to learn ?"
153135,i do not think so but i am not an expert at this . why did you remove linear regression output ?
152683,wow . very interesting dataset . is this under some ip or can you open source your raw data ?
153208,are the $ x_i $ individually _vector_ random variables ?
153237,is it possible to use the percentage of women as a continuous variable ?
153284,"how can something be bounded by $ 1 / mx $ if you have ( 0 , 0 ) values ?"
153177,"please clarify : what would a "" solution "" be ?"
153253,"have you tried it when specifying "" reml "" in lme ?"
153379,` how do i use these values to pick the correct hypothoses ?
153191,could you provide a little more context ?
153400,is there outside justification for the quartile division ?
153358,""" this zone gradually dissipates explaining the return to independence above a certain ipd distance . "" do you care about this ?"
153430,so your independent variable is actually a dependent variable ?
153442,"$ h_1 : p in ( p_0 , 1 ) $ you meant $ h_1 : p in ( 0 , 1 ) $ right ?"
153443,"why do you think something is wrong . the number of factors to extract is a semi-arbitrary decision , so what do you mean when you say that you are only getting one factor ?"
153459,"so quick summary -- you don't want predicted probabilities for each person , but some group ( treatment ) wise predicted probabilities ?"
153421,"is the idea here that you think the intensities are a non-linear function of the ( x1 , x2 ) coordinates , where the function in question takes the form of a multivariate gaussian ?"
153492,the daily data is collected at what intervals ?
153529,is there any reason as to why do you use openbugs ?
153210,what properties of pca do you want to preserve ?
153604,what fit indices are you looking at ?
153485,the focus of this question appears to be on how to compute the pdf of a transformed variable . why not read some of our threads on this by [ searching the site ] ( url ) ?
70330,can you show a better layout of your data so we can exactly understand what is going on ?
153649,what is your question ?
153719,"questions 2 , 3 , and 4 cannot be answered without further information . overall it is important to explain how these data were obtained and what they represent . are they a sample of something ?"
153811,can you give an explicit example for the $ f_i ( x ) $ ?
153851,"this needs some clarification . what is "" favorable "" in this case ?"
153897,what is the research question ?
153825,is this for some class ?
153962,can you say where you've seen this ?
153915,is there any relationship between the $ k $ on the left side and $ n $ in your $ n ^ { -1 } sum_ { h k } gamma ( h ) = 2 gamma ( n ) $ ?
60384,presumably with a sample size of 10 ^ 4 there will be some real difficulties getting anything past accurate third order moments anyway ?
154029,do you have absolute numbers or percentages ?
153956,"would it to simple to say : do as you always do , only use the matched sample in place of the "" raw "" one ?"
153916,"please clarify your question . do you actually mean 'results' by 'data' or are the algorithms producing the data out of nowhere ( if so , how ) ?"
154036,right now the question is a bit unclear and thus hard to answer . do you have an example of such a graph and can you show us the model specification ?
154070,"hint : since the left hand side of the inequality is proportional to the variance of a random variable , where in the definition of the variance might an integral be involved ?"
154079,how confident are you that this parameter has an impact on the outcome of the test ?
153925,what is the goal ?
154083,"does the term "" gam plot "" have a standard meaning ?"
154111,you can use the likert scales variables in the regression . the question is would they make a sense in your particular case ?
154091,are the experimental units people ?
154126,"aksakal did you mean "" returns are commonly globally mean stationary "" ?"
154121,"thank you for the edits , but the post remains really vague . could you elaborate on what exactly you mean by "" compare "" and what the objective of the comparison might be ?"
154137,how many supercomputers do you have networked ?
154143,what's your instrument ?
154149,please tell us more about your data . can they be considered independent ?
154147,what is the point of simulation when you have the entire population ?
62542,what if $ y_ { i 1 } $ is 0 ?
154215,welcome to cv . can you please add the output of your model's summary as well as the command you used to create this particular qq-plot ?
154232,welcome to the site . can you provide some more information about what your issue is ?
154254,the same result for different epochs ! did you train the network at all ?
154291,"are you trying to create "" bins "" or are you looking for outliers ?"
154333,"there are various examples in the ` zoo ` package : e . g . , ` ?"
154335,"* * covariance matrices are not computed this way . * * * the variables are first centered * to have zero mean . this complicates the relationships between the eigenvalues of the two matrices . so , what are you actually asking about : covariance matrices or the simpler sum-of-products matrices given in the formulas ?"
154339,did you use parallel processing when you fit the model ?
154358,are you asking about [ cluster analyses ] ( url ) ?
154402,what is your data ?
63447,"have you noticed your estimator is not unimodal , but that the recommendation you are following explicitly applies only to "" unimodal "" distributions ?"
154251,isn't k nearest neighbors sometimes used for recommendations ?
154389,"` despite the much better match on the left , . . . ` since this plot is on a log scale , i'm not certain that this is true . how do things look on a regular plot ?"
154378,stata has excellent documentation . have you checked the _methods and formulas_ and _references_ sections for the ` pca ` entry in the manuals ?
154455,what are you trying to determine with this data ?
153885,"i fail to see where this proof goes . it appears to be a "" sandwich to zero "" proof , which means that the last-last expression on the right-hand-side on the last imaged series of inequalities , that is the sum of four probabilities , should go to zero . the first and fourth component do go to zero per the assumption of convergence in probability of $ x_n $ , but the second and third ?"
154485,"when you say "" manual computation "" , what is it you seek ?"
154587,where is your month variable in the sample data ?
154489,which family did you use ?
154598,can you provide a simple example of data & / or code & / or output ?
154575,can you post your plot here ?
154469,should this one be marked as self-study or tax-free campaign-contribution ?
154644,which is the framework of this question ?
154682,do the rank of the element and the quantity of random vectors are related by the same number $ m $ ?
154725,on what scale were the tasks rated ?
154758,"if the variable is insignificant , why should you remove a group of observations based on an insignificant value ?"
154673,because they add nothing to the question . another question : did my answer help you ?
154775,"i'm not sure what exactly the question is . the title suggests that you want to know whether you * need * to transform the estimates back to original scale . if you want to talk about the magnitude of the estimates , then i suppose you need to back-transform them . but if you're only interested in the direction of the effect , you can simply stick to the log-transformed values . - or are you asking about * how * to bring the estimates back to the original scale ?"
154827,back propagation is a form of gradient descent ?
154549,"a bit question before our collaboration , should be : . . . which kind of data or process are you modelling ?"
154868,"it is not easy at all , can you let me know what is the type of seasonality that you have used ?"
152580,unclear : do you have to run a simulation or analyse data ?
154879,"this is a q & a site , and the format of this post doesn't really fit that . you should probably put the majority of the content in an answer , and leave just the question ( e . g . what is a list of cost functions used in nns ?"
154889,what is $ f $ ?
154915,"win space invaders , aren't the actions just : go left , go right , fire ?"
154943,""" . . . whether these two coefficients are in the interval . "" what interval ?"
80398,i don't really understand the question . do you want an explanation * why * its corresponding feature space is infinite dimensional or an interpretation as to what the resulting hyperplane means ?
154899,what are you quoting ?
154978,"you will find some good general advice , techniques , and worked problems by going through the other questions tagged [ tag : combinatorics ] . some of them recommend working on a simpler version of the problem first . how would you answer this one if there were just 3 discs randomly chosen from among 5 discs labeled 1 through 5 and the questions asked for the probability ( a ) of including at least 2 odd digits and ( b ) that the 3 digits sum to 9 ?"
154993,"welcome to cross validated ! i'd not categorize it , without a good theoretical reason to think that the risk was constant within each newly created category : see [ what is the benefit of breaking up a continuous predictor variable ?"
155006,what kind of methods have you tried so far ?
154976,which of the 18 topics do you feel you know best ?
155024,"other than proving broad tips , i am not sure we'll be able to help you with you more details . the distributions you are sampling from might be part of your problem . also , are the parameters that are failing to converge latent or observed variables ?"
155023,what is your end goal ?
153772,what's the generalized r ?
155088,what is $ w $ ?
155104,can you please show the results ?
148487,""" best "" is often subjective & a hard question to answer . can you provide any criteria for deciding one metric is better than another ?"
155129,see also [ when should you center your data & when should you standardize ?
155176,"please explain what it means to "" have all the variables in changes . "" the meaning of this phrase is obscure . note , too , that 0 . 75 % = 0 . 0075 is tiny . perhaps you mean 75 % ?"
155057,"by "" do the percentage . . . "" , do you mean compute the quotient 2nd / 1st ?"
155195,"your question "" how statistics changes in the course of time "" seems to be too broad for the format here -- a few paragraphs of answer could not adequately deal with it . even restricted to the subject of the title of the book , it's difficult to see how it could be adequately summarized in a short space . are you able to clarify / focus the question some more ?"
155219,"from one point of view , * of course * a should contribute more to a likelihood : it delivers more information . but getting down to your question : why do you wish to "" combine "" the likelihoods ?"
155192,did you standardize the variables ?
153923,"seems like you're interested in a causal effect of likes on revenue , yes ?"
155267,"you may have the problem that "" beauty is in the eye of the beholder "" . can you cluster the users response into clean "" modes "" ?"
154917,"since you said the paper assume $ text { cov } ( u_ { 0j } , u_ { 1j } ) = sigma_ { 01 } $ and you assume $ text { cov } ( u_ { 0j } , u_ { 1j } ) = 0 $ how can you produce the results of the papere ?"
155273,"so what you are looking for is the appropriate metric for evaluating any decision rules on your data , right ?"
154944,your edit leaves a post that contains a statement but not a question . did you mean to ask about ways to generate prediction intervals for poisson regression / poisson glms in general ?
155124,"the original question was presumably "" what is the variance of y = 5x 2 e ( 5x 2 ) ?"
155262,"the title of your question suggests you're wanting a proof of why the cramer-rao lower bound can't be reached by an estimator of a gaussian variance ( it can in fact , but only when the mean is known ) ; the body suggests you're asking why "" efficiency "" should be defined as reaching the cramer-rao lower bound & what other useful properties of an estimator might be defined . could you please edit to clarify ?"
155337,"i suspect any effort to recreate the contents of these three volumes would require far more than three volumes and likely be * more * expensive . perhaps the count of the number of books should not be the criterion one uses to select them , though . shouldn't their contents matter far more ?"
155299,"in statistical terms , your two "" parameters "" are best thought of as variables . as you have just 20 pairs for an image , why not post sample data here ?"
155351,"why do you think that you need to correct for different sizes of your two "" groups "" ?"
155300,"$ e [ x mid y ] $ is a _random variable_ $ z $ that is a _function_ of the random variable $ y $ . it just so happens that the _expected value_ of $ z $ is equal to $ e [ x ] $ , the expected value of $ x $ . now , we are told that $ e [ x ] = 0 $ and so $ z $ is a zero-mean random variable . why can't $ y $ be a random variable whose _function_ $ z $ has expected value $ 0 $ ?"
155362,"glmnet also centers the data ( translates it to have mean zero ) , are you doing this ?"
155398,what data were used to get the distribution of the races ?
155400,please tell us what information you are trying to convey with your graph and who your audience might be . what are the format and quantity of your data ?
155407,"it is difficult to determine what these p-values * mean * , and that is of crucial importance . unless you know ( independently of the data ) what the true effect size of each "" job "" is , then it's impossible to know how accurate the p-value is . it's certainly not the case that lower p-values are always better ! could you edit this post to provide more explanation of how these p-values were obtained and what they mean ?"
88058,"the meanings of "" valid "" and "" kernel "" depend ( unfortunately ) on the application : they have different ( although ) related meanings for kernel density estimation and in the "" kernel trick "" for svms , for instance . what is your meaning ?"
88189,this sounds like a very complicated approach . why not start with a simple pearson correlation ?
155465,"do you wonder if bp contributes to disease , or if bp differs by disease ?"
90250,"are you sure it's a numerical problem , not the real issue with rank deficiency ?"
155479,"you can't know the right features with complete certainty , though subject-matter knowledge might give you a very good idea ; & using the data to choose them is itself subject to uncertainty , introducing an optimistic bias . see [ training with the full dataset after cross-validation ?"
155521,"normality , autocorrelation and heteroskedasticity need not all go hand in hand ; hence , your title does not indicate a paradox or a problem . a different title might be more informative . as i understand , you are trying to build a good model so that the model residuals would satisfy the model assumptions . you might want to reshape or refocus the question slightly to get what you really want . by the way , is normality an important assumption for this class of models ?"
155629,"as a hackfix , you could trim your text matrix to omit the undesired ( rare ) words ?"
155666,"honestly , your data matrices aren't terribly informative . if the rows are the cases or units of analysis , are the columns time periods ?"
155701,"first , what's the distribution of $ x_i $ ?"
155699,thank you . could you explain what these data * mean * ?
155633,"what do you mean by "" component "" ?"
155762,i had some comments but they disappeared after migration . ( 1 ) can you post some sample data ?
155835,what is the application by the way ?
155569,can you give the reference of the paper ?
155833,how many different ones are there in your sample ?
155957,"with a continuous prior , we always have $ p ( beta_2 = 0 ) = 0 $ . . . do you mean that $ 0 $ belongs to a certain confidence region on $ beta_2 $ ?"
155962,note that your opening sentence refers to a * zero mean * . does ledoit and wolfe specify zero mean or are they dealing with a general mean ?
155870,"it may be that a different multiple comparisons correction will be more appropriate for you . can you say more about your situation , your data , your analyses , & your goals ?"
156021,"` t ( getme ( fitted_model , "" zt "" ) ) ` ?"
156030,"well by their very nature , targeting criteria would be linked to individual's characteristics , and hence potentially to your outcome ?"
156058,"agree that this is better for crossvalidated , but ( 1 ) we might need more context ( * why * are you running the regression ?"
156066,"can you define converge and diverge in a slightly less visual sense , and what the properties of these curves are ?"
155772,why is the ( random ) interest the same in every period ?
65048,possible duplicate of [ can i use the correlation between two variables when observations on each variable are autocorrelated ?
156145,"hint : do you know the double expectation theorem , that $ e e [ x y ] = e x $ ?"
156156,"in the regression , were coefficients for all of m , x and the m : x interaction significant ?"
156182,"would you possibly have some starting data , such as the data for period $ -2 $ and the sum for periods $ -1 $ and $ -2 $ ?"
156180,are you actually linking to the duplicate ?
156190,"double check your codings for the other variables . with the interactions you may accidentally be looking at simple effects not main effects . also , is this balanced data ( or at least nearly balanced ) ?"
156197,"i would add a comment but not enough points : ) remember what one [ definition ] ( url ) of a p-value is : p-value is the probability of obtaining the observed sample results , or "" more extreme "" results , when the null hypothesis is actually true from your answer above ( part a . ) , are you accounting for "" more extreme "" results ?"
155832,"as missingdataguy said , you would use bi-variate probit if you were trying to predict two dependent binary variables . here it sounds more like you have one variable to predict , but two datasets . what do you expect to find from your analysis ?"
156281,"is there * any * way to distinguish ` circ ` , ` 0 ` , ` o ` and the like later on ?"
156309,a dols ?
156316,why do you want to reduce your sample size ?
156317,"by partial correlation , do you mean eye-head correlation after adjusting for arm or just eye-head correlation ?"
156328,you should be more specific about what made you realize that you needed more precision . did you look at your data or compute any statistics to realize this ?
156290,could you provide a link to the emotional scale you are using ?
156397,were the same people in multiple treatments ?
156484,"although you have rephrased the question--and i thank you for that--you have not changed the misconceptions about p-values on which it is founded . i would like to suggest that you forget momentarily about p-values and focus on the essence of the problem , which you have made clear : is a new point consistent with previous ones ?"
156518,you mean the standard error of the _sample_ variance / standard deviation i guess ?
156447,what do you know about $ mu_i $ ?
156463,do you have any idea ( optimally : a distribution ) * how * the w-vectors from different plots are different from each other ?
156534,"although your stated objective focuses on "" daily rhythms , "" your description of the data does not include any information about how many days you observed . since a daily rhythm couldn't possibly be identified with a single day's observation , wouldn't that be important to know and account for ?"
156556,could you please edit once more : are $ theta_1 $ and $ theta_2 $ parameters and $ x $ and $ y $ the random varibales or vice versa ?
109173,i'm not sure what you're asking . . . can you give examples of attribute values for those unfamiliar with the game or the website you mention ?
156602,i am unsure of - total_risk = taking into account all the deceases or total_risk = risk_of_this_decease ?
156604,"the data might show you that 16 out of 29 of the "" mutation present "" cases survived more than 4000 days ( or whatever the numbers are ) , which is over 10 years . how would you work out the median from this ?"
156654,"this looks suspicious . i think there is an important covariate that isn't considered in your model or you even have repeated measures . also , i see that your response variable is in the interval [ 0 , 1 ] . is it by chance a probability ?"
156661,how about natural logarithmic transformation for both ca and fe ?
156712,you should also specify something about the relationship between $ k $ and $ p $ as they both go to infinity--does one go faster than the other ?
156732,what is your actual question here ?
156734,this doesn't seem obvious at all to me . what would a correlation mean in this case ?
156762,"many people work with the idea that you bracket a "" good "" bandwidth with a larger one that evidently smooths too much and a smaller one that doesn't remove enough noise . but it is important to remember that a bandwidth is not just a number but here , if i understand what you are doing correctly , a number with distance units . so , there should be substantive knowledge that should help with this : what is the spatial resolution of the data ?"
156456,"several of your premises / assertions are incorrect . for example , ( i ) you state you can analytically show that "" $ r_ { ap } = r_ { ab } cdot r_ { bp } $ "" , but this claim is not true in general , only under particular conditions ; ( ii ) you can fix a population correlation and still "" observe a sample distribution "" . you seem to have a number of misconceptions / misunderstandings . could you step back from your attempted solutions and explain more clearly what you need to achieve ?"
156815,"in what sense do you intend "" conditional "" there ?"
156923,"when you ask which to use , what is the intended use ?"
156152,can you say more about what this diagram represents ?
156736,the data plotted is clearly very different to the data in your example . could you provide a more representative example data set ?
157046,i have no answer but i like this problem . i have two ( related ) questions : how many patients are in your dataset ?
157071,"what is the timespan of the "" periods "" ?"
157086,"your approach does not scale . what would you do if wanted to find the posterior over many variables , and hence dimensions ?"
157121,"thank you for providing more detail . please bear with me and consider explaining what you mean by "" enough to determine . "" as stated , that's not a statistical question : either the two columns have a one-to-one correspondence with ( that is , determine ) the values of ` changed_position ` or they do not . the latter will occur when two deputies have identical values of their variables but different values of ` changed_position ` . in that situation , many people would be interested in assessing the rate at which a model makes prediction errors . in this context , what would "" enough to determine "" mean ?"
157129,what's wrong with eric-farng's answer ?
157159,it might be the correlations between the predictors - what is the coefficient for comfort if you include no other predictors ?
157181,"well , i think people disagree . it comes down to this : over what family of tests do you want to control the error rate ?"
157185,"please tell us what you want to determine from this array of p-values . note that you might need to adopt very strong ( and likely counterfactual ) assumptions in order to justify any generic procedure for testing such arrays : at a minimum , you will have to assume the aspects are independent . it also appears you have no data in this array about actual * risk * , which is ordinarily understood to be a function of the chance of harm and of the amount of harm itself . how , then , do you hope to relate this array to risk ?"
157178,"you need more information . at a minimum , please indicate over what time periods the counts of * * b * * cover ( per second ?"
157196,"the $ l_ { 2 } $ -norm of y is in reference to the mean , right ?"
157230,"coul you specify in your question what you mean by "" and so on "" ?"
157123,exactly what kind of statistical significance are you expecting with one data point ( per variable ) ?
157308,what are you trying to prove here ?
157327,"omar , there can be developed a great number of ( dis ) similarity measures to compare sequences . you should know exactly and in details what you want . for example , you say s3 is not equal to s4 . how much not equal in that case ?"
157332,the variable dimension thing is . . . messy . are you absolutely sure you've formulated the problem correctly ?
157344,your question is not clear . to _what_ did you apply polynomial regression ( what was your independent / dependent variables ) ?
157396,"do you have data on rainfall over the watershed , given that the level of a river or lake can depend on rain that fell far away ?"
157398,what happens to the $ 1 / 2 $ when you differentiate $ e $ ?
157423,is there some reason why you need to model this in terms of percent crop yield loss instead of as crop yield itself ?
157444,"are you interested in what happens in these exact cells , or are you thinking of these cells as sampled from a population & you're wondering what happens on average to cells in that population ?"
157438,"could you maybe explain a little , _why_ you want these variables to be approximately normally distributed ?"
157474,is $ x_1 $ a binary variable or something else ?
156879,"some * survey * data might be quite close to normal , depending on what you ask . what you have there are items from ordered categories as might be used in a * likert-scale * . these won't be normal and cannot be transformed to be normal . but that may not matter . what are you doing with the individual items ( do you add them , for example ) ?"
157521,what do you want to learn from this data ?
157418,"what do you mean by "" equivalent clusters "" ?"
157437,is this a programming question ?
157557,"is your question "" how did they get rid of $ cx_3 dx_4 $ in the numerator ?"
157606,can you post the data and the plot for people to comment ?
157432,could you tell us more about your percentages ?
157648,a little hard to say without more information ( can you provide a reproducible example ?
157694,"please explain us in editing your question what are these variables , do you have a column with actual wins / loose , how many rows ?"
157698,special case of url ?
157721,"this looks reasonable at first glance , but ( 1 ) i don't quite understand your last sentence ( "" however , i am unsure if this is correct for the interaction coefficient : "" -- please expand / clarify ?"
157733,is this not handled by the system identification toolbox in matlab ?
157716,"one has to suspect either some coding error in the spreadsheet or a mismatch between the statistical models underlying the ci and the mc calculations . in the absence of any information about the details , though , how could we do more than speculate ?"
157772,"what do you mean "" find the line ?"
157672,"because you have asserted "" m is a subset of n "" --and it would seem that should be interpreted as meaning a is a subset of b--then a would be the best subset of b that mimics a . something's obviously wrong with this interpretation . could you edit this post to clear up that confusion ?"
157792,"when you say "" different "" are you interested * only * in the difference in means , and if so , then are you assuming the spreads are identical ?"
157652,"also : _why_ write "" where $ z sim n ( mu , sigma ^ 2 1 ) $ and $ y sim n ( 0 , 1 ) $ . "" with a capital initial "" w "" as if it were the beginning of a new sentence ?"
157436,"hmm , should these two questions perhaps be merged into one ?"
157908,is this a question from a course or textbook ?
157225,this question maybe has better chances of getting good answers on url ?
157933,what metric to choose depends on the purpose of the comparison . why are you comparing this distribution to normality ?
158006,how many categories do you have ?
158237,you may be seeing nothing more than random variation on such a small sample . try the output of a number of such runs for both . are they substantively different ( are their means or sd's very different ?
158260,where do you see the standard deviation ?
158278,"why don't you just do "" secretly "" a repeated measures anova ?"
158373,"url take a look here , maybe explanation on page 81 is sufficient ?"
158419,you haven't written this in a way which makes sense . do you have a link to the actual paper ?
158436,"despite the total focus on stata , there is a statistical question here . in return : what is your idea of imperfect collinearity that stata might use to vet predictors ?"
158502,"assuming no measurement error , if the observed variance is nonzero , then it is significantly above zero ( at any possible level of significance ) , because it * definitively * establishes the variance is nonzero . if there is a possibility of measurement error , then what quantitative information can you provide about * its * variance ?"
158608,"sorry , but i don't think the edits help much . i can't follow what advice you are following or its rationale . watching out for the effects of the predictors on each other and worrying about how far they are standing proxy for other predictors not in the model is a large part of the art of regression . if your question arises from a specific dataset can you post that ?"
158620,"i would concur with ttnphns , with the proviso that "" independent "" be replaced by "" uncorrelated . "" what this question might come down to is what you actually mean by "" opposite behavior . "" could you give a description or example of what that might be ?"
158578,"in anova , the ( independent ) variables are all categorical , does it make sense to center them ?"
158612,"presumably a "" unit vector "" is not one with unit length , but one all of whose coefficients are $ 1 $ . even so , why is it obvious that $ mathbb { e } ( hat w ) = w $ ?"
158646,what are these correlations of ?
158650,are you talking about something along these lines ?
158204,"ordinarily there is no concept of "" significance "" in the winner of an election : the winner is the person with the most votes , period . thus , to understand this situation as you do , we need to hear from you concerning your * probability model * for the election outcome . exactly how do you conceive of this election as occurring by chance ?"
158662,"what kinds of objects are $ a $ , $ b $ , and "" diag "" ?"
158329,"sorry , what part is confusing ?"
158727,"what is your basis for saying "" it doesn't represent the data "" ?"
158754,"see also [ if a factor variable is to be dropped in model selection , should all levels be dropped simultaneously ?"
158751,hmm . . your residual stats can't help because they are about the prediction of y . leverages are about relations among xs ( predictors ) only . will you be able to compute squared mahalanobis distance between each data point of the data cloud x and its centroid ?
158602,"correct me if i am wrong , but normal distribution has a fixed kurtosis . the excess kurtosis is always equal to zero . see url do you want to combine several normal distributions so their combination has a specific kurtosis ?"
158857,there are many sources of variation . it looks like your approach has found that school-to-school variation is a significant source . may i make a ( possibly strange ) recommendation ?
158875,"the odds ratio ( or rather log-transformed odds ratio ) is easy to get , since you have the two proportions : $ or = ( . 42 / ( 1- . 42 ) ) / ( . 51 / ( 1- . 51 ) ) = . 696 $ ( assuming you want the or for group a versus b and not ther other way around ) . and then $ log ( or ) = - . 363 $ . the more difficult part is getting the sampling variance or standard error of the log-transformed odds ratio . can you assume that group a and groupp b are ( roughly ) of equal size ?"
158917,can you explain that with an example ?
158698,""" can someone also explain me the difference between the likelihood ratio test and apply the neyman pearson lemma ?"
158987,you need an hypothesis test in order to have a p value . how do you plan to compare the distributions ?
158989,what exactly are the null & alternative hypotheses supposed to be in this scenario ?
158992,could you please update your code so it can run ?
159015,"if adding temperatures makes no sense , then wouldn't * averaging * them be nonsensical too ?"
159004,you need software or you want an explanation regarding a suitable procedure ?
158975,asking 'how do i do ____ in spss ?
159020,"can you say more about your situation , your data , & your goals here ?"
159111,do you know anything about the long run probabilities of purchasing each item ?
159122,have you checked the eviews manual ?
159144,have you tried adding ar components to your model ?
159148,why do you need rnn if all your sequences have the same length ?
159169,"could you explain why that lower bound exists , how you know its value , and what it means ?"
159177,it is rather hard to say in the abstract . what kind of data do you have ?
159178,could you say a bit more about the goal of this analysis ?
159198,can you show you how i would engage with a bootstrap approach ?
159227,"what you are trying to accomplish is a bit unclear . it seems that if you want to choose the product with "" the higher probability of purchase "" for each customer , then you just need to take the predictors for each customer and compare what your model produces for probabilities of choosing a and b . as you present your data , this will very frequently lead to a having higher probability . what do you hope to gain by "" normalizing "" the probabilities ?"
159213,"i appreciate you supplying the data and code . however , it is not reproducible as-is : please indicate which libraries you are using for functions such as ` lmer ` , ` lsmeans ` , ` filter ` , and ` ggplot ` . indicate how to read in the data file ( which is large--it has 100 , 000 rows--and uses nonstandard delimiters ) . couldn't you possibly strip the input to a much smaller example so that your readers don't have to wait to perform so much calculation just to see what's going on ?"
159241,could you provide a [ reproducible example ] ( url ) ?
159262,"i wouldn't summarize experimental design in that way . even with a good design , just using single t tests will not somehow take into account the variation with other factors . how could it ?"
159267,is x a scalar and all other symbols are scalars having known values ?
159294,"usually the output of the pca will tell you how to linearly combine your features in such a way to reduce the number of dimensions you need to explain the variance of your data . however , it won't necessarily tell you which individual features are more important than others . if you want that , why not run a ridge regression on your dataset ?"
156963,is there some reason why you can't use a chi-square test for this ?
159325,"by truncated svd you mean that you are only interested in finding several leading singular vectors / values , as opposed to all of them ?"
159312,"it's not completely clear from the question exactly what you want to plot against what in your 'single "" best "" curve' . is this a plot of measured variable values against time , with separate lines for each sample "" ?"
159356,"you have only 5 independent variables , often a fairly small set for prediction unless you only have a very limited data set . is there some reason why you _need_ to remove predictors ?"
159378,"the simple answer is : no . you can use p-values to seek answer to the question : is there a difference , while you are interested in strength of this difference - it's a different question ! also , "" most distinct spending patterns "" does not sound at all like "" difference between means "" - are you sure that this approach answers your question at all . . ?"
159423,"can you be more clear about what you mean by "" optimize my result so it best fits across the rest of the 377 equations "" ?"
159261,your question is not entirely clear . how would these weights work exactly ?
159428,"i am a bit confused , have you answered your question ?"
159451,"the log link belongs to the poisson family , so ` poisson ( link = "" log "" ) ` in your ` glmer ( ) ` call would maybe fix it . using the log or identity links ( the second ends up calling ` lmer ` anyway ) doesn't really make sense to me , given the response is binary . see [ ?"
159454,please edit this post to explain what kinds of quantities $ a $ through $ h $ are ( random variables ?
159503,"it would be more useful to predict $ y_a $ based on $ ( x , y_b ) $ . the scatterplot suggests the predictability is no worse ( and maybe even better ) at smaller $ x $ than at larger $ x $ . there are some intriguing patterns that deserve comment or explanation : in particular , it appears $ y_b-y_a $ might have to fall within finite limits determined by $ x $ . if this is the case , why ?"
159533,"would you simultaneously have values of $ x_1 $ , $ x_2 $ , and $ x $ , or will you only have $ x $ for predictions ?"
159587,"it seems you are asking for an analysis strategy for a complex experiment . this is something you would normally hire a statistical consultant for ( once you know how to do the analysis , any programmer can do it ) . in any case , more context might be helpful . for example : it seems you are only analysing stimulus 1 for the moment . without knowing more about the setup , it is difficult to assess whether or not this is a good idea . you can add a random effect for repetition as well - do you expect the results to change with repetitions ?"
157771,"i'm not sure i understand the "" scenario "" for your question . does url contain the answer you need ?"
159534,are you merely trying to fit a parametric distribution to the data ?
159472,"i can imagine plenty of reasons--but they would depend on what the data mean , the specifics of the model , and why you are going through this exercise in the first place . could you edit this post to focus it on the kind ( s ) of model ( s ) you are thinking of and the kinds of data you are concerned with ?"
159650,"it is hard to see how the "" mean "" of any one simulated random walk would be the same thing as the * expectation * of a particular $ y_t $ . that expectation is , by definition , computed over the entire "" ensemble "" of possible random walks , of which your simulated walk is just one instance . when you simulate * many * walks--perhaps by overlaying their graphs on one plot--you will see that they are spread around the horizontal axis . how does that spread vary with $ t $ ?"
159713,"why not give logistic regression a go if you are trying to predict y given x1 , x2 , x3 ?"
159771,could you explain why the $ y $ coordinates are missing from the figures and the tables ?
159786,did you find the answer to your question ?
159789,are you looking at the difference between elevated and ambient ( using hedge's d or an equivalent ) ?
157755,what kind of display do you want exactly ?
159807,could you post your data or full output ?
159674,is it possible to disclose your data ?
159870,"so if you don't also have indicators for your group membership ( your model treats the group as not being relevant to the response ) , then any confounding between group and this indicator won't matter . however , this does concern me that there's something i haven't understood about the situation -- for example , if you only have one indicator variable , how are you creating a hierarchical model ?"
159892,what do you mean by a non-vector dataset ?
159946,can you clarify your question ?
157954,what is the subscript $ t $ in your first formula ?
159992,the problem is all your situations have two samples but you only describe ranking a single sample . with the t-tests in 2 . and 3 . how are you organizing the ranking ?
160032,"have you yet tried the kolmogorov-smirnov test , a classic for comparing distribution functions ?"
159896,just to understand your data . you don't have raw data ?
160109,how many independent variables in total do you have ?
159307,"part of the answer is available in a thread [ comparing the t-test to logistic regression ] ( url ) . it sheds some light on when the "" ideal "" approach might be preferred and when it should not ( because it may be a less powerful way to achieve the study objectives ) . even use of the arcsine transform is questionable when the groups have different sizes . this leads me to ask , * to what are you referring by "" bad practice "" ?"
160146,do * * you * * * have * to use so much * * * formatting * * * ?
160194,"sometimes authors use set notation when working with probabilities because probability can be viewed as a set function . it's just a matter of taste , really . are you just wondering about notation or the sufficiency principle ?"
160228,"if $ x' $ is the minimum of a set of $ x_i $ s , how is it possible that it wouldn't be equal to one of the $ x_i $ s ?"
160305,isn't the purpose of the confidence bounds ( the gray shaded regions ) to show outliers ?
160333,self-study ?
160326,i thought r ^ 2 was computed using the squared error vs . the mean compared to the squared error vs . the fit . if you know the error from the fit then it shouldn't matter if your domain is univariate or multivariate . is that right ?
160355,why should the rounding change whether a variable is ordinal or ratio scaled ?
160363,are you just wondering what the symbols in that formula mean ?
160133,are the discounts only offered * after * the conversion ?
160288,"thank you for the edit . i do need to check , though , that you meant what you wrote . you seem to be looking for a subset of variables with maximal expectations among them all . however , by employing a k-s test and referring to "" non-dominated variables "" you are checking something totally different : you are comparing entire distributions and perhaps have in mind stochastic dominance . which sense of "" maximal "" is the one you * really * mean ?"
145685,maybe you will want to link to where amoeba has dropped the idea you are starting from ?
160486,can you post the data ?
160561,welcome to the site ! you will need to clarify much . is classify ( 2 ) a function ?
160572,"the two events being considered are not "" a white is drawn from bucket 1 "" and "" a black is drawn from bucket 1 "" , so the fact that you cannot get a white and a black ball from bucket 1 is irrelevant to the question about the second event involving a different bucket . define a specific event for e1 and a specific event for e2 and consider the definition of mutually exclusive i gave -- i . e . ask yourself "" can they both happen ?"
160586,can you clarify ?
160665,the johansen test intended to test for cointegration among ` i ( 1 ) ` time series . none of your series may even be remotely considered ` i ( 1 ) ` . they each appear to simply alternate between two values . what exactly are you trying to test ?
160585,"i'm a bit unclear on just how you fit a regression with arima errors using ` gls ( ) ` ( i assume you are using r , right ?"
160675,"by "" regression line "" , do you mean the in-sample fit ?"
160634,"1 for double checking with a different package . that said , i'm not familiar with dunn's test , but [ the documentation for the ` dunn . test ` package ] ( url ) notes that it uses a one-sided test , which would give you a p value half as large as a corresponding two-sided test ( assuming a symmetrical distribution , which would be the only type that would make sense here ) . is it possible that the other packages use a two-sided test ?"
160716,"the missingness seems to have some kind of structural component . if you haven't actually measured those data , it doesn't make sense to smooth them then put the smoothing into a forecasting model . how would you take account of the uncertainty due to smoothing in your forecast ?"
160726,""" * all 4 numerical variables are nonparametric . * "" -- sorry , but there's no such thing as "" nonparametric variables "" . i see many questions here that try to use this terminology and i doubt quite so many people could all conjure up essentially identical terminology from scratch -- if you can recall , where have you seen the term ?"
160764,"what do you mean "" a poisson random variable and $ f ( x ) = x ^  $ "" ?"
160862,"it's not clear it's * necessarily * "" meaningful "" with normal data . what constitutes meaningfulness in this situation ?"
160865,"can you look at the sales of the trained employees , or do you only have aggregate data for each location ?"
160904,what is your null hypothesis ?
160870,what is the question ?
160952,are you sure it's not supposed to be $ var [ d_i ] = e [ d_i ] $ ?
160977,is there a reason you haven't written down the likelihood function for the observed data ?
160990,were the patients randomly assigned to the different dosages ?
160836,"it's not quite clear precisely what you did , but it doesn't sound like your analysis is quite suitable . could you give more details on what you did ?"
161040,"can you say more about your situation , your data , & your goals here ?"
161153,could you be more precise on characteristics of your data ?
161167,do you want to test the difference between the devices at level 3 ?
160835,i think this will be hard for people to answer . can you say more about your situation & what you did ?
161182,what makes you think that the predictions are poor ?
161164,since algorithms for estimating lca are randomized : are you sure that the only thing that changes is not just the class labels ( e . g . class 1 becomes class 2 and class 2 becomes class 1 ) . . ?
161271,why this expectation is of interest ?
161314,why are you using 1 . 05 in ylim and the exact bound otherwise ?
161317,"where does that "" 170 "" come from ?"
161348,i do not understand the rationale for an average of bayes factors . is there any case this is equal to a true bayes factor ?
161278,"ok . how many cases are you analyzing with your 100 predictors , and what do you want to do with the model after you build it ?"
161395,where did this quote come from ?
161449,is there a known finite total number of possible qualities ?
161456,"not directly answering your question , but what type of data do you have ?"
161463,"i think i read the question wrong . the null of the adf unit root test is that rho = 1 . ( but the coefficient is actually rho-1 so the actual test is that the model coef is zero ) . the alternative is that rho is different from 1 in either direction . so , as long as the estimated coefficient returned is between 0 and -2 , then you know that abs ( rho hat ) 1 and stable . if the coeff returned is greater than zero or less than -2 then you know that the solution is not stable ( abs ( rho ) is that what you were asking ?"
161461,"finding the expectation requires knowing the bivariate distribution of $ ( x , y ) $ . what are you assuming it is ?"
161519,"it seems that 13 subjects responded to condition 1 , 9 to conditions 2 and 3 . are this all the data , or is the set it much larger ?"
161535,""" good "" is an ambiguous term . good as in 1 ) are my model assumptions correct ?"
161517,"what results did you get , and did you check how much they vary for different seed values ?"
161659,"there's a plethora of rules . . . and to my eye they tend to oversmooth , some vastly so . what properties did you want this "" golden rule "" to have ?"
161662,can you explain the difference in notation from the $ y $ and the $ y $ in each regression model ?
161573,"what is "" little jiffy "" ?"
161581,"please define "" residual "" first in the context of a logistic regression setting . do you expect its standard deviation to be a single value , no matter the regressors ?"
161569,"this question : "" is there a way to consider all fibers and all subjects in a statistical model ?"
161743,interesting question . do you also have the data for the driver in 1993-2004 ?
161750,"can you state your real problem , in the language of the application ?"
161759,distribution remains same for whole month ?
161751,"the statement of your question is somewhat obscure , especially because the connections among the six paragraphs are not evident . could you explain what constitutes "" fitting an analytical measure to data "" ?"
161805,i don't understand your notation . can you format your question a little better ?
161869,mutual information ?
161947,appropriate for what purpose ?
161973,"what do you mean by "" pair of predictors "" ?"
161849,"you need to examine why that particular variable is being omitted in the output . is it constant , or directly proportional to some other variable , as the warning message implies ?"
161984,what is it that you actually want to achieve here ?
161977,"( i love seeing "" asymptomatic "" appear on our site . it is a medical term for "" showing no signs of problems . "" presumably you mean "" asymptotic . "" ) could you elaborate on the distinction between the "" number of parameters "" and "" the number of ways [ to ] express "" them ?"
162053,could you explain how you are computing sub-nanosecond runtimes ?
161804,"to help other community members weigh in , it may be helpful to write up some of the approach . for instance , have you obtained the third and fourth moments for a single exponential $ mu $ variable as well as for their sum ?"
162009,definitely check for outliers . what was the null hypothesis ( mu = 0 ) ?
162080,"presumably the mean and variance would be all you know . of course if you have more information you'd no longer treat things as though you only knew a mean and a variance . this is somewhat like saying before i flip a coin i would treat it as a bernoulli random variable , but after i see that it's heads i wouldn't . so why would treat it as bernoulli distributed at all ?"
162110,are you familiar with the delta method and / or block bootstrapping ?
162131,i'm skeptical whether you should use separate models . can you tell us more what these ` factori ` variables are ?
162042,what does the series itself look like ?
162196,"allowing partial functions would make nonsense out of most formulas for expectations , moments , distribution functions , and every other form of analyzing random variables . do you have in mind some reason or application why it might be important to use partial functions ?"
162211,"( 1 ) is called "" regression . "" for ( 2 ) and ( 3 ) , what additional information do you propose to use ?"
162228,"if you feel it makes sense with a single predictor , why wouldn't it with two ?"
162296,is rejecting the null hypothesis of no location shift really of importance to you ?
162293,can you tell us a bit more about what you are trying to do ?
162316,"what do you mean by "" compare the different travel time and distance parameters against themselves ?"
162338,are you just asking for a ` time ` by ` height ` scatterplot in which you can see that there are multiple instances at certain points ?
162252,how are you extracting features from text ?
162375,how does such a question arise ?
162395,"neither of the tests you mention are really * nonparametric * ( though it may arguably depend on just how you define the term ) ; though fligner-killeen would tend to come closer to it , i think . they are both pretty robust against non-normality , however ( at the expense of some power at the normal , naturally ) . what would constitute the "" best "" one may depend on circumstances ( and what things you want to do "" best "" at ) . however , with 50k observations , ( is that in each group , or in total ?"
162442,have you thought about utilizing a factorial design for this analysis ?
162473,is this a self-learning question ?
162484,"what is your tool of choice , ?"
162482,can you briefly describe the difference between the teams ?
162517,why would you do it for all coordinates simultaneously ?
162536,if $ x_2 $ and $ x_3 $ affect $ x_1 $ how can there be no multicollinearity ?
162393,what are you trying to learn ?
162575,more suitable for [ stack overflow ] ( url ) ?
162569,` where n is selected amount of classes ` that's unclear . could n be the total sample size and k be the number of classes ?
162676,"when you analyze your simulated data , you are leaving $ u $ out of the regression model , yes ?"
162679,what do you mean saying ` exact ( not corrected for multiple comparisons ) ` . was that you computed exact ( permutation test ) p-values ?
162691,1 . i don't see any fitting going on there ; this makes it a bit hard to guess what the situation actually is -- how are the coefficients obtained ?
162720,have you tried simply plotting the corresponding values of ` bar ` on the horizontal and ` dot ` on the vertical axis as a scatterplot ?
162776,"regarding q2 : if two class covariances are assumed to be equal , then the midpoint on the line connecting two class means , i . e . $ ( mu_1 mu_2 ) / 2 $ should lie on the decision boundary . this should uniquely specify $ w_0 $ , shouldn't it ?"
162796,"but the truth is $ chi_d ^ 2 $ , think about the simplest case , project a standard normal random variable $ z $ onto $ mathbb { r } ^ 1 $ ( which means the projection is $ z $ itself ) , what is the distribution of $ z ^ 2 $ ?"
103253,is x ( the discrete variable ) ordinal or not ?
161953,why does this need to be done as 1000 separate models ?
162843,compare them w / respect to what ?
162818,acceptable to whom ?
162894,have you looked at modeling your data as a simple poisson distribution ?
162891,"could you please explain what you mean by a "" linear trend "" in the correlations ?"
162969,"are the data paired , i . e . the data are $ ( a_i , b_i ) _ { i = 1 } ^ n $ or are they not , i . e . do you have two different data-sets $ ( a_i ) _ { i = 1 } ^ m $ and $ ( b_i ) _ { i = 1 } ^ n $ ?"
162966,"consumption at time $ t $ impacts consumption at time $ t 1 $ . for instance , you crashed your car , and had to buy a new one in time $ t $ , do you think it won't have any impact on subsequent consumption ?"
162897,"welcome to cv ! you might have more luck obtaining a useful answer if you give a fuller description of your aims . for instance , what use do you plan to make of these clusters ?"
162999,what are your dependent variables ?
163000,"the term "" testing $ r ^ 2 $ "" is rarely heard of . why don't use the mean prediction error ?"
162587,"you also entirely skip the time series aspect of the data and state . the posterior for $ x_t $ comes from the $ x_ { t-1 } $ passed through the state equation $ p ( x_t x_ { t-1 } ) $ to generate a prior for $ x_t $ , then conditioned on $ y_t $ via the likelihood function $ p ( y x ) $ . what , in this scheme is then h ?"
162913,"to study the influence of the cooking event on the behaviour of your subjects , you should measure pre event and post event behaviour in the same way . is the problem that you cannot do that ?"
163033,is $ 5 $ too small sample size for a decent simulation ?
163054,seems a bit subjective . why are the behaviors of a and b more similar than those of a and c ?
163069,"there are all kinds of ways to cope with this using linear regression , but the very first thing you should do is include the constant in a multiple regression to see whether it differs significantly from zero in the first place . what results do you get ?"
163079,"what _exactly_ is meant by iid when you say that $ ( x_i , y_i ) $ are iid ?"
163092,are you asking how to write a loop to perform the same operation on multiple objects ?
163094,"it's not clear to me that kruskal wallis is suitable ; ignoring the possibility of time dependence ( aside the effect of the intervention ) , aren't there two factors here -- before / after and location ?"
163140,"because the cv is not a pure measure of dispersion ( and would not even be applicable if some of your measurements could have negative means ) , and yet you have computed and compared cvs in an effort to address this question , one wonders what you actually mean by "" dispersion . "" could you clarify that ?"
163174,"do you have access to gelman and hill , "" data analysis using regression and multilevel / hierarchical models "" ?"
163181,is ` observation ` the name of your table ?
163232,"what do you mean "" the combinatoric terms don't combine cleanly "" ?"
163244,do you have access to a statistical software package like r or sas ?
163274,well you could apply discretization in order to transform numerical features into categorical . is it important for you to keep the features numerical ?
163159,"that zero in # 1 ( '0' ) is meant to be an 'o' as in observed events , right ?"
163298,( i ) what do you mean by 'work' -- are you referring to significance levels close to nominal ( and if so how close is close for you ?
163334,"what is intended by "" valid "" there ?"
163330,what is slow ?
163398,"i was surprised to see you propose using a histogram and t-test to deal that data that "" isn't completely independent . "" neither of these procedures will reveal or deal correctly with a lack of independence . could you therefore explain the sense in which the data are not independent ?"
163433,"i thought by definition $ i ( x ; y ) = h ( x ) h ( x y ) $ , where i is the average mutual information . i'm finding your question confusing because isnt the information gain already an entropy based measure ?"
163486,what do you mean by curve ?
163475,why do you need a significance test ?
163493,are there predictor variables / covariates here ?
163549,why would you like to do something like this . . ?
163531,i am unable to see the connection between the question asked in the first paragraph and the application described in the second . could you explain what one has to do with the other ?
163596,do you need spatial autocorrelations as well ?
163518,is this rts ?
163608,more information needed about what you are trying to do . what is 'uniform distribution set' and why are you randomly choosing from it ?
163614,"( 1 ) but please note that stouffer's method in this form is not appropriate for two-tailed alternatives . the problem is that it overlooks the possibility that one study might have found an effect in one direction and the other , an effect in the opposite direction . one has to check that this has not occurred . to get to your question : in what sense is this "" artificial "" ?"
163642,"do you have multiple x variables & a single y variable , or do you have multiple y variables ?"
163660,"the $ t $ -test assumes normality , at least for smaller samples , and these data are markedly non-normal . you would probably want to use a non-parametric test , but more importantly , what is the actual question you're trying to answer ?"
163704,"can you clarify your problem in that way that its clear wether it is a classification / regression , clustering , feature engineering , etc . question ?"
163802,"please describe exactly how you are running a ks test on each vector . in particular , do you know the range of this uniform distribution beforehand or are you estimating it from the values in the vectors ?"
163778,you describe two techniques : one of them relies on the * order * in which you listed the data and the other ( the histogram ) does not . is the ordering meaningful or not ?
163846,you have cropped the graphs . we can't even tell whether the theoretical quantiles are on the horizontal or vertical axis ( different software make different choices ) . can you paste in better figures ?
163868,"it sounds more like "" heavily right skewed "" vs i-can't-guess-what . . . can you show examples ?"
163912,""" power "" is a property of a statistical hypothesis test . what null hypothesis and what alternative hypothesis are you using ?"
163573,how about a propensity score adjustment ?
163921,"you appear to be describing the * maximum . * however , your question does not supply enough information to determine and objectively support any particular answer . you are essentially asking your readers to guess the results of a modeling exercise in which you relate these metrics to actual default experiences . if you don't have such data , then we're all just guessing . do you have relevant data ?"
163842,thank you ! are these school averages explanatory or response variables ?
163917,by implementation you would mean code for a statistics package ( which would be off-topic here ) or a statistical procedure for your problem at hand ?
163986,"what does "" service point "" mean ?"
164003,"yes , you should be using that sort of call . you need to provide a set of covariates that match both the original set as well as covering the time intervals of interest for the prediction . see ` ?"
164014,"components are orthogonal ( i . e . have correlation zero ) , that's right . this does not contradict my answer in the linked thread . what * exactly * do you mean , when you say that 100 % variance is explained when you use all components ?"
161951,if there were ties at the split point i would think there might be problems but you have prevented that . can you show that any reallocation of two assignments will create a larger absolute difference ?
164067,"may be i'm missing something , why don't you remove nas and start with the first value if next day ?"
164017,what can you say about $ g ( 0 ) $ or $ g ( 101 ) $ ?
164111,can you show the code you used to resample ( augment ) your rare class ?
164101,"could you please add the output of ` plot ( fita2 , which = 1 ) ` to your question ?"
164119,"normally the "" / - "" refers to the dispersion of measurement errors . this suggests that computing a range as you propose would mix up two completely different things : the range of your means ( 16 . 7 to 54 . 4 ) and the dispersions of their measurements . it is difficult to imagine a context in which that would be meaningful . could you enlighten us concerning the intended interpretation or purpose of this calculation ?"
164128,see also [ how should outliers be dealt with in linear regression analysis ?
164120,what are your explanatory variables ?
163378,"what is particularly "" bayesian "" about rejection sampling ?"
164179,model averaged estimates of * what * per se ?
164209,what is a-h here ?
164222,"dimebucker91 : since [ the reference you provide ] ( url ) has an expression of the joint pdf , what is exactly your question ?"
164215,"maybe i'm looking at the wrong version , but on p . 7 of url they have $ ( mathbb { e } [ alpha f_ { ij } ( 1- alpha ) s_ { ij } - sigma_ { ij } ] ) ^ 2 $ ( not $ delta_ { ij } ^ 2 $ ) . if that's the right version , then they just wrote $ $ alpha ( f- phi ) ( 1- alpha ) ( s- sigma ) alpha phi ( 1- alpha ) sigma - sigma , $ $ where $ phi = mathbb { e } [ f ] $ and $ sigma = mathbb { e } [ s ] $ and expanded the expectation of the square as $ $ alpha ^ 2 mathbb { v } [ f ] ( 1- alpha ) ^ 2 mathbb { v } [ s ] 2 alpha ( 1- alpha ) mathrm { cov } ( f , s ) alpha ^ 2 ( phi - sigma ) ^ 2 $ $ using the usual definition of variance . is this close ?"
163993,"the gaussian ( or perhaps it's an error function , if it truly is cumulative ) looks like a poor fit . why not use logistic regression ?"
164145,"when you write ` union a_b : ele3 , ele4 ` , surely you meant _intersection ?"
164165,"are the different columns different variables ( eg , height , weight , age , etc ) ?"
164439,are you asking for an appropriate statistical analysis for use with missing data ?
164497,why should it be ?
164499,"glen_b i didn't see anything the matter with the original notation , nor does it appear that using "" n "" has clarified anything . there is no notational problem with using the same symbol for a bound variable in the sum and a specific value outside the sum--it is well-defined and unambiguous . tarvoc : what do you mean by an "" mse estimate "" ?"
164436,have you looked at clustering using [ dbscan ] ( url ) ?
163922,how did you get the ( s ) arima model ?
163206,when would you bother trying to calculate the log-likelihood for a case that has no chance of happening ?
164541,how many lines do you have ?
164579,"what "" meaning "" are you looking for : the meaning of r's code or the meaning of such a matrix ?"
164598,how you get this ?
164636,can you give some more details on how you calculate the subscales ?
164669,scouserintrousers could you elaborate on why this distinction important ?
164671,"are x & y spatial coordinates ( eg , latitude & longitude ) or just 2 features ( eg , local temperature & rainfall ) ?"
164687,"some questions : when you say a "" sampling "" of plots , what do you mean ?"
163559,gurkenhals : your update shows another good way of visualizing the relationships predicted by the model . again a little explanation would be helpful - & what are you asking about this addition ?
130974,"i am curious about the source of your information that "" k means is only designed for continuous variables . "" would you be able to cite a reference ?"
164748,"i see that the numbers don't add to 100 even though the average is supposed to be 20 . what would you want to do if they all said , say 13 ?"
163695,"are the layers n-2 , n-3 , . . 1 linear or nonlinear ?"
164720,how many clusters ?
164773,"could you please explain what you mean by a "" bi-level linear model "" ?"
164526,what do you mean by 'data has become random' ?
164672,"this is hard to follow . can you say more about your situation , your data , your variables & your goals here ?"
164805,could it be that you are actually getting the * negative * of aic or bic ?
164831,so you are trying to see if a particular case used in your model is an outlier with respect to the other cases : is that correct ?
164806,"what's "" the cw "" ?"
164868,why are the data missing ?
164889,"a negative binomial glim is a kind of count model . the response is supposed to be counts . a [ count ] ( url ) , by definition , cannot be a fractional value . do you have such values ?"
164855,"see what the help page says about the ` eval . points ` argument . note that the values returned by any kde are a * density * , not a "" mass , "" so i am concerned that you ( or at least some readers ) might misinterpret the meaning of your threshold . what do you understand it to represent ?"
164825,"i think a better analog to the one-dimensional case would be to have $ f ^ i sim gp ( 0 , k ) $ . each observation is the result of the overall process , a group effect ( random ) and noise . you have added another level of hierarchy to the problem by giving each group its own process ( instead of an instance of a common process ) . why do the $ k $ need to be random ?"
164891,"out of curiosity , to what "" eda texts "" are you referring ?"
164896,"i am curious about what body of "" theory "" you are invoking to conclude that deep nets are "" superior "" in regression--and superior to what method , exactly , and according to what metrics and for what purposes ?"
164555,"do the elements of $ x $ have some natural similarity function under which $ f $ ( or $ mu $ ) can be assumed to be reasonably smooth , or are they just independent symbols ?"
164863,"how can you check , with only five points , relevant non-normality of the underlying true population ?"
164931,"for correlation to make sense , x should be associated with y . for example , if x is a vector of length 7 representing daily units of bread sold from monday to sunday and y is vector of length 5 representing daily units of butter sold from monday to friday , then you may want to consider matching x and y by "" day "" . so what are your test results and is there a logical association between them ( i . e . why are they of different length -i didn't quite understand this from your description ) ?"
164950,"the problem with "" good enough "" is that mileage varies . expectations minus reality equals disappointment . what do you expect from your fit ?"
164953,"could you explain what you mean by an "" unsatisfactory result "" ?"
164960,what do you already know that you can use ?
164998,another hint : what will happen with the two intervals in question if you simply increase the number of replications from 100 to 1'000'000 ?
165000,( 1 ) there's no requirement to bin continuous independent variables for logistic regression - see [ what is the benefit of breaking up a continuous predictor variable ?
161941,"i would like to confirm that your question is this : i have data , and a candidate model , and i want to fit the model coefficients using the data . i think you might be delighted to discover the power of the "" glmulti "" library , if you have the data . the second model has no ageyears . this makes me think you might have their model , but not their data , and you are trying to reconstruct a realistic form of the data . which is it ?"
165018,in which package can we find the ` randn ` function ?
165047,"chameleon is irreproducible in my opinion , and spectral clustering usually just uses the pairwise distance matrix , doesn't it ?"
165062,"do you mean that you are 95 % confident that the label for x1 is correct , and believe that a different label holds with 5 % probability , or does "" confidence "" mean something else here ?"
163356,what's a midplane ?
165128,"please tell us how the results differ between ( 2 ) and ( 3 ) . it would also help to describe how you standardized the variables . one possible source of slight discrepancies in estimates would be the presence of missing data , so in your testing have you made sure there are no missing data ?"
165187,"what do you mean that * * timepoint * * has "" intervals [ that are ] are variable "" ?"
164903,you might receive an answer if you give more info : what is doe in that context ?
165260,"1 , nice sketch . do you have a control condition with no plants growing ?"
165269,whuber i don't think any of the answers to [ the question you referred to . . . q / 4364 / 6633 ] ( url ) or comments thereon have any relevance to arka's question . could you be more specific as to which answer or comment you are saying is an _explicit_ answer to arka's question ?
165268,what do you mean by 'statistically equal to zero' ?
166328,do you know what a binomial distribution is ?
166363,why would all of the chickens choose blue ?
166372,did you account for the jackknife multipliers properly ?
166388,what will * you * actually do with a model that requires you to know already the value of something you're trying to predict ?
166390,can you clarify what you need here ?
166389,"what do you mean with "" clusters of words in text "" ?"
166406,try ` contrasts = list ( domain = contr . sum ) ` ?
166399,what was in the tea ?
166413,did it work ?
166437,"so you have 7 yearly observations ( or 28 quarterly , or 84 monthly , or . . . ) ?"
166468,why do you compute ` mean ( mean ( traindata ) ) ` ?
166469,"can you clarify what you mean by "" real data "" ?"
166516,"looking at the graphs , there seems to be quite a clear seasonal pattern . when neglected ( as in the tests above ) , it may cause trouble . have you considered using seasonally-adjusted data instead of raw data ?"
166538,i thought your dependent variable was just # intrusions . are confusing * dependent * with * independent * ( two binary variables for the experimental conditions ?
166584,what are the strange results you are referring to ?
166536,"i don't really follow this . what do you mean by "" group by program_id depending on their similarities between rio and sao paulo "" ?"
166610,i don't understand the question . can you give a concrete use case where you would want to change the classes ?
166637,i don't understand the distinction you're making . could you articulate it a little more precisely ?
166693,dsaxton what support do you have for that comment ?
166694,are all of your original data values greater than 0 ?
164705,"the r results show the call , so we know what function and options you used on that side . what about the jmp side ?"
165125,what do you mean by properly ?
166723,"generally , the phrase "" confidence interval "" refers to the precision of an estimate of a parameter . i gather you only want to determine limits that bracket off a give proportion of the population distribution , is that right ?"
166741,"can you clarify what you mean by "" an overall trend "" ?"
166756,"the difficulty here with a yes-or-no question like this is if the answer is "" yes "" , we can't actually post an answer to the question , since single sentence answers ( let alone single word ones ) aren't really allowed . yes , it's right , but how in general does one expand on that ?"
166743,can you post the data and minimal code to reproduce ?
166776,"you didn't specify the empirical option for the standard errors without telling us , did you ?"
166796,see [ distinction between linear and nonlinear model ] ( url ) & [ why is polynomial regression considered a special case of multiple linear regression ?
166810,"set 2 does not look all that non-normal : there are so few data that it plausibly could be a sample from a normal distribution . in such cases it may be going too far to apply such a strong nonlinear transform ( whose box-cox parameter is influenced entirely by a single value of 3 . 82 ) . since you're performing anova , it doesn't seem to be relevant that this dataset is non-normal in the first place : anova does not require normality . in fact , when the alternate hypothesis is true , anova is tantamount to an * explicitly * non-normal model . why , then , are you doing this ?"
166821,"are you sure that you are extracting the right objects from ` fit ` , and what those object actually mean ?"
166845,what do the thick black dashes in your images mean ?
166852,"when you say "" try to use approximation "" . . . what approximation are you referring to ?"
166840,"first , is depression ~ ~ stress in the model ?"
166886,do you pick 30 numbers randomly ?
58537,can you provide information on how you are calculating p-values ?
166753,"i'm not sure your question makes sense . there are two variables , one is continuous , and one is binary . you wish to calculate the correlation of the two variables . is this correct ?"
166922,"can you cite some of these papers , & / or quote relevant discussions that use the term ?"
166989,robust pca of candes et al . decomposes matrix $ x $ into matrix $ a $ that has low rank ( and is not sparse ) and a matrix $ e $ that is sparse ( and is not low rank ) . so $ a $ is supposed to be low rank . what's the point of another pca step then ?
167008,can you provide the code / function calls you used to get this output ?
166997,i think that this is more of about properly framing your research : what question are you interested in answering ?
166897,"do you mean that your dv is a categorical variable with 7 levels ( 6 different pathogens "" no pathogen "" ) , but that there are patients with 1 of those pathogens ?"
167062,what do you mean by data sets ?
167014,aren't they the same model ?
167124,have you tried -marginsplot- ?
167102,""" valid "" in what sense ?"
167021,"if it is easy with ar ( 1 ) , then recall that ar ( $ p $ ) can be represented as ar ( 1 ) . see [ this ] ( url ) p . 5 for "" companion form "" for a var ( $ p $ ) model ; ar ( $ p $ ) is just a special case of var ( $ p $ ) . perhaps this could be useful . but what exactly do you mean by "" so that the same autocorrelation function ( ac ) is kept "" ?"
167164,do you see * any * evidence in these data that the experiments have different success probabilities ?
166964,stefan did you ever solve your problem ?
167171,"i'm a bit confused . there is one "" question "" and many "" items "" ?"
167138,` wilcoxxon rank sum paired test ` sorry ?
167196,"don't you want both powers in the formula to be $ 2 $ , rather than one of them $ 3 $ ?"
166333,so your total sample size is two ( $ x_1 $ and $ x_2 $ ) ?
81636,subhashc . davar : does [ how to use pearson correlation correctly with time series ] ( url ) help ?
167241,can you elucidate why you don't feel that leaving out people who don't express a preference is inappropriate ?
164219,do you have the actual function ?
167303,what is a sophisticated regression ?
167334,you get 0 for what exactly ?
148280,antoine really exciting question ! was a definitive answer found ?
167346,what exactly are you trying to accomplish ?
167361,what are you quoting from ?
167386,why would you want to do this ?
167430,"some more information on the nature of the scale would help . are there always 40 points on the scale each day , but in most cases the score is 0 ?"
163006,could you please elaborate on what you're exactly looking for ?
167454,which software are you using ?
167503,"content based recommenders mainly build on item-to-item similarity . that is , items similar to those liked / viewed by the user are recommended . which papers do you refer to ?"
167521,when you did a glm . . . how exactly did you do it ?
167542,"if the underlying relationship is not exactly as specified by your model , then the answer is clear . this pushes the burden back on you : how sure are you that your model is * the one and only correct * one ?"
167443,why do you need to identify a distribution ?
167562,could you please explain the nature of this graphic and what it represents ?
141558,are your data counts of 'alive' & 'dead' ?
167663,"gaurav , why shoudh i choose ets model ?"
167688,"do i understand you well that you have 50 percentages , and that each of these 50 percentages is the fraction of 'positive' answers on 15 questions ?"
167702,what is the actual question ?
167547,could you clarify what $ theta_j $ is ?
167732,could you explain in a few words what is a * binary symmetric channel * ?
167794,"for the users where ` openwithsmartphoneind ` is na throughout , is this because the value of that variable is unknown for those users , or because it always takes a "" no "" value ?"
167798,what are the outcomes ?
167483,i see that you have left the question as 'unanswered' . what is the main question that you still have ?
167277,i'm not quite sure this is a bona fide recommender system problem . how will users query the model ?
167823,how many observations did you use for computing each proportion ?
167825,"i believe you may have misinterpreted some of these diagnostics . the * very first * thing you should do is to make diagnostic plots instead of running these tests . after all , with so much data you likely have the ability to detect complex forms of nonlinearity and heteroscedasticity , but their magnitudes may be unimportant for prediction ( and attempts to accommodate them risk creating an over-fitted , and thereby badly-predicting , model ) . what do these plots show you ?"
167866,"the way this question is asked suggests you are interested in the mathematical underpinnings of "" regression analysis "" ( which is a broad , vague topic by the way ) rather than in regression itself . could you clarify this point ?"
167870,"you make a series of statements , but don't seem to actually ask a question . what is it you want to ask ?"
167897,"how , exactly , does the output from your linear model ( which is not shown ) indicate it is "" a better predictor "" ?"
167936,are you aware that there have been quite a few similar questions on this forum earlier ?
168012,"see also [ given the power of computers these days , is there ever a reason to do a chi-squared test rather than fisher's exact test ?"
168022,"do you use only the categories of restaurants , or is there some data collected about the individual restautants ?"
168059,hint : exactly what statistic is this correction factor being applied to ?
168109,"do i understand it well that $ w = mg mt ct $ such that $ delta w = delta mg delta mt delta ct $ and that you want a decomposition in relative growth of mt , mg , ct ?"
168110,"i am curious what an "" interval "" is . for instance , i see no basis to reject a solution that identifies the apparent inverted peaks--even though that would be quite different from the solution you are suggesting . could you provide a more specific description of the patterns you are attempting to identify ?"
168128,"it should be ( more or less , as the test statistic is a discrete random variable ) a uniform distribution from nought to one . did you intend a one-tailed or a two-tailed test of the null ?"
168186,"what exactly do you mean when you say that the model becomes "" very very messy "" ?"
168182,"can you please explain , what do you mean by "" frequency "" here ?"
168264,"so am i correct in saying that this is a weighted mean among $ n $ subjects , with the weights being the number of measurements per subject ?"
158225,why would you need to combine them ?
149321,how much faster do you want it ?
168312,"$ x $ is a random number , what is the problem with doing $ x ^ 2 $ or $ ax b $ ?"
168332,i thought gretl was open ! ?
168311,"i assume that your $ beta j $ have changed , but that at the same time their standard erros have changed ?"
168229,"i don't understand what you mean by "" natural extension . "" what is that intended to be ?"
168425,"hi pete . am i correctly summarizing when i say that you want to construct tfidf matrix in chunks of 10k , constantly updating the idf component as you go along ?"
168432,"is the low-sample "" class "" that you mention the target of your analysis ( i . e . , the dependent variable ) ?"
168452,welcome to r ! you want to search for more words or across more documents ?
168468,"if prices in the markets b and c never fall into $ [ 6 , 10 ] $ why would you want to predict them in this range ?"
144177,$ beta_3 $ is never defined . what is $ beta_3 $ ?
168511,"i admit i don't know anything about power divergence , but i don't see how lambda = 1 corresponds to mle , since setting lambda of 1 gives us a denominator of 0 in the leading coefficient ! are you sure you've correctly specified d ?"
168537,are you sure your expression for $ hat { sigma } _k ^ 2 $ is correct ?
161346,"it is difficult to tell what you are asking , because you appear to use "" dataset "" synonymously with "" variable , "" which is unusual and confusing . could you provide a more explicit description of what kinds of data you actually have ?"
168562,are you concerned about the absolute best aicc to meet a publication requirement ?
168669,"if there's no error , then why would you need regression at all ?"
168676,"since i don't follow what $ m ( x ) $ really is-- "" dimension reduction projector "" is a rather vague term--i am focusing on the literal statement of the question . it seems to ask , in complete generality , whether there is a mathematical relationship between the eigenvectors of the mean of a set of matrices and the eigenvectors of the matrices themselves . is this really your question ?"
168609,is there any update so far for the right answer ?
168724,two questions . 1 ) is this the adjusted $ r ^ 2 $ ?
168774,"it isn't clear to me if this is ultimately a stata coding issue ( in which case it would be off topic here ) , or a statistical issue ( on topic ) . either way , it will be difficult to diagnose without a [ reproducible example ] ( url ) ; can you add one ?"
168851,where did you find those definitions ?
168848,i don't think so . why do you think you need to do that ?
168863,would wishart distribution help ?
168870,"you have a 2x2 table of counts ( obese , not ; high , low ) . are the counts balanced ?"
168871,"could you explain what you mean by "" edges "" and "" sum up values . . . to infinity "" , given your data stop at $ x = 94 $ , which seems just a little short of $ infty $ ?"
158631,related : [ are there algorithms for computing running linear or logistic regression parameters ?
168830,can you please provide a link to the answer you seem to be referring to ?
168928,"are you simply saying you created a new logical variable weekday indicating if the day is , indeed , a weekday ?"
168897,"for each game , let $ p $ be the probability of positive review ( one different $ p $ for each different game ) . tou could present confidence intervals for each $ p $ . if you have many games and want a ranking , there are statistical methods for that too , but maybe complicated with only "" basic stats "" . then you would need to formulate more precisely your goal . can you post a link to your data ?"
168953,are you willing to assume that $ j $ is smooth ( say twice continously differentiable ) and convex ?
166903,"i agree . it seems that the $ tpr $ coordinate is undefinited when you vary the threshold on probabilities . on the other hand , the $ fpr $ coordinate should vary from 1 to 0 varying the threshold on probabilities from low values to high values . however , why do you need this ?"
168940,"thanks , yes , that's clearer now . i have attempted an edit to your question to perhaps make it clear in the question itself , but you may want to edit it further . is this for a class ?"
168806,"what do you mean by "" batch effects "" ?"
169044,"are your data count data , as in the cited paper , or are they fluorescence intensity data , as in traditional expression microarrays ?"
169118,what is the nature of the ` twenty_five ` variable ?
169157,the value of the exponent $ gamma $ appears important . is it $ gamma leq 1 $ or $ gamma 1 $ ?
169160,this would really depends on which questions you want to answer ( e . g . is there any interest in whether things change over time or is the interest only in the average ?
169123,you might be interested in this : [ how should one interpret the comparison of means from different sample sizes ?
169242,"are these the true conditional expectations , or estimated conditional expectations ?"
167051,". . . ( continued ) a hardcore frequentist , in search of a class of estimators from which to select the "" best "" one , might reasonably decide to consider the class of all bayesian estimators ( i . e . priors ) and therefore use the estimator ( prior ) that is best according their "" objective "" criterion . is such a person frequentist ( because of how they select the best estimator ) , or bayesian ( because they consider only bayesian estimators as candidates ) ?"
169334,this is only part of the difference between the two but did you notice that ` lm . circular . cl ` doesn't fit an intercept term if you don't tell it to ?
169335,"why not just plot 2 curves , 1 for male & 1 for female ?"
107472,what do you mean by anomaly ?
169382,do you truly want to know the effect for the contrast between arbitrary months ?
168065,"could you post the data , or scatterplot ?"
169392,"for what purpose are you "" normalizing "" the data ?"
169396,"each "" eigenvector "" is a vector that ( if i understand your setup correctly ) has as many elements ( components , coordinates ) as you have genes . so what do you mean when you ask about "" the magnitude "" and "" the sign "" of an eigenvector ?"
169488,"can you give sample code , sample data ?"
169489,what are the gene expression numbers ?
169510,"i'm confused , do you want something "" more "" rigorous or "" less "" rigorous ?"
169529,will the rest of the dimensions become available later ?
169580,"what do you mean by "" has an effect on these birds or not "" ?"
169592,is this a question from a course or textbook ?
169623,newb question : does bootstrapping count ?
169742,"what do you mean "" an interaction dependant variable "" ?"
169758,which formula did you use to calculate the power ?
169664,"please note that ols does not assume predictors are independent . it is only certain particular solution methods or formulas that make such assumptions . what is of importance is how you select the ridge regression multiplier , not that the estimate of $ beta $ might be biased . if that multiplier is selected by eyeballing a ridge trace , then you don't really have a way to quantify uncertainties , which calls into question most of the formal diagnostic tests in linear regression theory . this leads me ask what you actually mean by "" ridge regression "" : how exactly are you estimating its parameter ?"
169706,"i apologize for the downvotes--they are scarcely a friendly introduction to the site , are they ?"
169677,"i'd advise using smaller points and plotting the line in a contrasting color . the fact that it's clear that the data are not drawn from a lognormal ( nor the log-data from a normal , naturally ) may be of little consequence depending on what you're trying to do . why do you need to identify a distribution ?"
169789,what is the evidence for a transformation ?
169199,"what is "" rare "" for you ?"
169655,"sure , but since there are plenty of ways for "" usual analytic methods "" of estimation and as many bootstrap variants , you either need to provide detail on what you did or the code so that we can infer ourselves . otherwise you'll just get very generic answers that will hardly help you , and certainly no answer at all to "" which is the result to be trusted ?"
169838,may i assume that the time-series are monthly ?
169854,"i don't see any error * per se * : this appears to be a well-founded attempt to reason with data , albeit perhaps with a small dataset ( which is not an error in itself ) . but are those 50 people just those your interlocutor happens to know or are they a complete census of all the people living in the area ?"
169895,is the issue that you don't know how to interpret the p-value ?
169906,is this a question from a course or textbook ?
169805,can you please address the following to make your question answerable ?
169969,"thank you--that's an interesting application . but what does "" model fit "" mean ?"
169970,_ $ t $ -distributed_ maybe ?
169934,` is there a reason other than convention or convenience why this reordering would be necessary ?
171050,"you're looking for a quality score . . . but how do you define "" quality "" in the first place ?"
171061,what does * fm * stand for in * fm-ols * ?
171125,"the formula is correct , but could you please explain what asymptotics you are using ?"
171130,"what is "" em clustering "" ?"
171156,"are you asking about normal distributions of the variables themselves , or of the residuals after fitting a model ?"
171203,i was wondering what you decided to use for this ?
171261,"why do you want to fit a "" mixture "" of gaussians if you know that your data consists in only one gaussian ?"
171267,"if you have sales data , do you also have a customer id ?"
171301,i would suggest to start by trying the same process using ` party ` package instead of ` partykit ` . i think the ` type = 'simple' ` plot works better that way . what is your dummy variables' values ?
171324,"do none of the answers to the questions showing as "" linked "" and "" related "" to the right of this question satisfy you ?"
171343,"what would it mean to "" put these 6 numbers together on one equation "" ?"
171360,"i'm not sure i understand . . . are you saying you do not have values for 4 different nights and days , but just the median ?"
171375,"when you say "" treatment is randomly assigned to true or false based on the probability of treatment for that subject "" , does that mean that a row is assigned ` treat = true ` if ` prob ` is greater than some cutoff ?"
171374,have you had a regression course yet ?
171389,in your question ; is 'method' and 'model' the same ?
171062,i don't understand what it is you want to do . do you want to calculate the difference in time for all combinations of y ?
171473,"is there a reason you have chosen to simulate 9 , 759 , 911 observations ?"
171524,"and can you publish the data itself , not simply the plot of it ?"
171577,what about pca and mca ?
161966,what do you mean by * uncertainty * ?
171539,` the data is centered around zero ` is that the column centering ?
171273,"there are some problems with your intervals , for example : "" ( 2 . 5 , 2 . 1 ) "" is [ backward ] ( url ) , with the upper limit before the lower . "" [ infinity , 1 . 5 ] "" has the same "" backwards "" problem , * and * you have infinity in a closed interval ; the real line doesn't work that way ( unless you're using the extended real line , but in that case there are some other issues to fix with your question ) . are you missing minus signs on some of those quantities as well ?"
171632,did you google ` matlab factor analysis ` ?
171568,"do you really mean $ iid ( mu_ epsilon , sigma_ epsilon $ without any specification of distribution form , not , for example , normal distribition ?"
171680,"you have 'played around' with the standard deviation , not with the variance ?"
171695,a question for you to ponder : what population quantity is the difference in sample means measuring ?
171594,are you sure that $ u $ and $ y $ are independent ?
171705,"if it's bounded between 0 and 8 , i wouldn't start with a poisson . but why do you need to fit a distribution at all ?"
171652,"no matter how i try to interpret it , i cannot make sense of "" i want to find the minimum number of individuals that should be identified in each sample so that i can conclude that the proportion of individuals of each species remains the same for the rest of the sample . "" would it be possible to phrase this in a different way ?"
171754,"in $ operatorname { var } ( varepsilon_i x = x ) = sigma ^ 2 $ , $ x $ does not have a subscript . is that intentional ?"
171768,did i answer your questions ?
30723,if you _randomly_ split the sample into 5 subsamples your 5 means will almost coincide . what is the sense of making such close points the initial cluster centers ?
171815,why not just use a mixed effects model ?
171338,which language are you using ?
171860,possible duplicate of [ how to understand degrees of freedom ?
171928,how do you know that the models selected by aic are overfitted ?
155989,it sounds like you want an r / python tutorial . that is off-topic here . can you make your question more specific ( & software neutral ) ?
171938,"maybe you should ask do you require a level of floating point numerical mathematical software , i . e . , numerical analysis , education from your software developers ?"
172003,have you considered integer linear programming ?
172008,data is something you observe . so what is null hypothesis data $ s $ ?
172039,"i'm surprised that this recipe , which i'd never seen before , gets so close to my answer of $ 546 $ . do you have a reference for it ?"
172040,please clarify : you appear to say that there are four inaccessible villages in the list of 500 . is that correct ?
172024,please be more precise . what the new constraints should do ?
172044,"have you considered parsing the files and storing them in data structures like arrays , or much better , a data frame ?"
172048,""" outlines "" ?"
172178,this needs to be tightened up a bit . what property of two random variables would result in zero distance ?
172181,self-study tag ?
172189,do you want confidence bands or prediction bands around the curve ?
172213,are all the discounts the same amount or % ?
172225,what is the actual structure of your data ?
171853,what kind of data do you have more precisely : you have n different participants and for each of them you have a response1 and response 2 ( and the difference ) and for each prticiapnt you also have values for 7 other variables ?
172226,this question has quite a lot of hypotheticals . could you re-phrase it to what you actually are trying to do ?
171139,"would you comment more on the real , underlying disease process and how the risk categories were assessed in each of the two datasets ?"
172299,can you say more about your situation & your data ?
172371,could you make your discussion a little less abstract ?
172379,"the impulse response of variable x in period one will be the shock to variable x itself , won't it ?"
172393,"in short , no it does not . just apply the convolution formula to derive the density of the sum or difference of two elliptical variates and this should come out clearly . elliptical distributions are not naturally associated with degrees of freedom , what do you mean by these ?"
172163,"it makes even less sense . why would you construct a single tree from a rf , when you already have a rf ?"
171187,so can estimate mean and variance of each subject if i understand you well ?
172446,how many separate actions in each sequence ?
172474,"could you explain what a "" negative time value "" means ?"
172515,high school student interest ?
172519,you presumably want a mixed-effects version of ordinal logistic regression . i have an example here : [ is there a two-way friedman's test ?
172030,1 . you still don't specify nearly enough ; what's the dependence structure between x and y ?
172586,how many papers do they examine ?
172626,what are the ` number_category ` s ?
104812,what are these data ?
172641,"possible duplicate of [ why does gap statistic for k-means suggest one cluster , even though there are obviously two of them ?"
172663,"could you tell us what "" $ u $ "" is ?"
172648,"re ( 3 ) , since $ a ( x-h ) ^ 2 c $ can be rewritten $ ax ^ 2 ( -2ah ) x ( ah ^ 2 c ) = beta_2x ^ 2 beta_1x beta_0 $ , you can test for changes in width by tracking the estimates $ hat beta_2 $ and for changes in location via the estimates $ - ( 1 / 2 ) hat beta_1 / hat beta_2 $ . the first is straightforward while the latter can be accomplished within a maximum likelihood estimation framework . btw , my first reaction to an "" incompatible copy "" error would be to reinstall the software . have you been able to load your model directly into winbugs ( without using r ) ?"
172518,can you give a specific example of how your results differ from the author's results ?
63807,"what do you mean by "" skewness and kurtosis are known exactly "" ?"
172746,why are you doing pca in order to find predictors ?
172759,"in * * r * * , you would encode such features as * factors * . why language are you using ?"
172782,taking the coursera regression course ?
172792,who's to say that having oval kernels is incorrect ?
172812,what does having every card in the deck mean ?
172844,is there a linear relationship between the number of clicks on ads and revenue ?
172795,"before scaling , what's the smallest value you have ?"
172895,what happens if you add ` alpha * sigma ` instead of subtracting it ?
172177,"probably the just mean that it will be costly to collect data . . . , so budgetary constraints is that "" downward pressure "" ?"
168353,"clearer , at least . here $ perp $ is intended to mean "" independent "" , "" uncorrelated "" or something else ?"
173007,why do you bin the data ?
173024,""" can you provide links where i can find more information ?"
173000,"when computing the score , is it allowed to use the outcomes of people that are not on the list ?"
173026,"check the output using "" model_all2 - lm ( y ~ x2 x1 , data = df ) "" instead , so with reversed features . what happens ?"
173034,is the observed function noisy or deterministic ?
172943,"sorry , this is not an answer , but i cannot comment since i don't have enough reputation . can i have the data you are using ?"
173076,how many observations do you have ?
173060,related : [ how big is big data ?
173113,"instead of dropping datapoints , would you be interested in a more refined approach called robust regression in which you attach very little weight to outliers ?"
173108,"( 1 ) are you making a distinction between "" jointly independent "" and "" independent "" ?"
173119,could you clarify what you mean by ` n ( 0 . 995 2 . 351d ; 13 . 732 ) and mu = 28 . 813 ` ?
173121,can you list the formula you are using ?
173216,"i suspect the problem may be that the posterior distribution of the hyper-parameters is not very gaussian , in which case the laplace approximation is unlikely to work well . do the results of slice sampling suggest a gaussian is a reasonable assumption ?"
173219,can you explain what the five variables represent ?
173232,""" the prev ( ious ) state is fed back to obtain the next state "" there might lie a deep misconception about markov chains . what is the precise definition you are using ?"
173251,r ^ 2 of spline fit to residuals ?
173178,"this question seems rather broad . if possible , could you be more specific about the kinds of help you seek ?"
173311,why would you want to use an estimate if you know the true value ?
173042,what are you expecting the forecasting ( software ) method to do ?
173355,"there are many , many possibilities here . see discussion at url and probably elsewhere . are your measurements at regular time intervals ( probably not ) ?"
173363,can you share your code ?
173288,""" yet this makes it physically impossible for us to draw two red balls on the second round . "" so what ?"
173381,hint : is $ 1 / 2 = int_0 ^ 1 x dx $ a function of x ?
173404,markl . stone would you consider writing your comments up as a brief answer ?
173409,why are you implementing box-muller yourself / by hand ?
173438,can you include a small snippet of your dataset for understanding it better ?
173415,"in ` chisq . test ( ) ` , have you tried using ` correct = false ` ?"
173477,closely related : url ( showing how to estimate parameters of a distribution based on binned data ) . could you explain how your plot is related to the data table ?
173551,aren't ( univariate ) bayesian credible intervals already plotted along the diagonal ?
173554,whuber : is this really true ?
173588,"there are many tests called the "" tukey test "" ( i could name a handful without even trying ) . what are you testing , and why perform a hypothesis test for it rather than some other form of assessment ( say some diagnostic display , for example ) ?"
173437,can you state what your hypothesis about chinese children is ?
173619,is this self-study ?
173652,can you present a link to a downloadible paper ?
173683,"on an unrelated note , are you a haverford student / alumnus ?"
173679,"in asserting "" $ bigcap_ { 0 leq t infty } $ "" is uncountable you are implicitly assuming the parameter space is uncountable . is that assumption actually made by the sources you are quoting ?"
173697,is this a question from a course or textbook ?
173706,is the formula ` lmer ` or ` lme ` as you indicate ?
173708,it would appear you actually have only * two * predictors : isn't each one always going to be equal to $ 1 $ less than the sum of the other two ?
173728,you are using spark ?
173740,what exactly is the problem you're trying to solve ?
173742,"welcome to cv ! i think your question suffers from a lack of clarity . what do you mean by "" belong in the glm ?"
173792,"are you asking about how to group independent variables based on correlations ( then the nature and even existence of your dependent variable is of no relevance ) , or are you asking about how to build a good regression model and want to group / omit variables specifically for this purpose ?"
173833,what is the question you want to pose to your data ?
173830,matthewdrury uncool to post a possible answer because of the self-study tag ?
173862,how are you setting up the problem and what results are you getting ?
173893,this means $ p 2 . 2 * 10 ^ { -16 } $ and is effectively close to zero ( actually numerically undistinguishable from 0 ) . do you also ask how to interpret such a small p-value ?
173813,i think the second call should not be 'lmer' but 'lme' ?
173933,it is not clear to me what you trying to do . what is your model trying to learn ?
173805,from your current idea of using a distance correlation i presume your variables are univariate ?
173986,"then add the self-study tag . also , do you know * a priori * that the data is normally distributed and you want to find the 95 % quantile of the data or have you estimated the parameters for a normal distribution and want to find the quantile based in the parameters ?"
174006,"since sample skewness and kurtosis are just statistics , it isn't evident what you mean by "" accuracy . "" could you explain what this means in an edit to the question ?"
174044,why the weird 'sqrt ( sd ) ' ?
173712,are you saying you have * nothing * ?
174076,what makes you think the data are paired ?
174099,please clarify . does the failure condition only apply if the roll is not also a botch ?
174112,are you predicting the stock price or the returns on the stock price ( this is equivalent but it matters when you measure forecast accuracy ) ?
174131,"this is a great question . aside from [ is normality testing "" essentially useless "" ?"
174137,this is for a class ?
174154,how are you going to calculate $ ( i-p ) ^ { -1 } $ ?
174182,"are these a series of records over time ( eg , all the transactions at a single atm machine w / timestamps ) ?"
174211,"see also [ clarification on interpreting confidence intervals ] ( url ) , and [ what does a confidence interval ( vs . a credible interval ) actually express ?"
174214,"there is some relevant discussion in the comments ( but no answer ) here : url the only way they differ is in possible assumptions for the error distribution ; ls is essentially assuming a normal error distribution with a pure observation error model . ml is more flexible , including allowing for process error in addition to observation error . is this experimental data , so that you have no error in the counts ?"
174239,moderated mediations are pretty complex ( and there's more than one kind ) . do you understand how this can happen with regular moderation ?
174246,what dimensionality is the data ?
174268,how many classes do you need to classify ?
174260,"is there a type , $ k = k $ ?"
171154,"your function doesn't appear to contain any unknowns . in what sense is there an "" fitting "" going on ?"
174281,"is the issue the 1 : 100 ratio , or is it that there are only 30 observations in one category ( hence overfitting , complete separation and other issues ) ?"
173798,that's an interesting point ! which algorithm / solver are you using ?
174355,"do you mean "" when both the dependent and independent variable are categorical "" ?"
174358,why not ask that as a new question ?
174396,"do you want to add a new objective function to the core glmnet routine , or add a new objective to a cross validation loop to choose $ lambda $ ?"
174333,are you familiar enough with model comparison before you dive into hierarchical models ?
174467,why would you expect for them to be different in continuous case ?
174474,i fail to understand what you want to do : what evaluation are you running ?
174489,is the sample size large ?
174524,can you post the result of ` head ( your_data . frame ) ` ?
174527,"in an svm , only positive $ alpha $ estimates make any contribution to the model predictions . is this what you're after ?"
174543,how many observations do you have in one window ( in case of minutes data and in case of seconds data ) ?
174390,"note that likelihood is a function of the parameters , while the model is attempting to describe the distribution of the data . there's no inconsistency . indeed , consider a logistic regression for binary data , where the fitted proportions range between 0 . 2 and 0 . 475 . the mode of the bernoulli distribution is in each case 0 -- so you're saying that the model should consist entirely of 0 ?"
174556,what about first using some form of multidimensional scaling ( maybe multiple cotrrespondence analysis ) and only then using $ k $ -means in the reconstructed representation space ?
174530,"the scores in the sample data shown , are for individual phones , yes ?"
174476,"if it is nearly constant , do you mean there are minor deviations ?"
174505,""" clearly after n throws of the die , i should estimate p1 as number of 1s rolled over n , and so on up to p6 . "" why is that clear ?"
174374,where are the $ sigma $ 's ?
174709,do you have any ideas as to which it is and why ?
174710,please spell out your acronyms . what is mlp ( multi-layer perceptron ) ?
174724,"what does "" nonparametric dataset "" mean ?"
101130,what is the nature of the non-linearity ?
174279,"how is $ l $ defined , in the integral ?"
174754,are you able to compute the expectation of the product of your two gamma variates ?
174795,how many data points do you have ?
174805,let's start at the beginning . why do you think that $ e [ 8 ] 2e [ t ] e [ x_t ] = 0 $ ?
174500,"note that a game of bingo ends when * someone * bingoes , and admits a maximum of ( permutations of bingo squares for numbers 1 . . n where n size of bingo square ) . the end result is a very lengthy procedure for choosing a winner ( uniformly ?"
174224,"what's "" rf "" ?"
174813,why do you want to assume some parametric form ?
153832,i have a similar though less pronounced dataset where 25-50 % of the values are zero . did you find an answer or a technique ?
174838,"observe that for 10k of your records , you do not have an observed response to compare your predictions to . how does that inform your thinking ?"
174869,"i don't know what is "" better "" . better in what situation ?"
174870,where did you read that ` auto . arima ` tends to overfit ?
174881,what do you mean by find a distribution of residuals ?
174899,are you sure your gradient calculation is correct ?
174906,"eli , welcome ! great question . lots of follow ups . will this model be given "" labeled "" data that identifies when spikes happened ?"
174923,"hints : the $ z $ 's are from a _white noise_ process , and so $ cov ( z_t , z_s ) = 0 $ unless $ t = s $ . so look at each and every one of the $ cov $ thingies that you calculated . is it possible that the subscripts are equal ?"
174844,did you mean ` y_hat - 10 * * fitted ( fit ) ` ?
174960,why would you need a normal approximation ?
174961,you're missing some information in the question ; were you told that $ u_1 $ and $ u_2 $ were independent ?
174976,why 'not meaningful' ?
172734,"do you want to compare all columns ( e . , g x1 vs x2 , x2 vs x3 ) or only compare data to column 1 ( e . g . , x1 vs x2 x1 vs x3 ) ?"
174280,have you looked into the [ anderson-darling goodness of fit test ] ( url ) ?
174859,what metric are you using to assess model quality ?
175021,is it a [ multiclass classification ] ( url ) problem ?
109747,"sebastianraschka : yes , i noticed . it is weird indeed . however , notice that the first of your own ( non-scikit ) lda plots also shows non-zero correlation and hence something must be wrong with it as well . did you centre the data ?"
175036,"if your series is a random walk , perhaps with drift , the model is really simple . there is nothing to fit , except to estimate the drift coefficient if it is non-zero . the forecast will be a straight line just as you said . the problem of non-stationarity is actual if you were to estimate a model more complicated than an arima ( 0 , 1 , 0 ) , perhaps with drift . but what is your ultimate intention ?"
175066,"i did not understand in what way you are comparing "" overlapping samples "" ?"
175085,describe your data . what's sample size ?
175077,more sense in terms of modelling some specific real-life phenomenon ?
172723,i could always be wrong about that : - ) . have you considered tweeting your post or otherwise drawing attention to it on social media ?
174908,could you please explain your code ?
175137,"what do you mean by "" or this information is only conveyed by scores . "" ?"
175153,do you know the probability $ p ( a cup b cup c ) $ ?
175169,could you define what is differential item functioning ( or add a link to a definition ) ?
175189,self study ; ) ?
175223,does that mean you don't have the individual data for the ages ?
175125,"i have no clear idea what you intend by "" this would require some how taking previous regression estimates and incorporating them into a larger feature space "" . are you simply trying to update parameter estimates as predictors are added ?"
175245,could you elaborate a little more on your problem ?
175255,did you have the curiosity to check what is the [ delta method entry ] ( url ) on wikipedia ?
175303,which kind of model are you planning to use ?
175341,how many rows and how many values per row ?
136303,"your function $ j $ get parameter $ { theta } $ , so where this value in function ( i think in left side you write in matrix form and in right in scalar ) ?"
175413,isn't this a duplicate of the linked question ?
175417,"if the model is to be used for forecasting , why are you interested in parsimony rather than simply using ridge regression and using information from all the predictors ?"
175373,have you calculated the cramer-rao bound for this ?
174248,"could you explain what you mean by "" evaluate the predicted values "" and "" calculating the error from the new data "" ?"
175350,"what's "" strong independence "" ?"
175509,"can you clarify what do you currently do in the resampling step , e . g . , add pseudocode of your algorithm ?"
175382,what is the favor . . . ?
175600,what would it mean exactly to say the height of students in a sample was normally distributed ( or not normally distributed ) ?
175621,can you present your confusion & cost matrices ?
85576,"i believe you have an error in your question ( since , specifics of the question aside ) one would expect the denominator to be the square root of a chi-square on its df ( $ sqrt { z ^ 2 / n } $ ) . by taking $ sqrt z $ you have a 50 % chance of taking the square root of a negative number ; i doubt that's the intent . is this for some subject ?"
175553,what are the samples going to be used for ?
175678,can you tell e . g . between '3' & '3 or more' in the first experiment ?
174106,are you saying you want lasso ?
175682,"your response categories are * ordered * . you should be using ordinal logistic regression , not multinomial lr . then use the model formula to get the predicted probabilities . you can see an example in my question here : [ how do you predict a response category given an ordinal logistic regression model ?"
175758,how would the pooling work ?
175770,i'm curious to see how a model with 0 . 97 adjusted r-squared gives you such a poor predictive capability . what happens if you try to predict the training dataset ?
175778,have you heard of the ( strong ) law of large numbers ?
175806,do you also have the ordering constraint on your $ p $ 's ?
174460,jeffrey are there any parameters behind the last day return of the market in model 3 ?
175883,why do you want to do this ?
175880,you're probably trying to see whether the ratings downgrade has a new information that impacts the stock price . does this mean that the ratings agency has access to some information that is not already known to investors ?
175886,is $ t $ continuous or discrete ?
175760,"do you want a model relating perceived support & environmental behaviors , or do you only need to test if they are related ?"
79168,hello growinman ! have you seen my answer to this question ?
175899,direct convolution ?
175905,i'm curious why this question is tagged as 'random-effects-model' ?
175914,"sorry , i just deleted the comment . can you double-check your last equation ?"
175956,was the model fit to proportions ?
175941,"could you elaborate on what you mean by "" noisy data "" ?"
176074,"what do you mean by "" the "" correlation coefficient , given that ( by definition ) there is more than one regressor variable in any multiple regression ?"
176081,could you provide more details on your simulation design ?
176072,"not sufficient information in there ! what are those four opttions 1 , 2 , 3 , 4 for instance ?"
176099,one should not rely only on the pre-analytic heuristic devices when choosing the number of factors to extract . reproduction of correlations ( how much better is it when you extract 2 factors instead of 1 ?
176123,are you trying to say that sigma_approx is an estimated covariance based on n samples of a p dimensional normal ?
176124,"could you please add some information about the number of participants . is many 20 , 50 , 100 , or even more ?"
176135,many ( most ?
148649,"maybe the reviewer is asking for the usual frequentist p-values , independently of your bayesian model ?"
176199,do you know all $ r_1 $ s before any bet or know $ r_1 $ right before your each bet and after your previous bets ?
176205,"since you ask * how will i be able to obtain this equation while accounting for other cvs i . e . ect2 , ect3 and ect4 . * , does the name of structural var ( svar ) ring a bell ?"
176237,what precisely is your question ?
176244,"could you use a logistic regression model with squared terms , e . g . , with age , age squared , income , and income squared ( and possibly interaction terms too if appropriate ) ?"
176257,your error surface aside : ooc : in what sense is this a genetic algorithm ?
164230,how is $ mu $ related to $ r $ and $ p $ in this perameterization ?
176371,what is your goal for the final model ?
176358,what is the goal of your analysis ?
175380,this is hard to follow . can you make this more concrete ?
176408,i don't have the book . were they discussing the [ box-cox family of transformations ] ( url ) ?
176477,"have you checked pfaff "" analysis of integrated and cointegrated time series "" ( 2008 ) ?"
176373,"could you provide a larger version of the figure , or would that violate copyright ?"
176436,how many samples do you have ?
176503,""" * my question is how come the pdf value is not "" zero "" or very very small since the distribution is continuous ?"
175968,your notation is a bit confusing to me . are $ x $ and $ y $ vectors ?
175975,"slightly better , but i still can't understand it . what are the sum of squares ?"
176611,what's $ x $ in your question ?
176599,possible duplicate of [ why does the lasso provide variable selection ?
176627,why would you like a class specific gini metric ?
176655,johnsonjason did you ( or someone at the firm ) pick these prices at random or are they determined by market forces ?
176670,hint : $ var ( x ) = e ( x ^ 2 ) -e ( x ) ^ 2 $ . you have $ x = s ^ 2 $ . what happens if you substitute ?
176679,"can you check the first several posts under "" related "" in the sidebar -- and clarify in your question the ways in which your question is different from those questions or is not answered by any of the answers to them ?"
176691,"let me try again . what statistic does it say to use , * exactly * ?"
99710,is there some reason you have to use just one chain ?
176715,lasso classifier is a ready solution that combines feature selection ( in cases there are too many features or collinearity present ) with classification ( see r's ` glmnet ` package e . g ) . why would you think about filtering features in lasso and then carrying these results over to logistic classifier at all ?
176740,what kind of a model you have ?
176768,which bit don't you understand ?
176751,"are you asking for a decision rule regarding the number of clusters to retain from k-means or for approaches to understanding what the clusters "" mean ?"
176671,"two years have passed , i'm curious to know where you're at on your road to ml ?"
176786,is your customer really this statistically literate ?
176781,i've seen this as a textbook question . is this for a class ?
176790,where do the two datasets come from and how are they similar or different ?
176806,could you explain why you want to make your sample distribution match the population distribution and clarify what operations on the sample data you would permit in order to make this match come about ?
176888,could you clarify your question ?
176969,"no , it isn't a vertical shift . if you use the equation i list at the linked thread you will get a different regression line . it may help to read my answer here : [ what does the formula y ~ x 0 in r actually calculate ?"
176985,"does the relationship $ f_ { x , y } ( x , y ) = g_1 ( x ) g_2 ( y ) $ hold for _all_ $ x $ and $ y $ or just at a specific $ ( x , y ) $ ?"
176930,"1 . can you clarify whether the data are counts , or continuous observations with known standard deviations ( or perhaps something else ) ?"
176988,"when you say sas hangs , do you get an error message in the log or does it just take "" forever "" to run ?"
120584,"the way you capitalize "" poor man's asymptotics "" makes me think i must be missing knowledge of a reference ( or possibly have seen it but forgotten it , which amounts to much the same thing ) ; either an actual book or paper , or possibly even just a cultural reference . i know of "" poor man's data augmentation "" ( tanner and wei ) , but i don't think this is connected to what you're getting at . what am i missing ?"
177016,"if i look at your edited code , the sd column are all different , ie . only one observation for the mean and median to compare . i meant that providing a reproducible example so that there are multiple sd values that are same , if there is only a single observation to return na ?"
177163,"do you mean what is the distribution of the sum of discrete uniforms $ [ 1 , 4 ] [ 1 , 6 ] [ 1 , 8 ] [ 1 , 12 ] [ 1 , 20 ] $ ?"
177188,"usually for a meta-analysis , you need an effect size , and a standard error ( or variance ) for each sample being pooled . sometimes you get this from the study , sometimes the paper provides information that lets you calculate it . usually in a meta-analysis you are combining results from studies that compare two groups . what information do you have ?"
177197,at what point are you stuck ?
177203,why do you think something is wrong ?
177220,"on multithreaded , have u tried liblinear instead ?"
177221,"may we presume "" $ k $ "" is a synonym for "" $ t $ "" ?"
177227,"how do you define the mutual information metric between two "" vectors of 100 . 000 observations "" ?"
176785,"at a bare minimum , what do the non-parametric 95 % -cis look like ( using the sign test ) ?"
177241,could you be a little more specific on how you observe the data ?
177253,this model would not take the location ( e . g . proximity to the land ) into account . or is it also going to be an environmental variable ?
177265,"try defining what a systematic difference is for you . for example , are different variances a systematic difference for you ?"
177286,this code is suboptimal both for the estimation you want to do as well as the presentation you want to do . for the later just see this thread : [ how to make a great r reproducible example ?
177337,was the first order term significant before adding in the interactions ?
177340,what's the temporal structure of your data ?
177339,"it might help to ( 1 ) define "" feature transformation "" - sometimes it seems to be used narrowly to refer to principal component analysis & related data reduction techniques , & sometimes to mean feature engineering / creation / construction ; ( 2 ) explain what kind of situations you're imagining - what about the data * can * be taken for granted ?"
177355,* * what * * differences in geolocation ?
175996,have you looked at the cross correlation function ccf ?
177453,"couldn't you take a stratified random sample , but sample with certainty from the the smaller classes ?"
157136,"these terms mean different things in different contexts . statistics has developed as its own discipline but also within other disciplines ( think econometrics , psychometerics , etc . ) . as a consequence there are many examples of the same name that has been used for different things and the same thing that has been given different names . can you give us the context within which you found those terms ?"
177462,this isn't answerable without more context . can you perhaps find a short quote from this textbook that uses both notations and edit it into your question ?
177478,this thread on [ is pca followed by a rotation ( e . g . varimax ) still pca ?
177507,what do the weights represent ?
177520,what would you like to illustrate with a quantity such as the median survival time in this case ?
177570,how would we know how to interpret this if you don't ?
177532,"no . . . varimax maximizes the sum of the squared * variances * of the loadings , so its trying to make them as * unequal * as possible . also , why would you want to equalize the components ?"
177616,"what you have described is not a random variable , it sounds deterministic , so why do you want to fit a distribution ?"
177633,"can you define in your question what you mean by "" factor "" ?"
177613,what does your last sentence mean ?
177582,"you could always recode your data into two categories : "" much "" and "" little "" and use a bernoulli model . . . you can do things like this , but why would you like to do so ?"
64880,nick right : but what * are * such graphics actually called ?
177688,what exactly is unclear for you in [ the change of variable method ] ( url ) ?
177564,can you link to any of the resources you are referring to ?
177749,"you did not define your notations , i presume that $ f_ { jj } ^ { ( n ) } $ is the probability to first return to $ j $ in $ n $ steps . in which case i would call the state $ e_j $ _recurrent_ . what are the roles of $ f_ { jj } $ and of $ p_ { jj } ^ { ( n ) } $ ?"
177792,your question is not clear - could you elaborate a little bit more ?
177846,are the different blocks assumed to be independent ?
177848,is a single measurement at time moment $ t $ sufficient to infer the state of the system - healthy or faulty ?
177870,can you motivate why you think the products are natural things to equate across the pairs ?
177889,it's not clear to me what you're asking . is it obvious to you that the left hand side and right hand side are in fact equal ?
177903,there's a lot of information at the link that can help you interpret olr models . can you be more specific about what you need to know ?
177642,can you give some more information about your dataset why you assume that all months have 28days and a year 336days ?
177997,* why * do you need the constraints ?
178019,"if this is a self-study question , please add the tag . are you aware that $ mathbb { e } [ overline x ] = mathbb { e } [ x_1 ] $ ?"
178036,have you heard of non-parametric density estimators like kernel estimators ?
178119,"whuber if its empirical distribution and we do not know nothing more about it , then it seems to be available solution - but maybe op can edit for more details ?"
178149,"why do you want to "" fix "" the skewness ?"
178166,"just to maybe help you answer your own questions : what does the 95 % interval represent here , and what is the null hypothesis that you test ?"
178197,what is $ mathcal { l } ^ 2 $ ?
178195,i'm not sure i understand the question . what else is there to do ?
178110,i must admit that i don't really understand your question . are you simply asking how to compute $ g $ that maximized the trace from equation ( 5 ) ?
176824,this sound like homework ?
178267,have you done a unit root test ?
178274,there seems to be no overlap between your variables & your model . does the thief know when the apples are being monitored ?
178343,is there some reason why you do not want to use logistic regression ?
178370,edit your question and tell us the assumptions of your ar model . usually there's an iid error term . does it have positive variance ?
178371,you are using an improper accuracy scoring rule which brings a lot of randomness to the evaluation . this is also a symptom of having training and test sets that are too small . how many independent observations are in each ?
178384,please review the [ wiki ] ( url ) for the ` [ analysis ] ` tag . can you provide a sample of your data ?
178401,"what exactly is this "" something which is already random "" ?"
178420,why would you want to do this ?
178388,"i am that person : - ) but please note that , first , i have already some time ago updated my answer to remove the confusion , and , second , that whole thread is closed as a duplicate of another thread : url did you look there ?"
178431,"are y1 & y2 measured in the same units ( eg , cm ) ?"
178492,"do you mind citing where a newton-raphson algorithm is referred to as "" gradient descent level ii "" ?"
178537,"did tou try result - lme ( activity ~ site , data = table1 , random = ~ site individual ) i . e a random effect on the site variable ?"
177233,could you give some context---how do this equation arise ?
178682,what is your exact research question ?
178730,are your estimates $ hat f $ and $ hat g $ based on independent datasets ?
178609,"your description is missing the connection between $ s ( t ) $ , $ n ( t ) $ and the $ x_i $ 's . can you please include it ?"
178738,but why do you want to use logistic regression to calculate probabilities in the first place ?
178752,are your time series only 21-observations long ?
178788,"i can't identify a clear question here . "" confirm my understanding "" followed by an extensive list of things to check doesn't seem to fit the question-and-answer format ( and in particular sounds likely to lead to the [ non-answer ] ( url ) answer "" yes , that's correct "" ) . "" i have no idea how to x "" isn't a question either . "" put me on a path "" is basically "" try to guess how to teach me x "" . is it possible for you to rephrase this into one or more question posts that are actually questions-with-answers ?"
178651,"the notation $ { y x } $ is not at all standard , can you provide a reference or a definition ?"
178888,could you give a small example ?
178887,"it's not clear what your data example means . for instance , are the words "" school student . . . and so on "" meant to be data entries followed by a bunch of numbers ?"
178920,i'll try a simple argument : the formulas ( 16 ) and ( 17 ) in the paper cannot match unless $ gamma'_ { ip } = 0 $ because otherwise ( 17 ) involves $ f_ { t-p-1 } $ ( coming from $ delta f_ { t-p } $ ) while ( 16 ) does not involve $ f_ { t-p-1 } $ . does that make sense ?
178928,"do you want to compare on * both * ` var2 ` & ` var1 ` together , or do you want to stratify on ` var1 ` & run 2 parallel tests on ` var2 ` ?"
178905,"could you name precisely what tests are you considering , and give relevant references ?"
178954,"i'm not sure whether this question is about choosing a cutoff for class assignment on the basis of model-generated probabilities , or if you believe the splits in your decision tree are sub-optimal . could you please clarify this ?"
178968,does [ this one ] ( url ) ( the reference to r doesn't alter the explanation ) get at what you want ?
179014,"given the name of you outcome variable , ` mean . proportion . disease ` , and the beta-distribution tag , i assume that this variable is measured on a 0-1 scale . so may i ask why you are using logit here ?"
178135,must it be an unconstrained optimization problem ?
176736,any chance you can post your sample data plot ?
179067,did you try googling syllabi on the subjects ?
179109,it it possible that your variables simply aren't strongly related to the response ?
179132,"in addition to the above , i have now edited your question to make it more clear . in particular , i edited the title which was outright misleading . can you please take a careful look at my edits and see if they indeed represent what you want to ask ?"
179108,"the complement of ` fatal / severe ` is anything else . so there should have been $ 4 $ crashes on ` principal ` road classes total , or there is a problem with your data . regarding * * 1 * * , are the ` degree of injury ` classifications ordered ( ie ` fatal / severe ` ` visible injury ` ` pain ` ` property damage ` ) ?"
179138,thanks thelatemail . just a clarification . i understand ks test explains whether two samples are significantly different or not . can i give probabilistic distributions values to the ks test ?
179172,could you provide a proper reference to the paper you quote ?
179181,are you familiar with the [ general linear model ] ( url ) ?
179195,are you sure the time subscript for $ y $ is different from the time subscript for $ x $ ?
179210,for what application do you want it ?
179230,do you have population values ?
179261,in what way is your data hierarchical ?
179273,what timescales will the median be calculated on ?
179105,are both x and d ( in 1 ) continuous or they are in fact discrete and you treat them as continuous ?
179283,what is $ c ^ 1 $ ?
179220,"how are the ss calculated in these two cases . typically , there is a "" corrected total "" which is used when you have the intercept . i don't know what matlab does . what happens when you calculate the ss manually / naively ( & equally ) for both models ?"
179394,"( leaving aside my concerns with how this would come up in mcmc ) -- since you don't give any data , could you show the ways in which laplace was inadequate ?"
179412,"no , i'm afraid it doesn't . what is $ x $ ?"
179431,are the participants who started initially different from those who started in a later month ?
179413,your approach is bizarre . why are you recycling $ x_i $ for each coordinate of $ phi $ ?
178857,"if i'm reading the question right , then the statistical part ( "" does b's last claim reflect the working bayesian's position ?"
179467,before you do all that you should ask yourself : 1 ) how important is it really that my error be normal in this context ?
179137,"in view of the two conflicting answers , it's apparent that you should justify your choice of null & alternative hypotheses with reference to the context . where does the burden of proof lie ?"
179485,could you maybe post the picture of the plot ?
179455,"no precise reference here or url . no explanation of the parameterisation ; we need to see a density , distribution or quantile function formula . you seem to be referring to some $ xi $ and $ sigma $ ; what is the third parameter ?"
179493,do you get negative weights with ada-boost ?
179476,"why not just create a new factor using ` interaction ( factor1 , factor2 ) ` ?"
179580,"some essential information seems to be missing . exactly what "" sequence "" are you referring to ?"
179606,"please clarify : did you run 16 correlations ( with 10 to 300 data points each ) , or just 1 ( with 16 data points ) ?"
179611,"i also wonder which textbooks say things like * for ridge regression , it offers better predictability in general * ( in contrast to lasso , i understand , not in contrast to unrestricted regression ) . perhaps * general * is not that general in their use . also , how much interpretability are regularization methods supposed to yield ?"
179641,"on what basis do you assert significance when you say : "" * see that the second one is significantly different from the others * "" ?"
179673,clear heteroskedasticity and skewness in first plot ; possible nonlinear relationship . what are the data ?
179678,you have a density for $ s / sigma ^ 2 $ . . . can you identify a posterior density for $ sigma ^ 2 $ ?
179683,is it as simple as mapping the * average * response time over the 32 trials for each condition ?
179558,"what do "" ml techniques "" stand for : maximum likelihood or machine learning , or yet something else ?"
179701,"proof-reading code is generally off-topic here . but out of curiosity , * how * does your code fail ?"
179622,please restate your question . are these really independent variables ?
179732,"you also note that , in the presence of a significant interactions , that the main effects no longer matter since the model is now evaluating the predictors in the 2-d interaction space . if * y-hat * -- the predictions -- are unaffected by centering , what's your concern ?"
179715,"what is a "" null test "" and how exactly did you compute the p-values ?"
179706,do you know what the matrix $ x $ is in this situation ?
179798,"bootstrapping does not solve any problems with distribution of your data - it is a method for estimating confidence intervals , errors etc . for different methods . you would use bootstrap the same way with pearson or spearman correlation . what do you need bootstrap for ?"
179819,"what exactly do you mean by "" this "" ?"
179833,"why are you taking note of the fact that ` 33559 ` occurred only once , eg ?"
179845,"when you say your "" r ^ 2 statistic is constant over all the values . "" what values are you referring to ?"
179882,tldr ; could this be possibly related : url ?
179885,why not regression ?
179418,"usually , $ m $ is the slope & $ b $ is the y-intercept . also , you seem to have the same variable on both sides of your equation . do you have a $ y = f ( x ) $ ?"
179924,what is the actual output when 26 is expected ?
179934,are you sure that it should not be the other way round ?
179799,what kind of differences are of interest ?
179956,"what do you mean by "" bad "" results ?"
179959,"xian , i am wondering why you tagged this q with [ self-study ] ?"
179877,trying to understand your actual question ; are you asking whether arfima is suitable for predicting queue dynamics from residence time distribution ?
180012,you mean binary classification problem ?
88865,did you use * * the same scaling * * for both training and testing set ( e . g . did you use the same coefficients for training and testing ) ?
180078,"what do you mean by "" analyze "" ?"
180092,""" * the variance of a binomial parameter is always the same for a given success rate e . g . , rate of coin landing heads . * "" -- can you explain how you get this conclusion ?"
180075,correct ! ( why can't i put just that word ?
179947,start with forming a question . what interests you ?
180129,"1 . you mention uncertainties on inputs , but i note that some of the models you mention are not suitable for cases with uncertainties on inputs ( e . g . regression , at least the usual kind , is one example ) . 2 . are you talking about a ) the uncertainty because the parameter estimates are not their true values , b ) the noise in the process that relates known inputs to observed outputs , c ) the uncertainty / error introduced by using model $ m $ when the actual process is model $ m' $ , or d ) something else ?"
180138,"since you are analyzing mean values , do you also have the * n * or sample sizes for each as well as their standard deviations ?"
179994,how much data do you have ?
180181,"can you clarify what you mean by "" a stochastic process is a generator of iid sequences "" ?"
180222,can you clarify what it is about the ` log ( drivers * 1000 ) ` that is confusing to you ?
180193,"it seems clear that any useful measure will and indeed must be calculatable directly from the transition probabilities as these are what define a particular class of chains . also , there will be some loss of information in that in general no scalar measure will be reversible to give a matrix uniquely . but the variance of the probabilities is a first candidate as the variance for $ a $ is zero and the variance for the other two is much larger . it is naturally an inverse measure . but what do you want this measure for ?"
180256,"sorry for the pedantry , but , implicitly , $ x : omega to [ 0 , 1 ] $ , then ?"
180258,don't do what you're doing . what are you actually trying to achieve ?
179492,have you tried ` etregress / treatreg ` ?
180317,how many unique pages are there on this website ?
180325,could you explain * why * you are comparing these variances ?
180302,the ` education ` column ?
180377,"can i rephrase your question as "" should i worry if the subjects with repeated measures differ systematically from the subjects with a single measure ?"
180363,could you actually include the two commands and such that you used to estimate these models in stata in the question ?
180400,interesting analysis . what * is * the dv -- unit sales ?
180419,what exactly is the hypothesis you want to test ?
180264,is it possible that the true model is a combination of both of your hypotheses ?
172728,how many scholarship type you consider and how students you have ?
180294,"it looks like you have 60 , 000 records . is this correct or is it potentially a massively larger file ?"
180513,what is the point of having both $ sigma $ and $ tau $ as hyperparameters ?
14947,have you already decided against using t-tests ?
179990,"think about what you're asking in an intuitive sense . the sigma algebra generated by some rvs is like the "" information "" the rvs carry . does information / knowledge about $ z_0 , ldots , z_n $ always allow you to reconstruct $ v_1 , ldots , v_n $ ?"
180582,would this not be some kind of [ ` empirical bayes ` ] ( url ) where some or the data are used to determine the prior distribution ?
180593,have you tried fitting a simple logistic regression to it and visualizing the sigmoid ?
180597,"the notation "" $ mathbb { p } ( x_1 in a_1 , ldots , x_n in a_n ) $ "" is a shorthand for the event $ ( x_1 , ldots , x_n ) in a_1 times cdots times a_n $ : that is , each $ x_i $ simultaneously lies in the corresponding $ a_i $ for all $ i = 1 , ldots , n $ . how the probability is actually "" evaluated "" depends on the form in which it is available to you , such as a probability function , a probability density , a ( multivariate ) characteristic function , or something else . in light of this , could you please edit the question to clarify what kind of answer it's looking for ?"
180804,few questions come to mind : ( 1 ) is everybody censored at the end of the 5 years period ?
180285,"in concluding "" do not reject null hypothesis ; series is not stationary "" for the second test , your reading of the results as "" not stationary "" would hold even when the observed t-value was negative and near zero . shouldn't the comparison be to the * absolute * values of the t-statistics ?"
180867,is there any reason you couldn't do a chi-squared test ?
180904,"rather than using the ` standardise ` function , which doesn't work on all the estimation functions , what happens if you rescale the input variables manually ?"
180766,"how would you count the number of draws if you ended up emptying the run and still never observed a "" blue "" ?"
180914,did you ever find an answer to this ?
180842,"the problem is not the skewed data , the problem is that your model is either not identified or is only just identified . you have two factors , one factor has three indicators , two of which are shared with the other factor . that's a bit of a strange model . can you post your results ?"
180745,what answer would you want given your example ?
180992,define a new variable equal to lagged flow and use it as an input . ( also trim the variables so that they have equal length . ) is there a problem with that ?
180518,"still doesn't look good . . . what is the conditional mean part of your model , could you include it in your original post by editing it ?"
180981,` elec ` is highlighted - is it some sort of a keyword in r ?
181058,see url but why are the counts all multiples of ten ?
181106,"umm . . . the parameters will be exactly what you stated : $ alpha_t , beta , x_0 $ . it's hard to guess what you're looking for in an answer . could you expand on the question a little ?"
181139,"using the notation of the thread you reference , it would seem you are requiring that when $ x = 0 $ , $ 0 = mathbb { e } ( y ) = a exp ( bx ) c = a c $ . so why not use the solution there to fit the model $ mathbb { e } ( y ) = a exp ( bx ) -a $ ?"
181001,"the sum of two functions is well defined ( as is the difference ) ; if you say "" the sum of $ g_x $ and $ g_y $ "" you're simply saying "" $ g_x g_y $ "" in words . what is it you actually mean to ask ?"
181166,"what do you mean by ' "" clustering "" banks' ?"
181168,can you provide more information ?
181171,"there is more than one meaning of "" discrete normal distribution . "" rounding the continuous one [ is one possible definition ] ( url ) . another approach obtains a normal-like distribution supported on the integers by [ maximizing the entropy given the mean and variance ] ( url ) . is this what you mean by "" discrete normal "" ?"
180779,self-study ?
181196,i expect there's a very good reason why you're having trouble finding that exact case . is there any reason you really need that in closed form ?
181148,""" * taking the logarithm of the kernel density estimate seems suboptimal * "" -- what are you trying to optimize , exactly ?"
181230,"firstly , ` chisq . test ( a , b ) ` doesn't do what you think it does ( did you look at the degrees of freedom ?"
181238,what's r & r analysis ?
181227,what do you expect this function to do with the information that it's skewed ?
181255,"that claim seems reasonable but since it's been some years that i studied these things , i don't want to mislead you . do you understand why in the present case , this is not a ump test though ?"
181257,how long of a time series are you working with ?
181155,"is it true that there are many possible ellipses that are centered at the origin ( where x1 & x2 intersect ) , & make contact with the far ends of x1 & x2 ?"
181267,what kind of data do you have ?
181278,can you tell us where and why you get stuck in the r programming ?
181313,"what distinctions , exactly , are you making between "" credible , "" "" correlated , "" and "" significant "" ?"
181333,um . . what's a baci ?
181339,"this is a nicely put-together question . just a quick note to complement frank harrell's answer below : how many of your records show an 'event' ( e . g . , death ) ?"
181445,some clarification would be helpful . i've assumed that the 10 games are same in each dataset . why aren't you interested in a ranking based on the total popularity of the games ?
181456,do you know the neyman factorization theorem ?
132652,why would you like to figure out which distribution fits your data best ?
181496,"of course this data is not stationary , what is the periodicity of data ?"
181516,predicting * what * aspect of the distribution of volume ?
181588,it's quite likely that you are doing nothing wrong and that the data is sufficiently diffuse so as not to permit a more accurate analysis . describe your target variable . what are the features like ?
181578,what is the problem with glm and formula for you ?
181634,note that auc gives the same information as concordance . see [ this page ] ( url ) for example . could you say a bit more about the purpose of your modeling ?
181642,"could you say more about why you expect the _p_-values to take a uniform distribution , and how the range of the expected uniform distribution is determined ?"
181676,is your 5 ( factor analysis ) efa or cfa ?
181712,"it is not whether the correlation is estimated or known . if $ x_i sim gamma ( t_i , lambda_i ) , i = 1 , 2 $ and $ rho $ is given , we cannot say _which_ joint density $ f_ { x_1 , x_2 } ( x_1 , x_2 ) $ we are working with ; there are _numerous_ possible joint densities that could have produced these correlated gamma random variables . _which_ one do you want to simulate ?"
181785,why would you expect the residuals to be normal ?
181787,"could you explain what you mean by "" something special "" ?"
181791,do you know if $ x $ and $ y $ are independent random variables ?
181818,are you asking about * causal * dependence ?
32133,what is $ f $ ?
181872,possible duplicate of [ when to use the wilcoxon rank-sum test instead of the unpaired t-test ?
181958,what do you know about the dgm ( data generating mechanism ) for these features ?
181985,are you simply trying to assess how different your data is from the reference ?
181992,how could the time-varying measurement have any effect on outcome if outcome does not vary with time ?
181884,variance reduction methods ( eg control variates ) typically require a relationship with the underlying random variable not its expectation . could you give the exact problem you are trying to solve ( namely the constraint equation ) . . are f & g invertible ?
182033,what does $ chi ^ 2 $ stand for ?
181935,""" * the data does not follow a gaussian distribution , so i know that i have to use a non-parametric repeated measure test * "" -- this does not automatically follow ( one might instead make a different parametric assumption , for example ) . when you say "" to avoid groups variability . . . "" it's a little unclear why it would be necessary to do this ( or to be honest which 'groups' those are ) . if you could be more explicit about what you did and why that might help . ( note that it is not the marginal distribution of the response that is assumed to be gaussian ; what did you assess and how did you assess it ?"
182096,why not a [ grouped bar chart ] ( url ) ?
182124,is that time series data ?
182133,"are you after a sampling distribution of an * estimator * for $ mu $ or are you taking a * bayesian * approach ( in which case , where's your prior ?"
182136,what's your purpose for doing this ?
182131,"it is hard to tell what you are asking . what "" difference "" do you seek to explain ?"
182148,"robust regression is ( arguably ) intended to make outlier identification unnecessary , or equivalently to allow that in its wake . the practice is a little more complicated as flavours of robust regression work in slightly or even very different ways . we need to see your data but it sounds like a very well-behaved dataset so that you are likely to be disappointed in your search for outliers . but there are many threads here on outliers : did you read around before posting ?"
180647,"there appears to be insufficient information : what are 'sites' and what is being classified ( if 'an equal number of normal vs . ill' samples are collected from each site ) . the latter seems to misconstrue 'balance' , e . g . if a certain 'site' has a greater illness / normal ratio , this gets misrepresented according to the explanation above ( and that would be the largest , and ignored , site effect , no ?"
182151,( 1 ) so for some treatments you've discarded * * one quarter * * of your observations just because they were higher or lower than you thought they should be compared to the other observations for that treatment ?
182172,"don't you actually want to find $ e ( y_ { t 1 } y_1 , y_2 , . . . , y_t ) $ ?"
182177,"i don't know if there's a "" best "" choice for picking a certain point but , intuitively , they should be the same for both metrics : race and lap duration . i argue for the beginning of the race for race duration and the beginning of the lap for lap duration . i would also like to note information that could be incorporated beyond "" no extra measurements . "" for instance , * track * constitutes an important factor that should condition any eventual answer . you also mention "" multiple drivers . "" is it possible to identify them in your data as a driver skill factor ( individual differences in concentration ) ?"
182209,"because "" compatible "" is vague and has no generally accepted statistical meaning , could you expand on what * you * mean by your uses of this word ?"
182212,"if you used the formula $ z = frac { x - text { mean } } { text { sd } } $ then any values below the mean will have a negative z-score and any above the mean will have a positive z-score . as it is currently written , the question is quite unclear . when you say "" explain how this still works "" , what does "" this "" mean ?"
182213,"_without_ replacement , the number of draws cannot exceed $ max { b , w } 1 $ , no ?"
181951,your understanding is wrong : see e . g . [ what is the meaning of p values and t values in statistical tests ?
182026,i don't know spss but is the method you're using unsupervised ?
182229,will you always have the same amount of data in every distribution to compare to the ideal ?
182245,whuber can you give a citation for a decent intro text or two about good ways to perform sequential tests ?
182183,can you say more about the nature of your response variable & how it varies between 0 & 1 ?
182316,"seen better , seen much worse . judging these plots is a dark and subjective art . i am a fan of residual diagnostics but , consistently with that , i believe , i stress that getting the functional form right is more important than matching error assumptions exactly , which you will never manage . the main messages i pick up from the plot are that the overall shape looks about right , but i see two big clumps and one smaller one , so does that match anything we should worry about ?"
182232,what is your actual objective ?
182293,could you write down an expression for the ellipse ?
182395,"those two regression lines would have different slopes so you would have two different models , with two different slopes - could you clarify your question ?"
182400,"in their absence , why not develop a defensible heuristic of your own ?"
182410,is this a question about statsitics / ml ?
182417,"what exactly do you want to do , estimate a regression like $ c = beta_0 beta_1 f $ where $ c $ is computing time and $ f $ is fitness ?"
168687,"i'm having trouble following the new paragraph because classification and hypothesis testing differ in aims and approach . could you explain what "" null hypothesis "" is being evaluated in this procedure ?"
182435,why are you so confident 3622589 is incorrect ?
182452,"i am puzzled why you seem puzzled here . people with similar scores will tend to be put in the same cluster , and all else is fine detail . why is this surprising or disappointing ?"
182472,what are you assuming ?
182507,"when you say "" length , "" i think "" distance . "" are these values distances ( in the sense that it is nonnegative , satisfies the triangle inequality and d ( x , x ) = 0 ) ?"
182509,"you're welcome : ) i think that should be all right , it is just an threshold . try an alternative cv method and check if you get at similar result . here's an example of how to use random forest and some diagnostics . 42 real testing ?"
182551,"two questions . first , is the state space finite ?"
182552,"i will admit to being confused by this data . it might help to provide more information about what is being rated , e . g . , is it really a * classification * into one of 6 types or is it a scale of some kind ?"
182592,"where bias may not be small ( as in small samples ) , i'd really tend to look for something more like minimum mean square error . what's the point in caring that your estimate could be wrong on average , when in fact your alternative estimate could be much more wrong because it's got a high variance ?"
182662,could you describe what you mean a bit more ?
182478,"what do the words "" gaussian "" and "" central limit theorem "" have to do with this particular problem ?"
182699,why would you need references ?
182564,how is your data distributed ?
182745,"this is a pretty specific methodological question that lacks a specific answer . it would help our understanding if you elaborated a bit more on what you are trying to do with this analysis , e . g . , why would you want to do a factor analysis of this data in the first place ?"
182778,pegah but what if some other hyper parameter choices are better ?
182824,i'm not sure that i understand what you are doing . do you have 2 or more treatments on each group ( pre and post-op ) ?
182842,"if the items in your sum are all positive , how are you getting negative values ?"
182793,"what do you mean by "" uniformly distributed over j space "" ?"
182881,"to me it looks like you've been asking variations of this question since last spring . assuming that you have a standard data matrix with features ( fields ) in the columns and observations in the rows and that you're interest is in finding similarities between fields , how then does this become a cluster analysis ?"
182890,"how is the production code "" pretending it's boolean "" ?"
182411,"can you put the details in your question rather than in comments please . what is "" guarantee each data point to within 5 % "" intended to convey ?"
182908,do you have some distribution for the pixel intensity assuming a known location for the point object ?
182905,i wouldn't use the r for [ model selection ] ( url ) . also for clarification and a better understanding : what's the relation of interest that you want to analyse statistically ?
182926,can you clarify what it is about the output you don't understand ?
182962,are $ x $ and $ y $ independent ?
182936,"i understand where you are going with this , but i think to make it clearer , what are you calculating the expected value of under the frequentist paradigm ?"
182988,""" * i'm assuming that this is how i would plot for "" skedasticity "" ( sorry if i'm using the wrong term there ) . * "" . . . . what were your trying to achieve in plain english ?"
183037,the cell counts most likely do not meet assumptions of normality . they will probably be poisson or quasi-poisson distributed . how are you determining the assumption is met ?
183138,"i don't understand your extra point . the question clearly states interest in what is above or below prediction . the precise scale of residuals is secondary and even at best 2 and -2 don't mark any kind of formal confidence limits , if that is what you are seeking . what you mean by "" expected frequency "" here ?"
182915,the distribution of $ a / b $ is different than the joint distribution of $ a $ and $ b $ . which do you want to find ?
183074,"are you asking for help with the code , or with how kernel functions work with ridge regression ?"
183209,were your p-values calculated using 1-tailed tests ?
183232,are the standard errors the same ?
183246,"the range for n should be all real numbers , unless you impose more restrictions . is n the sample size ?"
183270,if you'd typed ` ?
183248,can you please throw in some context on what you are measuring to make it more fun ?
183161,could you write down the exact model you are working with based on the data that you provided ?
183337,looks better . why don't you simply use ` mean ` ?
183352,the * users * can change the prices that are offered to them ?
183227,how would you use pca on a graph ?
183366,"what do you mean by "" garch / arma "" ?"
183412,"have you considered asking your teaching assistant , community ta , user group , peers , or prof who assigned the question ?"
183402,"if you have $ ( x , y ) $ points what is $ x $ and what is $ y $ ?"
183451,are you asking what is an appropriate statistical test for a trend ?
183329,how big is each of your batches for the sgd ?
183518,"maybe the suggester meant "" the p value of the trends "" . in which case you could calculate a spearman or kendall rank correlation between your variables and ( 1 , 2 , 3 , 4 ) . wouldn't be too informative with only four data points , though . can you ask whoever suggested the "" p-trend "" for clarification ?"
183569,how many instances do you have in your training set ?
183574,have you tried creating a second variable ?
183601,"1 often proportions $ ( pi_1 , pi_2 , ldots , pi_k ) $ do not have linear relationships with the response . if reparameterizations such as $ $ pi_i = frac { exp ( lambda_i ) } { exp ( lambda_1 ) cdots exp ( lambda_k ) } $ $ were to improve the model , they would also permit natural , simple interpretations . have you examined the linearity in your data ?"
183625,"if you have 1 dependent variable w / 2 levels , you have * binomial * logistic regression , not multinomial . do you actually have $ ge 3 $ unordered response categories ?"
183645,does the three-level meta-analysis suggested at [ how to best handle subscores in a meta-analysis ?
119990,"the [ wikipedia article ] ( url ) gives the student t cdf explicitly ( as a multiple of a hypergeometric function ) . since it is so straightforward to shift and rescale the argument , it would seem there is no need to spell it out , so i surmise the difficulty you encounter is associated with this "" inverse scaling parameter . "" exactly what does that mean ?"
183599,do you have a reference or at least a name for the algorithm used by ` pymining ` ?
183663,"why are you calling those more extreme points "" asymptotic values "" ?"
183686,have you tried regularization ?
183709,"i don't understand : according to your formula , you need to multiply ( 0 , 0 ) with your m1 $ scaling -- this should yield zero , no ?"
183739,what exactly have you tried ?
183723,your 2nd link is broken . did you have a look at this question ?
181563,"thanks , i think i get it now . imagine there were no problem . in your preferred analysis would you need to assume a normal distribution * across * subjects ?"
183846,i don't understand what you are asking . what is a single sem model ?
183853,are your zeros really zeros ?
183861,is the discrete feature ordered ?
183871,"does this question really "" show research effort "" ?"
169299,notice how your ar ( 2 ) coefficient is not significant ?
183825,"understanding this question is problematic . if "" $ x $ "" means "" $ x $ "" then the first equation is obviously false in general ( because both expectations are the same but one of them is multiplied by $ n $ ) whereas if "" $ x $ "" is something else , then the expectation on the right hand side is meaningless : where is the random variable ?"
183916,can we see your code ?
23785,i read that you were using dcov to compare non linear time series and combine them with weight . . i was wondering if what you did is using a weighted distance covariance . . meaning that you gave different weights to your data using a weight vector to calculate the distance correlation ?
183986,"this looks like frequentist statistics and thus data or observations should be random , not the inputs or regressors , shouldn't they ?"
183996,"for consistency , it must be the case that $ sigma ^ 2 leq a ^ 2 $ where equality holds when $ x $ is a discrete random variable taking on values $ -a $ and $ a $ with equal probability $ frac 12 $ , and for this special case , $ $ mathbb ee ^ x = frac { e ^ a e ^ { -a } } { 2 } = cosh a . $ $ how much worse do you do when $ sigma ^ 2 a ^ 2 $ ?"
184001,what type of physical phenomenon are you observing ?
184014,what are you going to do further ?
183684,""" is there a simple way to implement it on a microcontroller ?"
183946,are you interested in particular kinds of deviation from the expected ?
183612,"you have only 1 "" fred "" girder ?"
184157,it is not clear what do you want to do - could you edit and clarify ?
184246,"quite old question , but have you found an answer here ?"
184247,what do the variables measure ?
184277,"are the outcomes exclusive , dependent , independent ?"
184318,were the students randomly assigned to the groups ?
184343,it would depend on the practical use ( skewed data ?
184346,"you need to be clearer on what you mean by "" resample "" . are you talking about bootstrapping a finite dataset ?"
184341,"since a correlation coefficient can be computed without any reference to regression at all , could you clarify what * you * mean by "" correlation coefficient "" ?"
184374,"are you asking about how to present descriptive information conventionally in a 'table 1' format ( as is common in biomedical research ) , or are you asking for stata code ?"
182312,what cointegration test are you referring to ?
184306,"what exactly do you mean by "" representative "" ?"
184063,is it a typo that the first line of the expected output is a truncated version of the input ?
184416,"welcome to cross validated ! it's not clear , but possibly related : [ is it valid to include a baseline measure as control variable when testing the effect of an independent variable on change scores ?"
184444,"how are ` decision_x ` , ` decision_y ` and ` decision_z ` related ?"
184440,"i think the initial sentence may be causing a lot of confusion . it asks how to "" simulate "" a "" joint cdf . "" later on , however , you cite the formula for the copula . it would therefore appear that nothing needs simulation . if you want to plot the cdf , why not do so directly ?"
182788,"you have nominally stated a deterministic quadratic programming problem , which is specified by the inputs dmat , dvec , amat , bvec . this problem has a deterministic solution . where does the randomness come in ?"
183480,"well , in that case i think that the fact we use $ k $ -means means we can get as many clusters as you want . no need to use "" signs "" . ( or maybe i misunderstand what you want to do ?"
184308,as to your approach - does a covariance of 0 imply independence ?
184486,the key question : are the values missing at random ?
184520,"what do you mean by "" fully correlated "" , $ d_ { 12 } = 1 $ ?"
184534,where are you starting from ?
184501,what do you think ?
184559,many threads here on transformation ( nearly 900 tagged as such ) . did you search before posting ?
184590,"your professor is correct that it is shrinking relevant parameters , but so what ?"
184612,in model 2 and three you model some variables as both fixed and random ( e . g . temperature ) . what do you think are the random effects and how are they related ( nested ) ?
32273,user9617 your link is dead could you please update it or better add the reference so people can still google the resource in the future ?
184606,"you can certainly estimate a non-linear model like the one you have shown above . the question is , why would you want to ?"
184721,"of course , the truth is it won't be any named distribution . what kind of deviation from a theoretical distribution are you interested in & why ?"
184700,"please explain your notation . what is $ phi , sigma , dots $ . also , giving a link to the book and the page / section number would be helpful in understanding the question . that said , the argument of the $ log $ function is the ratio between two probability values which must always be positive . btw , do you make sure that $ q ( h_i theta ) $ is non-zero ?"
184741,"welcome to cv ! software questions are generally off-topic here , and your question as it stands is rather broad and unclear . could you edit to be more specific ?"
184777,"a pedantic remark : is $ x_i sim u [ x_ { i - 1 } , 1 ] $ intended to mean $ x_i mid x_1 , ldots , x_ { i-1 } sim u [ x_ { i-1 } , 1 ] $ ?"
184804,did you check if your independent variables did not contain the dependent or a proxy for it ?
184807,please clarify the question . in what sense do you 'have' the processes and in what sense do you want to be able to 'say' they are independent ?
184869,"i don't understand your edit . why is it "" quite obvious "" ?"
184880,are there two separate warning messages ?
184008,why do you think you need 2sls ?
80189,is this question alive ?
184905,"stephankolassa what about this situation makes you say "" inherently confounded "" ?"
184907,"isn't that essentially a question , what is the difference between regressing $ y $ on $ x $ versus $ x $ on $ y $ ?"
164638,"not entirely sure what you are asking . are you looking for optimization algorithms for the training problems ( e . g . qp for svm ) , or are you looking for hyperparameter optimization methods ( e . g . optimizing c and kernel parameters for svm ) ?"
185056,"apart from the r implementation , why would you "" compare the seasonal effect of separate days "" if you differentiate with a lag of 365 days ?"
183834,i'm not quite sure i'm following this . can you give a simple example / some example data ?
185040,think about what is the the population and the sample . are your subjects a sample from a population or are you only interested in just those subjects that you have ?
185091,"'normalization' here might be a bit broad , and might be hard to translate to a circular statistics context . what exactly is the goal of your procedure ?"
181771,what's your training data ?
179052,it's probably $ z_ { t-1 } $ rather than $ phi $ that is the error correction term . how is your ardl model different from the standard vecm ?
185175,have you thought about using a box-cox transformation ?
185222,could you also describe your simulation extra to providing the code for it ?
185198,could you include the estimated model coefficients ?
185256,"what is the meaning of $ p ( a h_1 , h_2 , h_3 ) $ ?"
185336,why is it difficult to read in the data and form the contingency tables ?
185348,is this a question from a course or textbook ?
185367,do you have some reference or a numerical example for your claim ?
185417,do you have a source for the claim ?
185421,could you be more specific ?
185425,you mean the ` range ( ) ` ?
185427,i think you need to give more infromation if you want us to help . how is the score evaluated ?
181440,"how "" reliable "" are the confidence estimates ?"
185443,` measuring the same psychological construct ` . why then didn't you focus on testing that the combined tree sets produce only one major factor ?
185450,"did you get predictions from both heuristics for each sample , or did you use different samples for each heuristic ?"
185373,am i right to think you're talking about the $ d_4 $ [ coefficient of the moving range that appears in the upper control limit formula ] ( url ) in a shewhart control chart ?
185467,"where did you get the numbers 0 . 3413 , 0 . 4772 and 0 . 3413 ?"
185385,shouldn't it be $ ( x_k - k ^ 2 / 2 ) $ ?
185474,are you just asking how to determine if a p-value is significant ?
185481,"i can't tell from the information given here , but would stigler's method enable you to find the asymptotic variances of the * univariate * variables $ s_n pm t_n $ ( both of which are linear combinations of order statistics ) ?"
185489,"you do not seem to use squared error anywhere , aren't you ?"
185444,do you mean to ask a question about coefficients rather than the independent variables ?
185520,"i don't quite follow this . if you have 3 different operators who use each device , why don't you have 3 datasets instead of 2 ?"
184783,"if there are a lot of exact zeros that's very important information . please add it to your question . is the variable otherwise ( at least notionally ) continuous , or is it discrete ?"
185237,arbitrarily sized as in e . g . 25 instead of 10 ?
185638,why would it be surprising that there wasn't a relationship between their performance on this challenge and exam scores ?
185652,please post data . . . very curious pacf at lag 25 exceeding 1 . 0 . what software computed them ?
185683,what is the domain of $ x $ and $ y $ ?
185718,do you just want to plot it ?
184910,gung but what are the grounds of such assumption ?
185744,"regarding the edited question , the mean-reversion process is described by the vecm . vecm explicitly shows how $ y_t $ and $ x_t $ interact . doesn't the vecm representation answer your question ?"
185747,what is $ n $ here ?
185754,are the three cognitive functions comparable theoretically and / or by measurement units ?
185780,do you know the numbers for each intermediate day ?
185756,"in the applications i have seen , which cover engineering , environmental , financial , physical , demographic , and economic ones , most lognormal distributions used in models and fit to data have $ sigma $ less than $ 1 $ and almost always less than $ 5 $ or so . what are you trying to model with such an astronomically large value of $ sigma $ ?"
185843,why isn't the number of readings the same thing as a weight ?
185989,"it is ambiguous whether this is a statistical issue or a coding issue ( & i don't know stata ) . that said , i notice your stata output includes ` type1 omitted because of collinearity ` , & ` type2 omitted because of collinearity ` . i wonder if that's related to the issue . would r work if you dropped ` type1 ` & ` type2 ` ?"
185995,can you explain the context around or motivation behind your question ?
185882,"btw , as a comment : the bottleneck in here is your $ mu $ function that is complicated and is prone to return all zeros . are you sure you need this exact function ?"
186042,"if you sometimes get 1 mode , sometimes 2 , sometimes 3 then the first thing to consider is how stable the modality is and how far it is an artefact of the measurement or reporting process . jumping towards mixture modelling seems a little premature . i am not especially surprised at minor modes in a sample of 367 when ( from the evidence here ) the number of possible values is quite small . is the variable continuous in principle or discrete in principle ( i guess the former , but please confirm ) ?"
145602,"what * quantitative * criterion do you propose to distinguish "" near-zero "" from "" zero "" variance ?"
186060,does the discussion at url answer your question ?
164949,is url a duplicate ?
184348,"by "" randomly distributed "" do you mean * uniformly * randomly distributed ?"
186184,"the short answer is definitely yes , but maybe you want models you are actually interested in ?"
186221,"i may have a different understanding than you intended by "" repeat the data over and over again . "" i took that to mean duplicating the data records . in your post , could you clarify what that process is ?"
186196,are you missing a $ y ^ ty $ term or does it somehow get dropped ?
186258,"could you please explain what you mean by "" dependent groups "" ?"
185740,"section 5 . 8 , * infill asymptotics * , of the first ( 1991 ) edition of cressie's book is clear . although it does not provide a definition in mathematical notation , an example ( of asymptotics that are "" more delicate than infill "" ) is explicitly given two pages later using mathematical notation . could you perhaps quote your own paper's description of "" infill asymptotics "" ?"
186278,are you sure you understand the notation properly ?
186307,using the tensor decomposition seems to be a good idea . but what about your predictions ?
186341,ssdecontrol : i am one the people that also voted this to be closed . look at your answer for example ( which i have upvoted btw ) . do you really say something about * how to setup the model * ?
186352,what exactly is the prediction error in this context ?
186386,"by "" explaining vectors "" you mean eigenvectors ?"
186405,do you know what the mean and standard deviation of $ bar { x } $ are ?
186426,"karl , isn't it not more and not less difficult than to interpret results of multiple regression with non-orthogonal predictors ?"
186374,"isn't the null , h0 generally that the event had no effect ?"
186455,"could you explain what you mean by "" get over $ 10 $ "" ?"
186468,glen_b this particular question does not seem to appear in grimmett & stirzaker so i don't think there is any need to reference g & s . perhaps the op can confirm this ?
186496,do you know bayes rule ?
186595,"what do you mean by "" population of this variable "" ?"
186644,what is the question in here . . ?
186664,could you describe distribution of colonies sizes in greater detail ?
186665,do you know anything besides the means ?
186525,how does your data look like ?
186667,can you explain in what way your results are weird ?
186463,"also , i don't wanna be "" that guy "" but did you try google ?"
186685,can you say more about your situation & your data ?
186696,for what values of $ x $ ?
186682,do you mean calculating percentage of values equal to mode ( url ) ?
184713,"do you want to do * inference * on whether the intervention had a statistically significant effect , or do you want to model the intervention to obtain better * forecasts * ?"
186725,what kind of data is this ?
186737,"i edited your question to keep it open . ( if you just want a guide to how to choose . . . it will be considered * too broad * ; but asking for a book / reference is on topic . ) ultimately , the only way to be able to choose which to use is to learn about all the techniques & what they do / how they work . do you use r ?"
186764,"that looks * linear * , but nothing there seems to suggest that you have the * best * one unless you specify some things about $ mathbf { a } $ . what's the criterion for * best * here ?"
186782,"cross-sectional is so named because it is a single point in time . i think you mean prospective , longitudinal , but not panel data . but can you describe the "" units "" are they students within schools , teeth within a mouth , etc ?"
186818,"imo , eq 4 is false with regards to eq . 3 . i do not see how you factorize $ p ( c ) $ $ n-1 $ times . maybe you wanted to set $ 1 / p ^ { n-1 } ( c ) $ ?"
186733,what is $ v $ in your question ?
186797,this sounds like an homework question : can you add the ` self-study ` tag if so and in any case tell us where you are stuck with this derivation ?
186862,do you know the exact dates for the adoptions ?
186913,given your actual questions the code doesn't seem too relevant . do you mainly want to understand permutation testing ?
186935,could you elaborate on why you think such calculations would be any different for the $ chi ^ 2 $ distribution than for the normal distribution ?
186900,"it's not a nitpick : it indicates your speculation is very wrong . simply barring the obviously incorrect cases does not make the other ones any more correct ! btw , in what sense do you mean "" converge "" ?"
187015,can you explain where the value of 20 . 38 in part 1 is coming from ?
186838,"by "" a is present "" , do you mean that when $ a = 1 $ , $ b $ and $ c $ are correlated and when $ a = 0 $ they are not correlated ?"
187078,"i don't know what you mean by "" bayesian anova "" . my assumption is that you just place priors on the regression coefficients and variance , but then this just means you have more assumptions rather than "" less restrictive assumptions "" . you can certainly have a more flexible model , e . g . non-gaussian assumptions , but this has nothing to do with using a bayesian analysis . can you please define "" bayesian anova "" ?"
187136,"i am not aware of any restriction , in any common definition of variance , to continuous functions . what definition of variance are you thinking of ?"
187116,"there are some unclear points in your question . when you say "" to show what is the interaction between aerosols and plants "" do you mean either one of them being the dependent variable and the other being the independent variable ?"
186813,"we can't guess what might be wrong when all relevant details are missing . can you supply a minimal working example ( a small set of data with the same problem , plus a clear description of exactly what you did ) ?"
187228,"instead of eigenvalue , do you perhaps mean engle-granger ?"
187243,"ok , i don't really know where to start but your are confusing a lot of terms here . pretty much everything in [ anova ] ( url ) is about comparing means , incl . [ post-hoc tests ] ( url ) , which are done after the anova and when no a priori hypotheses were specified . the f-value is simply the signal to noise ratio - why would you want to adjust this ?"
187174,"you need to edit your answer , telling us the properties of $ epsilon_i $ . are they observed ( i . e . part of the data ) ?"
187250,"did you perhaps mean "" shocking it at time 20 "" instead of "" shocking it at lag 20 "" ?"
187300,a logarithmic distribution is a particular discrete distribution ( e . g . url ) . do you mean lognormal ?
187303,"if you have the distribution , how are the expectations unknown quantities ?"
187158,"when you say "" is modeled "" , it is only modeled that way if someone * does * use that model ( and doesn't speak to its suitability ) . do you mean something like "" may be reasonably modeled "" ?"
186164,how do you know which columns are causing the issue ?
187240,"precondition and / or tikhonov regularisation are pretty much our only chances . having said that , what exactly do you solve ?"
645,"this seems very vague to me . what kind of data , and what kind of analysis ?"
187344,"do you only want to know if the mean of the distribution of test 1 scores is closer to the mean of the gold standard , or do you want to know about the agreement of the variables as a whole ?"
187340,i don't see what's troubling you . a choice between proportion and percentage is just one of display format . the important thing is the formula ; words that are used are conventional . the fact that kappa can be negative might seem most difficult to explain ; with luck you'll never have results that poor . this seems more about your audience or readership than concepts : what can you tell us about that ?
187389,what about using svm with different class weights ?
187297,i have a suspicion that it might have something to do with the intercept being included into ` cx ` . can you double-check by removing the column of ones from ` cx ` and ` intercept = false ` from the ` glmnet ` call ?
187407,isn't the point that you can't ?
187448,"what is / are "" human factor [ s ] "" ?"
187418,"for those of us not familiar with a garch model , can you tell us what $ epsilon_t $ are and what your data are ?"
187548,""" homoscedasticity "" ( meaning a dispersion of residuals that is approximately constant regardless of the fitted values ) is a correct interpretation of these plots and it's exactly what you want to see . what's the problem , then ?"
187181,may it be the case that for wls you consider * standardized * residuals while for ols you consider * raw * residuals ?
187663,250 * 250 means 250 firms observed over 250 time periods ?
187675,"so , you want the mean of your data to be an unbiased estimate of the mean of the three populations , where the populations are of the same size ( relative to each other ) & their variances are known a-priori , is that right ?"
187667,how many possible values of a binary $ n $ -vector are there ?
187682,"in addition to what nick said ( 1 ) : the red lines show ( i quote the doc verbatim ) "" * the slopes of the least-squares reference lines in the scatter plots are equal to the displayed correlation coefficients . * "" what exactly don't you understand from matlab's doc ?"
186275,did you try to show that their ratio converges to a constant ; that is to show $ lim_ { n rightarrow infty } frac { f_1 ( n ) } { f_2 ( n ) } = k $ where $ k neq 0 $ is a constant ?
187644,""" confusion matrix with heatmap "" sounds promising ; care to show that ?"
187729,what do you mean by best ?
187746,"you wrote "" variance of 4 ( light-years ) "" , which s dimensionally incorrect . is the variance 4 light years squared , or is 4 light years the standard deviation ?"
187788,how many observations do you have ?
187831,what makes you think that the posterior isn't also a continuous pdf ?
187485,how many iterations your optimization routine needs to find $ theta_ { t 1 } $ ?
187870,question is ambiguous : do you seek code in r or do you want advice on strategy ?
187736,"welcome to the website . it is clear that you tried to solve this problem on your own but you do not pose this question in terms of statistics but rather simiplistcally in terms of "" drawing ci bands with matlab "" . your question has a well-defined statistical aspect ( ci for deming regression ) . can you please reformulate your question in terms of statistics ?"
187869,"you'd be throwing away information . suppose you've 4 observations $ x_1 , x_2 , x_3 , x_4 $ from a gaussian : is $ frac { x_1 x_2 } { 2 } $ sufficient for the mean ?"
187706,can you post a reproducible example ?
187912,"what distinction are you making with the phrase "" real space "" ?"
187931,how many participants filled out the survey at all three times ?
187890,could you look at the comments to the answer and help us find out what your setting is ?
187949,i corrected your formatting - please check if it is correct . what is your question in here ?
187980,"do you have the actual underlying data , or just the top 5 ranking ?"
181713,"unless $ m $ has some very special value , you haven't a prayer of expanding this expression around $ x = 0 $ because it's not even defined for negative $ x $ . what problem are you trying to solve that led to this exercise ?"
188034,what's the response variable ( the dv ) ?
188063,"you need to provide much more information about what you want to achieve with "" reliability testing "" . are some of these questions meant to measure subscales ?"
188061,are these mean values ?
188098,are you trying to recreate logistic regression ?
188144,can you say more about how you would standardize the mean ?
188207,can you just abandon $ x_ { t } $ ?
188293,"your example of an "" anomaly "" isn't clear . are you just trying to identify outliers ?"
188319,what is the meaning of $ i ^ prime $ ?
188358,"is this a markov-switching model or a dlm , or something else . i cannot really tell what your doing . could you write the equation for the model and define the variables your estimating in a more formal way ?"
188374,"to which direction of the matrix $ ( x_ { i , j } ) $ does the covariance apply ?"
188336,what have you done to attempt the question ?
187989,"perhaps a proof by construction , where $ b_1 = a_1 , b_2 = a_2 - a_1 , dots $ ?"
188626,"there is some incosistency in the notation , namely that $ boldsymbol { mu } / 2 = boldsymbol { mu } ^ { t } boldsymbol { mu } / 2 $ . that cannot be right because the inner product is the * square * of the norm . i suspect that the two in the denominator should be a power and that would bring it to the definition of the noncentral chi squared distribution that i know , that is with noncentrality parameter $ boldsymbol { mu } ^ { t } boldsymbol { mu } $ . can you please verify this ?"
188642,"how exactly are you defining "" best "" ?"
188527,i don't know if this is answerable at present . can you tell us more about your situation & your data here ?
188676,what is your question ?
188708,what is the research question ?
188595,what is the problem with the two linked posts ?
188753,"you might want to look into the package ` glmnet ` . the problem with lasso , however , is that some of your categorical predictors might be left out while others might be retained . are you okay with that ?"
188750,"until you can tell us more about the model , the data , and the roles of the $ theta_i $ in it , this question has many possible correct answers . presumably the question you are quoting has a context--perhaps it's one in a series of questions about a particular statistical setting ?"
188789,"did you look at roc ( receiver operating characterstic ) , brier score to compare the relative performance of two predictions ?"
188801,"it sounds from your question like after your initial thought ( normal ) , which would take seconds to check even if it wasn't obvious , you tried nothing whatever [ . ] ( url ) . what did you do with the other 59 minutes ?"
188806,""" sample more frequently when there is variation , and less frequently when there is not "" could work in sample , but that would be difficult to use for out-of-sample predictions . are you interested in the former or the latter ?"
157486,what is the date at which the observation ends ?
188824,can you post the data ?
188841,"sorry , i accidentally posted this as an answer , it should be a comment . . i am not sure whether i get your question correct , and i am not an expert on that field . however , as you already know how solve for the dcc-garch parameters you can easily sample from ( x , y ) conditional on the garch-parameters ( this is equivalent to sample from a bivariate normal with given parameters ) . given this sample you can solve the integral nummerically via monte-carlo . . . does this make sense ?"
188842,did you have a look at url ?
188843,why do you need the data for the theoretical quantiles ?
188887,your expression for the pmf is ambiguous . do you mean $ frac { 1 } { 3x } $ or $ frac13 x $ ?
29682,"( 1 ) because $ int l ( theta x ) dx = 1 $ for all $ theta $ , i believe even the constant in $ l $ is defined . ( 2 ) if you think of parameters like $ phi $ and $ theta $ as merely being * coordinates * for a manifold of distributions , then change of parameterization has no intrinsic mathematical meaning ; it's merely a change of description . ( 3 ) native english speakers would more naturally say "" likelihood * of * $ theta $ "" rather than "" on . "" ( 4 ) the clause "" when $ x $ is observed "" has philosophical difficulties , because most $ x $ will never be observed . why not just say "" likelihood of $ theta $ given $ x $ "" ?"
188945,"sorry , but i don't understand how your descriptions tie up at all . if you just have 30 observations x 9 variables , what logic groups them as $ x , y , z $ ?"
188954,"i think your confusion is due mostly to ambiguity in the question : "" optimal "" can be interpreted and defined in many ways , and it's not apparent from the question what the author meant . might it be related to the [ bayes optimal classifier ] ( url ) ?"
188921,"link to the question in physics , perhaps ?"
188958,that seems unexceptionable : what's the nature of the disagreement ?
188988,"what , exactly , do you consider your "" population "" to be ?"
188993,"perhaps i am misunderstanding the approach , but would there not be an issue with an analysis conducted ignoring the random forest done beforehand ?"
188936,welcome ! can you describe more your mcmc scheme ?
189011,what is it that you ultimately want to achieve ?
189065,"you ask two questions : "" is this possible "" and "" is this possible . "" but what , exactly , are the referents of the two "" thises "" ?"
188752,"after your edit : you say that an umpt exists , that could be but , what is your test statistic , what is the critical region ?"
189078,possible duplicate of [ why a sufficient statistic contains all the information needed to compute any estimate of the parameter ?
189167,"be aware that "" what kind of analysis should be recommended in this case ?"
189182,"interesting . . . asymptotically aic and mse should select the same model , if i am not mistaken . perhaps there is some problem with likelihood in aic , e . g . the assumed error distribution is far from the realized residual distribution ?"
189319,"this question is unclear . what does "" llmhlhlmmlhh "" represent ?"
189349,"which are the independent variables , $ x $ and $ y $ ?"
165083,do your license plates have only numbers ?
188342,are you sure you are trying to predict hazard ratios and not failure times from this analysis ?
189408,can you post code that created the numbers ?
189428,"hi bonnie , and welcome to the cv community ! could you share a bit more information about why you retained 3 factors--have you considered conducting parallel analysis , nested model comparisons , or evaluating model fit indexes to see if they support your decision ?"
183468,how pronounced is the decrease ?
189482,have you looked at firth's penalized ( partial ) likelihood approach as implemented e . g . in sas ?
189511,how was the plot obtained ?
189519,could you explain why you introduce a possibility of keeping the same value in the proposal ?
188778,"what's a "" cfi difference test "" ?"
189556,"it depends on your alternative hypothesis and on the critical region you define , can you be more specific about the hypothesis test ?"
189310,can you be a bit more specific ?
189581,isn't this the p-p plot ?
189611,box-cox transformation ?
189612,what are the research questions you wish to answer ?
189627,maybe ` ?
189697,i'm not sure to understand . do you mean a confidence interval of the ratio of variances ?
189708,"that is true . so salary inequality refers to inequality within a team , not across teams ?"
189709,"i would clarify your point that "" all sufficient statistics "" are known . a random sample of $ n $ points is , as a whole , a sufficient statistic but surely you don't mean all possible random samples . do you mean minimal sufficient statistics ?"
189720,are the probabilities of alice & bob finishing the race independent of each other ?
189692,why do you want to use deep learning ?
189739,did you try to add a small jitter to the diagonal of the covariance matrix ?
189755,"is "" f ( x ) "" something other than just x ?"
189454,hi tom -- how does that change anything ?
189769,"what do you mean with "" not a factor graph "" , what else can it be ?"
189776,is this a homework question ?
189778,what is the subject-matter context here ?
189746,"but it shouldn't be a continuous , should it ?"
189832,"if you got a contingency table of purchased yes / no , what about just doing two chi square tests of independence - one between test 1 vs test 2 , one between test 1 test 2 vs control ?"
189524,"is there something you're worried about in particular , that would lead you to doubt a method you've been using ?"
189163,what is knn clustering ?
189869,is this a question from a course or textbook ?
189888,do you know what the ` combine ` function that you are attempting to use to combine ` gbm ` objects is ?
189959,"they're the same . equality of random variables means they have the same distribution function , characteristic function , and all that . and for the second part , do you mean $ ef ( x ) = ef ( y ) $ for any 'reasonable' $ f $ ?"
188288,"are you trying to understand how imputation works ( eg , how to combine . . . , what m is feasible . . . , etc ) , or are you asking for help w / the r code ?"
190002,"i'm not sure i understand this situation . it looks like you really have just * one * dependent variable $ y $ along with $ 10 $ collections of observations of it , and ditto for the independent variables . if so , you are looking for a multiple regression solution . how does your situation differ from this commonplace one ?"
190080,does sharer_prob have intermediate values r just 1 & 0 ?
189977,"i don't see a table with the test results . the one included looks like estimation output for an unrestricted vecm . also , what is the actual question ?"
190151,"very strange , can you get the individual predictions and find out which records it is differing for ?"
190192,this is a bit hard to follow . can you say more about your data ?
190230,$ f ( x_i ; theta ) $ is piece-wise constant as a function of $ theta $ ?
190066,what is your ultimate goal ?
190005,have you tried elastic net ?
190374,what is the outcome variable for this analysis ?
190457,"it seems there's really nothing to "" prove "" : it comes down to the definition of the family . do you have a specific example in mind that could illustrate the content of your question ?"
190340,are you only looking once ?
190482,"from your comment answering nick cox , i think you not so much want the importance of each variable on row level , in the abstract . what you want is to explain in words a decision taken based on the model . say you reject the loan application if probability of default , from the model , is larger than a certain cutoff , like 0 . 01 . then you want an explanation of that decision in legal terms ?"
190472,did you mean to include an image there ?
190535,the two subclauses of your 'p . s . ' are not logically connected . is this a homework exercise ?
190537,"are you asking how such rates can be calculated for a specific interval in general ( eg , mathematically ) , or are you asking for r code ?"
190556,could it be that there is an absolute value in the nth order statistic ?
190561,so are you wondering if the root can be 1 ?
190152,can you post the data ?
190660,"i'm not quite sure how a percentage could follow a weibull distribution ( typically defined as a distribution on $ ( 0 , infty ) $ and not on $ [ 0 , 1 ] $ or $ [ 0 , 100 ] $ ) . in any case , would you not think that students might be overoptimistic ?"
190571,is this a machine learning question or a pure math question ?
190683,what sort of application are you looking for ?
190744,"i see that imputer has been removed from cran , so i do not know what rmse does . with that in mind , is there any reason to think that a lower rmse is better for an imputation ?"
190763,"what exactly is "" fish density "" ?"
190288,can you double-check the formula of the intercept ( coefficient $ a $ ) ?
190787,do you have a lot of observations in the training / validation set ?
190819,similar problem : what is there to test ?
190707,it's clear whether you're looking for an algorithm or method ?
190851,is the covariate correlated with the grouping indicator ?
190852,because pca is almost always used as an exploratory technique--especially in environmental sciences--your concerns may be misplaced . could you tell us more about what you're trying to use it for ?
190907,"the 10 ^ -18 is the chance that a specific pair of people will meet on a specific pair of days . so , to find the expected value , you have to multiply by all pairs of people and all pairs of days . does that help ?"
190914,"fcop , which part of that definition is helpful ?"
190868,could define rmse % more formally ( e . g . provide a formula ) ?
190971,"what happens when , say , $ y_1 $ is a constant ?"
190981,"note that a particular quantile ( conditional on predictors ) is a point , not a band . suppose you are interested in the 0 . 75 quantile ( upper quartile ) . what fraction of the data would you select and how would you select it ?"
190779,"your question seems a little jumbled / less clear than it could be . could you define $ x_1 $ and $ x_2 $ in relation to what you know , and clarify what exactly you're trying to do and where you get stuck ?"
191038,what are the auc's in scenario 2 ?
190122,"i'm not clear what you're after . what does the term "" defining elements "" mean ?"
191095,in part ( a ) can we assume that $ mathbf { x } $ has full column rank as in the gauss-markov conditions ?
190899,why are there so many close votes ?
191113,"because you tell us the mean of $ epsilon $ is $ 0 $ , you may substitute $ 0 $ for $ e ( epsilon ) $ and $ operatorname { var } ( epsilon ) $ for $ e ( epsilon ^ 2 ) $ in your formula . what does that produce ?"
191126,it is best not to assume people read r code . do you just want code review ?
190987,"sorry , it's not clear to me -- why would them being "" from the same inventory "" or not be relevant to the question about a change in mean ?"
191152,have you ever seen ( or sketched for yourself ) a normal density curve ?
191183,"could you please specify the code you used to draw this plot , and the software ?"
191251,do you mean the maximum likelihood estimate for $ beta_1 $ ?
191256,can you provide a reference supporting the idea that this is actually how the process is done ?
191258,"could you state the model with more detail : is this correct : each one of the $ n $ persons , independently , makes a call with probability $ p $ . in the case they make the call , the waiting time until the call is distributed exponentially , with some known parameter $ lambda $ . then we ask for the $ k $ th order statistic of the calls ?"
191300,i would suggest that you should not denormalise the data . why do you think you should do it ?
191303,"have you tried to fit a nb distribution , shifting your var by 1 ?"
191325,who's to say that's possible ?
191389,"it is not at all evident what you are asking . if you know $ f $ , then by all means integrate $ x f ( x ) dx $ to find the expectation--ignore the sample . if you have a sample but do not know $ f $ , then by all means estimate the expectation of its parent distribution by taking the arithmetic mean of the sample . but what you are proposing to do , and the context in which it is done , are not at all apparent . could you edit the question to supply this missing information ?"
191471,"acf and pacf are not helpful for your data , they either show some kind of complicated arma lag structure , or large ( relatively ) number of lags . what is the nature of series ?"
191220,i assume these data are time-series stamped . could you show us the actual paths with respect to time ?
191537,"when i meant the standard deviation , you provided the standard error of the coefficient of the regression , correct ?"
191222,hmmmm . isn't regression supposed to do that ?
191541,i'm not sure what your second question means ; do you mean that any one error is guaranteed to cause a system failure ?
16547,is the meta-analysis really just averaging all these difference values of r ?
191667,what exactly is the question you're trying to answer ?
191693,"fascinating question . these lines can be oriented any which-way , or are they maybe parallel to some axis ?"
191718,"pca and discriminant analysis work with the eigenvectors of different matrices , what makes you think that the coefficients are the same ?"
191737,"i'm not sure i know what "" good enough to represent "" means . what sort of "" loss "" would you suffer if you used set2 in place of set1 ?"
191611,can you provide a [ reproducible example ] ( url ) ( simplified code & output ) ?
191770,the chi-square value you're asking about is the one from the kruskal-wallis test ?
191771,do you know of some other papers that have used the technique ?
191377,can you explain why you prefer a nonlinear model over a standard var ?
133765,in what sense is this w / i subjects / repeated-measures ?
191864,your formulas are definitelly wrong . how come $ epsilon_t = sigma_t epsilon_t $ ?
191867,the [ top google hit ] ( url ) links to the official account of the algorithm . what part of this do you need explained ?
191879,"is yt a subscripted y , like $ y_t $ ?"
191855,"what do you mean by "" accessing "" ?"
191803,"1 ( 1 ) how can you justify the first assertion in the "" additional information "" section ?"
191908,2 . what's $ s_w $ ?
191981,is this a question from a course or textbook ?
192007,"given that the parameters in a model literally could have any value , in what sense could you possibly conceive of * any * of these as being a measure of * anything * ?"
192168,"i'm not sure if this is quite a duplicate , but you might want to read : [ dispersion of points on 2d or 3d ] ( url ) , & [ 2d analog of standard deviation ?"
192169,"i do not understand why he calls it "" scaling constant "" given that it depends on $ x $ . does he mean maybe that it is a constant with respect to $ theta $ in the likelihood ?"
192129,"it's not clear whether the form should be treated as a composite or not ( e . g . , is something like the sum of behaviours meaningful ?"
192212,"the entire point of the hypothesis test is to try to figure out when the null hypothesis is false . you figure out the distribution given the null is true , and if it is instead false the test statistic will be from a different distribution where it will tend to have a higher chance of being in the rejection region . so any kind of hypothesis test will tend to be done in situations where the null may be false . can you clarify what's different here ?"
192225,the nomogram you want to use has a reference somewhere ?
192121,homework ?
192139,"where you say "" score of player $ i-j $ "" ( which seems to idendity one player with the number that is the difference between the numbers $ i $ and $ j $ ) , might you have meant "" score of player $ i $ minus score of player $ j $ "" ?"
192284,is this an exercise for a class ?
192328,"unsupervised learning algorithms do not lend themselves to purely quantitative decisions . this is due to the fact that the choices involved in arriving at any solution are highly subjective and , therefore , are not optimizable . you need to provide a little more context to this question . for instance , would you describe the information ( features ) being clustered ?"
192335,could you describe your problem in greater detail and provide data example ( e . g . data sample or plots ) ?
171947,"if vector 1 , feature 1 is $ 0 $ , & vector 2 , feature 1 is also $ 0 $ , do they have that feature "" in common "" ?"
192385,"1 . yes , or more generally "" if the null hypothesis is true . "" random data do not always mean zero difference or zero correlation ( aka you can have randomly generated data that are correlated at r = 0 . 8 ) ; 2 . why are you computing them as if they are dependent events ?"
192399,which axioms of probability are you using in your alternative calculation ?
192226,"be careful . a more accurate statement of your question would be something like "" after we have inspected data by groups , * and discovered that one group appears to have a high average , * what is our confidence that this group with the largest average in the dataset is the group with the largest average in the population ?"
192459,are the binary features the result of one-hot encoding ?
192487,are the base rates listed anywhere ?
192479,can you draw the path diagram you are trying to fit ?
192465,"some details are not quite right . what exactly do you mean by a "" complex $ n $ -sphere "" , given that you are working * inside * an $ n $ -dimensional complex space to begin with ?"
192572,"surely you could find a few tens of thousands of such examples just by browsing through this site . in light of this , just what kind of answers are you looking for ?"
192576,did you try taking the expectation of $ x $ ?
192619,"if $ x $ is not from a normal distribution , then exactly what do you suppose $ bar x $ and $ hat { sigma } ^ 2 $ are estimating ?"
192518,what does it prove if you show that some things are unrelated ?
192653,have you tried $ mathrm { median } ( x ) pm2 mathrm { mad } ( x ) $ ?
192748,can you provide a uncertainty on your $ b' $ measurement ?
192722,are you sure ` coeff ` is a $ 27578 times 151 $ matrix ?
192757,how do you know the non-zero values have a lognormal distribution ?
192625,these are not universally-known terms . do you have a reference ?
192783,"for most $ x $ , the chance that $ f ( x ) = 0 $ must be zero . the nearest i can guess to what you're trying to ask concerns how to construct a subset $ mathcal { i } subset mathbb { r } $ based on the data . your prior , your model of the data , and your statistical assumptions about how $ f $ is related to the data make this a * random * set , so you could try to construct a short $ mathcal { i } $ with a high chance that $ f ( mathcal { i } ) $ includes $ 0 $ . would this be an accurate interpretation ?"
192800,can you say more about which part doesn't make sense ?
192807,is this a home work ?
192771,"the questions are vague because you don't give enough details : what do you want to "" model "" or "" fit "" ?"
192898,"what does "" $ c_ { bar { tau } } $ "" mean ?"
192917,it sounds like you may be looking for something like a likelihood ratio test ?
192939,would it be possible to make a comparison between tanks ?
192944,what is the joint distribution of $ x $ and $ y $ ?
192959,why do you think you have to take the integral from $ 0 $ to $ y $ to get the marginal distribution ?
191882,wild guess : doesn't the sample size determine the sample standard deviation ?
193035,"expected second derivative is an average . if you average small things , they are still small . why do you think they become big ?"
193036,"also , does it mean that you have sold more than 10 items for * all * days or * at least one * day ?"
193048,hint : are maximum likelihood estimators always unique ?
193046,did you ever find out if your algorithm is correct ?
193090,"oh , i think it's my mistake . so diebold is saying that the * * population * * variances of the h-step-ahead forecast errors should be non-decreasing in h if the forecast is optimal ?"
193054,"maybe i can help you if you share a small sample of your data . from what i understand you have many time series of temperature and humidity and for each one you want to predict if it's going to rain , right ?"
192785,"additional comment : surely some effect for a grouping ` subject : word ` can be present . by definition none of the variables are orthogonal to each other . i am pretty sure that you might be able to argue a ` subject : block : word ` grouping too , but what good is that for your research question ?"
193134,are you asking how to compute moments of $ g ^ { -1 } ( x ) $ where $ x $ has a uniform distribution ?
192994,what is the underlying distribution ?
193205,""" i assume that oil and gas prices are exogenous and want to instrument them by its lags . "" perhaps you meant "" endogenous "" and "" their lags "" ?"
193225,"you need to describe what's going on more accurately , as a number of things are unclear . also , what you describe as a "" normal probability plot "" doesn't contain a plot -- that's a table of numbers . your nscores don't seem to be right ; your percentile ranks are symmetric about $ frac12 $ , which suggests your normal scores should be symmetric about $ 0 $ . how are your "" nscore "" values calculated , exactly ?"
193230,"just to verify , are you trying to predict what kind of polygon the image is ?"
191767,"i don't understand what's happening in steps 4 , 5 , 6 . can you explain this in more detail ?"
193168,have you tried a subgroup analysis or a meta-regression to explain part of that heterogeneity ?
67179,what happens if you've already drawn all the $ 2 $ s by the time you draw your first ace ?
193366,some people seem to consider this question too broad - in that case could they suggest improvements to narrow its focus ?
193332,what makes you think the data are overdispersed ?
193383,how many measurements / peas were there ?
193055,"it sounds like the data is very clearly non-uniform already ; i . e . if you make a histogram , is it immediately apparent that the data is not uniformly distributed ?"
193468,the strings are of different length - how are you calculating the hamming distance between them ?
193207,probability of what ?
193527,how can you say that the judgement of both pathologists is equal ?
193576,okay . well in either case i don't understand the last equation you have . if you integrate over $ a $ then how do you choose a specific $ hat a $ to maximize . . . . . you are integrating over all possible values of $ a $ right ?
193604,"how do you define "" nurses attitude "" and "" extent of practice towards the care of the dying "" ?"
193629,"could you expand "" ctt "" . irt is a family of models , so i is important to say which models you consider ( binary , 2-parameter rasch model ?"
193656,are your customers bosons ?
193674,"in the last paragraph , when you say "" as optimal as possible "" , do you mean "" as simple as possible "" ?"
193709,what's the rational function ?
193713,i wonder if sample size would make a difference here . have you tried it for varying sample sizes ?
192291,"frank , this is a bit of a side-issue , but why did you want to use "" the average vip score across all components "" ?"
193708,"what does "" a / = b "" mean ?"
193726,are the 2nd numbers sds or ses ?
193745,is this a school project ?
193752,"just some guess : doesn't the "" poly "" -function include a constant term ( at $ x ^ 0 $ ) ?"
193617,"are you sure they aren't coded as -1 , 1 ?"
193825,could you please explain how these plots work ?
193824,"please spell out your acronyms . what is "" mdp "" ?"
136267,isn't a square missing in the denominator ?
193848,why do you use a gaussian glm and not simply an ols model ?
193860,where is the ` carseats ` dataset ?
193929,is this a question from a course or textbook ?
193986,are the roles assigned independently of how were they assigned previously ?
194005,"in theory you could , but it really doesn't make any sense to do so . if you take a pca on your pca , you ignore the fact that some pcs matter more than others . if you really want just two dimensions , why don't you just take the first two pcs ( although not knowing your system , this may not make sense ) ?"
194006,"it partly depends on what you are going to use the model for ; actually , you may select different models depending on the intended use ! so what is you goal ?"
125353,what are the proportions of your data that fall into each of the classes ?
194166,"i haven't read this paper yet , but have you considered sampling from the domain of interest using a latin hypercube design ?"
194229,i find myself longing for a loss function . can you quantify--if only approximately--the damage that would be caused by mis-classifying any point ?
194278,"reconstruction error is the concept that applies ( from your list ) only to pca , not to lda or naive bayes . are you asking about what reconstruction error in pca means , or do you want some "" general definition "" that would also apply to lda and naive bayes ?"
194246,"please tell us what you intend to happen to the probabilities after some balls are withdrawn . after all , if you remove $ k $ balls sequentially , then after the first ball is removed the remaining probabilities no longer sum to unity . exactly how , then , are we to determine the chances for each of the $ n-1 $ remaining balls ?"
194277,"this probably belongs on [ softwarerecs . se ] , not here . can you clarify your situation , though ?"
194335,aren't you missing $ = s $ at the end of the sum in the penultimate line ?
194387,"it all depends on the * meaning * , in your experiment , of "" zero "" and "" aborted . "" what exactly are you measuring ?"
194401,"i see no justification for using an f-test when doing testing in a binomial model , whereas there is an argument for an asymptotic chi-square test . on the other hand some packages try to do t-tests and these equally lack an argument in the same situation . the best one can say for them is they asymptotically approximate the asymptotic approximation , which isn't an argument for any small sample benefit . does matlab offer any justification you know of ?"
194395,is your question about determining significant lag values or plotting the cutoff ?
194499,"in that situation , wouldn't you take the average of all confidence intervals to improve your estimate ?"
194472,you already have ` sex ` as a fixed effect . no reason to have is interacting with ` subject ` in the random effects part . you want to investigate for this after all . similarly i cannot see where you have something repeated ; maybe i misinterpret something but i cannot see this at this point . also why is ` conditions ` a nominal variable treated as a random slope ?
193431,you go from 14 to 35 degrees of freedom . is that would you expect ?
194549,"dave giles has an extensive blog post [ "" ardl models - part ii - bounds tests "" ] ( url ) covering bounds test in ardl . could it be useful ?"
194552,could you try to edit your question for more details ?
194504,"your null hypothesis shouldn't be "" there is no difference in frequency of mole hills observed in each bin in field 1 "" ; you already know there's a difference in the observed frequencies . it should be that there's an equal chance of a molehill's occurring in any bin . ( which seems a little odd given that the last bin's * any * distance over 12m . how far from the fence did you look for molehills ?"
194573,it's a little unclear what your question is . are you asking why the predicted probabilities are not exactly the same as the values in $ y $ ?
194630,what's physics of the phenomenon ?
194619,what are the data ?
194649,"what do you mean by "" were not statistically different "" ?"
94421,"how do you mean "" represent data "" and "" good estimates "" ?"
194743,you do not need to add na values . ` na . omit ` removes observations containing na values anyway . the model shouldn't have a problem with the different number of subjects ( does it converge and do you get a reasonable result ?
194769,"do you have a direct measurement of "" popularity "" ?"
194773,` but what about if n p ?
194481,what is the reason you are not just finding out this particular person's income ?
194782,"for clarity , you * are * asking how to modify this update rule , and not for help developing a software implementation , yes ?"
194754,"if your variables are cointegrated , they will be highly correlated . that is to be expected and should not be perceived as problematic . could you elaborate more on the issue of multicollinearity ?"
194804,could you edit your question by ( a ) naming the data set if it's a publicly-available one and ( b ) provide an example of a statistically-valid statement that you would like to use the pooled datasets to be able to say ?
173794,"can you try to compute $ mathbb { e } [ x ] $ , $ mathbb { e } [ x ^ 2 ] $ , $ mathbb { e } [ x ^ 3 ] $ ?"
194852,have you tried scaling the penalty ?
194891,what exactly do you want to test about this probability ?
194897,have you tried to transform your response so that the output is no more bounded ?
194956,how are you calculating that sd ( $ hat { theta } $ ) ?
194975,and what is the default in sas ?
195014,what does this have to do with categorical data ?
194946,how did you compute your chi-square value ?
195034,"i've followed the "" rise of the data scientist "" ever since it became mainstream in about 2008 . to me it was and is mostly a marketing term fuelling a hype - the disciplines statistics , machine learning , data engineering , data analysis all are the same with different emphasis . paraphrasing g . box : if asked questions such as "" are you a bayesian , frequentist , data analyst , designer of experiments , data scientist ?"
195047,"you get the same number of coefficients with two separate models as with a single model with all the interaction effects , so why would that be less professional ?"
195063,have you categorized the plain text passwords yourself into the same categories as the questionnaire ?
195071,did you mean to say 273 rows ?
194837,what is emergence ?
195119,"if you use a model to generate data , how can the resulting data possibly be used to validate the model that was used to generate it ?"
195128,is it a homework exercise ?
195164,do you know what kernel density estimation is ?
195177,did you try the 'predict' function ?
195212,"i believe the data you posted above does not have age and gender information of students who didn't leave the course , to the contrary it only has data of only those students who left the course ?"
195218,"sure ; but the point is that doesn't bite . you are just changing the units in which you work , but the position of the minimum in parameter space is the same . the problem is analogous to this . which $ x $ minimises $ ( x - 2 ) ^ 2 $ ?"
195256,what happens when the dragon is killed ?
195239,"could you explain the connection between "" conditional rates "" and the "" factor "" nature of your response ?"
195312,"for what reason can you not calculate $ cov ( t_1 , t_2 ) $ ?"
195338,did you log the data or acf ?
195286,are $ g $ and $ h $ independent ?
195294,"i'm not seeing what you're seeing . what are you trying to do , interpolate the data points ?"
195293,"you say that y is a proportion , but in your data it is between 6 and 10 ?"
195157,you probably need to refine the question . do you want the chance of flopping a straight ?
195403,"hi , can you share part of your code to check ?"
195428,what is cef ?
195446,"setting aside the specific linkage issue , what would "" best "" mean in your context ?"
195493,how large are the datasets ?
195499,can you give some examples of what you have read ?
195450,"you can center data ( subtract the mean ) , but i've never heard of centering the mean . could you clarify please ?"
195517,what kind of data will you be using to estimate this and in what sense are you estimating the entire * function * ?
195518,how are you calculating accuracy ?
195526,"` most of them being ordinal ( product name , retailer , retail outlet , etc ) ` ordinal ?"
195516,you can use logistic regression with the response as a binomial instead of a bernoulli . is that your complete dataset ?
195489,"1 . what are you testing , exactly ?"
196598,what are the data ?
195192,"if you were to do it your way , how would you infer $ g_2 $ ?"
196658,do you know with absolute certainty that the data are normally distributed ?
196667,have you tried what you get with extremely large sample sizes or across lots of different dataset realizations ?
195508,unclear : what is the parameter of interest ?
196714,could you please clarify the question ?
196771,what do you mean the mle of a data set ?
196734,aic is calculated by glmmml as ` aic . model - -2 * fit $ loglik 2 * nvars ` ( see source code ) so are you sure that you are pasting the proper values in here ?
196807,"your edit is not clear . you * * are * * asking about closed form solution for linear regression . it is given in the linked thread . if you use the formula , you'll get the answer . what else do you need ?"
196841,"if dirac delta is a subclass of gaussian then its kurtosis must be 3 , right ?"
196846,"` sample ` samples values ( pseudo- ) * * randomly * * , so you should expect the output values to be rather random than predictable . . . ` sample ` does not use any cdf , it just returns random integers . also : what do you mean by sampling from density ?"
196608,"since there is no randomization , it seems problematic not to adjust for potential covariates ( e . g . ancova ) and to do e . g . propensity scores for 201x vs . 201y entry . how huge would effects have to be to pick them up with such a tiny sample size ?"
196906,is this a homework question ?
195321,can this unusual slope be produced by several outliers ?
196934,what kind of regression model you are planning to use ?
196937,"are you calculating a sample median ( in which case , it doesn't matter what distribution the sample was drawn from ) or finding the distribution of the sample median ?"
196956,what about multinomial regression ?
196683,"what do you mean by "" n = 3 "" ?"
197004,"i still fail to understand the experiment you are doing . what do you mean by "" the first class is the same as the second class "" ?"
197024,can you clarify your question ?
197030,"how do you compute the "" maximum likelihood confidence interval "" ?"
197044,google did a big study where the related ( 1 ) marks by interviewers on these types of puzzle questions and ( 2 ) subsequent job performance . what did they find ?
197054,"brian . mackey : nice ! but i see your program gives a probability of 100 % that the work is done after 11 weeks or so . 100 % ! so really * nothing * can go wrong , right ?"
195287,"for me the expected shape of the target would be a key decision criterion . differences between samplers may not be huge for multi-normal targets , but they can be substantial for bi-modal or other complicated targets . should the shape somehow be included in the question ?"
197084,could you describe your data in greater detail ?
197122,"no covariance or the term $ sum_ { i = 1 } ^ n x_i y_i $ though , right ?"
197139,is ` rsq1 ^ 2 ` equal to ` rsq2 ` ?
197166,i am not sure what you are talking about . do you have multiple units of randomization per subject ( eg two eyes in a man or four wheels in a car ) ?
197210,what makes feature selection of interest vs . concentrating on predictive accuracy ?
197227,are you sure you don t want to include a term involving $ text { ln } x_2 $ alone ?
197239,could you please add an example ?
197249,"are you interested in the number of times they preferred shade to light , or in the total weight of the food stored in each ?"
196882,thank you for the additional info . are you sure that is the right formula if you have the sd ( diff ) ?
197306,"is "" user 1 "" the same entity both times ?"
197309,"sounds like you have a strawman : "" if i choose a poor test statistic , it will aim me in the wrong direction . so why should i choose any test statistic at all ?"
197275,"travisj - look at ward hierarchical clustering , and the cubic clustering criterion . this has some overhead , but gives good cluster count assuming that the uniform random is effective as a non-informative prior . jmp has this built-in and is decently fast . constellation plots can be nice . if you save cluster then you can do decent fits by cluster . can you provide some sample data , or link to a decent sample set at a repository like uci ?"
197326,"you seem to have $ z $ on both sides of the equation . in addition , i don't see an error term & / or distribution . can you clarify these aspects ?"
197325,"what's a "" tammed point "" ?"
197355,"maybe this is a silly question , but did you make sure that you centered your inputs to have mean zero ?"
197356,"changing some zeroes to ones changes the hit rate and the false alarm rate , while the roc-curve is the set of couples ( hit rate , false alarm rate ) for different values of thresholds for the score ?"
197261,get more samples . if you are trying to build a classifier using only 32 samples you are aiming for something that is most likely not reproducible . what is your goal with the study ?
197266,""" i have accurate data of the last 3 years "" - is this daily data ?"
197494,what type of neural network are you using and what are your parameters ?
197523,have you plotted the data ?
197546,"1 because you really to have tried to answer it yourself but as a friendly advice : go ahead and edit this into a smaller question . to that extent , can you not numerically evaluate a log-likelihood cost function , gets its hessian and see for yourself how the partial derivatives look like ?"
47459,"the first thing i notice , though this might be a typo is : "" the prior for $ n $ is the pdf of the exponential function at $ n $ . "" do you mean poisson ?"
197594,you say that you get either very large or very small random effects . are they bimodal or just high variance ?
197345,"( only a comment ) i think your idea using an lme is very reasonable ; i think that the idea of using ` difficulty ` is very reasonable too . i think that z-scoring the ` dscore ` is unnecessary at first instance , i would do it only for estimation purposes usually . i do not understand why you do not model ` score ` directly and use ` condition ` as a covariate . otherwise how can you assess what is the associated ` difficulty ` anyway ?"
197550,"welcome to our site ! i find this question quite unclear at the moment . what do you mean by "" i am not working with a sample "" ?"
197640,"for an interesting review of the history of the delta method , see ver hoef , jay m . ( 2012 ) [ who invented the delta method ?"
197656,i think $ n $ is not batch size ( or dataset size ) but rather number of parameters in $ w_i $ . in this way $ lambda $ is stabilized among different choices of architecture . can you show any source where $ n $ is denoted for sample size ?
197672,possible duplicate of [ can principal component analysis be applied to datasets containing a mix of continuous and categorical variables ?
197691,what you mean with scale input or output ?
197744,if both means are the same what else behaviour would you expect of $ t $ -test ?
197762,the model formulas should tell you the difference . are you after anything more specific ?
197757,i can't understand your question . are you asking * which * of those distance measures you should use for fuzzy c-means ?
195412,"as far as i know--and this is consistent with the wikipedia page you quote--the skellam family has only * two * parameters , $ lambda_1 $ and $ lambda_2 $ . what does "" $ k $ "" represent ?"
197787,"this is hard to follow . what are "" un ( , ) "" ?"
197817,"while not being very "" formal , "" would it not be suitable for your purposes to simply plot the frequency distribution for the true and false cases separately and look for a shift ?"
197819,what did you use when you tried glmm ?
197835,"sorry , i misread your original post . how many predictors do you have ?"
197804,why not allow $ theta gt 0 $ and test $ h_0 : theta le 1 $ ?
197255,"as far as i can see , you want to know how to find the distribution of x y , given the distributions of x and y ?"
197048,how big is your data set ?
197616,"metrics for std devs and errors are sensitive to the number of observations , * n * . how big is your panel sample size ?"
197878,"aic uses the number of parameters and the maximum likelihood ( ml ) , so it is the ml that will be the tie breaker . why not use it ?"
197939,does this answer your question ?
197639,can you clarify what you mean by circular . is it in polar coordinates ?
197885,are you asking specifically about how to use tensorflow or are you asking a modeling question ?
198078,"have you considered searching our site for [ threads about "" likelihood "" ] ( url ) ?"
197607,"you can't do it here because there is no one clear way to define if they "" differ "" . are you interested in the trajectory , or the final value after a set period of time , or something else ?"
198141,does your data source for the % iles list * * its * * data sources ?
198133,i don't see why you would need to use bootstrapping for this . it seems like a much more straightforward modeling / prediction problem : how does $ p $ depend on $ c $ ?
198157,can you find out at which stage the first unusual results appear ?
198216,"after a long heated discussion we have learned that data scientist is [ "" a statistician who lives in san francisco "" ] ( url ) . now , why would russian language need a term for * that * ?"
198251,what makes you think that you're overfitting ?
198266,"are your scores binary , i . e . only 0 and 1 , ordinal or measured as i assumed ?"
196717,what is your session info ?
198349,"also , what kind of lasso model is used to calculate the prediction error ?"
198181,"suppose there were only autocorrelation factors causing temperature change , but the autocorrelation wasn't stationary ( i . e . the temperature was unstable and would explode upwards or downwards from the initial condition based on random noise ) . would you want to interpret that as "" temperature isn't increasing "" ?"
198378,why do you need a closed form ?
198413,you claim $ y $ has no moments but you want to show that $ text { var } ( y ) infty $ in some cases ?
198400,"you are using ` lm ( ) ` , so you are fitting a glm only in the sense that ordinary least squares ( linear ) regression is a special case of the glm . if diversity has some non-normal distribution , you may want to use ` glm ( . . . , family = ?"
198443,"i would disagree with most of this "" solution , "" primarily because it is so vague and non-quantitative as to be almost useless . what exactly do "" clustered rather closely , "" "" largely symmetrical , "" "" sharp and narrow , "" "" same general location , "" "" appear similar , "" "" slightly greater , "" "" notably different , "" "" broad , "" and "" clear data "" really mean ?"
198437,you say you are ` using a svm for classification ` . but what classification you are using in lda ?
198456,"hmmm , is your data normally distributed ?"
198361,"the fact that negative values are predicted is not really problematic , but it * is * apparent that the predictions are far worse . i notice in the package help that the authors strongly suggest not fitting lars with ` genlasso ` . perhaps there's some numerical instability of the algorithm ?"
198099,it's not completely clear -- do you want to sample from some fitted model ?
198548,$ x = ( z- mu ) / sigma $ has a standard normal distribution and $ v = x ^ 2 $ . what is the distribution of the square of a standard normal ?
198594,could you explain why the kurtosis is of interest ?
198479,"i wonder what you might mean by "" $ epsilon $ st . d . of the mean $ mu $ "" , since there isn't any single standard deviation in sight ( unless $ sigma $ is a multiple of the identify matrix ) . what , then , does "" st . d . "" actually refer to ?"
198680,why do you think the repeated measures are not being taken into account ?
198776,"do your textbooks or notes actually define or explain what they mean by "" linear relationship "" ?"
198807,yes it's possible . the most basic explanation is that the extra variable absorbs residual variance & increases power ( see : [ how can adding a 2nd iv make the 1st iv significant ?
198803,is $ binom { 3 } { 4 } $ a typo ?
198762,what type of data are you using ?
149327,did you do a search on google ?
198820,is all of your temperature data for a single location or are there multiple locations in your dataset and you were just showing a few of the variables above ?
198825,two questions : 1 ) is the data seasonally adjusted ?
198816,"mucus sounds positive , it might be possible to transform it to normality via something like the log . do you have repeated measures ?"
198887,i am curious what that data represents . could you give us a little background information ?
194613,"yetian what do you mean by "" not i . i . d "" ?"
198766,what is your model ?
198929,"could you elaborate on what you mean by a "" first par of eq "" ?"
198842,""" higher lifespan expectancy "" for whom and in what sense ( median , mean , upper quartile , for the longest living 10 , 000 ) ?"
198932,could you find the coefficient of $ y_1 $ in the right hand side ?
198946,is there some reason why you don't want to use ` relevel ` to accomplish this ?
198340,is this a data scientist interview question ?
199001,"for what "" tests [ do you ] need . . . - a normal distribution "" ?"
199059,some possible approaches include ( a ) exploiting the formulas for computing a pdf or cdf upon a change of variable $ h $ ( in terms of the absolute value of the derivative of $ h $ ) and ( b ) using the probability integral transform . are you familiar with any of these ?
199066,can you give us some simple example ?
199067,"why don't you graph the binomial distribution and superpose the normal , and poisson approximations , and draw a line at $ x = 20 $ ?"
199076,my guess is that the problem is that the would be support vectors samples lie on a line and collinearity breaks everything . did you solve it in the meantime ?
199096,by some of them or all of them ?
199127,"what do you know about the "" bunching "" process in this data ?"
199086,"i do not completely understand your design , but by any chance isn't mixed-design anova what are you looking for ?"
199147,"i don't quite see where the "" additional variance term "" is . apparently there are two levels of ` cond1 ` and both are shown in the output , as they should . nothing extra seems to be present . why don't you simplify the situation and run the simplest possible regression that involves this variable , something like ` lm ( rt_log ~ 0 cond1 ) ` . does its output make sense or not ?"
198909,could you please post some mock data and code showing the model ( s ) you are trying to fit ?
199156,"interesting problem . just to be clear , you are interested in the similarity between outliers ?"
199164,"do you mean the third * central * moment ( ie , the skewness ) ?"
199182,"re ( 1 ) : what distinctions are you drawing between "" inverse , "" "" ratio , "" and "" fraction "" ?"
199220,can you clarify the situation & your goals here ?
199221,"what does it mean to be "" told "" $ p_ { x_1 } , ldots , p_ { x_n } $ ?"
199264,"about ` stl ` , did you already read the associated paper ?"
184565,all your links go to the questions . specifically what text are you referring to for the assertion that the posterior probability that a ci covers the mean is either $ 0 $ or $ 1 $ ?
199338,do you mean agreement when you say correspondence ?
199314,what kind of method are you trying ?
199375,"the documentation for ` glmnet ` is great . its manual page clearly states it handles binomial , poisson , and multinomial responses , all of which are applicable to the kinds of data that produce proportions . it also handles weights and offsets . what more do you want ?"
199377,are you sure that your two plots are not transposed ?
199388,"by "" number of dimensions "" do you mean "" count "" ?"
199406,"can you post the system of odes and whatever methods used to "" simulate stochastically ?"
199429,how accurate do you need the index to be ?
199436,"for example , a [ $ chi ^ 2 $ distribution ] ( url ) is underspecified without a degree of freedom parameter . what is your difficulty with the explanation at url ?"
199400,"of your 100 samples , how many are in each of your binary classifications ?"
39230,"if you have the computing power to generate all permutations ( or some well-defined set of re-assignments of the data ) , why not systematically generate each exactly once ?"
199462,have you read these comments ?
199471,"bjrn has a good point . if you know the numbers who voted ( not just the percentages ) then a [ logistic model ] ( url ) would be appropriate . otherwise , you could consider [ beta regression ] ( url ) . note that your confidence in a percentage value will be higher in cases where more votes were cast . standard linear regression is risky here . also , do you have data on all cities ( and towns and unincorporated areas etc ) within each state so that a nested analysis ( city within state ) is possible ?"
199539,use [ e-m ] ( url ) . just a few e-m iterations are guaranteed to move the candidate solution towards a ( local ?
199542,"` lme ` is just an r function , what kind of model do you have in mind for this data ?"
199552,why the log scale here ?
199558,are your classes unbalanced ?
199574,have you calculated the variance at each n ?
199532,"thank you for the edits , john . could you please explain what you mean by a subject to be "" homogeneous with respect to all unobserved covariates "" ?"
199546,why are you trying to construct confidence intervals on $ p $ -values ?
199505,"indeed , i think "" * how to implement a correct permutation scheme ?"
199614,"what do you mean by "" doesn't correspond "" here ?"
199549,"i think it would help if you could explain * * why * * this is time-to-event data ; what , exactly , is the response you want to model ?"
187474,could you explain the relationships among these plots ?
199738,"is the position of the object random , or is it following a trajectory through space ?"
199749,"can you say more about your situation , your data , your classifiers & their performance ?"
199787,"if it did , you would have three rows , right ?"
199820,"maybe the vertical bars should be double vertical bars , to represent a euclidean norm ?"
199833,what dissimilarity measure are you using ?
199850,"also , how are you splitting them ?"
199615,what are the mixing weights ?
199858,"what do you mean "" convert "" ?"
199856,hint : first compute or look up the variance of the $ x_i $ . can you compute the variance of $ frac { 1 } { 2 } x_1 frac { 1 } { 2 } x_2 $ ?
199895,"so , if you mean that you are computig "" overall dendrogram "" correlation between the distance and the step level and not for a specific partition ( solution ) - then the question why do you need so . are you not going to arrive at a partition ?"
199909,"actually , 40 % , in a 6 class problem is not that bad . if you were assigning class randomly you would have an accuracy of 16 % . besides , how did you tune your neural network ?"
199937,"some parameters are here to control the sparsity of each model . did you try a model with a large number of features and a large "" c "" ( the cost parameter ) ?"
199940,"it seems that there is some limiting behaviour , first that values of $ x $ cannot exceed $ 100 $ ( meaning $ 100 $ % ?"
105363,did you switch the definitions of $ alpha $ and $ beta $ partway through your post ?
199969,how do rosenthal and colleagues propose to convert the t-statistic to r ?
199956,"could you please provide a link to the "" old post "" you are referring to ?"
200005,do you mean how to estimate a covariance matrix from a sample of gaussian vectors ?
200007,"i saw arguments in the duplicate that look like "" mathematical justification . "" could you explain what exactly you mean by this term , then ?"
200020,"it's too general a question , and the answer would really be a chapter or a long article . why don't you settle for a very concrete single question , instead ?"
200042,what is the error on the training set ?
199910,can you say more about your implementation of mh ?
199409,peter can you say a little more ?
200090,this is a little short for a question ?
200102,see [ logistic regression : what happens to the coefficients when we switch the labels ( 0 / 1 ) of the binary outcome ?
200145,have you tried taking $ mathbb { e } ( g ( m ) -g' ( m ) ( x-m ) ) $ ?
200150,the edit helps a lot . are you asking how to write out the log likelihood function $ l ( b x ) $ without knowing anything about $ a $ yet ?
200193,"is this a symmetric matrix . . . $ [ e ^ top , f ^ top , g ^ top ] = [ h , l , m ] $ , $ a $ symmetric , etc ?"
200237,do both $ x_1 $ and $ x_2 $ come from the same distribution or do they differ in terms of the mean and variance ?
200242,could you please say a bit more about the structure of your data ?
200253,"$ r ^ 2 $ is a measure of how much variation is accounted for by a model . if you have no variance , it makes no sense to talk about how much of it the model explains . why are you using only a single point for validation ?"
200277,"you say you want to "" detect events "" , but the events don't seem to really exist--you defined events arbitrarily . what do you really want to determine in your data & why ?"
200345,"obviously yes , compute mean of ` 1 , 2 , 3 , 4 ` and of ` 1 , 2 , 3 , 999 ` . what exactly are you asking ?"
200327,why do you want * clustering * ?
200384,"in order to have a testable hypothesis , you need to provide a quantitative criterion for "" as a whole "" or "" most . "" does that mean more than half ?"
200401,""" revere "" ?"
200427,"your phrasing "" take 5 marbles "" says nothing about taking them in any particular order . so let's turn your question on its head : why do you even introduce an order into a problem where order plays no role ?"
200430,"but it does * not * apply everywhere ! like all other statistical procedures , there are circumstances where this one can be expected to give useful results , others where it definitely will not work or be misleading , and everything in between . have you noticed that * all * the theoretical justifications for bootstrapping are asymptotic ?"
200410,who says ?
200453,"welcome to cross validated . please edit your question so that it is clear what you are trying to achieve in your analysis . for example , what is the outcome or outcomes you are trying to model ?"
200470,"what do you mean by "" perfect results "" ?"
200500,"bound to become a classic question 1 ! the bayesian approach , because it allows us to ( at least subjectively ) answer the question we are often interested in , viz . : "" in light of the evidence ( data ) , what is the probability that the hypothesis is true ?"
200540,do the physical processes of retention and elution suggest particular distributions ?
200554,can you provide more detail on * why * do you want to center your values ?
200581,doesn't the relationship $ xi_s = mu_s - xi $ fully answer this question ?
200584,"just out of curiosity , what is the bottleneck with bo ?"
200653,what is the expected value of $ x_ { ( n ) } $ ?
200675,the multivariate gaussian are infinite and there is no need to cut it into the finite space region . in the books authors are used to visualizing gaussians using circles or ovals ( it depends on covariance matrix ) on 2d space . but even in this cases they mean infinite regions . are you sure that you got it right ?
200580,were the sites randomly sampled ?
200708,what does the plot of the residuals look like ?
199962,can you create a spectrogram of the data ?
200765,i don't follow this question because ( 1 ) it is not true that copulas are defined through correlation matrices ( that is kind of the whole point of copulas : they are far more general ) and ( 2 ) the statement of the question in the last sentence is garbled and almost unintelligible--perhaps some typographical errors crept in ?
200770,"are you trying to select the best classifier based on the accuracy score , or just trying to measure the predictive accuracy for a classifier that you've already selected ?"
200799,"` everything that i have read has been in matrix algebra , which i do not understand ` why not dedicate one short evening to read about matrix algebra ?"
200862,could you explain more specifically what you think the obstacle to applying a $ chi ^ 2 $ test would be ?
200534,and what do you want to do ?
200971,"what does "" different "" mean ?"
200982,"are you familiar with marginal likelihood , bayes factors , prior / posterior predictive distribution , prior / posterior predictive check ?"
200983,why exactly do you want to transform an ordinal categorical variable to a continuous one ?
200866,what were the original measurements ( y-values ) ?
200620,"please include library calls in your code . i'm assuming ` gam ` comes from the ` gam ` library , but then i get an error since the function ` s ` does not have an argument k , did you mean df ?"
33197,i wonder . . . how does the hyndman et al . book treat the topics you list above ?
201220,"are you regressing $ x $ and $ y $ on a similar variable , such as $ z $ ?"
201243,"please explain the context of your question and tell us what the "" sd line "" is . although many people could make reasonable guesses , this is not a sufficiently standard term to be readily understood . and what , exactly , would a "" standard deviation point "" be ?"
131485,why not check for collinearity and see ?
201287,"i think you could try to specify better what you want to do and what you are willing to do , to allow people better understand how to help you . maybe it is just because i am not specialist in ( apparently ) some medicine field . based on my understanding of the partial picture you have provided , i could suggest to group values of a variable based on the literature ( can you find online what are people who used these data did ?"
199271,"exactly what kind of "" limit "" does ( 3 ) refer to ?"
201407,"you can't deduce correlation from slope . also , could you edit the first sentence to make it clearer ?"
201422,you appear to expect minimizing aic to lead to overfitting . what leads you to that expectation ?
201435,can you say something about what these functions might look like ?
201455,so what is the question ?
201549,"your "" quadratic denominator "" distribution is actually called a [ cauchy distribution ] ( url ) . [ note that you got the normalization factor wrong . ] can you explain the sense in which you're measuring how well the density is approximated ?"
201153,"what is "" that way "" for those of us who can't see it from the source code ?"
201582,are you looking at a [ chinese restaurant process ] ( url ) ?
201593,could you edit your post and go into more detail about the neural network you used ?
201605,"once you have differenced your data , why do you want to find significant autocorrelations ?"
201610,can you define some of your terms ?
201658,your question is quite generic . we need more input . is it a pairwise meta-analysis ?
201682,"do these "" wild "" estimates arise when the bootstrapped dataset samples very few cases , or the design matrix is very sparse so that the resulting logistic model has small sample bias , sometimes to such an extreme that the model is singular and point estimates are merely truncated glm fitting routines that landed on the boundary ?"
200590,do you actually want the log-likelihood or do you instead want the log-posterior ?
201724,why do you actually need feature selection ?
201721,you need to say some things about properties of complete sufficient statistics . . . what do you know ?
201723,how did you get the mean here ?
201783,"when i was doing a similar exercise , i would fix $ alpha $ and then select an "" optimal "" $ lambda $ based on cross validation across the folds . i would then measure the out-of-sample performance for the fixed $ alpha $ and the "" optimal "" $ lambda $ ( this would be an optimistic measure , but we are not generalizing it at this stage , so no problem ) . i would then change $ alpha $ and repeat all the same . once the grid of $ alpha $ s is exhausted , i would select the $ alpha $ that delivers the best performance , and the "" optimal "" $ lambda $ corresponding to the $ alpha $ . would that make sense ?"
201713,can you provide the explanation you already tried ?
201799,see also [ what is the difference between estimation and prediction ?
201840,"you said bic presumes that there is a "" true "" model -- and i offered a case when this is relevant ; it is relevant for the consistency of bic . however , should this be relevant for other properties or uses of bic such as model averaging ?"
201686,what about prior knowledge coming from past experiments ?
201862,"you should edit that new information into the original question , together with some more , preferably in the language of the application . how many variables ?"
201857,could you provide a reference to a textbook or lectures notes ( if any ) that you are following ?
200617,"are the weights included in the classification scheme itself , as with a weighted regression , or only in the accuracy assessment ?"
201894,"i do not understand what ( 2 ) is asking , because the mean of $ bar x $ must equal the common mean of the $ x_i $ . what , then , does "" $ x $ "" refer to ?"
201921,is this a question from a course or textbook ?
201953,what is unclear for you ?
201971,"since the gis is perfectly capable of accounting for any speeds you care to specify along the road segments , why not use it directly to estimate ambulance driving times ?"
202000,"if you're going to "" average raw items , "" it would seem that you have made no use whatsoever of the pca results . so what were you hoping to accomplish with pca ?"
202011,"i'm not entirely sure what you're asking . do you mean that you observe a number of pairs $ ( l_i , d_i ) $ where $ l_i $ is your variable of interest and $ d_i $ is the class that $ l_i $ belongs to ?"
202043,"why would you expect ols to "" yield suboptimal results "" ?"
202069,do you perform all calibrations for the same set of $ x $ values in every case ?
201537,"what is the meaning of "" expected value of dependent joint distributions "" ?"
202104,is centering in both cases the same - the centering of every _column_ of x ?
202121,first get straight why you want to remove any predictors at all if you thought them worth including at the outset . is your model over-fitting ?
202179,"why do you "" need to use the ratio of two variables as the dependent variable "" ?"
202180,"type-i error probability is $ p ( l ( x ) { c } h_0 ) = alpha $ . a notion of consistency that i am familiar with in the context of testing is * test consistency * , which says that $ lim_ { n to infty } p ( l ( x ) { c } h_1 ) = 1 $ . do maybe have a reference for "" criterion consistency "" ?"
202201,"yours is a good question , to my mind , but not yet formulated clearer . less technically - more substantially . what do you want to test , actually ?"
202221,"i think something worth mentioning is , when you reflect on what are trying to express by the phrase "" then the feature variable with that coefficient must have little predictive power "" , can you precisely lay out what that really means ?"
202239,can you clarify whether you are asking about 1 . 10 in general or just in the context of 1 . 10 with a ci which includes unity ?
201035,"is that the quotient of $ x , sigma $ , or $ x $ given $ sigma $ ?"
202249,"the phrase "" has a probability to die in $ f ( t ) $ "" makes no sense : perhaps some words are missing ?"
202264,"user333700 , why not post an answer explaining how & why the 2 models are not the same ?"
202265,"a couple of things to think about : my concern here is that you mention the tests being expensive and not routinely measured , which indicates that there is some kind of selection factor into getting the test done . what proportion of your study sample has the genetic markers ?"
202285,"just because they might lose with the odds you made up doesn't mean they'd lose with the odds they'd actually have . generally the returns are such that the bookmaker still makes a profit every time ( in some cases the additional money-back sweeteners might not be covered by odds but by other sources of revenue - are there any transaction costs that users bear , for example ?"
202307,repmat how so ?
202331,"just out of curiosity , should it not be that $ phi_ { 22 } = frac { theta ^ 2 } { theta ^ 2-1 } $ for ma ( 1 ) ?"
202356,could you clarify how what you are describing differs from bootstrap ?
202348,this is an interesting situation . can you provide your data ?
202374,are you asking how to decide among the polynomial orders ?
202291,"there are some ambiguities that make this question hard to follow . there is a "" cocktail party problem , "" but it would seem that any solution could be a called * a * "" cocktail party algorithm . "" moreover , it is not clear how relevant this problem ( or any such algorithm ) , which concerns source separation , is to the problem of "" detecting all words . "" which aspects are of concern : identifying speech ?"
111150,your question is lacking a real question as far as i understand it . can you clarify what you want ?
202432,are you only wondering how to integrate $ bar x / ( 1- bar x ) $ ?
202211,it's not entirely clear to me what you are using to bin your data . are you just trying to bin by certain predicted probabilities in order of increasing predicted probability ?
202445,what is it that you are predicting ?
202365,"what "" groups "" do you have here ?"
202435,( 1 ) the factor of $ 1 / sqrt { 2 } $ does not belong in the expression of $ f $ . ( 2 ) is $ t_m $ known to you ?
202553,have you worked out what the variance of this distribution is ?
202564,"your zero at present has some meaning . arbitrary additions will throw that meaning away . if you plot what you have as a bar chart , some groups will plot above and some below zero . what's the problem with that which would be improved by what you propose ?"
202485,this may be a dumb question : but which accuracy are you referring to ?
202586,when was this standard printed ?
202595,can you provide a small sample of your data ?
202605,could expand a little bit ?
202587,this question is unclear at least for cross validated since it does not even mention which language ( r ?
202664,what package is ` holdout ` a part of ?
202138,using the less-precise scale you have made just a single measurement ?
202681,what packages are pulling in ` na . approx ` and ` adf . test ` ?
202718,"i would begin by contemplating the "" obvious "" answers and pushing them to extremes . for instance , why shouldn't the answer be $ 42 times 5 $ minutes ?"
201878,isn't $ w ( theta ) $ nonnegative here ?
202164,"if you are interested in the development or accumulation of the treatment effect over time , it may be best to rename 'period' as 'time' , and to encode it as a continuous variable rather than a categorical one . how do you expect the effect to develop ?"
202776,""" in the test dataset the sign of one is changing from ve to -ve "" - what do you mean exactly ?"
202358,"can you please put the complete code as well as the input data ( lat , long , temp ) needed online somewhere ( say a github gist ?"
202132,can the occurences of the patterns overlap ?
202793,is this self-study ?
202824,what is ` xlvef ` ?
202890,do you know a pair of sufficient statistics for a sample from a normal distribution ?
202901,"since you have a video feed , can't you capitalize on the wealth of additional data it offers ?"
202912,what's wrong with just including them both ?
202941,does this help ?
202957,are you aggregating your sector measurements from something less discrete ?
202965,could you try to make your question more precise ?
202968,why don't you just use a numerical solver ?
202977,how do actual intrusions enter into this ?
202547,it is not really clear what are you doing and what you want to achieve ?
203032,so you know the integrals . why don't you take them ?
23983,"sorry , stphane , because my comments above did not take into account the fact that you only requested one component ( so deflation doesn't play a critical role here ) . however , it seems that your optimization function doesn't impose unit norm weight vectors , such that $ a ^ 2 b ^ 2 neq 1 $ in the end . ( btw , ` ?"
203017,"using the variances as * relative * weights was the right idea . however , they are not the variances of the means : those need to be divided by $ 50-1 $ if you want meaningful standard errors to be estimated . the resulting standard errors in the fit will therefore be approximately $ sqrt { 50-1 } = 7 $ times too great . ( i presume that $ 7 times 0 . 2 approx 1 . 8 $ due to imprecision in reporting these values . ) could you confirm that this indeed is the case ?"
203170,does this help : url ?
201790,why not sample from the posterior distribution using mcmc and average them ?
203200,a ) can you confirm you have an intercept or bias term . b ) i would just use regular logistic regression with l2 regularisation rather than on line gradient descent . the l2 regularisation puts a penalty on coefficients ( ie only deviate from average if there are sufficient samples ) . c ) look at relative deviance to the null model ( ie the log loss over the log loss of the intercept only model - ie give all ads the average ctr ) [ google pseudo r squared ?
203233,you could . . . but what if you have a bimodal ( or n-modal ) distrbution ?
203197,"in what way is this "" inverse "" ?"
203270,can you explain what you are doing ?
203277,how's that better ?
203278,"can you sample from $ p ( y_1 , y_2 theta ) $ ?"
203323,"your question is unclear in some places : when you said "" if they were the same , of course , red = red2 and blue = blue2 , "" did you mean the objective measure of "" they were the same , "" ( i . e . the researchers set red to be equal to red2 ) or did you mean whether the study subject * perceived * them to be the same ?"
203328,what about regularized regression ?
203348,"what do you mean by "" statistically viable "" ?"
203258,?
203404,how are you splitting ?
203384,how would you do this for one sample tests ?
203383,"i've tidied this up but one reference is incomplete and the other is missing . the first line of stata code is illegal . requests for stata code are off-topic here and the emphasis on stata code would stretch people more accustomed to other software . still , there seems to be statistical question buried here : can you make it more obvious ?"
203433,"if you ever wonder "" how can i do commonly used model in r ?"
203452,"on 2 . 1 , have you computed the overall probability of being late or the probability of being late and being on a flight provided by y ?"
203494,how much data you have ?
203506,can you display the acf plots or traceplots ?
203507,using a no-intercept model is questionable . what results do you get * with * an intercept ?
203535,"also , since dirrechlet is the conjugate of the multinomial , why do you need pymc for ?"
203519,"could you please explain what these probabilities represent and precisely how they provide information about "" dropping to a new low during the ten years "" ?"
203513,what is the dimension of the sample space ?
203673,what hashing algorithm was used ( or what do the final hashes look like ?
203688,if you know nothing about the function ` j ` then there is no hope to solve this exactly short of exhaustive search . however if ` j ` has some nice structure there may be efficient approaches . could you please share the form of your function ` j ` ?
203689,"this is definately not true in general , you're argument shows that you need to be able to conclude that $ pr ( bar x_n geq 0 . 6 ) = pr ( bar x_n leq 0 . 4 ) $ . perhaps you know something about $ x_n $ ?"
203730,"could you say a bit more about what you mean by your "" indexing model "" ?"
203755,welcome to cv . your question is a bit sparse in explanation . would it be possible for you to amplify or further elaborate what you mean ?
203773,"i think the assumption of independence is unlikely to be a valid one . do you really think that if someone has a two-wheeler , that that doesn't say anything about the probability that they have a 4-wheeler ?"
203792,"also , are you interested in estimating $ delta ^ { x_0 } $ as a whole or $ delta $ and $ x_0 $ separately ?"
203813,which is more expensive 1 ) running gmm background or 2 ) subtracting sequential frames ?
203828,why are you dividing the sample by 100 ?
203858,""" what are your thoughts "" is not a great fit for cv . can you make your question more focused & concrete ?"
203864,""" true at significance level  "" is a very unfortunate wording ( since it doesn't make any sense ) . but your interpretation looks right . what is suspicious about your numerical results ?"
203868,"by "" rejection / acceptance region "" , i assume you mean $ alpha $ , the type i error rate . what exactly do you mean by "" test statistic "" in this context ?"
203769,which blas do you use ?
203787,not sure what you mean by accuracy ( is this a nn for classification ?
203888,what's the model * for * ?
203833,what does the indexing over $ bf h $ mean ?
203932,the title to this question is based on a false premise . do you think it would be possible to rephrase the title so that it reflects better the content discussed in this thread ?
203950,"welcome to cv . unfortunately , the plot is * not * self-explanatory . you need to stipulate what your question is . does it have to do with the precipitous drop in price during the dot com recession ?"
203735,"do you mean * forecasting * future values , or identifying the true underlying trend ?"
204019,5 variables and 1 dependent variable . what about sample size ?
203227,what is the source of the question ?
203743,which paper ?
204095,"welcome to cv ! when you say "" none works , "" what we're the results and what were you expecting ?"
203872,what are x & y ?
204149,gung this question looks like a statistical one to me : what is this output telling us ?
203184,why do you want to use a wilcoxon test for data that is essentially binary ?
204194,what are the data ?
204210,what is the goal ?
204215,how are the error rates defined ?
204239,"could you please explain what a "" sharp "" difference is and what it might mean to "" sharpen "" a "" segment , "" "" cluster , "" or "" difference "" ?"
203269,"is your model a simple linear model , or is it a mixture model like you alluded to in the comments ?"
201146,"i must say that i have not ( yet ) read what matloff wrote on the topic , but still , in order for your question to stand on its own , can you perhaps briefly summarize why he finds any standard example of p-values usage not "" good / convincing "" ?"
204329,how about your losses after each iterations ?
204320,""" right way "" must be understood with respect to a * purpose * : what are you hoping this calculation will tell you about a "" walk "" ?"
204361,your second question is not clear . specifically what bayes factor ( bf ) are you trying to approximate ?
204382,what kind of model are you estimating with the em ?
204188,see ` ?
204403,if what is reported is the difference between them ( 0 . 2 in your example ) then presumably the range is -1 to 1 ?
204273,why chop the series into blocks any way ?
204463,"if - as you claim - there's an infinite number of ways of giving such a sample of values ( all between 0 and 100 inclusive which have a mean of 90 and a standard deviation of 33 ) , perhaps you could show us * just one * of those ways ?"
204521,did you center your data matrix $ m $ ?
204289,"ttnphns i think ismael's question is more broad , he wants a name for any $ f ( x_i , x_j ) $ matrix where $ f ( ) $ can be any ( perhaps only symmetric ?"
204486,"what does "" random "" mean here ?"
204573,what is your understanding of this situation for ordinary least squares regression ?
203836,could you make what you are asking more specific ?
204609,"seems like you mean conditional probability , aren't you ?"
204625,are you using the p-value to determine the strength of correlation ?
204626,"at the end of [ your first page ] ( url ) , it says $ f_ beta = frac { ( 1 beta ^ 2 ) pr } { beta ^ 2p r } $ , which , for $ beta = 1 $ , is the $ f_1 $ score . this is the $ f_ beta $ score , a generalization ( see [ wikipedia ] ( url ) ) . what did you mistake for the $ f_1 $ score in [ your link ] ( url ) ?"
204657,this does look weird . any chance of a reproducible example ?
204386,"adrian i see people are voting to close this question as too broad . it may be so , but as i see it you are basically asking : "" can cv be helpful if we are interested only in modeling , not in forecasting ?"
204752,"thank you for the edit . since i suspect the answer depends on what $ g $ specifically is , do you have a particular proposal distribution in mind ?"
204730,have you seen both ?
204569,the meaning of a correlation between two probability distributions is unclear . can you further clarify what you are computing and how ?
204799,"what does "" converting "" mean ?"
204802,"let's focus on the statistics here and forget about stata implementation , which is off-topic here . how are expected frequencies defined for your problem ?"
204826,"does this assume that tribbles began traveling at a particular time point ( so that there was tribble # 1 ) and continue forever since then , and the probability should be computed over this infinite time span ?"
204868,""" suddenly come across "" . . . where was this , and what , exactly does it say ?"
204839,giuseppebiondi-zoccai i admit my ignorance of limited independent variables . . . is that just like limited dependent variable but for independent variables ?
204909,"welcome to cv . first of all , this doesn't look like "" continuous ratio data "" to me . rather , it looks like ordinal , zero heavy count data . next , based on these two datasets , there are no points of agreement in # 1 and rater 2 in # 2 has no life events at all . finally , what is being rated ?"
204920,how do you define the concept of conjugate priors ( if not this ) ?
204883,"the description of model 2 is so vague that it may be difficult to give good advice . it even appears it involves more parameters than you have observations , suggesting it might not even be identifiable . could you present model 2 in a more explicit manner ?"
204902,"what's "" some resource "" exactly ?"
205000,"if the average of the kernel is nonzero , that kernel is effectively creating a * systematic * shift of the density estimate . do you really want to built such a bias into your procedures , especially when it's so easy to fix ?"
204994,i assume all the variables are positive ( or non-negative ) & continuous ?
173356,"it doesn't seem clear to me that the wording implies necessarily * sequential * factorization , as the observations are iid . during grad school , a professor mentioned that the product implies that one * could * use asymptotic approximations for bayesian analyses but strangely this had not caught on ( sarcasm ) . perhaps the book could be hinting at that ?"
204969,can you say a little more about your situation ?
205029,"i suspect that what you mean by "" novelty effects "" has something to do with unpredicted deviations that may be due to the drug under investigation , and if so then the answer is that you have no way to predict the size of them or their variance so you cannot conduct a power analysis to determine sample size . ( and note that you will need to do a confirmatory study before it can be safe to make an inference about them . ) is that what you had in mind ?"
205073,"kernel smoothing regression techniques don't need to do anything to add a data point ; the work is all at prediction time ( except in choosing a bandwidth , but you can probably do that much less frequently ) . do you need to keep a current set of estimates on some test points , or are you just asking about code to accomplish keeping the predictive model up to date so that test points can be predicted on at any time ( which is probably off-topic here ) ?"
205107,"if $ lambda $ is known to be 0 . 1 , how can you put a prior on it ?"
205120,"should "" exhausting "" be "" exhaustive "" ?"
205109,could you give references for * time-varying copula * and * dynamic copula * ?
204987,"if you used a complete data set , what would be the values of a subset in it ?"
205157,"welcome to our site ! i think this would be a clearer question if you could explain what the "" statistical error "" might mean that you refer to at the end ?"
205173,"good question ! is it also of some concern that two of the posted "" own "" price elasticities , i . e . , price a with alt aor price c with alt c , are negative ?"
204820,""" if i haven't made any mistakes . . . "" - did you check for mistakes ?"
205243,"bey , you wrote "" given a prior , a likelihood model , and the data "" . . . comments have to be terse . answers can be long , but i was intending to make a comment . do you need to ask a different question ?"
205253,possible duplicate of [ the two cultures : statistics vs . machine learning ?
205299,"don't bother about variable correlation , rf models handle these very well . if your purpose is prediction , you must remove the year feature as any new year will be an extrapolation . you may benefit from making a new feature defined as days ( or weeks or months ) away from brightest day on your hemisphere . lattitude is nice too . what are label ?"
205303,"so what is the sum of f ( x , y ) over these 18 combinations of x and y ?"
204810,"could you quantify the buzzword "" deep learning ?"
205401,how can it be infinity ?
205403,i see only 2 questions . was there a 3rd ?
205431,omitted variable bias is not the only econometric issue . endogeneity would be another one . do you have to write a project on okun law specifically ?
205423,is this what you are looking for ?
205450,are we talking about regression ?
205453,can you show your model in standard mixed effects notation ?
205472,"am i correctly interfering that you have only 5 examples of class 0 , but 456 of class 1 ?"
205520,is this a programming question or a statistics question ?
205503,"could you please explain what you mean by "" sort "" a histogram ?"
205532,area under what curve ?
205540,excellent topic . is it correct that all cited results are asymptotic for sample sizes going to infinity ?
205551,how many q-values do you have ?
205574,ok . could you be more concrete ?
205587,"ah ok , i see why you want to do that now . do you have an example of such a scatterplot ?"
205622,"what do you mean that there is a "" significant relationship between v1 = average and v2 = high "" , eg ?"
205629,possible duplicate of [ what information does a box plot provide that a histogram does not ?
205603,"before scaling your data , have you attempted a transformation of your features to get them normal ( i assume that would make your analysis easier ) ?"
205645,"what's goal of the survey analysis ( what parameters , associations , do you hope to estimate or test ?"
205660,how many observations do you have ?
205719,it's hard to say . i can't really follow this . can you give the model itself ?
205733,would it be fair to say that you are interested in a * supervised * learning algorithm where income is the target and the other features are predictors of income ?
205470,what data do you use to train your classifier ?
205813,"have you run an ols regression , yet ?"
204527,what does 'to perform an hypothesis test to realize about some assumptions' mean ?
205802,"could you maybe explain what you were _trying_ to do , mathematically , with those charts ?"
205830,could you make more explicit the sense in which you think of the iv as changing over time ?
205833,"it is unclear what is your data and what do you want your "" deterministic "" algorithm to do ?"
205853,"is "" $ x $ "" supposed to be a random variable & the "" $ x $ "" on the lhs a different rv ?"
205842,you might want to add some context ( what is the x-axis ?
205857,what is the goal of your modelling ?
205915,re the last equation : is that * really * what your book's formula says ?
205945,how long are you running the algorithm ?
205999,why it is useful or helpful to plot ranks in the first place ?
205803,"how do you define the "" best "" model ?"
206057,"have you investigated "" hashing "" algorithms ?"
206075,what does tan mean ?
205723,it's not clear what you're actually clustering on . do you have qualitative features of the menu items ?
205756,can you explain what your variables mean and what you're trying to model here ?
205555,analyst1 : can you explain where you take the covariance between $ hat { beta } _i $ into account and how you estimate it ?
206140,"can you explain what "" ratio y "" means ?"
206082,"could you add references to the sources you cite rather than just linking to them as "" source "" ?"
206216,"i think the answer is that you can't . that is to say , it wouldn't be possible to integrate massively categorical information such as ip address into a traditional , linear pca founded on continuously distributed features . of course , you can ignore ip address and run a pca on the non-categorical information . but mixtures of scale types -- particularly mixtures of "" normally "" distributed with 0 , 1 or dummy features -- are a challenge for pca . would you describe your data matrix ?"
205954,dole would a toy simulation be helpful ?
206279,"as you discovered in your previous answer , your definition * is * different . so what are really trying to ask here ?"
206287,"we won't be able to answer this question unless you disclose the details of your application of the formula . presently you seem to be saying that you attempted to carry out the illustrated calculation in the wikipedia article , $ $ 0 . 4 times 80 0 . 6 times 90 , $ $ but that you didn't get $ 86 $ as the answer . maybe you should find a working calculator ?"
206343,what do you mean by 'group of people' ?
206380,"there are so many questions like this on cv . why not start by browsing the threads on the right side of this screen or typing "" time series ___ "" into cv search , substituting one of the acronyms you're curious about for '____' ?"
206195,"this sort of question was asked several times here , i expect . did you try first a search of ` clustering binary sparse ` ?"
206401,"for a difference of means wouldn't you compute the observed difference and then the differences for the bootstrap samples and form confidence intervals using these values for the difference itself , rather than for individual means and trying to interpret overlap ?"
206417,"questions that are only about how to use r are off topic here . it isn't clear if this is a statistical issue or a purely r issue ( which is how it's presented ) . can you say more about your situation , your data , your analyses & your goals here ?"
206149,"could you post some pictures of your result , alongside the proposed growth curve ?"
206081,"this question is completely mystifying . what are "" breakers "" ?"
206462,are your predictors discrete or continuous ?
206468,shouldn't the prevalence of drinking mothers also be a binomial ?
206501,"` but in the scree plot there is no elbow at all ` . sara , why not show the scree-plot to us or give your data ?"
206539,what is that you are trying to do ?
202343,"without additional assumptions , this seems unlikely . ( let $ alpha_i = 1 $ for simplicity . let $ epsilon gt 0 $ be small . suppose that associated with each $ f_i $ is an interval $ i_i $ on which $ f_i le 1 $ and $ pr_i ( i_i ) gt 1- epsilon $ , outside of which $ 0 lt f_i lt epsilon $ , and $ i_i cap i_j = emptyset $ for $ i ne j $ . then the separate generators would almost always produce values in $ i_i $ , but the probability of $ prod f_i $ could be concentrated * anywhere , * seemingly unrelated to the $ i_i $ . ) so , what else can you tell us about the $ f_i $ ?"
206579,are the percentages ratios of * counts * or are they continuous fractions ?
206532,it depends on what your question is ?
206592,question : is it possible to control anything without applying some correction ?
206652,"it might be beneficial to also assume that $ n geq2m-x $ , otherwise i think x similarities are guaranteed , but the formulas may not work . is this a valid assumption ?"
206655,"( 1 ) presumably you are asking to demonstrate asymptotic normality of the * solution * to the foc ( "" first order conditions "" ) , not asymptotic normality of $ beta $ itself . ( 2 ) what is the relationship between $ beta_0 $ and $ beta $ ?"
206697,"( the first equation does not clearly define a function . if you intend it to define $ hat p $ implicitly in terms of $ beta_0 beta_1 $ , then it's * identical * to the second formula . ) in what sense do you mean "" more symmetric "" and why would it matter ?"
118115,"i guess if somebody voted to close that other q when it appeared it might have been closed , but by now i think the answers there are surpassing the answers here . so i am reluctant to vote to close that one as a duplicate . we can close your q as a duplicate of that one though , or we can try to ask mods to merge one of the qs into another ( this means that the answers will get moved to the other thread ) . what do you think yourself ?"
198535,could you please include the plots into the question as to avoid readers to re-run your code [ and install two packages ! ] ?
206726,"havesspeas wrote "" on average , the time interval is 2 . 4 minutes between trains , so [ i think ] intuitively , i got the answer that p ( x = 6 ) = 1 . "" your intuition is wrong , and is obviously not attuned to probability calculations , so don't rely on it ( or use it at all until better developed ) . systematically work through the mathematics of the probability calculations . do you know what a poisson process is , and how it relates to the probability distribution of time between events ?"
206620,"i am not clear about your question . what do you mean by "" features selected by lasso as a kind of validation for selected features "" . also , i am not clear about "" using different thresholds "" ?"
206817,"some basic data analysis might help here . you say the rate is 2 % overall , but what about by various predictor variables ?"
168254,do you have 60 owner's and walkers ?
206864,outcome1 and outcome2 are independent as well ?
206896,maybe you just don't have good variables for prediction ?
206907,"i get "" restricted page - you have reached your viewing limit for this book "" . what did it say ?"
191609,can you provide a simple example dataset for the reliabilities & the descriptive statistics & results from the prior study ?
206959,"two closely related questions you might want to look at : [ in statistics , should i assume $ log $ to mean $ log_ { 10 } $ or the natural logarithm $ ln $ ?"
206970,what is $ f $ ?
207009,are all 6 million non-cases relevant to the study problem ?
207010,did you manage to solve this issue ?
206991,"are you sure about putting the emphasis on test results for stationarity ( adf , pp , kpss ) vs . autocorrelation ( dw ) ?"
206876,your notation isn't terribly clear . what is $ k $ ?
206690,this reads like a reworded version of a routine textbook-style exercise . is this work for some class ?
206877,does the proportional hazards assumption hold in the first model ?
207074,"i don't understand your data . if ` match ` is a factor , why does it have values in the hundreds ?"
207090,"what do you mean by "" compare "" ?"
206997,hi moskowitz . is my answer going in the direction that you were hoping ?
206897,"i don't think you are going to get much help unless you either post your code and the output ( perhaps using a public dataset like the oaxaca . dta that's bundled with stata's ` oaxaca ` command ) or you show us the mathematical formula for your decomposition . as it stands , this is akin to saying i made coffee and there's something floating in it . what could it be ?"
207184,why do you need a null hypothesis in this context ?
207218,can you please cite the paper you refer at ?
207271,not really answering any of your questions : with humans it's common to deal with the height / weight correlation by combining them as bmi ( url ) ; maybe that works just as well for eels ?
207121,"there can be asymmetric distributions with mean , median and mode equal and they need not be pathological . for example , binomial distributions often qualify . more seriously , near equality of these measures doesn't rule out a small fraction of outliers which could dominate analysis . that is a bigger deal than the result of shapiro-wilk . what's the sample size here ?"
207307,"typically , the predictors are assumed fixed , or conditioned on , so assuming the error vector to be normal does imply the estimators are normal . are you considering x fixed ?"
207314,"are you using estimator = ml , and estimator = wlsmv ?"
207264,"nice question ! but i'm confused by the claim that $ 1 / sqrt n $ doesn't converge , what did you mean by that ?"
207339,"you are struggling because the gm makes no sense for non-positive numbers . instead of searching for meaningless extensions of it ( such as complex values ) , have you thought of using a different estimator of scale ?"
207346,no . of organs a donor will produce ?
207348,do you mean that the difference in the original pairs is lower than if the rows are randomly shuffled ( and destroying the original pairs ) ?
207326,what do you mean by 'random process' here ?
207387,what kind of % s are they ?
207355,what kind of results do you get when you use the model that was built on the extremes and apply it to * * all * * data ?
207403,""" however , i know the range of values "" . . . do you mean by this that you know the highest and lowest values in the sample ?"
207404,"to rephrase to see if i have well understood , you have n variables , and for each of these n variables you have t observations , is that right ?"
207425,do we ?
207500,do you mean 2x2 table ?
207509,"this question is way too broad , how does you dataset look ?"
207527,"so you are measuring one variable $ 36 $ times ( once per month ) for $ 12 $ groups . in terms of maths you could write your data as $ y_ { ijt } $ where $ i $ is a sample ( $ i = 1 , . . . , 4000 $ ) , $ j $ is the type ( $ j in { 1 , . . . , 12 } ) $ , and $ t $ is the month of measurement ( $ t = 1 , . . . , 36 $ ) . is this correct ?"
207383,welcome to the site . can you edit your question so that the image embedded in the post instead of us having to click on the link to see it ?
202729,"hastie et al . in this formula and in the quoted paragraph use $ x $ to refer to the vector of predictors , not the model matrix . it's a column vector , hence it needs to be transposed . in contrast , in ( 1 ) the same letter $ x $ refers to the model matrix where each vector of predictors ( one sample ) is a row . hence the lack of transpose . does this resolve your confusion ?"
177840,"i am off to catch a flight , so i will write more later , but yes , you could use either a mixed effects model or you could use the method of generalized estimating equations . but first to questions : are you interested in the associations or effects of the individuals in your study or are you primarily concerned with the population as a whole ?"
206806,imagine your colleague had not included the i don't know category . what would those persons have answered ?
179658,"would you clarify what an "" irr "" is ?"
207612,what quantity is it you seek a ci for ?
207669,"( 1 ) interesting question but . . . how do you defined "" caused by "" ?"
207700,which presentation ?
204141,"your question contains the term "" f-regression "" . what's that and how is it different from regression ?"
207589,are you familiar with the kolmogorov-smirnov test ?
207727,what correlation matrix are you referring to ?
207745,"another question you might like to consider is "" what is the probability of four out of four kids all being born on the same day of the week ?"
207815,can you explain what do you mean by * * fit vs test * * against * * fit vs train * * ?
207748,please try to make your question self-contained - could you at least include the formula and the relevant excerpt ?
207714,please edit your question to add a link to the paper in question . what is the statistical significance of each of the parameters ?
207357,do you have a group of firms / regions / etc . that you are trying to forecast or just a single one ?
207945,do you have any censoring ?
207946,is that not perhaps rather a binomial outcome - perhaps with some way to reflect that there is a respondent effect ( leading e . g . to beta-binomial regression or a generalized linear mixed effects model with a random respondent effect ) ?
207963,technically you should not be taking the mean of a likert scaled response since it is ordinal . of course people routinely do this with 5 or 6 category response sets . you'd be adding another layer on this by converting the mean scores to z scores so now you're building in standard deviation into the scores as well ( which is not appropriate for ordinal items such as yours ) . so can you do it ?
207999,how do you justify removing the outliers other than this making things more normal ?
208005,"the chan , golub , and leveque paper addresses numerical computation of sample variance , and is not really focused on sample mean . which are you really interested in ?"
208022,"does it make sense to use stock volatility as the measure for the event of "" walking away "" happening ?"
208023,"if you know that the $ x $ and $ y $ directions are orthogonal , why not estimate their medians independently ?"
208037,thank you ; that helps . but then isn't the domain of $ hat f $ exceptionally clear from the notation ?
208052,try a wilks-shapiro test for normality ?
208057,you ask about combinations or permutations ?
208123,could you provide a plot of geneticevents ?
207553,"* what * a statistic estimates is for you to stipulate ; it makes no sense to ask about it . ( that would be neither a meaningful statistical nor a mathematical question . ) what would make sense as a question would be something like "" what properties does $ underline { t } $ have as an estimator of such-and-such ?"
208209,"you talk of "" use "" and "" computationally efficient "" but it's not quite clear what you mean . are you talking about data to be used in regression analysis or classification ?"
208064,"you're missing a lot of context and definitions that are needed to make sense of this question . what does "" $ x_i x_i ^ prime $ "" mean ?"
208191,"what are $ a_t $ , $ mu_x ^ * $ , $ sigma_x ^ * $ ?"
208229,how many classes are you dealing with ?
208253,why not a model explicitly designed for count data ?
208248,what are you trying to model ?
208286,draw a horisontal line ?
207864,"if i'm understanding correctly , wouldn't $ e ^ { -3 . 9365491x } $ itself be the weighting function ?"
208274,"the question is not completely clear to me . so in essence , you want to calculate how many installs one paid user brings ?"
208221,are you sure the seasonality is still there ?
208277,"1 . ` ols ` is not a function that comes with r ; neither is ` rcs ` . if i paste your code it in would not run . presumably you're using the package ` rms ` , but you should state so explicitly rather than leaving people to guess . $ : $ 2 . it looks like your question is already answered at the bottom of your code -- ` function ( f ) ` produces the equation you seem to be asking for right there in your output ; an equation directly in terms of splines . what were you seeking that's different from that ?"
208308,are you sure you have the exact same data ?
208329,have you any references ?
208362,"do you _have_ to find the pdf of $ y $ first and then integrate it over the negative real line , or can you use the method pointed out by mpiktas which avoids finding the pdf of $ y $ ?"
206821,throughput is requests per second ?
208408,what is it you want to know about these measurements ?
208436,should the bound depend on $ p_1 $ only or should it reflect known values of all the $ p_i $ ?
208437,"what makes you think that the p-value should be "" adjusted "" ?"
208439,if you are interested in testing $ h_0 : ; ; f ( y_i mid c ) equiv f ( y_i mid d ) $ you could simply use a two sample k-s test . url are you looking for somwthing else ?
208430,what do you mean by sparse data ?
208456,"if you want to go bayesian , i would recommend familiarizing yourself with url however , i'm not sure that taking a bayesian approach will improve your accuracy . maybe you could considering changing the frequency of your data ?"
208268,this isn't really clear . can you give a concrete example to illustrate what you want to do ?
208495,"thinking about your post . . . if fisher decided on rejecting the null only if the lady was right on all her guesses ( i think that was the case ) , and there is only one possible way of getting all the cups right , shouldn't the probability of this taking place be $ 0 . 9 ^ 4 = 0 . 6561 $ be the actual power ?"
208502,it isn't clear if this is a code problem ( off topic here ) or a machine learning conceptual misunderstanding ( on topic ) . can you clarify ?
208533,just to clarify you want to use the ad-statistic to check what ?
208580,"what's wrong with * weighted random sampling * , besides merging similar objects ?"
208583,"whatever you model , why don't you apply the standard engle-granger test ?"
208608,"by "" independent variable "" , do you mean x or y ( predictor or response ) ?"
208602,"once a distribution is asymmetric , it's no longer clear what is meant by "" centered "" . do you take to that be mean zero ?"
208632,"when you take a sample , how far away from the true mean would you expect its mean to be ?"
208470,` performed an anova ` ` the dependent variable being the diagnosis ` . you did anova with nominal dependent variable ?
208708,"the graphic is exceptionally misleading . * the horizontal axis is not linear . * it is visually symmetric , implying that the distance between the "" 10 % "" and "" 25 % "" marks should equal the distance between the "" 90 % "" and "" 75 % "" marks . but those two distances are 42 , 910-33 , 430 = 9480 and 96 , 110-76 , 160 = 19950 . its lie factor of 19950 / 9480 = 2 . 1 is high . thus , the interpolation methods suggested by the graphic are unlikely to be accurate . could you tell us anything more about this "" standard distribution "" ?"
208720,may we assume the numbers are equally likely and drawn without replacement ?
208763,did you debug this out ?
208421,"( 1 ) you use "" wp "" for two different quantities--could you fix that ?"
208794,where did you get the data ?
208856,"i've tried typesetting your question a bit more neatly . please feel free to revert any changes if i have accidentally damaged anything during the formatting . could you clarify whether by "" devore's "" you mean * probability and statistics for engineering and the sciences * by jay l . devore ?"
208885,"i don't see ` e ` defined anywhere . is ` z ` supposed to be ` c ( x , y ) ` ?"
208914,is this table yours or someone else s ?
208909,could you define more precisely what you mean by population monte carlo ?
208858,it's not entirely clear to me what you're asking here : is it just help with the code ?
207876,what is your precise question ?
208970,"try also the similar questions on this site , e . g . [ "" does correlation assume stationarity of data ?"
208979,what is the $ s_t $ ?
208992,"could you give a reference for * in linear regression the errors are assumed to be normally distributed , conditional on the predicted value of y * ( if you have any ) ?"
209017,"are you asking about fitting the model , or about how predictions are made once the weights have been estimated ?"
209037,i wonder what is the gain from modelling non-network data this way . you seem to be asking 'why not ?
209045,at first you need to understand which type of distance will satisfy you . is euclidean distance ok ?
209027,"can you define your variables : are $ theta $ and $ z $ supposed to be the topic distribution per document and the word distribution per topic , respectively ?"
209065,"it depends on a lot of things , doesn't it ?"
209069,"perhaps a swtich to polar coordinates , after switching to independent rvs x and z ?"
208526,should $ triangledown x_t = alpha triangledown x_ { t-1 } w_t $ read $ delta x_t = alpha delta x_ { t-1 } w_t $ or is this some notation i haven't seen before ?
209087,"do you want to know the best growth temperature for a 'generic' fungi strain , of which the types listed in ` iso ` are just a subpopulation ?"
76219,what is your _question ?
209196,"sure , why not . ( i first thought this question might get closed because it's not connected to statistics closely enough . ) i like your approach . however , isn't the y axis redundant , now ?"
209222,"i'd expect to see a dataset- or subject-matter specific reason for choosing which variables to enter into the ` inflate ( ) ` option . absent that , a project looks like a fishing expedition . although it is fairly obvious , i'll underline that these models aren't always easy to fit ! how many parameters are being estimated here and how many observations do you have ( please make both explicit ) ?"
209237,"$ $ x sim text { poisson } ( lambda ) $ $ can you write the distribution of $ 1 x $ , perhaps as a pdf using case notation ( if . . . then . . . ) ?"
209253,what's your intercept ?
209264,"url tells you the mean and the variance , which you can plug into the formula for $ vi $ . if that doesn't fully answer your question , could you explain what you mean by "" maintaining "" a definition ?"
27297,if you type ?
209340,"this is a routine textbook-style question as is commonly set as an exercise ( indeed , i recall answering a version of it for an exercise when i was a student ) . you should add the ` self-study ` tag and follow the guidelines at the self-study [ tag wiki ] ( url ) on asking such questions . in particular you should ask about specific problems you have encountered in your initial efforts -- what did you try , and where did you get stuck ?"
209263,can you explain the norm $ cdot _ { tv } $ ?
209395,"hint : what is variance of number of successes , and therefore of sample proportion , in a binomial as a function of p ?"
209377,how many variables do you have ?
209437,two questions : 1 . how many elements do the clouds $ x $ and $ y $ have ?
209213,"how about creating groups based on geographical regions , such as northeast , southwest , etc . , that are more meaningful from the business perspective ?"
209482,user164945 why do you think you are not correct ?
209560,"second line should read $ p ( a , c b ) = sum p ( a c , b ) p ( c b ) $ right ?"
209578,markov switching ?
209595,"could you clarify what you mean by a "" standardized t distribution "" ?"
199583,why are they euthanised ?
209619,"1 for showing admirable effort ! however , this is a very , very , long question . would you be able to break it up into several questions ?"
209575,i appreciate this is not a direct answer to your question but would you not want to include an offset to account for city size ?
209624,"( 1 ) this situation is impossible if the computer is truly guessing . what mechanism is operating to limit the numbers of correct guesses and to assure equal chances of 0 , 1 , or 2 correct ?"
209665,"is your data inherently ordinal , as robertf appears to assume ?"
209689,you can still use mixed models if your independent variable is changing over time . or am i misunderstanding your question ?
209741,why do you want to keep a sum of other variables in the model ?
209754,what is the ar1-2 test ?
209770,"i think this really needs more information e . g . about the nature of the data gathered . are you talking about how the [ effective dose ] ( url ) ) might be measured , or rather about how it might be predicted on the basis of other information ?"
209812,"could you explain what the first set of results you presented after "" the tutorial indicates that a significant eigenvalue is required even if the test statistics passed "" means ?"
209655,i am honestly not sure . why does it have to be the tukey method ?
209876,to be clear : are you trying to see whether the differences between the two organizations in the effect of centralization on innovation ?
209902,there was somehow similar topic [ here ] ( url ) . i am not sure if i understand you - do you have any independent variables ?
209909,"which textbook do you mean by "" the textbook "" ?"
209934,what about your result doesn't make sense ?
209874,any idea how to make the intervention have long time influence ?
209998,thanks ! but is there ever a cdf that is not strictly increasing ?
210007,it is very difficult to assess such plots when the x variable is so skewed as the spread of the points will be greater where there are more points . have you thought of working on the log scale ?
210015,"frankharrell so , the chunk test for linear and quadratic terms would provide evidence for whether or not * both * terms are zero . in the case where one term is zero but the other is not , how would this test help in understanding which was which ?"
210031,"that's quite a tricky question , and a good example of why you should think through your analysis plan before you design a study . is your hypothesis only about option c ?"
210058,"why not take the hint and relate $ nx_n $ to $ z_n $ , then apply the first results ?"
210039,"re the new criterion ( 4 ) : that's always a wise thing to ask for ! since the cdf of the maximum of $ n $ iid values drawn from a distribution $ f $ is $ f ^ n $ , and its derivative is $ nf ^ { n-1 } f ^ prime $ , you will need a distribution for which $ f ^ n $ has a "" nice closed form "" for all $ n $ , suggesting you rewrite $ $ f ( x ) = e ^ { g ( x ) } . $ $ now we're back to where we started . . . . if you can't speak to the left tail , the need for scaling , symmetry , or other useful characteristics , maybe you could say something about the phenomenon you are trying to model ?"
209864,is it possible some of your observations could come from table salt water and others from seawater ?
210117,javlacalle : the post you link to is completely different . did you paste in the wrong link ?
210112,"just to clarify , you don't have 16 samples , you have 16 observations from a single sample , right ?"
210123,is this a question from a course or textbook ?
210154,"what is "" z "" in your equation and what is its semantic ?"
210227,how do you measure that the 4 features are indeed relevant ?
209841,"the point is elementary . suppose i count with error and my values are integers like 0 , 1 up . how i am better off rounding to even numbers or to the indicator above or below 5 ?"
210291,"in any case , i think , you mean at least the centered data ?"
208780,the fact that you explain so much variance with your specification is puzzling . is there a table in the paper you're tring to replicate that corresponds to the table for your fixed-effects ( within ) regression ?
210309,what is id ?
114944,does this answer you question ?
210001,"so , your output looks like , say , base . a = to_match . b , base . b = to_match . d , and so on ?"
210380,"show what you tried so that we can identify where you went wrong . the correct integral is * very * easy , yielding to obvious application of routine integration methods . how did you do $ e ( x ) $ ?"
210207,is either everything or nothing in a bin expired ?
210423,do you have a single observation for each distribution ?
210424,"you're trying to predict a ( 0 , 1 ) variable . i can't see why you're being advised to carry out linear regression as well as logistic regression : logistic is the better model . for logistic ( or indeed linear ) regression the distribution of each predictor need not be normal . if you're screening possible predictors the distribution does indeed bite a little for the t test , but i don't think that should matter much for your purpose . why not plot your possible predictors and the response to think about which to use ?"
210451,can you paste in the output you are having trouble interpreting ?
210483,"although this result is difficult to [ search for ] ( url ) , it has been shown in dozens of threads . the first relevant hit turned up by that search is url where a generalization ( to regression involving more than just a constant , as here ) is proven in several ways . but since you don't recognize the formula for $ hat sigma ^ 2_k $ as the standard definition of a sample variance , exactly what do you understand the variance to be ?"
210512,the question discuss framework transformation . you could tag it this way ( you used already 5 tags ) . there is still no framework transformation tag . why does the question has a svm tag ?
210307,"suppose the six tests are labelled a , b , . . . f . have you predicted that ( for example ) a , b , d , and f are the ones which are significant or just any 4 from 6 ?"
210535,do you have a full working example for the second step ?
210409,"can you be more specific about what "" doesn't work "" means ?"
210539,"welcome to our site ! have a look at our [ help / on-topic ] to get a feel for the kind of issues that are considered on-topic here . a lot of this question seems to revolve around debugging code , which is explicitly outside the scope of this site , but it seems you might have a genuinely * statistical * ( rather than coding ) issue here too . do you think you could edit your question to refocus it on the statistical aspect and de-emphasise the debugging ?"
210563,before i started worrying about partitioning the heterogeneity i would be concerned about whether the $ y_i $ are normal . if they are standard deviations it seems unlikely ( and how did you estimate their standard errors ?
209907,what statistical property holds when a distribution is memoryless ?
64759,what do you want to do with $ alpha $ and how do you plan to use these data afterwards ?
210619,what makes you think that ` badai ` should have a lower auc ?
210646,do you just want a hazard that depends on covariates but that is constant over time for each tree ( no age dependence ) ?
210661,why do you need to transform your data in order to calculate a correlation ?
210681,"are you asking how to find an angle , given its sine and cosine ?"
210692,are the two columns headed 2 . 5 % and 97 . 5 % not the limits of the confidence interval ?
210697,wouldn't total ice cream melt in a county be more closely related to population of the county than to its area ?
210742,could you just flip the ratios ?
210413,url ?
210727,"depends on what you're trying to do . are you trying to see if there is a bivariate association between $ y_i $ and each $ x_n $ , or do you know if there is a relationship between $ y_i $ and $ x_n $ , after controlling for other $ x_n $ ?"
210865,can you provide more information about your situation ?
210880,"when you say the data do not fit the assumptions , do you mean that the data are count data and are therefore not normally distributed ?"
210896,are you saying you wish to randomly sample individuals from a population and then estimate the density of residence throughout the city grid ?
210914,"so $ log { frac { pi } { 1- pi } } = alpha a s r . fn $ , right ?"
210919,have you read url ?
210925,"you'll need to provide more information . for example , what is 3d6 or xdy ?"
210932,( 1 ) how many years do you have in the panel and what is your research question ?
210933,welcome to cross validated . it seems you have a statistical question somewhere in there buried under a ton of code . questions that are solely about programming are off-topic for this site and may be removed . can you edit your question to emphasize your statistical question ?
210849,"the question as currently posed asks about "" the derivations behind regularization "" , and this is simply too broad . the derivation of equation ( 4 ) in the paper is proposed as an * example * . this is different from a question that * explicitly * asks about a specific derivation , which [ as i wrote ] ( url ) would * not * be too broad . does this explain why your question was closed as "" too broad "" ?"
210979,"i don't get your assertion "" p-values make sense if i assume an unlikely event already happened "" ; can you explain your reasoning ?"
210981,could you edit your post to emphasize the question ?
210987,"it's not quite clear what you're asking for . how does the "" correlate when they're low "" work ?"
211000,"if it was inverse gamma , how would it come to have terms like $ lambda ^ 2 $ in the exponent ?"
210960,ssdecontrol : why don t you edit that into the question ?
211007,"anyhow , that's a whole heck of a lot of exponentiation . do you have a good rationale for this function ?"
211071,the answer seems to be in your title and in your question . you need to run a multiple regression analysis . if that is not what you need then can you expand your question to tell us why that does not work ?
211086,"let me check my understanding at a high level : ( 1 ) in each step of this algorithm , either the "" distortion measure "" ( strictly ) decreases or else convergence is declared . ( 2 ) there are finitely many "" sites "" to cluster . ( 3 ) any solution--a "" cluster assignment "" --is a partition of the sites ( into "" clusters "" ) . are these characterizations correct ?"
211101,"could you , please , explain this : "" in other words the result can be right in either 4 / 4 , 3 / 4 , 2 / 4 , 1 / 4 or 0 / 4 of all cases "" . what does the first number represent ?"
211180,question 2 : [ diebold-mariano ] ( url ) test ?
211206,have you seen a definition of ( weak ) exchangeability ?
211209,how can be p ( x omega1 ) = 2x for 0 = x = 1 ?
210944,you used ` decomposite ` in r ?
211216,"by introducing subscripts on $ a $ and $ b $ you are suggesting that $ s $ is either finite or countable ; thus , you seem not to be looking at all such transformations , but only a predetermined set of them . that could greatly complicate the answer . could you clarify what you're trying to ask ?"
211263,what is a b c d and are you looking for results on the basis of complexity as a variable ?
211268,what if businesses which generate large amount of waste are more likely to recycle than those with small amount of waste ?
211250,what * are * you seeing ?
211160,"is your vector of parameters really of the same dimension as your data set , $ n $ ?"
97581,"sphericity assumption does * not * require anything about the covariances of the differences . it requires only that their variances are equal ( but not necessarily equal to one ! ) . see e . g . [ an introduction to sphericity ] ( url ) . in his comment , ttnphns wrote that sphericity "" implies "" that the covariances are zero , i . e . his statement seems to be that if the variances ( of the differences ) are the same , then their covariances have to be zero . perhaps he can comment himself on why this should be the case ?"
211379,are you plotting the residuals against the fitted values ?
211436,"i don't know the answer , but have you tried each of the method ?"
211466,what is the actual model here ?
211473,"do you have only one x variable , or are there others besides stress ?"
211479,"as best i understand this , you are summing the variances of x's only . why would that be related to correlation ?"
211514,what question does a cdf answer ?
211555,what kind of data are you working with ?
31876,it is not at all clear what your question : * the rho formula divides the covariance by sd of x and sd of y . does it result in validy coefficient ( or true correlation ) for the population . * is asking . i'm having trouble linking this to the question posed by your title : * what is the effect of scaling down covariance in the formula for rho ?
211574,are you asking about the specific situation $ m = 4 $ and $ n = 3 $ ?
211561,"this is basic linear algebra , are you familiar with any linear algebra ?"
211627,"mark yes , seeing multiple solutions to a problem is instructive . but it's unclear what you are reacting to . do you refer to your proposal as "" circus tricks "" because neither $ z ^ { } $ nor $ z ^ { - } $ has a density ?"
211468,what are d & p here ?
211668,"do you mean "" logarithmic distribution "" as in url if not , then what ?"
211697,"by "" calculus training methods "" do you simply mean methods that make use of derivative information ?"
211742,"you need to provide much more information than this . what are $ b $ , $ s $ and $ phi $ ?"
211745,"it looks okay , so maybe the bug is in one of the functions you use . can you show the code of ` trainlinearreg ` ?"
211840,who's to say that any more accuracy is possible ?
211852,"what do you want to use your "" distance "" for , and at what phase of the modeling , "" solution "" , or model results analysis process do you wish to use it ?"
211886,where does your data come from ?
211950,"just from your plot , it seems your model is overfitting---it captures the training data too well . how did you select the hyper parameters ?"
211984,"specifically , the sentence "" my next goal is to find a sweet spot , ie a point very [ where ?"
212007,are those percentage values ?
212028,did you shuffle your input samples before training ?
212056,"when you write $ lambda $ , you are referring to the tuning parameter , right ?"
212084,"i didn't follow what you meant by "" too many dimensions "" : isn't this a poisson process * in time * , with just one dimension ?"
99683,can you write down how they're specified mathematically ?
211951,"could you add an ( non-code ) explanation about what the experiment does , and show the results ?"
212117,"i wonder whether there is any useful information in the starting states of each chain . ( for instance , if these mini-chains are random segments selected from a single larger chain , the distribution of starting states might reflect a stationary distribution . ) could you tell us how those starting states were determined ?"
212105,why does it feel wrong ?
212120,"gee they might have started you off with something simpler , where the signals are a little clearer . if we assume that the data are drawn from an arma model , it's hard to guess its order from this , but it's at least arma ( 1 , 1 ) and there's some indication of seasonality at lag 12 , possibly an sar component -- * is it monthly data * ?"
212203,"interestingly enough , we [ don't seem to have a question ] ( url ) on this simple question . this one comes close : [ what does positive skew show ?"
69001,"jasonmorgan i agree with what you say but currently ` mcmcsamp ( ) ` is not available because of a number of issues ( one can check the ` status of mcmcsamp ` section in glmm . wikidot . com / faq for more details ) . i feel that at the moment time , probably ( parametric ?"
212068,there is no equivalent of ` if vertrauen - . 0001 ` in your r syntax so far as i can see . show us the results of ` summarize uw goodguy ` in stata . can you get the same results if you omit the interaction term in each case ?
212289,"what do you mean with "" i only have unobserved points and for some of them i have upper and lower bounds "" ?"
212322,perhaps zero-inflated poisson regression ?
212350,how * exactly * have you specified the model in your r script ?
212356,"are you sure of the "" condition "" formula ?"
212257,please check again -- should there be a squared term in the numerator of your test statistic ?
212410,"thank you . i am still puzzling over what chi might mean by "" statistically equivalent . "" does he define that anywhere in the paper ?"
212439,"in the paper you linked , they use an mlp classifier , with a hidden layer , purportedly with a 99 . 45 % accuracy . would this not suffice for your purposes ?"
212445,"your questions are thoughtful but there are several of almost unrelated ones here . it's usually not a good strategy on cv , it's better to ask clearly focused questions , one at a time . ( q1 ) why does fa extract only one factor ?"
212452,"could you elaborate on what you mean by "" sample from a discrete set "" ?"
212574,"what does "" vars = 3 "" mean ?"
212472,"welcome to our site ! you probably should specify the context you mean - are you specifically interested in [ simple linear regression ] ( url ) ( "" y on x "" , the bivariate case ) rather than multiple regression ?"
211663,"what do you specifically mean by "" resample the validation set ?"
212622,"it is unclear what is your question , could you clarify ?"
99125,my question when looking at the figure is : what is $ i $ ?
212607,what's your question ?
212679,can you share the link for the tutorial or anywhere that shows that the result should be a uniform distribution ?
212703,have you considered doing nested cross-validation already ?
212695,see here : url does it clarify ?
212500,"looks like you are right . have you considered looking at the "" big picture "" and thinking of $ s $ as the interior of a right triangle with base $ 2 $ and altitude $ 4 $ and finding the area that way ?"
212744,can both happen at the same time ?
212263,"a question that is stated this abstractly needs to be utterly clear about the meanings of its terms . in general a "" physical model "" involves no stochastic components , raising the question of the sense in which you mean "" independent . "" what is the source of the implied randomness in your models ?"
212758,"presumably by $ mu sim n ( 0 , 1 ) $ you are referring to a prior rather than a distribution on a higher level of a hierarchical set-up ?"
212832,"i wonder whether this might be a better fit for economics se , in its current incarnation ?"
212856,"could you explain what you mean by the "" product of two binomials "" ?"
212840,"i tried to highlight your question as it was a bit lost in the long text . so essentially , would you like us to go through the code and look for a mistake ?"
212903,can't figure out your issue . but are you sure having memberid as a predictor is wise ?
28984,"you say that the substitution probabilities are not required to sum to 1 , are they independent ?"
212932,it's not clear to me what's wrong with these estimates - can you explain ?
212896,"you need to make this self-contained . people aren't going to want to navigate elsewhere and read a lot of stuff to answer your question for you . in addition , are you just asking for code check ?"
212623,is there a denominator ?
212974,pretty much anywhere in spatial statistics you can substitute geographic distance with distance along a network . what analyses are you actually conducting ?
212212,what does the book say about $ u $ previously ?
213034,"incodeveritas no question about that ! what's the quote , * drink deep or taste not the pierian spring * ?"
213017,"it sounds to me like you're asking about independence : for example if you get heads once , does that make 'tails' more likely next time ?"
213051,this is a little hard for me to follow . can you provide a concrete example ?
213056,"what does "" success "" mean ?"
213050,the best possible model would predict the true $ tau $ quantile ( conditional on $ x $ ) . are you using simulated data ?
55826,"could you give some more details about the research situation and the model on which you're trying to conduct the sensitivity analysis ( i . e . , the contents of sobol . fun ) ?"
213072,what do you mean by validate ?
213098,are these groups randomised or do you need top account for other factors ( harder to do in rank tests ) ?
213187,"you say "" i've been taught to use linear mixed models such as . . . "" . can you go back to whoever taught you and ask them how to interpret the results ?"
213213,are you sure about the convergence rate ?
213200,can you edit your question to include a sample of your original data ?
212139,"see [ creating an index of quality from multiple variables to enable rank ordering ] ( url ) & [ nist , * engineering statistics handbook * , 5 . 5 . 3 . 2 . 2 , "" multiple responses : the desirability approach "" ] ( url ) . and the sum of the squared z-scores is 6 because that's the denominator you used in your calculation of the standard deviation : $ sum left ( frac { x- bar { x } } { sqrt { sum { ( x- bar { x } ) ^ 2 / n } } } right ) ^ 2 = ?"
212774,which is your model ?
213340,"at such a small sample size the deviation from the line might only be chance . if you do a number of plots of random data from a normal distribution and compare it with your plot , does it look unusual ?"
212742,"you say , "" will happen before "" , which strikes me as an unusual phrasing . how many rolls are there total , 4 ?"
213347,could you tell us about the explanatory variables you are using in your model ?
213342,"can your dv take on any value continuously between 0 and 6 , or just integer values , or perhaps just a limited number of intermediate values ?"
213381,isn't the number of degrees of freedom related to the sample size ?
213159,great write up . is the problem because your forecasts sit outside the range of because they are not accurate enough when back-casting ?
213061,what is actually the question ?
213406,first : why do you have * another * data set ?
213479,how can you get a sensitivity for each subject ?
213295,"when you say "" what is the probability of this outcome and all other possible outcomes that have an equal or lower probability of occurring ?"
213496,is $ f $ the pdf of the normal random variable ?
213462,do you know the truncation threshold and want to recover the mean and standard deviation ?
18112,""" * spearman generally reports better correlation than kendall-tau for our data , and i was wondering what that says about the data specifically * "" . . . likely nothing ; kendall $ tau $ is [ often nearer 0 ] ( url ) than spearman's $ rho $ when the correlations are not really close to $ 0 $ or $ pm 1 $ - it measures association differently ; the fact that it's typically smaller in magnitude doesn't mean that the spearman correlation is 'better' ; they're just measuring different things about the data . what would lead you to say 'better correlation' ?"
213592,just immediate guess w / o exploring your q : could some differences be due to the default ss type ?
213598,"glen_b , thank you for reminding , and i'm aware of the problem . but could there be a solution for the op , free of it ?"
213603,"what does "" go with eighteen the log of time "" mean ?"
213611,prove which argument ?
213624,"one of many definitions of outliers is that they are values surprising on the current model of the data . as you are clear that a normal distribution is an implausible model , you should assess your data in the context of a better model ( lognormal ?"
213686,your example really calls for using an exponential distribution for the solution . so--are you interested in the solution to your example or in the abstract question you have posed about the geometric distribution ?
213726,are you using one hot vectors as an example ?
213698,i don't understand what you have in mind . can you give more concrete example of the data that you would want to apply this hypothetical analysis to ?
213768,note that the odds for white are more simply 10 / 9 . what you describe is the standard calculation so do you have some special doubt ?
213561,"( 1 ) your question is unanswerable because you haven't fully specified the distribution of $ ( x , z ) $ . do you intend that it be bivariate normal ?"
213797,i am catching up on the lingo in stats so let me make sure i understand your problem . you have a set of data that you know is sampled from an exponential distribution . you have prior belief on the parameter $ lambda $ being drawn from a normal distribution with mean $ mu = 2 $ and standard deviation $ sigma = 3 $ . you would like to compare the probability $ theta = frac { 1 } { lambda } 1 $ with an alternative hypothesis $ theta = frac { 1 } { lambda } 3 $ . is that correct ?
213900,"good question ! it's related to * variable importance * in regression models . prior to measuring the accuracy is defining it - how would you explain what assigning 30 % of credit to display , say , * means * ( beyond stating the method you've used to calculate it ) ?"
213938,i don't understand question number 2 . can you clarify ?
213464,"can you give a reference framework that is of interest to you , so the discussion is not too broad over all method . are we talking about linear regression here ?"
214103,"the logarithm is a monotonic transformation , so you could simply work on the logged data , which are normally distributed ( so [ your link ] ( url ) applies ) , then exponentiate the order statistics . or what am i missing ?"
213722,"categorizing continous variables does not make interpretation easier . imagine you categorized human age in 10-year groups , you make predictions using your model and get different results for two persons who are the same except their age : one is 39 years old and another is 40 years old -- does this mean that there is a qualitative difference between those two age groups . . ?"
214295,"in general you should have enough data to try a more complex model , i . e . , second order markov model . if not , may be the first order markov model is sufficient enough . why do you want to try 2nd order model ?"
214101,why not use a more powerful graphical method such as a probability plot ?
214340,"just to make it completely clear , when you talk about "" balancing the groups "" , do you mean "" among the marbles that have been selected "" or "" among the marbles which have not yet been selected "" ?"
214373,do you expect that two plots that are 1km apart and within an allotment will be more similar than if they were 1km apart but in distinct allotments ?
214352,"is there any reference on this "" y-aware pca "" at all ?"
214343,"to find $ e [ x_ { ( r ) } x_ { ( s ) } ] $ , you will need the joint pdf of $ ( x_ { ( r ) } , x_ { ( s ) } ) $ . have you derived this ?"
212768,how to incorporate the sphericalness of the earth to a model is strongly depends on which model they use . could you briefly describe their model ?
214415,"* third , in r , does p affect the exogenous variables . * no . but you can always double check by looking at the model output . your post is very long , which may put off some users . i understand you are trying to be as explicit as possible to make everything clear and nice , though . my initial guess of your problem is that you have too many variables in the model , making it hypersensitive to the data , which harms forecasts . any random wiggles are perhaps interpreted as genuine signal when you have 12 lags of multiple variables . does lag order 1 or 2 still perform as poorly in forecasting ?"
2844,"for the 2nd question , you mean the eigenvectors or the component loadings summary ?"
214424,in particular : are you assuming gaussian noise when your noise is actually uniform ?
213473,scortchi interesting . where does this 0 . 15 number come from ?
206844,could you post these distributions ?
214365,"i suppose it could be deduced from the formula , isn't it ?"
214485,is this some kind of fundamentality contest ?
214495,why not doing dunnet's test in that case ?
212866,"what is "" lehmanns book "" ?"
214539,"if this is for homework or an assignment , could you please add the [ self-study ] tag and read its wiki ?"
214556,what exactly is unclear for you ?
31597,"do you want the code to do this in r , or just to understand the issue conceptually ?"
214608,you need to specify exactly what regression you're running and why . are you estimating market betas ?
214609,how was this sample obtained ?
214443,` real data ` in what sense ?
214414,"it seems like you already have your answer . i would default to # 1 since i am not too familiar with hamiltonian mc , but then again , why would you use hamiltonian mc ?"
214641,"your equations for $ beta_ { 0t } $ and $ beta_ { 1t } $ are missing $ $ signs , right ?"
214618,what about the ml estimator ?
214674,is this more of a question about how to implement something / use spark or is there a particular statistical question you have ?
202722,possible duplicate of [ does the beta distribution have a conjugate prior ?
214728,why are you normalizing at all ?
72074,did you manage to understand why the auto-arima function chooses the particular lag structure compared to all other possibilities ?
214746,how do you intend to use $ y $ to compute $ pi $ ?
214761,"i'd use a local polynomial smoother as a function of date . it's clear that your average won't dip much below 1 , but you need a smoother to make clear whether there are systematic dips . a coarser method is to average in bins of say 15 or 30 days . do you expect any influence from day of week ?"
214755,maybe you can ask your grandma how she would draw a line that best 'fits' a cloud of points ?
214828,an astute question . see also [ on fisher's exact test : what test would have been appropriate if the lady hadn't known the number of milk-first cups ?
214850,( 1 ) are the observations independent ?
214853,how did you calculate your log fold change ?
214866,"you seem to be equating a uniform prior ( referenced in the second line ) , which is a beta $ ( 1 , 1 ) $ distribution , with the improper beta $ ( 0 , 0 ) $ prior ( described in the third line from the bottom ) . could you please clear up this apparent contradiction ?"
214920,"marceloventura it is not clear that this is a homework . sergey adamov , is it . . ?"
214779,can you say more ?
214970,( 1 ) but it helps to expand acronyms ( cadf ?
214664,"you choose priors * prior * to seeing the data , not based on it . if you set up priors based on the data you have then you use the same data twice : to set prior and then to calculate likelihood , so to multiply the two in the end to get posterior . maybe you should start with some bayesian habdbook like "" bayesian data analysis "" by gelman et al or "" doing bayesian data analysis "" by kruschke ?"
214447,have you checked where the predictor values that lead to these high values are in your model space ?
215036,what are you trying to test ?
214861,"it's hard to understand your question , but it sounds like your goal is to train a classifier that will take in a time series and output a class label that corresponds to membership in one of your clusters . if the goal is to map new time series to clusters , why not just assign each new time series to the nearest cluster centroid , as k-medoids does ?"
214973,"the point of a binomial is to estimate the physical frequency of your events . afterall , how else would you calculate $ pi_i $ ?"
215118,"most importantly , if you're looking at l-estimators , do you measure radius from sample center or from point of aim ?"
215095,""" i tried to use rtsne package and "" and what ?"
214961,"well , both links say , that aic-based model-selection lose some theoretical properties ( performs worse ) when the model is "" not good "" which is not the case for leave-one-out cv / k-fold cv . how does this not target your question ( irrespective of your trust on this statement ) ?"
215751,could you specify what language your code is in ?
219433,"let's consider a simpler version of the same question , where you will flip a fair coin twice . by assuming the chance of each flip of being heads is 50 % , that's a 25 % chance of two heads . you flip the coin once and happen to see heads . analogously with your question , it seems you would maintain that the chance of getting one more heads is still 25 % . * how do you square that with your original assumption that the chance of a heads on the second flip is 50 % ?"
220148,"so what is your question , explicitly ?"
180588,welcome to cv . doesn't this simply involve the * binning * of your counts into a histogram ?
224668,what algorithm exactly do you have in mind ?
226707,"restated differently : are you looking for % male for each region ( i assume % female is 1 - % male ) , and then seeing which regions are statistically significantly different than the average and by how much ?"
230703,why does it matter ?
230716,"in the height example , even each individual has stopped evolving . are you after that , or after a more general "" steady state "" where the [ property ] of each individual still varies over time , but this variation ( and / or members entering and exiting the population ) balance out so that the distribution is stationary ?"
230722,"okay then in that case i would do fruit type color as that in itself is a complete 'type' of fruit , given your specification ?"
231924,can you set up contrasts in limma ?
237181,your description of your case is ambiguous to me . it sounds like you want to determine if the type of pot has an effect of cooking time * after having controlled for lid * . is that what you want to know ?
237185,can you provide the actual models that you are fitting to the data ?
238724,"the likelihood function ( lognormal ) can be updated each time you obtain a new x . to do that , it suffices to estimate mu and sigma based on the most up to date sample . no ?"
240756,do you want to post your code or explain what your steps are ?
241755,"there are dynamic averaging as well , so you don't need to "" hold "" data to estimate its mean and variance . you can also look at row-to-row changes in means or variance to adjust whether learning needs to be re-started . what are you trying to do , in particular , here ?"
247361,are you using a $ t $ -test ?
248219,is this a question from a course or textbook ?
252216,can you link to the paper ?
252411,"you mention classes , as if your data were categorical , but you are asking about histograms , exponential data and standard deviation , all related to continuous data . are your data categorical on numeric ?"
254442,"welcome to the community . in the above , there's quite a lot that you're not telling us about the problem , including how you determined that multicollinearity was the underlying issue . how can we comment on the appropriateness of the analytic method ?"
255644,"you do need the exogenous variables for the next 10 months if you want to forecast the next 10 months using your arimax model . if you don't have the actuals , you could potentially create another ( regression ?"
258895,are you sure you mean * unconditional * distribution . . ?
259361,something like partial correlation or maybe multiple correlation ?
259511,"what is your goal predicting long-term changes after seeing the initial ones , then why not ?"
262819,what are you quoting ?
264062,"you haven't specified how these parameters enter the density or cdf . presumably $ mu $ is a location-shift and $ beta $ a scale parameter in a two-parameter exponential ; e . g . for the cdf do you mean $ f_x ( x ) = 1 - exp ( - ( x- mu ) / beta ) , ; quad x mu ; : mu , , beta 0 $ ?"
265359,who are you quoting at the start ( the part in grey at the top of your post using blockquote markup ) ?
265792,can you clarify - you only have 6 data points ( numbers ) which are the means from a larger dataset ?
266190,what is the purpose of the feature selection you are trying to do ?
267064,do you mean to say that $ x $ is just a function of some other ( presumably finite ) collection of random variables ?
267881,what does gdp stand for ?
268002,why exactly such sample sizes make it too small for modeling ?
162156,"in what sense would the statistics derived from these models be "" incorrect "" ?"
268889,i don't understand your question . the two models you list look the same to me . are you trying to compare the asymptotic relative efficiency of the maximum likelihood estimator for a multinomial logit w / a 3-level response to the binomial logit ?
201241,"just doing the math blindly , i got ( d / r1 ) ^ 2 as 1 . are you sure you took your derivatives correctly ?"
188935,the papers answer your question directly and for sure they provide more detailed answer than you can possibly get on such site like cv ( that very unlikely would be longer than one printed page ) . so what exactly do you want to know ?
16742,whuber giving characteristics of density patters ?
168552,are you sure what you want is a gradient descent implementation ?
153981,"a couple clarifications before someone can answer : can you clarify what you are asking in 1 ) , is it "" what about the performance of the parameters outside of the grid ?"
199215,"it all depends on what you mean by the "" probability density of a sine wave . "" if you have in mind sampling the graph evenly across its length , you will get one answer ; but if you sample it evenly across the horizontal axis , you will get another . could you tell us more specifically about how you intend to sample points on a sine wave ?"
180468,to clarify : do you want to do pca with weights or do you really need to compute covariance matrix ?
115526,henrik did you ever find an answer to this question ?
95598,"it looks like you have two dependent variables . do you have both ( liquid / solid ) observations for the same individuals , or are the people being fed liquids and solids from separate sets ?"
217592,where have you heard that advice ?
129970,"what discipline are you "" beginning graduate student "" in ?"
139492,"the bonferroni adjustment is quite strict . have you tried to use any other method , for example holm-bonferroni ?"
100236,"when you ignore the adjacency constraint , you are just re-asking the scrabble questions : the only changes to make are to increase the rack from 7 to 16 letters , limit the dictionary of valid words appropriately ( * e . g . * , have it contain only the target word ) , and possibly to change the letter frequencies a little . note , too , that the scrabble answers already handle the limited number of copies of each letter . would you like therefore to modify your question so it will not be closed as a duplicate ?"
76277,"what do you mean by "" r does not use weights to modify the mle "" ?"
131341,"are you after a characterization , or a partial list of common cases ?"
254069,"because there's no conceptual or mathematical connection between these two definitions , it's a little hard to figure out what you are really asking for . the function $ l ( p_1 , p_2 ) = - ( p_1-p_2 ) ^ 2 $ , for $ ( p_1 , p_2 ) in mathbb { r } ^ 2 $ , is convex but not one-to-one : is this the sort of thing you are looking for ?"
167708,"please clarify a few things : in linear regression , one usually also has an error term . is this the case here ?"
208331,your formula is * so * close to the one in the wikipedia article that we are left to wonder what additional help you are looking for . could you articulate the nature of the obstacle that is preventing you from connecting the two ?
26383,"if you have the density function for the minimum , then it's exactly the same as doing the calculation for an arbitrary random variable , $ x $ . are you asking how to derive the density of the minimum ?"
2093,do you want to generate normal random variables truncated to range between 0 and 1 or uniform random variables between 0 and 1 ?
97167,( 1 ) are all your effects linear in the logit ?
196752,"what does it mean for a _vector_ to have values in $ [ 0 . 0 , 1 . 0 ] $ ?"
237462,"if you get a new case for data-set 1 , would you have a method of assigning it to an existing cluster ?"
240703,"i don't have time right now to answer everything here ( maybe later ) , but "" so the eigenvectors indicate the correlation between the component and the variables "" - this is wrong . where do you see this in the quotes that you gave ?"
179392,how you model your dynamics with the constraint die will very much depend on the question you want to answer . do you want to consider all modifications of your die separately ?
265704,"the sum of two pdfs * cannot * be a pdf , since it would have total probability 2 ( neither can you sum two distributions and get a distribution out ) . do you instead mean that you want the pdf of a random variable that's the sum of a poisson random variable and an exponential random variable ( which would suggest you're after the * convolution * - not the sum - of their pdfs ?"
110005,"how about adding a pi_0 with x_0 = 0 , and using the technique for the coefficients totaling 1 ?"
181517,possible duplicate of [ when to use an offset in a poisson regression ?
212792,""" foregoing the benefit of having de-correlate your features "" -- what do you mean ?"
26178,it's not entirely clear to me what you're asking for . how does what you want differ from the table you reproduce above ?
149037,"if those are real data , what about trying a bivariate logistic regression , such as those in cran package vgam ?"
143294,"could you be more specific about the properties , your distance measure should fulfil ?"
190014,"no , because you'd be * dividing * by the number of points in a region . in other words , you would be , in effect , disregarding the number of points in the region . make sense ?"
253993,what's so hard about converting everything to the same temperature scale beforehand ?
272714,you might not know the means . . . . we use the test to test for difference in means . does that answer your question ?
174057,can you show the estimated standard deviations of the random effects ?
202459,"broadly speaking the graph is what you expect from repeated sampling from _any_ distribution with mean 0 and sd 1 . there would be small differences in the configuration depending on parent but just looking at the graph won't help you see them . more and more samples won't help given overplotting . the fallacy can be seen from a simple case . my mean is near 0 and my sd is near 1 : does that show that i have n ( 0 , 1 ) ?"
124235,could you elaborate on the goal of this analysis ?
110348,could you please cite that last paragraph ?
176551,"if this is not a stata question , then you should explain to the majority of non-stata users here what the commands you used do and not presume that it's evident from their names . even more crucially , what is the response ( outcome ) variable such that a poisson model appears an alternative to a logit model ?"
178612,"what is the form of $ t ( x , beta ) $ ?"
239087,"do you mean , you have some regression model $ y_i = mathbf { x } _i' mathbf { beta } epsilon_i $ and for whatever reason , you know that the variance of $ epsilon_i $ is $ sigma ^ 2_i $ , that is , ( i ) the variance of the residual is different for different observations ( ii ) you know what the variance for each observation is ?"
126162,"what are your criteria for "" better "" ?"
149022,"after several readings , i still do not understand what you might mean by a "" p-variate , "" nor do i have any useful clues about what "" transfer back the values "" might mean . could you perhaps give a concrete example or alternative description of what your aim is ?"
89926,what are the points that are plotted ?
243632,you want to compare binary to continuous variables ( what for ) ?
196901,"my internet searching just now suggests that the terminology * partial effect * and * marginal effect * --which i had taken for granted in these matters--may not be as well established as i had thought , nor entirely clear . [ this stata journal article ] ( url ) , for example , employs the more descriptive terms * marginal effect at the mean * ( mem ) and * average marginal effect * ( ame ) ; are these what are meant respectively by 'partial effect' and 'marginal effect' as used in this post ?"
17109,"cool question ! can i ask though , what motivates needing a single measure ?"
231059,"it seems to me that user roland's comment to the question you are linking to , answers your question perfectly . what is exactly that you don't understand ?"
256519,possible duplicate of [ how to choose a predictive model after k-fold cross-validation ?
257049,just a question : do your data come from a monotone settings or do they also contain some counter examples ?
111611,why do you have identical versions of this q cross-posted at both sites ?
273555,akkarin can you give a source for the claim ?
273581,"coincidentally , i just visited stats . stackexchange . com to pose a very similar question -- and this guy beat me to it by a couple of hours . is that a poisson process ?"
167640,"you need to specify better the quitting process ! is quitting possible only at round $ m $ , or at any round after round $ m $ ?"
214082,can you provide reference for this formula ?
268735,possible duplicate of [ what intuitive explanation is there for the central limit theorem ?
276143,"since i do not keep track of your questions , can you shortly explain what you mean by a "" composite index "" ?"
276323,it seems to me that if there are some common parts in the two routes that could cause the dependence . to help further you may want to show table 4 . also the question should have the self-study tag . are there other factors that are considered in the problem such as time of day ?
276034,how many times was the response or outcome variable y measured pre- and post-intervention ?
278506,what kind of symmetry ?
278525,"what does it mean to remove black from { red , black , green , yellow } ?"
279840,can you more clearly identify your aim ?
92284,"can you list the levels of your factors , & paste the output from the model ( ie , ` summary ( model ) ` ) ?"
144219,petrbel : i'm sorry i don't know where to start from . have you read the links suggested by whuber ?
178435,just a few questions to clarify the issue . how many data samples do you have ?
215290,what data are ` ph1 ` ?
225216,is your assumption of independence between phone booths ( i . e . the spacing argument is about distance between phone booths ) or independence between trials ( and the spacing argument is about being far apart in time ) ?
257175,"on a first look , this is too much about code review ( off topic ) and too little about statistics ( on topic ) . could you help us by formulating your question more in terms of statistical concepts and problems and less in terms of code ?"
283086,if you're fitting to * sample * moments you can get odd results ( not least -- but not only -- because the sample moments are quite misleading when the skewness and kurtosis are high ) . how are you choosing the skewness and kurtosis ?
284244,how do you define / understand random effect ?
284411,how is this quantization performed ?
284669,did you transform the data ?
284712,what paper ?
286354,what metric are you seeking to optimise and why ?
296972,is there any reason why you want to use the dersimonian and laird method ?
299973,"what do you mean by "" ensure "" ?"
3804,"hello harlan , can your details be translated in mathematical notation ?"
308206,""" is a function "" in what sense ?"
311071,"have you noticed that the ols estimator $ ( x ^ prime x ) ^ { - } x ^ prime y $ is highly nonlinear in $ x $ , too ?"
311458,i followed you here half way through but then i lost your argument . can you rephrase why it is only partially correct ?
311585,i'm not sure i follow . why are two chains estimating different parameters . . . ?
312466,"in your formulation , what stops you from reducing it to a typical regression problem by defining $ gamma equiv v ^ t beta $ ?"
313262,the line has the form y = ax b where a and b are the estimated parameters . just plug in x = 25 to get y = 25 a b . that point will be on the line of best fit ( least squares line if that is the method you are using . is this really what you meant ?
166533,which version of excel and what implementation of regression ( ` linest ` ?
321359,"do your model and the estimates it produces also * perfectly * reflect , * without any error whatsoever , * how the world works and the measurement process you used ?"
329042,"what do you mean by "" your machine learning algorithm "" ?"
329714,"i don't know how your data are organized , but couldn't you just write a routine in which it would train on a sequence from company a , reset the state , then train on a sequence from company b , reset the state , etc . ?"
329915,have you heard of scatterplot matrices ?
336969,did you even read just the wikipedia article ?
339378,"what are the "" lasso properties at the mle "" ?"
341754,is the dependent variable a count ?
347718,this is a vast topic and it would help readers to understand what your current level of understanding and experience is . i assume you are confident in python since that is what you ask for . have you any experience with nlp ?
89900,"all of these are at least somewhat suspect . they seem to have clear bounds , which isn't really consistent w / the standard ols regression model ( but may not pose too much of a problem in practice ) . also , there may be some non-linearity--ie , mis-specified functional form . the wiggly-ness of the fitted line on the plots is driven by a smoothing parameter , you don't necessarily know how literally to take it . you can get another perspective on that same information by getting the ` acf ` & ` pcf ` of those residuals . what are these data / the models ?"
90102,( 1 ) why would pearson correlation be a reasonable metric for quality of approximation ?
91103,can you say more about your data & your situation ?
91540,"i assume that your $ h_0 $ is $ mu = 0 $ , correct ?"
91800,what software do you use ?
91978,"you have covariates , but you apparently only assess whether your models give the correct * total * numbers . have you looked at whether your predictions match the actuals per case , i . e . , taking covariates into account ?"
92829,is this a bivariate dataset ?
93151,is the pattern of zeros such that permutations of the rows and / or columns could yield a triangular matrix ?
93547,i think we will need more information . do you have measures at baseline ( before implants ) ?
93561,can you provide a reproducible example ?
94071,"something seems to be missing here . confidence intervals , hypothesis tests and empirical proportions ( or estimators ) are usually computed _based on observed data_ . there does not seem to be any data here . have you left out some part of the problem text ?"
94690,1 . what is y measuring ?
94716,what distribution are you trying to sample from ?
94959,"can you spell these out , & say more about your situation & your data ?"
95451,"you must clarify what do you mean by "" random guessing "" : do you mean $ a $ ) "" i will flip a fair ( 50 % -50 % ) coin in order to decide whether i will predict that an observation is "" good "" or "" bad "" "" or $ b $ ) "" i will take the sample proportions are adequate estimates of the underlying probabilities , and so i will construct a coin where the "" bad "" side will have a 75 % probability and the "" good "" side will have 25 % probability of landing , and then start flipping this coin "" ?"
95609,"hi akrist . could you put up a plot of the call series at quarter hourly intervals so that we can see what it looks like , and what might be appropriate ?"
95503,"` each node of the tree can divide cases based on a single question only ` can classification tree , not clustering , be closer to what you want ?"
95661,"whether any suggested solution is appropriate will depend on two things , which i hope you can clarify in an edit to your question : ( 1 ) do you hope to exploit the evident * ordering * from non-smoking to smoker to daily smoker ?"
96069,"( 1 ) it's not particularly useful to talk about poisson * errors * ; better to simply refer to the poisson distribution of the observed response . ( 2 ) $ y = ax b $ isn't simple proportionality , that would be $ y = ax $ . ( 3 ) when you say errors , do you mean * standard errors * or something else ?"
96380,"this is a conditional probability ( given the rank of the previous card , you can work out the probability ) , but your question originally sounds like it's after the unconditional probability ( you don't know the rank yet , you're trying to work out the probability the second card is larger than the first without seeing either ) . is that the case ?"
96450,99 . 73 % sounds very specific . why did you decide on that particular confidence level ?
96539,maybe a screenshot ( instead of pointing to a link ) could help ?
96543,"what would it mean for the $ r ^ 2 $ to be "" higher than it should be "" ?"
96795,"do you have 3 , 30 , or 100 branches ?"
97061,there is too much here to address . which * one * of these questions do you wish to have answered ?
97343,at the moment question is not clear to me . you have two univariate gaussian distributions . what do you want to infer then ?
97412,"what do you mena with "" i take the same results for both "" ?"
97642,is this a homework question ?
97776,you might want to extend questions some ( 1 ) is this a time series ?
97825,"could you show us some plots of your data , e . g . how loan amount varies with income for various age buckets and genders ?"
97889,"nick , apologies if i am being obtuse , but why isn't this simply a 3 by 3 $ chi ^ { 2 } $ test with * post hoc * 2 by $ chi ^ { 2 } $ tests adjusted for multiple comparisons ( and possibly for continuity corrections ) ?"
99115,can you give more details regarding the cost function and how you're minimizing it ?
99907,"let me start by stating i consider the question a very interesting one , and i would love to see it answered even in its more general form ( url ) . i think there are two ways of looking at it . the first is that prices during war are higher , the second is that the onset of a war leads to a price jump . if the second option is what you would like to prove ( which i find more interesting but more complicated ) , should one consider some kind of saturation mechanism associated to the price increment ?"
99973,1 ) what is a ` replicate ` ?
99952,"i find your second paragraph unclear -- could you explain how something akin to "" anova "" * could * be okay , yet a binomial glm would not ?"
100097,"thanks for the clarification . if i get it right , you have an unnormalized posterior , which you can sample from with mh , but you need the normalized posterior f to calculate t . since your dimensions are low ( three ) , why not calculating the normalization constant of the posterior with numerical integration ?"
100110,could you please describe your grid and grid cells more in detail ?
100194,just to be sure : you split the sets * * randomly * * into training and test ?
101047,"maybe it's me , but i can't work out what's going on from your description . abundances are integers ?"
101032,"could you expand a little on what you mean by "" randomly distributed "" ?"
102616,"could you tell us what criterion you would use to define whether a peak is "" significant "" or not ?"
102778,"normally , one cannot advice only on the basis of the format of the data ! what do the data represent , and what do you want to achieve with your analysis ?"
102928,how can a model have multiple roc areas ?
103067,is there a specification for when the hdi is only partially overlapping with the rope ?
103229,"do you want the sum to be a random variable with mean zero , or do you want the sum to be equal to zero for every realization ?"
103296,"the [ gamma distribution ] ( url ) is the canonical example , but perhaps you should post a histogram with your data so we can get more of a feel ?"
103336,"i assume we can take $ e ( x ) neq 0 $ as given . if it does tend to be even in the region of 0 ( i . e . that it might sometimes be one side and sometimes another , and in either case might come close in some sense ) , i'm not convinced of the wisdom of looking at the relative error . by contrast , if $ x $ is a positive r . v . , relative error often makes a lot of sense . is $ e ( x ) $ somewhat likely to be negative ?"
103414,please clarify how you would generate a subsample with a distribution matching the historical one ?
103869,"you want to the know how good the "" fit "" is . but what are you fitting ?"
103939,"when the larger model is true but the submodel false , the asymptotic distribution is not $ chi ^ 2 $ anymore ( in linear models with gaussian errors , for example , we get things like exact noncentral-f distributions so the asymptotic distribution should be something like nc- $ chi ^ 2 $ i'm guessing ) . so why would we expect it to be $ chi ^ 2 $ when both the larger * and * the smaller model are both wrong ?"
104048,"you will need to add some representative values here ; people aren't going to want to click a link and download an unknown file . i tried to edit your question , but it still isn't very clear . can you clarify it further ?"
104598,"although you define $ g $ specifically , you replace it with a * different * definition in your calculations : that's where things go wrong . regardless , there's a fundamental problem with this question : if $ x $ has any chance of being negative , then $ y $ does not have a pdf . also , why do you keep writing "" $ y = 0 ldots 1 $ "" ?"
104958,do you know anything else about the relationship between $ a $ and $ b $ or properties beyond simply positive definiteness ?
104968,can you please edit your question to clarify your actual meaning ?
105124,why do you think it isn't multinomial ?
105201,could you clarify the ambiguous notation ?
105291,"of course it's better . if there's no penalty to getting something wrong , you have an additional opportunity to score some points . is there some constraint you forgot to include in the question ?"
105333,"do you have a sense of what spss means by "" conditional effect of predictor at values of the moderator "" ?"
105501,my understanding is that you want to increase auc by choosing some specific samples ?
105778,it doesn't seem clear what you're concerned about . you can get no error term ( the interaction ) with or without sphericity . what makes you think your second paragraph is necessarily true ?
105801,"i don't know much about quality control & control / p-charts , but i can't follow your question . can you explain this more fully ?"
106016,""" not correlated ( r-squared 0 . 006 ) "" means that they are not * linearly * correlated . perhaps there is some other correlation involved . have you plotted the raw data ( dependent * vs * independent ) ?"
106131,your present specification has a nonzero chance that the error term will flip the sign of $ x $ ; is this actually possible ?
106153,"probably not without a lot more details about your survey . are the answers intended to indicate the same construct , or different ones ?"
106233,"although others might find enough here to respond to , i do not yet see that there is enough information to support a well-reasoned answer . would it be possible to be a little more specific about the data you plan to combine ?"
107454,how different are we talking ?
107489,can you say more about what the scores are for each person ?
107704,how do you want to treat log of negative errors ?
107818,"can you say more about what "" they are spread uniformly in time and in space "" means ?"
107938,"if your dependent variable is binary , binary logistic regression is the way to go . what do you mean by "" 1 independent variables ( factors ) ?"
108386,"what do you get with much larger number of bootstrap samples , e . g . 20'000 ?"
108479,your question is unclear . convert to the probability of what ?
108571,could you post any code where you think the problem might exist ?
108641,"can you say more about the process you are asking about , or provide a reference regarding this estimator ?"
108757,the [ no free lunch theorem ] ( url ) might apply here ?
108997,"what do you mean by "" regression weight "" there ?"
109087,what is your question here ?
109595,what was the sd for the effect size ?
110433,"it is not obvious to me what "" real time scenarios "" means . do you mean "" real world "" perhaps ?"
110569,do you observe a site more then once ?
110606,"what is the "" filtering "" supposed to do ?"
110908,you ask specifically about multi-class lda . what makes you think that multi-class lda and two-class lda behave differently in this respect ( under violation of normality and / or common covariance assumptions ) ?
111010,the confidence bands around the qq line are pretty cool . can you share the r code you used to obtain them ?
111817,"it is a bit unclear what you mean with 'prompted' . do you mean subjects were tested four times , twice in each condition ?"
111890,have you checked the assumptions for an independent t-test ?
111957,because you're trying to predict $ y $ from $ x $ ?
111965,are $ x $ and $ y $ independent ?
112004,"hello anna , it would help to know a bit about your approach : do you normalize your data ?"
112376,"can you explain better / more what is $ n_ { runs } $ and "" 0th element "" ?"
112511,did you mean to say you have two * independent * variables ?
112540,"so you have six bags , each of which may contain a single toy , and you want to know the probability distribution of the total number of toys after looking in just one of the bags ?"
113094,( 1 ) to what end ?
113191,what about just using quantiles ?
113766,"are you familiar with how the logistic regression model emerges from an underlying "" latent-variable "" linear regression model ?"
113715,"what is the "" esd test "" ?"
113933,could you give as an example of r code for which you get that error ?
114020,are you designing the study or analyzing data that have already been collected ?
114409,this seems kind of broad and unfocused ; can you make your question more specific ?
114979,are you asking how to produce samples from distributions whose multivariate moments will match the moments of the data ?
115025,"geez , are these all measuring temperature at the same place , or different places ?"
115087,possible duplicate of [ what is theta in a negative binomial regression fitted with r ?
115316,"welcome to cv ! i reformatted the formula using the built-in latex formatting syntax ; feel free to roll back the edit if i made a mistake . also , do you have more detail on the question ?"
115364,` matching is done based on the shape of the curve not in vectorial distance ` i could not quite understand this . could there be missing some words ?
115617,do you know the distribution of $ x_i $ ?
115650,what sort of analytic framework are you using ?
115805,"can you tell us a little more about "" relativity of miles driven per year "" what kind of values does it take ?"
115927,what is the purpose of this method ?
116296,"how does the "" linear rule "" help , since we already know the mean-values vector ?"
116607,"if you simply want to estimate means and variances of columns of frequencies , weighting seems pointless . exactly what random variables are you defining ?"
116694,"well , you say they were asked if they strongly agree , agree , some neutral answer , disagree , strongly disagree . i assume you assigned them 5 , 4 , 3 , 2 , 1 , right ?"
116855,the kolmogorov-smirnov test looks if the data follow a _certain_ normal distribution . how did you specify $ mu $ and $ sigma $ for that purpose ?
116725,what are lr & qlr ?
117262,for sampling ( eg gibbs ) i believe you need a prior . do you have one ?
117693,"wouldn't the size of the changes $ varepsilon $ tend to be proportional to the price ( e . g . if price is $ 100 , it might shift by say $ 5 , but if price is $ 1 , surely it's not going to be doing that ) ?"
117723,what type of error are we talking about ?
118013,can you say some more about the data ?
118271,"ok , i understand your problem a little better , but what is your ultimate goal , to properly classify a mutant given the presence or absence of specific interactions ?"
118491,could you re-partition the data sets and try again ?
118684,can one assume independence between the measurements ?
119807,how do you get total probability exceeding 1 ( and by a long way ) ?
118579,pardon my ignorance but why wouldn't you just fit n and n 1 models using em and compare their fit ?
120357,"i see how $ h_n $ can have infinite variance but i see no way it can have infinite expectation . in what sense then do you mean it can "" have infinite mean "" ?"
120707,"can you clarify your question beyond "" give me some advice "" ?"
120712,"what do you mean by "" $ y $ is distributed normal with mean $ x $ and $ x ^ 2 $ "" ?"
120871,"i don't think i understand the argument about ties . you seem to argue that because the function $ alpha to gamma ^ { * } $ from $ [ 0 , 1 / 2 ] $ to $ [ 1 / 2 , 1 ] $ is not surjective , then it cannot be injective . but a consideration of such functions in general , such as $ gamma ^ { * } ( alpha ) = 1 / 2 alpha / 2 $ , shows that this conclusion is not necessary . what exactly do you mean by "" infinitely dense "" ?"
120935,"in addition to whuber's comments : it sounds like you're going to gather some data at a single location in a single day , which is arguably not what they're talking about . if not , how are you going to gather your sample in a way that reflects their n ?"
121347,have you looked into spss statistics algorithms document ?
122040,"you need to explain what parameter is being plotted here . also , why do you know the true value ?"
122153,"if $ y_i sim mbox { poisson } ( lambda x_i ) $ , what is $ e ( y_i x_i ) $ ?"
122235,why are you using ` nlmer ` ?
122577,( welcome to our site ! ) what does the histogram of log incomes look like ?
122716,what are the replicates you are referring to ?
123175,ssdecontrol : or maybe the op means symmetric residuals ?
123198,"it's hard to say from what you have here . be aware that w / such a large sample , tests of normality and homogeneity will reject the null w / very trivial deviations . in what way are the data non-normal & heterogeneous ?"
123256,"because your use of terms like "" quadrat , "" "" grid , "" and "" dimension "" leaves me totally lost , i suspect you might be using them in ways that are unfamiliar to me ( and therefore to others ) . would you be able to explain them ?"
123443,"are these count-proportions ( of n subjects , k had attribute a ) or continuous proportions ( this milk is 2 % cream ) ?"
123574,"kendall's tau should be exactly the thing for this situation , and one would expect a negative sign for it . i may be misunderstanding you . could you clarify what you mean by "" curvilinear relationship "" ?"
124153,is this for a course ?
124512,"missing not at random ( mnar ) is by definition missingness related to the outcome , something different from what you mean , i believe . i am not sure what is a better term , truncated data ?"
124782,anyone else agree with me it is a ill-proposed question ?
124898,"could you elaborate on exactly how your result is "" wrong "" ?"
125082,doesn't the decision depend on the type of product ?
125312,you're right about the null hypothesis--but exactly how would you go about testing it ?
125794,i don't see what case a axactly is ; you mean you have one value for each day ?
125804,i don't understand the question . are you asking what is the best way to summarize a posterior distribution using a single value ?
127049,is this a question for some subject / course / textbook ?
127443,"first : edit your title , because * * everyone * * here want to solve some problems . second : your description is a little bit vague , did you consider writing something more ?"
127492,what's the objective ?
129860,have you checked what topics are being currently published ?
130091,seems like you are describing gaussian process . what kind of data do you have ?
130404,"i'm a little confused by your models labelled 1 . and 2 . i understand in general terms what might be intended by y , "" some covariate "" and age , but then what's xi1 , xi2 and xi3 ?"
130687,""" examine the effect of the treatment on the dependent variable while controlling for los "" . . . if los is your dependent variable , you * can't * be controlling for it , for then it would appear on both sides of the equation . is it your dv ( in which case you're not controlling for it ) or is it a covariate ( in which case , it's not your dependent variable ) ?"
131149,what do you mean by 'similarity' there ?
131428,do you want a formula to convert a cox ph model to a standard linear regression model ?
131451,"could you please explain what kinds of measurements these are and what a "" paired report "" might be ?"
131477,what is your question ?
132680,you are running two fixed-effects panel regressions on data sets where there's no correlation except within each panel ?
132852,what exactly do you mean by * smoothly migrate between structural changes * ?
133034,for what truly tiny countries is trade measured by * counting * indivisible items ?
133084,"regarding efficiency : set ` v - w - m - s - numeric ( 1e4 ) ` to avoid growing the objects . pre-allocation will make your code much faster . regarding your question : so , your question is why the distribution of the simulated p-values is very skewed ?"
133116,"i don't know if there is a point in making a list of software that does * not * do something . do you * really * want to list all the "" t-test calculators "" that float around the web in thousands . . ?"
133249,"yes , it's clear from your question you think it looks like a ( central ) t . the question is , what is your basis for thinking so ?"
133730,"so are the people in the reviewer group are each exposed to a particular person in the reviewed group , & each person in the reviewed group was exposed to a particular person in the reviewer group ?"
133933,"i gather you aren't replacing the balls . are there enough balls that you can use an approximation w / constant proportions , or do you need exact results ?"
134538,why you need it to be analyzed using daily data ?
134721,"if you really do have the entire population of interest , statistical testing is of no relevance : just look at the results . in practice this situation is * extremely * rare ; if nothing else , the results of a test have some variation that is best attributed to chance . at a minimum , your "" population "" thereby becomes the set of * all possible sets of pre-post test results ; * your data are a sample of that population ; and your target of inference concerns properties of the subjects you tested * as they were at the time of the test . * but don't you want to infer something about * the intervention * itself ?"
134778,"what do you mean , operationally , by 'reliable' ?"
135681,what if it makes the type i error rate for fixed effect parameters closer to the nominal value ?
135803,"is it theoretically possible that there could have been an interest rate but didn't happen to be one , or is it not possible for there to have been one in those cases ?"
135806,what is the length of ` y ` ?
135799,the mplus manual and website and forums are great . did you look there ?
136025,home work ?
136089,"please add the ` [ self-study ] ` tag & read its [ wiki ] ( url ) . note that you can get your $ tex $ expressions to display correctly by putting dollar signs around them ( eg , ` $ tex $ ` ) . can you say more about what you've tried & where you're stuck on the last part ?"
136541,"what is an ( a , b , 0 ) distribution ?"
136551,is this for a class ?
136564,""" non-linear model "" is a pretty broad category . did you have one in mind ?"
136912,"i don't understand the part that "" estimation method is biased "" . from your description it seems you have a list of counts , so no estimation was done ( so nothing can be biased ) . maybe the sample is biased ?"
137005,"the standard way is to use ordinary least squares with no weights at all . in what sense does this "" perform poorly "" for the higher values of $ x $ ?"
137263,the function ` covmcd ` in ` robustbase ` both produce a vector of robust mahalanobis distances ( usually called statistical distances ) wrt to the fmcd estimates of covariance and location . try ?
137288,could you please explain the purpose behind this intended splitting ?
137386,"as a matter of terminology , the first bullet is called a "" model-based approach "" while the second is a "" design-based approach . "" [ googling ] ( url ) will provide literature examples . as far as ( 2 ) goes , i'm not sure what you are asking , because it is unclear to which "" techniques "" you refer and even the sense of "" fundamentally different "" seems a little vague . perhaps you could elaborate on these points ?"
137714,"this is rather a jumble of not-too-closely related questions that seem to be concerned about estimates , counts , and fitting distributions . as such they will be difficult to decipher or answer . what is really going on ?"
137850,what kind of differences are you looking for ?
137906,this is a regression with errors in variables or random / mixed effects . the mcmc issue should be clarified and may asked as a separate question . do you observe the $ x_i $ 's ?
138084,"as a matter of terminology , assumption ( 3 ) implies $ x $ is a random variable . therefore $ g ( x ) $ is a random variable , too . one would not ordinarily refer to it as something that can be "" estimated . "" in fact , it's not entirely clear what you mean by this expression : does "" $ x_1 $ "" refer to ( a ) one value of $ x_1 $ for one of your observations ; ( b ) the vector of values for all such observations ; or ( c ) an independent random variable with the same distribution as the random variable $ x_1 $ in the model ?"
138625,"your first paragraph refers to "" the covariance of a vector "" . your second paragraph refers to "" the third moment of a matrix "" . how are you defining "" the third moment of a matrix "" ?"
138656,do you have information about the full $ 2 times 2 $ contingency table ?
138768,"your model is unusual . you don't have a term w / only x & not also d , but then you have an interaction term . this is usually a bad thing to do , but perhaps this is intended as the data generating process . are you sure you want it that way ?"
139292,how do you know that y and z do not satisfy the ph assumption ?
139677,"most optimization methods ( except for the most naive and simplistic ) will succeed with this function , because it is purely quadratic . could you explain your concern about real-valued parameters ?"
139761,what have you tried and where do you encounter problems ?
139697,what distributions are known exactly other than $ p ( m ) $ and $ p ( theta ) $ ?
139838,"this question is extremely broad , because it ( implicitly ) covers all of time-series analysis and spatial analysis , yet it doesn't even describe what kinds of data you might have . are you actually interested in birds or are you using them as a metaphor for some other problem ?"
140012,""" price per area "" would suggest you want to * divide * rather than multiply as shown in the final formula . did you perhaps forget to insert a "" $ / $ "" ?"
140071,"there is at least one problems with using robust regression : the effect of explanatory variables tends to be non-linear , but ols will not give you that . can you clarify what the source of the boundary points is ?"
140573,which covariables do you have ?
140777,why are the arrows directional ?
140874,"maybe this is something i should know about and i'm going to embarrass myself by asking , but what do you mean by "" a cube "" here ?"
140905,"this is an old question , but did you ever find an answer ?"
140755,"the mean / sd description assumes * nothing at all * about measurement errors . it describes the actual measurements , not the underlying numbers that are being measured . so exactly how do you want to "" account "" for the measurement errors ?"
141330,have you tried ` bayesm : : rwishart ` ?
141624,is this self-sudy ?
141666,"please give an exact quote , in context , for the first definition , along with a proper reference ( including edition and page number ) . ( in fact , please also give a proper reference for the other book , for completeness sake ) ; do they explain what that actually means ?"
142162,"i don't think anyone will be able to answer your question , or even point you in the right direction , until you finish the question . once you have the data , what will you do with it ?"
142238,why don't you compare actual depths without binning and making histograms ?
142874,"is there a "" hat "" missing on the subtracted x's in the first row ?"
142877,is this homework ?
143058,"some more clarification may be needed : is the number of states finite , countably infinite or uncountable ?"
143062,"cointegration is a phenomenon when a weighted sum of two integrated time series is stationary . ( i leave integration of orders above i ( 1 ) and the respective cointegration aside for simplicity . ) this does not depend on any model . ols is an estimation technique , not a model . you have posted a lot of questions , would it be possible to see which ones are the most important ?"
143088,what is your sample size ?
143210,how to you perform model selection and performance estimation ?
143278,"can you state the specific factorial design you used , which variables , etc , with formulas ?"
143300,can you decipher in the question what is dtw ?
143353,what was the count of the data ?
143359,what is the model supposed to do ?
143487,any reason not to use ` rinvgauss ` from ` suppdists ` or ` rinvgauss ` from ` statmod ` directly ?
143616,"you have a lot of background here , can you clarify your actual question ?"
143950,can you explain / describe your methods in addition to providing links to youtube videos ?
144012,could you edit your post to give any details about the table columns ?
144027,is this homework ?
144420,"this question is not readable because ( a ) "" $ w $ "" is defined both as a random variable and as a "" variance "" , which is self-contradictory , and ( b ) the tag phrase "" in terms of $ sigma $ and $ s $ for all these things to hold "" makes no sense . please edit this post accordingly . btw , what is the basis for your "" only sane "" assertion ?"
144454,"just trying to understand the question : when you want to * show that rows tend to converge * , do you mean that given a sequence of matrices $ a_1 $ , $ a_2 $ , . . . , you want to quantify whether they are getting closer to the "" ideal "" matrix $ a' $ ?"
144773,"i've never seen this notation before . can you provide references to the definition ( i'm familiar with kernel methods , but not the notation used ) ?"
144962,"when you say 'significance levels' , do you ihstead mean p-values ?"
145098,""" so according to the math , i can be 95 . 2498 % sure that the variant is better at some level than the original . "" -- which mathematics says you can conclude that ?"
145135,"please give references as you would expect to find them in good literature . "" prml "" = ?"
145383,can you elaborate on how price and area are related ?
145660,"what you are saying sounds strange . if the two medians are equal the test cannot be signifiant . might there be some technical nuances , such as weighting or missing data , that you pass over silently ?"
145811,could you describe your data in greater detail ?
145915,"what do you mean by "" does not compare impressively "" ?"
145961,what is your jags code ?
146026,when you refer to your data as a 'series' . . . are your values observed over time ?
146164,"is "" digotomous "" intended to be "" dichotomous "" ?"
146345,it's not entirely clear ( at least to me ) what's being asked . you have the residuals - are you concerned that the residuals aren't capturing some interesting aspect of your model's fit ?
146404,"if you take a look at the above conditional of $ ( theta_1 , theta_2 ) $ given $ tau $ or $ tau ^ { -2 } $ , what form of conjugate prior distribution on $ tau ^ { -2 } $ does it suggest ?"
146637,notation tends to differ a lot by ( sub- ( sub- ( sub- ) ) ) discipline . what is your intended audience ?
146699,can you explain 3 more ?
146684,are you sure that's your generator matrix ?
147442,so is your question how to multiply each row of ` x ` by ` a ` ?
147979,"hmm , assuming $ bar x $ is the mean , then it can be negative . so what is $ sqrt { bar x } $ ?"
147959,"if you run ` coeff = pca ( rand ( 1600 , 5000 ) ) ` , you will see that ` coeff ` is of 5000x1599 size . meaning that with 1600 points you can only find 1599 principal components in 5000-dimensional space . of course ` coeff * coeff' ` will then not be an identity 5000x5000 matrix , because it will be low rank and have 5000-1599 zero eigenvalues . the reconstruction of your data points should still be perfect though ( and not "" lousy "" ) , because all your points lie in this 1599-dimensional subspace . does this make sense ?"
148567,"is it possible you meant "" [ manova ] ( url ) "" instead of "" monova "" ?"
148925,"( 1 ) i would guess you aren't really thinking about this as a discrete distribution , but rather as a * discrete summary of a continuous distribution . * that's a little different , because it opens up the possibility of interpolating within each of the three bins . is this the sort of approach you are looking for ?"
148962,is this a question from a course or textbook ?
149440,your final sentence is somewhat ambiguous ( in what sense do you mean 'include' ?
149604,douglas : i changed the original title so it is less generic . please free to amend it if you think it does not reflect your original theme but do be more specific that simply stating : ` why do we need to estimate the covariance matrix ?
149656,why do you want to compute these shares ?
149715,"a couple questions - are all the predictors ( plate , arrangement , number of items ) included as independent categorical variables ?"
151165,are x and y random uniform ?
151163,what's wrong with just increasing $ n $ to 10 ^ 7 ?
151739,can you add some r code so we can have a closer look ?
151946,it would be helpful if you provided some information on the intended statistical analysis plan . you talk about independent components so i assume you run a factor analysis or another dimension reduction technique ?
152139,is the definition in ( 1 ) really what you mean ?
152158,"whether all the categories for a dummy should or may not be included in the model depends on what you want to use the model for . do you want to make statistical inferences about effects , or do you just want to be able to make accurate predictions ?"
152428,how are you determining which words are keywords ?
152466,"if you're asking "" why does the tag wiki say that rather than what i think it should ?"
152550,could you clarify ?
152743,could you tell us which variable should be the outcome variable and which one ( s ) should be predictor variable ( s ) in your regression model ?
153137,"( 1 ) "" stimuli "" is plural , "" stimulus "" is singular . . . so "" * did one stimulus . . . * "" . ( 2 ) when comparing a first vs a second , are you just interested in a difference in the average or are you interested in any difference in pattern ?"
153352,"what do you mean by "" similar "" ?"
153408,"if you consider 1 experiment as one observation , then it makes sense to treat a percentage as a continuous variable . but technically , i think an observational unit in your case is a single cell , not an experiment , so your outcome is categorical . is there a reason why you do 3 experiments instead of doing all cells at once ?"
153409,can you post more of your code ?
153635,"how many voxel's are you looking at this could quickly get computationally intractable , quite quickly . efficiency in this context is also a function of how much time are you willing to wait , and what computational resources you have access too . intuitively i don't see what you are really trying to do with these correlations , what does the pca of these things do for you ?"
153687,can you please clarify what are $ a $ and $ b $ ?
154062,"you really do have to define _suitability_ to get good answers here . otherwise the success of any data reduction is success at a given purpose , i . e . why do you want to do this ?"
154257,"closely related threads , such as url and url illustrate the general procedure . it's not perfectly clear what you're trying to ask , though . it sounds at some points like you are requesting an exposition of maximum likelihood theory and at other points like you just want to derive ordinary least squares from a normal likelihood . could you edit this post to make it more apparent what kind of answers you are seeking ?"
154325,"the short answer is no ( although some readers might be tempted to suggest a two-component gaussian mixture model , which arguably is a "" standard bimodal distribution "" ) . a more relevant issue is * why are you looking for such a distribution * ?"
154511,"this post , as currently written , is likely to engender debate and confusion . you need to distinguish more clearly between a coefficient and its estimate , as well as indicate whether you are conceiving of ols in a bayesian sense ( with a prior probability distribution for the coefficient ) or whether you really mean to be asking about the * p-values * of tests of the coefficients instead of * probabilities * . have you searched our site for related posts ?"
154521,"in order to check your model , i would suggest if you could you print the validation or test loss too . make sure that when you evaluate both of them you turn off dropout . dropout should only be used in training . if you are using torch there is an option ` model : evaluate ( ) ` and ` model : training ( ) ` to switch between modes . what is your dropout ratio ?"
154623,you wan to incorporate prior knowledge ?
154846,i'm not sure i understand the question . could you want ` y ~ factor1 * factor2 * factor3 ( factor1 * factor2 * factor3 sensor ) ` ?
155018,aksakal : please clarify your suggestion . which of feller's books covers * statistics * theory broadly relevant to the table of contents at the link the op provided ?
155329,"instead of -7 . 11 , what value are you expecting ?"
156288,you should tell us about your real problem ! what does the numbers represent ?
156408,"your question seems to be asking multiple questions in one ; and some of them are about inferring causality . even if products 1 and 2 were in the same category , how do you know one cannibalized the other , as opposed to simple correlation or anticorrelation ?"
156718,i suppose refitting the model with ` zz ` added as a level to the original data is out of the question ?
154088,"they are not paired , are they ?"
157555,maddenker : does one of those papers deal with this specific question ?
157628,is the cost per click or per impression ?
157700,"what do you mean by "" correlation "" here ?"
157819,what's your regularization regime ?
158145,"one of the benefit of rank correlation such as spearman rho is to be robust to a monotonic transform of your data , and only relies on order . it is apparently what you are seeking . why not considering another "" correlation "" or similarity measures ?"
158324,"in general , how you treat a variable depends on the analysis you are performing . if you could provide more of that contextual information you would likely get answers that are more useful . btw , what distinction are you making between "" on "" and "" in "" in the second variable ?"
158664,how these values ( 1 to 14 ) are obtained ?
158674,can you say more about your situation & the randomization procedure you used ?
159452,"note that table ii is misleading : it must be providing probability * densities * , not "" probabilities "" as claimed . because the study is behind a paywall , you cannot expect readers to know the details . in particular , how many parameters do these weibull distributions have ?"
158831,"normally a value doesn't have a distribution at all--it's just a number . could you please edit this question , then , to explain the sense in which your values could be * varying * or * uncertain * ?"
159563,can you add some more context here ?
159627,what does it mean to decompose a random variable into partitions ?
159711,"are you familiar with the concept "" degrees of freedom "" in a statistical test ?"
159714,"how would an "" isolated "" ( from applications ) probabilist figure out what's a worthwhile problem to work on ?"
159810,how many rows are in your data set ?
159900,are you familiar with [ post-hoc tests ] ( url ) it seems you refer to them . . ?
160000,aren't they mathematically identical ?
160193,welcome to cross validated ! can you explain the application or give an example in which these data arise ?
160316,welcome to our site ! have you looked at the [ many related questions on interpreting negative binomial regression output ] ( url ) ?
160537,hint : suppose $ x $ were originally in meters and then you changed it to kilometers . what should you use in place of $ log ( x 1 ) $ in the new units ?
160788,hello and welcome to cv . can you give a little more information about the study design ?
161678,can you edit the question to include your comment in the text ?
161760,what spss version are you using ?
162016,"it would be nice for you to describe and explain your pictures of matrices . in what way the 1st is "" centered "" and the 2nd is "" circular "" statistically ?"
162276,"it is strange . can you present the spss syntax and some data , to reproduce the finding ?"
162534,"try to repeat your simulation while holding not only the group sizes ( 500 each ) but also the sum of "" 1 "" ( over the pooled sample ) constant . the p value of fisher's exact test is derived under this "" fixed marginal distribution "" setting . does the picture look better then ?"
162553,"what are the "" cave "" bits for ?"
162603,can you post the code for what your linear regression method is ?
162699,this question isn't very clearly stated . can you provide a working example ?
162718,"with counts this large * any * test will tell you there is a "" significant "" difference . for instance , apply a chi-squared test . the underlying question is * why do you want to do this * ?"
162871,"i do not understand why you are complicating your question by introducing $ x $ , because it seems that all you are asking is how to sample $ y $ from a truncated poisson distribution : to obtain $ z $ , independently sample $ x $ from a poisson ( or whatever distribution you please ) and add it to $ y $ . is $ x $ intended to play a more important role than that ?"
162910,what's aft model ?
163571,what does a plot of ` churner ` against ` daydiff ` look like ?
163701,"please explain what you mean by a "" winner . "" if in fact these are all the donations that have been collected , and the "" winner "" is the larger total , then the dispute is settled by comparing the two sums . since you haven't availed yourself of that simple solution , apparently you have some other concept of "" winner "" in mind--but what is it , exactly ?"
163985,can you provide a reference for this property about the covariance matrix ?
164207,"i don't think we we are really clear on what it is you are trying to do . before making references to external sites , can you tell us what it is you are trying to find and how your variables are measured ?"
164351,could you perhaps specify what are your $ x $ and $ c $ ?
164378,"you're switching between hats and tildes , do they mean the same thing ?"
164402,"r is open source - you can always review the source code . for example , paste in r console ` summary . lm ` and ` lm ` to see the code . you'll learn that residuals are what you say they are : the difference between fitted values and the actual data . what is not clear about residuals for you ?"
164409,""" now suppose i want to weight the data so that the observations with intensity 2 have double the weight of the 1 observations . "" - why would you want to do that ?"
164450,well what does each row represent ?
164721,this isn't clear . why do you need to identify the distribution of these data anyway ?
164934,( 1 ) to find the maximum-likelihood estimate $ hat pi $ you need to find where the log-likelihood function reaches its maximum . calculating the score ( the first derivative of the log-likelihood function with respect to $ pi $ ) is a start - what value will this take at the maximum ?
165158,can you give the model ?
166623,"will , instead exact ( exhausive permutation ) test , a monte carlo ( simulated permutation ) test suit you ?"
166583,"in part 2 ( 2 ) , there must be a typographical error . in part 2 ( 3 ) , yes it's horribly confusing--what do you mean ?"
166633,is this a verbatim copy of a question from some test or assignment ?
166729,"so each respondent provides 6 responses , is that right ?"
167166,can you clarify the claimed 'simplification of the kalman gain equation' ?
167814,you mean logistic regression with a binary dependent variable ?
167888,"i don't think your first procedure is correct unless you assume $ ( x , y ) , , z $ has a bivariate normal distribution . in the second procedure , exactly what "" appropriate statistical test "" would you use , given that $ r_x $ and $ r_ { y , z } $ appear not to be independent ?"
168113,"it's not yet clear what aspects of your data you consider relevant to "" clustering . "" is it some combination of being separated by zeros , or separated by multiple zeros , or attaining "" high "" values above zero , or something else ?"
168792,"could you clarify "" reliability analysis "" ?"
168917,"your intuition is correct . you do add the coeficients together to obtain the distribution of their sum . the other questions you cited pertain other isssues . however , the one thing to be careful of is that the draws should not be taken randomly from each marginal posterior but rather from the multivariate posterior of all the beta . this is because the beta may be correlated . what method are you using to estimate / approximate the posterior ?"
169168,how much data do you have ?
169238,are they all simple random samples ?
169258,you want to generate integer data points ?
169260,how were the splits obtained ?
171437,"although i am unfamiliar with ` testmeanshapes ` , i would bet it is bootstrapping the p-value and you have used a default of $ 1 / 0 . 000999 - 1 = 1000 $ iterations . would this be correct ?"
171699,do you want just to obscurify a term for your audience ?
172100,"` search-vol ` & ` bid ` are not commensurate . you need to specify how you are going to equate them . ie , how many searches are worth $ 1 ?"
172131,"that said , before doing any of that . . . i suggest that you'll probably need to edit the question to provide more details before we can answer the question . what approaches have you considered , and why did you reject them ?"
172206,"why not work with x in [ 1 . 2 , 1 . 2 eps ] instead and take limits as eps - 0 ?"
172339,this is hard to follow . do you want to cluster on your response ( y ) data ?
172495,"by terminological convention , we say that you 'regress your * dependent * variable on 4 * independent * variables' . can you say more about the "" fta "" ?"
172556,"are you trying to write your own "" shazam "" ?"
172981,i am not sure that i understand : you measure a at different points in time and then you estimate $ a = beta_0 beta_1 t $ ?
173221,how do you compute the kullback-leibler divergence ?
173302,"although your question refers to a "" change , "" what is your reference ?"
173313,"in regard to "" richness "" : i'm sorry i didn't understand what it means ( as least as you've put it ) . clustering algorithms are many , how can you expect that they all obey some particular fancy requirement ?"
173555,"can you say more about your situation , your data , and your goals here ?"
173972,can you please describe your experiment and your dataset a bit more clearly ?
174051,like this ?
173989,"doesn't lda require that your data are all multinomial categorical variables , while gmm certainly requires that your data are all continuous variables . what kind of data are your 168 user activity variables ?"
174667,"if i understand you well , you are trying to model dynamics of prescriptions as a function of year ?"
174849,i think you have to be much more specific . theoretical or applied orientation ?
174791,"could you explain more clearly what you mean by , "" sum of gaussian mixture "" ?"
175338,in what sense will your model be non-parametric ?
175479,"if the $ n $ continuous uniform random variables sum to $ 1 $ , then with $ n = 3 $ , $ x_1 x_2 x_3 = 1 $ and so the distribution of $ frac { x_1 } { x_1 x_2 x_3 } = x_1 $ is the same as the distribution of $ x_1 $ , right ?"
175561,are these percentages count proportions ( counts divided by total counts ) ?
175637,can you give an example / some context to make this more concrete ?
175779,can you provide more information ?
176065,which branch of social sciences ?
176277,why not dividing by the maximum value of each column ?
176283,"let me get this right , you have 672 variables , each with its own set of 30 , 000 time sampled points of the respective variable's value as it changes over time ?"
176361,asking for code / help with error messages is off topic here . but are you sure you have the right model ?
176350,"where you have "" ` sin ( beta [ 4 ] x ) ` "" shouldn't there be a ` * ` between ` beta [ 4 ] ` and ` x ` ?"
176644,"to what "" fallacy "" do you refer ?"
176925,isn't there a minus sign missing in the exponent ?
177062,what is the second package ?
177206,"i am not sure i understand your question - you do not want to do it by hand , but also not rely on statistical programs ?"
177569,can you explain exactly what you mean by exponential regression ?
177677,the target of any prediction interval is the value of a particular random variable . which random variable do you have in mind ?
177589,"thanks for the update and thanks dougal for the edit . what i think should be clarified before i can vote to reopen is what exactly is "" predefined groups "" in the title and "" categories you have already determined "" in the last sentence . do you mean that you want to select a subset of features that yields good unsupervised clustering ( option 1 ) or that you want to select a subset of features that allows good supervised decoding of the group membership ( option 2 ) ?"
177947,could you say a bit more in your question about how you wish to use the description of the curve ?
177987,"is "" data "" supposed to be qsec in the list of coefficients ?"
178142,"is it guaranteed that $ x_1 , x_2 , x_3 $ have a trivariate normal distribution ?"
178514,can you please add the plot you obtained with your code ?
178566,how exactly did you calculate the $ r ^ 2 $ ?
178688,is the ratio of 0 . 08 / 0 . 01 what you intended ?
178035,i don't quite get your question . why not just sum a & b ?
178948,"what does "" agrees with test data "" mean ?"
178960,this is hard to follow . can you make this more concrete ?
179208,note that the z-score of the * sample mean * isn't 2 . what's the standard deviation of a sample mean ?
179334,* of course * you can calculate mean and sd of percentages : just plug them into the formula . what should be of concern is how the resulting values will be interpreted . could you explain why you have been asked to perform this calculation and what will be done with the results ?
179319,could you state your null and alternative in the same form ?
180654,in what way was mvtnorm unsuccessful ?
180370,are you sure the models matched ?
181121,"there are myriad ways to do this , depending on how the pdf is given to you and whether you need a large sample . could you edit this post to provide this information as well as to explain the purpose of this exercise ?"
181199,are you sure it has an analytical closed form ?
181596,are these nested regression models & are the predictors the correlated variables you refer to ?
181915,"if your * population * is 30 , where do the other 70 come from ?"
182099,"i'm a little confused by "" introductory-graduate-level statistics background "" ; the first two terms seem to contradict each other . can you clarify what that includes ?"
182482,"welcome to our site ! i think you mean "" it is implied that all bins $ i ge 7 $ contain zero counts ?"
182767,surely you mean mean absolute error ?
182954,"without the data , it's a little hard to see what's going on . can you post e . g . the first few rows of ` mytrain [ myfeatures ] ` ?"
183003,"that comment was for future viewers who may have thought to vote to close because of the extensive code , not for you really . on a different note , your model was fit with ` lag . max = 10 ` . do you think that may have something to do with it ?"
183017,"when the $ x $ 's are gaussian , the variance will be distributed as chi-squared . cf : [ why is chi square used when creating a confidence interval for the variance ?"
183176,"just to be clear , are you saying you want to know about a model like this : $ x p , n sim bin ( n , p ) $ and $ n n ^ * , p ^ * sim bin ( n ^ * , p ^ * ) $ ?"
183568,"one way to make sense of the formula is to understand the ( undefined ) function $ phi $ to be the * complementary * cumulative distribution function of a standard normal variable and $ z_ { alpha / 2 } $ ( also undefined here ) to be the value for which $ phi ( z_ { alpha / 2 } ) = alpha / 2 $ . then , since $ alpha lt 1 $ , $ alpha / 2 lt 1 / 2 $ , whence $ z_ { alpha / 2 } gt 0 $ , entailing $ z_ { alpha / 2 } / sqrt { t ^ { * } } gt 0 $ and $ phi ( z_ { alpha / 2 } / sqrt { t ^ { * } } ) gt 1 / 2 $ and finally $ alpha ( t ^ { * } ) lt 1 $ , as it should be . could you therefore revisit your reference and tell us precisely what $ phi $ and $ z_ { alpha / 2 } $ mean ?"
184095,are you working in an externally regulated environment ?
184342,"simple question , shouldn't the equation be $ y = x hat beta varepsilon $ without transposing the model matrix $ x $ ?"
184660,what arew your sample sizes ( in each group ) ?
184849,"could you elaborate on what you mean by "" cannot see any plot that resembles a gaussian copula "" ?"
185066,"i don't understand what you mean by "" the bias term in the residuals . "" in terms of the model you wrote down on the second line , what exactly would this be ?"
185138,what is $ w $ ?
186162,what does cv rate measure ?
186235,by time fixed effects you mean $ lambda_t $ ?
186434,what do you mean by variability ?
186593,"are we talking about a standard t ( $ mu = 0 , sigma = 1 $ ) ?"
187311,did you specify to r that window and angle are categorical variables ?
187391,how much data do you have ?
187605,i am not sure i understand the role played by $ z $ here . ?
187968,please check your parentheses carefully in the latter half of your formula . writing something like $ phi ( x ) ^ 2 $ ( where $ x $ is $ ( c_j- mu ) / sigma ) $ ) is ambiguous : did you mean $ [ phi ( x ) ] ^ 2 $ ( which could also be written as $ phi ^ 2 ( x ) $ in analogy with $ sin ^ 2 ( x ) $ denoting the square of the number that is the sine of $ x $ ?
188087,hint : how many possible collections of center points can there be ?
188330,can you prove that $ ( b_n ) $ is a markov chain ?
188425,"the large number of frequencies coded as exactly $ 1 $ suggests this exercise may be futile , because it is inconsistent with a distribution that has a density there . could you explain how you originally obtained these data and tell us why you want to estimate a density for them ?"
188755,"for intuition , you might contemplate proving the contrapositive . suppose $ x_n $ did * not * converge in probability to $ 0 $ . given that these variables are nonnegative , what would that imply about the limit of the means ?"
188837,"you may want to include a bit more detail , such as who "" they "" are . maybe include the text to which you're referring . i'm guessing the issue is with the variance of the estimate of $ int f ( x ) dx $ . how are the authors suggesting you reduce this variance ?"
188985,"welcome to our site ! i think for this question to be answerable you need to clarify what you mean by "" how significant ` v3 ` is "" - do you mean more * statistically significant * , in the sense of how strong the evidence is for including ` v3 ` in your model , or do you mean it in the everyday sense of the word "" significance "" to mean "" importance "" ( in which case you are likely more interested in the magnitude of the two regression coefficients ) ?"
189322,where does the term occur ?
190116,"can you say more about what the graphs are , how many there are & what the null hypothesis in question is ?"
190142,welcome to cross validated ! for a start would you explain what you're in fact measuring ?
190149,"the question is unclear . it looks like you have 16 , 000 observations of a 12-dimensional measure , or 16k 12-bar graphs . . what kind of smoothing are you looking for ?"
190330,"what do you mean by "" betas "" plural ?"
190346,"in the machine learning tradition , hyperparameters are tuned in some manner by the analyst to optimize model performance . in the bayesian tradition , the choice of ( hyper ) prior is used to represent uncertainty about some aspect of the model . i can't pin down which tradition you subscribe to ; could you clarify what you're trying to do ?"
190531,"what do you mean by "" clusterize "" ?"
190734,"you haven't said what the purpose of your visualization is . is it exploratory , or are you trying to communicate something to an audience ?"
190874,"there's a tricky issue of what you mean by "" maximizing revenue "" here . for example , fix a time $ t $ , then you can ask what strategy will give you the most money ( expected value ) at time $ t $ . is this what you are interested in ?"
191033,have you found anything on a pubmed search ?
191124,"by "" small outlier "" do you mean "" negative number with large absolute value "" or "" small in absolute value "" ?"
191443,i am getting the impression there is an s-shapes curve in your data . have you compared your simple linear fit with a higher order polynomial ?
192162,what is it you are reading ?
192194,"odd things get published so something having been used in a published paper may not be the best criterion to pick what to do . it would probably help if you told people how you measure "" busy "" . is it e . g . number of visitors , cars on the road or clicks on a website ?"
192440,"you start out asking about "" independence "" and wind up writing about "" correlation "" as if they were equivalent--but they are not . which of those are you trying to ask about ?"
192838,perhaps 2d whiskers / error bars like this ?
192905,"do you mean in terms of algorithm implementations ( eg support vector machine uses quadratic programming , compressed sensing ) or statistical problem definitions ?"
192986,"this lacks some detail . when you say "" estimated power "" where is the "" estimation "" ( rather than calculation ) part coming in ?"
193217,"there are also semi-supervised learning algorithms . btw , why 82 and 6 does not fit 35 , 42 , 82 , 89 , 3 , 6 ?"
193330,how many practices are there ?
193364,could you explain the reasoning that led you to each formula ?
193425,"do you want to construct a probability distribution , is that what you're after ?"
193348,"when you say , "" students do not have the same code "" do you mean they do not have the same student id so you cannot track them longitudinally , do you mean that the survey instrument you administered is modified over time , so not all items can be mapped , or do you mean something else ?"
193590,did you perhaps mean to write $ frac { partial } { partial a } $ on the right hand side ?
193988,"i'm confused by the phrasing of your question . you refer to distance to the red boundary , "" my treatment variable "" and "" the cutoff variable ( x ) . "" are those all referring to the same thing ?"
194092,"it's unclear what you mean by a "" cluster "" . for example , why not create classes of all zeros , all ones , and all twos ?"
194281,how many opponents do you have ?
194386,"is a "" way "" the same as a "" method "" ?"
194464,can you describe your data better ?
194885,can you post the complete or part of the data ?
195048,possible duplicate of [ cost function of neural network is non-convex ?
195539,"currently the only question your post contains is "" isn't the expected value of the distribution beta (  ,  ) just  / (   ) ?"
196759,maybe you're right . did you try to simplify it ?
196824,how many subgroups of users do you have ?
196848,"the scale matrix of a multivariate $ t $ distribution does not generally satisfy the properties of a correlation matrix , e . g . that the elements are between -1 and 1 , or does it ?"
197463,question : how can you have 25 customers at month 10 when your month 9 has only 22customees ?
197629,why do you think it should be another gamma ?
198007,this is probably best gotten from the documentation ( [ ?
198380,thank you . so when you apply $ fb $ you are first subtracting $ 1 $ and then adding $ 1 $ to the indexes . how does the result compare to what you started with ?
198627,"when you say your data are "" stored in integer "" do you mean that the original data are effectively real numbers that have been truncated ( rounded down ) ?"
198658,what is $ z_x $ ?
199236,can you be a bit more clear about your criteria ?
199379,also why are you subtracting a poisson random variable from $ x $ ( i'm guessing $ x $ is the same as $ x $ ) ?
199678,"the phrases "" for a specific parameter "" and "" two cell types "" ( biological ?"
200397,"i think it is a good question . at the same time , the answer depends on the specifics of your analysis : ( 1 ) do you use anova ?"
200494,it is not totally clear how does your data look like . could you post your data ?
200771,"david , would you be so kind as to draw out the equations for the test statistic of your positivist null hypothesis ( i . e . $ h ^ { } _ { 0 } : ( ta_ { t } - tb_ { t } ) - ( ta_ { c } - tb_ { c } ) = 0 $ ) ?"
200789,what is your application ?
200786,i am afraid you need to provide more details . be specific . how does your database look like ?
201000,it seems strange indeed . did you make sure the variables were scaled before the pca ?
201777,i assume you are analyzing the occurrence of some type of cardiovascular events . do you only have aggregate data or do you have ( or can get ) individual patient data ( so that you could do a time-to-event analysis ) ?
201800,could you describe your data and your model in greater detail ?
202400,"could you explain why you want to "" normalize "" this matrix ?"
202804,"a lognormal is not a serious candidate here for your counts , as it can't be zero and is in any case a continuous distribution . an exponential is also not a natural distribution for counts , as it is continuous . i'd start with a poisson and see how well that fits . having counts of 0 is no problem with chi-square as the point is how many counts of 0 you have ?"
203036,it'd be useful to have a picture . say a histogram of your random effects coefficients with the proposed normal distribution over-layed ?
203991,can you add a reference to this ?
204159,where is the time field ?
204203,what are you using the validation set for ?
204389,"you didnt define what you mean by "" optimal setting of the knobs "" can you explain ?"
204410,"what does notaation $ pi ( theta ) in ( 0 , 1 ) $ mean ?"
204632,"welcome to cv . first of all , you are positing directional predictive model ( s ) with a hypothesis that different rankings will have differential sales effects . given that , correlations are symmetric measures of linear association which do not lend themselves to a test of that nature . you probably want to think in terms of a regression model . next , how are you proposing to obtain these rankings from amazon ?"
204751,have you tried the ` simulate ` function in ` lme4 ` ?
204841,"` attach ` can cause all sorts of nasty behavior , and is generally strongly recommended against . are you using it for a strong reason ?"
205544,what exactly do you believe to be biased when using ols ?
205692,"the coefficients you quote in the text do not seem to bear much resemblance to the ones from r . also , why not use r to do the predictions ?"
205805,"in such "" change of support "" situations it is often useful , if not essential , to consider * what * the slow instrument is measuring . there are differences between reporting a one-minute average , a time-weighted one-minute average , a one-minute maximum ( or minimum ) , a "" snapshot "" for the middle of that minute , or a value of a random instant within that one-minute interval . each of these would suggest a different solution . could you clarify this for the case you're interested in ?"
205806,"please clarify the title / the question . your first display is just an equation , which cannot be "" biased "" in and of itself . biased for what ?"
205884,"there is a large literature on parameterization in mcmc . it sounds like you want somebody to do a literature search for you . have you done a scholar . google . com search for "" mcmc parameterization "" ?"
206043,"i find it a bit difficult to relate this to standard regression . as i read it the $ x_i $ and the $ t_i $ are all data so there is nothing to estimate here except the intercept $ i_0 $ . i'd like to see the output from a statistical program , which would flag this situation . otherwise put , what is inside your vector $ beta $ ?"
206073,"if you don't care about the function , why do you think you need it ?"
206273,"by "" linear regression did not fit "" , how did it not fit ?"
206571,can you give a complete citation for the paper in question ?
206834,can you tell us more about transformations that you perfrom ?
206837,are you looking for a joint test of significance for all your indicators ?
207175,do the test regressions match ?
207183,can you clarify what do you mean by parametric models ?
207193,"( 1 ) the plot cannot be correct , because the sum of weights of outgoing arrows is not unity . ( 2 ) since your data are not given in the form they would naturally take if you had observed a sequence of transitions , what exactly do they represent ?"
207303,what would you do with this number if you had it ?
207325,"i want to raise pretty much the same points as scortchi . how do you know "" if the p-value of a statistic test does not follow uniform distribution "" ?"
207544,self-study ?
207653,do you know the definition of the deviance ?
207739,"over-fitting most likely , and small sample size . 16 fold cv in your case is only dropping 3 or 4 units . that is weird about loo not giving consistent results though - possibly a machine precision thing ?"
207833,"are you only interested in the uncertainty in the globally optimal objective value , and not the uncertainty as to the one or more argmin values which achieve it ?"
208042,davidechicco . it is position a row identifier you could pull it out and put it into a column in the dataset ?
207728,"is your "" known distribution "" vector sparse ?"
208641,please provide some context : how were your data obtained and what distributional assumptions are you making ?
208684,what exactly do you want to compare ?
208940,"i don't know anything about this , but a quick perusal of url , shows that your 'info' is being used to specify entries in the estimated ( inverse ) covariance matrix which are constrained to be zero . are you constraining all entries to be zero , or at least enough of them that all zeros is the only solution it can find ?"
208977,does the title of the question actually match what you really want to know ?
209173,"scortchi , perhaps * off-topic * is not a very good characterization . imho , the first question is valid but too basic ( there is no such reason for closing , though ) , the second one is * off topic * while the third one is * too broad * . what if the op deleted the last two questions ?"
209421,is this homework or self-study ?
209472,"i don't follow this . what "" 4x4 covariance matrix "" are you referring to , eg ?"
209593,could you give a reference for the pp test with an exogenous break ?
209827,sorry--what does the first row signify again ?
210417,is ` crop ` associated with a specific field / site / block ?
210458,"question 2 : could you please elaborate what do you mean by "" terrorist attacks "" , "" internet use "" and "" stability "" ?"
210751,"welcome to cross validated . in order to allow our users to help you , you need to add more details to your post . can you post some of your output here so that we know what you're dealing with ?"
210836,"could you expand or at least define and explain your many abbreviations , to make this intelligible ?"
210872,this isn't sufficient -- what did you derive the conditionals to be ?
211213,could you describe verbally what you code does ?
211238,i don't understand your situation . are you wondering if there were more app installs as a result of the meetings you've conducted ?
211345,"given the likelihood function , all that's left to do is to maximize it with respect to n . do you know how to do that ?"
211647,"sorry i might be reading it wrong , but won't the sum of med and high always be 1 ?"
211657,"i do not understand this plot . what does the "" index number "" represent ?"
212052,"to be clear , you want to compute the correlation between two matrices ?"
212354,"do you have a specific prior and likelihood that you are interested in , or is this a general question ?"
212573,"i dont understand , what is the question ?"
213136,are you doing the calculation for the odds ratio or the log-odds-ratio ?
213257,what do you know about the sequence of $ x $ s ?
213278,"this seems at best an indirect and awkward way to approach the question of how two variables are related . you have two variables , so plot them and then think about their relationship . if you show us the data , or at least a graph , we might be able to suggest a model . in contrast , division into quintile bins is arbitrary and loses information . what is that you are comparing , the means of # patients diagnosed for different bins of years in practice ?"
213320,"your intuition is good , but i think the question as it stands is too abstract yet non-technical for me to give a good answer . can you edit the question to provide more context ?"
213438,can you tell us which research paper you are referring to ?
213534,could you give a full reference for tsay ( 2010 ) ?
211544,"your question is very subjective and opinion-based . what do you mean by "" good explainability "" . why do you consider regression to be "" poor "" ( comparing to what ?"
214015,have you tried looking into packages that specifically cater to big datasets ?
214126,this book url gives a very good and clear answer to your question in 600 pages . i am afraid that your question may be too broad to be answerable in a consise way . could you try to make your question more focused and precise ?
214221,minor notation question : you indicate that $ vec x_i in x ^ n $ but the domain of $ d $ is $ x times x $ . should the former be $ x $ or the latter be $ x ^ n times x ^ n $ ?
214440,could you explain the purpose of your analysis ?
214467,what is the purpose of doing this ?
214515,"hi , and welcome ! i took the liberty of editing your post a bit . question : if you are talking about a * posterior * , then you * won't * "" encounter "" a single value from this distribution the next time you perform an experiment . are you trying to summarize a * predictive distribution * , i . e . , the forecasted distribution of a future * observable * ?"
214634,have you considered taking the mode instead ?
214801,"since for large $ n $ the central limit theorem implies $ s_n $ will have an approximately normal distribution , and no gumbel distribution is normal , it is important to know the value of $ n $ . in particular , the answer when $ n = 1 $ is a gumbel distribution . could you tell us what your $ n $ is and what the estimated gumbel parameters might be ?"
214909,do you think this is a coding issue or an issue of your conceptual understanding of training nns ?
214926,"math looks ok to me . you should probably say 'stochastic gradient descent' , since you're operating on a single point at a time . sgd is sensitive to the learning rate . yours is small , so maybe it's just progressing very slowly . have you tried changing it to see what happens ?"
93540,do you know about seemingly unrelated regression ( sur ) ?
215025,could you be more specific about your problem ?
215034,"what do you mean by expressing it as "" formula "" ?"
222227,"since $ x $ was transformed , not $ beta $ , a "" back-transformation "" of $ beta $ would seem to make no sense . could you clarify what you are hoping to achieve ?"
235504,do you know if the population being sampled from is normally distributed ?
254077,things seem to be inconsistent as gsw comments . if for subject 101 observation 560 no_day is 205 exp ( 205 ) cannot possibly be 0 . 000035 . is this all your data ?
272597,"please tell us what you mean by "" cumulative variance "" : your formula , by ignoring variation in the means of those "" elements , "" does not appear to provide their actual cumulative variance . and could you also stipulate what you mean by "" best way "" ?"
275789,it might help if you provided a little more information . is there any way you could provide a plot or provide output from the summary of your model ?
295422,"what do you mean by "" as $ x , y to infty $ as $ x to infty $ "" ?"
311054,"1 irishstat but i wonder if bamboo77's "" no other variables "" includes seasonal identifiers . . . that is , is she ( or he ) simply looking for a description of each time series against the clock , but not against theories of the clock ?"
215762,"asking for code is off topic here . if you are having a problem with a concrete coding issue / errors , it can be on topic on [ so ] with a [ reproducible example ] ( url ) . can you add one ?"
217464,couldn't you downsample matching sets ?
217524,what do you mean by standarizing them and what do you want to compare ?
57976,"what do you understand "" evidence "" to be here ?"
219195,can you add more detail / context ?
219384,what exactly is unclear for you in this formula ?
219388,looks like you didn't finish writing the question ?
219526,hint : what is the variance of the bernoulli variable $ 1 { x_i le m } $ ?
221092,why do you want to transform the data ?
228297,what does the support of your random variable look like ?
228339,"how were the clusters identified , exactly ?"
228341,a separate issue might be lurking here . the high adjusted $ r ^ 2 $ and low overall p-value are startling in light of the nonsignificant coefficients : that suggests there is a severe collinearity problem . ( have you run collinearity diagnostics ?
215102,can't you just read off the coefficients of $ t $ and $ t ^ 2 $ in the characteristic function in order to deduce the values of $ mu $ and $ sigma ^ 2 $ ?
215154,if this question was already asked but you find it important to re-post it after some time passed than maybe you could provide a link to the previous question ?
215167,what does the scatterplot look like ?
215196,"1 . what does "" results "" mean , specifically ?"
215214,what are the variables ?
215241,it is not clear what do you mean by using mle for hyper-hyper-parameters - could you provide an example ?
215328,"i'm having trouble understand the question . it sounds like you're talking about binning continuous values in $ [ 0 , 1 ] $ into discrete categories like "" good "" , "" excellent "" , etc . based on pre-specified ranges for each bin . are you asking what the the justification is for this procedure ?"
215338,but why did you need 2 colours on the 1st one ?
215182,yes . error ( site / time ) . not yet clear about coding or scoring and is that an 'interaction term ) frequently used in anova ?
215377,"flipping a log-normal results in a left skewed distribution on the negative numbers , bounded above by zero . is that what you meant ?"
215420,what is the purpose of such matching ?
215425,perhaps you should edit your question title to make it clear you want something that applies to interval data ?
215230,what is the actual question ?
215384,can you describe the method and how it compares to logistic regression ?
215532,the error message is telling you that with all the variables in the model the model can either perfectly match the result ( no statistical error ) or that you're trying to estimate more parameters than you have data points . how many rows of data do you have ?
215560,what do you want to learn from your data ?
215635,how many data were there total ?
215648,"do you expect run time to be a function of this parameter , and are you trying to approximate that function ?"
215697,can you post some more details ?
215442,"what does "" similarity "" mean to you in your situation ?"
215777,can you provide more context for this ?
214852,"it would be helpful to know how you are quantifying prediction accuracy- an r2 metric , leaving data out , or something else ?"
215587,"it is strange to see "" error term "" and "" pareto distribution "" in the same sentence , because it is hard to conceive of the pareto as a meaningful distribution for an * additive * error . are you perhaps using it multiplicatively ?"
215847,"i don't totally get your experiment , but do you really want treatment nested within time ?"
215861,"because your description isn't clear , could you confirm the following interpretation ?"
215835,two questions conflated here : why not more commonly used ?
215604,"i take it you are doing iv from a gmm perspective and in stata lingo , trying to calculate the "" robust "" weighting matrix ?"
215920,why do you believe you need a nested random effect ?
215926,check url or url but i'm wondering what is aim of your study ?
215943,can you cite where you read this ?
215802,"the answer to "" how can one test for the presence of the x vs y correlation while accounting and controlling for the presence of x vs z "" is to perform a multiple regression of $ x $ against $ y $ and $ z $ . could you explain why any of the other information you have provided would indicate that is still not the right answer ?"
215967,"exactly what is this "" average standard deviation "" intended to represent ?"
215985,"( 1 ) yes , your interpretation is correct . the answer to ( 2 ) is a bit more involved . are you familiar with matrix notation ?"
215557,is the bimodality an artifact of the binning for the histogram or a reflection of real behavior ?
216046,do you believe there is a relationship between the seed value and the goodness of the model or are you asking how many seeds to try ?
216051,"it should work correctly , you are taking the right approach . how about if you plot x1 versus y ?"
216057,"is your diagram intended to convey that the original data are bounded on ( 0 , 1 ) , or is that just how the drawing turned out ?"
216130,"what do you mean that "" r gives me an error that i have to few observations of one variable "" ?"
216148,what is the relationship between $ x $ and $ x $ ?
216177,"possibly , yes ; consider the proportions of sand , silt , clay in a sample , with the sum of these proportions equal to 1 . if i remove clay i can still work out it's contribution because that is 1 - ( sand silt ) . by definition , sites with no wetlands will have proportionally higher amounts of one or more of the other land-use types because the land use must be something other than wetland . the opposite is true too : high wetland % - low everything else . i presume these proportions don't add to one here otherwise i'm not sure how the model even fitted ?"
216029,"what do you mean by "" how close is the given data to the circumference of a unit circle "" ?"
216307,why don't you try ?
216238,what was the sample size for your data ?
216335,you have been reading for days about the ordinary least squares estimation method and you haven't hit on the $ ( x'x ) $ matrix and its role as regards the standard errors of the obtained estimates ?
216205,"what would the "" predictors "" be in comparing two means ?"
217350,""" due to computationally intensive calculation of stahel-donoho , the mcd estimation is preferable . "" can you cite the source for this claim ?"
216310,"it is not clear what do you mean . in general , in regression case you have model like $ y = beta_0 beta_1 x_1 beta_2 x_2 varepsilon $ where $ beta_0 , beta_1 , beta_2 $ are unknown parameters to be estimated . in your case you seem to know them in advance ( 1 , 2 , -1 ) , so what do you want to estimate ?"
217392,"your question is unclear : you can easily find the value of $ mathbb { e } [ x y ^ 3 ] $ as a function of $ sigma_1 , sigma_2 , rho $ . what is unclear is how does the data intervene in this evaluation . do you mean estimating $ mathbb { e } [ x y ^ 3 ] $ based on the data ?"
217401,which community are you interested in ?
217407,what is your y variable ?
215541,""" mse measures the quality of an estimator , while mspe measures the quality of a predictor . "" - this will depend on your context and community . i work in forecasting . forecasters * always * use "" mse "" for the thing you call "" mspe "" - simply because the * prediction * error is the only one we are interested in . who cares about the error on unobservable parameters , anyway ?"
216333,1 . by step 6 do you instead mean that everyone has added to * each * of the original notes ?
217454,"there must be a typographical error in the crucial part of your question , because "" $ x ^ prime $ "" appears nowhere on the right hand side of the defining equation for $ k $ . could you please fix this ?"
216325,what does the image represent ?
216110,what is the support of that density ?
217505,what is $ f $ . . ?
217507,"for me it is not clear what you actually do , what you optimize and what weights are you talking about . . . could you try to make your question more clear ?"
217596,which relation are you trying to discover ?
217597,is there any problem with summing the results ?
217593,"prior , or posterior distribution ?"
217687,isn't the point of trees that cutoffs are found in a data-driven way and do not have to be pre-specified ?
217770,"for each observation , you have measurements $ a_i $ , $ b_i $ , and $ c_i $ ?"
217777,do you have data on customer profiles ?
217792,what does $ gg $ mean ?
217785,what does multivariate mean here ?
217817,why not just set a lower bound for ili times and discard those that are too short ?
217846,you need to describe your experiment a bit more . . . . are the samples and controls paired together in some sense ?
217717,welcome to cross validated ! what are you asking exactly ?
217895,` how do i know it converged to a global and not a local minimum ?
217972,why do you think it would affect the validity of the cox regression ?
214513,( plus : what does the subscript $ y $ refer to in the $ epsilon_y $ error term ?
217998,"the underlying question is not sufficiently well framed to have an answer . what would "" probability "" of success mean ?"
215744,a little more explanation of the context might help here . why do you want to go further ?
218040,"do you have the same measurements available for the future point in time , for which you already have the 5 mentioned values ?"
217786,"if you got errors with the data , you should get errors with the covariance matrix ( unless you had missing data , or used something other than ml ) . perhaps some code would help ?"
218102,are you only ever going to have one predictor variable or perhaps several ?
218205,have you considered not doing pca ?
218213,"hot issue in us at the moment . need to be careful about "" selective reporting "" in terms of what actually gets written down by police officers . for example , how are 'warnings' handled ?"
218265,"because the [ expectation of any positive variable is the integral of its survival function ] ( url ) , $ $ mathbb { e } ( x ) = int_0 ^ infty ( 1-f ( t ) ) dt = int_0 ^ 1 ( 1-ct-2t ^ 2 / 5 ) dt = 1-c / 2-2 / 15 . $ $ thus , you need only compute $ c $ . could you show us how you found $ c $ ?"
218188,what is the nature of the recorded data ?
218356,"please be aware that to most people what you are doing is * transforming * the data ; "" normalization "" is something entirely different . there obviously are problems with your transformations , since you cannot even deal with the zeros . what motivates you to try these particular transformations and what evidence do you have that they accomplish anything useful ?"
218358,i don't understand point # 4 in the reproduced table . what table lookup are they talking about ?
218388,"i was taken aback at "" correct for regression to the mean . "" could you explain how you expect that to improve the prediction ?"
218389,can you expand on your second question as on the face of it they would not be addressing the same scientific / clinical question ?
218238,"this is all rather verbose and somewhat confusing . is the question essentially , "" i have a random variable $ z $ for which i've calculated the sample mean $ x = frac { 1 } { n } sum z_i $ and the sample standard deviation $ s $ . how can i calculate the standard deviation of $ frac { 1 , 000 , 000 } { x } $ ?"
218360,"what is the "" non-linear least squares estimator "" ?"
218417,are you sure the variables are dependent ?
218337,do you know what the 8 motivations & 4 running groups are already ?
218229,"who is "" you "" in your question ?"
218448,"you mention the kernel size , so it sounds like you're using an rbf kernel . are you optimizing this hyperparameter ?"
218490,what kind of convergence are we talking about ?
218410,possible duplicate of [ how can i test the difference between a population proportion and sample proportion ?
218548,how much data do you have ?
218557,are your models actually different ?
218567,"mdewey thanks for the tip . i'm a bit skeptical about the ability of monte carlo methods to overcome instances where 0 observations are present in a cell , but i'm not familiar with this method . the r help page on ` ?"
207932,did you find anything useful that address any aspect of your question ?
218632,[ why do statisticians say a non-significant result means you can't reject the null as opposed to accepting the null hypothesis ?
218638,"1 . see [ this question and its answers ] ( url ) . 2 . given the nature of your question has changed , and assuming you don't still have answers here after reading that link , can you please edit out the questions that you now understand and just focus on what you want to know ?"
218649,"hi ruehri , i'm interested in a similar kind of problem , would you mind if i slightly modify the question to include examples in theano plus a suggestion about the network setup ?"
218021,"currently your notation says "" instrument i = avg profit & max loss / per trade = instrument ii = instrument iii "" . is this correct ?"
218644,""" ` promotion ` is the promotion-value for the day - it's simply the number of times an advertisement has been on television . "" this description makes me think ` promotion ` should be an integer . how can an advertisement be on television 20 . 8 times ?"
218667,care to explain why the single regression line looks better to you ?
218681,"if there is no way the test says you have the disease if you do not have it , then what does that imply for you having the disease if the test says you have it ?"
218691,""" i tried to approximate the experimental data as a normal distribution and then do an exact multinomial test using the xnomial library for r "" i think we'd need a little more detail on the approach before saying whether it's reasonable or not . and is there any reason to think the distribution of failure frequencies will have a normal distribution in the first place ?"
218782,"the data look plausibly bivariate normal so a good starting point would be the means and covariance matrix , but if you could post a sample dataset itself that would be better . moreover , the question is a bit confusing because you don't state what programming language you want to use . what compilers or run-time interpreters do you have access to ?"
218821,did you read the next paragraph ?
218837,possible duplicate of [ what exactly is a hyperparameter ?
218889,is it homework ?
218919,"you might need to be more specific . there is ` rjags ` which provides an interface to jags . do you want specific models , e . g . regression , glms , non-linear ?"
218880,"$ f ( x ) $ is simultaneously the tightest possible upper and lower bound for $ f ( x ) $ . this shows that you need to provide more information in the form of constraints : what kind of formula would constitute a "" bound "" ?"
217428,"are your data in the form $ ( x , w_1 , w_2 , y ) $ or do you have separate datasets with one involving $ x $ and the other involving $ ( w_1 , w_2 ) $ ?"
218900,do you have any additional information about your subjects and the scores ?
218996,"well , there are many possibilities . more details could help narrow it down , like what's the number of both negative and positive samples ?"
219028,"1 ) this is a stats question , not a programming question . 2 ) cant you just ` sample ( 0 : n , n , replace = t ) ` ?"
208416,why do you expect that the covariance will die for asymptotic n ?
219029,take * any * bivariate dataset . plot it . pick any one of its points and slide it up and to the right until it is so far from the rest of the points that you cannot distinguish them from each other on the graph--they are all clustered in a little space at the lower left . ( 1 ) what happens to the spearman coefficient ?
219082,"if the transaction is not fraudulent , is * * amount * * the expected gain ?"
219114,would you find it easier to compare areas of square shapes ?
219134,"wolfgang , to calculate $ sigma ^ 2 $ , why we divide by $ n-2 $ instead of $ n-1 $ ?"
215513,"if you say that the parameters of the svm's are not identical , do you mean the in both cases you have different radius r for the rbf ?"
219122,have you read section 2 . 3 [ here ] ( url ) ?
219120,"could you describe the "" tree structure "" in greater detail ?"
219233,"i don't understand why the topic would be urgent now , after almost two years . and i also don't understand what you're looking for . is it a text book description ?"
219259,why does the interaction between ` prepost ` and ` withindaytime ` reflect the * change in the change * from pre-to-post treatment ?
219159,shouldn't the expected number of events be the cumulative intensity instead of just the intensity ?
219283,you are correct : a picture would help . why not draw it ?
219338,it is not clear for me what and why do you want to resample . . ?
219362,"` using polychoric correlation with non normal ordinal data ` . the very title of your question is oxymoronous . how can a categorical data be manifestly normal or non-normal , i . e . continuous ?"
219407,"are you trying to see which of 2 proxies better agrees with a gold standard , or just what the agreement is between a proxy & a gold standard ?"
218873,what hypothesis test do you have so that you are looking for $ p $ -values ?
219451,welcome to cv . how have you been able to define firm age ?
219471,"i'm actually not so sure that the chi-squared test was made obsolete by the availability of computing power to perform fisher's exact test , e . g . are your marginals truly fixed ?"
219512,$ p_1 $ and $ p_4 $ are not random given the model . what do you mean by variance ?
219533,can you explain more about how your intuitive sense operates ( in a way that would make it clear why / how it excludes rmse ) ?
219556,your last paragraph is a bit confusing . are you asking what kind of monotonicity you need in addition to npl to get ump ?
219611,but what is the ultimate goal of the whole undertaking ?
219718,i wonder if there's something you're leaving out : is there some reason you can't account for these subgoals in a standard mdp state space and transition function ?
219684,"hi , it looks like you are using different data for both models ( all the numbers in the second matrix are higher than the corresponding value in the first matrix ) . why don't you run both models over the same data ?"
219786,is there any chance you could post your output from r ?
219243,"if you now the _formulas_ of them all , why not show them in your question ; and then ask "" how are their properties different given these formulas ?"
219857,"could you be more specific about what you mean by "" this method "" ( polynomial regression ?"
219891,do you have a variance-covariance matrix for these parameters ?
219899,"although not all functions with unique minima are convex , all convex functions have unique minima . often one can check that a function is convex much , much more easily than whether it has a unique minimum . that alone merits the attention . in what sense , though , are * all * ml researchers interested "" mostly "" in convex functions ?"
219939,is this purely for visualisation ?
219958,( 1 ) why not combine your datasets into one and draw the histogram of that ?
219971,could you show a sample that has the lower quartile at 0 . 7 and the upper quartile at 1 . 36 and yet has the variance at 0 . 1045 ?
219974,"could you please explain what you mean by "" matches "" ?"
220000,"can you please define what you mean by "" machine learning "" ?"
220034,do you have 44 observations on your 8 variables ?
220053,are you comfortable building a model with only $ n = 10 $ observations ?
219555,"1 . i wouldn't call this a "" power law "" . it's a quadratic through the origin . normally you'd describe something as fitting a power law where you need to estimate the power . 2 . why would you plot that on a log-log scale ?"
220119,"pls , provide background : what is the original source of the problem ?"
216095,"i got the feeling you should call sgdclassifier with 1 / alpha ( after your calculations ) . but this is just an empirical feeling looking at the default-value and the recommend grid-search range [ 10 ^ 1 , . . . 10 ^ -7 ] . another matter : are you sure your sgdclassifiers converged ( might be hard to check ; and yes , you got a huge amount of iterations , but that should not really help in theory , if the learning-rate / learning-rate-schedule is bad ) ?"
220144,are you also making the assumption that $ gamma 1 $ ?
220164,"where in the dataset are "" black "" and "" white "" even referenced ?"
220181,can records be replicated more than once ?
220184,"hello aphire , what is now your concrete question ?"
220199,". . . as an offset log ( employee ) ; - ) ( if used log-link ) ! imho . . . you've got the same results , but what ( in what scale . . . ) you wont ( prefere ) to interprete it ?"
220224,formulas for the sample variance of $ a_1 cup a_2 $ are given at url does that solve your problem ?
220228,i don't really understand your situation or what you're trying to do . can you make this clearer somehow ?
220078,"let me ask you if i really understood what your question . lets suppose you have the data $ x_1 , , x_2 , . . . , x_n $ . in your example you want to find out the value of $ x_1 x_2 . . . x_n $ , but you are not able to perform the whole summation . is that why you need the approximation ?"
220295,"imagine that you labeled etiquettes of the categories as 1 - "" not at all "" , 2 - "" a little bit more than nothing "" , 3 - "" much less than average "" , 4 - "" average "" , 5 - "" very very very very very much ! ! ! ! ! "" . now , would you say that the difference between 3 and 4 is the same as between 4 and 5 ?"
219959,welcome to cv and 1 . can you refer to the specific function you are using ?
220031,what was the reviewer's comment ?
219828,what is your interpretation of the intercept estimate ?
220234,this is probably too broad to be answerable in its current form . can you make this narrower & more concrete ?
220385,i can't follow your situation . can you make this more concrete ?
220408,"but when you compare , say , columns ( 5 ) and ( 6 ) , the estimates don't appear to be significantly different given the standard errors ?"
220308,"i find it's more error prone to specify the model . : ) counting by hand is how i check i got the model correct ( because of lavaan defaults , which can trick me ) . can you post your code ?"
220299,could you please edit your question to give the output of ` dput ( x . ts ) ` ?
220473,not necessarily--are you looking at an unstandardized estimate of the loading ?
220491,"pinocchio , two minutes of googling brought me to url where you can scroll down to read about "" histograms "" . have you already seen this documentation ?"
220505,"this question reads remarkably like your other two questions at url and url both of which ask exactly the same thing : "" can i ignore the multicollinearity . "" could you explain how the answers you got do not address the situation ?"
220594,"now , about the question itself , a clarification : i think what you mean is multiple measurements of the same observations , right ?"
220540,"do you have the same units measured in both proportions , or are they different units , but from the same population ?"
219918,do you mean that the agent cannot measure the state directly ?
220544,"are you sure the single quadrant ` atan ( z ) ` and ` arctan [ z ] ` are adequate as opposed to ` atan2 ` and ` arctan [ x , y ] ` ?"
220656,` codes for indices ` what do you mean ?
220653,"did you mean "" if $ p $ is also i . i . d . ?"
220650,so each person answered the questions twice ?
220705,how do you define the dimension of the model ?
220713,"because the answer depends on how to tell when "" arrangements for discharging passengers "" are distinct , could you please explain what that means ?"
220722,"would it help to have 21 predictor variables ( called a , b , . . . , u ) each zero or one depending on whether that level is present for this case ?"
220416,"you're asking about bias in the sample average of $ text { impact } $ across experimental units , but what population quantity is this average thought to be a biased estimate of ?"
220759,you have $ r_ { t 1 } $ in the beginning but nowhere else . should it be $ r_ { t 1 } $ ?
206707,what did you read ?
220760,the answer will depend on the purpose of the quality measure . can you clarify ?
220706,"these displays seem to be useful summaries of your results . they are even "" quantitative , "" showing the relative distributions of rankings in these 2 dimensions . why do you need something more ?"
220824,could you please say more about the hypotheses you wish to test with these data ?
220717,"( 1 ) what is a "" consistency estimator "" ?"
220879,how do you define correlation between a random vector and a random scalar ?
220889,from * which * data do you want to predict * which * information ?
220882,"could you elaborate what you mean by "" y-values are evenly spaced "" and "" the sample isn't uniformly distributed in time "" ?"
220908,please edit your question to address the following : what is the larger goal of this study ?
220920,i don't understand how it could cost you money to count visitors to your website . don't you already your web server's logs from every visit in 2015 ?
220921,one or two-sided hypothesis is the dilemma that you must decide on in advance . _could_ there be that b might turn out better than c ?
219459,you're probably missing an expectation on the l . h . s . ?
220972,"this is not a well structured question . are you trying to group levels of a factor , or discretize a continuous variable ?"
221028,can you separate the years into months ?
221077,i am not familiar with gauss- legendre quadrature . so what exactly are the $ x_i $ s ?
221134,"could you explain what you mean by a "" normalized "" covariance ?"
221195,your question indeed seems to be closer to the content at cross validated ( cv ) than to one at this site . do you want me to migrate the question to cv ?
220784,"what do you mean by "" the "" upper bound ?"
221266,"you know the binomial has two parameters , $ n $ and $ p $ , right ?"
220375,do you possibly mean that you would like an unbiased estimator of $ e left ( frac { a } { b ^ 2 } right ) $ ?
221325,"for the z-statistic , do you want to calculate the z-statistic from the pvalues of the z-statistic ?"
221329,"in many fields of physical science , $ r ^ 2 0 . 9 $ would imply incompetence of researchers and / or a useless theory . in many other fields , $ r ^ 2 0 . 1 $ might still be interesting depending on the state of the art in an otherwise intractable problem ( e . g . as indicating possible agents or influences ) . so , i suggest that there are no useful general criteria . literature in your own field should tell you what is publishable . otherwise , what do you mean by acceptable ?"
221348,"please explain what the bar over the $ x_i $ means . obviously it does not have the usual meaning of an arithmetic mean , for then the weights would be known . regardless of what $ bar x_i $ might be , i don't see where there is anything unusual here : aren't you just posing $ n $ separate regression problems ?"
220672,am i missing something ?
220788,"hi zach , welcome to cross validated . please tell us a bit more about the instruments . are you doing mid-ir or nir measurements ?"
221213,could you please clarify the nature of the ` population ` variable ?
221484,would you include such information if you were writing a report in a traditional manner with a word processor ?
221465,what are your true parameters for $ mu $ and $ sigma $ ?
221516,why was it transformed to the log10 scale ?
221535,"small terminology issue : these are not two datasets , but two variables in the same dataset . small practical issue : please provide the data so that they be copied and pasted . provision in an image is much less helpful : who wants to type in 32 numbers with lots of decimal places ?"
221524,"could you please say a bit more about the nature of the "" proportion "" that ` tr . ma ` represents ?"
221556,""" data in aggregate ?"
221475,not necessarily . what about the outliers ?
221205,what does your stratification information look like ?
221630,"$ ldots , $ finding a confidence interval for the $ x $ -intercept ?"
221648,( 1 ) i suspect ` proc genmod ` & ` nbreg ` may calculate standard errors from the expected fisher information rather than the observed . ( 2 ) see ` ?
221653,can you explain your data in a little more detail ?
221582,1 ) do the questions increase in difficulty as the test proceeds ?
221674,"1 . but instead of "" sitting utilized "" didn't you mean "" sitting unused "" ?"
221685,do you have an actual graph ( edges and nodes ) for the paths that these points lay upon ?
221684,significance of what ?
221701,perhaps a different question you could ask why is your method better that differencing months ?
221703,"there is an attribute ` ` ` reconstruction_error_ ` ` ` which could be used , although i don't know how to make this compatible with the given gridsearch functionality . but there is also the more general question : what are you using this embedding for ?"
221704,what's the data ?
221715,have you decided on a specific method for representing documents using pre-trained embeddings ?
221713,"it sounds like icc might not be what you want . please edit your question to add [ these details ] ( url ) , and also to clarify your secondary question : you say you are "" being asked about variability within persons , relative to the variability over time "" , but * what * are you being asked about it , and who's asking ?"
219607,"i edited your question for readability . however , i don't think i understand what you are asking . are you asking if your code is correct ?"
221716,"great . another thing : in your $ y $ matrix , do all $ mn $ points represent * the same * organ property , or are some measurements of thickness , some measurements of curvature , etc . ?"
221756,could you share more details about the planned analysis and the estimates you have obtained ( and their sources ) ?
221721,the problem probably lies in the error message from r so i would focus on this and not try to get around it by running the same model in matlab . which model gave this error ?
221863,can you say more about your situation & your data ?
221872,can you add a reference ( citation ) for the definition you are quoting - what is the source ?
221867,"by "" dependent samples "" do you mean _paired_ samples ?"
221907,"do you specifically want to do feature selection , or rather you are fine with using all the features but need to avoid overfitting ?"
221080,two questions : are _n_ and _ alpha_ known or unknown ?
221902,"what do you mean by "" in terms of x and y "" ?"
221914,can you provide more details about your data - for instance what are ` vara ` and ` varb ` ?
221877,"how are you defining "" best model "" ?"
221959,which variable are you regressing on which others ?
222086,do you want to predict the radio station based on single songs ?
222088,have you tried extracting word frequency for instance ?
222116,"could you edit your post to include a quote where your lecturer uses $ sigma $ , $ mu $ etc . in a way you don't understand ?"
222179,this problem can be answered in practical terms ( as stephankolassa did ) or in absolute terms ( some sort of theorem that shows a given model can learn a problem iff certain conditions are satisfied ) . which one do you want ?
126829,does it account for explanatory variables ?
222023,your question is too broad to be answerable . what are you modeling ?
222198,"i struggle to understand what you're asking . as you've said , the purpose of the model is to model both topics * and * links . how else would the model learn to predict links if not from training data ?"
222215,"talking about consistency is when we have one estimator . but then say you have two consistent estimators , then which do you choose ?"
222278,what do you mean by small ?
95667,"would it be at all possible for you to provide a reference for the table you used , here ?"
222289,do you have pre & post data ?
221751,"( 1 ) can you explain at all * why * your statement "" has been strongly criticized as incorrect "" ?"
222351,what exactly do you need help with in interpreting the table ?
222461,"19 predictors with 41 observations is almost certainly resulting in some overfitting , the main question is how bad it is - did you also perform some variable selection from even more predictors ?"
222422,""" to deal "" in what context ?"
222465,please give more details on your research questions . between the two what ?
221745,possible duplicate of [ how often do you have to roll a 6-sided die to obtain every number at least once ?
222376,"please clarify the physical relations among the variables you list under "" design or nesting . "" that's needed to determine the nesting vs factorial structure . for example , do different regions have different sites ?"
222570,i edited this to fix the english . but we need a lot more detail . what is your dependent variable ?
222499,"you've described the physical information without providing a rationale for why you need it to be at intervals of only one minute . in addition , it sounds as though you've collected data for only 1 month out of the year -- october . is that correct ?"
222627,"it's machete work to see the question here . you are asking what would be good summaries of . . . data you don't show us . that's hard to say . i'll peel off one facet and say that for all the interest of chebyshev's inequality in probability theory i've never seen it used to report on real data . for one thing , would your audience know anything about it ?"
222654,you said ` patchtype ` is a blocking factor - so how can it be nested in ` treatment ` ?
222700,is it possible the components of the deviation could be correlated ?
222708,"i'm not familiar with matlab but [ mnrfit documentation ] ( url ) suggests that it is for fitting multinomial logistic regression , not a 'standard logistic regression' as you name it . perhaps a confusion there ?"
222746,could you please say more about the relations among the 5 different outcomes you are modeling ?
222740,"sorry , i'm not sure what you mean by "" nearly impossible . "" are you suggesting that , given random sampling , it would be "" nearly impossible "" to get different betas ?"
221161,does it work correctly if you kick out the random effect and use ` lm ` instead of ` lmer ` ?
221522,what is the random factor of your mixed model ?
222848,"quick thought , define $ hat { x } = x_ { max } - x $ ( i . e . flip the histogram , whatever it is , left-right ) and you'll get a right-skewed distribution which comes up quite a lot . . . ( exponential distribution , log-normal , etc . . . ) . how is "" configuration "" projected onto a single dimension ?"
222873,cross-posted at url i've lost count of the number of times i've asked you not to re-post your old questions from * mathematics * here - would you please stop doing it ?
222925,can you clarify exactly what you understand by changing the scale of $ y $ ?
222914,what exactly is the problem ?
222949,"are you more interested in prediction ( predicting habitat selection for new telemetry data ) , or inference ( understanding habitat selection using telemetry data ) ?"
222969,are you simply repeatedly calling the model . predict ( ) function after the net is fitted or rerun the whole python script ?
222961,"at first blush , it would seem you could formalize this as a partially observable mdp . but , i've only ever seen pomdp observation functions expressed as a function of the $ s' $ , i . e . the next state , rather than the current one . ( your intuition paragraph somewhat confuses me when the agent acts , it decides whether to check and then gets a probabilistic observation if $ z = 0 $ , but gets a reward based on the state of $ z $ , is that right ?"
223034,"i would not expect the intervals between bug reports to be exponential -- they'll tend to come in clusters after new features are added , and then reduce as bug fixes are released . they might also be affected by day of week effects and time of year effects and so on . it's just possible they might be reasonably approximated by a mixture of exponentials perhaps , but why do you need a specific distributional model for the times ?"
223071,have you considered multiple imputation to deal with the missing data ?
222844,why are you avoiding anova ?
223123,i do not understand your question . . . what improvement are you writing about ?
223117,"sales are * always * seasonal and autocorrelated . if your model structure does not account for autocorrelation , then it'll show up in residuals - where else could it go ?"
223178,"aksakal , but is there anything "" right "" with this ?"
3069,would you care to explain why you couldn't also look at r ?
223297,has your question been solved ?
223316,why is the seasonal flag set to false ?
223379,where income in your arima ?
223404,also how many rows and columns do you have ?
223431,can you expand on the statistical question here ?
223436,"are these distances two-dimensional , as suggested by the image , or three-dimensional ?"
223433,"your example is unclear . you have ` event a ` and ` group a ` . so when you say ` a is 90 % of the users ` , which ` a ` is being referred to . btw , why would you use the same letter to describe two separate entities in an example ?"
223465,can you assume that the raw data within the original studies have a ( roughly ) symmetric distribution ?
223468,"by "" new test feature set "" are you referring to adding a new independent variable coded for each correct prediction ?"
223415,"if you don't apply some such constraint , you could not identify any of the parameters , because you could add an arbitrary $ delta $ to each $ alpha_i $ and compensate by subtracting $ delta $ from $ mu $ . so are you asking why * some * constraint is applied or why * these particular constraints * are applied ?"
223577,"do you have a specific function , $ f ( beta ) $ in mind ?"
223582,why do you think those odds ratios are appropriate for a proportional odds model ?
222812,"i think that you need to start with a clearly stated question that can , at least conceptually , be answered given the data you are collecting . for example , does equality of ability improve results during cooperation ?"
223668,what about reading something like url first ?
223671,"could you explain what you mean by "" moving randomly in groups of 4 "" ?"
223679,can you assume that the population means of $ x $ and $ y $ are zero ?
223494,"can you provide the exact reference that mentions the "" laplace noise "" ?"
223721,thanks . will try to replicate it and update my answer . is that the output you get from running it on your real data ?
223749,do you have one 7-by-7 confusion matrix or all possible confusion matrices at the different thresholds ?
223794,"what's your data size , number of columns and rows ?"
223805,"obviously it can be done in $ n-1 $ evaluations due to the sum-to-unity constraint . this suggests drawing the $ v_i $ in the same order as the descending sequence of $ d_i $ , stopping at any point the sign of $ s $ is definite . if you want to do any better , what can you tell us about the distribution of the $ v_i $ ?"
223835,"when you say it will come back , have you actually tried it ?"
223802,"please define your abbreviations , what is oob ?"
222727,"1 ) why the particular lag structure ( 1 , 3 , 5 ) ?"
223862,can your plot the joint confidence ellipse for the two coefficients ?
223893,"before formulating the solution , you should formalize the problem . what is your algorithm calculating ?"
222604,what exactly is your question ?
223918,what happens if you use random = ~ 1 source ?
223924,are these really * confidence * intervals ?
223922,"how do you know that the random effect "" is not significant "" ?"
223965,are you not using head size as a predictor ?
223967,since you have the raw data why not analyse that directly rather than using a two-step approach of calculating a summary statistic and meta-analysing it ?
223983,"this is a strange question . you suggest a procedure without supplying any basis for it , offer an example showing how awful it can be , and then ask "" is it useful ?"
223986,do you have any remaining questions or concerns after reading url ?
224000,there are a number of very unclear points in your question . to mention just two : 1 ) ` have a 127-question survey . . . with efa i have kept 56 items and got 8 factors ` what does that mean ?
223535,are these questions from a course or textbook ?
224033,do the distances between the suppliers matter ?
224097,"just to be sure : you are not using any "" factor rotations "" here ?"
224115,"tsay has written quite a few things . could you please give the specific reference you are following , for the benefit of future generations ?"
224177,you consider doing this in two stages ?
223818,what is $ beta $ in this context ?
224170,why not read some of [ our posts on the clt ] ( url ) to understand what it actually says ?
224188,did you resolve the issue ?
224204,was the pca done on the covariance matrix or on the correlation matrix ?
224098,so you want $ x $ uniformly distributed and then you define $ y = sin x $ and $ z = cos x $ ?
223885,i like your question and suggested some edits . please specify how you generate $ pi $ from the $ x $ . do you estimate the probability for observing $ y $ and then generate inverses from it ?
224200,what is the goal of your analysis ?
224316,"i'm not sure i understand what you want to do . if you have data on likes of posts and their corresponding comments , wouldn't it make more sense to look at a scatter plot where the x-axis is the number of likes on the post and the y-axis is the number of likes on the comments ?"
224330,"could you specify what kind of "" improvement "" you have in mind and how do you see machine learning's role it it . . ?"
224337,"by "" random sampling "" of data do youy mean bootstrap ?"
224308,can you post a reproducible example ?
224374,do you think your own question is a duplicate ?
224380,can you please edit your question to include the output of ` summary ( fit ) ` ?
224361,"when the expectation of a * non-negative * random variable ( such as $ ( x-ty ) ^ 2 $ ) is nonzero , what are the chances that variable is positive ?"
224413,i think whuber is hinting that we don't know enough about your problem to give you much help . can you edit your question to tell us more ?
224415,auroc value of 1 . 0 on test or train set ?
224239,"when you say "" ancona "" what does the second n stand for ?"
224403,"what do you mean by "" didn't account for the number of replicates "" ?"
224509,have you had a look at url which gives an example of a three level model ?
224496,can you be more specific about the context in which you read this sentence ?
224544,what are you trying to achieve by knowing the movie preference similarities of two users ?
224665,are you following the notation in some particular work ?
202518,what do you mean by x and z being the same ?
224761,user112638 what do the four activity frequency values represent exactly ?
224759,why do you want this ?
224747,there is not enough information here to answer the question . what are the cards and their quantities ?
224786,why do you need f ?
224745,"what do you mean by "" identical specifications "" ?"
224817,can we get a link to the paper ?
224833,what's actually the question ?
224843,how good is your network at performing the task ?
224844,why are ` baseline_age ` and ` subject_id ` perfectly correlated ?
224916,maybe you can help me with this an old man in the sea ?
224919,"should the last bit of paragraph 3 actually say $ x_t - x_ { t-1 } $ , or something similar ?"
224971,"how to define "" prove / show "" , are you trying to ask an algorithm to search the data set that contains certain pattern ?"
224862,when you say $ bern $ do you actually mean [ * binomial * ] ( url ) ?
224980,"whuber yeah , but that's not the way that this cut-out seems to be doing it . you're referring to the alternative option of taking the second moment of the first derivative , right ?"
224990,do the discontinuities at t = 24 / 0 for the polynomial fit annoy you ?
224653,"( 1 ) for those interested , spanos is discussing the "" submarine "" example from [ morey et al . ( 2015 ) , "" the fallacy of placing confidence in confidence intervals "" , * psychonomic bulletin & review * , pp 1-21 ] ( url ) - & see [ what do confidence intervals say about precision ( if anything ) ?"
224995,"please explain what you mean by "" multiply the points "" by a constant . would that refer to ( a ) changing the units of measure of $ x $ and $ y $ or ( b ) rescaling the values of the process ?"
225042,what's the evidence that anything is actually converging to anything ?
225069,"say you need to predict [ 1000-year flood ] ( url ) , it's something that happens * very * rarely ( you [ may even have no data ] ( url ) concerning with such case ) , but still you may * need * to build some model and predict it . . . what would it change if someone arbitrary told you that you need e . g . 50 % . . ?"
225094,"i'd say you have it backwards . if we enter coefficients , we believe that we * know * them . on what basis would we calculate standard errors , which are a measure of the parameter estimates' variability ?"
225122,why not just bring your 3rd measurements to a 1-100 scale ?
225046,is $ kappa $ non-random ?
225210,could you please indicate how many samples there were in your analysis ?
224029,"in your sample code , why do you take square root in "" weighted_mu = sqrt ( wtd . mean ( d $ value , d $ weight ) ) "" ?"
225239,""" enough normal "" to do what ?"
225273,"1 because it sounds interesting . ( "" * . . . the square is solid $ i times i $ . the circle $ s ^ 1 $ is hollow ( dim 1 ) . . . i 'm not a statistician * "" . . i would have never guessed ! : d ) more seriously , what you mean by * mixed noise plus gaussian * ?"
215212,"what would constitute "" reliable "" for your purposes ?"
225341,"do you have a specific problem class in mind to which you are applying em , as well as the type of constraints , and algorithm / software for performing it ?"
225340,1 . are you asking us to check your code ?
225348,"do i understand you correctly that you want your algorithm to work "" online "" with new inputs and learn from them . . ?"
225385,40 features and 105 rows ?
225395,"a good question , i would in fact like to see a good reference for this too . sidenote : with a model this powerful you might be able to use all features just in their raw form , but i understand that this is not what you aim for . additionally you might a ) one-hot encode unordered factors , b ) convert multilevel factors to plain numerics ( this introduces an additional and probably wrong relation ) or also one-hot encode them , then c ) treat all those like continuous variables and apply scaling etc . before handing them to models . but i guess this is what you'd call a "" rough fix "" , right ?"
225422,did you include an interaction in your ancova with your baseline ?
225390,one other difficulty i have is the title and first paragraph refers to * future * values but later the body of your post seems to be talking about predicting observations in the past . which 18 time periods are you trying to predict ?
225482,are those the * only * requirements ?
225495,do you really need an unbiased estimate ?
225434,what is / was the measure going to be used for ?
225514,"instead of writing "" common nonlinear transformations "" could you be more specific about what this family needs to achieve ?"
225536,"your question seems to revolve around a possible misinterpretation of "" almost sure convergence "" ( or possibly in assuming it even applies ) . the formula you provide is unclear : what exactly do you intend it to say ?"
225539,"what exactly do you mean by "" tune "" and what do your data look like ( if you have any ) ?"
225477,"you answered your own question with the last phrase , no ?"
225552,"use a pair of dice where one is red and the other green . you can tell them apart , but someone with red-green color-blindness can't . should the probabilities be based on what you see or what he sees ?"
225575,"i agree that the proposed idea has issues . just to clarify : calls are not assigned to a group from the queue , they are grabbed by the next person to pick up , who might be from group a or group b , correct ?"
225588,it's obviously a bug and appears to be a result of gross extrapolation . are you looking for any other kind of answer ?
225557,"i think this is a great question to ask because it gets to the heart of multiple comparisons corrections and key assumptions in conducting this type of analysis in the context of a common vein of research . however , the only question in the text is "" does someone with more knowledge than em want to comment on it ?"
225654,i understand that the user can check how many attributes as he wishes and how many times as he wishes . what i don't understand is what you want to do with your weighted index . why do you need an index that values three times more if the user checks type than if he checks country ?
225675,hm . . . it retrospect it should but then why you have so few df's ?
225677,possible duplicate of [ what skills are required to perform large scale statistical analyses ?
225720,"imagibe a scenario with two missing values per line , randomly scattered over columns . how do you want to fill the gaps by multiple regressions when there are no complete observations left to train the models ?"
225311,"do any of the insights in viechtbauer , w , bias and efficiency of meta--analytic variance estimators in the random--effects model , journal of educational and behavioral statistics , 2005 , 30 , 261--293 help here ?"
225761,what is the larger context here ?
225328,could you write the expressions for the functions you're coding algebraically ?
225874,"i laud your zeal in running down answers to every possible question nuance your students may encounter . however , if the stats text you have discuss only one type of hypothesis test , does that tell you something about the kinds of questions your students are likely to get wrt correlation ?"
225882,why are you using observed vs predicted rather than standard predicted vs residuals ( standard ` plot ( fit ) ` method ) . . ?
225740,i don't see why it's a problem . what happens if you run it ?
225701,can you provide some more context ?
225986,can you clarify the question ?
225994,"there's no difference whatsoever between the two * structures * you illustrate . did you perhaps want to show just * two * value fields in the second example--one for the type of tie ( 1 , 2 , or 3 ) and a second for whether it exists ( 0 or 1 ) ?"
226024,"1 to glen_b 's comment . plus , the way i read your question , the nonlinear dynamical map , $ f $ , is totally irrelevant to answering your question - if that is not the case , then why do $ f $ and iterateis beyond $ x_0 $ and $ y_0 $ matter ?"
226049,"if you are interested in the presence of an interaction , then the first model is the one you should look at . it checks if the effect of "" tree "" on survival depends on "" pctrans "" and vice versa . note that p values obtained by ` drop1 ` are very , very rough approximations only . do you think the binomial distribution is a good model here ?"
226056,"in your data set , how many cases are there for those who got that cancer , and how many that died from it ?"
225141,is the mere existence of such an effect actually interesting to you ?
226085,what is your question ?
226109,"just out of curiosity , what would be ` prob_real ` ?"
226134,most forms of meta-analysis require some measure of variability so the problem is likely to be the studies which just provide a single estimate . can you give us more details ?
226131,"a weighted average won't necessarily equal a simple average . if there is reason to suspect that they should , that could mean that your weights are inaccurate . can you type / paste in your data to make it easier for people to work with ?"
226171,what's the exact warning message provided by lme4 ?
225099,how exactly did you compute the those hazard ratios ?
225937,what is your outcome and what are the 6 covariates ?
226238,if you have an excess of zeroes have you considered zero-inflated poisson ( or negative binomial ) ?
226306,"if there is a simulation or an empirical illustration in the paper , some of the authors should have the code ( otherwise , how did they do that ?"
226326,where do these percentages come from ?
226369,"btw , it is not $ 10 ^ { 18 } $ . it is $ 10 ^ { -18 } $ . maybe that is the source of the confusion ?"
226385,what clustering algorithm did you use here ?
226066,what is happening in month 5 and year 2015 ?
226279,use robust standard errors ?
226487,could you post your results so we know what you are talking about . . ?
147289,what is the nature of your time series data and what is the frequency ?
225947,"without digging into the weeds of your analysis , it's tough to say with any confidence what could be going on . one can opine though . it sounds like collinearity between the new terms and the main effects is driving the changes and , additionally , model instability . have you run any of the standard regression diagnostics , e . g . , vifs , collinearity checks , partial correlations , etc . ?"
226592,"convolution is for when you * add * independent variables . ( "" what's the distribution of the total score or both tests ?"
226559,"it's nothing to do with latex , you simply have to put 4 spaces in front of each line of output . i've done some of it for you , perhaps you can do the rest ?"
226076,"you cannot apply the ljung-box test on residuals of an arma model ; see e . g . [ "" testing for autocorrelation : ljung-box versus breusch-godfrey "" ] ( url ) or [ "" how many lags to use in the ljung-box test of a time series ?"
226705,"hi annamarie--welcome to the site . a quick clarification question : are you more interested in using your iv to predict the the "" stuff "" that is similar among the questionnaires as your dv , or are you more interested in using your iv to predict the "" stuff "" that is unique about the similar questionnaires as your dv ?"
226729,"the variable length comes from the number of ticks , right ?"
213675,"you have a lot of questions in one post ( and the title does not quite reflect them , imho ) . it would be easier for the audience if you focused on one concrete question . also , could you specify what are * inverse problems * , * propagated errors * , etc . , if you need to use those terms ?"
226817,which numerical example ?
226822,you wrote $ k 100 $ then $ h_0 = 0 100 = 0 $ . do you pointed all task condition ?
226829,does [ this answer ] ( url ) help ?
194063,you need to estimate the risk somehow to make it operational . are you familiar with stein's work ?
226854,why are you surprised ?
226901,"if "" cov "" is supposed to be the covariate , are you intending to model survival as a function of the covariate values squared minus the product of the values of the covariate times its mean ?"
226883,did i answer your question ?
226810,"what are you mean say "" frequency "" ?"
226943,that's great . what's your question ?
226844,"it's easy in the case where $ ( log x_1 , log x_2 ) $ are bivariate normal . did you intend that situation or did you mean for it to be a general question ?"
226913,is the precise model order at which the algorithm gets stuck ` 2 1 1 2 0 0 ` ( p d q p d q ) ?
226991,by uncertainty do you mean standard deviation or is ey a noise term or is this a reference to something else ?
226993,how do you make sense of $ e ( x y ) $ if the random variables are defined on different probability spaces ?
227023,consider an analogy : what is a frog ?
227060,are the parameters for a person the same in each replication ?
227052,"it isn't clear to me what kind of guidance or feedback you are asking for , could you clarify ?"
227071,it took me several re-reads to figure out exactly what you were asking there . can one not actually take the limiting value ( since all the coefficients will be set to zero -- you can figure out the fit easily enough ) ?
227078,is the sample size random ?
227114,1 this is an interesting question . just out of curiosity -- why don't you want to use relus ?
227125,what's wrong with a sparse data set with thousands of variables ?
227129,you said you are using linear regression ?
227118,can you post figures of your models ?
227138,"could you explain what aspect of any multimodal distribution your measure of "" central tendency "" ought to reflect ?"
227167,where is x and the interaction term in your formula ?
227139,does the ssa provide data about the * number * of children born with a name ?
227051,"* i have used an arima ( 1 , 1 , 0 ) model on a stationary time series . * there already is a discrepancy . arima ( p , 1 , q ) is for nonstationary , unit-root models . also , it is really strange that the fitted values are considerably below the actual values ; you should investigate that . could you post your model estimation output ?"
228213,"perhaps i misunderstand your question , but how would you "" just consider the error array which we obtained as an output "" ?"
228215,"what are you trying to classify , exactly ?"
85750,i would look at the variable importances . you could then scale by the importance . do you know that the other columns are as informative as the first ?
228238,could you post the 9x9 var-cov matrix for that study ?
226392,are you referring to both parts of the model or is this just for the count part or just for the hurdle part ?
227175,"you have 11 months of data on 22 , 000 apps that are nested in rank_categories . how many rank_categories are there ?"
228313,does the number of cases worked have an impact on the rating / performance ?
228337,"it's unclear what "" these tests "" refers to--your describe data but don't appear to specify any tests at all . it's not even clear how many tests you performed , nor how the data used in each one might be interrelated . could you supply that information ?"
228409,you mean negative regression coefficients ?
228403,how did you code the day of week variable ?
228418,"are you saying $ alpha $ takes on only two values , $ 0 , 1 $ or perhaps $ alpha in [ 0 , 1 ] $ ?"
227053,"you said * "" every participant is measured in all 3 background conditions "" * - so how many participants are there ?"
228514,how familiar are you with bayesian inference ?
227178,what is the actual hypothesis you're interested in ?
228570,can you post the data ?
228641,"could you clarify what you mean specifically by "" non-linear correlation "" and "" multiple correlation "" ?"
228661,what exactly is your question ?
228670,can you provide source of this recommendation and / or the direct quotation ?
228757,"your data aren't annual , right ?"
228549,at the moment this question is quite unclear to me . could you explain a little more about your set-up ?
228796,"this could be done , but first it's important to understand how the cis were developed . in particular , if they were computed from a common model and dataset , they might be correlated , which would appreciably affect how they could be combined . could you supply that background information for us ?"
228699,why would you build this model when you can model actual returns ?
228811,does it get better if you subtract the mean from each column ?
228830,""" use averaging or kalman filters for filling . but they are not good for large filling large missing data . "" -- are you implying that there are a lot of "" random "" missing values in a given section of time ?"
228800,this is probably due to the way the factors are coded . do you have a link to the data ?
228853,are there specialties besides rei that obgyns can have that you have in your dataset ?
228883,there's no reason to think that any simple distribution will accurately describe the 'true' population distribution . a simple model may be adequate for some purpose and in other situations you may not need an explicit model at all . what do you want to do with it ?
228888,"is there any reason why you don't just use a mixed effects model , which can handle unbalanced designs ?"
228936,you describe a non-linear model in your first paragraph and then say you specifically do not want a non-linear model . can you explain the apparent contradiction ?
228955,how do you have fully observed hidden states ?
228932,"what do you mean by value "" separating "" the two groups ?"
228755,isn't l itself in that case a metric that differentiates your three groups ?
228989,"what does the notation "" $ mathcal { n } $ "" mean to you ?"
228997,"this question is like "" how can you know what is in the box if before you look into the box ?"
229018,but how do you schedule it wrt initial centroids ?
228721,1 but is there finite-time guarantees even for non-adaptive mcmc ?
229096,are you able to go back in time and record historical values ?
229102,i assume you are minimizing the sum of square error where error is defined as the difference between the house price and a forecast house price that is a linear function of house size ?
228792,"how are the binary variables coded ( 0 and 1 , -1 and 1 , etc . ) ?"
228946,does this help : url ?
229161,1 . are you sure that hypothesis isn't the alternative ( h1 ) ?
229183,were there any warning messages ( e . g . about records with missing values having been deleted and / or categorical variables only having one level ) ?
229100,could you provide the specifics of how a normal distribution was fit to the data ?
229191,"could you include the equations and some context in your question ( by editing it ) , so that people do not have to check the book to understand what your question is about ?"
201952,"what do the values 0 , 1 , 2 , 3 , 4 , 5 refer to ?"
229218,"this is an example of simpson's paradox . url you might want to consider using a different type of analysis since your data is categorical , unless there is specific some reason you are using a z-score ?"
229250,can you give us any more detail about your precise scientific question ?
229255,"not all your variables are time dependent , e . g . people don't grow shorter or taller all of a sudden . weight changes , but only gradually . if so , running time is the only time series here . right ?"
229257,have you considered a regression model ?
229258,what are the locations ?
229322,do you have data from every possible combination of drugs ?
229124,have you asked on ` lavaan ` mailing list ?
229186,"welcome to our site . please supply more details : what kind of "" real difference "" ?"
229308,"if i understand your question correctly , then the inputs are correlations between pairs of * predictors * ?"
229491,what are the test statistics in each case ?
229328,could you not just only consider people in the areas that both companies can deliver to ?
229449,please explain how you obtained $ 1 . 87 $ when the mean of the distribution you present is $ 1 . 29 . $ what's the source of your data ?
229433,j . krauel can you comment further on how your measurement is made ?
229555,"it would be helpful if you define the content of records used for poisson regression runs : what is the range of the dependent , what are the independent features ?"
229588,did you consider [ f1 ] ( url ) score ?
229650,logistic regression ( = binomial ) refers solely to the outcome which is assume is your y . that is not to say that there are no issues with x1 and x2 can you clarify that y is indeed the outcome ?
229661,you have 21 observations ?
229666,is there reason to believe that the other nations all have the same mean ?
229649,"the calculation of ms_total is not something i've ever come across . that does not make sense to me . calculation of ss_total , on the other hand , is essential for anova . can you cite a reference that explains how to calculate ms_total and why it is necessary ?"
229676,is there a particular reason that the coordinate representation is too big ?
229681,"perhaps i'm missing something , but why would you want this ?"
229692,"when you write ` f ( x1 ) ` , what kind of function ` f ` do you have in mind ?"
229720,what's the convergence tolerance in ` optim ` ?
229721,"there is a lot going on in your post , i am having trouble to follow . could you please try making it a little bit more structural and highlight what the actual questions are ?"
229781,it would be easy enough to provide a worked example with more context . what do the weights represent ?
229840,"in your search for gamma , are you limiting the search to [ 0 , 1 ] ?"
229901,"what is "" $ k $ "" ?"
229905,is ` nodes0 ` the independent variable ?
229631,"asking for code review is , as far as i understand , off-topic ( at least in the sense of "" are there bugs in my python implementation "" ) . there may , however be an underlying methodological confusion . can you clarify what the distribution you are sampling from ( which variable ( s ) conditional on which variable ( s ) ) and what the code is attempting to do ?"
229948,"antoni , have you found what you were looking for , and could you perhaps even self-answer ?"
156138,have you considered fitting a ` poisson ` model with population as an exposure ?
229966,do you suspect that the coin is biased ?
229846,"what do you mean by "" constantly "" ?"
229988,could you explain how computing mahalanobis distances would provide any information at all about the multivariate normality ?
229996,"if you want to capture the effects of the entity dummies , why not do a fixed effects model ?"
230034,"to clarify , is the idea to find the best variant ( highest proportion of clicks ) of the now 10 buckets ?"
230085,"does my answer below suit your needs , at least as well as you think you're going to get ?"
225319,are you asking for a rigorous proof ?
230138,do you have an end goal for the analysis ?
230166,97 % . . . of what ?
230207,"with pcr , the r2 on the test set usually has a peak at some number of pcs and does not increase all the way . why do you think that one "" would expect "" the latter ?"
230130,what is $ n $ ?
230255,can you give us more detail about what exactly you want to compare and what your sentence describing the table means ?
230263,how are you producing the mle of y ( t ) ?
230272,"don't impute values to the abstain , because unless i misunderstood the question people chose to abstain . you shouldn't impute values to non-missing values . i would use multinomial logisitc regression and be open about any limitations you think your approach has . why couldn't you just have the abstain be your baseline category ?"
230271,i agree with you this is less likely to happen . what is mtry ?
230242,"logistic regression is much easier for you , an analytic solution is much easier for the computer . do you really need the latter one ?"
230238,what is your intended use ?
230317,"the definition of "" continuous distribution "" is that there will not be positive probability of sampling any given value . you can even specify certain * infinite * sets of values and they will still have zero probability . btw , what is the output of ` 1-max ( x ) ` ?"
230326,the image is hard to read . what are you flagging ?
230335,welcome to the site ! can you clarify what your exact question is ?
230260,"what do you mean by "" getting converted "" ?"
230345,suppose $ lambda_1 $ happened to equal $ lambda_2 $ . you would likely use a simpler expression for the waiting time involving just one integral . is your formula equivalent in that case to the simple expression ?
230351,what was the size of the test set ?
230415,perhaps also of interest : [ do bayesians accept kolmogorov axioms ?
230275,what is the nature of the ratio in your y variable ?
229833,"it depends on how those frequencies might be interrelated : you haven't given enough details for us to assume that they represent statistically independent observations , for instance . do you think you could flesh out your post a little to provide some of this important information ?"
230501,how did you calculate your confidence intervals ?
230201,"what do you mean by "" why "" ?"
230575,is there any reason you are using ` lme ` and not ` lmer ` from the ` lme4 ` package ?
230612,"maybe it's not just about quantity of explosions , maybe quality of explosions matters ?"
217941,why are you transforming these independent variables ?
230644,"while the cox model ( using pkg : survival with coxph ) would give you access to all the information you needed , you will need more than just the coefficients . the curves make me think that a more parametric analysis would be justified ( also supported by pkg : survival ) . the knowledge needed to answer it would be that gained in a second year graduate course in survival analysis or perhaps the third or fourth year undergrad stats course . this does appear to be a business-related task and maybe you should be thinking about soliciting a consultant's time ?"
230672,what exactly is unclear for you ?
179346,isn't this question a duplicate of url how does it differ ?
230723,in what sense do $ a $ and $ b $ 'have less conditional probabilities' ?
230598,how large an n ?
230752,"it depends on the details of each string . possibly you are thinking of your 500 strings as being some kind of random sample from a large set , but if so , exactly what is that large set ?"
230779,what is the new question asking ?
230784,"just to be clear : by "" shift "" you don't mean the usual sense of "" translate "" ( via adding a constant vector ) , but instead you mean * permute the components * , right ?"
230797,what is your question ?
230809,what is your dataset ?
230620,the $ x_i $ are i . i . d uniform on some range ?
230842,"it's really not clear to me what you're doing in your complex example ( you seem to be calling it regression in your title , but it isn't ) . can you give a small numerical example , and if possible a link of the kind of model you're talking about ?"
230734,try out a simple model that includes * only * ` pan_size ` and see whether the summary and lsm results agree with each other . i'm not quite sure what ` glht ` is doing about setting reference levels of all the other variables ?
230866,could you expand your question by including the book's definitions for $ x_j $ and $ z_m $ ?
230867,what is the burr distribution ?
230872,could you tell us more ?
230873,why not just graph ` object1 $ speed - object2 $ speed ` where times are equal ?
135376,"before choose your layer activation function you must check your data and in which format you will train it . tanh and sigmoid outputs are bounded value and rectifier output - is not . so , maybe rectifier works fine for you because your data is suited to this activation function ?"
230391,is this a question from a course or textbook ?
230920,"what does "" statistical interpretation "" mean ?"
230936,could you provide additional information ?
230915,would it not be wise to find out why your model cannot be estimated first ?
230265,1 . how do you get 3-way anova out of two treatments ?
230921,"william you may want to make a footnote that the original question included a statement "" maximum likelihood estimation corresponds . . . to maximum a priori estimation using a uniform prior "" , so the comments / answers have context for future readers ?"
215938,"do you need the synthetic data to have proper labels / outputs ( e . g . classes ) , or is your goal to produce unlabeled data ?"
231076,"so to ` test' anything , knowing more about how your data looks would be helpful . could you visually show us your data structure , such as the unit of observation or at least some more info ?"
231097,are you willing to go towards a multi-label classification ?
226935,is there really any fundamental difference ?
231164,"never seen it before personally . do you know * * any references at all * * , literature or internet ?"
231172,are you sure you want to use multinomial rather then categorical distribution . . ?
231173,""" it is possible that the same person has been sent a letter and a text message as the data is over a 2 . 5 year time period . "" -- are you able to identify these users ?"
231258,can you please help with what variable it is ?
231302,"yes , the method is correct in the sense that you are performing a conventional bonferroni correction for multiple testing , with the result that the family-wise error rate , i . e . the expected number of false positives , is controlled at 0 . 05 . however , this often has very low power . may i suggest you consider controlling the false discovery rate ?"
231314,numerical optimization ?
230479,i am a bit confused : can't you view your matrix as a correlation matrix ?
231171,can you clarify the situation you have in mind ?
231332,do you have any data . . ?
231194,"if you look at the expression for $ y_t $ , which $ x_i $ are * actually * being summed up ?"
61215,what do you think the first pc represents ?
231449,"the easy way to see that z can't be poisson is to compute the mean and variance . if it were , the mean and variance would be the same . out of curiosity , what makes you certain that z has a distribution that you know a name for ?"
214844,is this a homework excise ?
231552,"could you explain what you are trying to accomplish with this "" normalization "" ?"
204970,"can you say more about your situation , your data , your analyses / models , & your goals here ?"
231619,"so you have 50 years x 50 variables , is that correct ( 50 x 50 table ) ?"
231649,it's not entirely clear what you mean . if the relationship was quadratic then why would you try and model the two variables using a regression that doesn't include the quadratic term ( i . e . a linear regression ) ?
231680,"without a reproducible example , we can only speculate , so i would ask you what happened when you increased ` maxit ` ?"
231694,what kind of variables are these ?
231652,could you clarify this with a small example ?
231714,"if you consider what "" sufficient "" means , your definition would likely lead directly to a simple method of deriving this result . which definition do you have in mind ?"
231728,"do you know anything about x , y , x besides the fact that they are discrete ?"
231717,idif could you disambiguate the question regarding what's actually known ?
231412,"welcome to cross validated ! it's not quite clear exactly what procedure you're describing by "" fa , pca , sem selection and loading of variables "" : using principal components analysis , say , to guide selection of predictors as in [ using principal component analysis ( pca ) for feature selection ] ( url ) or [ how to use principal components analysis to select variables for regression ?"
231796,"can you specify what you mean with "" sample "" and "" impossible "" ?"
231777,"your ` ` str ( ) ` ` does not show the dv - ` ` out ` ` . also , what is it that you are asking exactly ?"
231872,"when you don't know how the response was generated from the regressors , your data will be almost useless for testing . why not generate av according to a specified model based on uv1 and uv2 ( with known coefficients ) ?"
186600,are you assuming x and y are independent ?
231666,"so , if the random variable's range is not finite , it clearly models some other variability in addition to that of random sampling the individuals from the finite set of individuals . but in this case you will not find out $ e [ x_i ] $ exactly even by sampling all individuals in the finite set . can you clarify whether you are looking for estimating $ e [ x_i ] $ or $ ( x_1 ldots x_n ) / n $ ?"
231893,how many variants are you examining for relation to the phenotype ?
231937,"for example , cluster all living in region x with data from 2000 to 2005 ?"
231943,have you performed some basic search on the definitions of discrete and continuous variables ?
231973,"i don't see the ` randomly drawn parameters ` part , could you link that ?"
232010,"without having seen the paper , or more details it is impossible to say . can you maybe edit that in ?"
232030,"what's wrong with your garden-variety classification quality measures like accuracy , f1 , auroc , etc ?"
232084,"are you interested in the equal-n case , or generally ?"
232145,your text is a bit hard to comprehend . could you try making it clearer ?
232142,can you edit your question to show us the distribution of bird_cnt ?
231799,what do you know about sufficiency ?
13433,what do you mean by bonferroni adjusted intervals ?
232233,"looking at the code i think it's probably due to choices in the setup of the call to ` uniroot ` that are giving "" different results "" in a small numbers ( the 4 and 12 ) situation . i think this is a numerical precision issue more than a statistic problem . would you be making any real-world decision differently if the ci has a lower bound of ` 1 . 00348216 ` ?"
232288,does the problem still exist if you let glmnet choose it's own sequence of lambdas ?
232281,you say it is uninterpretable but then in your next sentence you explain what happened . can you clarify ?
26016,"i have never really understood the rule of thumb that says "" 10 cases for each predictor "" ( and unfortunately i don't have access to the book written by agresti ) . what i mean is : if i have 100 subjects of which 10 are cases ( the ` 1 ` 's ) and 90 non-cases ( the ` 0 ` 's ) , then the rule says "" include only 1 predictor "" . but what if i model the ` 0 ` 's instead of the ` 1 ` 's and then i take the reciprocal of the estimated odds ratios ?"
232328,the marginal and joint have different number of * dimensions * . how are you going to compare their shape in general ?
232332,"( 1 ) where you write "" dependent , "" do you mean each $ x $ value is * paired * with a $ y $ value ?"
232338,what is the distribution of $ y_ { i } $ ?
232342,it depends on your objective function and the values of the bound ( box ) constraints . how did you determine what values to use for those bounds ?
232344,it depends on many things . are you using trend ?
230816,"are l , y , and z independent ?"
232356,"let's ask instead , who are not frequentists ?"
232370,"note that a software-specific issue like "" in what ways is matlab's glmfit implemented differently than python statsmodels' glm . fit ( ) ?"
232406,you have data and are choosing an analysis ?
232373,i presume you mean c are covariance matrices . how are your non-positive definite covariance matrices generated ( computed ) and how far do they deviate from positive definiteness ?
232422,what is your data about ?
232433,could you show your code in r ?
232484,have you considered performing spline regression on the daily values ?
230763,"do you mean to say "" predictors "" here ?"
232513,what is your question ?
232531,` that a and c are more similar than a and b or than b and c ` do you mean to compare profiles of the 3 rows ?
232533,can you be specific about your model and lags ?
232540,do you have any hypothesis on how much time the casual effect needs to affect the outcome ?
229884,"of your 107 cases , how many are in each type of cancer ?"
232572,how is treatment assigned ?
232576,can you post an example scatterplot of your data ?
232504,"your edit defines the overall svm problem . you still need to define the smo sub-problems and iteration . for example , what is $ e_i $ ?"
232590,are you just asking how this could be coded ?
231983,i am glad if my answer was able to help you . however note that it is fine for you to answer your own question on stackexchange . so i might suggest that you could put your edit as an answer ?
232639,"i don't know for sure , but it makes it easier to fiddle around : ) what happens if you use the default settings ?"
232638,"as it stands , this question is not well-posed . what are you trying to evaluate about the model ?"
232675,were you able to find anything out about this over the last 25 days ?
232677,so it's like a correlation parameter ?
232673,which text are you talking about ?
232687,why do you think that gls would not work ?
232779,what exactly are you trying to test ?
160054,"cholesky works just fine , and this is really a "" can you find the bug in my code "" type question . the title and content of the question , as it is originally written , are basically "" cholesky doesn't work , what's an alternative "" ?"
232821,"if you can calculate the posterior probabilities * without * using mcmc ( so to save them ) , then why would you like to use it ?"
232824,could you give an example of what you are actually doing . . ?
232827,are you sure if the inverses are computed correctly ?
232864,"you can obviously choose a small random vector and add it to the previous position , but i'm guessing that's not realistic enough . i think you need to define what you consider "" realistic "" before modelling it . do the vehicles thrust and coast ?"
232886,"testing whether $ x xrightarrow { granger } y $ involves assessing the partial correlations between $ y_t $ and $ x_ { s } $ where $ s t $ , for one or more lags of $ x $ . so $ x $ is lagged with respect to $ y $ . can this explain the apparent paradox ?"
232697,do you have a specific model in mind for the residual correlation ?
232775,isn't positivity one of the axioms underlying probability theory ?
197986,""" with a random intercept for every observed combination of a and b "" ?"
233010,"how many nodes are in your network , and how many of them are you intending to prune ?"
232972,do your results stabilize if you increase the number of folds ?
233033,is that confusion matrix the one from your test data set ?
233061,do you know in advance how many pseudo random values each thread will use--or at least can you obtain a good upper bound estimate ?
233071,"the correct ` lmer ` syntax is ` model - lmer ( time ~ gender age runs friends ( 1 athnumber ) , data = mydata ) ` . is that a typo in your question ?"
233105,have you tried asking john kruschke how he made the diagrams for his book ?
233147,"not sure of the context , but perhaps for simplicity they are just describing the "" large sample limit "" case ?"
232942,"can you give title for some of the books you tried , so we can get a better idea of what you are * not * looking for ?"
233196,why would you differentiate the mgf n times ?
233195,have you thought of merging them into a variable with two levels ?
233207,"are you asking if it's ok from an econometric point of view , or if it makes sense theoretically ?"
233214,"i don't follow your situation / data setup . can you say more about your study , your data , & what you are trying to achieve ?"
186757,"casper , please clarify -- are you primarily concerned about it as a security issue ( e . g . there's considerations related to more than just probability ) , in which case it may be a better fit elsewhere -- or are you asking a primarily probability question ( which fits here ) ?"
231945,what is the goal of this technique ?
231870,"you should spell out lstm , what does it mean ?"
26699,"why would this question be better on so , nico ?"
232553,"did you look for an answer in 1 ) spss command syntax reference , 2 ) spss algorithms document ?"
232959,"in the last plot , shouldn't the confidence intervals "" pinch "" at the known points ?"
233258,is there a reason you'd prefer not to use a standard loss function such as mean squared error ?
233373,"to clarify : each individual has a number of cells associated with it , and the number of dots per cell can vary . is this a correct description of your data ?"
233377,"are $ x_1 $ , $ x_2 $ , etc . . . iid draws from the same underlying distribution ?"
233389,what are you assuming about $ epsilon $ ?
233422,why don't you pool the 30 samples and treat the data set as one ?
28383,i think you need to explain why you chose quantile regression over least squares regression . were the residuals not normally distributed using least squares regression ?
233490,which package ?
232736,"afaq , it would help if you told us more about what type of person would answer your questionnaire . are you hoping to give it to * security experts * in order to assemble a consensus on what schools should do to become more secure ?"
233509,did you also bump the number of nodes in the output layer to the number of classes ?
233518,do you know what a mixed model is ?
233521,the most striking feature in your plots is observation 7 . is there any scientific explanation for it ?
233523,"this question seems reasonable to me . i am not sure who down-voted it , but it would be helpful if you could give a reason ?"
233229,do you mean x3 in the second equation in a ) and b ) ?
233552,every possible distribution you want to know about would have to be done separately . most of these won't be tractable ( though some simple cases will be ) . under certain conditions the distributions ( via the fact that the numerators are averages and applying slutsky's theorem to the ratio ) will converge to normal distributions as $ n to infty $ but the convergence ( when it happens at all ) may be extremely slow - in many cases much too slow to be of any use . you can of course explore the sampling distribution via simulation . what do you need the sampling distribution for ?
233409,1 . why do you want to shorten the series as much as possible ?
233588,it looks like your questions are extensively answered at url could you identify and highlight any that are not ?
233592,it seems unlikely that you want 1198 different coefficients for org_id . why not treat it as a random effect and use coxme from the coxme package ?
233601,i reckon to go with 7 clusters ?
4086,are you sure you want to limit yourself so severely ?
233558,how is your data formatted ?
233614,how many genomic events on average you have per sample and time point ?
233484,you should spell out lstm . what does that mean ?
233630,"can you say more about the context , e . g . what could be x , what could be y ?"
233641,do you have a specific context in mind ?
233691,is there some larger context for doing this splitting ?
233700,can't answer your questions about ancova directly but have you considered using mixed effects regression to model the response curves ?
12209,what do you mean with overlapping region ?
233731,"are you effectively asking "" if my data are paired is it okay to ignore that pairing when trying to calculate an interval for the difference in means ?"
154449,"by choosing 3 elements , do you mean how many possible sets of 3 elements there would be , or how many times you can draw 3 elements without replacement ?"
233795,"actually this patterns are machine learning . of course you can do it with machine learning , but a person needs to do a feature extraction first before giving it as an input to ml algorithm . which features would you extract from this examples ?"
233727,two comments . 1 ) can you clarify what the axes and points are ?
233827,i couldn't agree more with the general . a learning rate of 0 . 5 and 10000 trees seems a bizarre setup . have you checked the learning curves ?
231620,"msis what do you mean by "" nicer "" ?"
233831,"are you trying to include a random intercept for "" speaker "" and that's the effect you are looking for ?"
233853,have you tried using the parameters of the distributions as features ?
233804,"just to clarify : the "" random change "" in the mc method is randomly generated by the researcher ?"
233885,""" are always meaningful representation for the data , right ?"
233858,"can you say anything about your situation , the data , & the model ?"
233953,"what is "" feature space "" and "" competitor feature space "" ?"
233648,when your hypothesis of interest is about variances ?
233632,is this a home work ?
234000,when you say you centered your predictor given that it is zero or one what values were you left with ?
234024,i started writing an answer but couldn't figure out notation . are you taking $ mathrm { tanh } $ to act elementwise on the $ n times h $ matrix arguments ?
234022,so panel is a categorical variable ?
233205,"you need to clarify what your goal is . is it to predict sales for next month ( so the company can have adequate stock ) , or to predict conversion rates , or to look for the effects of special deals or other a / b kind of issues ?"
234098,do you have some reference to the methods sas is using ?
27025,it's pretty hard to provide good advice without knowing the objective of your analysis or more details about the nature of your data . would you care to elaborate on these ?
233001,you should give us more details of your experiments ( s ) . what is the nature of the experiment ( what did you do ?
234159,"lily , were you able to satisfy the 1-3 steps listed out in the link i referenced ?"
234201,isn't your task rather a classification task ?
233548,"please clarify the two methods that lead to the close prediction accuracy . do you split the data into training set and validation set , where the validation set is used only for optimizing hyper parameters , and not for training ?"
234237,does this probably qualify as [ ` self-study ` ] ( url ) ?
234213,could you clarify a bit what you mean ?
234275,if you could provide more info this question would be easier to answer . we need clear understanding of structure of data as well as nature of problem . . . structure / type of your data in each study ?
234291,model with constant ` mu ` . . . as opposed to nonconstant ` mu ` ?
234137,"are you sure $ x $ can be normally distributed if it is sampled from an particular interval $ [ a , b ] $ ?"
234313,can you give us more details ?
234324,"sorry to have misunderstood . so how what do you actually have -- a series of $ ( x , f ( x ) ) $ pairs ?"
234330,"please spell out your acronyms . what are "" mdp "" & "" pomdp "" ?"
234027,i am not very familiar with recommender systems ( perhaps you could include some example papers in your question ?
234385,do you actually need that model or just want to explore ?
234405,can you show us the graph you got ?
234246,one note about the structure of your data . why not restructure the matrix with one row per individual per period ?
234462,"did you mean "" . . . from the sepal . width and the * * petal * * . length * * "" ?"
234475,is there some randomness involved in the model fitting procedure ?
234524,"your final question is a little unclear - are you essentially asking "" how can i decide which is redundant "" ?"
234541,did you split your data into training and test data or is the 48 % result derived from the same data that trained the regression ?
234591,"were there $ 0 $ 4's & 5's , or do you only care about 1-3 ?"
234597,"when using ordinary least squares linear regression ( ols ) one has to check for outliers that will hopelessly bias correlation results . questions back to you , 1 ) are you using ols linear regression ( you probably are ) 2 ) are you asking for a least error prediction of y given x ( what ols does ) ?"
234496,"thank you for fixing the typo . now that the model is clearer , are you asking about how to interpret an interaction ?"
234599,are the $ d $ unobserved ?
234613,"i don't understand , what would like to do exactly ?"
234634,could you explain what you mean by the rule of 30 ?
148106,"why is there no data in the training set with the "" extra class "" ?"
234729,what kid of trend are you expecting ?
234463,it's a repeated measures design . how do you know you don't have normal data ?
103803,are you using all your data to fit the model ?
234757,how many dimensions are you working in ?
234768,"could you explain what you mean by "" the data is independent "" ?"
234774,"would you specify what the deterministic function is , please ?"
234814,did you mean sigma and not delta ?
233850,"i just meant that all 3 outputs of ` svd ( ) ` would be needed for $ x $ , as it is not a symmetric matrix . note that if we assume for simplicity that $ x $ is centered ( 0-mean ) , the covariance is $ c = x ^ tx $ . then given ` [ u , s , v ] = svd ( x ) ` , i . e . $ x = usv ^ t $ , the covariance decomposition will be $ c = v ( s ^ 2 / n ) v ^ t $ . for grayscale images , commonly the $ k $ roughly corresponds to "" frequency "" ( more oscillatory basis vectors ) , and the energy decays with $ k $ . not sure if this holds for you ?"
234866,excellent work ( i just had my phone last time we talked . . . ) . can you share the estimated parameters if we were to assume a log-normal ?
234904,have you seen this one ?
234908,"i must be missing something , because the game appears to reduce to this choice : either you are paid an amount equal to the total number of marbles ( and the state of the game can change for the next round ) or you are paid nothing ( and the state of the game does not change ) . isn't the optimal strategy obvious ?"
234903,what about page 47 of url ?
234920,"well , classic pca can be performed on multicollinear data . taking this note , why won't that satisfy you ?"
234953,can you paste in your contingency table ?
234989,what you are asking is very broad and without context - could you say rather more about your situation and what you are attempting to achieve ?
234396,"if your question is "" is machine learning only about estimating * something * ?"
235004,what language or environment are you using ?
234987,what have you tried so far ?
235018,does looking through url help ?
235037,"ratios of gaussian distributions are not generally gaussian . for example , if the means are both zero , the ratio would be cauchy , and in other cases are more complicated . in your case , you have some confounding factor as the results are correlated , did you rank them in ascending order or something ?"
235043,"yes , that's poor implementation in just the way you indicate . but "" yes "" isn't much of an answer and you haven't left much scope to say anything else . shouldn't you raise this with the author of the function ?"
235100,"this sounds like an uncertainty quantification problem . some more details on the problem would help answering the question . physically , what are the $ x_i $ and $ y $ ?"
235117,what types of variable are the dependent variables ?
235122,is this a question from a course or a textbook ?
235129,can you also keep the sum of e ^ 2 ?
235160,"the usual r formula syntax can be used : ` sales ~ satisfaction year ( year - 1 region ) ` . however , i'm skeptical of including slopes without intercept . what theoretical reason do you have to believe that only the time trend should vary between regions , but not the intercept ?"
235162,how exactly are you sampling the values of $ x $ and $ t $ ?
30035,are you sure that you want to use linear regressions ?
235214,so $ delta x = x - langle x rangle $ in general ?
235251,could you provide a link ?
235264,"hi david , thanks . if i reopen your question could you post a brief answer ?"
235216,is wn following a normal distribution ?
235255,could you tell us more about the data ?
235311,"i may just be being dense , but it's not clear what you're asking . could you perhaps re-express your questions in terms that don't require knowledge of what a gene expression analysis is ?"
235295,"this seems to mix together some problem in some unstated software and , possibly , a statistical misunderstanding . questions should be as far as possible self-contained and * * not * * depend on reading external links or on people understanding source code in some software . many details are not clear : what does the function you used do ?"
235322,i may be dense but i'm not sure i understand what you're doing there . is it possible to include a small example calculation that shows what calculations you do and also has the property you're discussing ?
235346,is your response variable discrete ( liking score = 1 to 10 ) or binary ( liking = yes or no ) ?
235343,could you provide a reference where you actually saw the formula * without * minus sign . . ?
235370,"if i understand what you're doing , i think your question essentially duplicates [ multiple regression in r results different to simple linear regression ?"
234232,can you post some output ?
235418,"how would you quantify your errors , are they basically standard deviations and the error bars are 95 % intervals ?"
32303,"what do you mean when you say "" my data is circular / directional "" ?"
235470,"where does your "" wealth "" data come from ?"
235498,"if you have whatever procedure that allows you to compute a * single * realization of the estimator , then that procedure will take a median over some empirical distribution of * pairs * of points . so why not just do bootstrap resampling on that point-pairs pdf ?"
235529,could you clarify what your hypothesis is ?
235450,"this is an interesting question , but "" how they should be ranked "" is a rather subjective issue , which i don't think would be amenable to an objective , calculated answer . perhaps when you say "" difficulty calculation "" in the title , really you are after something like a calculation of the probability ?"
235562,"i haven't really absorbed all your question , but there's no reason heteroskedasticity and collinearity ( vif ) should be related . what exactly is the question ?"
235577,so you have 5 observations for many countries . what is your deponent variable ?
235572,"1 , good question , but i find your title confusing , too specific , and do not quite see how it is related to the body of your question ( why neuropsychology ?"
235609,"when you say "" the results for efa and mds overlapp substantially , and when i use mokken scaling on these items , i get high scalability and reliability "" do you mean that you used efa to identify factors and then applied the mokken scaling to the items that load on a single factor ?"
235620,can you provide reference mentioning it and a broader context ?
189258,"please consider : if each variable , a , b , and c , had just 2 levels , then there would be 2x2x2 = 8 groups . does this design really have only 3 ?"
235623,do you have any idea how big p = 10 ^ ( 10 ^ ( 10 ^ ( 10 ^ ( 10 ) ) ) ) really is ?
235607,are x and y vectors of dimension $ 1 $ ( in general ) ?
235649,"very nice question . is this a homework or self-study exercise , though ?"
235671,you might want to add the [ survival ] ( url ) tag . do you know the age of the components ?
235687,the question is how can you select them before the decision tree ?
235599,"interesting that we don't seem to have a "" hashing "" tag here , though i believe there are a good number of posts dealing with at least [ ml ] ( url ) [ related ] ( url ) applications ?"
235714,what exactly to you want to use kde for in here . . ?
235725,are you asking for the pdf of the sampling distribution of the statistic ?
235744,"so far , i know that your data is not paired . that rules out the more powerful tests . it is unclear from your description what should be used . 1 ) is the data normally distributed ?"
235770,do you know the * distribution * of log x or x ?
235777,"the choice of loss function depends on what the final , ultimate objective is that you are trying to optimize . first think about that . is it simple expected accuracy ?"
230392,"i'm confused about what you're asking here : given that it's * not * , in general , a dimensionless quantity ( as explained in the accepted answer at url ) what exactly would it mean to "" treat it like "" one ?"
235606,have i answered your question ?
235815,what is the question here exactly ?
235829,what is the question ?
235843,is this a [ self-study ] ( url ) question ?
235853,which interaction ?
235892,why do you think that large difference in sample sizes is a problem ?
235862,"possible duplicate of [ in neural nets , why use gradient methods rather than other metaheuristics ?"
232263,"what exactly makes them "" obviously wrong "" ?"
235982,where do the weights come from ?
235996,"also , it'd be worth mentioning what use you are making of information revealed over the course of the game - are you working entirely from other players' questions ?"
236021,"there's a disconnect here : you appear to be asking to convert a statement about "" fb "" into one about "" hb "" . could there by some ( critical ) typographical errors ?"
236028,have you looked at our threads on logistic regression and glm ?
236055,how do you want to compare them ?
236060,"forgetting gpu for a minute , is your basic goal to choose $ k $ distinct values from a finite set of $ d $ values , where the values are sampled without replacement and with uniform weights ?"
234386,* * 1 . * * initial values of what matter for what ?
236084,do you care about the coefficients or are they nuisance parameters ?
235856,"why 0 . 05 / 3 , if you do 6 tests ?"
236110,"ok , interesting . however i do not get what do you mean by using bootstraping in here ?"
236118,1 . * why * is it necessary to identify a distribution ?
236144,what is your data ?
236148,switch to [ non-parametric ] ( url ) or empircal methods ?
236155,why do you see it as a problem if the absolute values of your coefficients exceed unity ?
236168,"are you conducting a sampling design , or just scraping data , say , from the web ?"
236200,"you need to use the sample sizes $ n_i $ along with the $ bar { x } _i $ in order to carry out anything like this . your remarks about maximum likelihood are obscure , because you seem actually to be performing some kind of bayesian computation rather than ml . similarly , the final remark about "" regress each of the samples to the mean "" is difficult to comprehend . could you elaborate on your post by describing the actual problem you face , rather than this abstraction of it ?"
236217,this seems like a case where some simulations could be enlightening . do you have some potential applications in mind ( even if toy problems ) ?
234567,could you go into more details on how does your data look like ?
236161,"the exposition in your post is confusing about that matter , because evidently you are * not * actually using $ l $ as a loss function . could you perhaps elaborate on the specifics of problems ( 1 ) and ( 2 ) in the post ?"
236258,would something simple help ?
69952,what happens if you omit variable selection ?
236312,"but you're also not interested in specific numeric values , i would think . is there really a difference between 150 and 150 . 1 and 150 . 000001 and 151 ?"
236339,could you provide more information regarding your input time-series ?
236343,in ms quant analysis don't they teach stats ?
236362,you may get more helpful answers if you can give a bit more context to your problem ?
235254,"hmm , i might misunderstand the question . but i think , you are looking ( combinatorically ) for a subset s of size - say - l = 50 variables from all , which leave the least unexplained variance in a regression of the other variables on s * ( "" most representative "" ) * ?"
236449,"when you ask about the proportion of the population that "" lies above or below the mean "" . . . are you asking relative to the sample mean or population mean there ?"
236484,"what do you mean by "" residual plot "" ?"
236485,"can you clarify the term "" gradient checking "" ?"
236243,is this an empirical problem ( i . e . fitted model with assumptions being violated ) or a theoretical ( math ) problem ?
236520,could you provide a link or a reference from where you have this definition ?
233639,can you explain lstm ?
236068,can you quote the part of the article you refer to ( where they're talking about independence ) so people can see what is being claimed while reading your question ?
236650,"whuber agreed ! conceptually , the purpose of a model is to reduce the complexity of the real world into something comprehensible . not the other way around ! a "" more complex "" model could be built by simply adding more "" x or y variables "" . however . . . by "" complex "" do you mean , say , "" larger "" , "" more realistic "" , or "" less understandable "" ( for its own sake ) , etc . ?"
236652,"please note that $ a sim b epsilon $ does * not * imply that $ epsilon = a-b $ ( as random variables , which apparently is how "" $ a $ "" , "" $ b $ "" , and "" $ epsilon $ "" must be understood ) . for instance , suppose $ b $ and $ epsilon $ are iid standard normal . then the variance of $ a $ is $ 2 $ . since "" $ sim $ "" appears intended to mean "" has the same distribution as "" rather than * is equal to , * it looks like we are to assume $ a $ is independent of $ b $ and $ epsilon $ . but then $ epsilon = a-b $ would have a variance of $ 3 $ , which is impossible . could you therefore explain your notation and assumptions ?"
236691,can you clarify what all the subscripts means ?
236820,"this seems to be taking an expected value of $ f ( k / n ) $ where $ k $ is distributed as a [ binomial distribution ] ( url ) with parameter $ p $ and $ n $ trials , for which the expected value of $ k / n $ is $ p $ ?"
236806,is it possible that it is on the log scale ?
236729,"perhaps i misunderstand the problem , but wouldn't it suffice to make a hash table and then compress it with a standard lossless compression algorithm ?"
236753,i think the question and notation are not clear to me . are you saying ` sign ` instead of ` sgn ` ?
236865,"could you explain what you mean by the "" non-distributed approach "" and what you mean by "" distributing "" an algorithm "" through weighted least squares "" ?"
236879,is there some standard metric for similarity you are referring to ?
234189,"what do you mean by "" small "" ?"
228523,welcome to our site ! is this a question from a course or textbook ?
37389,how have you assigned items to scales without carrying out a factor analysis ?
236949,ancova is typically used to model continuous covariates in the analysis of a factorial design . if your covariate is discrete ( as your question seems to suggest ) why not include it as another factor in the anova ?
236988,what do you want to find out of this ?
116928,say you have a sample of 10 data points . what is the chance that an 11th data point is greater than the 10 you have collected ?
236990,my initial intuition is that some kind of bayesian approach would be most natural ?
237009,"adding an irrelevant feature can only cause overfitting , which will generally lead to decreased accuracy . which part of this is causing confusion ?"
237036,"what do you mean by "" test if the volatility of stocks and indices have risen in the past ?"
235730,"trying a simpler case of $ mu_1 = mu_2 = 0 $ , $ sigma_1 = sigma_2 = 1 $ will reduce the clutter quite a bit and make you see the forest instead of the trees ?"
236441,have you thought of meta-analysis which synthesises estimates from different studies ?
237088,"there is an entire decision tree for calculating effects . it would be better , if you want someone to answer to explain exactly what your study design is . for example , if you have a known control group size and you want to know how many experimental group patients you need that is one type of question , and the variations on the theme are numerous . what kind of effect size are you looking to detect ?"
237092,can you please clarify a bit more ?
236946,"it may be likely that your problem is non-convex , in which the classical notions of "" mle "" and "" confidence regions "" would have limited applicability . that is , in the optimization sense , "" gaussian errors "" usually correspond to a local ( negative-definite ) quadratic approximation to the objective function . so "" uncertainties "" are based on the local hessian ( could be a non-local quadratic model , for dfo ) , which ignores the possibility of a multi-modal objective function ( i . e . separate peaks ) . do you get different solutions when initializing $ theta $ randomly and re-running the estimation ?"
237071,"you are reporting different analyses . in particular , your variables ` gen ` differ : one uses "" f "" as the response and the other uses "" m "" . you therefore cannot compare coefficients one-to-one ; you have to convert one model into the other before you can decide whether they agree or not . an easy check is to compare the * predicted values * of both models . do they agree ?"
237151,could you perhaps illustrate what you mean with your venn diagram suggestion ?
237162,i don't understand how your response variable works . so is it 1 if it is actg and 0 otherwise ?
237132,"playing devil's advocate , corrections are performed to reduce the chance of a type 1 error . how do you know that the effect that was significant before the correction but which was not significant afterwards was not a type 1 error ?"
237152,it is not clear what paper you ae referring to . can you clarify ?
146907,why not do feature selection based on lasso or some similar method ?
237010,can you say more about your situation & your model ( etc ) ?
237211,"can you provide the data in a more user-friendly format ( ie , paste in the numbers ) ?"
236626,"for the general case , how large is $ n $ ?"
233725,could you explain why the likelihood is in this case not available in closed form ?
237281,is this an exercise or assignment from a book ?
237054,is this a question from a course or textbook ?
237310,"my concern here is that the number of discrete weather conditions is too large and c ( k ) may never repeat . additionally , treating weather conditions as discrete doesn't make it clear that two very similar conditions are "" close "" to each other . instead , could you consider the weather as a set of n variables that are normally ( or uniformly or whatever ) distributed ?"
226845,"richard , your question is fine and important ( 1 ) . just maybe i'd rather re-word it a bit in a manner like "" we usually use pca as a dimensionality reduction for data where cases are i . i . d . assumed . . . what are typical nuances in applying pca for time series data where cases ( time points ) are lag-interdependent . . . ?"
237354,if your outcome is indeed a ratio would you not be better off modelling it as log ( ratio ) ?
237086,can you show the calculation you did to get something other than 1 / 741 ?
237340,would beta regression be another option ?
235226,"try to make the q much more specific . what do you want to simulate , for what purpose ?"
237194,are you just asking about the legend ?
237404,"although in its current form this question doesn't seem to be on-topic here as it is simply asking for a package recommendation - see our [ help / on-topic ] - i think you * could * bring this within the scope of our site by changing the question to "" what is the name of this graph ?"
237438,what is your goal ?
237440,one ought to refer to the original definition for the reasons . do you have a reference ?
237464,context ?
237475,"instead of testing country by country , why not aggregate all the countries together and get a global smoker rate ( which is what you're looking for anyway ) for 2013 and 2014 , and do a binomial test of proportions ?"
237349,"authors are free to use whatever notation they like , aren't they ?"
237517,"could you explain what you mean by "" a method that cancels the weighting "" ?"
237541,did it work ?
237542,do you know how the global measure is computed from the individual data sets ?
237559,"what do you mean with "" normalize "" ?"
237554,"* * 1 * * . the question should ask for sample size not population size . $ : $ * * 2 * * . what's $ p ( x = k ) $ in a $ text { binomial } ( n_1 , p ) $ ?"
237577,"you could start with the 2d case , which might allow easier visualization ?"
237381,what are these letters / variables ?
237564,can you post the data in a format so that we can reproduce the results with proper statistical software ?
237619,in your justification for the bounty you say you want to get the variance of these estimators . don't you think that these are in the link of my comment supra ?
237610,possible duplicate of [ cross-validation in plain english ?
237608,"the pattern in the var forecasts seem to suggest that they're being generated by two different models . for example , the 2014 var forecasts are probably from a model in differences ( since they hover around zero ) while the 2015 var forecasts are probably from a model in levels ( since they don't return to a mean of close to zero ) . can you confirm whether or not this is the case ?"
237746,"a test that compares a subset of the complete data vs the complete data would not be a valid test . why not test two things : first , whether the proportion 0 . 0345 , for instance , is significantly different from zero , and second , whether that proportion is significantly different ( two-tailed ) or higher ( one-tailed ) than the proportion associated with families with no history of cancer ?"
237753,"plz i search for an explanation of the word vector written in the text abs_terms . txt , what's the meaning of this values exaclty ?"
237769,it depends on the algorithm . but does it really matter ?
237796,"boy , this sure looks like homework . have you looked at the "" help "" recommendations for presenting and labeling "" self-study "" questions ?"
236866,"for a pure optimization question , url is also an option . i am not sure if language specific questions are on topic there though ?"
237699,this sounds more like an attempt at accidental discovery . is there any guidance you have in terms of a problem you are trying to address using this data ?
237826,is your question solely about how to use matlab ?
237833,have you tried searching for answers to this question ?
193306,have you heard of stochastic gradient descent ?
237860,so the complaint variable $ y_i $ shows the number of complaints over the five year period ?
237883,"johnsmith sure . i was talking about your pc2 where it seems you were confused about all signs being negative , weren't you ?"
237966,how would your friend work with models that have parameters that are not directly estimable from the data ?
237975,"multi-objective optimization is hard . if you have two objectives $ x , y $ to minimize , is $ x-1 $ better than $ y-1 $ ?"
237998,have you considered the [ silhouette coefficient ] ( url ) ) ?
238032,what do you mean by this notation ?
237961,what is large ?
236933,this seems a little as if you're trying to get someone to write a paragraph of text that you can use in your work . will the author of the accepted answer be included as a co-author if you go on the publish their response ?
238088,"( a ) you're welcome to invent any kind of definition you want , but a definition by itself is without any utility . what matters is * what you can use your definition for . * yours does not deserve to be called a "" sufficient statistic "" until you can show that all--or at least most--of the important properties and theorems enjoyed by sufficient statistics also hold for your definition . ( b ) i cannot make sense of the paragraph about "" my issue . "" could you elaborate on what you think the problem is ?"
237963,are your data ` number that survived ` out of a ` known initial total ` ?
238098,is this a question from a course or textbook ?
238108,what exactly is $ p $ supposed to be ?
238131,"try googling "" inverse variance fixed effects meta-analysis "" that may provide you the answer you want ( assuming that treatments were assigned by randomization within each group etc . ) . it is not clear to me what you mean by "" access to the individual-level variance rather than only the group-level variance "" - do you mean that you want to assume that variances differ by group ?"
238160,could you please make the question clearer ?
238082,if it were so wouldn't it be really simple to achieve asymptotically increasing accuracy for any problem ?
238201,"the density of the * unconditional * response reflects how the mean response varies with the regressors as well as the variation around the mean . thus , the appearance of a weibull response does not imply the conditional variation will itself be weibull . ( indeed , it could be gaussian for that matter . ) what does the distribution of the * residuals * look like when you do a quick and dirty ordinary least squares regression ?"
238222,"in the definition of "" linear "" models : yes . but could you explain more the context of your question ?"
238250,"matthew that's how i have interpreted this question : a request to do that math ( or otherwise find some suitable algorithm ) . but ray , how could we possibly suggest such improvements without having the details about the structure of your matrix ?"
238321,is that even a one of the 4 questions you asked above ?
238359,"what do you mean by "" area under the peaks "" ?"
238410,this is a time series . what does it mean to have separate training & testing sets ?
238411,"can you tell us what these binary vectors represent , and what is your goal ?"
238435,can you define more clearly what a path is ?
238400,what orders of magnitude are we talking about ?
238476,"could you clarify what the "" pairwise distances "" are ?"
238497,use linear programming to see if it is separable ?
238534,can you tell us why you want to know this ?
238548,"you need to explain the situation in more detail . your data appear to be discrete -- are your data counts / scaled counts , or are they rounded / truncated measurements ?"
238581,"robinkramer please clarify what you think you mean by random effects . when statisticians say random effects , they usually want to account for clustering among different observations . for example , say you had repeated measures on the same individuals , so each obs is one person at a certain time , and you had 4 observations per person . you arguably should fit a random effects model ; each person has a person-specific random effect ( usually assumed to be from a normal distribution ) . when you say gender , smoking , etc , those can usually be modeled as fixed effects . so , what do you mean ?"
238596,can you recheck the problem here ?
238644,""" the best i got was near 30 when i took the geometric mean but obviously it's incorrect . "" could you show us * how * you took the geometric mean of ?"
238661,"i am from a very different community , so this may be a silly suggestion . . . but could you try to estimate linear markov transition matrices over the ordinal measures between time snapshots ?"
238699,what specifically are you trying to interpret ?
238204,any duplicate records in your folds ?
238776,"you want a simple , easy example . . . but without mathematical notation ?"
238787,"in terms of goodness of fit , it's a regularization method . have you studied ridge regression ?"
238758,is this effectively a programming question that should go on stackoverflow in the r section ?
238778,do you mean sampling from truncated normal ?
238836,"behaviorists , at least , tend to take it as a basic assumption that classical conditioning and instrumental conditioning are universal processes in animals , with any individuals who lose one of these fundamental abilities quickly dying due to failure to learn about its environment . are they wrong about that ?"
238597,"welcome to the site . acronyms should not be used without defining them , especially when they are unrecognizable and not related to the field in which they are cited . you question needs to be better defined . what is your hypothesis , how are you measuring outcomes ?"
111756,"thanks for awarding the bounty to my answer , harvey ! would you say it resolves this issue for you , or are you looking for a more detailed exposition ?"
239010,"i think there might be a sensible question here , could you please explain what you want to achieve with this ?"
238636,this looks like a scatterplot . in what sense do you perceive of it as being any different ?
239059,would you like a single number to represent the similarity among all the samples in a group ?
239080,is this the first order condition for the maximum likelihood problem ?
238383,i don't understand your question 1 . setting weights of what ?
239100,this concerns whether the process the data came from is a [ stationary process ] ( url ) or not . a . more advanced treatment of the topic is found in [ what is the difference between a stationary test and a unit root test ?
239127,"you might be overthinking this . from the raw data , just find the value ( s ) of power that the most people like , aka the mode of the distribution ( distribution = number of people who will accept a given value of power distribution ) . is there a reason this can't be done in your case ?"
239108,can you say a bit more about your data and what you're trying to achieve ?
239137,"take a "" very general "" family of distributions , like a many-parameter version of the exponential family , put "" reasonable "" priors on the parameters , then run this with your $ n $ observations through mcmc to get a "" posterior density "" ?"
239149,your title says you want to do a regression type analysis but in the text you ask for a graphical representation of the relationship between two categorical variables . can you clarify and if necessary edit the question or the title ?
239081,do you know how it fits the lognormal distribution ?
238943,i don't quite see what you need explained . plainly means can be different whether or not the paired values are correlated . can you clarify what the problem is that needs explaining ?
239115,you are going to need to give more detail here . what information do you have ?
239259,"it might help to look at what that topic contains compared to the other topics . also , is the same effect observed in the training set ?"
239048,"if i'm reading this correctly , you want to use only one subject's observed count , and so * n * is irrelevant . is that right ?"
239310,* complete * your stats knowledge ?
239333,"well , isn't it better ( other things equal ) to be right on average than wrong on average ?"
239341,"aren't [ relu ] ( url ) ) activations popular with convnets , though ?"
239109,you need to clarify what you mean by large . do you mean very wide or very long ?
239366,"could you tell us a little more about what this "" mean "" is intended to represent ?"
239382,i see that you assume that the question is about uniformly distributed points and euclidean distance - is it correct ?
239393,are your outcomes count proportions ( counts in some category divided by a total count ) or continuous proportions ?
239297,"if brand $ xyz $ is the product of brands $ x $ , $ y $ and $ z $ , are they independent brands , or dependent ?"
239406,"welcome to stats . se . in its current form the question is unanswerable , since it is too broad . please try to give us more details . what kind of data are you using ?"
239432,you could decompose any linear model like this . it seems to depend on where you're looking for an effect and what you believe is meaningful . what's the reason for looking at the difference in the first place ?
239431,"my favourite introduction to measure-based probability , for readability and choice of topics , is b . candelpergher , [ _thorie des probabilits . une introduction lmentaire_ ] ( url ) . unfortunately , it's again in french . are you sure that you don't want to learn a bit of french ?"
239447,how do you mean equivalent ?
121504,"( 1 a : subj ) is : a random intercept for subj nested in a , but i'm not quite sure if it is what you were interested in computing . . ?"
238438,can you add the result of the model ( s ) and a descriptive of the categorical variable ?
239481,drake - i think i agree with you on first q . don't understand the second . what do you mean 'they compute the singular value decomposition or eigen-decomposition of xt xxt x or x xtx xt internally' - you have just shown the code where it is all done using svd on x ?
239536,"some portions of the question are misty a bit . in particular , what is ` raw component covariance matrix ` ?"
239559,how many observations are there per doctor ?
239518,what exactly was the question ?
238496,"your "" update : i added an answer "" replaced the previous edit with your architecture description and an illustration . is it on purpose ?"
239657,"the problem you're describing is a little bit unusual . you claim to have three separate sets of 1-dimensional data $ ( x_1 , y_1 ) $ , $ ( x_2 , y_2 ) $ , and $ ( x_3 , y_3 $ ) , with a linear relationship in each and a possible covariance matrix in the observations $ y_j $ . is this what you really mean ?"
239668,"to be clear , you want the distribution of $ m_t : = max ( y_1 , cdots , y_t ) $ ?"
239697,i am not certain i understand your problem : do you want to just estimate one set of coefficients ?
239713,your sample is whatever it is . any preceding estimates of sample size are completely irrelevant . the situation is like searching for a coin you dropped on the floor . you guess it's under the bed and start searching there . finally you find it under the desk . should you give up and start over because you found it in a different location than you initially thought ?
239716,do you have information about the variable in your data both before and after the event ?
239645,have you done this ?
239734,"siddhesh , i fear that this comment trail might be going in a misleading direction . could you clarify your objectives ?"
239642,why not just do a paired test for 0 on the difference ?
239724,is this a multiple choice question ?
239784,"some useful information is missing , e . g . , how many products are you analyzing ?"
239793,you get 0 if you set ( $ frac { d ln l } { d p } ) ^ 2 = 0 $ . but who says you're allowed to do that when solving for fisher's information ?
230546,what do the bars indicate ?
239840,can you think of any pair of iid random variables that satisfy this before you try to characterize all such random variables ?
238797,you say the data is weekly but i sense that it is daily with readings taken at hourly intervals . is that correct ?
238141,"can you please define what you mean by "" * fail in most cases * "" ?"
239679,i take it you want to incorporate the fact that the second and third conditions are themselves only observations on some presumed underlying distribution . so under the null hypothesis there's some population multinomial underlying conditions 2 and 3 and the multinomial for 1 is itself a mixture of them ?
239873,i think a more fundamental question is why do you need a single variable instead of using all four at once ?
239899,can you give the functions you are actually working with ?
239867,did you try l'hopital's rule ?
239954,how many variables do you have ?
239923,how many racial groups do you have ?
239946,"the p values are telling you that the mean of level x is different than the mean of the reference level . in your update this would be 10 vs 4 , 10 , vs 5 , etc . you do not want to just drop levels because they are not significant . i think you need to take a step back and define your hypothesis because that will guide the analysis . do you want to compare each level to 10 as the reference ?"
239995,"your comments suggest some really fundamental confusion concerning functions and their inverses , darkace . would it help to rename $ p $ as "" $ x $ "" and $ alpha $ as "" $ y $ "" ?"
240000,"for starters , it would help if you would tell us the marginal distributions of the inputs . this sounds like run-of-the-mill uncertainty quantification , thus i gather you're modelling the inputs as independent , right ?"
239999,is there a reason to believe that batch-to-batch variability will be the same in all conditions ( at all combinations of treatment factors ) ?
240006,"by "" loading into 1 factor "" do you mean that you performed a factor analysis , that factor analysis had a one factor solution , and all items loaded on that one factor ?"
240036,could you explain why you are sampling ?
240016,practically how do you compare 100 numbers ?
240044,"please write out your abbreviations : in particular , what does "" cef "" refer to ?"
240045,when you say the data points have error bars do you meant each of them is a summary statistic of a number of data points ?
240093,the variance of the sum the $ n $ random variables ?
239610,""" rotation failed to converge in 25 iterations "" - what rotation ?"
240151,"i am really interested in your algorithm called "" enter link description here "" . can you please elaborate ?"
240156,what exactly do you mean by including both random and fixed effects ?
240196,what's the species abundance distribution of the original data set ?
239942,"are you trying to classify such that , say , new observations can be placed in either group in the future or are you trying to infer something about the group from your variables ?"
240238,"two questions : 1 ) is the noise level in your example "" typical "" ?"
240019,"if you want to identify subjects , how can you possibly remove "" entire "" subjects for a test set ?"
240251,what does thie decrease by 12 % mean ?
240262,"hannah , draw u1 and u2 as x , y axes - what corresponds to z = z on the graph ?"
240270,can you say a little more about the modeling approach you are using ?
240290,"you're getting the same shape u with and without the log transform - it's just stretched out into a skew on the original scale . it won't be easy to interpret , but a ` poly ( log ( your_variable ) , 2 ) ` would probably do well . i'm now unclear on your goals - how well do you * need * to interpret this variable ?"
240163,"for the title , you might include "" non-negative variable "" , as that seems the focus . and you might re-word more like "" what options besides exponential ?"
239956,what is the exact structure of the output variable you're trying to predict ?
240366,"sounds like you don't have a multicolinearity problem - the vif is small . also , you mention having 4 predictors , then 10 , then just using 2 . why is a specified number of variables important ?"
240361,"package "" ellipse "" seems to focus on bivariate normal , too . therefore , i wouldn't expect anything different than other sources focusing in bivariate normal . what did you do using ellipse ?"
240383,"when you are using $ text { plim } $ , aren't you addressing consistency rather than ( un ) biasedness ?"
240325,"what do you mean by the "" second method of solution "" ?"
240437,"ttnphns , why not make that an official answer ?"
240463,"the question about code is off-topic , but the rest of the question is on-topic , imo . as you mentioned you tested without regularization , are you sure your data are not linearly separable ?"
240466,sensitivity depends on knowing the true state so unless test b defines that i think the answer is no . can you perhaps expand a bit on your data set-up ?
240487,""" $ r_1 , . . . , r_n $ are their wilcoxon singed [ sic ] ranks "" - can you please explain what this means ?"
240360,"i think it would help if you can say something about the way in which the sample is * not * multinomially distributed . what is the nature of the violation , is it the independence assumption for instance ?"
240525,did you get anywhere with this ?
240527,"i am not sure , but perhaps add fewer hidden layers ( e . g . a single one ) but add more units to it ( 10 or so ) . i am not acquainted with keras , could you please double check if you are using its api correctly ?"
240557,what about modelling the expected ratio ( or maybe the ratio of expectations ?
240278,what prior distribution on the bias do you wish to assume ?
240476,please give the details in order to resolve the apparent discrepancy . what are the circumstances ?
240588,statistical significance relates to a specific hypothesis test . what's the hypothesis and test statistic ?
149438,"are the * only * known quantities the coefficients ( and hence $ p $ ) , t-stats , p-values , $ r ^ 2 $ and adjusted- $ r ^ 2 $ ?"
240172,"just to be clear : the observations of type 2 are bounds on the i-th observation , whose exact value we don't know , right ?"
240624,1 . see my answers here url and also here url have you read the slides that you linked to ?
240615,"i've made some corrections but your should check the subscripts in your mathematics -- it looks odd . do you mean $ mu_ { c , i } $ where you have $ mu_c , _i $ ?"
240644,"within each sample the success and failure counts are ( at least notionally ) binomial , right ?"
240650,"you cannot compute a roc curve for each patient . the points that shape the ( empirical ) roc curve are due to different patients . you question is still vague . should your classifier use the whole time series or just one single measurement , and you just ask when to measure it best ?"
240665,did you try the bootstrap ?
240716,what is ` glm ( mxdf ) ` ?
240726,"would it be possible to post a sample of your data , e . g . first 10-20 rows of your dataframe ?"
240724,perhaps just delete now and ask as richardhardy suggets ?
240735,"it's not 100 % clear if this is what the question you refer to is asking , but ( aside from the distribution you look up ) what is the difference between a z test and a t-test ?"
240791,"i don't have time for a full answer right now , but here is a hint : how many parameters does $ t $ have ?"
240803,what tables are you using ?
240852,what do you want to find with your clusters ?
240873,"hi , i'm not sure i understand how you are using roc and for which purpose . each point on the roc-curve is a parametric function of the threshold $ t $ i . e $ left ( x ( t ) , y ( t ) right ) = left ( fpr ( t ) , tpr ( t ) right ) $ evaluated for * all * datapoints . you can see it as if you're plotting the confusion matrix of the classification at each threshold . this means you can't 'throw away' data points as each segment will correspond to all data points . should i clarify ?"
240586,can you paste in your output & some sample data ?
130881,what is your measure of sparsity that is fixed for you ?
240725,what is n ?
240096,do you have any specific type of model / prediction in mind ?
240954,"this is hard to follow . can you provide a simple , concrete example of what you're doing & what the problem is ?"
240850,"there are many bizarre nonsensical phrases embedded in this post : "" magnets ai , "" "" dane dive , "" "" tune axis , "" "" fire bad . "" are you a computer ?"
240988,"your edit appears to pose a different question : although originally you seem to want a * confidence interval * for the proportions of balls , the edit seems to ask for * prediction intervals * about a sequence of future steps . which of these questions are you trying to ask ?"
240989,"can you edit your question to provide some more information , for instance by giving some examples of these linear equations ?"
241044,"closely related to that particular covariance function : url though this , too , is for a set of points . can you clarify what you expect a "" simulation over the real line "" to output - it's ( obviously ?"
241032,i recommend you to read this q : url ( i will even consider it a duplicate candidate . ) ` i'm confused where the values for the scree plot come from ?
241048,what have you tried ?
241130,have you tried ` plyr : : ddply ` ?
241160,1 ) why is your corr matrix not symmetric ?
241155,have you tested multicollinearity ?
241182,there are better ways to analyze this data than a comparison of pearson correlations . have you considered other methodological options ?
241134,can you plot the distribution of beta carotene intake for those with cancer and without and compare the distributions ?
241214,so you have one between-subjects factor with two levels ( two groups ?
240755,"normally one would consider a "" transformation "" to be a function $ t : x to x $ , in which case $ t ( emptyset ) = emptyset $ is the only possibility for $ b $ , whence $ mu ( b ) = 0 $ . since you have supposed something that contradicts this conclusion , could you please explain what you mean by a transformation ?"
241240,have you already run this code ?
241248,"do you need help just interpreting your results , or with the methodology ( since you mentioned unbalanced factorial ) ?"
241021,can you work out the standard error of the estimate ?
241250,the likelihood is a function . a function is not automatically maximized at a turning point . ( e . g . consider -- where's the mode of an exponential density ?
241271,what's $ e ( hat { alpha } _ { _ { ols } } ) $ going to be equal to ?
241286,"the diagram appears to suggest there are cycles in the net , that would imply that this is a recurrent neural net . why couldn't there just be regular connection from the controller to the read-write head and back again ?"
241316,"well , for a given image it might not be clear what should and shouldn't be included in its labeling . you can imagine a picture of a single brick might be labelled as such . but should every single pictures with a brick or a brick wall be labelled as such , even if it is only a small part of the background ?"
241222,"maybe you are leaving out some important details , but it's possible to construct counterexamples for these statements . what happens if $ s_i $ is standard normal but $ g_i = text { sign } ( s_i ) $ , for instance ?"
241382,"i am a bit surprised that you specified intercept = false but still got an estimated intercept . this may not matter , but what happens if you specify mods = ~ factor ( exp ) - 1 instead ?"
241390,does ( 28 : 84 ) mean the amount of data points in two groups ?
241433,"without even looking at the link , why would you be surprised to see the chi-squared distribution ?"
241422,did you get any warnings from your lm fit ?
241441,"yes you are correct in that $ x ^ tx $ is non-invertible . however , perhaps your colleague performed some penalized regression like lasso to get coefficients ?"
241471,"i think the behavior will be unpredictable because the model is not identifiable . that is , how can the model fitting procedure possibly know for instance that $ beta_1 = 100 $ and $ beta_2 = 0 $ rather than $ beta_1 = 0 $ and $ beta_2 = 50 $ ?"
241491,which is it ?
241519,"this is strange . i have no experience with python , but the nan values do indicate that something is wrong . the regression might give wrong answers for various reasons , but it should at all times at least give answers . could change the number of examples from 100 . 000 to say 5 and then manually check whether x and y get correct values ?"
241560,"tim , what do you mean by "" how did they find "" ?"
241388,"yes , and i edited it somewhat further . can you specify which package you are using and add some pertinent code ?"
241634,are you sure that you are not just fitting noise ?
241718,did you try plotting the datasets first and see what kind of patterns are there if any ?
134334,do you have a link to the publication ?
241793,how many features do you have ?
241845,is there some random process that is not seeded in the same way each run ?
241859,"` if there are any general solutions ` , ` r has functions that can perform clustering on data with nas ` i'm sorry , ben , to me these phrases are conspicuous that you don't have any specific plan of your analysis . the "" problem "" itself hasn't been described as a problem . _why_ chunking variables in subsets must be done ?"
241873,can you provide a complete citation for parmar et al . ?
241860,possible duplicate of [ examples of processes that are not poisson ?
241955,how is the rss defined ?
241967,can you clarify the sense in which you mean close to ?
241979,"your problem is not the roc analysis , but your predictor . you need to define what is a "" positive "" prediction . does any measurement above a cut-off define the sample as positive ?"
242003,you mean the residuals ?
242034,do you have any prior knowledge on how you expect the airflow to behave ?
242033,what is that you don't understand ?
242047,12 million observations seems somewhat excessive for a glmm . is it really necessary to fit the model to all observations ?
242048,"if you have approximately 7 variables for each dimension , then is there any reason why you can't just sum the scores for each variable and use that as a measure of the dimension ?"
241992,wouldn't this highly depend on what you want to know ?
242062,"those are distinctly different tests , so your question can be resolved by considering what it is you want to determine : are you trying to tell whether the collection of all data is consistent with independent draws from * a single normal distribution * or do you want to know whether each group looks like independent draws from some normal distribution , * but possibly a different distribution in each group ?"
242146,sounds like you're using your bag of words to try to classify tweet sentiment ?
242142,"if your boss wants positive coefficients , why not solve the following quadratic program ?"
242175,how are you coding the predictors ?
242206,?
242285,can we trust 3020 $ ^ circ $ c ( presumably celsius is being used here ) as a temperature ?
242322,"the link you included also has a faq with an answer to the quetsion : "" why is your calculator different from other sample size calculators ?"
242163,what is the correlation between ?
242344,can you add a full reference / citation to the linked paper ?
242348,"that's no problem , now you know . can you provide some sample data ?"
242461,are you only adjusting on 10 or so p-values ?
241685,"so to clear , it seems that every individual has a mean and a standard deviation and that each measurement for a given individual is an iid random variable ?"
242335,have you tried adding an [ interaction term ] ( url ) # introduction ) ?
242476,"your code does not make much sense : you are sampling ` bp ` 10000 times and then you take just the last sample . . . moreover , why do you sample without replacement if you want to conduct bootstrap test ?"
242479,which programming language are you using ?
242521,which normality test are you using ?
242590,( 1 ) could you explain the relevance of the * second * derivative of the cdf to your question ?
242406,elaborate more on why your data isn't iid ?
242627,"i can't follow your question , it seems very confusingly worded to the extent that i can't clearly tell what you're describing for example , what do you mean by [ -1 , 0 , 1 ] and how does that relate to the gaussian ?"
242649,""" prtest "" isn't widely used term -- it's probably the name of a function in stata , likely an abbreviation for "" proportions test "" . out of interest , why doesn't a chi-square test seem right to you ?"
242653,posterior probability of what ?
242711,"if hpvtime is 18 how do you know it was relid 3 , not 4 which also spans 18 ?"
242722,why would it be a problem to remove products for a given customer to see if the engine starts recommending it ?
242247,can you provide the reference for the text ?
242772,"when you say how , do you mean programming wise , or conceptually ?"
242821,where does the quote come from ?
242856,what else is in the model ?
226362,how much variance do those 2 components explain ?
242868,"do you really mean "" each $ x $ "" or did you intend to write "" for each $ ( x , x_2 ) $ "" ?"
242878,"i think that 95 % ci would be what you would get if you did a two-sample t test with * equal * variances . your formula , however , is for * unequal * variances . what did you your calculation yield ?"
242914,are you talking about the conditional or the unconditional distribution of y ?
242935,is it correct that the correlation test inside the for-loop is independent of the loop-variable $ j $ ?
242724,"it seems like a decent amount of time and thought has gone into this question , but it's received relatively little attention . i wonder whether having a more explicit question would help ?"
242948,what does it mean ''in ascending order of the time they take'' ?
242963,"i don't think it is meaningful to seek the ` sample covariance ` of two sample variances . given a set of data $ ( ( x_1 , y_1 ) , . . . , ( x_n , y_n ) ) $ , $ s_1 ^ 2 $ is an estimator that will produce a single number , and $ s_2 ^ 2 $ is an estimator that will produce a single number . what then is the _sample covariance_ between those 2 single numbers ?"
242799,perhaps show us the things which do not correspond to give someone a clue ?
242000,why are you predicting width with burial ?
243085,"so two samples , each of size $ n $ , are drawn from the same finite population and you want to know what the expectation of the product is ?"
243090,this seems so wrong . . . is there any reason why you are avoiding to use a squashing functions and a more appropriate cost function ( i . e . cross entropy ) ?
242990,you need to explain in more detail how the non-integer values arise . how do you come to be dividing by 3 ?
243115,"it isn't clear what you are asking . could you explain in what sense the convergence rate of $ bar x ^ 2 $ is "" faster "" than that of $ bar x $ ?"
243118,"i can't quite work out what you're asking . are you saying "" given some spherically symmetric distribution , such as a bivariate t distribution , how can i generate ( x , y ) pairs from it ?"
243139,could you supply enough information to help us know how the lr was applied and to determine whether it was applied correctly ?
243144,mr . liu what type of data is it ?
243151,the beta distribution is bounded at both ends and the gaussian distribution is not . how do you expect to handle that issue ?
243095,can you provide us with more details about the study design ?
243188,can you show the qq-plot ?
243208,look at the good-turing estimation problem ?
243078,which book ?
239993,"using your code in r , i find that both cor ( x , y ) ^ 2 and cor ( z , y ) ^ 2 equal . 50 . are you finding otherwise ?"
243219,"what does "" geometric probability on $ omega $ "" mean ?"
243281,what is the probability that the sun will rise tomorrow ?
243335,well those are count proportions - but is sounds like you don't have the denominators ( which impact the relative variances of the observations ) . do you have the numerators of the counts or only the ratios themselves ?
243361,this doesn't make a lot of sense . how did $ x $ disappear from the right hand side in your second expression for $ f_n ( x ) $ ?
243383,could you try to be more specific on what kind of sampling do you have in mind . . ?
243386,is this only for 1 or more than 1 product ?
243385,how large is your corpus ?
236202,is there anything about the problem that treating it as censored at 15 hours would fail to capture ?
243412,"note that they set the premise of the paper up right at the start : "" * you have just finished running an experiment . you analyze the results , and you * * * * find a significant effect * * * . * success ! but wait how much information does your study really give you ?"
243432,what's your left hand side variable ?
243217,can you make some of your notation more explicit ?
243446,"linear regression model is a * model * . ols is an * estimation technique * . given this , what kind of setting are you actually interested in ?"
243315,are you sure $ x_ { -j } $ should not be $ x $ with the $ j $ th * column * removed ?
243529,have you taken a look at bootstrap theory ?
243576,is this [ tag : self-study ] ?
243590,"classic cca is 2-set cca . generalized cca is for any number of sets ; it , however , projects not on "" the other "" set but on the "" averaged "" set . regarding your questions now . ( 1 ) the strength of association between sets is not necessarily reflected by the _number of_ strong / significant can . correlations . this number is the essential dimensionality size , necessary to account for the association . ( 2 ) more "" complex "" ?"
243616,why beta ?
243589,"could you elaborate on the difference between "" estimating "" and "" making educated guesses "" ?"
243634,meyn and tweedie ?
236910,"if you sum the values of a single observation and do not get * * one * * ( or 100 % ) as the answer , then either they are not proportions that make up a whole or else they are reported with some amount of measurement error . unless the lab is giving you negative concentrations you certainly won't get a sum of zero ! what , then , are you trying to ask about a "" closure effect "" ?"
243697,"do you want the plot to help yourself understand what's going on , or to present to others ( eg , in a paper or a talk ) to communicate some point about the data ?"
243725,is series data real valued ?
243732,"good . new information should be added as an edit to the original post , please do so ( there is an "" edit "" tab below the post , use that . and also , the numbers in the output from the program , what do these represent ?"
243701,what analysis are you planning to do with each group ?
243743,daily data ?
243747,so there is only a single design variable ?
243686,what does wss stand for ?
243792,are you thinking of a koyck model ?
243787,"can you provide your data , and indicate the software ( if any ) you are using to perform the test ?"
243833,"aksakal , the confidence bands are already there , aren't they ?"
243689,"[ i agree with firebug and iliyan bobev that you should be using the individual votes ] , and the question is to understand exactly what differences in the two processes explain the better performance . eg are you comparing accuracy on individual vote to accuracy on election ?"
243605,without knowing what would count as a good measure for your scientific question this is very broad . can you expand on what properties you are aiming for ?
243894,have you tried konig-huygens ?
243887,"when you say "" i know that the sum must be a uniform ( just from guessing ) "" . . . are all ( or essentially all ) of your guesses true ?"
243970,also what kind of model are you using ?
243974,"it appears you have a survey with two items ( hair type and body type ) , with 5 responders in the first month and 6 responders in the second month . is this correct ?"
243371,could you copy ( the relevant parts of ) algorithm 2 into the question to make it self-contained ?
244006,gaussian process regression typically assumes a stationary data series . is there a trend in the data ?
244009,your outcome ( ` ` s_ratio ` ` ) is a count divided by another count ?
244018,what measure do you use for * training * error ?
244033,are you sure about the parameterization ?
244027,why not plot the density functions of some exponential distributions and compare them to histograms of your data ?
244039,"it's a clumsy solution , but if you have some sense of whether a response is correct or incorrect ( i . e . if an ungrammatical item is rated excellent ) then could you not just calculate the percentage of correct responses per person and remove anyone who performs particularly poorly ?"
244044,"i see what you did , but you're not quite getting the generating process right . let's assume the observation is a failure with probability $ p_0 $ and a success with probability $ 1-p_0 $ . then , if it's a success , which category does it belong to ?"
244084,"if your model is multivariate ( more than one equation ) , isn't taking the ols-based covariance matrix as $ omega $ the standard textbook example of feasible gls ?"
244183,is this a question from a course or textbook ?
244195,"do * variables * have weight , or does somehow * number of variables * have weight ?"
244172,sales volume in units or dollars ?
244268,"what if you code an intercept , as predictor ( i . e , vector of one's ) ?"
244309,"just to clarify , when you say "" all the models "" do you just mean all types of neural nets ?"
244343,it sounds like you may want to cluster standard errors at the firm level ?
244336,possibly this url is a duplicate question ?
244354,why do you need to integrate it ?
244326,why do you think this is true ?
244121,are you forced to use the categorizations ?
244396,how did you reason that the probability of getting heads given a biased coin is 1 ?
244438,""" dig deeper "" is a bit vague . were there particular kinds of things you were hoping to find out / particular questions you wanted to see if you could answer ?"
244280,"when you say "" mean-centered "" do you mean that column averages are subtracted , row averages , or both ?"
244428,"when your code contradicts a theoretical result , you have to suppose there is a problem with the code . it is not the purpose of this site to debug code . given that fact , do you have a statistical question to ask ?"
244444,this reads like a routine textbook exercise . is it for some class ?
244509,"your title seems to mismatch your question . your title suggests that you are interested in [ multivariate kernel density estimation ] ( url ) , but your question suggests that you want to do some kind of classification . please edit and clarify what exactly is your data and what do you want to achieve . it is hard to comment if the solution is correct if the problem is unknown . moreover , what do you mean by estimating kde "" against row of a matrix "" ?"
244567,""" sampling obviously makes sense for medical studies , because we know a priori that humans all have quite similar genomes "" i do not have medical background , but do * really * our dna differs less than our political views ?"
244593,"i have no clear idea what "" higher residuals below the mean than anticipated "" means . what glm did you fit ?"
244551,you'd need to show $ omega $ is positive definite . where does $ h $ come from exactly ?
244608,why not re-run your old data with the new model ?
244363,you present 25 models . which model do you want to evaluate ?
244618,what is your goal ?
244602,is this a question from a textbook and / or assignment ?
244671,maybe evaluate the [ kl-divergence ] ( url ) between the empirical and theoretical distributions ?
244607,"i didn't really follow what you're doing . but for hypothesis testing , how about bootstrapping the whole procedure ?"
244429,"could you make it more specific what do you mean by "" continuum armed bandits "" ?"
244730,have you checked url ?
244732,welcome to cross validated . can you give us more detail about the outcome variable ?
244757,did you check the cran package tsclust ?
244750,isn't the coefficient of determination just r ^ 2 ?
244421,"is your choice variable simply $ n $ , the number of observations ?"
244815,""" did not work "" ( not "" working "" ) is not informative as a problem report in any forum . what happened ?"
244824,"what do you mean by "" regression analysis does not take into account the errors "" ?"
244825,you know an unbiased estimator of $ mu $ . can you find an unbiased estimator of $ 1 / sigma $ ?
244836,"what do you mean by "" only "" ?"
244832,"if $ x geq 0 $ is the situation ( i see it's in your title now ) , can you also edit it into the body of your question as well ?"
244846,"can you clarify what you mean by "" family trios and affected sib pairs "" perhaps by showing a concrete example or two ?"
244858,do you train the same net a second time or does it create a new net ?
244876,this is not an empirical joint distribution--it is merely a summary of data . in what way do you hope to use it to infer or represent a distribution ?
244522,can you paste in the section [ s ] & the picture in question ?
244957,"hint : fix $ i $ and $ j $ and write out explicitly what $ ( y_ { ij } - overline y_ { i cdot } ) $ is ( that is , expand that $ overline y_ { i cdot } ) $ term completely ) , and then decide whether it depends on $ a_i $ ( or on $ mu $ for that matter ) at all . if not , then $ sum_ { j = 1 } ^ j ( y_ { ij } - overline y_ { i cdot } ) $ is essentially like a $ sum_ { j = 1 } ^ j ( x_i- bar { x } ) ^ 2 $ where the $ x_i $ are independent $ n ( 0 , sigma ^ 2 ) $ random variables , isn't it ?"
244963,did your df change ?
245002,"ok , so far i've understood that you have count data of your genes and want to identify genes with "" unusual "" high ( significantly higher ) counts . correct ?"
245013,"you're misunderstanding what the first test tells you . further , given a rejection , you don't need a second test to tell which one you'd conclude is greater . * just look at the proportions * and you'll see why the first null was rejected . ( incidentally , faced with that table of numbers i wouldn't have bothered with actually calculating a p-value . it's obviously so small that any attempt at an actual p-value calculation is pointless - what would be the value in it ?"
245044,what is ` fit ` column ?
245039,""" whereas the dependent variable ( a ) has 13 values "" does that mean a is not a continuous variable ?"
245063,"how to estimate the "" unwilling to identify themselves as trump supporter . "" effect : maybe focus groups ?"
245096,i'm confused . why can't you just compute the feature ranges in each class separately ?
245098,are the pre / post values in pairs as in the data set ?
147527,"have you tried running lmer ( eref ~ time window group : time group : window time : window time : window : group ( 1 subject ) , data = datalong2 ) ?"
245120,it looks to me like $ f ( x ) $ is already an expected value ; $ e ( f ( x ) ) $ will just equal $ f ( x ) $ because there's no randomness left after the summation . the variance would then just equal $ sum ( f_i ( x_i ) -f ( x ) ) ^ 2p_i $ . or am i missing something ?
245152,$ ( 6 % 16 % 56 % 26 % ) 100 % $ . so respondents can provide $ 1 $ answer ?
245175,could you maybe show a plot of the time-series ?
244729,"is your goal prediction , inference , or something else all together ?"
245041,what about variance ?
244660,have you looked into gaussian cox processes ?
245219,can you post the r code you use to run the inference ?
244883,"sych model would not predict x but e ( x ) ( see [ here ] ( url ) ) , so you won't see any extreme values in the predicted x -- i guess that in early warning system you would be interested in the extreme values . . ?"
245244,why are we talking about taking limits inside expectations ?
243944,"you turned a binary classifier into a classifier that has 3 possible outputs , how did you change the algorithm ?"
245280,5 . do you want a regression model with autoregressive errors or just a regression model ?
245297,what is the problem with treating these as categorical regressors in your model ?
245332,you can standardize the variables first . that's what ` princomp ( ) ` does when you set ` cor = true ` . is there some reason to think the relationships are multiplicative ?
245352,why do you use only two components ?
245361,when you say you have the total sample size and event rate for the study does that not answer your question ?
245245,"sure , just letting you know . what is the relationship between ` freq ` & ` weight ` ?"
245348,do you want the model equation ?
245188,why don't you ask your professor ?
245405,what do you mean by 'regression' ?
244839,what package is that function from ?
245430,your first paragraph is ambiguous : could you please edit it to include proper quantifiers and some description of the context ?
245393,* * ( 1 ) * * are you asking how to improve the model ?
245431,"you may need to provide more information . for example , what do you mean by a 73 % success rate ?"
245455,this is interesting . care to share your data ( and / or your code ) ?
245508,"by two-level do you mean multilevel , or hierarchical ?"
245510,"could you clarify what you expect to gain by "" splitting "" the quarterly data into months ?"
245535,is the specific pattern which you are trying to find predefined ?
245482,why do you have the same lag order in levels-var as in vecm ?
245551,"carl i regularly deal with real data problems quite well-modelled using poisson distributions where the parameters are substantially less than 1 ; indeed frequently they're below 0 . 01 . many of the questions of interest cannot be answered by treating it as binomial ( e . g . something more or less akin to "" if we have a poisson process with $ lambda = 0 . 1 $ per unit of time and we observe it for 8 . 5 time units , what's the probability of at least two events ?"
245437,from what information are you attempting to estimate a sample size ?
245572,it's not clear how you can possibly apply wilcoxon test here . can you elaborate ?
245571,do you have reason to believe that all the unlabeled data are falses ?
245605,your answerable statistical question concerns the sign change when additional variables ( the interactions are added ) . isn't that [ answered already in these threads ] ( url ) ?
245540,"if the distributions are constant over time , time series models would be irrelevant . if , however , the distributions change with time and knowing the last distribution ( or a few recent ones ) gives you extra information about the newest distribution ( the outcome of which you want to predict ) , then time series models may be relevant . could you write down a model for one or all of your series ?"
245638,what definition of tail dependence do you have ?
245669,could you clarify that you mean $ y = wx $ and not $ y $ is the convolution of $ w $ and $ x $ ?
228199,your question is how to do it or is it about validity of your algorithm ?
245641,can you clarify what the p-value you derived from each of your 1000 simulated data-sets represents ?
245600,if the chamber chosen is random every shot then the optimal strategy should be obvious . is there more to this game ?
245726,"i wouldn't confidently say that the homoscedasticity is violated by looking at the plot alone , did you look at url ?"
245774,fine : - ) so if you use the $ sqrt { n } $ then you should have some non-covering intervals ?
245712,is the answer by user11852 below what you were looking for ?
245806,and what do you do when $ x 0 $ ?
245825,"by the way , why do you use the subscript mle for a gls estimator ?"
245837,* none linear * relationships ?
198939,"it is difficult to determine what you need because you appear to be using the word "" permutation "" as if it were a synonym for "" combination , "" which it is not . could you please provide a definition of what * you * mean by these terms ?"
245862,i'm assuming you want to analyze how long something takes . have you read about survival or time-to-event analysis ?
245824,does it have to be * exactly * one or is approximately ( like 1 . 0076 ) good enough ?
245880,can you please provide a better title for your question ?
244489,could you please indicate the source of the reference ?
245901,how many observations do you have per set ?
245860,what is reproductive property ?
245442,near duplicate : [ how can a regression be significant yet all predictors be non-significant ?
245915,please explain what the data mean . where are the sales ?
245955,"if you have no assumptions , how are going to compute a likelihood in the first place ?"
244481,"it's unclear what you are asking : by "" non-negative "" do you mean * non-negative definite * or do you mean * all coefficients are non-negative * ?"
245902,"tim , [ finite-fixture-model ] ( a tag that you used here ) does not have an excerpt . care to provide one ?"
245543,what are mp1 & mp2 ?
246078,what is your goal with this model ?
246077,do you have a balanced design ?
246065,do you have any additional information about the groups ?
246085,i'd be very cautious about that ` r-squared = 1 ` . do you have an idea of what the potential weights should be ?
246088,is there a specific reason you do not use backpropagation ?
246082,we have had ordinal logit and probit models for 50 years or so ; why do researchers not know about or fight shy of them ?
246124,"$ w = 0 $ minimizes that function for all data , but this probably isn't what you're after . can you explain more about what problem you're trying to solve and what $ w $ is ?"
246175,was this solved ?
246193,are trying to kill performance ?
246200,is it the same data ?
246211,if you're going to generate multiple correlation coefficients through bootstrapping then why not generate a distribution of $ r_1-r_2 $ and use that to calculate a p value for the difference in coefficients that you observed ?
246229,have you considered a proportional hazards model ?
246014,what is the partial covariance matrix ?
246234,it's not entirely clear what you want : if you have $ r = . 8 $ with $ p = . 04 $ then would you want that to be shown in a different colour / shade to $ r = . 8 $ with $ p = . 03 $ ?
246268,what do you want to know the effect size for ?
246221,what is the criterion of winning ?
246258,what is the context ?
246302,"not sure if this is worth to be considered an answer , so i am posting it as a comment : maybe there is some terminology coming from projections ( as $ x ( x'x ) ^ { -1 } x'y $ is a projection of $ y $ onto the $ x $ space ) ?"
245300,"you say you have "" integers from 1-to-7 "" , but then you show data that are clearly not integers . it appears from your description that your y data is not continuous but on an ordinal scale . why do you believe you can use an ` lme ` model with such data ?"
243922,could you explain why you multiply the sample variance by $ ( n-1 ) / n $ ?
246332,i see $ n $ equations and $ 2n $ unknowns . is your question about how to describe the solution set ( a variety of some sort ) ?
246142,"let $ x $ be end users and $ y $ be total cost . take the original model $ log ( y ) = beta_0 beta_1 log ( x ) $ , which "" fit the trend quite nicely . "" dividing $ y $ by $ x $ is equivalent to subtracting $ log ( x ) $ from $ log ( y ) $ . thus your model implies $ $ log ( y / x ) = beta_0 ( beta_1-1 ) log ( x ) , $ $ which is a beautiful linear relationship between the logs . this makes it difficult to believe that "" no transforms yield a linear relationship . "" since $ r ^ 2 $ is next to useless for evaluating linearity , that's of no help . could you describe what you're doing more specifically ?"
246189,why do you need an explicit functional form ?
246432,the variable contains counts or is a continuous variable ?
246245,"why don't you try out a set of different models , cross validate and iterate till you find a better fit ?"
246465,"so if there's a 5 % chance of wrongly rejecting the null hypothesis , and 2 . 5 % of this are false positives ( i assume you mean 5 % -2 . 5 % ) , then what do you think the other 2 . 5 % represents ?"
246368,can you tell us what the actual sample size is ?
246387,"please explain why you think "" $ f $ should equal $ t ^ 2 $ . "" what are the assumptions needed for that to hold ?"
246485,what are the priorities of the site-owner ?
246511,"could you explain what this "" uniform distribution parameter "" means ?"
246528,"do you have monthly data , weekly data , daily data ?"
246563,do you have reason to believe that there is a latent normal variable that lies behind people's manifest responses ?
246629,"for many people "" nd "" means "" nondetect "" . what does it mean here ?"
246619,is this r code ?
246657,could you describe what this aggregate should represent ?
246687,what do you want to use the clusters for ?
246669,"regarding the real ( birdwatching ) problem , how did you get the $ p_ { ci } $ s ?"
246694,"can you explain "" mosaic codes "" ?"
246682,would it not be simpler to include a factor which distinguishes between type a and type b females ?
246724,"just to add to the options , why not also consider kendall's tau ?"
242270,which formulas are confusing you ?
192954,why not just plug your data into a poisson or negative binomial regression model ?
236646,"can we rephrase your question as "" for what glm families does the linear predictor correspond to a location parameter for some continuous distribution , and a selection model ?"
119853,"i am curious , is it not enough using a non overlapping offset ?"
246822,"do you want to include age , race and bender information in that comparison ?"
246829,why should the researcher's choice of model affect the test set ?
246842,does the weighting relate to variables that you can condition on in the regression model ?
245491,so your design is within subjects regarding the emotions but between subjects regarding the groups ?
246855,"the formula provided in the slides you link to is for the probability , not for the state . could you clarify your notations ( or else point out how i misunderstood the question in my answer ) ?"
246852,have you at least tried to do some calculations by yourself ?
246864,why do you say that they are different in their definition of probability ?
246640,good question . where did these steps come from ?
246912,why not just calculate it ?
246932,"is there any stochastic , i . e . , random about your problem ?"
246960,why did you decide not to use the same coefficient for each situation ?
247006,strange . can you provide the title or a link to the paper ?
246950,"[ see here ] ( url ) . also , edit the title of your question to be more specific . some 1 out of every 30 posts on this site would fit the title "" what test to run ?"
246796,ig is a prior or likelihood ?
247082,without more detail about your scientific question this is really hard to answer . can you edit more details into your question so we know why you put the covariate into your model and why you interacted it with treatment ?
247089,"you keep on saying covariance , but do you mean correlation ?"
247087,by factor analysis do you mean factorial anova ?
247172,do you mean to say you are generating a rng * for * a normal distribution ?
247167,"what is your mean resultant length and sample size , in this case ?"
247185,where did you use regression before ?
247127,you're probably better-off recasting your anova into an ols regression . do you have a variable that explains the multimodality of the outcome variable ?
247268,"what do you mean by "" how can i contrast "" ?"
247305,why not simply use a permutation test ?
247331,individually are their theories any good at predicting the weather ?
247312,i'm not sure about your terminology : ` shared variance between the factors ` ( or ` columns ` ) . principal axes or column points ?
247162,you have both $ y $ s and $ x $ s in your text but only $ x $ s in the formula . should the $ y $ s in the text actually be $ x $ s ?
247414,"statistics to measure what , exactly ?"
247423,what is the purpose of your question ?
247445,in your last comparison do you mean better than c ?
247450,"you have to do another model with a different reference group . i just noticed that you only have 2 clusters ( i . e . only 2 different levels of the clustering variable used in the gee model ) . if this is correct , you shouldn't use a gee model at all . it is often recommended that you have at least 50 clusters . perhaps you can just include the clustering variable as another independent variable instead ?"
247463,you want to sample them with probability proportional to their value or to their value exponentiated ?
247476,why is this important to know ?
247499,. . . well no response in a couple of hours ?
247517,""" my accuracy is fairly good "" : accuracy of what ?"
247597,"this looks like code check , which is off topic here . ( if that's what you want , you could try deleting this & posting on the [ codereview . se ] se site . ) can you clarify your machine learning question & add pseudocode for those who don't read python ?"
247614,i think you are going to have to narrow this one down to get sensible answers . how are you proposing to forecast ?
247577,"are you interested in $ p ( a x_1 , ldots , x_n ) $ or $ p ( a b , x_1 , ldots , x_n ) $ ?"
247652,2015 had 365 days . why not use just daily date with specified origin as predictor ?
247670,wouldn't this break the markov assumption ?
247737,don't autoencoders fall under the umbrella of manifold learning ?
247413,what is this output from ?
247806,are all your variables standardized ?
224376,what's the problem ?
247866,what does $ sigma $ represent here ?
247959,are all of the events ( deaths ) in your data in the last period ( 2015 ) ?
247960,"just to be clear , are you trying to predict a variable with these 8 features and is that variable the value on the y axis ?"
248006,"can you point us to , and ideally edit into your question , the reasons why people have told you not to do this so someone here can argue against them ?"
248001,you do realise presumably that a dataset small enough to be a paradigm case for fisher's exact test is not likely to be amenable to the sort of multivariable analysis you propose in ( b ) ?
248045,no you cannot inculde error terms in glm ( ) . what about logit transform your response and considering a linear mixed model ?
248104,perhaps some of the discussion in url may help ?
247964,do you want to summarise each column or do you want to compare the distributions ?
248155,what makes you think that you need one observation per asset ?
248237,can you say more about what you want from such a reference ?
248262,do you have the actual data or do you want a conservative choice in the general case where you don't know the data ?
248386,* the question is how to assess consistency of the two proxies for each species . * how do you define consistency ?
248396,is there any particular reason you're not using a random forest ?
248459,"you usually apply bootstrap when you have a single statistic and you want to obatain a distribution / confidence intervals from that statistic . if you already have distributed data , bootstrap is not useful . when you say 'describe the physics' ; what do you exactly mean ?"
248465,can you categorize the bars into say k types where each type has a binomial distribution n = 5 and p = p_i ?
248301,"probably not . do you have explicit forms for $ alpha , beta $ ?"
248496,i think it is still a matter of wrong frequency . ` auto . arima ` should definitely pick up this pattern as long as the relevant frequency is specified . what is the actual frequency of your data and how long a period does it span ?
248505,chi-square test comparing 12 means of one year to the other could be a start ?
248503,what are you trying to do ?
248646,is this a question from a course or textbook ?
248603,what is the statistical question ?
248676,it would be helpful if you could elaborate what several means ?
248668,multiple observations for one stock ?
236975,"so , just to clarify , they were allocated to a condition and then each gave exactly two binary responses which have equal status ?"
248692,what are you trying to fit to what ?
247461,"there is no reason for it to be invalid , but why do you want it ?"
248804,""" i understand this is not 'allowed' "" why shouldn't it be ?"
248780,do you have an error plot for your model training ?
248758,your understanding of p-values could use some refinement : please visit url your question seems otherwise to be the same as url but it's impossible to tell because you haven't explained where those individuals came from or what you are trying to accomplish . are you trying to draw conclusions about * only * those 1000 individuals or do you hope to make more universal inferences ?
248779,can you explain us ( as an edit to the original post ) where that constraint comes from ?
248891,"could you explain what "" binary model "" you are referring to , given there are no binary data here ?"
248291,are you sure you are using the same data ?
248900,"this clearly requires a repeated measures analysis / mixed effects model . the difficult part is that your three dvs are percentages and that they depend on each other . consider this scenario : males and females eat equal amounts of prey a and prey b , but males also eat an additional amount of prey c . in such a case , you'd get different percentages for males and females although they eat the same amounts of a given prey a or b . do you have access to data giving the actual amounts ( this would require you to estimate the number of pellets excreted ) ?"
248706,"jokes aside this not a trivial question : i was looking this a bit more carefully and it does not have a good obvious answer . someone would have to carefully read the c code and i am uncertain it is worth it , my skim-read didn't find anything obvious . they are many points where things could be muddled ( eg . ` yval ` are passed as double so when fitting may unintentionally some aliasing takes place when splitting ) but i can't see one * obvious * thing . maybe you so this ?"
248875,can you expand on what criteria you are uisng to decide on whether one transformation is better than another and for what purpose you are doing this ?
248923,how did this problem come up ?
248194,"you should be able to formulate this as a system of equations , and then the task is to solve it in terms of the parameters you are allowed to vary . which of the two steps do you find problematic ?"
248935,could you please say a bit more about how you are planning to use your cox model after it is built ?
248970,is this [ ` self-study ` ] ( url ) ?
248982,can you graph either qqnorm or ecdf ?
248882,do you want to expand on your statistical question ?
248801,perhaps now is the moment to edit some of this extra information into your question and ask what courses of action are open to you ?
249045,"are you asking for help w / the code , or w / the idea of cis here ?"
248413,"i would perhaps add a [ cox-model ] tag . also , can you show the ` head ( wrds ) ` - just to see how the dataset is built ?"
211551,"since you're using a non-parametric test that is based on ranks , why not just code all the "" out of time "" cases with 501 ( or any other number greater than 500 ) ?"
249015,"if you can't see any value in plotting a histogram of your ivs then maybe you shouldn't do that , but is there any data which you've collected that you do think is of some value to the work you're presenting in the report ?"
249083,why do you want to remove the outliers ?
248902,"are you examining changes over time in abundance or prosomal width , or simply interested in mean values over all observation times ?"
249047,lda stands for which method ?
248814,what is $ u $ ?
249116,"to answer this , we are going to need to know a lot more about your study , your data , your models , & your goals . can you say more here ?"
249134,would this be better off at so ?
249135,"if you're already averaged the coders ratings , is there a reason you can't use a paired t-test for the male vs . female ratings that come from the same participant ?"
249131,"could you explain how you obtain a value of "" $ 100 ( 1 sqrt { 2 } ) $ "" for the standard deviation of a variable whose variance is $ 2n = 200 $ ?"
249171,it looks like there's clipping at approx . 270 ?
249191,"in what way do you mean "" work "" in the title ?"
249011,"what do you mean by "" mean of the variable "" ?"
249245,"looks like 2 , 3 or 4 possible outliers ( assuming that the shortest bars are all showing single values ) . if these were my data i would try to check whether there was some mistake with those or an extra story in terms of where they came from , or values of predictors for those observations . but : why do you want to call some data outliers any way ?"
249248,what's met ?
249274,welcome to crossvalidated . please tell us a bit more about your outcomes ( is it binary ?
249277,welcome to crossvalidated ! is this a homework question ?
249297,what does lnn mean ?
249177,could you please tell us what you think the connection might be between finding clusters in data and estimating a mean or standard deviation of the data ?
249334,"could you elaborate on what you mean by "" more valid "" ?"
249309,i don't immediately see how this should require a self-study tag ?
249399,what were the exact problems you faced when using random forests ?
249419,are you talking about computational efficiency ?
249431,could you give some background ?
249441,"ols regression predicts the conditional mean of the dependent variable , while quantile regression predicts the conditional median . however , it seems that is your dependent variable ( the number of years ) which can only takes integer values , rather than your predictors ?"
249466,"if both models were fit to the same data , the the sum # paramters # df would be the same for both models . those sums are not the same , so this cannot be two fits to the same data . so it can't make sense to compare goodness of fits . how do you defined "" complexity "" ?"
249536,"what do you intend "" analyze "" to include ?"
249432,a little bit of explanation would be helpful to understand your question . what kind of index are you calculating and how do you think the model may help in that ?
249560,if i understand you correctly this is not about sampling but about the inclusion criteria for your study . are you screening everybody and then just recruiting those aged 18 to 22 and speaking german ?
249586,is that perhaps a homework exercise ?
249641,is this an exercise for some class ?
249736,would you have any way of knowing which items had been retrospectively overrated ?
249062,what exactly is the difference between $ a_1 $ and $ a_2 $ ?
248955,could you please provide a minimal reproducible example ?
249784,"the treatment of poisson processes with variable arrival rate $ lambda ( t ) $ is quite standard , but of course it is assumed that $ lambda ( t ) $ is a known function . but you not only want $ lambda ( t ) $ to be a function that needs to be estimated , you even refuse to assume that the value of $ t $ is known . so , what meaning do you assign to the estimate that $ lambda ( t ) $ has value $ 5 $ , say , for some unknown value of time instant $ t $ , and has estimated value $ 3 . 9 $ , say , at some other unknown time instant $ t ^ prime $ ?"
249831,i find it hard to see this comparison as appropriate for a significance test if only because of queasiness about their interpretation as samples ( from what precisely ?
249578,"so you have each person do this estimation and task once , or you have one person do multiple rounds of estimation and task , or some mixture ?"
249656,""" well "" needs references . where does "" expected "" come from - give a single example before describing a sum . bold the actual question . find a way to augment the "" expected times to get a head "" . . . i recommend simulation . does the flip that made the head count ?"
249881,what is cv ?
249673,see also : [ why don't we use significant digits ?
249936,what do you mean by 'the true parameters' ?
249788,could you provide outputs of other two reduced models and anova results ?
249965,you have a problem of confusion . outlier models assuming normality are really saying that in the absence of outliers the data are normal . when outliers are present the data should not look normal and so why test the data sets for normality . ?
249976,could you please explain your notation ?
249858,"it seems you have no control over the data that enters the feed , so your proposed schemes are all rejection sampling . why do any rejection at all ?"
200460,"welcome to cv ! several questions to clarify yours : what do you mean by "" baseline "" features ?"
250010,there is a lot of questions here . have you checked [ the existing threads on kernel pca ] ( url ) ?
250027,how many levels are your 8 categorical variables ?
250090,is it possible you're being a tad rigid in your definition of meta-analysis ?
249235,what exactly are a and b ?
250155,"your table represents how well you fit your present data set . have you run any tests related to the generalizability of your model to other samples , like repeating your procedures on multiple bootstrap resamples ?"
250176,"do you want your index to represent reporting behaviour each year ( i . e . , one score per year per country ) , or overall ( one score per country ) ?"
250162,"are you trying to determine when a cumulative # like annual sales to date will exceed a "" certain large number "" given the monthly sales so far ?"
250181,why can't you use anova ?
250177,does taking the first difference of the data help ?
250154,can you give a reference for the claim ?
250232,have you tried * cosine * metric ?
250230,what is the problem ?
250235,"could you explain what you mean by "" different "" ?"
250241,"` when i look up the p-value corresponding to z = 3 . 24 i get the inverse of 0 . 001 ; 0 . 999 ` - how exactly do you "" look [ it ] up "" ?"
250254,if you look at ?
250265,"are you just asking for help w / the python code ( which would be off topic here ) , or do you have a statistical question about mle ?"
250279,"because $ y = kx ^ 2 $ is manifestly * not * logarithmic , could you clarify what you mean by "" logarithmic "" ?"
250282,"so , what is the question ?"
250114,can you post the data for people to play with ?
250294,maximusdooku what type of outputs are these ?
250277,how are you doing your predictions ?
250412,did you make changes to the process after the 23 failures ?
250422,"the criterion to "" generate a subset with a different mean "" isn't sufficiently specific to be answerable : there are far too many answers , all different . could you elaborate on * why * you're doing this and what you hope to accomplish with this generation procedure ?"
250442,is machine learning even necessary ?
250269,wouldn't any kind of claim like this have to be conditional on an assumed state of nature--and wouldn't that by default be the null hypothesis ?
250238,"your problem sounds like it may be suitable for a [ hidden markov model ] ( url ) ( hmm ) , but the description is not fully clear . one issue is that your time series may not resolve all changes , but the hmm framework could handle this . a more significant issue is that your data is only loosely connected to your variable of interest , and you have no ground-truth training data . a related issue is that you likely need background data to constrain * rates * : how long does it take to load / deliever a package ?"
250320,"can you say more about your study , your data , & your goals ?"
250548,"possible translation of question : "" what are some goodness-of-fit tests for linear regression models ?"
250559,to get the standard deviation and everything else you need to know the hypocotyl length for each of the 30 seeds for each experiment . what are you trying to test anyway ?
249087,did you try with skew-normal distribution ?
250578,"to clarify : at the start you say $ b $ is a function of $ theta $ , but then later in your definition of $ p_ theta ( x ) $ you have $ b $ as a function of $ x $ , and then again later it changes back to $ theta $ , and then again back to $ x $ . which is right ?"
242564,perhaps this paper ( also from martyn plummer ) will clear up the confusion ?
250591,there are several thing that are unclear . what does the variable z represent ?
250590,why not still call it bernoulli ?
250466,"can you simply recast your procedure as an ols regression on dummy variables , and follow standard mi practice from there ?"
247688,you should spell out ecm = expected cost of misclassification ?
250621,what do you mean by $ x = b $ ?
250644,are you sure that you are not just looking at the difference between the proportion ?
250679,are you assuming the remaining letters stay in place ?
250667,why not simply perform hyperparameter tuning ?
250704,do you want an answer to the general question or just to variances . in the special way you use monte carlo in your question ?
250700,""" however , there is no guarantee that 'these 20 data' is a representative of the $ f_t $ ! "" huh ?"
250532,there does not seem to be a reproducible example here which it would need but perhaps better on r-help or stackoverflow ?
250772,have you looked at the likelihood ?
250793,"isn't the zeroth assumption of any inference , bayesian or frequentist , that the sample is representative of the population ?"
250797,can you expand on this a bit ?
250811,how did you code the many categorical features ?
250826,"if $ j $ is already quadratic , why do you want to approximate it with a quadratic function ?"
250832,can you provide some more information here ?
250853,i'm confused about your explanatory variables . do you have very many missing observations of those variables ?
250854,"you said it yourself , * "" the probability of k successes is $ p ^ k $ "" * , what's different now ?"
234048,have you seen this language used for $ p 1 $ somewhere ?
22391,what are $ k $ and $ k_n $ ?
250984,so what exactly is your question ?
250881,could you provide a log of both the new parameters and the new loglikelihood after each step ( lets say for the first 10 steps ) ?
251025,""" it is written in a lecture material of a renowned professor "" - do you have any link ?"
251066,what about a qqplot or a relative distribution plot ?
251076,do either of these url and url help ?
251080,is there any substantive reason why they are missing ?
251077,"indeed , pr ( x = x ) = 0 but density of x in x f ( x ) may not be equal to 0 . shouldn't you use a label 'self-study' ?"
251089,"it depends on how you want to "" use "" the clt . do you know the parameters of your random variables or not ?"
251106,possible duplicate of [ how to plot roc curves in multiclass classification ?
202698,have you considered the ` teffects multivalued ` approach ?
251129,"do you have independent samples of $ a $ and $ d $ or one sample of their joint distribution $ ( a , d ) $ ?"
251160,you can't fit an arima model on r with s as a variable ?
250886,"exactly * how * is the scatter matrix "" used "" in the posterior wishart distribution ?"
251178,what about poisson regression ?
251140,can you post an example dataset that goes with the figure ?
250130,did you try logistic regression ?
250178,can you clarify what your data set represents ?
251274,what kind of models do you want to implement ?
251276,"be clear on why you would use yates' correction , e . g . , are you trying to make the test more conservative like fisher's exact test ?"
251296,your formula looks like it is backwards . shouldn't it be ` dep ~ pred ` ?
251336,"my question to you is "" how did you exactly form these 17 values "" ?"
251349,what is your question precisely ?
251369,your interpretation looks fine to me . there is no contradiction between the two statements so if you are still concerned perhaps edit in an expansion of your doubts ?
251347,what does it mean that $ delta x_i = 1 $ ?
251407,"are you saying that you have measurements of 7 variables ( responses to questions ) and you want to "" merge these 7 "" to form one index ?"
251426,what do your residuals ( studentized ) look like ?
251053,do you have a ` net ` object ?
251393,"you just want to know if they've increased , or if they've increased by some ratio ?"
251424,"please provide an example of your data and code so far . did you assign the marks to the point pattern as a factor , so it is a multitype point pattern ?"
251507,"is my reading of your question right : there are two groups of patients ( slow and fast responders ) , but you don't know a priori which is which . so , in statistical language , you could say that there is a latent variable ( unobserved ) describing patient's response -- in the simplest case a latent variable with two values ( slow and fast ) ?"
251367,which papers have you read ?
73065,cramrs v is for two nominals . what is bad about regression ?
251517,why do you want to compare models this way ?
249789,"could you provide more information , for instance , what is that variable with 43 levels ?"
251602,"what did you mean by "" known uncertainties "" ?"
249688,"carl , good point , i did not use the proper term there ( accuracy vs . precision ) . i wonder what adjective combine the two , meaning both accurate and precise ?"
56066,what makes you think that the test statistic being reported is necessarily a wald test ?
251608,are you trying to do prediction ?
251610,did you use your data to formulate the hypotheses and plan also to use it to test the hypotheses ?
251226,can you explain the code ?
251624,""" pooling the underlying data is not an option "" why ?"
251632,i find it hard to follow what you are doing . in constructing your model do you have a sample of patients ?
251641,could you say more about the type of classification algorithm you settled on and wish to illustrate in this way ?
251660,"( 1 ) please explain how one "" samples . . . intervals . "" what do those intervals * mean * and what model are you implicitly assuming about how "" sampling "" takes place ?"
251265,are amymed and amy the same variables ?
251755,do you mean subjective in the choice of markers or in extracting them from the primary article ?
251806,what does annotated dataset mean in the first place ?
251805,what is your likelihood function that you are going to use mle with ?
251832,"* * hint * * : avoid computing the hessian , if you can , and use the calculus of convex functions instead ! define $ mathbf z_i = y_i mathbf x_i $ and the corresponding matrix $ mathbf z = ( mathbf z_i ) $ . can you rewrite the first term as a quadratic function of the vector $ alpha $ and utilizing $ mathbf z $ appropriately ?"
251838,"it would be interesting to know what you mean by "" the result for the condition . "" to which condition would you be referring : "" c "" or "" e "" ?"
251845,olejnik_ can you pick a specific example from the table ?
251858,are they paired so that actress aged 22 was the same year as actor 44 ?
251947,perhaps i do not understand but will the hr not depend on the characteristics of which patients each doctor saw ?
207354,"it looks more like 33 months to me , wasn't it asked in april 2014 or am i misreading it ?"
251956,"when you cite someone , could you provide a full reference instead ?"
251523,"it's difficult to discern what you're trying to ask . what prevents you from generating the $ u_i $ using ` runif ` and taking their negative logarithms , exactly as defined in your opening statement ?"
251700,"is your question "" what is the definition of bias [ in statistics ] "" ?"
252004,does the same phenomenon occur with the usual glm ( ) logistic regresion ?
251831,"little bit surprised to hear all the "" what is amova ?"
251989,do you know the numerator and denominator og the ratio ?
252077,what exactly are you correlating here ?
185108,"what do you intend by "" nonparametric distribution "" in your title ?"
252112,what does it mean to predict total using one of its parts as a predictor ?
252128,"by the way , your wikipedia link goes to "" proof 3 "" . if you instead go to "" proof 2 "" , then the equation $ mathrm { var } ( bar { x } ) = sigma ^ 2 / n $ is * immediately followed * by the sentence : "" this is a property of the variance of uncorrelated variables , arising from the [ bienaym formula ] ( url ) . "" did you check that link ?"
252141,what exactly would you want it to mean ?
252161,what is ` tree2 ` ?
252162,is this a question from a course or textbook ?
252182,"davies-bouldin can be computed both from case-by-variables data as well as from distance matrix . the other two require distance matrix . you say you have dataset and not distance matrix and your cluster analysis processes data , not distances . well , many clustering algorithms are still _implicitly_ based on some distance dispite they don't process them ( [ see e . g . ] ( url ) ) . can clusterone be such one and the distance implied could be deduced and computed ?"
185505,can you be more specific ?
252248,is this a homework question ?
252147,the question is confusing . first you say you want to predict y given x and point out correctly that for squared error loss it is the best predictor . but then you pick var [ y x ] . are you still trying to predict y ?
252296,what is the significance level ?
19000,can you tell us what the textbook is ?
252215,"it seems to me that trying to estimate $ kl ( p , q ) $ when p is unknown is overall pretty useless : are you sure that this is really a quantity you want to estimate ?"
251914,where is xi'an comment ?
231086,"i don't understand what you are proposing with "" divide each observation into multiple observation "" . could you elaborate ?"
246442,"in your example , item $ a $ only appears once ?"
252424,can you tell us a bit more about the datasets in question and the purpose for sampling ?
252427,"have you tried with another classifier , like naive bayes ?"
252420,"whether it's a simplification or not , it could change the answers ( although probably not too much ) . it could also help you to clarify some of the concepts . for instance , what does "" simultaneously "" mean ?"
252470,what is the relationship between the points and the circles ?
252466,when i look at the post it looks like the borders cut off so that some words are missing . nevertheless it looks like it describes minimal sufficiency of the sample mean and variance and then mentions that the normalized residuals are ancillary statistics meaning that they provide no information about about mu and sigma . knowing that what is your question ?
252482,more fundamentally what does survival mean here ?
252480,how do the object ranks relate to the matrices ?
252495,did you mean 1 coh pop ?
252498,"p-value depends sample size , i guess you have pretty big sample , isn't it ?"
208742,are the zeros real zeros ?
251980,what is the question for # 3 ?
252541,do you want to force the clusters to be spatially contiguous ?
252517,what classification algorithm are you using ?
252560,can you split on the discrete variable ?
249727,do you mean that you would like to generate data from an hmm ?
252600,i've added ` self study ` tag . did you try to a small real data snippet ?
252613,are b and y correlated ?
252325,several comments : 1 . ) could you write out your regression equation so that those of us who are not r users can understand what it is you are trying to fit ?
252548,"what do you mean by "" each time "" ?"
252645,can you show what your tables look like ?
252610,i assume that you realize that what you're trying to do is impossible . this must be a class project ?
252691,the formula in your question appears to be wrong -- that is not a chi-square statistic . can you give a source for the formula ?
249860,"what do you mean by "" the actual structure is changing "" ?"
252687,"demographer , what are the table headers for the 2nd table ?"
252363,what's your goal for performing this comparison ?
252730,"lm . fit doesn't actually do the fitting . it checks arguments and sets information up before calling a c function to do the actual qr decomposition at the line : ` z - . call ( c_cdqrls , x , y , tol , false ) ` . . . and then the rest of lm . fit is converting the output to suitable form etc . the c function "" dqrls "" will presumably be a conversion to c of the old fortran routine dqrls ( which itself is calling linpack functions to do the work of finding the qr decomposition ) . are you asking "" how does qr decomposition work ?"
252744,""" i need to give more importance to instances according to another variable . "" what does that mean ?"
252710,could you provide some data-example that is similar to your data ?
252763,"i wonder what you mean by "" logical negation . "" a false negative , fully spelled out , is a condition where * the null hypothesis is true * * * and * * * the null is not rejected . * according to the propositional calculus , then , its negation is * the null hypothesis is false * * * or * * * the null is rejected . * how do you conclude $ 1- alpha = beta $ from that ?"
252761,could you include some output from the margins command ?
252772,"it's not clear from your description that you have information about the sampling rate , e . g . do you know that you have x % of the observations ( either of days , or people , or products ) ?"
252692,"to which of these variables does "" $ x $ "" refer to in the expression "" $ f ( x y ) $ "" ?"
252391,could you tell us more about your data ?
252781,could you provide an example ?
252792,what is the purpose of your pilot study ?
17407,"( 1 ) i'm wondering if this question has a "" right "" answer , though . should it be cw ?"
252794,"tim another interpretation is that there may be dependencies among the characters in each "" sentence "" that would limit the total number of unique values the machine will produce , so how might one go about searching for such dependencies ?"
252808,can i assume that by size you mean sample size ?
252817,"a growth rate implies a growth of something ( outcome ) along time . the did parameter is obtained from subtracting the a outcome from the c outcome ( result 1 ) , subtracting de b outcome from the d outcome ( result 2 ) , and then , subtracting result 2 from result 1 . therefore , the unit of measurement needs to be the same for treatment and control ( so to compare apples with apples , and not apples with oranges ) . why do you think it wouldn't work if the outcome value for the series is not close to each other ?"
252842,* some say not * - could you cite any source ?
26804,why does it matter ?
252878,do you have the numerator and denominator of the proportion ?
252879,"it looks like you only have one model , and are predicting using that . the bagging , in the sense of an rf is about an ensemble of weak learners . how are you training your swarm of smaller models ?"
252892,"the wilcoxon rank-sum test is non-parametric , meaning ( among other things ) that normality in your data is not important with regard to the test . is there a specific reason that you want to examine normality here ?"
252721,heteroskedasticity looks obvious from the plot . is the qq plot done without transformation ?
252867,to compare variances you divide one by the other and then use f . i do not see where you did that . which one you divide by which and which value of f you use depends on whether you have a directional hypothesis . does that help at all ?
252884,how can a single patient be in both a treatment and a control group ?
251926,how did you arrive at your statement that $ sigma ^ 2 = 3 . 882 $ ?
252913,"welcome to the site . please edit your post to tell us more about the dataset that you have as a benchmark and the data set or source for the two parameters you are trying to test . also , the test you use really depends on what kind of variables temperature and power are . are they continuous ?"
252922,"why is $ u_i sim text { u } ( 0 , 1 ) $ ?"
197351,"sorry , can you explain what you mean by dependent and independent here ?"
252620,"for 2 & 3 , what if $ x_i = x_j $ but $ y_i neq y_j $ ?"
252960,"i am not familiar with your notation , but in your second equation , shouldn't the first "" $ = $ "" be a "" $ - $ "" ?"
252951,are you looking for a particular predefined pattern ( like the one you mentioned in the original post ) or for whatever pattern may be mined from the data ?
252958,"chen , can you explain your underlying model model more clearly ?"
252864,"how is $ ( x , y ) $ in your second picture considered as being _inside_ the unit circle ?"
253028,where does this come from ?
252963,"i don't understand the question . what's "" fully corrected t-score ?"
232302,"i think you should start with decision trees , since they are relatively easy to implement ( see e . g . ` rpart ` package in ` r ` ) . and extensions such as random forests . another option : since you clearly have different states , maybe something with markov chains can be useful ?"
253054,is the probability to lie different for each expert ?
253067,does column index correspond to the table ?
253062,wait a minute ! what other sex is there that you can sample ?
253029,how do you obtain the right side of the last formula without the $ k $ ?
253058,"why not just give people a list & ask them to rank the colors . also , are you assuming that everyone will have the same preferential ordering ?"
253082,"i suspect the answer doesn't have anything to do w / whether or not you're using spss . i don't really follow this , though . what do you mean by "" natural group "" ?"
253095,i suppose the real question is : how can you sample if you don't know the distribution ?
251497,can you tell us a bit more about the data-generating process ?
253122,"what do you mean when you say "" the correlation works "" ?"
253135,you need to explain a bit more what you actually hope to achieve with this analysis . it sounds like you're trying to do variable selection . why ?
253183,aside from your r code it would help if you provide background on your question . why do you think a chi square test is appropriate ?
250284,"it seems to me that in order to get $ alpha ^ k cdot alpha ^ k = 1 $ ( normalization ) , you need to divide by $ lambda $ . this is simply algebra as per eqn 9 . or are you asking to clarify what's happening in eqn 9 ?"
252832,so x is the real part and y is the imaginary part of the complex normal ?
253157,i think there is missing information here . are the 36484846 discharges from 1 hospital or a combination of both ?
253123,what do you mean when you say that the polynomials at a point are uncorrelated ?
253291,that's ok . sometimes stuff is hard to find . what do you want to diagnose about the model ?
253234,"how would you define the bias for $ b_i $ : in terms of its limitation to $ [ l_i , u_i ] $ , or in terms of possible values of $ b_i $ over all real numbers ?"
253308,1 . how are $ a $ and $ d $ related ?
253326,have you ever heard of cochran's theorem ?
253335,"coins either come up heads or tails , but it can still be the case that p ( heads ) = 0 . 5 . how is that ?"
185507,"in addition to excellent points already made : if this is such a good idea , why isn't it in courses and texts ?"
253470,"why would it be valid even to average * euclidean * distances , given that they are not additive quantities ?"
253344,"100 dimensions would already count as very high dimensional ( compared to the 2 , 3 or perhaps 4 dimensional real world applications that euclidean distances are originally used for ) . don't expect much change between 100 and 1000 . distances are different , ok but by how much ?"
253456,"what is the definition of $ b $ in _ "" b ) is $ x_t = ( 1 b ) y_t $ stationary ?"
253490,you write example data and that both are factors . ( 1 ) proportion is a factor ?
253568,"i'm sorry , but why is this not a function of $ ( x_ { ( 1 ) } , x_ { ( n ) } ) $ ?"
253551,did you check this site for possible duplicate questions ?
253333,what does $ phi $ look like ?
253590,the allegedly nonsensical part or the question can be split in two questions : does $ frac { overline { x } - mu } { s / sqrt { n } } $ converge to normal ?
253621,what is your data ?
252174,what is your sample size constraint ?
253629,"is there one answer that is correct , and one that is not correct ?"
253690,"so if i summarize , you work with vectors of proportions ( or histograms ) and you would like to represent them through a model ?"
253033,"i believe the answer to this question requires a clearer explanation of what exactly the "" $ dy $ "" values represent . ( i suspect their squares might be proportional to the diagonal elements of $ m $ , but there's not enough information here to be sure . ) could you tell us about the $ dy $ ?"
253700,"you have bayes net with variables x1 , . . . , xn right ?"
253704,those sample sizes are really small to test normality . since the means appear to be different i would think you are applying k-s test separately . if so why aren't there results from three tests ?
253478,is this a question you're answering for some subject ?
253723,"the loss you report is on one batch , one epoch or a moving average over the epoch ?"
253720,"as michaelchernick says , there's no objective answer without defining "" safer "" . if you're twice as likely to die in a car every time you get in one in japan than the us , but you have to get in a car four times as often , which one is safer ?"
253728,"please explain what you were doing when you were "" trying to run a t-test . "" for instance , were you pairing these data or not ?"
253732,""" generally accepted "" has little meaning , because there are infinitely many possible formulas and the one you choose ought to be appropriate for your analytical objectives . could you explain * why * you want to weight the data and what the weighting needs to accomplish ?"
253744,"since transformations are straightforward and powerful methods , could you explain why you prefer not to apply a transformation ?"
157255,do you know which of the ten types of coins each trial belongs to ?
253778,what's lead ?
253514,harisf : why not explain what your case is ?
253833,careful with the indices . what is the index run in the objective function to be minimized ?
253885,i think there have been some similar posts before . have you tried searching for them here on cross validated ?
253886,i meant to say that in general integrating a normal distribution over a range of values does not yield a closed form expression . so i don't think it is possible unless your definition of closed form is different from mine . do you consider an infinite eries a closed form ?
253707,i guess by svm you mean signal vector magnitude ?
253231,is there anything changing across their 10 trials ?
253916,"i wish there were more information available . could you use the "" qqplot "" from the 'car' package in 'r' ?"
253820,"i am confused by your problem formulation . the point estimates are different , period . hwowever , the estimators are consistent , so they converge in ever larger samples . now what meaning does your hypothesis test have ?"
253926,"this is a confusing post , because the images don't have any evident connection to what you seem to be asking and you don't really describe how you "" create a scatter plot of the distances . "" could you elaborate on what you are attempting to accomplish ?"
254020,"it's so easy to construct counterexamples ( that is , pseudorandom number generators that are * perfectly * uncorrelated ) that i suspect you might be using "" correlated "" in a more colloquial sense than is usual in statistics . could you clarify what you mean by "" correlated "" ?"
254018,"could you direct us to any place where this is "" written "" ?"
254037,possible duplicate of [ under what conditions should likert scales be used as ordinal or interval data ?
253832,if you are not sure then why carry on without further checking ?
254076,"the title might be clearer if you just said [ dot product ] ( url ) . also , you need to specify the * joint * pdf of $ x $ and $ y $ , e . g . are they independent ?"
134507,can you explain what kind of data you have a bit more ?
252702,what do you mean by outer product ?
252642,did you found anything ?
254101,"* however , if i add sigma to it , it comes very close . * what comes very close ?"
254152,by your comment on fisher's exact test are you referring to the 'norm' of limiting it to 2x2 tables ?
254051,can you please add what you are goal is ?
254207,"please spell out your acronyms . what do you mean by "" gmm "" , * gaussian mixture model * , * generalized method of moments * , something else ?"
254217,"what specifically are you having trouble with , including quarterly data with daily data ?"
254220,"i would agree with g5w , but want to interpret it as probability . is that correct for your application . eg is there only positive and negative ( or are there also eg don't knows ?"
253990,"with these conditions you must have n = m . i think you want g = { a_ ( 1 ) , a_ ( 2 ) -a_ ( 1 ) , . . . , a_ ( n ) -a_ ( n-1 ) } . does randomly select mean selecting each number with probability 1 / m on the first draw ?"
254284,"ljung-box tests for autocorrelation , not for stationarity / nonstationarity . also , what do you mean by * a model seems insignificant * ?"
254295,maybe you should ask yourself why you are removing influential in the first place . by removing the influential observation what problem are you trying to solve ?
254229,"there is a near-universal notation for sequences ; namely , regular expressions . your question appears to employ some kind of idiosyncratic variant of that , so it will be important to explain what it means . ( i would guess that , say , "" ( b , c , d ) "" refers to a single symbol in the set $ { b , c , d } $ , written $ [ bcd ] $ as a regular expression , but that's only a guess . ) the "" additional information "" is mysterious : what does timing information have to do with an abstract question about sequences ?"
254227,have you taken a look at the c code that r uses to compute the acf ?
254355,"perhaps you want to re-think and re-phrase your question , since the sentence "" supposingly . . . "" does not hold , as it stands . perhaps you meant "" supposingly , f m "" ?"
254373,"could you explain what you mean by "" left multiplying with $ a ^ { -1 } $ "" , given that $ a $ is non-square and therefore has no inverse ?"
254286,does the [ wikipedia article on design effect ] ( url ) help you ?
254456,i think your diagnosis is correct . why not just ignore all the comparisons with 0 if they make no sense ?
254314,"cagdas ozgenc : in many cases ( such as logistic regression ) mle is still consistent for the "" least false "" parameters . do you have a reference for your claim about inconsistency in the nonconvex case ?"
254441,i'm not sure what you want to do . what do you want to correlate ?
254468,can you make it more precise what do you mean by powerlaw distribution ?
254431,can you show us some sample data ?
130310,what do the numbers mean ?
254555,presumably you are using the sandwich and lmtest packages . you can type ?
254562,how many level of breeds are there ?
254606,are the 2 sets paired ?
254632,"do the 3 files represent replicate determinations of the same genes on the same patients , or is the relation among the files more complicated ?"
254641,can you confirm every importance ended being the same ?
254651,why are deciles relevant to graphing the data ?
254689,"add the error term to the log-model and include it in your back-transformation . you'll see that with the log-transformation you have made an assumption regarding your errors and as a consequence you've placed less weight on larger values . if that's not what you want to do , you might need to make different assumptions . possibly a glm would be preferable ?"
254709,"1 ) what is the "" classic framework "" ?"
254734,it seems like you are using the ` lme ( ) ` function from the ` nlme ` package and not ` lmer ( ) ` as you indicated . furthermore your random term specifies ` site ` and ` plot ` which are not present in your example data . also it seems based on the data you provided you only have one tree per treatment and block ?
254761,recurrence ( as you probably know ) means you return to the state infinitely often while transient means that at some point you will never return to that particular state . the summation result must have something to do with these definitions . does the notation for p_jj mean the probability of return to j within n steps ?
254791,"if it's an academic article , why you can't you cite it and why do you need to mangle its data ?"
254803,"it doesn't matter what software you are using , the result will be not estimable . the question then is why does revman think your mean and sd are zero ?"
254806,"since power is a concept of * sample design * , rather than an analysis of data , could you please explain what you mean by "" achieved power "" ?"
189136,you have to teach said course ?
254807,after looking up the mind reading machine i am learning a lot of interesting stuff about what shannon accomplished constructing playing games even as complicated as chess ?
254648,"you'll probably be able to do better if you have some domain knowledge about the nature of the sensor and the random process . i presume that there's a time series of true readings $ x_t $ ( not observed ) and a time series of measurements $ y_t $ ( observed from the sensor ) , with some relationship between $ x_t $ and $ y_t $ , and you want to infer $ x_t $ given $ y_t $ . what can you tell us about the relationship between $ x_t $ and $ y_t $ ?"
254778,"because "" looking at "" is a vague statement of your objectives , could you elaborate on what you're trying to accomplish ?"
254720,are your gifs realistic ?
254937,"welcome to cross validated ! you'd be better off dropping the first paragraph , in which apologies & excuses for a lengthy question lengthen it still more . clarifications you might edit the q . to provide include : ( 1 ) what's a measurement & what's an index ?"
254907,"you have an unnecessary ` vector [ n ] flashes_ ` introduced in the model block , unused in the sence that there are no probability statements related to it . thus , each component of that vector has an improper $ u ( - infty , infty ) $ posterior . does the issue persist after removing this ?"
254882,your question is not clear . mean and variance of which variables ?
254931,your question nevertheless seems to not be specific enough to get a reasonable answer . there are very many forms of cross-validation . what version do you have in mind ?
255036,"could you please learn mathjax and replace the scanned formulas with typed formulas , that is , with $ latex $ ?"
254996,see ` ?
255077,it is unclear what you're asking . what is the objective in this setting and what specifically is your question ?
255107,"what do you mean by "" assume all normal distributions "" ?"
254999,"such as a piecewise-smooth but everywhere continuous fit , say , which would somewhat akin to a piecewise linear model ?"
255114,usually people add a jitter . what do you want to convey ?
255136,i am unsure about your experimental design . is the following correct ?
255165,how do you compute the total cross-entropy per-epoch ?
255174,"can you post your data , or a sample of them ?"
255190,is it correct that your first ` seach . model ` and your second ` search . model ` are the same ?
255205,"i am not very familiar with this , and my feeling is there is no precise definition . however , wouldn't a "" black swan "" be an * * event * * rather than a * variable * ?"
251345,can you write out the equations for the models you fitted so that those of us who are not spss users don't have to trudge through the code to see what you fitted ?
255307,can you clarify what you mean by an interval for the generated numbers ?
255338,"welcome to cv ! to summarize what you are saying : you want to select students based on their improvements in grade , controlling for the class that they are in . i . e . you want to select student that are better than their class mates . is that correct ?"
175374,"fixed parameters don't have a covariance ( unless this is a bayesian formulation , i guess ) . are you talking about covariance of parameter * estimates * , $ text { cov } ( hat { theta } _i , hat { theta } _j ) $ ?"
255355,why do you think there is necessarily something wrong with what you have ?
254599,"for these data , what you are doing with your "" density plot "" and "" histogram "" is meaningless . it's hard to tell even how you constructed them . what are you trying to do with these data ?"
255346,"i would think "" smooth measure "" implies something about the scales of spatial variability , which your plot would not show . are there sharper changes / gradients in $ sigma $ between neighbors when using $ k $ ?"
255373,"is this homework , or are you a practitioner ?"
255392,might i suggest [ consulting an atlas ?
255223,"my guess is that it is based on the [ simulated annealing ] ( url ) metaphor , and considering the probability distribution to be the "" objective function "" ?"
255378,"discussion of outliers is always imprecise because we can give different definitions for the same data depending on your intent . this is especially true for multivariate outliers . recognizing that outliers are designated points that look extreme or unusual but are not necessarily erroneous is also the right approach . nevertheless i have some questions about the data . i take it that ind3 is the student grade but what is ind2 and what do the symbols r , s , p , and q mean . also what does the numeric dependent variable stand for ?"
255437,"i'm not quite sure i understand what you mean . are you trying to find out you would say "" ss ( a a * b ) "" in english words for example ?"
255458,i'm currently working on a dataset which is pretty similar to yours . first of all : what kind of products are you trying to model ?
255467,by z-score do you mean that you want to remove the mean and then scale by the standard deviation for each of the three scales separately ?
255499,"i see explicit solutions in the first thread you reference , so could you please elaborate on what you might be looking for in addition to them ?"
255376,"the conditional law does not have a density , because $ pr ( x = u u = u ) = 1 / 2 $ . did you take that into account ?"
255514,kaya can you clarify what you mean by the sentence starting 'i probably made the mistake . . . ' ?
255537,is this question hypothetical or are you experiencing this in real data ?
255549,"they cannot , because you have changed the distances--unless perhaps you mean something unusual by "" distance "" ?"
255525,"can you rewrite this so that it's a single , self-contained narrative ?"
255568,how many hypotheses are you testing ?
255569,"in what sense your last model is a "" fixed effect "" model that the first two are not ?"
254479,can you add some more about what you have tried so far ?
255561,the graph does not appear to be what you describe . what do the two axes represent ?
255576,i'm not sure i see how they were generated makes any difference to their interpretation . can you say more ?
255715,"we're going to need more information about your situation . you've added the ` [ time-series ] ` tag , but i can't tell if you really have time series data . you say you have "" times that events happen "" , are you talking about something like the hour of the day when a purchase is made on a website , or the length of time between an initial event & a follow-up event ?"
255743,whuber are you suggesting that the link you give us a duplicate or are you suggesting that a chi square test is an appropriate analysis . ?
255749,"your formulation following "" in other words "" is the classic formulation of a regression problem . regression , then , would seem to be the tool of choice . but in this formulation all references to a "" category "" seem to have disappeared , so what is the connection to the rest of your post ?"
255775,you also implemented your idea . what was the residual plot here ?
255735,what are t1a / b in your model ?
255823,"what do you mean by "" for a particular $ w $ "" ?"
255822,"let's say you've trained a regression model . it has a positive coefficient for salary = higher the salary ( absolute capability ) , higher the chances of paying-up . now is that really the case ?"
255857,does y have an error term also ?
255877,"the likelihood is not a probability in the mathematical sense of the term . it is the value of the probability distribution function at the point x , given the probability function parameters . does it answer your question ?"
255909,why take the square ?
255755,"could you please explain what you mean by "" data robustness "" ?"
255751,"given that variable "" importance "" is such a hand-waivey measure , why are you so concerned with getting a very precise measurement of it ?"
255962,are there known causes of breast cancer that you have no data for ?
255969,kindly clarify - is c the dependent variable or x ?
255998,"are you only interested in the paper and code you cite , or would you be interested in other techniques for multi-output gaussian process regression ?"
255462,"the transition function that is typically learned is from states to states . based on what other information could you "" segment "" the environment ?"
256025,it all depends on what you are trying to accomplish . are you building a prediction model to be used as decision tool for new observations ?
256061,i would suspect something with the actual 2016 data that you added . is that missing ?
256065,see [ are ecologists the only ones who didn't know that the arcsine is asinine ?
256082,"the difference in $ r ^ 2 $ is rather alarming . what do you mean about "" using the same random state "" ?"
256115,why one million full-time workers ?
256125,"it sounds like you have no information about what the correct options are , so how could you hope to succeed in answering either of these questions ?"
256138,"why do you start your question from "" -2 down vote favorite "" ?"
255889,welcome to cross validated ! the histograms suggest you're able to identify observations from several different populations - is that in fact the case ?
256251,can you provide some context for this ?
256273,schemes like [ these ] ( url ) can help a bit to understand consequences of unbalanced designs . i surmise your case is unbalanced disproportional ?
256280,how about features for the hours of the day ?
87966,are you aware of the [ academia ] ( url ) site ?
256291,"let the categories be $ x_c in { 1 , 2 , 3 } $ then you could define $ x_1 = 1 $ if $ x_c = 1 $ and $ x_1 = 0 $ otherwise , $ x_2 = 1 $ if $ x_c = 2 $ and $ x_2 = 0 $ otherwise . then use $ y = beta_0 beta_1 x beta_2 x_1 beta_3 x_2 $ . would that be an option ?"
256365,are the squares free rotationally ?
256404,when you say you would use multinomial--would the outcome be an 8 category variable comprised of the $ 2 ^ 3 $ possible combinations of the three binary variables ?
256412,why are you integrating over $ theta $ ?
256418,i suppose you would like to show it because it is a homework or take-home test problem ?
256450,doesn't this follow from central limit theorem ?
256432,could you provide more context to your question ?
256470,"do you understand what the part where you typed "" link = log "" means ?"
256471,"what are you trying to do , is this scientific work ?"
256482,this question seems to be too broad . it also is confusing . please make it clear what source ( s ) you are referring to ?
256440,"exactly what "" intuitive idea "" are you asking about ?"
256629,"note that no-one worries too much about the limiting case of this problem , which is an indicator variable as predictor . otherwise , why throw away information ?"
256453,is this a question from a textbook / exercise ?
256714,why would dropping a number into negatives be a cheat ?
256680,not sure how you got your model to work . . . the code seems to mix ` lme ( ) ` and ` lmer ( ) ` syntax . which package were you using ?
256720,just a suggestion to add some information to your question : to what level of nesting do the candidate variables apply ?
256620,"i think this is often done for event-driven clinical trials , i . e . all patients are asked to come in for final visits during , say , may and june ( after each having been followed by a variable duration of follow-up ) . typically , then any data after the final visit for a patient in this time period is considered right-censored at least for the primary analysis of the trial . this is partially for operational reasons and partially because often the trial intervention will be stopped at the final visit and you do not want to mix up the questions "" does it work ?"
256728,"the calculation for the mean of residuals looks fine , assuming that nothing odd happened while fitting the model . do you have reason to believe the mean residual is * inaccurate * , as opposed to just being inconvenient ?"
255547,could you indicate what bounds you are using on your integral ?
256810,is the problem you're working on the generic prediction of any arbitrary data type ?
256797,to detect changes you don't need clustering at all . why the idea of clusters haunts you ?
256824,"i would imagine in r you could say data rnorm ( 1 ) and get a very correlated second sample . but depends on the correlation structure you want . anyways , is this a homework problem ?"
256839,"what is "" an exact point measurement "" ?"
256745,"you are looking for a nonlinear mixed effects model . you need to account for the fact that same chick was measured in time which is why the values are correlated . you can start [ here ] ( url ) . to get a list of models , check out ` ?"
256918,the edf are a function of the traces ( sum of diagonal elements ) of the smoothing matrices for each smooth . from ` ?
256928,"what could "" slope "" possibly mean without an assumption of a linear relationship in the first place ?"
256650,"the question , as currently , is unclear / broad . clustering results are simply a vector of cluster memberships ( labels ) . what , beyond that , do you want to "" present "" ?"
256975,could you provide a specific example of an hypothesis you propose to test with respect to province versus city within the province ?
257009,neat idea . are you using a softmax for the cost function ?
257022,"what is the architecture of your network ( how many hidden layers , how many nodes in your hidden layers ) ?"
257027,how many data points are in each dataset ?
257030,what else would you call something that estimates the parameters of the model ?
257047,"one can never actually measure an entire distribution--that's physically impossible . how , then , do you obtain these means and sds ?"
257034,"there is a very interesting post that could be a partial duplicate to your question . it is "" kendall tau or spearman's rho ?"
257086,"if i understand you correctly you * assume * that human cognition can be described using bayes theorem , so bayes theorem could be used to "" reverse "" their thinking process . . ?"
257094,could you add the overall research question or aim of your study ?
257166,how much ram do you have on your machine ?
257167,"it is not clear what is the problem in here . are you comparing to the * true * known sd ( e . g . because you simulated this data ) , or to empirical sd ?"
257174,"i cannot match that distribution to your function unless i ( a ) change $ alpha $ to approximately $ 2 . 3 $ and ( b ) divide it by approximately $ 47 $ . you seem only to be attempting to approximate a function of $ varepsilon $ by a formula of the form $ c varepsilon ^ { alpha-1 } ( 1- varepsilon ) ^ { beta-1 } $ --but what does that have to do with "" distributions , "" "" mechanisms , "" or anything else statistical ?"
254567,"when you mention the restriction $ x_t 0 $ for all $ t's $ does that mean that the normal is truncated , which makes $ x_t $ and $ epsilon_t $ dependent ?"
257210,is this a question from a textbook / assignment / exam ?
256707,have you verified that these traits are indeed independent ?
257320,"was the higher frequency of mut4 a pre-defined hypothesis that you were testing , or was the higher frequency only suggested by the experimental results themselves ?"
257317,"if one wins 53 % of the time , the other should be 47 % , so shouldn't the description read "" the first player wins 6 % more than the second player , "" or "" 3 % more than half the time "" ?"
257346,"i don't see the figure in the paper , can you please add the source ?"
257352,are the very high users isolated ?
257362,"this looks very blurred question in its some phrases and formulations . what is "" randomness "" here , what is "" batch effect "" ?"
257314,what kind of regression method did he use ?
257312,"also , how accurate were the original predictors ?"
257406,bad numerical methods in excel ?
130723,but what do people usually use nhst to reject ?
257440,"every statistics package ( sas , spss , r for sure ) will do this for you , usually offering several options of how to do it . why do you want to do it by hand ?"
257442,i'm interested to see any answers . would i be on track if i guessed that your dissertation advisor directed you to use sem in spite of what you know about your data that makes sem seem inapplicable ?
257468,do you mean spearman rank correlation ( as in the tag ) or pearson correlation ( as in the question ) ?
257469,what does it mean for you for age to be independent of survival status ?
257537,"g5w , why not turn that into an answer ?"
257539,what null hypothesis ?
257511,have you looked at don rubin's multiple imputation text it deals with surveys ?
257548,"is each "" population "" a mother ?"
257572,"the definition of a graphical model is : "" a probabilistic model for which a graph expresses the conditional dependence structure between random variables . "" as we can draw a dependency graph to represent a nn , it falls in this category of "" graphical models "" . where does your misunderstanding stems from ?"
257563,do you know anything about why the data might be missing ?
257590,"what did you mean by ma ( 1 , 1 ) in the title of your question ?"
257604,"what is "" x "" and what exactly do you mean by "" p ( y ) "" ?"
257633,i'm not sure it's very clear what you're trying to do here . are you trying to resample your columns ?
257637,"i'm not sure i'm following you . why do you want to "" ensure the next draw is not the previous sample "" ?"
257677,"i'm a bit puzzled by your dependent variables , if it is a sum of prices divided by an average price , is that not some continuous numerical response rather than a yes / no ( or some integer out of a larger integer total ) ?"
257661,"can you please clarify what npa is , in this context ?"
252695,we need more information . what orders of arima were used ?
257685,what are you trying to compare ?
257740,"do you mean "" less than 3 "" or "" greater than 3 "" ( which is what "" 3 "" means ) ?"
257762,"can you provide a link to the full article ( e . g . google drive , box , dropbox ) ?"
257768,""" students "" will implicitly be treated as a random effect since the variance of the residuals will be a function of student differences . the harder question is whether you want to treat "" tests "" as a random effect . that is , do you want to generalize your results to tests other than the 9 used in the study ?"
257786,what is your goal ?
257804,"the hardest part is defining the event . do you want to find the probability that any 1 , 2 , or 3 consecutive outcomes are as extremely different from others as this or just two consecutive outcomes ?"
257805,what would make an appropriate pairing ?
257777,"stationarity conditions do not exclude categorical variables , now do they ?"
257597,could you clarify some of the elements of your design / measurement ?
257750,one question to ask in such analysis is . . . are targets correlated ?
257866,"i tried your script , but it says ` ss ` not found . can you fix it ?"
257868,"you could plot each matrix as an image using imshow ( ) such as explained in this answer url yet i wonder , how do you identify late comers ?"
257784,uh ?
257922,i don't understand the issue . since for most metrics the diagonals are predetermined--they provide no information whatsoever--why are you even including them in your calculation ?
48162,can you be more specific about what steps are confusing you ?
257912,"from what you've put here , it's hard to say . can you post the plot ?"
257951,"what might you be hoping for besides a simple "" yes "" ?"
257236,it is hard for us to comment without more information . could you please post the code that made your plot along with some data so that we can recreate your display ?
257974,how was this plot created ?
257977,you haven't said what your link function is . do you want the relationship on the scale of the linear predictot or on the scale of the response ?
257818,statistical independence in this case depends on how you sample your points $ x_i $ ( with replacement ?
257228,can you include pngs of the two fitted functions ?
257815,i don't quite understand your concern . k = 10 is reasonable . k = n ( where usually n 100 ) is reasonable . so why would k = 100 be unreasonable ?
258030,is this ` scaled = ( data - mean ( data ) ) . / std ( data ) ; ` a matlab command or rather a pseudo-code ?
258025,"okay , i see now . if you use k = 40 then the remaining eigenvalues do not matter , that was my confusion . previous plot was probably more appropriate . i don't know what goes on , looks like something might be wrong in the ` transform ( ) ` function . do large values in ` norm1 ` agree ?"
257895,excluded from what ?
258085,is bearish / bullish a binary condition ( where you're only ever one or the other ) ?
258027,did you look for outliers ?
258120,you might also edit your post to tell us why you want to this . what scientific question is it trying to answer ?
258046,"are you looking for an analytic bound on $ f $ , an algorithm to approximate it for particular inputs , or what ?"
258113,how is a time series deterministic ?
258215,"close , but is $ x = -1 , y = -1 $ possible ?"
258254,fdi = foreign direct investment ?
258280,what is it that troubles you about comparing the observed proportion to the population proportion ?
258286,this is not clear to me . are you trying to compare each individual observation to the known sample ?
258301,what exactly is unclear for you ?
257917,1 . your raw numbers in your link don't indicate how the data are organized ( which numbers go with which method ?
258327,in what context ?
258387,"do you want to simulate , or do you want to use something like the delta method ?"
258393,i still don't see how you are asking that in the text of your question . could you please edit it to make it clearer what you are asking ?
258213,how is this distinct from your earlier question [ independence of points from same underlying function ] ( url ) ?
258409,what does your sample data consist of ?
24799,can you describe in more detail what you're doing for the cross-validation method ?
258246,"is there any reason , why there are no absolute cell counts instead of just percentages ?"
258460,"ignoring the pairing will not invalidate the statistical test , it will just reduce the power of the test . are you concerned about finding the most powerful test ?"
258485,"i do not understand your question , because your code accomplishes exactly what you seem to be asking for in its title : it simulates a linear regression with heteroscedastic errors . are you asking for methods to estimate some kind of model for the heteroscedasticity ?"
258495,persumably that is just a small part of your data-set ?
258541,"the answer usually is "" nothing , "" unless the $ a_j $ are very special . your expression is a sum of independent lognormal distributions . if any of the $ a_i $ is even of modest size and positive , then even for very large $ n $ that distribution won't be approximated well by any gaussian . rather than constraining or simplifying your question so severely that only bad answers are possible , why not tell us what the underlying problem is that has motivated your post ?"
258578,why are you assuming that both $ n $ and $ m $ have the same value $ j $ ?
258506,i think we need to see more code to diagnose the problem . can we see the code that gerarated model and model1 ?
258630,"may be more appropriate at url . is there any relation ( commonality ) between the 500 , 000 instances ?"
258642,what do you mean by the misclassifiction cost's error vs rate ?
258671,"doesn't your third routine already give you the binary "" valid "" , "" not valid "" output ?"
258674,"you cannot say anything in general if your understanding of "" nonlinear "" is the conventional one ( meaning that it cannot be expressed as $ y = alpha beta x $ for constants $ alpha $ and $ beta $ ) : $ y $ could be not skewed or skewed in either direction . do you really mean that "" nonlinear "" is * solely * the logarithm or the third power ?"
258652,could you elaborate on what the difficulty is in computing the tangent of ` x ` ?
258733,well the $ phi $ in the link is defined in the same way as you define it and the thread shows that both approaches are equivalent ( which is exactly what is the idea behind the reproducing kernel hilbert spaces ) ?
258773,should this have the 'self study' tag ?
258841,"could you tell us where this term "" diversity "" appears and what its definition might be ?"
258866,it looks like you will be testing 90 effects . can you consider some primary and others secondary ?
258821,is utocorrelation coefficient a typo ?
258808,"which is correct : i should eat an apple , or i should eat an orange ?"
258930,"what does "" reflect the population "" mean for you in your context ?"
249040,are you trying to address the problem of having ( too ) many moderator variables ?
258946,why do you want to calculate a correlation measure ?
258979,what is your unit of analysis ?
258944,"this question isn't entirely clear to me , but i think this is based in a confusion about what happens in a pca when p n & why . it may help to read my answer here : [ why are there only n 1 principal components for n data points if the number of dimensions is larger or equal than n ?"
258550,i'm not sure i understand . are there 50 students in total being judged on two tasks or are there 50 students in two different groups doing different tasks ?
171819,are the scores yes / no or continuous values ?
259076,"no , it was only a suggestion since i think it's difficult to asses the predictive value of a model by splitting in too low group set . maybe i don't fully understand your original problem ?"
259064,why did you group the data from your 5 point scale into 3 categories ?
259111,what do you mean by uncorrelated events ?
258045,your question is difficult to answer without more context . what is it you'd like to achieve ?
259142,i tried to modify the formulas in order to improve readability . can you please check that the new formulas are correct ?
259149,are you saying you only know the mode and variance . . . and nothing else ?
259159,1 ) is the first display equation : $ text { kprob } _i cdot text { stock } _ { ( c-1 ) i } $ supposed to sum to 1 ( summing over $ i $ ) ?
259186,"since taking a ratio obliterates all information about the actual counts , this approach looks unpromising ( and clearly is inadmissible in the technical sense of being a uniformly inferior statistical procedure ) . why not model * both * responses simultaneously ?"
199927,"thanks . i assume the study variable is supposed to be 1 , 1 , 2 , 2 ( and not 1 , 2 , 1 , 2 as it is right now ) , right ?"
258706,"are you looking at a test of independence in 3x2 and 4x2 tables , or at something larger than 2 on the other dimension ?"
259248,i suggest putting the whole executable example . how did you get those numbers of variables ?
259293,have you tried doing the calculations by hand and adding 0 . 5 to every cell ?
259282,"there are two things going on . first , let's imagine that $ c $ is diagonal ( and with ordered values on the diagonal ) to begin with . is it then clear why $ w = ( 1 , 0 , 0 , . . . 0 ) $ maximizes variance ?"
259305,"you might start with getting an idea of why the 20 % is missing . are they just random non-responders , or might these be the ones very ( dis ) satisfied ?"
259342,repeatedly measure the same object multiple times and compute sd ?
259337,do these data arise from a randomized controlled trial ?
259191,"it sounds like there's an error in your calculation , but you haven't provided any information that would help us determine whether that's the case . could you show how you are performing the calculation and give a tiny dataset for which you obtain a negative value ?"
259345,"what are "" fluctuations "" in your context ?"
258849,with regards to faster solution did you ensure that nls and nlm used same optimizer ?
259388,"michaelchernick , is it against site rules to ask elementary questions ?"
259418,"i am curious , did one of my suggestions solved your problem ?"
259473,"first off , you have a bi-objective optimization problem ( close in mean , close in variance ) , so there will be a collection of "" non-dominated "" solutions known as a pareto frontier . while the greedy algorithm may not be optimal , we might be able to bound how bad it performs . would that be meaningful for you ?"
259464,have you stumbled upon [ this tutorial ] ( url ) ?
259535,"if you have enough cases then leave it as 0 to 16 ( you did mean that , not 1 to 16 ?"
259544,could the poisson model be of help ?
259582,"you need to edit this to expand . for instance you say "" or is there another formula ?"
259611,"what's this for , kriging ?"
131249,how do you propose that the downpayment is related to risk ?
259700,you have a continuous and a nominal variable . why can't you just use a simple logistic regression ?
259715,the first question is : is $ y $ count data ?
259751,which method are you using to do the meta-analysis ?
259735,what is lse ?
259362,"there are too many questions and the topic too broad to be a good cross validated question . putting that aside , my quick reaction is that linear regression is often a great place to start and you may want to lookup the caret package in r . there are several tutorials out there . i'm guessing you covered ridge regression , lasso , and possibly elastic net ?"
116464,neither hogg & craig nor casella & berger are texts on probability theory . are you asking for texts on * mathematical statistics * from a rigorous ( measure-theoretic ) viewpoint ?
259832,"in what sense is any of these p-values "" wrong "" ?"
259849,i'm not sure i really follow this . do you want to have an estimate of the number of clusters in different datasets ?
259858,"thanks . . . . a predictor requires a coefficient : - ) how will anyone know that the within-sample results give the best , most reliable estimates of this novel predictor's coefficient . . . standardized coefficient . . . standard error . . . or , generally , performance ?"
234194,"i'm not sure that confidence intervals are the right tool for this . for clarification : are you primarily interested in comparing mean scores between thing 1 and thing 2 , or do you have a different primary goal and are looking at this as well ?"
208231,probability of what ?
259964,can you provide the output ?
259973,"if i understand well , you have standardized the predictor values ?"
259908,` cubic cluster [ ing ] criterion fails at least 50 % of the time ` what's that operationally ?
259704,"an "" assumption "" is something that a theorem can have . linear regression has an "" assumption "" of iid errors ( it's not $ y $ s that are "" assumed "" to be iid in linear regression ! it's the errors ) in the sense that the gauss-markov theorem has this assumption . now , is there any theorem that one has a mind for logistic regression ?"
259983,"when you say "" stochastics "" perhaps the more natural terminology in american english would be probability or probability theory ?"
260083,have you tried a time series textbook ?
65179,"could you expand on what you mean by "" observe "" a range ?"
260141,"it's unclear what you mean by "" unusual . "" when all counts are in one cell that implies the marginal distributions are concentrated in the corresponding row and column , that's all . as gammer asks , what is the hypothesis you're trying to test ?"
260201,"with the sparsity of your data , i'd say any hypothesis test , be it in a longitudinal analysis ( which would be some kind of mixed model ?"
260186,"one can do this computation with or without using the mgf , but i assume you've been given this problem to help you understand what an mgf is . do you know what the mgf is for a normal distribution ?"
260219,related : [ fine tuning vs joint training vs feature extraction ] ( url ) [ what does end to end mean in deep learning methods ?
260286,why not remove trial types that are of no relevance to your hypothesis ?
260294,"you case is strange because your validation loss never got smaller . your learning rate is suspiciously high , typical learning rates are about 0 . 001 . what range of learning rates did you use in the grid search ?"
260335,why do you need to compute it ?
260348,independent from what ?
260344,"are $ x $ and $ y $ independent , in part ( 1 ) ?"
260159,"lope i notice there are two terms at the end of the bracket $ x_d $ , $ y_d $ . do you really mean to include those ?"
260088,"for readers who are non-golfers , could you point out where in these data there is any information that relates to the * relative * outcomes of the tournament ?"
260436,can you share actual figures from you run that made you think there was overfitting ?
260442,"what do you mean by "" better "" ?"
259659,what are you predicting ?
260450,"what do you mean with "" not random "" ?"
260476,why did you use tag ` multivariate ` ?
260489,"so , you want to split the data using the categorical variables ( i assume they are the independent variables ) ?"
260306,can you share the code ?
260553,is days in hospital skewed ?
260382,"you want that your model will have the property that the prediction based on a ( height , weight ) pair will be indifferent to the rest of the features and its position , am i right ?"
260610,""" i have really no idea how to continue "" is not the kind of question we are capable of addressing in this forum . do you have a specific question about statistics or machine learning that might fit with the aims outlined in our [ help ] ?"
260628,"hint : the _conditional_ distribution of $ y-x $ _given_ that $ x = x $ just the distribution of $ y-x $ which is $ n ( 0 , 1 ) $ ?"
260650,"could you elaborate on what the "" least squares estimation "" method is precisely doing ?"
260272,can you provide some context for this question ?
260652,"if you think it is a non-homogeneous poisson point process , why do you fit a cluster / cox process ( which is not poisson , but has clustering of the points ) ?"
260704,you don't have any information on cases with no accidents ?
260708,are you looking for logistic regression ?
260721,"regression can be broadened further , but the plain ( or perhaps vanilla ) idea is arguably conditional averaging : how does the mean response vary with conditions ?"
260722,"so , $ y $ is a function of treatment $ d $ and covariates $ x $ . you want to know whether $ partial y / partial x d = 1 $ is the same as $ partial y / partial x d = 0 $ ?"
229645,why do you say the second notation is easier to compare with hinge loss ?
260419,why would you consider this as a problem ?
260504,do you know or did you google 'simplex method' ?
260820,"there's something of a grey area where we can sometimes tolerate something that may become a list -- e . g . where it's not clear if there are any instances of some object ( "" can this ever happen ?"
260734,why do you state that $ p ( x_t = 1 mid x_t 0 ) = p ( x_t = 0 ) p ( x_ { t-t } = 0 ) $ ?
260866,"see [ advanced statistics books recommendation ] ( url ) , [ what to learn after casella & berger ?"
260712,"one thing that's wrong is that you have an interaction term without the main effects that make it up . in addition , interpreting the main effect of speed when you have an interaction involving speed is not straightforward . and , on your link , there are tons of files ( including some you might not want to be in a public link ) . which ones have the data you used ?"
260776,how is $ lambda t $ approaching $ infty $ ?
260877,could you define the nature of a matrix ?
260945,your question is not very clear . do you want to compare two gini coefficients ?
260800,what is the clustering variable ?
260782,have a look at my answer here ( especially to question 2 ) : url does that help ?
260980,are these pearson residuals ?
261015,why you want to use dunn test ?
261117,re ( 1 ) : how do you propose to deduce the distribution of means-of-length ?
261145,are the outputs ordinal ?
125311,"i see no significant bias in your simulation , nor do i see a mechanism to introduce bias in your description . however , that may because you are vague about the operation "" the marginal probability distribution of the sample is computed "" --if there is any way to bias the result , it must be there . perhaps you could elaborate on that process in your question ?"
260444,"have you tried [ stan ] ( url ) , or it's not feasible for your problem ?"
261200,"your questions seem objectively unanswerable because you haven't yet described what "" closest "" is intended to mean . could you elaborate on that ?"
261206,scipy may use an adjusted algorithm for the calculation . have you taken a look at the code ?
261009,"could you explain how a correlation coefficient manages to measure anything about "" performance "" ?"
261058,have you checked the original paper ?
259829,"maybe i misunderstand , but should the question instead say , "" $ a ( i , j ) $ , $ b ( i , k ) $ , and $ c ( j , k ) $ "" ?"
261223,what is the fourth state ?
260533,a crucial piece of information is missing . how many samples have you got in the training data ?
261227,what is * the * problem ?
261205,what is the nature of the scientific question ?
212584,what is it you want to know about these data ?
261176,could you elaborate on what you want to do and what data you have ?
261298,"are you looking for outliers that are extremely large , extremely low or both ?"
261373,this question isn't very well defined : exactly how is the price fluctuating ?
261423,"form what you are saying that they made research on how money influences happiness , so what ?"
261442,there is no need to normalize what is your model and what data do you have ?
261479,"your question is pretty fancy and i'm not sure i understand it all , but are you ruling out repeated simulations ?"
261511,if you have $ 1-c leq a $ then $ -c leq a-1 $ then $ c geq 1-a $ . does that help ?
261112,"in model 2 , isn't the ate equal to $ tilde { beta } $ plus the average of $ gamma_j $ ?"
261380,"for clarity , do you want to go from the definition of bc to the log likelihood ( how i interpreted your q ) , or vice versa ?"
452,"i am not sure of what you meant by "" robust standard errors are reported as a matter of course "" standard errors of what ?"
261377,"it's difficult to determine what you asking . what do you mean by a "" special case "" ?"
163943,what is health t1 ?
42948,doesn't the problem go away if you ditch frequentist stats and go with it or bayesian methods ?
261671,"not sure i follow . they are fitting one variable models , computing the auc of this model , then discarding ?"
261674,can you give a little bit more detailed description for the benefit of us not knowing american football ?
261694,""" so for example ( i'm completely guessing here , my apologies ) , can we exclude the possibility that adding a penalty , which 'pulls' the weights towards a prior value , might help during training by allowing the model to escape a local minimum or saddle point slightly faster ?"
261742,"please clarify : what are the different "" sources "" , how many are there ?"
261819,these r-squared values are from the training set or from the test set ?
261839,"if $ int p ( x ) , text { d } x infty $ , you can turn $ p $ into a probability density . which meaning can you associate with this probabilistic object ?"
260927,what test did you use to check if the residuals are integrated or not ?
261883,"hi , welcome to cross validated . when starting , it's a good idea to take the [ tour ] ( url ) ( as you alredy did ) and to peruse the [ help pages ] ( url ) . for example , you can increase the readability of your posts , and the likelihood of getting an answer , by writing formulas using [ markdown sintax ] ( url ) . this time i did it for you : can you check that the formulas have your intended meaning ?"
261872,can you please define y ?
261887,"ok . could you tell why it is so "" clear "" that this sum shouldn't look normal ?"
261918,matlab is optimized for vectorized calculations . did your matrix approach use for-loops ?
261956,first three measurements were done in the same time ?
261913,to what are you referring ?
261976,your $ r ^ 2 $ value is over the training set ?
261978,"you can turn this into a binomial distribution with $ p = 1- phi ( 1 . 5 ) $ , what is the probability that you get $ n / 2 $ successes from this binomial distribution ?"
261779,$ p ( x_0 = b ) $ is a _negative_ number $ - frac { a } { b-a } $ ?
261790,"look at the comment of glen_b in the link you include . that's very helpful . is your percentage score the ratio of two counts ( e . g . , number of right answers divided by number of questions in the exam ) or is it actually a continuous variable ?"
213578,what type of data is this ?
262043,is there any clarity as to what happened to cause that change ?
262077,a classifier can only be tuned using data and data is described by features . therefore you first chose features and then optimize hyperparameters ( such as by crossvalidation ) . could you provide examples for both cases ?
228763,"are you looking at a particular data set , and thus need to consider making the data tractable for computation , e . g . selecting , scaling and offsetting the data so that the initial computaion tends to succeed . or is this a more general look at the hows and whys ( without a specific data set to compute against0 ?"
262079,what exactly are you trying to find ?
262106,"sycorax : could you make your statement more precise ( software , calibration , & tc . ) ?"
55186,"well these are different quizzes though , right ?"
261154,"this has now attracted four answers which ( a ) do not seem to have much contact with one another , and ( b ) have attracted many down-votes . perhaps you could edit your question with some more information about the problem you are facing and see whether that clarifies the issues ?"
262137,honeybunchesoffloats what if you have sample of size 1 ?
262156,are you asking what's the definition in the context of the paper or in general ?
262160,"i do not use r , but checking in python it looks like ` confint ` is a 95 % confidence interval based on the ` estimate ` and ` std . error ` , assuming the standardized pdf is a $ t $ distribution with ` df ` degrees of freedom ?"
262180,try logistic regression ?
262245,possible duplicate of [ what is the difference between a population and a sample ?
262251,"the term "" statistically significant "" has no meaning without specifying the null hypothesis . so , what is the null hypothesis you want to test ?"
262259,wouldn't it be simpler to construct this as length given it was cracked times the probability it was cracked probability it was not cracked times number of attempts ?
262311,"perhaps by "" normalized "" the paper means in the sense of a vector , which is simply rescaled ?"
262324,"this is rather broad ( & somewhat unclear , as you mention ) . can you provide some example data ?"
262326,can you clarify what you mean by dependent variable here ?
262331,"i think some concave transformation ( log , or sqrt ) for response is desired , as the variance is non constant ?"
262143,are these random variables independent ?
262244,markov property is a definition . so your last equality being true is equivalent to the markov property being true . do you mean you want to test this assumption empirically ?
262336,what is theano ?
262352,"yes , you should look at autocorrelations at the multiples of the seasonal frequency ( 12 , 24 , 36 , . . . for monthly data , for example ) . also , it looks like you are already aware of the seasonal unit root tests but do not want to use them because it is tedious to implement them in python . so what is your real question then ?"
262384,"so you don't have a question about the code , but the statistical method ?"
172939,"since the two terms both involve the same $ x $ , they certainly won't be independent in general , so that's not something we can "" note . "" precisely what assumptions are you making about the relationship between $ sigma_0 $ and $ sigma_1 $ ?"
262436,"i have not heard this before , do you have a source ?"
262437,` and writing code in matlab to try it out ` are your results from your code or from some known established package ?
262421,( 2a ) what kind of relation do 'use' and 'y' have ?
262476,how do you measure the accuracy ?
262093,"how many cases and events are there , over what range of ages ?"
262467,"there would be * a lot * of distributions with that property ! , for instance , some ( not all ) gamma distributions . can you tell us something more about the variable you want to model ?"
262486,can you clarify your first question ?
262406,"0 . 005558 seems really small , as well as your other coefficients . i cannot see the image as i am through a secured network at work , but what is the scale of your data ?"
262587,how did you decide that those 4 entries do not follow the linear equation ?
262606,"what would it mean to "" compare "" them in this context ?"
262672,"in ( a ) and ( b ) , what justifies ignoring the fact that the number of coins is random ?"
262677,could you plase examplify the scenario where you don't have the target ( function ) ?
262693,what is your goal ?
262768,"1 . you say "" non-leap year "" in your first paragraph but your second paragraph clearly discusses leap-years ( which have 366 days - contradicting the first paragraph ) . please clarify your question . ( you should also make clear how this question arises ; is it related to coursework , for example ?"
88991,have you looked at the plot formed by the mean for each iteration ( meaning for each new random value ) ?
191919,compared to what ?
262811,what's your model summary ?
262825,what would your conclusions be if $ p ge 0 . 05 $ ?
262821,please write explicitly the expression for $ bar x_i $ . what does it average ?
262798,"catchy is a perfecty "" proper "" distribution . how do you define pathological ?"
262871,"are you asking how to do the ml estimation for the gamma distribution , or are you primarily trying to understand the optimization algorithms that are provided in r ?"
262753,aren't they the same thing ?
262895,i thought decision trees generally don't require scaling ?
262930,"do you mean : "" is it possible to get the same classification using on one hand knn and on the other hand a decision tree ?"
262934,is this self study ?
262969,"to me this sounds like informative censoring ( ie . being part of certain subsample of your study is associated with becoming censored ) . could you add the details of how this could have come to occur ( were treated individuals seen more often after the intervention , are reasons for dropout known , etc . ) ?"
262999,"` but still keeping its format / correlation , correct ?"
263010,a standard approach is kriging : have you considered that ?
261754,is the multilevel structure in any way related to the sampling weights ?
231582,i was going through my old answers and noticed this one was not accepted . do you perhaps need further clarification ?
263036,"1 ) i would recommend reading [ statistical tests for variable selection ] ( url ) br 2 ) i liked stephen kolassa's comment br 3 ) i am curious how this really work , i don't have experience with this . how would the partial least squares model look like ?"
263048,"please add some more details about what you are trying to accomplish with this regression model . this would probably be substantially overfit if you have a standard linear regression with that many samples and features . what aspect of "" the performance of the model "" are you trying to evaluate ?"
263069,"hi , imputing t-2 from nothing but demographics makes me think your results here will be crap . what is the survey data set you are using , and what variable name are you looking at ?"
263125,can you tell us more about the structure of your data ?
263136,"1 . do you really mean "" log ( y ) = log ( x ) "" ?"
263169,"1 . what's an "" excel "" ?"
263166,and what seems the problem ?
263053,"i am not sure of your semantics , but do * [ particle filters ] ( url ) * count ?"
263108,"the question is unclear . find the pc1 or its "" sign "" ?"
263287,it is not obvious to me that this is a valid thing to do . can you provide a bit more detail about the data ?
263339,please make your question more specific . give more details . what variable is measured in percentage ?
263357,"not sure tu fully understand your question , but the rho must depend on the position of ( the center of ) the sphere i assume ?"
263405,"rfs are not designed for and do not explicitly integrate temporal considerations . given that , why use them at all for this analysis ?"
263419,could you share with us some more details ?
263413,"i have no experience with betting , but why does bookie's implied pwin bothers you in this case ?"
263401,"what do you mean by "" test the classifier "" ?"
263297,1 . excuse my ignorance -- how does one exonerate ( i . e . * absolve from guilt * or sometime * release from duty * ) a subject ?
263428,i would not recommend using forward-backward selection to begin with - is there any reason you are not using ridge regression or lasso or elastic nets ?
263534,to an extent it depends on who is doing the defining ( e . g . some people would define $ l ( theta ) = f ( mathbf { x } ; theta ) $ ; some will say that he likelihood is only defined up to a constant of proportionality and so replace $ = $ with $ propto $ ) . for a simple regression the expression you have above is fine ; the problem is more interpreting what it says . is the definition [ here ] ( url ) sufficient for your purposes ?
242225,the question appears to be out dnns rather than nns in general ?
262956,"a deep reason is hinted at in [ this answer ] ( url ) : $ f $ equals $ x ^ alpha ( 1-x ) ^ beta $ relative to the measure $ d mu = dx / ( ( x ( 1-x ) ) $ . that reduces your question to "" why that particular measure "" ?"
263617,what's the problem with multinominal ?
263622,you spend one $ df $ to estimate the parameter for hp in both cases . in the first case you also spend one on estimating the intercept . you have 30 respectively 31 residual degrees of freedom . what do you mean by df for tss ?
263627,"are you looking to do this test for _each_ of your ~ 250 occupations , based on ~ 3 data points each ?"
263693,"in your graph the r ^ 2 values are ranging between 0 and -40 . i suggest you to google r ^ 2 . also , k-fold vs r2 plot is very unusual . lastly , in pls regression you need to choose number of latent variables . did you choose them manually or let the software do it ?"
263383,i do not think that in meta-analysis we usually consider the power of the trials we meta-analyse . can you clarify that part ?
261102,2 . intercept in a model for levels is not the same as drift in the model for first differences . 4 . how exactly do you obtain the forecast intervals ( verbal explanation and / or r code ) ?
263722,"please explain the criterion you are using to "" match "" a chart . could one reorder the bars in one chart , for instance ?"
263728,"what exactly do you mean by "" twice . . . as indicative "" ?"
263742,"maybe you can model the % loss , for example with a beta distribution ?"
263746,"with such huge sample sizes i would first be preoccupied about the independence assumption , there is bound to be some substructure , subgroups , changes with time , . . . which covariables do you have ?"
263735,looks like a $ theta $ is missing in the first factor on the right hand side ?
263788,what do you wish to do ?
263794,does kl mean kullback-leibler ?
263795,"so you have response data with * uncertain class labels * . for each observation , do you have a probability vector $ ( pi_1 , dots , pi_k ) $ summing to one ?"
263739,can you give some context ?
263516,"well , think about this . you sample 10 items and get 9 successes . i sample 1000 and get 900 successes . who will have the more accurate estimate of the mean ?"
20584,"why not use the initial condition as a blocking factor ( lower , middle , upper third ) and set it up as a randomized complete block design ?"
263859,"the trickiest part will be how to treat the nodes -- are they fixed , or do you determine their values from the data ?"
263893,what is your question ?
263900,"i have a feeling that it will be difficult to get an answer here . i used to answer a lot of garch questions but am less active presently , and i have no experience with news impact curves , so it would require quite an investment of time to learn that and then write an answer . maybe you could try on quantitative finance stack exchange ?"
263926,there are $ frac { ( 10-1 ) ! } { 2 } $ ways of choosing a hamiltonian cycle on the complete graph . why are you not simply multiplying that by $ 0 . 5 ^ { 10 choose 2 } $ ?
263948,what do you mean by a confidence float ?
263977,are you asking a statistical question - is it technically possible - or a programming question - how do i do it in r ?
247197,have you read the answer ?
24992,"are you , for example , claiming that an ohm has a privileged physical meaning that , say , 1 / ohm does not have ?"
264011,can you clarify your question ?
263096,could you give some more detail in how you are going to use the model ?
264016,why do you think ridge should perform better ?
109222,"this is strange . . . in case control studies don't we usually estimate * odds of exposure * as a function of case / control , not the other way around ?"
264025,"would dividing all your numbers by the same value "" eliminate size differences "" ?"
264030,"is that a "" very high "" rmse though ?"
264045,"could you explain what you might mean by "" every single independent variable "" ?"
106238,what is $ chi ^ 2 $ ?
263855,can you please explain the new tag restricted-mean ?
252449,did you try to write down the likelihood of the model you define ?
264130,* am i right in thinking that i cannot interpret these ?
264141,you already asked this q : url what is wrong with the answers there ?
264082,( 1 ) should be $ frac { 1 } { theta ^ 2 } sum_i x_i ^ 2 $ not $ frac { 1 } { theta ^ 2 } sum_i x_i $ and ( 2 ) what do you mean by isolate $ theta $ ?
264166,"could you clarify what you mean by "" lda on $ x $ , "" which makes no reference to any responses at all , and by the similar phrase "" lda on $ x ( x ^ tx ) ^ { -1 } x ^ ty $ , "" which--since it is the projection of the responses into a subspace--makes no reference to any predictors beyond the space they span ?"
264167,"you could start with calculating a cross-correlation function , and maybe show a plot of it in your post ?"
204250,interesting question . can you provide a little more scientific background about what is random about the stimuli and what the condition a vs . b manipulation is ?
264215,"this is often what is done in practice , am i missing something ?"
264225,"i am not sure i understand your problem exactly , but your title and first line seem might indicate you are looking for repeated sub-sequences in a longer sequence whose elements are drawn from a small "" alphabet "" ?"
264132,"it is somewhat difficult to test the problem without having data to reproduce it , or at least some output of ` summary ( ) ` on your models . but notice that 0 . 74 = 2 * 0 . 37 - maybe the ` predict ` function uses the mean as a reference , instead of the correct level ?"
262504,"what do you mean by "" normalize my data "" ?"
263818,what do you mean with 4m and 2m standard deviation ?
264288,why do you think the coding given by ` contr . treatment ( ) ` is wrong ?
263364,"pca won't really help here - you're interested in the variance of the * * output * * , not in dimensionality reduction . i suggest to first of all include a sample data set in your question , so that it's more clear what you're talking about . secondly , are you interested in testing whether the mean of $ y $ is different across the groups , while controlling for the values of $ mathbf { x } = ( x_1 , dots , x_n ) $ ?"
264353,how many groups are there ?
264374,why ?
264436,"304 is not huge , but it is large enough for small violations from normality to hopefully be unproblematic . sadly , "" hopefully "" is not such a scientifically useful term . i'd be surprised if the problem disappears with a mixed model . the model of final length as a response variable seems risky to me , as you will likely need to interact all your other variables with initial length . can jmp compute bootstrapped p-values ?"
263917,"i don't see any estimator here : by definition , an estimator is a function of * data * , but you haven't exhibited any data at all . what then could you possibly mean by "" unbiased "" and "" estimator "" ?"
264371,what are the expectations taken with respect to ?
263796,can you specify exactly what happens if the marked pile has more than one script already ?
264520,i am not sure whether i understand this question : isn't a model with the identity link ( instead of the canonical $ ln $ link ) just a regular linear regression model ( and not a poisson model ) ?
264521,possible duplicate of [ how do i find correlation measure between two nominal variables ?
264541,"maybe you could try with some other software , such as package ` algdesign ` in r ?"
264542,"so , you have one q , with four possible answer alternatives , of which exactly one is correct ?"
264545,did you try logistic regression ?
264539,are you referring to the book * an introduction to statistical learning * ?
188202,"this isn't answerable yet . what kind of model did you use , a neural network , eg ?"
169891,"you graphs say air , not lnair on the y-axis . are you sure the stata code is correct ?"
251776,"actually , that's a useful example : the variational method in the paper defines a function to minimize ( kl divergence ) , which turns out to be equivalent to maximizing log-likelihood . ( "" the overall procedure can thus be viewed as coordinate ascent in l , "" says the paper . ) does that help ?"
264632,"1 ) if you remove smooths from a gam , you essentially get a glm . so doing that won't really solve your problem , as your result is indeed strange . 2 ) what kind of variables are those ?"
264646,"kw isn't adjusting for all those covariates that are in your model , and ( even if that weren't already enough to fully account for the results being different ) it also uses the data quite differently in assessing group differences . why would you expect it to give the same result ?"
264660,what does cp stand for ?
264687,"calculate the entropy for the continuous distribution , then calculate it again from your probability table of 500 values . is it close enough ?"
264689,what are you trying to predict ?
264734,which effect size do you want to detect ( in terms of $ p ( x_ { case } x_ { control } ) $ ) ?
264754,"it is not entirely clear what you mean with "" variancve for each breed is significant "" how did you obtain the data ?"
264715,why would you want to bin the variable ?
264598,"there are of course optimizers with more robust convergence , though often false convergence or finding local minima . i assume that you don't have a gradient function ?"
264818,"do you have experience with streaming data , in either spark or elsewhere ?"
264829,can you please give more detail on your data ?
264848,"imagine there are true effects in h1 and h2 , and your statistical procedure successfully detects the h1 effect but fails to detect the h2 effect . therefore , you include this gene in your list of genes significant in h1 but null in h2 . does this constitute a false discovery ?"
264852,can you plot the predicted vs real skipping rate for your data with the model that gives r ^ 2 ?
264880,"when you added the ` [ statistical ] ` tag , did you notice it said , "" this tag is deprecated . do not use it "" ?"
264895,"what is the education of "" death people "" ?"
264889,"could you also please specify ( a ) how you know the mean $ m $ of the doubly truncated rv ( e . g . do you 'know' it from data , or by some formula ) , and ( b ) do you know the parameters of the normal distribution from which the doubly truncated pdf is derived / constructed ?"
264911,below we use the multinom function from the nnet package to estimate a multinomial logistic regression model . there are other functions in other r packages capable of multinomial regression . we chose the multinom function because it does not require the data to be reshaped ( as the mlogit package does ) and to mirror the example code found in hilbe s logistic regression models url does this help ?
264913,"er . . . it doesn't . let $ k = 1 $ ; clearly all values are smaller than 1 . the distribution of the smallest , $ x_ { ( 1 : n ) } $ , cannot converge to a number more than 2 . 7 times as large as the upper bound on the domain of the variable . are you sure you transcribed everything correctly ?"
264935,"if your model . matrix is nonsingular , it means there is no inverse . however , i am curious , can you try to fit your model without the random effect , using ` gls ` instead ?"
264938,"also i think you meant to write $ $ t = { emptyset , omega , { 1 , 2 } , { 2 , 3 } , { 1 , 3 } } $ $ and finally , shouldn't you ask it at math stack ?"
265026,what exactly is this graph showing ?
265045,the link states very clearly that the response is wine quality ( an ordinal variable with 10 levels ) . any reasons why you don't want to just use that as a response ?
265121,"the multinomial is not particularly hard to use to work out the probability of a specific event ( like with "" 5 observations with these probabilities $ p_i $ of an observation appearing in bin $ i $ , what's the probability of getting three in bin 1 , one in bin 2 , none in bin 3 and one in bin 4 ?"
265152,why are you against ( multiple ) imputation ?
183456,what makes a permutation test * ad hoc * ?
265175,"` for each i . . . i do a linear regression and find coefficients ` how are you going to do a multiple "" linear regression "" for each point i separately ?"
263155,could you also include the summary of fitted models ( their coefficients and standard errors ) ?
265221,"is your question , 'do i use ` ln ( x / 10 ) ` or ` ln ( x ) / 10 ` ' ?"
264625,why do you think squared loss is wrong ?
264899,1 . you don't specify the relative numbers of each color -- are there twice as many green balls as blue balls ?
265215,"it looks like you have 2 factors of interest and no subplots , so a crd makes sense . is there some other variable you want to block on ?"
265240,what's your goal with the model ?
265270,"what do you mean "" i am stuck at the initial stage that calls for the feature extraction "" ?"
265261,i don't understand what the data are like here . logarithm of what precisely ?
265272,isn't this a standard panel data problem ?
265276,with regard to your second question : sufficient statistics are most certainly non-unique . any linear transformation of sufficient statistics is also sufficient . can you tell why ?
265308,"do you believe that your series is well-modeled by an arima process , but that the entire arima structure may have changed due to the intervention ?"
265211,""" is it reasonable to conclude that $ p ( b mid a ) = p ( b ) -p ( a ) $ ?"
265266,try ` ?
265335,do you remember which paper it was ?
265365,i wouldn't know how to correct the numbers here . there is no obvious clue which of the sds is off . can you contact the researchers ?
265383,"the estimate of the mean is far from trivial : for many purposes , the ratio of the sample means is a poor estimate of the ratio of the true means . it can be corrected using the sds and the correlation . however , whether and how to correct it depends on why you are making this estimate ( more specifically , on what it costs you when your estimate is wrong ) . the same applies to the ratio of sds : could you explain what you intend to use this ratio for ?"
265392,"with so much data any difference will be statistically significant , the scientific question is : does it matter ?"
265408,"you didn't make "" age "" a dummy variable , did you ?"
265416,"welcome to cross validated . before starting to post , it's strongly advised to take the site [ tour ] ( url ) . in particular , you should add the ` self-study ` tag to questions such as yours , related to self-study , and describe what you have attempted so far in order to solve the exercise . we can then give you hints on how to proceed , but we cannot do your homework for you . in this specific case , i would start from the definition of [ vapnik chervonenkis dimension ] ( url ) . do you have that clear in mind ?"
265437,"richardherron : not really , in this case $ e [ tilde { u } mid tilde { x } = x ] $ is itself a random variable , as a function of random variable $ eta $ ( the variance of $ tilde { epsilon } $ ) , so it cannot be deterministic as your second formula suggests . maybe you want $ e_ { eta } [ e [ tilde { u } mid tilde { x } = x ] ] $ ?"
265441,"can you clarify whether each row is the result for one territory only ( each row represents a different territory ) , or are there several rows that belong to the same territory because rows can represent patches within a territory ?"
265452,"welcome to [ stats . se ] ! please take a moment to view our [ tour ] . in regards to your question , it depends . some software have inverse poisson , some don't . in the end , you can usually program such a function . what method are you hoping to use to solve your problem ?"
265455,welcome to [ stats . se ] ! please take a moment to view our [ tour ] . there are several possible answers to this . how closely does the model need to match your data ?
100046,are the mles ( not the log-likelihoods themselves ) comparable ?
265517,could you provide more details on where you are stuck ?
265520,can you explain the exact conditions that must be satisfied ?
265532,"welcome to cross validated . you mention 4 dependent variables , but from the rest of your question it looks like you are only interested in one of them ( capacity development ) . is this correct ?"
265546,can you provide a small example dataset to illustrate your situation ?
265563,is there some reason why you can't use the classic correction for mean and standard deviation instead for those features ?
207055,"what do you mean by "" fails to produce output "" ?"
265568,"i'm by far not an expert but there may be one problem . suppose you could test which model ( or approach ) is better , do you test it in bayesian or frequentist way ?"
63463,i don't see an outcome variable ?
80596,what are you trying to achieve with this procedure ?
265596,"what's the null hypothesis , and what is exchangeable under it ?"
265559,"could you please explain what "" first appears "" means ?"
265661,the area under the curve ( auc ) is a measure of discriminatory power . if you want an out of sample estimate of it then you have to estimate it on the test set ?
265722,your procedure is indeterminate ( how exactly do you determine the kde ?
265808,"before you start transforming anything , are you referring to normality of your data ?"
261098,"could you try whether : code glmer ( firstresponseaccuracy ~ 1 lag aware samelocation lag : aware lag : samelocation lag : aware : samelocation ( 1 subject ) , family = binomial ( link = "" logit "" ) , data = data_flicker ) / code gives you what you want ?"
265857,rickdefieux can you edit your original question and provide this information up there ?
265858,"what is "" inverse norm of z "" ?"
202706,what is the definition of median ?
240470,what * exactly * do you mean by saying that the samples are log-normal but are all discrete integer values ?
265913,why the count-down from 5 to 1 ?
265984,did you really make changes ?
266000,why do you think tschuprow's t is contradicting the results from the chi-square test ?
266013,"could you explain what you mean by a "" predictive "" pdf ?"
266036,have you specified your time series frequency as 7 before feeding it into ` auto . arima ` ?
266050,what is the reason the group sizes are so different ?
266078,how big are your observations ?
266113,have you tried the binomial distribution ?
266127,in my awareness / understanding ( see footnote [ here ] ( url ) ) cda is a synonym to ( multiclass ) lda . discriminants in multiclass settings are extracted as canonical variates . do by mda you mean multi-class lda ?
266124,is it correct to assume that that is a subsample of your data ?
266162,optimality of $ alpha $ in which sense ?
265874,would it make any sense not to use the absolute value when the derivative is negative ?
266139,"this sentence : "" normally , i would include a random slope for x1 and x2 , but the half of the data that come from sites with just 1 replicate preclude that possibility "" is unclear . why can't you do ` y ~ x1 x2 ( 1 site ) ` ?"
266197,"bayesian methods do not require that you know the exact incidence , do you know a range in which the incidence of a disease sits , such as between . 01 % and . 125 % ?"
266219,do you mean that you will make blood pressure categorical rather than continuous ?
266236,"are you defining $ mathit { stdev } $ as the standard deviation of a sample of survey responses $ x_1 , x_2 , ldots , x_n $ where each $ x_i $ can take the integer values 1 through 10 ?"
266264,1 do we keep the same $ lambda $ ?
266097,can you post the output of the two functions so as to see what the differences are ?
266241,do you really want a ceiling for estimated probabilities that is less than 1 and a floor greater than 0 or is it possible that you just want more of the estimated probabilities to fall further away from 0 and 1 ?
266319,to what would your mse apply ?
266344,how correlated are your variables ?
265404,"i don't understand the question . you want to compare ( 10 , 8 ) against ( 13 , 39 ) ?"
92542,how large are the samples ?
264327,"the warning means what it says , you have ties . the other $ p $ -values should be k though . i think you need to review holm's method though as your explanation does not make much sense to me . can you edit your post to say what you expected to happen ?"
266038,what is the purpose of your study ?
266178,i see you've chosen the tag ` naive-bayes ` . are you asking specifically in the context of a naive bayes classifier or in general ?
266434,does this partially answer the question ?
266440,"can you point to a specific place in the paper where this , you think , is happening ?"
266478,"it's hard to tell what you might mean by "" intuitively . "" your main question seems to be "" why isn't a random walk stationary , "" to which you have supplied an adequate answer . perhaps an image of someone stumbling blindfolded through an open field might help : would that person tend to stay near any fixed point ?"
266238,"this looks like the conditional expectation of a random variable $ i $ , given that $ y_i leq y_ { n 1 } $ . what is $ i $ ?"
266473,try ` summary . aov ( m1 ) ` is that what you want ?
1315,"just looking at it , it looks like a skewed normal distribution . are you sure the outliers are necessary for your analysis ?"
41615,"you may want to look at [ how to ask a statistics question ] ( url ) . as is , it's hard to answer this . sometimes a ratio could make sense , i guess . but what's your dv ?"
72047,how do you fit the data ?
258244,i think your confusion is about the difference between the variance of the scores and the variance of the difference between the means . perhaps investigate a bit further with that hint ?
266507,"have you tried just using a classifier ( svm , neural network , xgboost , etc ) to predict the label , given your vector of variables ?"
266516,can you tell us a little more about your data ?
266533,whether to use a repeated measures anova depends entirely on how the data is collected ( or the underlying model structure ) . can you edit your question to explain what sort of experiment / survey your data represents ?
266550,"understanding your question requires knowing what package you're using and what those functions are doing . to make it intelligible , could you please explain what it is outputting ?"
266569,regression ?
266577,"hello user3476463 , i got the same issue , and it's really annoying . have you found any solutions to this problem ?"
266596,how many predictors do you have ?
266604,"if you want to use taylor series , then begin by applying stirling's approximation to determine how many terms to use , then begin with the * smallest * terms and work towards the middle . if the argument $ x $ is negative , consider computing $ exp ( -x ) $ and then taking its reciprocal : this avoids cancellation from repeated addition and subtraction . out of curiosity : why could you possibly need extreme precision for a machine learning problem ?"
260387,"the 2nd pic is a rare case , albeit possible . are all eigenvalues nonnegative ?"
266622,which library are you using ?
221755,"at the moment i'm still confused , for instance * it looks like this when comparing b against a : a = [ 1 2 3 4 5 6 7 8 9 10 ] , b = [ 2 1 17 4 5 6 9 3 7 14 ] , spearman's rho = . 5030 . it look like this when comparing a against b : a = [ 2 1 8 4 5 6 9 12 7 13 ] , b = [ 1 2 3 4 5 6 7 8 9 10 ] . spearman's rho = . 8061 * . the correlation between a and b should be the same as between b and a . yours is not . . . but i don't understand your naming of a and b . the a in your first seems to become the b in your second , while the b in your first [ 2 , 1 , 7 , . . . ] doesn't match the [ 2 , 1 , 8 . . . ] in your second ?"
266639,"really great , thought-provoking question . in a sense though , you've put the cart before the horse in probing for advanced functional forms and techniques . the first question i would want answered is how many different types of patterns are you trying to identify ?"
266637,can you give some more information ?
266654,"your last question gives me pause : $ x $ will * always * have a density function with respect to the measure it induces . therefore your main question , "" does $ x $ have a density function , "" seems without any meaning . what are you trying to ask ?"
266868,"i don't quite understand the question . . . your data is drawn from $ p $ , but what's $ q $ ?"
266752,what is the subject of measured variable ?
266094,carl can you elaborate on why would one need to refit the model without non-significant predictors ?
267018,"could you explain how you intend to use these "" representative values "" ?"
125381,"are you asking about the statistical aspect of this , or are you looking for code check ?"
267020,there's more than one way one might put an additional covariate into such a model . can you explain more clearly how you think this relates to the present model ?
267134,do you want to prove why your first equation is the mle estimator ?
267069,"bayesian linear regression , for example ?"
266784,"from my pov there is no single * correct * answer to your question . given that , i would regard prescriptive comments as suspect . it sounds like the context of your analysis is a marketing one in terms of trying to understand the "" drivers "" of an average * usability * score . i think you need to provide more info , e . g . , are these averages over a fixed window of time , e . g . , a minute , an hour , a day , etc . ?"
267193,"usually , noise can be estimated from the residuals . the standard deviation of the residuals gives you the noise's amplitude , from which you should be able to get the snr . however , as you are not using a zero-centered noise , the fit parameters will have absorbed a part of the constant bias you introduced ( as can be seen in the biased value of tau you recover ) and the residuals will present a serial correlation structure , which might complicate the estimation of snr . do you really intend to use this kind of noise ?"
267189,"it was a question , is computing sum scores what you really wanted to do ?"
266699,i couldn't answer this with a formal proof but rather with some simulation studies showing that liml is median unbiased ( plus definition ) and that liml and 2sls with one endogenous variable and one instrument have the same small sample distribution ( hence if liml in this case is median-unbiased then so is 2sls ) . would this be sufficient to answer your question ?
267288,the recommendation is already given in the paper you refer to . what else do you need ?
266641,"is it true that you have only 3-6 months of data , or do you have 3-6 months of * nonzero * data and you know ( or can safely assume ) the values for the remaining months are zero ?"
267331,why is it causing instabilities ?
267338,"you can , of course , always add a constant such that your predictions are always at least 0 . but then your regression will not be the one that minimizes the quadratic errors ! if you need to impose boundedness on the predictions , as you already mentioned , you need to specify a different model other than linear , and this will depend on what your data is . maybe a left-censored tobit is what you need ?"
267345,( 1 ) regularization can be seen as making individual coefficient estimates worse while improving their collective performance at predicting new responses . what precisely are you trying to achieve with your interpretation ?
198695,adde a dummy variable ( 0 / 1 ) for the special events in your dropbox file them ?
267400,why should sse loss produce a convex curve ?
264600,could you clarify what exactly is unclear for you in the [ algorithms for automatic model selection ] ( url ) thread you refer to . . . ?
267441,possible duplicate of [ is pearson's r inappropriate for measuring regression accuracy ?
267465,are you familiar with what a normal distribution is ?
267432,"could you provide a description or mathematical definition of what you mean by "" overlap "" of random variables ?"
267473,"this is strange , gamma distribution is supported on $ ( 0 , infty ) $ while beta is supported on $ ( 0 , 1 ) $ . or do you mean something else ?"
216283,did you notice that those characterizations of $ r $ are specifically for the * social sciences * ?
267501,"we don't say "" pass "" or "" fail "" . please change it . do you mean "" reject "" and "" fail to reject "" ?"
267511,why do you think a transformation would help ?
264693,are the units of time the same for each company / id ?
267421,"( 4 ) kernel density estimation is totally nonparametric , why are you saying it's a parametric method ?"
267681,can you post some illustration of your data ?
267683,do you mean other than maximizing the likelihood ?
267723,could you clarify what you are asking ?
267735,i'm confused . . are you missing a subscript i on the v and w ?
267740,"i imagine you mean gender , not sex ?"
267770,the explanation below the plots doesn't help ?
267786,can you post a citation / reference for the claim that it is unacceptable ?
267838,could you explain why you might be trying to fit a spherical variogram to these data ?
267890,"what i understood from this long post is that you need to select an appropriate arma-garch model and then forecast from it . your questions seem to be , ( 1 ) how to select an arma-garch model ?"
252968,this is a nice question ( 1 ) . have you head about [ scoring rules ] ( url ) and in particular * strict proper scoring rules * ?
267877,have you investigated multiple imputation ?
267961,you could try a histogram with log scale on the y-axis ?
268032,do you have a distribution model for your data ?
264769,"how many events do you have , and how many levels of each crop and treatment do you have ?"
265978,the probability that all possible events happen is 1 . can the balanced test be stated in this way ?
268168,"what "" logistic regression textbook "" says this ?"
268182,"what are the "" products "" ?"
210752,welcome to cross validated . can you give us an idea of the distribution of your continuous dependent variable ?
268258,"please explain what your opening line means : what is an "" independent sample "" and what is a "" dependent sample "" ?"
266749,what kind of sampler / software are you using ?
268280,"could you clarify what an "" autocorrelation time "" is ?"
268340,why don't you choose a more tractable model for the data ?
268316,did you take a look at the acf and pacf plots of the residuals ?
268345,""" cross-loading "" is an unusual term in factor analysis . ( it encounters in discriminant / canonical / some other analyses , not is classic fa . ) what do you mean by it ?"
268361,"related : [ in a poisson model , what is the difference between using time as a covariate or an offset ?"
231292,why would you consider it to be linear . . ?
251681,"the 3d case is covered in detail at url what you mean by "" do not have constant axis "" is mysterious . consider the 1d case : the confidence ellipse is the usual confidence interval . * of course * its endpoints vary because they depend on the random data--but so what ?"
46784,what data does the magazine have ?
268428,look at the data . why are there so many ns ( presumably unknowns ) particularly in the ar region ?
268421,i did not refer to any specific part of that answer . the answer simply represented a a reasoning . weakly correlated items are strange to sum ( average ) into a _single index_ . it can be done sometimes under special motives but that won't be _statistically_ warranded . why do you resist the idea to keep all your important items as separate indicators ?
268357,why not just use the prior gamestates directly instead of categorizing them first ?
268299,how large is your data set ?
238138,"your post is a bit unclear . you have a response random variable $ y $ , and a predictor $ x $ . for each value of $ x $ , you can run a simulation and compute the corresponding $ y $ . right ?"
234942,"what is your "" degree of dependence "" exactly ?"
268502,"i don't know how matlab selects the set of regularization values , but it seems that the range doesn't coincide with the more typical "" swoosh "" behavior that shows the transition from under- to over-fitting . have you tried giving it a different set of regularization values , perhaps $ [ 10 ^ { -6 } , 1 ] $ ?"
212271,have you come across [ wilk's theorem ] ( url ) ?
167535,is the raw data ( the real x values ) available ?
268548,"it's unclear the sense in which you mean "" the equivalent case "" -- what specifically are you seeking ?"
268599,"ferdi , why do you think so ?"
268647,can you post an example where someone did this ?
268690,"can you describe your observations ( what are they , and is there a time-series element to them ) ?"
268429,"the statement of "" universal approximation "" in this question appears to have little or nothing to do with the statement in the referenced wikipedia article . indeed , it isn't even clear how one might approximate a * function * with a * process * . could you elaborate on what you're trying to ask ?"
267078,"in order to give a reasonable answer , please clarify what you mean by : a ) data , b ) modelling and c ) models . the key question - as usual - is what you want to do with * it * . but what is * it * ?"
268743,how much data do you have & how many nodes are there in your som ?
268757,the 3-level variables are categorical ?
268792,are you familiar with the strong law of large numbers ?
268796,"sure it's possible . just to clarify what may be your sticking point , why do you suspect it shouldn't be possible ?"
268026,how do the groups relate to the condition ?
268828,"just out of curiosity , which processor is giving you a better performance in scikit-learn ?"
268856,"for your future reference when you are writing papers for publication : apostrophe s stands for is ( "" what's = what is "" , "" it's = it is "" , "" how's = how is "" , etc . ) "" get's "" therefore does not make any sense ( get is ?"
268848,"[ leverage ] ( url ) ) , considered by category perhaps ?"
268874,"i am heartened to see you starting your exploration with * * simulated data * * , and have an idea about how to answer your question usefully . but one thing i'll need to understand better is the * meaning * of these 'disease types' . are these unrelated diseases , or do they represent grades / levels of severity of a given disease ?"
28744,"this isn't homework for the poster , but it is an exercise in gelman et al's * bayesian data analysis , 2nd ed * . i have a complete solution to the question . what's the protocol about posting full answers to questions which could plausibly be homework for someone at some point ?"
268755,"maybe you want to see the thread : "" [ the two cultures : statistics vs . machine learning ?"
268862,"what you say we "" know "" is not generally true . it seems you are implicitly assuming ( 1 ) all the terms in each time series have the same mean and variance and ( 2 ) the terms are all uncorrelated . one rarely uses "" time series "" to refer to such situations , which causes one to wonder whether you have actually formulated the problem you want to solve : is this question about time series or is it about moment estimators ?"
268987,a lot seems to be missing from this post : what is your first model ?
268996,"do you mean , select distribution before selecting the garch order ?"
269008,ok . what's your question ?
268774,did you perhaps leave out some condition from this question ?
269035,"if "" mobi "" is intended to be an abbreviation for "" mahalanobis "" could you please just write mahalanobis each time ?"
269048,"maybe , within each species , ratio of sodium uptake ( treated ) versus sodium uptake ( controls ) , or eqwuivalently , the difference of logarithms ?"
269191,do you have 2 observations for each participant ( what they took before & what they took later ) ?
269186,have you tried adjusting for clinical / demographic variables with propensity scores instead of cox regression ?
269207,what do you think about my answer ?
269208,"what's the problem with simply plotting , say , all variables that are ever among the five largest variables at any time step ?"
269224,there are two questions here . which one do you want answered . . . ?
269190,can you edit your post to show us the formula ?
269255,i have a feeling that the data you have is not gamma distributed . they don't look like ` k = 1 ` to me . what's the other parameter ?
269313,"what do you mean by "" fit a linear model for each participant "" ?"
269332,"i have formatted your question , please pay attention to this in the future . can you be more specific , which parts of the lengthy output do you need help with ?"
269365,why are you trying to fit a distribution model to your data ?
269373,"your definition of x doesn't seem right , i could write what it should be for you , but i think you'll have more fun figuring out how x matrix should look : ) . hint : does your $ x beta $ gives you what it should ?"
269329,what about var model and the notion of granger causality ( but also impulse-response analysis ) ?
269339,does it make sense to you ?
269340,single arm ?
269353,"i am not sure why you say that in the $ ln ( y ) = beta_0 beta_1 x_1 beta_2 x_2 $ model , a unit increase in $ x_1 $ leads to a $ beta_1 times 100 % $ increase in $ y $ ?"
269355,why not work out the distribution of $ x $ ?
269362,what $ n $ and $ k $ stand for here ?
269234,i doubt the fx rates could be i ( 2 ) rather than i ( 1 ) . perhaps there are neglected structural breaks that prevent the rejection of the second unit root ?
269511,it means you have a number of districts and a number of crops . small dataset you have qouted is for a particular distt . and for a particular crop ?
269516,* granger test * ?
269515,mean equal to $ mu $ ?
269530,do you know how to extract your samples from bugs ?
269550,"there seems ( naively to me , since i'm not an expert ) like at least two issues , which you could answer better than i could : ( 1 ) does a normal distribution accurately model the data ?"
269579,what statistical test ( s ) are you doing ?
269601,"my understanding is that cp's primary use is as a criterion for variable selection . sas is one of the few software packages that recommends this statistic . otherwise , i don't anyone who relies on it . your question is clear but my question is , why waste time trying to understand it ?"
269641,the question ( s ) aren't clear to me nor is the description of how the rankings are derived . would it be possible to include a reference or link to an article that goes into more depth in describing how these college and high school rankings are developed ?
140090,what are the numbers measuring exactly ?
269731,"the original question wouldn't have happened to say "" . . . distribution of $ y $ given $ y 0 $ "" , would it ?"
269738,"what do you mean by "" optimise "" ?"
269743,wht do you mean by pooled ols ?
269772,what was the reason for weighting the observations ?
269801,"you will need to make assumptions about the function if you want to make any progress , assumptions that lead to bounds on how much it can vary between samples . you also need to be specific about what you mean by "" optimal way "" : in particular , will there be any penalty for using more intervals in the approximation ?"
269757,what is otherwise your interests ?
269824,"assume that you have a sample of size $ n = 100 $ . you want to etsimate $ hat gamma ( 98 ) $ . you can consider only two products ( and assume for simplicity that the series has sample mean zero ) , $ x_1x_ { 99 } $ and $ x_2x_ { 100 } $ . are you going to divide them by $ 100 $ or by $ 2 $ ?"
269800,you are still using a lot of unfamiliar jargon . first of all what are pseudoitems ?
269915,the coefficients only make sense if the ols assumptions met . have you checked ?
269975,""" probability distribution "" do you mean "" probability density function "" ?"
270029,why not use a multilevel model ?
269555,what's the reason for not using glmnet ?
268568,what language or code does : ` library ( johnson ) ` refer to ?
269670,"since anova is regression , some of these questions have answers at url it's unclear what a "" significant outlier assumption "" might be--one hopes there are * no * outliers and that check is a big part of normality testing in the first place . might i suggest you therefore focus on the third and fourth questions alone ?"
270032,please edit your question to show what you tried . you also need to clarify which parameterization of the gamma you're using . some hints to get you started : on 1 . what values of $ x $ satisfy the condition ?
270070,welcome to cv . this is a great question . which command did you use ?
270009,what are your thoughts on how the current p-value of 0 . 08 is calculated ?
269663,"welcome to cv . since you're new here , you may want to take our [ tour ] , which has information for new users . are these models nested ?"
270148,did you attempt to search for answers already published ?
270161,are $ mu_0 $ and $ sigma_0 $ fixed ?
270301,a multivariate distribution is not necessarily a time series . so why are you computing autocorrelation and partial autocorrelation functions ?
270309,"you have marked this with the time-series tag and with the moving-average tag . the moving-average tag specifically addresses a running average approach . within time series , there is a box-cox approach to time series modeling ( aka arima ) where "" ma "" has a specific and specialized meaning . can answers assume you are referring to the windowed , running-mean-kind of moving average and not the arima-style ma ?"
270288,can you give us the context ?
270270,do you know how to pass from a continuous cdf to the pdf ?
270332,i don't understand what you are saying . it is confusing . are you using an imputation method or not ?
270344,could you clarify the intent of your question ?
269854,antoni can you point to any source where they flip the weights ?
270230,can you clarify what the question is ?
270482,does this accuracy based on the training or testing dataset ?
270092,can you please add a tag wiki for your new tag ` gsea ` ?
270566,are you using a cross-entropy loss function ?
270562,"if terminology helps for your searching , the case where you are shifting spatial divisions around without resizing is called the "" zoning "" variant of the maup . but , do you have any reference that suggests maup applies to probabilities like these ?"
270591,we're going to need a lot more information before this is answerable . what are your variables ?
270585,"a correlation coefficient of zero describes "" no correlation . "" could you clarify what you're trying to accomplish ?"
270609,can you display a portion of these time series ?
270611,are you just looking for a yes or no answer ?
270639,"hmm , doesn't the article say that gci is true for any convex polygon ?"
270296,is $ a b $ the event $ a cup b $ [ $ a $ or $ b $ ( or both ) ] or $ a cap b $ [ $ a $ and $ b $ ] ?
270668,the two stage process seems correct given the picture you have here . what computations go into producing the pink histogram ?
270647,"you wrote "" how are their respective distributions combined ?"
270683,possible duplicate of [ best suggested textbooks on bootstrap resampling ?
270711,there's a couple of related posts [ how does the generalized linear model generalize the general linear model ?
270714,while retaining the ( unstated but implied ) assumption of iid normality ?
270770,"sorry , but i simply do not understand . . . what is the question ?"
270788,"welcome to cv . since you're new here , you may want to take our [ tour ] , which has information for new users . are you sure that what you would like to do is possible by using a pseudo- $ r ^ 2 $ ?"
270808,it could be that your model is simply over-specified . hard to say . have you tried a simpler model in ` nlme ` ?
270782,""" 4 of these books may not be next to each other on the shelf . "" - can you clarify whether this means the four books may not appear as a consecutive block of four , or whether it means none of the four books is allowed to touch any of the others ?"
268760,"where in these data and graphics is "" animal growth "" represented ?"
270818,"is the model : you observe $ x = { x_i } _ { i = 1 } ^ n $ . $ newcommand { ex } { varepsilon_1 } newcommand { ey } { varepsilon_2 } newcommand { ux } { upsilon_1 } newcommand { uy } { upsilon_2 } $ you can estimate $ f ( x ) = a varepsilon ( x ) $ , $ g ( x ) = b upsilon ( x ) $ ; you split $ x $ into $ x_1 cup x_2 $ and do begin { align } ( f ( x_1 ) & - g ( x_1 ) ) ^ t ( f ( x_2 ) - g ( x_2 ) ) & = ( a - b ex - ux ) ^ t ( a - b ey - uy ) & = ( a - b ) ^ t ( a - b ) ( ex - ux ) ^ t ( a - b ) ( a - b ) ^ t ( ey - uy ) ( ex - ux ) ^ t ( ey - uy ) , end { align } which has mean $ lvert a - b rvert ^ 2 $ if the noises have mean zero ?"
270825,can you say more about your data & your model ?
270201,can you pool based on domain knowlege ?
270856,i don't understand what you want to do with the two intervals . are these intervals known and you only want to generate points between the intervals ?
270871,"( 1 ) what , if any , indication is there of lack of fit in the initial model ?"
270838,"no they are not correct . these solutions would be valid if the boundary of the support from below was $ 0 $ . now that it is not , the situation is more complicated . do you know the step-by-step logic based on which your solutions would be correct in that case ?"
270974,yeah that intercept is worrying . how many observations have a high probability of being in that component ?
270997,what exactly is your question ?
271025,"hard to say . maybe look to see whether there are non-linear effects ( polynomial terms or interactions perhaps ) and see whether that improves the fit , because a failed hosmer-lemeshow test often relates to a misspecified model . the low auc could mean model misspecification or just predictors that are not very strongly associated with the outcome . do you have other data you can bring in ?"
271034,how many proportions do you have ?
271046,how many categorical variables are there ?
271059,why not use multilevel model ?
271064,it would help to know what your scientific question is . do you want to be able to say that habitat a has more species than a' ?
271071,i think you mean 0 . 05 in the title not 0 . 5 ?
270968,levels are coded as dummy variables . what exactly is your question ?
271086,"since there are simple closed-form solutions to the continuous version of this problem , why not use them as initial solutions to the discrete version ?"
271088,what would be the goal of such an analysis ?
271065,"i cannot see anything wrong with rhat . to get some more useful answer , we need more details , like how do you obtain your data ?"
270763,it depends on the size $ m $ of the binomials and on the value of $ p_0 $ . is $ p_0 $ an  priori known value ?
270655,what do you mean by lm ?
271144,what are you optimising here ?
271215,are you interested in the interactions with weeks ?
271240,how many cases do you have in the lowest-frequency outcome category ?
271238,we need more information for this to be answerable . what are your variables ?
271333,how does $ alpha $ relate to $ theta $ ?
269964,"1 ) auc 0 . 69 sometimes is all you can get ; 2 ) i would try either an ` xgboost ` as aarondefazio suggested or a ` glmnet ` ( much simpler ! ) ; 3 ) sampling is not always a good way , from my exp . using raw data gives better results ; 4 ) be careful with pre-processing ; 5 ) ` maxdepth = 25 ` is a lot , have you tried 2 or 3 first ?"
271407,can you explain the term 'random effects' please ?
271415,the sample mean is not magically normal when the sample size exceeds 30 as the insert suggests . where did you get that the observations were bernoulli ?
7307,"so what you're after for the first pair is a proof that the median , as usually defined as the middle-rank value ( for an odd number of values anyway , to start with the simplest case ) is also the value that minimizes the sum of absolute deviations ?"
271392,"amirrahbaran if the image is the data , why is it not also a sufficient visualization of the data for your purposes ?"
271488,if that were the case amoeba why is there mostly code in the question ?
271499,"you've already listed your coefficients , why is the equation not known to you ?"
271100,"how did you obtain the10 samples . any reason to expect systematic differences between the 10 samples , like if they constitutes blocks in an experiment or samples from different subpopulations ?"
271528,"i am not the downvoter but this question is currently automatically flagged as low quality for its length and content . could you spell out some abbreviations , and use the question to body to give a little bit of background to the problem and what your reasoning is , rather than just restating the question title ?"
271446,you do not have enough detail to sufficiently answer your question . what variables do you have ?
271573,"i am afraid that "" useful "" is a * very * imprecise concept . what makes the estimate "" useful "" ?"
269314,where did you read that the ols estimator is inconsistent for non-stationary ar ( 1 ) ?
271598,don't you have to invoke package = 'powerlaw' upon reading in the data ?
271606,"if i understand correctly , you have a network that has already been trained on a dataset containing temp , wind , and humidity . i don't understand the situation with the new dataset . is it the case that : 1 ) all points contain only temp and wind ?"
271216,my inclination would be to use $ chi ^ 2 $ with m1 as expected and m2 as observed . is there any reason why you rejected that idea ?
271618,why does it matter to you how to represent interactions graphically ?
271628,how do you know the sex of the lobster ?
271556,why do you want to compare them ?
271662,"just looking at this chart isn't too informative . to develop a * statistical * estimate , more information is required that might help explain the evolution is processing time . can you explain and elaborate on the component parts that went into this highly aggregated , summary chart ?"
271669,what is a scobit model ?
271679,are the partner pairings the same from trial to trial ?
271714,"you'll need to specify what the graph represents , and is it labelled , directed or undirected ?"
271768,why do you use 5 layers ?
271806,"personally , i have no idea what you're talking about . why not create a contingency table of the as , bs and cs to examine the cross-purchase patterns ?"
271826,michaelchernick i think the lecturer is right . we can use anova table for comparing two models ?
251073,is it a homework ?
271852,is your estimator of the likelihood ( not log likelihood ) unbiased ?
271653,"your overloading of the symbol "" $ v $ "" to mean ( apparently ) "" variance "" as well as the covariance matrix $ v $ makes this question very confusing . could you clear up this ambiguity ?"
271878,"michael use the normal mle for variance : it works even with one value ( and is zero , but so what ?"
271924,can you please remove the scan and type the exercises using $ latex $ ?
272028,are you referring to a permutation test maybe ?
272061,"i am very interested in your question and posted a similar one about calibration plotting some weeks ago ( url alas , no answer as of yet ) . as to your question , randomly picking a dataset to plot is indeed considered a viable option , but i guess you'd also like to account for the uncertainty of imputation . which plots are you interested in ?"
272062,are you looking for hints and guidelines or for someone to actually design this simulation for you ?
272005,"if the graph on the top rhs is a pmf , why do the sum of the probabilities exceed one ?"
272152,can you clarify your situation ?
272166,it's not clear what you actually want to use these topic models to do . what are you trying to disambiguate ?
272178,is simultaneous equation models your want ?
272163,it's unclear what you're proposing ; a naive reading of your plain words makes no sense to me at all . how would making the covariate a * weight * be a suitable substitute for it being a covariate ?
272218,what article ?
270827,"please explain what you mean by "" significant . "" ordinarily this word has a statistical sense in the context of a hypothesis test : so what is the null hypothesis you have in mind ?"
231406,"given the heavy use of code and output , consider emphasizing the general ( non software specific ) nature of your question . the purpose of the graphics is unclear , because they are offered without any commentary or interpretation . are they really needed ?"
272267,so do you want to predict whether or not the plant will grow ?
272276,what do you suggest ?
272280,"wow , that's high . i got that reference from the book "" sample size determination and power "" by thomas ryan . do you have access to this title ?"
272298,""" interaction model not significantly different from linear model "" according to what test ?"
271443,"could you elaborate on the connection you see between characterizing a distribution and "" forecasting future samples "" ?"
272308,the espn piece explaining there soccer power index has been removed from their site . was nate silver's piece a question on cv ?
272318,can you explain how you used the bootstrap in your code ?
272295,what is the model ( for those not used to reading python code ) ?
26328,$ k $ independent trials per unit ?
272334,are you familiar with ( hidden ) markov models ?
272364,andrisbirkmanis what about map estimators ?
272377,and one more thing : what do you actually expect the interest to depend upon ?
272383,why would you want to modify your dataset so that it fits a particular model ?
270515,can you clarify which measurements you want to compare ?
272269,"i find the question presentation long and confusing and the clarification makes it even more so . can you state in two sentences , what is the question that you are trying to answer with the data analysis and why an answer provided by a multiplicative effect size is not satisfactory ?"
272450,can you please give a concrete example of how a few of your data-points look like ?
272494,could you explain how you obtained that confidence interval for $ beta_1 $ ( presumably it corresponds to ` height ` ) ?
271705,"the standard advice is to not use tsne for clustering , because the clusters are so dependent on the perplexity . it is supposed to only be used for "" visualization "" . but that isn't very clear to me , as one immediately looks for ( and sees ) clusters when looking at a tsne plot . therefore your question is a good one : what is tsne good for ?"
272508,how much data do you have ?
272052,could you be more specific on what exactly do you need it for ?
272528,"this sounds like an exercise question - see url however , i don't understand the problem - what are "" probability getting product a "" and "" % cause damage on product a "" ?"
272385,are you asking or telling ?
272551,"what , pray tell , is a psu ?"
272324,what do you mean by conditions ?
272629,have you seen this paper ?
272585,"question is a little broad , yes , but interesting ! to the op : can you please add details about your real application ?"
272647,"you've tagged your question with ` t-test ` , so you have an idea about where to start . what have you tried so far ?"
23479,what setting are you talking about ?
104116,"it is unclear what your data really are or what exactly these polynomials are representing . what is the actual distinction between "" some of the data "" and the "" full data "" and how is that related to the grouping ?"
272723,you must give more details for this to be answerable . is this multinomial logit / probit ?
271357,"could you spell out your acronyms , please ?"
272702,what is it you're interested in finding out about the two groups ?
272753,"both terms are essentially synonymous , are they not ?"
215216,looks like you forgot to write the 'log' in your logit function . . . and what happens if the input values are 0 or 1 ?
272729,could you make your question more precise ?
272793,have you tried tuning the regularization parameters ?
272831,i am confused on what you are asking . you can add two matricies of the same size because matrix addiition is well defined . but why are you doing that in the first place ?
272172,what you do ought to be motivated by the purpose of the analysis . why are you doing it ?
272843,"michael is correct . however , since the $ chi ^ 2 $ test is perfectly applicable and highly significant ( $ chi ^ 2 = 29 . 27 , p = 6 . 3 times 10 ^ { -8 } $ with continuity correction ) , and the bootstrap produces a p-value of only $ 0 . 2 $ , something is amiss . perhaps there are other covariates ?"
270068,can you provide more information about the outcome ?
272810,"glen_b , why isn't this closed as opinion-based ?"
272912,"are these "" given years "" within the range of your dataset or are they outside the data range ?"
272929,could you indicate which part of this notation you do not understand ?
272863,what's the response variable ?
231482,"1 . what would be optimal depends on the distribution you're sampling from ( not just its skewness coefficient ) . . . generally the point of using a robust procedure is to choose something that does reasonably well across a variety of possibilities , not something that optimizes a particular case . ( unless i mistake your meaning and your proposing some adaptive robust procedure or something ) . . . 2 . unbiased estimate for what ?"
16732,"what do you mean by "" measure of central tendency "" ?"
272958,how dynamic do you expect your speed to be ?
272922,i couldn't locate a book with that title . do you mean the book by devore ?
272961,what's wrong with aic ?
270379,"just to understand , you find the 'single cells' by some marker and then define some single-cell characteristic ( eg nuclear morphology , surface stianing , etc ?"
272941,could you be more specific ?
199280,another thing i always found puzzling was the appearance of $ sigma $ -fields in martingale theory . is there any reason to say we're conditioning on $ mathcal { f } _n $ instead of the past up to time $ n $ ?
272430,"interesting question . the "" choice "" of a breakpoint does seem odd . are you interested primarily in understanding the behaviour of r's breakpoints ( ) function ?"
273031,"and i don't know what your "" observed d "" is , actually ?"
272881,"the requirements of boundedness makes things more complicated . rational function fitting could solve all of your problems , but it's definitely not a robust approach : it will likely succeed on a data set and fail on another one , without warning . the second question you quote is actually quite a good suggestion : ` mgcv ` is a great package , and unless constrained polynomial regression is good enough for your application , you won't get out of this without using some specialized packages ( or reinventing * * a lot * * of wheels ) . why don't you show us your data , so that we can help you better ?"
273068,"what situation ( s ) are you talking about ( e . g . what research question , kind of data , kind of model , etc . ) ?"
273095,"i have written a package , to be submitted to cran in a few days , which is currently [ available only from github ] ( url ) . you could install it and try the ` ggpredict ( ) ` -function . in the help ( ` ?"
273114,there are four tests reported by ` mts : : marchtest ` ; which one is giving you the strange results ?
273111,"you cannot obtain a unique solution for two variables from the single last equation . generically , though , two equations in two unknowns have a discrete number of solutions , typically just one . could you therefore expand on what you are looking for in way of an "" explanation "" ?"
273161,could you provide a link to show where this is said and why it is said . ?
6907,"in what "" natural sense "" are these curves "" not that distinct "" ?"
273123,why should it be . . ?
273185,"carl , exactly what kind of limit do you have in mind ?"
273202,do we know anything about the distribution of error term $ epsilon_t $ ?
273222,yes but not on software . why do you think the other post is on so ?
271582,could you please clarify what you mean by * intersection area * ?
73175,which three parameter gamma ?
272896,"in your real dataset , are there also three features per data-point ?"
273311,why would you recode the answer as proportions and then do a poisson / negbin regression ?
273329,what do you mean with baseline ?
273218,can you edit the question to state your * * goals * * more clearly ?
273345,"is there any reason to believe that there will be serial correlations within the runs ( eg , the 1st run will be more like the 2nd than the 4th ) , or that runs within a series will be more similar that runs in a different series ?"
273372,what do you understand are the reasons for using the different types of t-test ?
273383,"i think [ lstms ] ( url ) are the way too go . secondly , you say 'compute spectrum coefficients , spectral rolloff , etc . ' ( i have no clue what some of those things are' . but why do you need to compute these ?"
273397,"i assume you mean $ beta = 1 $ , as $ beta = 0 $ is , with a notably rare exception , the same as $ beta_ { y g } = 0 $ ?"
273434,how many labeled images of your own do you have ?
273382,what does n stand for ?
273463,which kind of f are you doing ?
260889,"you assume that people in real-life make such structured , logical arguments ?"
273498,"there are possibly infinite ways of plain binning a continuous variable of any range $ [ a , z ] $ into a nominal / ( ordered ) categorical one . then there is also the choice of the amount of bins , and whether or not bins should be of equal size ( both in range as in amount of observations in them ) . any standardized way will therefore have arbitrary choices , which might not be appropriate for your research . so why lose information and bin ?"
273496,what kind of alternative are you looking for and / or what kind of information other than odds ratios and p-values for significance are you looking for ?
273509,so basically you want to select a model rather than evaluate a given model ?
5430,is the peak at around 7m the * only * object ?
10981,can the same number be selected twice ?
28230,do you mean your dependent variable is 3-dimensional ?
32815,kernel density seems like a reasonable way to go . if the kernel used integrates to 1 then by construction the probability will integrate to 1 . some more information on the parameter space would probably be helpful . approximately how many parameters are there ( 1 ?
56316,"1 . some fine points : ( 1 ) $ s ^ 2 $ has the ( noncentral ) chi-square distribution , not $ s $ . ( 2 ) you seem implicitly to assume the two conditional distributions $ m l_i $ are uniform over the sphere ( s ) . because this does not mean uniform "" on all the angles , "" i just want to make sure of your assumptions . ( 3 ) why do you invoke n-p in a setting that is bayesian ?"
68030,"alecospapadopoulos , here is an arxiv paper that might be what you are looking for ?"
117973,this already received an [ answer ] ( url ) on mse two days ago . why do you keep cross-posting ?
126351,"you might find interesting related material in our thread at url to avoid potential confusion among some readers , i would like to add ( and i hope this was your intention ) that your question should not be read as suggesting that all or even most actual datasets can be adequately approximated by a normal distribution . rather , in certain cases when certain conditions hold , it could be useful to employ a normal distribution as a frame of reference for understanding or interpreting the data : so what might those conditions be ?"
155037,i must be missing something . you're asking how to show that the covariance of any random vector is non-negative definite . what does this have to do with $ a $ or $ b $ ?
133083,the answer you linked makes an analytic solution seem very unlikely . what's the reason that a numeric solution won't suffice ?
217995,"` optimization problem ` yes pca problem could be solved via ( iterative , convergent ) optimization approaches , i believe . but since it has closed form solution via maths why not use that simpler , efficient solution ?"
183175,"great question . ( 1 ) in your third sentence , do you mean "" the sign of the eigenvector components of the largest * * eigenvalue * * of the laplacian determines the class assignment of the vertices "" ?"
246212,"i guess that you are dealing with large samples , so using $ n-1 $ instead of $ n $ would not make any noticeable difference , isn't it ?"
190942,"it is unclear what you mean by "" find the distribution parameters , "" because you have not described any parametric family of distributions at all , and in fact you go on to point out that there isn't any such family under consideration . the rest of your post seems to be asking us to tell you what the question should be . could you therefore please explain what the statistical context of this question is and what really is the problem that you face ?"
210698,"your notation is confusing . when you write $ a sim n ( x , x 1 ) $ , do you mean $ a $ follows a normal distribution with mean $ x $ and variance $ x 1 $ or $ a $ follows a uniform distribution on $ ( x , x 1 ) $ ?"
263499,"people speak different language , and different software have different default setting and syntax . why that is a problem ?"
203216,"maybe one way to address the question is to ask , what happens in linear mixed models when the model matrix is not full column rank ?"
210145,"more directly - as far as i know , "" expliciting "" is not a term in english ( i've only ever seen it arise when a french speaker is writing in english and i've never figured out what it's intended to mean ) . does it mean "" to make explicit "" or does it mean something else ?"
232816,"not quite related to your question , but i need to have a quick review of equality constrained optimization , do you also have a lecture slide for that ?"
236881,"you should add the [ tag : seasonality ] tag . what is your "" signal "" , i . e . what would be the $ x $ axis in a $ x [ t ] $ plot ?"
252354,why is that unfortunate ?
25870,if you only have $ n $ possible outcomes then your random variable can't be poisson distributed . or are you saying that you have several observations from a poisson r . v . and that you summarize those observations in a histogram ?
102835,are your ` tt ` levels ordered ?
31735,"what do you mean by the "" main probability curve "" for a logistic model ?"
74718,"as much as i like the discussion topic , this question is very broad and seems to be requesting opinions . as such , it's off topic for cross validated . is your question the title or all of the many questions within ?"
53102,"in effect this is your second go at this -- compare url -- but not much is happening here . concentrating on the stata side of this : did you look at the code of ` psmatch2 ` ( btw , a command , _not_ a function ) ?"
74350,i found your description of the conditions and problem a little difficult to understand at first . type i and type ii are technical terms that are different to your usage of type1 subgroup and type2 subgroup . as far as i can tell you are applying a t-test to data from a distribution with a mixture of means . is that right ?
126990,there is no study id variable in the dataset . are these supposed to be 10 studies ?
113851,what happens when you sample $ n 72 $ ?
171262,not sure i understand what the advantage would be . basically you are applying a function before feeding in the input to the network already ( the 0 or 1 decision for both inputs is the function i am talking about ) - why would you not model this function as part of the network ?
117549,"however , it's not clear why you would need normality . what are you trying to achieve ?"
76662,"i still do not see how fisher's distribution would apply . could you explain the sense in which balls are "" drawn at once "" with different * weights * ?"
161757,have you looked into [ aic ] ( url ) ?
143999,"have you looked at [ a forecast comparison of volatility models : does anything beat a garch ( 1 , 1 ) ?"
226359,could you elaborate on why your outcome is sites and not counts of insects ?
226270,have you looked into the perturb package in r ?
237636,` would there be anything to gain by enforcing the triangle inequality ?
38530,"like tomas i know of no reason you shouldn't transform variables before a mixed model , and i've read quite a bit on this topic . i've got the ramon and littel book . . . . what page are you referencing ?"
248643,"deltaiv , are you sure you mean probability theory and not statistics ?"
210798,"tis from the bard : macbeth act ii sc 3 : "" _who can be wise , amazed , temperate and furious , loyal and neutral , in a moment ?"
252037,would bernie sanders have qualified as an independent ?
253081,"loading ` library ( nlme ) ` is unnecessary , no ?"
6976,"pchalasani , does ltcm count ?"
248401,just for the context : what happened between t1 and t2 ?
11433,is it safe to assume that the data are being generated by the same process over time ?
176203,to answer it is important to know your data generating process . are these zeroes to be taken seriously ?
6967,why do the approaches described in the question you mention not work for you ?
44400,"if you rewrite the original model as $ y sim b frac { x_0 } { x_1 x_2 } $ where $ b = frac { a_0 } { a_1 a_2 } $ then you can identify $ b $ -- e . g . by the kind of log-transform you suggest , or through a nonlinear least squares model , or through a glm , or a number of other ways - but you cannot identify the individual $ a's $ in your formula . ( is this worth working into an answer ?"
31925,would the proportion of $ 1 $ s vs . $ t $ be useful ?
249884,""" * what's clear is that the type ii ss results from the car packaged produced results analogous to the type iii ss results from the lmertest package * "" wait , how is that clear ?"
260847,there's definitely no closed form solution . why did you feel there must be ?
261774,"have you trained an lda model for each party , or just one across the entire corpus ?"
134084,"this still appears to duplicate your previous post , which itself had already been answered . one answer to the [ duplicate of that post ] ( url ) states "" p-values are arbitrary , in that you can make them as small as you wish by gathering enough data . "" doesn't that address both # 1 and # 2 ?"
70984,"answering your question : obviously not , you cannot perform 91390 . it is not feasible and i don't think it could be interesting . instead , you use a representative proportion . in my opinion , i think that 100 would be more than enough . why 100 ?"
137702,"also , do not forget that a "" significant "" p value does not tell you anything about your theory . this is even admitted by the most ardent defenders : [ precis of statistical significance : rationale , validity , and utility . siu l . chow . behavioral and brain sciences ( 1998 ) 21 , 169 239 ] ( url ) data is interpreted when being turned into evidence . the assumptions an interpretation is based on need to be enumerated and then , if possible , checked . what is being measured ?"
159418,what do you mean ` uniform data ` ?
135595,"what exactly would it mean to "" solve for $ c $ "" ?"
165035,which part ?
137001,"how comfortable are you assuming that the process of generating a sale at all vs no sale , and the process of generating a certain $ value of sales given that at least one sale is made , are different ?"
140250,in what sense does the dispersion differ by group ?
140645,what is the vif ?
152202,"1 for a very good question . since p , q are discrete values it may be more efficient to do a grid search to find optimal order of p , q ?"
232300,"your previous question and this set of questions suggest you understand at least some of the terms "" random variable , "" "" realization , "" "" experiment , "" "" distribution , "" and "" population "" in unconventional senses . these questions are puzzling because they use the words in ways that don't quite make sense . so that your post can be answered , could you please ( 1 ) narrow it to a single question and ( 2 ) define , as clearly as you can , the technical terms that you are using ?"
179281,"by standardizing , do you mean both centering and scaling to a standard deviation of 1 ?"
184519,why don't you just use a propensity score ?
236564,"could the fact that a "" maximally supported "" student might receive 95 on the student scale and 75 on the teacher scale not be seen as something similar to difficulty within irt , particularly with polytomous scales ( i . e . if items used a four-point rating scale then a person may be reasonably expected to respond with four on an "" easy "" question , but respond with 3 on a more difficult question ) ?"
66655,have you checked out analysis of financial time-series by ruey tsay ?
95994,"i am somewhat curious why you would choose non-central student-t components , because they are not very computationally tractable : they have only a limited number of moments of small order and most of their properties are difficult to compute . what theory of the genesis of your data leads to such a mixture model ?"
184204,"you also need independence of the numerator and denominator . if the values are iid normal , you should have all three at once . however , "" * i wanted to see this in a simulation * "" needs to be rephrased to be in the form of a question , since it's not especially clear what you seek . what is it you want to know ?"
145037,why do you expect a cross-validation approach described in your question to be reasonable ?
97093,"i think simple random sampling without replacement should work . i'm baffled that you are getting overestimates . this looks like it maps exactly to estimating a population mean using the sample mean from a random sample . you are trying to estimate the population probability that an element of $ a_0 $ is in the intersection of the other $ a $ s . i've noodled with a simple example , and it works fine . how sure are you that you are consistently overestimating ?"
267633,have you considered the euclidean distance ?
270675,"btw , i cannot see your error codes above . would you point them out for us plebs , please ?"
200017,"could you explain the sense in which "" bootstrapping "" would serve to build and fit a regression model ?"
62677,"but that's the case with many other techniques as well and i think patrick's point is reasonable . also it was merely a comment , no need to become aggressive . generally speaking , why would you assume that there should be one true algebraically correct way to approach the problem ?"
88398,"would you mind explaining why it is unavoidable , since variable selection does not help with the "" too many variables , too little sample size "" problem ?"
20425,at time t do you know what was in the basket at time t-1 ?
163262,have you computed that $ 1 / 20000 approx ( 1 / ( 1 0 . 01 ) ) ^ { 1000 } = 1 / ( sigma_p / sigma_q ) ^ d $ ?
34059,why is an exchangeable covariance matrix structure appropriate for your data ?
22494,"hi max , how is the score from the test use ?"
29811,"sorry , i dont know how to answer your question buy i am quite interested on what you mention on re-calibrating the results of random forests using a logistic model . could you give me some pointers on that subject ?"
30514,tripped up our very own jeff atwood do you have references for that ?
59142,"i presume they mean [ this ] ( url ) , re : "" * i used spss , and i get a significance level ( . 0xx ) , not a t-stat * "" - what did you do , what output did you get ?"
78455,"the differences in $ b $ and $ x_0 $ do not appear large : check their standard errors . the difference in $ a $ is due to a basic mistake with logs : $ log ( y ) = log ( a ) b log ( x-x_0 ) $ ( which i guess is compensated for in the last line ) , whence the "" a "" in the log model should be close to the log of the "" a "" in the original model . when this change is made ( by replacing "" a "" in the first model with "" exp ( a ) "" ) the changes in all three coefficients are within the ranges indicated by their standard errors . in short , all appears fine : is there really a problem to be resolved here ?"
222767,"for the most part , these comparisons have already been done in multiple papers . see this one titled * do we need hundreds of classiers to solve real world classication problems ?"
88166,"you cannot have $ h_0 ! : p ne . 5 $ as your null hypothesis , hypothesis testing doesn't work that way . see my recent answer here : [ why do statisticians say a non-significant result means "" you can't reject the null "" as opposed to accepting the null hypothesis ?"
240202,"how were the "" calculated values "" obtained ?"
200745,does crossvalidated have any collections ( e . g . community wikis ) of simple simulation examples of p-hacking ?
245241,"that author must have a different definition of "" logistic regresion "" than i have . write him and ask ?"
81121,"can't you work with an unbalanced panel , where some periods miss , and use a dummy for adult as nick stauner suggests ?"
232829,"could you try using ` type . measure = "" deviance "" ` in ` cv . glmnet ` instead of ` type . measure = "" class "" ` ?"
180040,how about rigorously checking if your data is time invariant ?
200456,"welcome to our site ! could you give a full reference for "" mudholkar and hutson ( 2000 ) "" , as you would find in a bibliography or references section i . e . one that includes the title of the paper , name of the journal etc ?"
64829,can you provide the code that you ran to get the kappa ?
229904,"i don't see any place where you have informed spss that each of the nine values is the mean of 105 others , nor do i see where you have specified the nine associated standard deviations ( or variances ) , whose values are essential for doing the tests you propose . i also don't see any indication of "" significance "" in any of the output you have shared with us . consequently i suspect that you really want to do something completely different . what exactly is your research question ?"
142365,can you tell us more about these numbers ?
229723,"is it that you want to know the standard error , but don't have access to it ?"
229794,""" i want to find out the level of effect of each treatment in standard deviations from the mean of the control "" would it matter to you if treatment 1 had very high ratings for product 1 and very low rating for product 2 , while treatment 2 made no difference to the ratings ?"
273473,do you have many $ s_ { n } $ 's ?
50017,that seems to be a good reference in psychometrika that you linked to . . . so are you looking for an explanation of that paper in a simpler language ?
3101,can you explain why this is a pyramind and not a triangle ?
230354,"i don't follow this at all , because ( 1 ) you have already estimated $ sigma_x $ and ( 2 ) the rest is purely a linear algebraic question . obviously you're not looking at it this way , which suggests there's more to your situation than you have disclosed . could you clarify ?"
45965,could you fix this up so it's more understandable ?
235106,"if you are trying to predict t steps ahead , can't you create a training and test set and then see how accurately the output transition matrix matches the true total counts of the observed states ?"
2615,"also , on re-reading your question it is not clear what you mean by "" minimum eigenvalue initial correlation matrix "" . could you clarify what you mean by that term ?"
240289,"have you tried a generic root-finding or optimization method , such as r's ` optim ` function ?"
241523,is this the same 137 people for all options or is that just a coincidence ?
38111,isn't this terribly obvious when you note that an orthonormal basis for $ mathbb { r } ^ n $ can always be constructed by extending any orthonormal basis for $ u $ ?
79399,did you look at the answer by jeromy anglim in [ here ] ( url ) ?
62545,whuber nothing there on unit roots ?
63302,""" * i believe it is necessary to find the distribution of the data * "" --- whereas i believe it's impossible to find the distribution of the data , and in any case , usually pointless since -- for the models you mention -- the unconditional distribution of the data is not something assumptions apply to . what are your response variables , and what are your predictors ?"
63913,"so , what specific estimates don't match ?"
138550,"this question is close to the one yesterday at url glen_b's answer there would go a long way towards addressing this question , too . the key is to pay attention to the error structure as well as to the possible form of the relationship ( the "" link "" function ) . i would add that the premise you should have a standard default ( "" go-to "" ) model to try in all circumstances might be overly limiting and counterproductive . why not instead adopt a standard set of procedures to help select and identify appropriate models , without favoring any particular one ?"
128658,what is a symbolic representation of the time-series ?
18975,how would you interpret $ c_ { 2k } ^ k $ ?
74263,"first , what's wrong with the full model ?"
164641,"can you post ( some of ) your data , or a plot , such as histogram or dot plot ?"
137092,"are you running separate tests on each person , or are you running one test on everyone ?"
35905,i don't quite understand how this works . lifereg is a form of regression model that is structured to fit survival curves which have special constraints f ( t ) = 1 at t = 0 f ( t ) goes to zero and at least in the limit as t approaches infinity f ( t ) approaches 0 and f is monotonic nonincreasing . nlmixed fits a nonlinear model with mixed effects and no particular constraints on the response variable . how do you force the constraints and the form of the model in nlmixed to match the form of lifereg and guarantee that you are using the same estimation method ?
252206,"so is the issue that voltage level is a binary variable , & you want to force it to be included in the clustering ?"
252907,i advise that people should always look at the data prior to making inferences on the basis of statistical tests . how large is the difference in length between the dead and living sparrows ?
229354,"whuber : i did not notice that the op deleted that comment after i posted my answer . probably only myself and amoeba read it originally . hxd1011 , can you please add this information to the body of the original question ?"
147288,"the formula you quote , although often referred to in brief as a "" standard deviation , "" actually is not a standard deviation : it is an * estimator * of a standard deviation . i also notice in the thread you reference that one of the highest-voted answers states the sd is [ a "" version of "" the l2 distance ] ( url ) rather than the l2 distance itself . regardless , since dividing by $ n $ or by $ n-1 $ before taking the root is algebraically identical to dividing by $ sqrt { n } $ or $ sqrt { n-1 } $ after taking the root , doesn't that fact alone fully answer your question ?"
109129,why only ` belief that ice cream consumption causes murder ` ?
262708,"i work with economic data , but i have proven that it impacts biological research as well . your data sounds like my data . do you have exponential growth involved ?"
186096,"$ sigma ^ 2 $ is a scalar , why don't you take it out in front ?"
144076,are you wondering how to get r to give this to you ?
270978,"in ( 1 ) you're conflating two issues : see michaelchernick's answer [ here ] ( url ) . also , note that bias isn't the only desirable property of an estimator : see [ why are we using a biased and misleading standard deviation formula for $ sigma $ of a normal distribution ?"
210238,where did you see this ?
221074,"out of curiosity , how many observations do you have for each sample ?"
23225,will the images always have the same colour background ?
11544,have you found a clear solution ?
110426,` metrics to measure the overall correlation ` . you are thinking specifically about the determinant ?
222855,"is your sum over all pairs , $ x_i , y_j $ or did you mean something else there ?"
93352,what happens in ` r ` when you initialize the solver with the solution found by stata ?
97564,"a general solution is explained in my post at url there are , however , multiple different meanings of "" weights "" in statistics . ( for this reason some software such as stata supports up to * four * different kinds of weight calculations ! ) in light of this could you clarify what your weights are intended to mean or explain how they arise ?"
83030,do you have a lot of groups ?
144761,"what do you mean by "" standard "" when you say biplot ?"
145418,what are their definitions of hazard and survival ?
223711,"can you explain what you mean by "" the transition probability does not exist ( and we do not need to learn it ) "" ?"
205485,"possible duplicate of [ what is "" restricted maximum likelihood "" and when should it be used ?"
160646,"nmds , rda , cca . . . what are all these bright acronyms ?"
194035,related : [ is there more to probability than bayesianism ?
243564,have you looked at these lecture notes : url ?
247632,"it is generally hard to solve optimization with equality constraints . is there any way you can relax the "" = 0 "" constraint ?"
11328,this question has a lot of overlap with your two other questions at url and url please follow whuber's suggestions to improve them . has your first question ( ` error ( ) ` problem ) been sufficiently answered ?
204359,can you assume they have the same known parameteric form ?
265856,your fourth ( last ) bullet suggests you aren't computing confidence intervals : you seem to be asking for the * coverage * of a * prediction limit * . is that a correct interpretation ?
29758,can you describe the data more clearly ?
50712,"when you say "" $ c_1 $ is two gaussian variables "" do you mean a mixture ?"
22955,"if you fit one time-series to the pre-shift data in 2009 and a separate series to the post-shift data , what do your two times series look like ?"
52691,have you at least tabulated them one against the other ?
48739,"well , have you looked at a correlation matrix of krjxxx variables to see if they are highly correlated ?"
61547,can you share your dataset ?
7450,"to be clear , what precisely are you right-truncating ?"
184576,"in your displayed $ sigma $ matrix , the entries on the first two lines should be $ sigma_a ^ 2 $ and $ sigma_b ^ 2 $ , not $ sigma_a $ and $ sigma_b $ . also , could you not have picked * * any * * other symbol than $ b $ for the transformation matrix seeing as how you already used $ b $ in $ y_i = a b x_i z_i $ ?"
164804,i don't see anything in your code that would correspond to simulating data according to the null hypothesis of a normal distribution . could you show us where that would be ?
183218,"in the hopes answers to this don't get diverted into specifics that don't necessarily relate to the problem -- is this question more about * variance * per se ( for which discussion of squaring might be relevant ) , or the more general * concept * of variability ( dispersion , spread , variation -- for which it wouldn't ) ?"
137587,what do you mean by non-linear ?
234240,"could you clarify how a * count * could be "" non-integer "" ?"
41416,what do you mean by mediate in this case ?
46473,what answer do you believe is correct and why ?
239287,adding some of your data in the post will help give proper answers - how are the categorical variables constructed ?
142215,how did you create the decision boundary ?
158386,what about mcnemar's test ?
169564,"1 , very clever i see nothing wrong with the approach , s . e looks good , i'm not sure which s . e . you are referring ?"
249143,( 1 ) why do you think that a should be equal to cl' ?
243356,the seems like the same question you asked a few hours ago : url could you update your previous question instead of posting a new question ?
254497,can you clarify how your question differs from the one you cite ?
73950,"is your goal essentially to be able to sort your records by p ( category = 1 ) , & you don't want any ties ?"
79817,"interesting question . a couple of comments -- ( 1 ) ` rpois ` will generate from a vector of lambdas as is , you don't need to go through all that trouble to get it to do that ; ( 2 ) why do you say the fit should be exact ?"
88592,what ` earlier question ` ?
88862,is one of your categories particularly common ?
262500,have you looked at the documentation of the residuals function of ` survreg ` to figure out what it produces ?
93723,$ sigma $ is variance or standard deviation ?
12597,"what is a "" suck point "" ?"
95864,"is the dependent variable is dichotomous ( wants to go college , doesn't want to ) or ordinal or what ?"
212100,"because "" logged data "" is a ( terribly informal ) way of saying "" if the data are logarithms of the quantities you are taking the ratios of . "" if you're not taking logarithms , then why do you care at all about this quotation and what follows it ?"
269428,"it's unclear what needs a "" proof . "" since the sign of an eigenvector is arbitrary , you can use any procedure you like to set it . could you show us specifically how your question differs from the one you cite ?"
23874,"have you read baayen , davidson , bates ( 2008 ) , "" mixed-effects modeling with crossed random effects for subjects and items "" ?"
271553,some questions : how large is your dataset ?
28815,"what do you mean "" too trivial "" ?"
174220,"have you read [ this ] ( url ) , and explored the package { epimodel } ?"
83777,"yes , clearly similar . in fact , what's different ?"
41443,"if it is about r , could you mention it or add the r tag ?"
112705,what difference would the back-conversion make ?
124306,"why wouldn't a bic work or a test of the difference in the log-likelihoods , particularly since one is a nested version of the other ?"
117258,i am not at all sure the original argument covers hmms . you mention in other questions people using bic for hmm in papers . do they give some justification ( or refer to any ) for the form $ -2 log cal { l } p log ( n ) $ in the case of hmms ?
121875,"the sign is arbitrary is you reverse it for the whole factor only . you can't change it for only part of the factor's loadings . you say ` for rating set a . . . items 6 : 10 load positively on factor 2 , while for rating set b . . . items 6 : 10 load negatively on factor 2 ` . here one wants to ask - what's about loadings of items 1 : 5 with factor 2 ?"
164768,"your question is somewhat puzzling , because almost every formula for the variance ( or other moments ) of distributions applies to * all * distributions . what formula ( s ) do you know ?"
225265,why wouldn't you cross-validate using the same metric you are optimizing for in the test set ?
231529,"is "" ( link ) "" supposed to be a hyperlink ?"
223348,stepwise selection does not improve any aspect of estimation . what made you think it did ?
72970,i tried to resist but could not . have you read arthur goldberger's wonderful chapter on micronumerosity ?
255020,"` and set the number of factors i am expecting ` the purpose of efa is to set the number of factors [ m ] which is both ( or a compromise of ) best fitters of the data and most interpretable . this implies _exploration_ among several alternative ` m ` . if you are going to consider one predefined ` m ` ( "" expected "" ) then why not proceed straight to cfa using some or all the paramenrs from the literature , to test if they fit the data ?"
94839,what is p $ ^ 2 $ ?
255675,what are _objects_ to cluster ?
115090,how many times was each subject tested / sampled ?
202604,it is unclear how the post you are referring to answers the same question ?
64654,hint : the relation $ { rm e } ( u_i u_j ) = { rm e } ( u_i ) { rm e } ( u_j ) $ holds for all $ j $ except one . which one is it ?
26764,can you say more about what you want to do ?
72196,have you read through this chapter of the [ probabilistic programming and bayesian statistics for hackers ] ( url ) book ?
187098,"could you please clarify what you mean by : "" the cost of going to the next arm is c times the cost of a pull "" . is the cost of the pull a separate constant ?"
177486,could you please add a link to the previous question ?
228818,is $ x ( t ) $ a gaussian process ?
166525,"interesting edit . if your code produces some figure ( s ) , could you maybe insert them in your question ?"
231285,"classification trees / random forests , as i'm aware , can take categorical predictors directly and handle them properly . you don't have to one-hot recode them , do you ?"
245020,how do you intent to smooth the standard deviation ?
245811,what do you mean with encoding one options as -1 ?
245909,"* * hint * * : set $ s = x'x $ and note that $ $ s ^ { -1 } - w s w = ww ^ { -1 } s ^ { -1 } w ^ { -1 } w - wsw = w ( w ^ { -1 } s ^ { -1 } w ^ { -1 } - s ) w , $ $ and simplify the middle matrix using $ w ^ { -1 } = s lambda i $ . conclusion ?"
245918,what is your * * research question * * ?
231618,"i'd love to help you , but i'm honestly lost . what is it about your current formulation that dissatisfies you ?"
155214,"what exactly is "" $ x $ "" ?"
198915,could you clarify your intuition ?
11178,what is your question ?
16605,is your interest in the data or in writing the program ?
17468,"the correction for multiple comparisons is about your three correlation tests ( where $ h_0 : , rho = 0 $ probably ) * and * comparisons for your pairwise correlation values ?"
155087,"do you mean $ y in mathbb { r } ^ n $ , i . e . $ y $ is a random vector ?"
101413,shouldn't you do ` ~ 1 ph * temp tank ` and ` error ( tank / ( ph * temp ) ) ` ?
49607,"two of the factors are defined with only a single indicator , which if i'm not mistaken would make the cfa under-identified . do you have any luck when removing these two factors and re-estimating ?"
106210,"each realization of $ y $ is determined by the joint realization of $ { z , x } $ . for gigantic $ n $ , we expect that $ x_ { ( n ) } $ will be close to $ theta $ -and also , that $ z_ { ( n ) } $ will be "" very large "" ( since z_ { ( n ) } tends to infinity ) . . . _but not necessarily on the same pair of joint realization_ of the two . so , since $ z_ { ( n ) } $ will tend to dominate the determination of $ y_ { ( n ) } $ , it seems more realistic to state that $ y_ { ( n ) } approx z_ { ( n ) } x $ . . . if one defined $ y = max { x } max { z } $ , then the relation $ y_ { ( n ) } approx z_ { ( n ) } theta $ could be expected . . . i presume $ x $ and $ z $ are independent ?"
34263,"it might help to change how you think about chances a little . rather than thinking in terms of probabilities , which are numbers between $ 0 $ and $ 1 $ , logistic regression invites ( nay , forces ) you to think in terms of log odds ( which can be any real number ) . when you do that , logistic regression looks * remarkably * like ols multivariate regression . perhaps then your present question almost answers itself from this viewpoint ?"
44981,"although your current 2 respondents have made valliant efforts , this question is not really answerable without more info . can you edit / rework this q so that it asks a specific , answerable question ?"
86912,are these $ n $ objects supposed to be similar ( same dimensions ) ?
149912,there is something strange with your model : is $ k $ known ?
104113,can you describe your data in a bit more detail ?
122427,"robertkubrick : i don't recall any multivariate regression examples in * rms * , but is that ( i . e . multiple * responses * ) what you mean anyway ?"
138949,"when you graph a line and somebody says its slope is $ 0 . 5 $ , what does that mean to you ?"
76265,"your edit has not really made your question clear . the p-value is not a 'binomial prob' , pr ( heads ) . a sample is a collection of observations , but what an 'experiment' is depends on context and design . if you have 30 , 000 observations in a sample there is a 1 in 20 chance that the p-value will be less than 0 . 05 if the null is true ( and the test assumptions are valid ) . when you ask about 'observing the original 6 results' do you mean the proportions of heads or the 'significant' / 'not significant' results ?"
246691,what for ?
202277,using variable importance ( from some sensible procedure ) to filter out weak predictors doesn't seem like a terrible idea . can you clarify why you think this is bad ?
259183,"these assumptions appear to make no sense : if you know the parameter space , then you know $ mu_0 $ , and therefore you don't need any data to estimate it and the optimal estimate always is $ hat mu = mu_0 $ , not $ max ( bar x_n , 0 ) $ . ( how could $ bar x_n $ , assuming it's the mean of the data , possibly be negative anyway ?"
113468,"your last sentence seems a reasonable approach , as long as the "" occasional misses "" are not too many . are they ?"
167852,""" beta "" normally could mean one of three different quantities in this context : an estimated coefficient ; an estimated coefficient when the two series are standardized ; and an estimate of * volatility * ( or relative volatility ) . furthermore , how the estimates behave will depend on your estimation procedure . could you clarify these points ?"
126585,is ` rating ` a bounded value with limits given by the website ?
117634,was it fun to typeset that ?
273542,do you have a good reason to think that time between sales are exponential corresponding to a poisson process ?
273637,"are you asking when to include interaction terms in a model ( in general ) , or are you asking whether you must include interaction terms because two of the independent variables are categorical ( as in your specific case ) ?"
248363,"just to be clear , what you want to know is how to do a t-test ?"
273706,"one use anova and t-test usually in a situation when comparing few groups of cases . it seems that here you don't have groups , but four continuous variables . i believe it is rather linear model that you should use . could you clarify this , please ?"
189066,subjectivity is not a problem : but understandability is . questions must stand on their own without relying on links to other sites to make them comprehensible . could you therefore please summarize the context so that readers can follow your question without having to leave this site ?
273768,what can you tell us about the nature of measurement errors for $ x $ and $ y $ ?
273854,can you show the ` varcorr ` results from ` fit ` ( the small dataset ) so we can see what those estimates are ?
273929,might it be an adjusted pseudo $ r ^ 2 $ ?
255701,what do the scores mean ?
272480,"repeated-measures anova with only two conditions is just the paired t-test , right ?"
273851,are the sources independent ?
274003,how dou you check its authenticity ?
274023,welcome to crossvalidated ! can you elaborate on why you think there might be a relationship ?
274042,1 . what is the type of the ` pl ` matrix ( and its dimensions ) ?
274048,what exactly are your data ?
274051,what is your loss ?
274047,"i know you're writing for experts , but just to be clear would you please spell our or explain your abbreviations "" att "" , "" ate "" , and "" did "" ?"
273436,are all 26 features continuous ?
274077,how about cochran mantel haenszel statistics ?
271841,"what does "" interpreatno "" mean ?"
100036,what kind of dataset do you have ?
274151,hint : what variable ( s ) appear in model 3 that do not appear in model 2 ?
274142,isn't this about how to write code for a convolutional neural network ?
274165,"your question seems to be self-contradictory : if the data are obtained "" from the same people "" ( and are appropriate data for a t test ) then the sample sizes must be the same , so how could they vary between the investigators ?"
273580,can you please add a tag wiki for your new tag selectiveinference ?
220507,what you mean by conditional expectations ?
181922,"can you be more precise about what you mean by "" nonparametric t-test "" ?"
273433,why are all the p-values so low ?
274256,"it depends on the distribution of the underlying random variables you're simulating . in your case , it looks like you want to simulate correlated [ bernoulli ] ( url ) random variables ?"
274293,"please tell us what your observed variables are . on each trial in face categorization task , are you measuring response time and whether a face is categorized correctly ?"
274331,"i'm not sure about "" goal is to draw a random sample from this distribution which has a roughly uniform distribution "" . it's clearly _not_ uniform - so why ?"
274357,wow cowboy ! too many unknowns ! : d how are the $ z $ -scores calculated ?
274356,the question is not clear . . . can you provide reference to the paper ?
274387,why are you worried about causality ?
274391,"does "" linear constraints "" means that one of the coefficients can be expressed as a linear combination of the others ?"
274161,"this remains unintelligible to me ( what is "" going through general linear model , multivariate "" ?"
274392,"if you're only learning an embedding , what do you mean by recall ?"
269831,sounds interesting but how do you approach this ?
274268,do you mean 10 . 000 ?
274494,please keep us posted on the solutions you might find to this interesting problem : ) is it physics related ?
274507,"why the title flags econometrics is not clear . nothing mentioned here seems in any sense limited or intrinsic to econometrics . you've tagged transformations on which there are 1 . 2k questions , so did you check out the most highly voted ?"
274549,see [ deliberately fitting a model without intercept ] ( url ) & [ when is it ok to remove the intercept in a linear regression model ?
274517,"i understand . do you have access to the standard errors , in addition to the point estimates ?"
273278,so what is the output when you fit these models ?
83840,but isnt this just the rao-blackwell theorem ?
274622,"you should elaborate bit more . i have no idea what object is here . seems like n = 80 and each subject rates on item a , b , and c . where does this 8 object kick in ?"
274641,"is a highly related question , "" what's the density $ f $ for a random variable that is zero [ almost surely ] ( url ) ?"
274655,what is the point of this parameterization ?
274649,davidg . stork can we put the question this way : what is the simplest possible model under which we don't observe alien signals ( or those clock alarms in a house ) ?
274679,do you know the law of total variance ?
274723,did they give you the data or just the code and output ?
274680,the spss calculation does not appear to be of actual eigenvalues . where does it come from actually and what does it claim to represent ?
274731,"how do you define "" works better "" ?"
274755,"could you add the following to make more insightful what your situation is : ( 1 ) what do you mean by correlations between the variables ( have you made correlation matrices and tested these for significant correlations , hence the p-value ; if so i'd be more interested in the correlation coefficient ) ?"
274496,what can you say about the distribution of timeseries values ?
274786,"you mean complexity for any algorithm , for any problem . . ?"
274788,"the use of the term "" nonparametric distribution "" seems odd here . how is a triangular distribution anything but parametric ?"
274802,"i don't understand why you are asking this , since you have already remarked that the $ chi ^ 2 $ statistic "" does not indicate the direction of the deviation . "" because the test is based only on that statistic and the degrees of freedom parameter--which merely counts data--isn't it obvious you cannot obtain directional information from nothing ?"
274662,are these z-scores using the same mean and standard deviation for all the observations you're comparing ?
219822,"can you give some "" more formal "" reference that defines and uses / explains the psi ?"
274859,have you considered [ association rules ] ( url ) as a means of clustering ?
274879,are the individual values ( pre / post ) available or do you just have the percentage reduction ?
195271,have you tried transforming them onto the symmetric scale ?
274905,it is probably correct . maybe there just isn't a significant difference . why would you think there has to be ?
274891,"i think it's mostly right , although perhaps 1 should be added everywhere ( except for sarima ) because of the fact that also $ sigma ^ 2_ { varepsilon } $ is being estimated extra to the ar and ma coefficients . but i am not sure . also , what is your logic behind the 1 for sarima but not in the other cases ?"
263812,can you be more specific what data you have ?
274815,"i am confused by your second bullet point . you say that in the misspecified case , credible interval of the posterior will not match the confidence interval ; but why should any bayesian consider such "" matching "" as something desirable ?"
274836,that is a quite long paper ! can you cut out the graph ( s ) your question is about and include it in your post ?
274983,"yes , i don't see that you have established independence and i still doubt it would be ( even approximately ) the case . why does the protocol you added some detail on make the observations independent ?"
275034,why is the average absolute difference more intuitive than the average squared difference ?
185753,"you write that the mean = 0 . therefore , the length n vector of zeros is the expected value of the mvn . am i missing something ?"
275064,from your description expenditure appears to be a continuous variable . then a count model is probably not the best way to approach the problem . wouldn't it make more sense to use a tobit-type model ?
267397,how many data do you have ?
275121,"knitro might be faster and more robust than fmincon . there are many algorithm options . you can either supply exact hesaian ( or compute hessian-vector products ) or use quasi-newton . for quasi-newton , either bfgs or sr1 . sr1 might perform better than bfgs if there are significant non-convexities . what kind of constraints , if any , does your problem have ?"
275139,"we know they are two different models , why should we compare the prediction power ?"
275118,"an answer to this question ( essentially , "" what predictive methods are worth trying ?"
275173,"if the axis labels are to be trusted , this model does not satisfy the assumptions . ( obviously . ) what goes wrong and what can be done about it is impossible to tell without further information : what does the model look like that you fit ?"
275175,why not first consider the asymptotic distribution of $ left ( sum_ { i = 1 } ^ nx_i right ) / n $ ?
275048,how did you run a $ chi ^ 2 $ test ?
275200,i don't see where this provides estimates for the # of false positives or # of false negatives . if you had that information what would be the point of the hypothesis test in the first place other than to determine the validity of a certain procedure ?
275231,why would you expect a normal approximation to give the same value as you get using an exact calculation ?
275249,why did you want to transform ( other than the apparent skewness of the data ) ?
275297,is that a draw in the bayesian context ?
204782,"could you explain what you mean by the "" term $ bar x $ . . . vanishes "" ?"
275307,interesting question . but i have a question for you too : have you run the code yourself too ?
272627,it depends . what do you plan to use that vector for ?
64208,"what exactly do you mean by a "" large "" coefficient ?"
133181,"what is conversion "" ?"
246342,"why wouldn't you count that as the probability of being , say , half-red & half-blue ?"
275378,"also , is the second part ( below "" he transforms it into "" ) one long equation or two equations equal to each other ?"
52458,what do you hope to achieve with your model ?
274668,what is the source of your over-dispersion ?
275262,what is the extent of missingness ?
275429,why not simply take the average for x and for y and use that as the coordinate estimates . don't you mean the noise terms are normal with mean 0 and the two known variances ?
275506,just a big list of all possible loss functions w / their pros & cons is not what this site is for . to do it well would take a book . are you trying to build a specific classifier & are wondering what loss function to use ?
275523,what is your research question ?
275545,"what do you mean by "" density "" ?"
275660,in what event are you talking about ?
275694,"what does "" churn the sector "" mean ?"
275671,why would it not be ?
275805,"i do not know stata , and this seems to be more about the software than the statistics of it , but have you tried running both models and seeing if they differ from one another ?"
198075,"who in the world told you that "" almost everything is normal distributed "" ?"
275822,related ( if not duplicate ) : [ are group effects in a mixed effects model assumed to have been picked from a normal distribution ?
275675,how many entries can you afford to read ?
275859,"setting other things aside : if something is defined for $ n $ points , what exactly is the problem with $ n = 1 $ . . ?"
275873,what actualy is your question . . . ?
275925,"possible duplicate of [ what does having "" constant variance "" in a linear regression model mean ?"
275931,"in the case of a constant model ( ` y ~ 1 ` ) it's clear what you mean by the 'median' , but in the case of an ordinary simple regression ( ` y ~ x ` ) the solution can be a region ( bounded by straight lines ) in $ ( beta_0 , beta_1 ) $ space ( e . g . see the example data set i made up [ here ] ( url ) ) ; degenerate cases aside , i believe it's always a convex region . what is the intended meaning of ` median ` in that case ?"
275961,could you go into more details ?
276030,why do you use a feature selection technique but want to override it ?
276025,some or same ?
276029,that variable almost completely predicts the allocation so why not just use it ?
276059,increases compared to what ?
276061,what are you going to do about $ y- min y 1 $ being negative ?
276019,what do you want to know that you didn't already know before taking the sample ?
276065,"firstly : i don't think there is any way to make recommendations without any information . if you have no data from your own users , you could try to get data / information from other sources . is this kind of data sold anywhere ?"
276139,are you doing multinomial regression ?
276150,"1 . when you say "" how do we use the revised values ?"
276221,1 ) why would you expect to get the same pdq ?
276263,i don't think you have given enough information to allow a useful answer . is there some hypothesis you want to test ?
274904,what is your question ?
276350,are $ y $ and $ x $ centered ?
243544,"speaking of mahalanobis distance we usually mean a distance between a point and a clouds's centroid , or between two points in the same cloud . so its is a pointwise distance in any case , like euclidean one . but you want to extend its definition to a set distance , a distance between two clouds . it is surely possible , but i think it will transgress the definition of "" mahalanobis distance "" , so why need to do it ?"
240578,does that minus sign in front of $ x_ { 21 } $ really belong there ?
276360,often correlation is not very specific nor of much interest . could you tell us a little more about what you really want to find out ?
276309,"please explain your notation . in particular , although we might guess that "" be "" means a bernoulli distribution , what exactly does "" $ w $ "" stand for and what properties are you assuming it has ?"
275869,"i was not implying $ alpha $ would change . just that if you set $ alpha = 0 . 05 $ for example , and the null is true , then you expect to wrongly reject the null 5 % of the time , by definition , no ?"
276452,do you have 20 independent experiments each giving you an auc ?
276492,"the last few paragraphs of this question wander off into what looks like a triviality or something without meaning : typically , $ a $ has many more rows than columns , so it doesn't even make sense to refer to its "" inverse . "" what do you really want to ask ?"
276519,"the dtw distance is really supposed to be this , usually . note that the "" ground distance "" you use to compare single pairs of points within dtw is pretty flexible ( e . g . it doesn't have to be $ d ( x , y ) = x-y $ ) . perhaps your ground distance is not capturing the relevant differences ?"
276513,is your step 1 supposed to be [ naive bayes ] ( url ) ?
276525,i'm afraid that doesn't clarify anything : are you asking whether subtracting a distance matrix from the identity matrix will produce a correlation matrix ?
276537,"re "" which factor is the most important "" : you appear to have data about * popularity * of excuses offered by respondents in each survey . how would that be related to * importance * ?"
44560,is [ this ] ( url ) what you're looking for ?
276551,can you offer details of the paper ?
268713,"could you elaborate on what you mean by "" initialize the chain "" ?"
274720,"as its fairly easy to find more elaborate answers , here just a quick-and-dirty explanation : if for most combinations of class , feature pairs you have very little or , more likely , zero observations , how do you factor that in statistically ?"
276367,another ( somewhat circular ?
275744,"it's not clear what the scope of solutions to be covered might include - e . g . whether you're including things like "" exploding "" dice and "" roll 4 leave out the smallest "" . you should explicitly list out what you want to include , though it may be more productive in the first instance to start with a pretty short list ( so the question doesn't close as too broad ) . after each such item you'll need to clearly explain how it works ( a phrase like "" dividing constants and / or variables "" is not clear . . . what's varying there ?"
276625,"can you give a little more justification for your premise "" theoretically the autocorrelation should be considerably higher if country-specific variables ( e . g . election systems ) are added "" ?"
134533,"i am not sure if i understand your question - perhaps you could just do mcmc sampling from $ p ( alpha , beta mid d ) $ and discard the $ beta $ s ?"
276631,"quite a few algorithms have an "" * online * "" variant . . . is there a particular that interests you ?"
276637,what specific question do you want to investigate ?
276671,"if the chain ever hits state zero ( $ m = 0 $ ) , the product you are interested in will equal zero , right ?"
276677,"i am not familiar with r , but can lm give you the design matrix ?"
276700,"reference please , not just allusion and quotation . "" a less estimate "" ?"
11754,why not to start from the hypothesis that second level is described by $ beta_i = c_j varepsilon_i $ and to test if all $ c_i $ are equal ?
276725,geomatt22 why do you think it's a duplicate of that question ?
276645,"so , what is your question ?"
169015,"that sounds odd -- if you can comment you should be able to edit . . . . re your question : if $ e ( y ) = mu $ and $ e ( hat { y } ) = mu $ , why do you think $ e ( y- hat { y } ) = mu $ ?"
276793,"wouldn't "" predict the amount of tires changes "" be more a * regression * problem than a * classification * one ?"
276633,"i assume this is the paper your question arises from : hao , jie and godbole , anant ( 2016 ) "" distribution of the maximum and minimum of a random number of bounded random variables "" * open journal of statistics * , vol . 06 no . 02 , 12 pages article id : 65869 , 10 . 4236 / ojs . 2016 . 62023 . . . is that correct ?"
276804,what variables are you using ?
276847,"what do you want to do with the "" standard deviation matrix "" ?"
276849,"the likelihood function is usually defined as "" the likelihood of a parameter value ( s ) given a set of data "" . what set of data was used to derive this likelihood function ?"
276866,can you clarify on a simple example what exactly you want to achieve ?
276943,i would stick on the model 2 . homogeneous normally distributed residual . this kind of good situation is not common in practice . could you describe your difficulty on interpretation ?
276500,there is to little information here . what is the marginal distribution of the series ?
103242,why would the response be $ y / sigma ( x ) $ ?
277048,what is the space of nonlinear functions that you are considering ?
277049,what accuracy did they get that was better than yours ?
276916,why is your decision boundary not in the obvious gap ?
193665,i don't understand the reason you give for wanting to use ` lavaan ` over ` lmer ` . you can't estimate the two models ( one where the intercept and slope are correlated and one where they're not ) with ` lmer ` ?
276790,why the downvotes ?
277135,if you use log at some point someone is likely to say why not logit given the bounds ?
277165,are they the same 60 patients or a different set of 60 patients for each doctor ( e . g . their own ) ?
277170,what's your sample size ?
277182,what $ r ^ 2 $ do you want to achieve ?
277186,"isn't it still case by case except that your "" case "" is larger ?"
277179,surely $ hat { p } $ needs to be divided by $ n $ ?
62069,"disclaimer i'm someone with just enough stats background to be dangerous . / disclaimer so lets get dangerous . . . . my intuition agrees with yours that the gaussian isn't the way to handle non-continuous data . for continuous data one value on the number line has a different sort of relationship with all other values than does a number on an integer line , or a binary variable . binomial distributions describe binary variables . multinomial distributions describe multinomial variables . aren't these all exponential family members ?"
277314,"welcome to the site . in order to answer your question , you'd have to tell us more about what you are trying to find out . it's not so much that your distributions are "" spread out "" as that they have multiple modes . do you have any idea why they do ?"
277310,"i am not quite the expert on neural networks , but why use so little of your data ( 70 / 6000 ) to fit the model ?"
277336,overfitting is certainly a possibility . do you mean you have good performance for some iterations then suddenly the performance drop significantly ?
277361,"the sample size will be inversely proportional to the square of the moe . this phenomenon shows that you are missing some crucial elements in the formulation of your question . the most important are these : if the proportion of unaffected waterbodies is 99 % , ( 1 ) it's unlikely the proportion in a sample will be exactly 99 % and ( 2 ) you will probably want to construct a lower confidence limit of the unaffected proportion ( called a "" tolerance limit , "" or ltl ) based on the sample . * how small could you allow the ltl to be and what level of confidence do you need in it ?"
277155,what do you mean by grouped ?
277394,why are you making a normal qq plot of the residuals from a poisson or a negative binomial model ?
277415,what do you mean with : i never start with manipulation 2 ?
277427,"just to be sure , have you checked already the irt models ?"
277393,"your question and assumptions are not completely clear to me . but it seems like you may want to treat the map as piecewise-constant population density , defined by polygons ?"
277449,"what is the * purpose * of "" finding the trendline "" ?"
277460,can you please add a tag wiki for the new tag perplexity ?
277465,""" the original label is corig and the probability of it being that class is computed to be porig "" - how do you compute this probability ?"
277472,"what exactly do you want to predict , and what problem does your clustering solve ?"
277490,why are the features null . in the production data ?
277504,"from what i understand , the dissimilarity index you are referring to measures the dissimilarity between two groups ( or regions ) , while the dissimilarity between two sequences compares individuals , not groups . anyway , each dissimilarity measure has its own intuitive interpretation . also , we should be able to use any dissimilarity measure to evaluate the impact of an increase in a covariate x on the similarity with a reference sequence . why would that depend on the measure chosen ?"
277539,"you know the true volatility , not a proxy . how do you simulate ?"
277578,is this a [ tag : self-study ] question ?
277585,what are your data like ?
277589,this statistic is based on values of variances of the residuals . where did you get those values from ?
277604,what is your data ?
277598,"well , that's better . why does student01 have a proportion failed of 0 . 10 out of 25 questions ?"
277674,i am not familiar with r . could you tell me what prior is used for variance of random intercept in your second bayesian approach ?
277513,i don't quite follow your situation ( or maybe your reasoning ) . could you post a small example dataset to illustrate your question ?
277748,what kind of data is it ?
277136,"what does "" normally "" mean for something that can't be normal ?"
277810,"your idea of a "" cheating variable "" here seems similar to the "" correlation = causation "" fallacy ( or perhaps "" [ postdiction ] ( url ) "" ) . but your proposal seems more like "" how to determine if one predictor dominates outcomes ?"
277835,"i do not have much experience in this area , but i could imagine the multi-class logistic approach working ok perhaps . so for output you have a softmax , right ?"
277836,how many predictors do you have ?
277857,what is your motivation for doing this . how is age related to the classification problem ?
277821,"could you explain what you mean by "" way to go "" ?"
277880,what are you asking for in response ?
277879,can you show me an example with a significant f value and no significant relationship between the dependent variable and the regressors ?
277888,"do you mean x = 1 , . . . , n rather than y = 1 , . . . , n ?"
277905,do you want to perform a linear or non-linear classification ?
277917,daniel winkler - are you sure you've correctly written the likelihood ?
277948,de-bugging your code is off topic here but there does seem to be a possible statistics question here . is all = female male ?
277949,"this feels like an intermediate step and not your actual goal . if so , could you describe your actual goal ?"
277975,what kind of images have you tried to get cnns to work with ?
277982,you are right . what kind of summary would you need ?
277990,do you want to know how to calculate standard errors for two stage least squares ?
278021,"this seems very ill-constrained based on your description , so not too clear what you are after . off the top of my head , perhaps applying the [ logistic function ] ( url ) to your sample mean would work ?"
277921,"just to be clear , are you stipulating that $ t ( x_1 , . . . , x_n ) in mathbb { r } $ , and not something like $ mathbb { r } ^ n $ ?"
278082,what is the point if you don't have accuracy measures ?
278125,"i don't quite understand your situation . what do you mean that you have "" occupation status "" , but that you don't know if someone is self-employed ?"
278020,do you know gradient boosting ?
278143,think about the expression for beta hat . . . is there a random vector in there ?
278197,"on the first thing , what's wrong with the first link under "" related "" in the sidebar ?"
278085,"what do you mean by "" binarize into buckets "" ?"
278191,can you show a map of your stations ?
278216,does it have countably finite number of possible values for each dimension ?
250920,"how do you define "" reliable "" ?"
278188,maybe you can explain why you took this approach ?
278292,"can you say more about the kind of data you are working with , & your situation / task / goals ?"
277965,have you thought of looking at complier average causal effect ( cace ) ?
278329,"i can't guarantee that i'll have time to answer this , but are $ x_1 $ and $ x_2 $ independent ?"
278353,"quality is undefined here , but without defining it : ( easy ) do the methods agree in their results ?"
278311,something like 3 . 2-3 . 4 from here : url ?
278304,"what do you mean by "" the normal way "" ?"
278431,* what for * do you want to test it ?
278297,"so your data looks something like : ( 12 : 00am , message1 ) , ( 12 : 02am , message2 ) , ( 12 : 05am , message2 ) , ( 12 : 20am , message1 ) , ( 12 : 21am , message3 ) , . . . etc ?"
278443,do you wish to predict values for $ y_i $ or for $ y_k $ ?
278421,could you give a full citation for rahbek ( 1999 ) ?
278479,what is the dependent variable ?
278490,"do you want to predict ` tap pressure ` based on ` valence ` & ` arousal ` , or do you want to predict ` valence ` & ` arousal ` based on ` tap pressure ` ?"
278512,"this question is too broad for the qa format . "" any tips "" is a bad sign in a question . please narrow it . eg "" is there anything wrong with using a cnn layer before inputting to a lstm ?"
278533,""" present "" in what sense ?"
278566,"no , just because you standardized $ x $ ( or some of them ) do not force you to standardize $ y $ also . ask yourself : why do i standarize ?"
278568,how much iterations are you training both ( shallow and deep ) networks for ?
278581,these tests do not test for differences in medians -- you can have significant mann-whitney when the medians are equal and mann-whitney p-values of 1 when the medians look very different . are your data paired ( are they the same people before and after ?
278538,can you describe the data-generating process in more detail ?
278379,are you ok with the following answer ?
278600,"chi-squared , perhaps ?"
278596,"please give more background information about your goals . what is "" pls "" regression ?"
278648,hm . in that they measure two completely different things ?
278678,this does not seem like a question that has a definite answer given the information you've provided . is this all the information we have in this problem ?
278703,"could you give a reference ( except for the lecture notes , unless they are publicly available ) for the claim that the estimator is biased ?"
278707,"if you substitute $ z_ { t } $ in the first equation with its expression from the second equation and continue that way for $ z_ { t-1 } , z_ { t-2 } , dots $ , you will see something interesting . what about the [ tag : self-study ] tag , though ?"
278732,"what does "" improve my estimate "" mean in this context ?"
278745,what's wrong with using regular logistic regression when you have a lot of data ?
278729,and your question is ?
278801,"i like cart models and their ensembles . i like 'boruta' for variable importance . what measure / rubric do you use to justify saying "" imbalanced "" . you could do cv but only vary on the dominant sample-type . you can clone , or if you are daring clone / blur your low-population variable to be equal to the high-population one . have you looked at the leverage associated with individual points ( think plot of simple lm ) ?"
278880,wouldn't it be easier to simulate it ?
278888,"in the last line , is it arima ( 0 , 1 , 0 ) or ( 0 , 1 , 1 ) ?"
278872,are the factors in your 2x2 design between- or within-subjects ?
206202,how about ` predict ( se . fit = true ) ` ?
279021,why do you use so much space horizontally ?
279035,are you running a paired t-test ?
278961,"so what exactly are the parameters . you say you have machines with a min and max treshold , but what are the parameters that the genetic algorithm should optimize ?"
279077,"the "" hat "" over your $ delta $ s suggests they're estimated from data rather than actually known . is it the case that you really know the true values rather than estimates of them ?"
279062,why neither ?
277860,i'm not quite sure i follow what statistics you are quoting ; are these in outputs from ` gam ( ) ` models ?
279019,"i think you might be confusing estimator with predictor . so here , your ceo salary is the predictor for your roe . so my guess is you're asking whether your prediction ( or estimator ) for roe is unbiased ?"
208571,perhaps url will help ?
278285,looking just at statistical significance is unlikely to help you here . what happens if you look at the coefficients instead ?
174716,"i'm sorry it's not clear quite what you mean , especially with the word posterior . when you say discrete 2d , do you mean all points with integer coordinates ?"
279193,"when you say that the ''effect of age is strong and markedly nonlinear "" , do you mean that the effect of age changes with age , or that it changes with time ?"
279086,"what do you mean by "" add these terms to the ricker function "" ?"
277872,can you provide some context ?
279102,"what does "" validating a random variable "" or "" running off a random variable "" mean ?"
279350,"` some cells with zero values , which would cause them to fail assumptions ` why ?"
279368,you haven't made it clear what your alternative hypothesis is . is it not equal to 0 . 51 or a one-sided test . does the published study provide you with any measure of accuracy ?
279373,where in those columns of your dataset is there any quantitative information about developing disease ?
279382,do you have multiple observations per artist or painting ?
279429,"your question could be considered a duplicate of [ this ] ( url ) , except for the randomization part . does that thread help ?"
279451,have you tried using the same initial values in both cases ?
279515,"please keep in mind what "" sample "" means in statistics . when you say "" sample "" , do you mean "" observation "" ?"
279518,"i believe this is not the first time you have found vague , unreliable , misleading , or wrong information on that site . isn't it time you used a better statistical resource ?"
278963,"i don't think this is a duplicate ; the three links to other discussions talk about how to calculate p-values for given variables or factors . this is not what la is asking . the question here is how to get a * p * -value for the * * entire * * model something that i can't find discussed in the linked threads . if i missed it , where does someone address this specific issue ?"
279544,s ( x ) appears 4 times . are they the same or different thing ?
85757,"why do you want to select the 'best' clustering solution based on some "" internal "" clustering criterion as long as you've got an external criterion ( the labels ) ?"
279671,"do you have something particular in mind when you write "" random network "" ?"
279675,did you consider a two-sample k-s test applied to $ y-x $ ?
278043,is this is a balanced design ?
279705,could you edit your question to clarify what you're asking about ?
279524,have you looked at r package blme ?
279731,you seem to be familiar with fieller's theorem . have you tried actually plugging in the parameters ?
82326,answers in ` ?
279801,erp ?
279843,"1 . this is related to url ( see in particular my answer there : url as i think that the currently most accepted answer does not tell the full story ) . but your q looks a bit different : instead of asking how much variance a given linear combination of variables explains , you are asking how much variance a given subset of variables explains . correct ?"
279912,does that flowchart represent your final enrollment figures ?
279928,"your question is incomplete : * there is more than one way to compute the p-value . * the methods depend on what assumptions are made , including inequality or not of the variances . see url for instance . * * which t-test are you asking about ?"
279971,"unbalanced classes is tbe term to use , not sparse . can you edit the title ?"
279810,how many experiment groups ?
279984,"btw , yes it's true that the variance for a binomial with low or high success probability $ p $ is smaller than that with moderate $ p $ . . . . . consider the limiting cases $ p = 0 $ or $ p = 1 $ . in your example , what is the probability that the true ' $ p $ ' for coin b is bigger than $ 0 . 1 $ ?"
279720,"* how do i generate , eg : 1000 networks ( using erdos-renyi or watts-strogatz model etc ) and get an average of the clustering coefficient or the diameter over all the random networks . * what exactly is your problem ?"
194746,and what do you try to predict ?
153331,are there other variables in your data set you plan to use ?
37914,could you explain how these 4 predictors were coded ?
280107,can you tell us what you do understand and what you do not ?
280114,why did you put [ fractional-factorial ] tag here ?
278852,"what specifically is the "" this "" in "" this has been shown to be true for the bic , if the canonical link is taken "" ?"
280151,where did you want to place the tilde ?
279359,why are you running generalised linear model for categorical predictors ?
280198,did you scale your training and test inputs together ?
280207,"can you clarify the superscript , subscript notation ?"
280081,1 . in your second bullet point do you mean $ n_1 $ where you have $ n_i $ ?
280293,"when you say "" fit a weibull distribution when i have probability values "" can you be explicit about what kind of probabilities these values represent ?"
280303,"to clarify : do you want the average weight , or the distribution of the weights , given that the weight x ?"
280361,are you asking for the math or code ?
280364,what have you done so far ?
280358,"what is the fourth vertex , ( 1 , 1 ) ?"
280367,"you answered your question in the first paragraph : you told us that when the detector goes off , it is correct $ 99 . 99 % $ of the time . if that didn't refer to the probability , what does it mean ?"
280387,could you give more details about the study design ?
280052,what are you calling r ( 1 ) ?
280412,could you explain that intuition ?
280476,"you don't establish confidence intervals for the read time ; you might establish one for say the mean read time or the median read time or some other parameter of the distribution . if you want some kind of interval for a single read time , or a collection of them you'll need to specify the kind of interval you have in mind ( tolerance interval ?"
280459,you seem not to be sure that you would like to fit a gamma distribution . this raises the more fundamental question : why are you going through this exercise in the first place ?
280510,"you may want to refine your question to make it narrower & more concrete . if your question amounts to "" suggestions ?"
280375,"since it is mathematically impossible for the covariance matrix of data to have a negative eigenvalue , please explain in more detail what your situation is . how did you compute this matrix ?"
280430,"i'm not actually sure the self-study tag is necessary , this doesn't seem to be "" routine bookwork "" . perhaps we'll leave it there for now . the crucial thing is not the tag but the lack of clarity of what you're asking . what is it you say is geometric ?"
280502,your formulas do not appear to be measures of dispersion ( though they might be in some special circumstance ) . please offer some context for these . where do they come from ?
280590,what do you mean by the arima test ?
280607,"it's difficult to determine what you are asking . you seem to want to set limits that are likely to contain nearly every point in a sample of size $ 10 ^ { 11 } $ . are your "" subpopulations "" really that large ?"
280611,did you try interactions ?
280597,"in r's ` caret ` package ` confusionmatrix ` function ( which is what was used in the example you linked to ) , the no information rate is just the largest class percentage in the data ( this is explained in the help for the function , which you can access by typein ` ?"
280674,"google for super-consistency and cointegration . and as $ t rightarrow infty $ , what do you think the estimated $ r ^ 2 $ will converge on ?"
280695,just to clarify . you have two random variables that are independent from one another and what you want to know is the distribution of their sum . the reason that you want to know this is that you want to compute the 90th percentile of their sum ?
280713,at which level do you suspect there is correlation among your errors * within * the level but not between levels ?
280740,why do you say that you have a prefect fit ?
280781,do you preprocess your data ?
280723,"please ask a more specific question ; you'll need to make some assumptions to get much value from this . why would your "" rough proposal "" make any sense ?"
255022,why can't you use gower distance / similarity ?
90416,are those 20 % all lumped around taking 50 % ?
280874,"i see . so unlike "" bootstrapping "" , this term should apply in all contexts , regardless of what is being sampled ?"
280906,1 . what exactly did you test for normality ?
280934,have you tried multilevel imputation ?
280946,can you look at a log-version of the above graph or can you just show the graph without the zeros ?
280057,"xi'an but comparing two or more models through marginal likelihoods wouldn't be the same as using bayes factors , if all models were given the same prior probability ?"
280991,1 . would you post the output of all three options so that we could see how different / similar they are ?
281026,can you add details about a specific problem or reference ?
280304,it's not clear why this answer url ( in the thread that you linked to ) does not answer your question . can you elaborate ?
280950,are there always two answers from category a and two from category b ?
281007,"what do you mean by "" truncating "" here ?"
281074,"( 1 ) where are the "" binary outcomes "" of the title ?"
281085,how does the log-logistic relate to your linear probability model . can you clarify what you mean there ?
281160,"the way your question is formulated now , it seems that you run a logistic regression of y depending on x and you are trying to predict the probabilities of x . is that intentional ?"
280486,what do you want to use it for ?
6412,what is the purpose of your question ?
7727,"bobc , maybe one of the moderators can have your post migrated to this site . that would be the most reasonable . as for your technical questions , first of all , are you using the fft to do the correlation ?"
47862,"unfortunately , that negative value for ` y2 ` will hurt when you take logs . . . if you're interested in running a regression assuming $ y2 x2 sim text { lognormal } $ , you could just take the log of $ y2 $ and regress $ x $ on $ log ( y2 ) $ ; you're back in the normal distribution world at that point . is that negative value correct ?"
17656,have you tried changing the control parameters in the initial tree growing process ?
9009,can you update the plot to add the conditional median ?
43747,"so i'm learning the ropes with this , but should i just flag my post for a moderator to do this ?"
73096,cog ?
92604,do you know about vectorisation in r ?
114412,at which spatial locations $ s $ did you compute the median of the posterior distribution ?
139163,any reason to discard a dirichlet process over the components ?
156808,"very thorough question work up about a topic that is arcane by any statistician's standards . the obvious first questions , before one even gets into * interpretation * is , "" why do you need this test ?"
182764,the last three series are generated how ?
212630,can you clarify your situation more / add a more complete example dataset ?
221144,where is ` kfit ` function documentation available ?
220399,"it might be worthwhile noticing that your diagrams implicitly describe a probability distribution over the set of all possible states , one in which the balls are filled sequentially . that is * not * the same thing as the uniform distribution over all allowable distributions of the balls in the bins ! thus , the very first thing to decide is * what distribution are you trying to create ?"
247762,what's wrong with the way that worked ?
281199,"are you asking about a difference in results between two specific studies , or between the results of survival models in general ?"
281021,are your ` y ` labels 0 and 1 ?
281258,"could you explain how , if at all , this differs from a time series ?"
280437,"to clarify , you're looking to find the distribution of topics in each category's corpus ?"
281318,possible duplicate of [ a reverse birthday problem : no pair out of 1 million aliens shares a birthday ; what is their year length ?
281396,""" number of conversations "" is a * count * . it's discrete and non-negative so it's * obviously * not normal . why would you test what you already know ?"
281133,1 . hint : define $ a $ and $ b $ as independent coin flips and let $ c = ab $ . what happens ?
281375,"that's my point , if you don't know which method , then how are you to know what generated integer scores ?"
281213,"what do you mean by "" uniform "" ?"
240097,"your question is difficult to understand because you seem to use some standard terms in nonstandard ways . could you please explain what you mean by "" event , "" "" occurrence , "" "" sample , "" and "" instance "" ?"
281440,"could you explain what this "" $ delta $ "" notation means ?"
281282,"it's not clear to me what you're asking . what do you mean by "" the probability of occurrence "" and the "" total mean and variance "" ?"
281455,what does $ f $ denote ?
281524,can't you create a meaningful series / variable using both x and b ?
281599,better way to do what exactly ?
281522,is this a stats question or a programming question ?
281623,"the very first question to ask is how much data you have . neural nets are good , but they're not magic -- different dataset sizes , image resolutions and model architectures may result in completely different outcomes . could you give some more information regarding how much data you have and what other classifiers and neural net architectures you have tried ?"
281553,why are you using $ sqrt { 2l_i } $ ?
281214,"maybe . would you say could be implemented with bayes methods , with a prior on $ n_i $ implementing what you know about the variability in the $ n_i $ ?"
281682,what are you going to do with the fitted distribution ?
281705,"if you can get it without too much effort , what's the third moment skewness of the sample of total values and of both of the components of that total ?"
281527,"that helps , thanks . what sort of property are you asking about ?"
281859,"this question makes no sense for single distributions , because your use of "" unimodal "" necessarily refers to the likelihood as a function of the $ p_i $ . this makes me wonder whether you might be using "" likelihood function "" in some nonstandard sense . maybe you are using it as a synonym for "" probability function "" ?"
281562,""" i need to fit a 7-parameter function ( actually 6 since one of them is fixed ) on a histogram "" why ?"
278564,"what do you mean by "" the confidence is distributed as "" ?"
281940,where did you get these formulas from ?
281989,"applying "" careful thought and some experience "" is advice that will never go out of date . indeed , although this advice might * sound * subjective , what could be more objective than careful consideration and application of all relevant information to a problem ?"
281154,real data or simulated data ?
282152,"in order to answer this , you need to supply a clear characterization of what "" lod "" and "" loq "" are intended to mean . this isn't as obvious as it might seem , because there exist dozens of distinctly different definitions of these quantities . exactly which ones are you applying ?"
282180,"the criticism of "" heat maps "" comes down to the last line of ( 4 ) : exactly what are these "" better ways "" to communicate ?"
282289,"url . . . ( in the question ) or url ( ditto ) ; the log-likelihood is in several other questions . it's not clear what the point of posting a slab of code is ; we're not a "" translate code into mathematics "" site -- and what if the code is wrong ?"
282308,i think that the assumption is that $ o_i $ is poisson and $ chi ^ 2 = sum_i frac { ( o_i-e_i ) ^ 2 } { e_i } $ ?
282312,"okay , so when you're creating this data set , one of the columns needs to be what you want to predict : backend , frontend , fullstack . most people would rename that column "" y "" and encode the possibilities to 0 , 1 , 2 . what about all of the other pieces of data that you'll know about the person , in order to make the prediction ?"
282069,i don't see enough information here to help people understand what you want . what's the * purpose * of this analysis ?
282472,"there's no single "" most suitable "" distribution across all purposes . it really depends on what you're doing , how simple a model you want , why you want an explicit model ( rather than say a smoothed empirical pmf ) and so on . what's this * for * ?"
282482,"does the * distribution * of age differ between the datasets , or the * impact * of age on risk ?"
282487,how is the health index calculated ?
282501,"you define the $ e_i $ as the residuals with respect to the ols solution . obviously their sum is always zero : that's a mathematical property of the solution . but if the model is not what you suppose , then isn't it equally obvious that the expectation of any individual $ e_i $ could be any number whatsoever ?"
282509,is there a reason why you can't simply fit a logistic gam ?
282522,could you explain in more detail what your data mean ?
282534,"when you say that "" the same procedure was repeated after crossover "" do you mean steps 1-4 were repeated with the supplement that was not used the first time ?"
282604,"yea , is it anywhere else to be found ?"
282605,aerkenemesis is there a reason you are filtering neutral polarity ?
282595,"yes : tell us either the model or the method . seeing the parenthetical "" what kind ?"
282602,are you using any program to perform your analyses ?
282491,are $ a $ and $ b $ constants or random variables ?
282614,"one could show that the third moment skewness is positive easily enough , but that doesn't automatically imply that the mean will exceed the median ( i certainly believe the mean will exceed the median here but we'd need to prove that it does ) . what's this for ?"
282675,did you try normalizing your variables to have unit standard deviation before applying pca ?
282688,could elaborate on what 'representative findings' you are looking for ?
282699,"looks like a 2 ( interface ) x 3 ( scenario ) x 3 ( phase ) design . what is your dependent variable , is it binary , continous ?"
281443,"to be clear , you are asking for help on how to compute a weighted mean and ( weighted ) variance ?"
282619,$ yn = n $ times $ y $ or $ y_n $ ?
282710,"90 % probability of what , exactly ?"
282539,"could you please explain what "" x items left "" means ?"
282658,it's impossible to reasonably suggest anything because 1 . you don't indicate * what it is exactly you want to test for * ( what are your null and alternative ) ?
282813,"you can't interpret a qq plot in the presence of heteroskedasticity , so ignore that as your error is more fundamental . you would expect heteroskedasticity with proportions , from two different causes ( only one of which would be improved by transformation ) . can you show the residual plot you have this wedge shape in ?"
282087,can you post sample size and the error estimates for the different outer folds ?
282865,what exactly would you expect to be different ?
282883,integer division error ?
282887,in the first place why is n $ ^ k $ obvious ?
282908,1 . how do these fractions arise ?
282304,"if you're sure that "" every single predictor is unrelated with the outcome of the dependent variable , "" then aren't you done ?"
282933,would the gamma distribution work for this - mean = $ k theta $ and variance = $ k theta ^ 2 $ ?
282948,what makes you think that your usual method won't work ?
282982,"what is "" wf "" ?"
282989,"could you explain what "" directional correlation "" is and how you compute it ?"
282793,the correct word is effect not affect . is the problem with the chi square test due to low cell frequencies ?
282993,"are you familiar with the "" data is beautiful "" subreddit ?"
282903,it's not clear to me how you are using l to select sub-units from within the psu . can you explain that more ?
283028,have you considered the possibility that your respondents may have been a volunteering subset in the population ?
282359,"do you think that { $ x_i p_i sim mathrm { bernoulli } ( p_i ) $ and $ p_i sim mathrm { beta } ( alpha , beta ) $ } is the same as { $ x_i sim mathrm { bernoulli } ( alpha / ( alpha beta ) $ } ?"
282645,"group is a dummy : maybe 0 for control , 1 for treated . what is treat_time ?"
282460,what is rls here ?
283114,"the weighting they suggest is $ f ( x ) = int_w p ( w = w mid x = x ) f_w ( x ) dw $ . note $ p ( w = w mid x = x ) $ the posterior usually is computed via bayes rule $ p ( w = w mid x = x ) = frac { p ( x mid w ) p ( w ) } { p ( x ) } $ . you can see that $ p ( w ) $ is the prior on the parameters . that is by definition the regularizer . furthermore you are using the updated prior on the model to predict , so in this sense , is there anything better you could considered ?"
283130,55 observations and 20 variables ?
283104,"your title doesn't match your body text as far as i can see . the means and variances and covariances of the elements are all easy , but if you're dealing with the sum of the squares of the first $ k $ elements , then that's not "" the variance of the multinomial "" . do you need the distribution of the sum of the squares for something ?"
283172,not an answer but a hint : have you checked the formula for $ r ^ 2 $ ?
283152,have you made a search here on ` pca normality ` and ` k-means normality ` ?
283214,could you explain why a forecast error would be relevant to your estimate ?
282319,"sycorax , it isn't clear to me the op is asking about software . it seems to me that your comment answers the question . why not develop that into an official answer ?"
283237,"but keywords are totally enough to identify the licenses , aren't they ?"
283249,please clarify why you want to use a matching technique in the first place . what's the objective of your analysis ?
283300,"lots of methods are consistent for a conditional mean , and given that conditional mean , further conditional moments can be looked-at . can't you just take any consistent-for-the-mean estimator and look at its conditional higher moments via the residuals ?"
283268,which kernel are you using ?
283337,can you explain the underlying problem in more detail ?
283375,what is the goal of the model ?
283169,"what do you mean by "" masked image "" here ?"
283442,why not 110 % ?
283498,"can you clarify what you mean by "" learn a mapping "" ?"
283541,are the 'explanations' different for the four groups ?
281022,"the language in the question is still a bit vague . if you would be so kind as to improve it , i will vote to reopen the question . can you do that ?"
283554,do you know something about the delivery days with high amounts ?
283623,"were the acf and pacf that you plotted computed on the original , undifferenced series ?"
283688,do you want intuition or rigour ?
283698,"you can just do the same thing , can't you ?"
283712,what model do you have in mind ?
77375,hi josh . i'm not entirely sure where to best direct you off-hand . you might look in boyd & vandenberghe ( available for free online ) to start . i will hunt around here in a bit and see if i can give you a more definitive pointer . are you familiar with convex programming ?
7742,is q a distribution over e ?
283679,you are asking much too broad a question about your analysis strategy . could you find something specific to ask ?
3215,could you confirm that ( a ) d1 and d2 are the side lengths ( and not angles ) ; ( b ) that you are assuming the angle between them is a right angle ( for otherwise the atan formula is suspect ) ; and ( c ) that you are interested in the distribution of one of the other angles of this right triangle ?
261827,whats the problem ?
283761,what does each feature value of the input matrix represent ?
283769,is this time series data ?
283774,what makes you say they are different ?
283776,what makes you think the sample space has been reduced to only red cards ?
283839,"to clarify , do you mean that if the rct was assigned 50 / 50 , a 4th grader has a 25 % probability of being in treatment ( 50 % of being in treatment school and 50 % of being assigned treatment within school ) and a 3rd grader has a 50 % probability ( 100 % of being in treatment school and 50 % of being assigned treatment ) ?"
283869,a physical model might help you think through this . let the 40 items be white . paint the three chosen items red . put the 37 remaining white items and the three red items into a box . mix them thoroughly . model the selection of a pair of items by drawing two items blindly out of the box . * what is the chance that both those items are red ?
283829,can you add more detail about your question ?
283875,"i'll bet that if you were to run either of those commands again , you would get yet seven new imputed datasets , too : that's the nature of "" multiple imputations for incomplete multivariate data by gibbs sampling . "" the documentation states that ` m ` is the "" number of multiple imputations . "" it's hard to know what one could add to that description . what kind of answers might you be looking for ?"
283836,please state your hypothesis and key objective ?
283889,p-value of what ?
283763,have you tried using bayes to calculate $ p ( text { snitch in box i } text { snitch not observed in box i } ) $ ?
283115,"do you know anything about the classifier that was used ( eg , random forest , neural network , etc ) ?"
283912,have you tried adjusting your network architecture ?
283922,""" i want to investigate them "" what is your actually research question ?"
283878,"what would "" best "" mean in this context ?"
284039,"this model does not make sense to me , why do you want to treat ` substance ` as a random effect ?"
283965,"if you got 3 "" replicates "" and 10 observations per "" replicate "" , probably you observations are the replicates , and what you call "" replicates "" ( individuals ?"
284046,is this a question from a course or textbook ?
284055,did you find the answer ?
284073,"can you add more detail such as what your data are , what the goal of analysis is , what tests you performed , and how you came to this conclusion ?"
284126,"can you elaborate a little bit . if i understand you correctly , you're building features $ x_1 $ such that it is the average of the first 100 points , and $ x_2 $ the average of the next 100 pts in a time series , and so on . so the features themselves are time series , is that what you're thinking ?"
283170,possible duplicate of [ what is the root cause of the class imbalance problem ?
284153,"i think resample the minor class or subsample the major class will help . btw , your output graph is very beautiful , what tool or lib do you use to draw it ?"
284170,do you mean stand for ?
284259,"could you please explain what you mean by "" more related to a set of other variables "" ?"
284313,ok . i was confused since you said using it yields ( past tense as though you've already performed the analysis ) . what is your dependent variable ?
284324,"all i can imagine is that you might be misinterpreting the summation notation . this identity is much simpler than you might think . why not write out the sum for a small $ n $ , such as $ n = 2 $ , so you can see what it means ?"
284353,"if you know * a priori * that the distribution is normal , why not use $ bar { x } $ to estimate $ mu_ { x } $ and $ s_ { x } $ to estimate $ sigma_ { x } $ ?"
284338,what is depicted on the y axis here ?
284402,it looks like you are asking for code help . we don't do that here . what language are you using ?
99172,""" * but does this mean that the means are equal or that we have no evidence to suggest otherwise ?"
284460,very low compared to what ?
284474,could you post the data or something that approximates the data ?
284432,i'm not sure i understand what it is you are trying to do ?
284379,"i think you will need to be more specific about what you mean by "" random . "" the post intimates that you are undertaking considerations of * stationarity * and perhaps * serial correlation * , but that you are unconcerned about uniformity of states or of transitions between them . evidently you are focusing on more subtle characteristics , but which ones , exactly ?"
284502,i don't think you should have gotten this far without a statistical analysis plan that would answer your question . could you describe your analysis plan briefly ?
284515,how is the model going to be used ?
284360,is the sample mean of the sample variance of the iqr definitely theoretically t-distributed ?
284533,"you said $ n = 12 $ , but there are 12 dots in the graphs . you said you have one dependent variable , why you have two qq plots ?"
31123,"i do not understand this question . ( i may be alone in this . ) exactly * what * do you mean by "" frequentist "" ?"
284580,"after such a procedure , what is really left of your original data ?"
27573,"if the data are separable , does not any solution obtained by rosenblatt's perceptron algorithm give zero training error under 0-1 loss ?"
154277,"there is a rich , infinite variety of metrics one could construct . how to choose among them depends on why you're doing this . what's the objective of your moment-matching exercise ?"
283573,"you state you have four bags of each size . on what basis , then , have you * paired * them ?"
284620,"i only have a newer edition of shumway & stoffer , so i have not checked the reference , but why do you think there should be a seasonal unit root ?"
284689,is this a question from a course or textbook ?
284686,"1 . "" not normal "" does not imply you have to use a nonparametric test -- there's an infinity of parametric tests that don't assume normality ( and indeed apparent normality doesn't imply there's a problem with a nonparametric test either ) . . . 2 . kruskal wallis is not normally a test for a difference in means . ( e . g . you have have a significant kw with identical sample means . ) . . . 3 . it's not clear what you mean by "" single points difference "" . . are you saying that you seek something like pairing but with associated triplets rather than pairs ?"
284707,how are the categorical variables coded ?
284585,"$ hat mu $ is your sample estimate of the population mean . if the sample mean was reaally small , you'd want to reject , right ?"
284728,why do you want to use bayesian linear regression if you want to use it * exactly the same * as frequentist linear regression ?
284766,"okay ( yeah , i meant jensen's inequality ) . look at $ s_p ^ 2 $ . if you take out the denominator , and divide both terms by $ sigma ^ 2 $ what is the distribution ( hint : it is $ chi ^ 2 $ , but you need the df as well ) ?"
284641,hint : what are the mean and variance of this distribution ?
149700,how many observations do you have ?
284753,could you state your question and why the original analysis doesn't seem to give you an answer ?
284840,"interesting question . perhaps you could look at the lower bound of some confidence interval ( e . g . , 80 % , 90 % , 95 % , 99 % ) for predicted values ?"
284433,have you tried looking up existing related questions ?
284248,what's $ h $ ?
284881,what is the mean of $ x $ ?
284912,what about the group of 0-79 % and what about the group 120 % ?
284907,"if $ p ( beta , sigma ^ 2 ) propto sigma ^ { -2 } $ then how can it be normalized ?"
284936,there is no way your array of values around $ 450 $ corresponds to the box-pierce statistics for the data shown in the graphs . could you clarify what those values actually are ?
73131,in what way ( s ) were the scores you computed inadequate for your purposes ?
279926,is this a homework question ?
283673,what is the $ ^ { t } $ nomenclature representing here ?
284993,have you considered maximum likelihood method ?
285017,"what is "" significance test on the difference between the two ( from pre-test , and from post-test ) dependent mean proportions "" ?"
284815,what is ` glme ` ?
285051,also there seems to be something weird going on with your data . more than half your observations stay only 0 . 5 a year ?
285056,"this is a fun question . my approach would be similar to your four classifiers with a gbm model , and i'd try to understand why the predicted probabilities for similar animals are not similar . have you tried this with different classifiers ( e . g . , random forests ) ?"
284958,"thank you . although you have now described $ f $ , it still vanishes from the scene immediately , showing that the problem you have described ( constrained maximization of $ m $ ) bears no relationship to the problem you began with ( find a region enclosing a given probability of $ f $ ) . which of these two different problems are you trying to ask about ?"
285142,"do you want to know the correlation between them , or you just want them to be correlated in some way ?"
285151,i think that you should calculate alpha analogously with the way that the scale is scored . how is it scored ?
273140,can you provide more information about the personality ratings ?
263875,approximately how many assignments do ta's grade ?
285203,"this doesn't seem so much like "" learning "" as * figuring out * : there ought to be at least one solution and , if you provide additional criteria for choosing among multiple solutions , one * best * solution . a useful preprocessing step might include a generalized hough transform ( to detect squares ) , as described in a related thread [ about detecting circular shapes in images ] ( url ) . incidentally , did you intend that "" what we recover "" does * not * match the dots in "" an example layout "" ?"
285222,have you considered dimensionality reduction ?
285240,so what is the bottom axis ?
285230,1 . i don't claim the t-test is appropriate or not -- it depends ! i could suggest some values of $ p $ for which it would not and others where it would be fine . wasn't figuring out if the t-test would work okay for whatever circumstances you had in mind the point of the simulation in the first place ?
285312,( 1 ) the p-values are different because these are completely different statistical procedures that make different assumptions about the data's distribution . ( 2 ) is it fair to say you don't have a good sense of the data's distribution ?
285334,you only have ten samples in your training data ?
285352,"what do you mean by , say , ` exp [ 1 ] ` ?"
285368,"look carefully at the formula for your e-step , especially the parentheses . are you sure you got them right ?"
285342,can you say more about what your data are ?
285395,"going solely from what you have written , the first formula for $ c_f $ asserts it is a scalar multiple of $ v_f $ and the second formula asserts it is a scalar multiple of $ a $ . how could that be true unless $ v_f $ and $ a $ are multiples of each other ?"
285382,"is it multivariate or multiple regression , i . e . many dependent variables or just one dependent variable with many covariates ?"
285402,"if you have no calibration and the response is nonlinear , then what possible chemical meaning could those areas have ?"
285391,"what is "" locality "" ?"
285407,why are you training on input data that differs from your test input data ?
285256,"if you are after seasonality ( which means frequencies at least 1 / year ) , and you find this in the monthly data , then you can be sure that the annual data won't contain it ( nyquist theorem requires you to sample at least twice a year ) . or am i missing something in what you are trying to do ?"
285509,"i'm not sure if this will be a good fit here , we can see what people say . are you looking for help w / your code , or code check ?"
285504,doesn't the penalty to counter overfitting in svms * increase * with larger c ?
285530,why this particular test ?
285539,hint : what is the area under each curve ?
285454,"more context would be helpful , this is pretty generic . for example , does it really make sense in your context to assume all the observations in the same group have exactly the same probability of success ?"
285558,have you thought of genetic algorithms to modify the input ?
285564,why do you need to use a logit ?
285571,"since your title gives the obvious answer , could you expand on what kind of responses you might be looking for ?"
285585,are the 550 observations within the 7 projects independent ?
285562,constraint # 3 is unclear . what's the purpose ?
285609,can you tell us the source of this problem ?
285556,what kind of answer is sought here ?
285621,"based on the cullen frey plot , the beta distribution may be a good choice . is your data bounded ?"
285641,could you tell us what you hope a pca on circular data might * mean * ?
285668,what are your aims with the survey ?
285576,this question is a little too abstract and cryptic to seem answerable at this stage . what does your notation mean ?
285614,could you provide more information to your question ?
285719,is all data complete ?
285726,do you only have the single year ( 2006 ) ?
285769,"two comments ( a ) do you have the corresponding sizes of the studies , perhaps the area concerned ?"
285779,"a few clarification questions : 1 . you say that data range from 0 to 1 , but you are trying to tell if they are significantly different from zero ?"
285607,what do your variables look like ?
285791,"i don't think that you'll get a definitive answer here , because none exist . what might be useful here would be some sort of community wiki where people answer the question "" how do you tune your hyperparameters , and why ?"
285801,jakewestfall could you elaborate ?
285808,this depends on your research question of interest : do you suspect an interaction ?
285831,could you give more details about your dataset ?
285771,can you say more ?
285883,is this a homework problem ?
281913,"not sure which is the difference with your other question . anyway , great to see statistics being used to study whale sharks : ) what about getting in touch with the statistics department of your university ?"
285904,why would you take a seasonal difference instead of adding a seasonal ar term ?
285930,"what do you mean by "" minum co2 percentage "" . if your target is something like 40 % , 45 % , 56 % what minimum are you talking about ?"
285961,can you elaborate more about the data that you are dealing with and what you want to get out of it ?
285974,"please spell out your acronyms . what is "" pcp "" ?"
286003,"( 1 ) zero as a value would appear * a priori * to be impossible , thereby ruling out the poisson as a model . but why is $ 1 $ a possible value ?"
286025,row / column sums of the correlation matrix ?
286051,""" distributed normally "" do you mean "" uniformly "" ?"
286048,let me ask a couple of questions first . how many images like this do you have ?
286154,could you explain * why * these values have become missing ?
286152,"jamiemac thank you for your quick reply . however , i'm not sure if this is a clustering-derived problem , is it ?"
285969,"your question might be a bit broad . first of all , what kind of tool are you using or would you like to use ?"
286175,"please , help us to understand your problem better . you have some categorical variables , let's say $ n_x = 3 $ and you have categories apple , banana , cherry . you have some repetitions , say $ n_r = 10 $ . what would be your $ y $ ?"
286178,i don't understand your question . can you please specify what you are observing and what you are expecting ?
286170,you are asking us to make a lot of guesses about the structure of the data and the models you are comparing . could you fill in those gaps ?
286233,i'm getting warnings of failing to converge and largely unidentified . . . do you get this as well ?
286267,olegpavliv what is your goal ?
286052,""" nonparametric "" is a attribute of methods rather than of data . do you just mean "" non-normal "" ?"
286291,but can the ratio be bounded ?
286332,this question might be relevant url is relieff score ( assuming it is supervised ) computed using the full dataset or just the training set ?
189654,is this a homework exercise ?
286306,"thanks , but that still doesn't explain what they * did * . is what you called the dependent variable given as "" cd34 ( ) hcs count "" in the upper table , by any chance ?"
286343,"there is some confusion in this question . it begins by stating you have four * normally * distributed variables , and then it immediately contradicts that . the actual question is puzzling , because one generates lognormal variates by exponentiating normal variates . what , then , are you implicitly comparing when you are asking about "" any worse "" ?"
223160,can you post some of your data to give us a better idea of the data you're dealing with ?
286356,"it's not clear if you are asking us for how to code this or how to "" perform logistic regression "" generally ( i . e . the steps involved in carrying out the analysis ) . can you clarify ?"
286377,how much work did you put into this without an analysis plan ?
286396,perhaps it provides adequate power for the observed effect ?
286398,you need either strong assumptions or a strong result to test small samples . that makes it difficult to supply any kind of recommendation based only on the sample size . perhaps you could explain more about your sample and the assumptions you might be able to make about it ?
286409,when you say response ratio what exactly do you mean . for instance for number of nestlings what is tat divided by to get a ratio ?
143051,i don't think they are the same . have you tried it on some data ?
286424,have you try using smaller learning rate ?
286485,url . . . so $ text { var } ( x-y ) = . . . $ . . . ?
286005,"please do not [ cross post ] ( url ) at multiple stack exchange sites . also , have you checked related questions , e . g . [ these ] ( url ) ?"
286160,how do you know there is no variance within each consumer ?
285207,cross-validation ?
286436,"by "" locations "" do you mean * geographical locations * of the observations or * statistical locations * of the underlying distributions ?"
286598,a little confused by the naming of your variables in this post . the variables ` post . p1 ` and ` post . p2 ` suggest these are posterior samples . are these samples from the posterior distributions of the 2 groups ?
286613,"it's been awhile since i last used spss , but has process been updated to accommodate dichotomous outcomes ( it wasn't capable of this last i used it ) ?"
286629,"what exactly does the "" uncertainty "" $ delta h $ represent ?"
286626,"are you truly interested in the density or is it the "" gaussianity "" of the * distribution function * that actually matters ?"
286440,"irishstat , i honestly believe there is a lot to learn not only from the data but also from experienced statisticians such as yourself . but do you understand my point ?"
285892,"can you please explain what you mean "" just dross conceptually "" with an example related to a use-case ?"
286641,"out of interest , what is your formula for ` m ` ?"
286675,"why would you assume it should be "" immediately obvious "" ?"
76549,full reference please . why assume that we know it or will google it ?
286796,"so far , you haven't described any mechanism whereby a probability can be attached to the statement "" x belongs to d . "" since d is normal , literally * any * number can arise from it ( and all numbers have exactly the same probability of arising : namely , zero ) . so what are you trying to determine and how is x produced ?"
286808,sorry about not picking up on that typographical distinction--but isn't the quotation perfectly clear ?
286826,"a standard intuitive explanation is the "" tickets in a box model "" : [ search our site ] ( url ) . do you need an explanation at some other level of rigor than that ?"
286892,what is the purpose or the question you want to answer ?
286834,would [ understanding this acf output ?
286976,why extract features ?
286965,"check [ these questions ] ( url ) , maybe you will find an answer . now do you want to know how to select lag order in r ( a question about using software , thus off topic ) or what the theoretically optimal lag order is ( on topic ) ?"
287010,1 ) how is fm index used to compare dendrograms ?
287019,it's also unclear how you chose hyperparameters like the number of hidden units . did you tune these with cross validation ?
287024,"your question looks very similar to questions already asked on this forum . can you search / link to these , and tell us how the answers elsewhere do not answer your question ?"
287050,"can you not just simply do max ( 0 , fcst_val ) ?"
287069,is your question primarily about how to code this or how to debug a program ?
286444,"does this model compile , run , and give you contrasts that sum to zero ?"
287106,"i read the paper , and this paper is just like a statistical exercise . i guess w is related to mood's test , but the author did not say anything about it . also do you know what is "" predatory open access publisher "" ?"
287117,"i saw there was an attempt to edit the old one , with a decision pending . was it someone else than you who did that ?"
286415,"there are a bunch of issues with this question that will have to be resolved before it can be answered . ( 1 / 2 ) your first question sounds like an optimization issue , which we can't really answer without more information and context . why are you using ga ( rather than a deterministic hill-climbing approach ) in the first place ?"
287168,"there isn't a single multivariate beta , but any number of ways to make multivariate distributions with beta margins . are you talking about a dirichlet distribution or something else ?"
287192,"what would make a book "" good "" ?"
285453,"are the x's being conditioned on , as with a regression model ?"
287229,"at some point , don't you need to actually make a connection to some concept of "" financial stress "" ?"
287268,"if the question was already ask and answered , then what exactly do you need from us ?"
286649,i don't see anything there contradicting what i said above . can you point me to the exact statement that you think is contradictory ?
287290,the $ t_i $ values are not known ?
265985,is it possible to directly pool the bootstrapped samples and evaluate the calibration of that sample ?
286847,"there is some unclear points in your question and terminology . what is "" binary clustering "" ?"
287385,"the kernel is usually of somewhat lesser importance than the bandwidth . how are you defining "" best "" here ?"
287415,what are you actually looking for ?
287466,"that helps , but there are still some suspicious elements . for instance , do both ` filtered ( i-1 ) ` and ` filtered [ i-1 ] ` make sense ?"
287344,"welcome ! if i understand you correctly , you are asking which model is recommended for a specific research question . imo this is a fine question for crossvalidated . it would help if you add some information . what is the exact question you are trying to answer ?"
287530,where do you get the estimate $ lambda = 0 . 495 $ ?
287543,maybe google polynomial interpolation ?
287573,does wvs stand for world values survey ?
287593,"of * what random quantity * is this the "" variance per pair "" ?"
287633,where is the second distribution ?
287637,why are you interested in ordered logit if your data is not ordered ?
287659,is normality necessary for this ?
287669,"backing up , the fundamental issue is arguably not homoscedasticity at all but fitting a linear model to a outcome that is bounded ( and the bounds are attained ) . even if you choose to treat the outcome as measured , it is still bounded ! you are clearly aware of some of the issues here but i'd underline that many researchers would regard this model as fundamentally wrong as applied to this data . as an important detail , it's hard to see that a durbin-watson test is pertinent here outside a time framework . otherwise put , what order defines which observations are compared with which ?"
287687,"what do you mean by "" rolled up "" ?"
287386,are both routes used at the same time ?
287731,why do you think it might not be ?
287679,""" a solution in terms of probabilities at the end of a period for a line being in category 1 or 2 or 3 is required . "" what does this mean , exactly : the probability for it being in a category in an arbitrary day , in the end of the period , or something else ?"
287736,what are $ z $ 's here for ?
287767,perhaps r- packages are not backed by artificial intelligence . am i distracting you ?
287770,they both only admit all interactions ?
190883,do you have any hypothesis on why that might be the case ?
287825,what are the coefficient values - just out of curiosity ?
287836,could you elaborate on what you mean by homogeneous vs . heterogeneous groups ?
287809,are you operating within some statistical package ?
287791,"if it is "" only valid when $ alpha $ is 0 or 1 , "" then what sense does it make to plot values for all $ alpha $ in the range $ [ -2 , 2 ] $ ?"
287864,why do you have ` ( solution subject ) ` term but don't have fixed effect of ` solution ` ?
287874,can you say anything about the way in which - if it isn't uniform - what is likely to happen instead ?
287883,do you have access to the individual members' data or just the aggregate information ?
287084,"is your question mainly about how to choose a distributional approximation , or how best to fit distributions to binned data ( both statistical questions ) , or about how to approximately estimate a kde for grouped data ( a mostly statistical question ) or is it "" what commands do i use in r to draw a density to make this work ?"
287943,"are you looking for a single-step , closed form solution in the vein of , say , linear regression ?"
287958,"what do you mean by "" data is significantly different from 0 . 44 . . . "" ?"
287876,"can you clarify to readers what you mean by "" dgp "" ?"
287961,did you give a gap in training on day 4 & day . 5 as well ?
288031,your statements appear to be contradictory : would you expect $ 0 $ or would you expect $ 2 . 5 % times 17 = 0 . 425 $ ?
287857,"amoeba , why not develop that into an official answer ?"
288061,i might be misunderstanding something but what stops you from using a ( potentially regularised ) multinomial ( ie . softmax ) regression model and just get at running time a vector of number representing the probability of an incoming point to belong to one of the four clusters considered ?
288054,bootstrap the coefficients ?
288078,"look at it in reverse : for training the model , would you embed the images within larger backgrounds ( chosen in any fashion ) on the theory that the increase in the number of pixels couldn't hurt ?"
288032,"could you explain what you mean by "" is it fair "" ?"
288059,"it doesn't make sense to ask whether the mean of a vector ( or set of vectors ) "" is significantly different from zero "" : it either is zero or not . statistical significance attaches to a * hypothesis test * about some * model parameter . * what is your model ?"
288122,"do you have the actual numbers , or just the percentages ?"
288123,do you have a constant term in your regressions ?
288127,"are these diagnoses mutually exclusive , or is a patient 'able' ( in your data that is ) to have had multiple diagnoses during this 20 year period ?"
288104,"i deleted my post . . . your description of $ omega ( v , mathcal { d } ) $ was pretty clear . however , where did $ 10 $ come from in the second parameter ?"
288174,is this helpful ?
288180,"as i explained , by removing the fixed terms . which is not what you want to do , so why do you insist on a random model ?"
129847,why does this have the kalman-filter tag ?
288190,"could you explain , quantitatively , what "" best "" means ?"
288199,"for clarification , you write : "" i need to estimate how many calls we will need to observe in order to measure a significant difference of 0 % , 1 % , 5 % , 10 % in success rates for group a and group b . "" do you mean a difference in percentage * points * or actual * percent difference * ?"
288212,can you include the statement of theorem 4 . 2 . 1 in hogg and craig ?
288175,"you mentioned that you've read a number of posts . could you link to some of those in your post , so that other people that may stumble upon this question in the future can see where your train of thought came from ?"
288073,in the general case how many numerical values are possible in each point in the sequence ?
288248,is time to death really time to death or time to some unfavorable event ?
288095,"are you asking about the need to code categorical data into some type of "" contrast variables "" or _specifically_ into dummy ( one-hot ) type ?"
288146,"what justifies your deduction following "" so it has to be equal to "" ?"
288202,how many variables are there ?
288373,what was your sample size ?
288400,"analogously , is one in one the same as one million in one million ?"
288463,what is your question ?
288549,why not use ` lung_virus_counts brain_virus_counts ` as dependent variable in gamma glm ?
281436,"i have a feeling this question might be very interesting , but it is a long read with multiple questions 'hidden' among the sentences . could you reformat the text a little to show what your main concern ( s ) is / are ?"
288582,please add : what is $ x ^ * _i $ by definition ?
288614,"your data appear to supply no information about risk of death . to assess that , you would also need to know how many males and females were in each group originally--that is , the numbers at risk of dying . what are these data actually counting ?"
288664,do you want to maximise the information about the pairwise comparisons ( min . the ses ) ?
288320,"are you asking why , in the model $ y = x beta varepsilon $ with $ varepsilon sim mathcal n ( 0 , sigma ^ 2 i ) $ , we have $ hat beta_j sim t $ ?"
288673,why can't you just use the raw odds ratio as the predictor ?
288732,why do you assume it's better in the first place ?
288733,what is the version of excel ?
288245,"i'm confused by your description . if color is a single feature , such that you can dummy-code it , how can a single case have two colors ?"
288836,does the t-test involve measures collected at the level of the site or the level of the individual patient ?
288872,what do you mean by 50 % to 100 % consistency ?
287397,how many dimensions does the rv have ?
288815,"this now sounds sort of like a meta-analytic problem , where you want to take several effect sizes ( i . e . , pearson's correlations ) that have already been reported , and determine whether other factors ( i . e . , treatment or time ) moderate the size of pearson's r . is that sort of on target ?"
288928,could you explain why you think cagr ( computing a compound annual growth rate ) would be problematic for ratio variables ?
288942,have you seen a follow-up question by john with an answer by whuber ?
288948,what do you think about the answer ?
288629,i wonder if the [ woodbury matrix ] ( url ) identity can come into play here . i would think about the parameters in the sense of projection . i don't see how you derive your second e ( w ) expression . why is it correct ?
288823,do you mean the * dependent * variable is continuous ?
289012,what type of statistics is interesting to you or important for your work ?
289037,"yes , there is some confusion here and unfortunately it makes it hard to determine what you're really trying to do . could you tell us in what sense you are viewing * proportions * as "" categories "" ?"
289054,"the classic linear mixed model ( lmm ) analysis assumes that the residuals ( conditional on the random effects ) , as well as the random effects themselves , are guassian . this implies that the data have some multivariate normal distribution . it could be that the data you are dealing with is skewed , or doesn't have constant variance , in which case the lmm assumptions will not not satisfied . taking the log transform could help alleviate this issue . have you looked at qq plots of the residuals / blups , and a plot of the predicted vs . actual responses ?"
289060,"$ f ( x , y $ and $ g ( x , y ) $ are _random variables_ . so what does it mean hen you say that you want to _calculate_ $ f ( x , y ) g ( x , y ) $ ?"
288945,i think there is a confusion is what you write . can you explain in plain text what median ( x ) means to you ?
289161,"this doesn't seem to be well suited to lasso , as that will throw out some predictors regardless of how you pre-group them . that doesn't seem appropriate for this type of data based on states and classes . also , are you sure that you want to deal with these predictors as fixed factors rather than as random effects ?"
288998,"i'm not sure you'd want to do this manually by hand . why not just call in the numpy or pandas libraries and use their calculations instead of doing this by hand , or just use the pandas regression models ?"
289171,"you write sums . do you intend to restrict your question to discrete probability distribution or are answers for continuous distributions of interest , too ?"
289017,"could you please describe for us what "" overlapping changes "" and "" overlapping data "" are ?"
289244,"when you say "" then select k of these bins using some non-uniform selection criterion "" do you mean you choose the bins non-randomly , or they are chosen randomly according to some non-uniform distribution ?"
289251,what complicates the problem for continuous variables ?
289258,shouldn't 3 be 0 . 2 x1 x2 0 . 9 ?
289322,this seems spss-specific & so may be hard to answer for people who don't use spss . can you paste in your output ?
289185,"perhaps you need to add ` type = "" response "" ) ` to the ` lsmeans ( ) ` call ?"
289384,"dhineshkumar , what do you think about my answer ?"
289208,could you clarify the structure of the data ?
289400,the previous title suggested that you know that both bags have the same number of distinct words . is this indeed what you mean ?
289408,"i don't see why it must decay , which makes me wonder whether you have stated all your assumptions as intended . for instance , what is to prevent $ delta_1 = 1 $ ( which is needed for the fraction to be defined at step $ 1 $ ) , $ delta_2 sim text { bernoulli ( 1-p ) } $ , and $ delta_3 = cdots = delta_j = cdots = delta_2 $ ?"
289439,does [ this ] ( url ) help ?
289449,"someone can point me to a relevant citation if i am mistaken , but i have never heard of any controversy surrounding whether or not to check for homogeneity of variance before running a t-test ( and the commenter over at so does not provide any references ) . it seems like it would be a good idea to always check that assumptions are met when running statistical tests . . . ?"
290525,""" is this understanding incorrect ?"
289257,can you explain your problem further ?
289345,i think you have to step back and explain your problem more . what exactly is non stationary etc . if you are making predictions at multiple times how do you associate success with one particular time . ?
63786,what would you consider an error for the test rule ?
290566,"are you asking about test whether they come from the same * distribution * , without assuming any particular shape ?"
290584,are you using a particular test set ?
290608,what do you mean by * importance * ?
290642,the question is far too broad . what is the kind of data you are working with ?
24067,you ever find an answer for this ?
286239,are you sure the inicators are not intended to signal if the ramdom point is inside the circle ?
290767,what do you want to do ?
290810,"can you edit your question to tell us ( a ) who told you that it is a problem , ( b ) what their justification was ?"
290823,"please describe how you found this "" best "" model . what is the "" this "" that you want to have explained ?"
290842,"since you're presumably using generalized linear models to do your fitting in ( 2 ) why would you not simply use a continuous right-skew glm , like say a gamma regression ?"
290852,"the values 0 , 1 and 2 are counts ?"
290860,what type of model have you built ?
290826,"if you always write your improper integrals ( the ones with $ infty $ 's in the limits ) with explicit limits , what do you need to be true to make each of your manipulations hold ?"
290961,is x . 21 a binary variable ( either the tree is = 21m or it is not ) ?
290979,what are you hoping to use this model for ?
291013,"could you please explain the sense in which "" scalar "" is a type of "" measure "" and what any of this might have to do with spss ?"
291017,"i don't follow - how would you test what , exactly ?"
291039,"can you explain what your variables are , what you are attempting to achieve with each of your models , and what your scientific question is ?"
291064,"what is "" some outcome "" ?"
291072,would you consider obtaining the separate correlations between x and y for each level of z ?
290705,"can you show an outline of how you got from $ frac { l ( 0 , 0 ) } { l ( x_1 , x_2 ) } $ to $ e ^ { - frac12 ( x_1 ^ 2 x_2 ^ 2 ) } $ ?"
291040,what is a circular crown ?
291127,what are you trying to model ?
125608,"nickcox : would you also use "" indicator variable "" for the dummy variables in { -1 , 0 , 1 } used for sum-to-zero coding ?"
291178,what package are you using to construct the model ?
291189,how did you compute standardized mean change and what is smcr ?
291194,why bin at all ?
291107,how are you using the results of the model ?
291214,do you have a reference for mutual information as an acquisition function ?
291264,do both models give the same partial likelihood ?
291279,kmm lol how did you do that ?
291394,"first , methods like minibatch gradient descent tend to help "" jolt "" the solution out of local minima . second , global minima are often overfit -- acceptance of a non-optimal solution can be seen as a form of regularization . third , would not your method break down under certain shapes of the loss surface ?"
291396,describe the figure better . i don't understand the point colors . is it training / test sets ?
291417,"it's difficult to imagine any definite answer could exist , for the simple reason that although an * unbiased * estimator is well-quantified--its bias is zero--a biased estimator is not : its bias could be anything . where do you draw the line ?"
291419,could you explain the meaning of $ hat x- hat y $ in the denominator ?
291429,"you pulled a quick one in this question : in the situation you posit , nothing can possibly be normally distributed . the distributions of any possible test statistics are finite and discrete . if you use a normal approximation , then that approximation will always produce a positive p-value . but if you use a more accurate calculation , it could produce a zero p-value . those two conclusions aren't at odds with one another , because "" p-value "" refers to two subtly different quantities in the two cases . you might as well ask "" how is it possible for an approximation to zero not to actually equal zero ?"
291438,"in what sense would "" another method "" "" validate "" a value ?"
291460,you display a * left * skewed pdf in which the mean is clearly a little smaller than the median . are you perhaps viewing this plot in a mirror ?
291468,how does the equation you give relate to a regression model and its least square solution ?
291475,"have you checked [ the scientist and engineer's guide to digital signal processing by steven w . smith , ph . d . ] ( url ) ?"
1862,how about pca / fa ?
291607,how can it be stationary if the mean is different in two time periods ?
201959,recommend products that people usually buy together ?
8528,"if i understood you correctly , your final distribution is basically as good as your "" mock / randomly generated values "" for the objects . so - do you think you've sampled the distribution of your "" objects "" well ?"
291051,"should it be $ j $ for measuring identity , $ i $ for measuring condition ( with $ lambda_i $ for the condition instead of identity ) ?"
291757,not sure understand what you want to do . variance explained quantifies how much of the variance in the original signal is captured by the components you've selected . do you want to do something like choose the components that account for 95 % of the remaining variance after discarding the first 3 components ?
291780,"there's no assumption of constant variance of * residuals * in regression . there is a constant variance assumption however . ( btw can you please be consistent with residuals vs "" residues "" in your q ?"
291818,"does'nt make much sense to test for normality based on 5 observations , no power . what is your real goal ?"
89239,please clarify 'estimation problem' . what does the model do ?
291886,thanks for clarifying akie . i made some small changes to my answer . would you mind editing that clarification into your question ?
291927,e-mail the authors . . ?
291849,"your decomposition has already "" fit "" both a trend and seasonal component . those fitted components are available from the output . what are you trying to accomplish by "" fitting "" it again ?"
289426,is the customer's choice binary ( e . g . buy vs . not buy ) ?
291994,is there any chance you are confusing dependent and independent variables ?
292052,"i would be willing to bet a significant sum of money at very good odds that numerical integration is the only way to go . to clear up a point , is the end result supposed to be the kernel of a bivariate distribution of $ ( x , epsilon ) $ ?"
292066,"so success is bernoulli and time of success , conditioned on success occuring , is [ uniform ] ( url ) ?"
292113,"you also need to explain what you mean by "" overlap "" in this context . the normal distribution goes to infinity in both directions , so in one sense , they overlap completely . are you asking the proportion of the area under one pdf is also under the other pdf ?"
292147,are you asking how to find $ lambda $ mathematically or how to find it in ` glmnet ` model ?
292062,"it is , thank you . are you sure you have the arguments to ` dgamma ` correct ?"
291972,"i'm not sure i understand what your overall question is . you have datasets x1 and x2 ; and corresponding models m1 and m2 . and you want to know whether m1 fits x1 better than m2 fits x2 , as measured by aic ?"
292218,"could you please explain what these weights * mean * and what distinction you are drawing between "" applied to the fitted curve "" and applied "" to the base data "" ?"
292267,"as to the post you refer to , could you add what you are missing ?"
292324,what models are you comparing here ?
292346,"it seems like a multivariate normal distribution ( or multivariate student's $ t $ distribution , if you like ) checks these boxes . are there any additional requirements ?"
292326,"hi ! welcome to stackexchange ! i'm trying to understand , but it's very difficult to see the actual values until 2012 . . could you either plot each part separately or plot it on a logarithmic scale ?"
292341,"this remains a duplicate . the ` rsquared ` calculation used by ` caret ` is explained in the linked thread . the question of whether the calculation in the ( "" suggested by "" ) the linked thread is right is nonsensical . 1 ) if that's what this community has put forward in the past , why do you think this community will proffer a different answer now ?"
292356,"when you refer to "" most likely value "" in your penultimate paragraph , do you mean : ) that you really want to estimate the mode ?"
292297,have you considered using the akaike information criterion over your parameter complexity and evaluation criteria ?
292382,n unique what ?
292023,one problem with presenting code is it can be hard to distinguish between mistakes in the ideas ( the algorithm you intend ) and mistakes in implementation ( what code you actually wrote ) . it's much easier if you clearly explain the idea so that we're not conflating two sets of issues ( and then we're not stuck trying to debug your code - which is off topic here ) . when you say the variables are correlated is this intended to be conditional on ( i . e . within ) factor level ?
292315,"i'm unable to run your example at the moment , but a couple of clarifying questions : is there a particular reason that you are ending your investigation with cv . glmnet , and are using cv . glmnet on the whole data set ?"
292394,is there something wrong with the table you are presenting ?
260661,the unsolved mystery here is what the first column is doing ( the one with no header ) . does the help for whatever software you are using give a clue ?
292432,"welcome to cv . since you re new here , you may want to take our [ tour ] , which has information for new users . is there a specific reason to remove the constant ?"
292405,did you really intend what you have here : ` mu --fitted $ estimate ` ?
292507,"if you have seasonality and / or trend , then your time series is by definition not stationary . daily sales data typically exhibit [ tag : multiple-seasonalities ] , which arima models don't capture , so i'm a little surprised that arima should yield the best forecasts - you may want to look through previous answers in that tag . why do you explicitly want to use nns ?"
292526,pyxel have you checked this out ?
292554,what software are you using ?
292582,"the first one is just bayes' rule for the variables $ d $ and $ ( theta_1 , . . . , m ) $ . the second looks like some decompostion is assumed , maybe the author assumes something ?"
292585,can you post a mockup ?
292589,"i'd strongly suggest taking up r to do these models , as checking for this would be pretty simple . is there a way to save random intercepts ?"
292597,i'm not sure i follow this ; what statistic would be exchangeable under the null here ?
95947,if $ y $ was itself conditioned on some $ x $ then wouldn't this fall exactly out of the simpler version ?
292609,are you asking for how to parametrize the model to include seasonal components ?
292620,"do you have separate data streams , some of which are derived from identical markov processes , so the goal is to identify which sequences come from the same process ?"
292631,not clear to me why you want to use your instrument on only one dummy ?
292642,""" e "" stands for technique ?"
292651,are you asking how to [ use lm ( ) to write your own function ] ( url ) to fit arma models or are you asking [ whether there is an arimax package for r ?
292676,can you tell us more about your data . what are the green and blue lines on the graph ?
123367,you should give some more detail . how many regions do you want to use ( assume has the same visibility parameter $ p $ ?
292687,"does the distribution in question range from negative infinity to positive infinity , or is it bounded somehow ?"
292719,does these 40k binary features result from dummy coding of categorical variables ?
292743,see [ does testing for assumptions affect type i error ?
292546,"i don't understand what you are doing . you are calculating rmse for what exactly ( it is a measure of model fit , so i can't see how do you use it for comparing subpopulations ) ?"
292771,do you always want the smaller angle ?
292754,are the actual criteria for a wrong record that simple ?
286960,""" it means that controlling for test score increases unemployment "" -- how did you arrive to such interpretation ?"
292784,"endocranial volume is * not * normally distributed ; you know this for certain without testing it , since it cannot be negative . failure to reject with some test simply means your sample size was too small to detect the ( possibly small ) deviation from normality . if you're tempted to say "" i want to know if it's * approximately * normal , then the usual goodness of fit type hypothesis tests are entirely the wrong tool to answer that question . ( what are you trying to find out for ?"
293808,"it seems that you're removing duplicated values , not values that overlap between groups . can you explain your reason to remove them , or how these duplicates arise ?"
293898,"if somebody suggests you to nest season within site , why don't they suggest to nest color within site as well ?"
293923,this is just change of variables url this is purely a calculus issue . here are two videos where a professor at mit explains how it's done : ( 1 ) url ( 2 ) url are you sure that you have the basic mathematical prerequisites to be attempting to learn about this topic ?
293875,what are you trying to achieve ?
266059,"nice work . i think that for the bottom half , $ eta = 0 . 9 $ or $ eta = 1 . 0 $ gives not a bad fit . of course you can consider topics that are more evenly distributed , but i imagine they are of little use . how would you interpret a topic that is uniformly distributed ?"
293852,"when you do the sign test you use the binomial with $ p = 0 . 5 $ but you could use nay value you wanted instead . but i somehow feel that is not what is bothering you here , would you like to edit your question to explain more if i have not understood you ?"
292619,so the procedure will give you only those 5 choices . but percentile method is ambiguous . is it efron's or hall's percentile method ?
293995,"afaik , granger causality is not about which variable moves first . how would you explain that ?"
293955,"what are "" normal equations "" ?"
292532,i'll answer that soon . ( i'm travelling a lot lately . ) could you edit your question to include this new question ?
294020,"( 1 ) what would you do if the data were $ ( 0 . 5 , 0 . 6 , 0 . 7 , 0 . 8 ) $ ?"
294029,fea = finite element analysis ?
294065,"since the mean in a one-parameter exponential is a * scale * parameter , the more typical way to compare means of exponential distributions would be as a a ratio ( * does the ratio of scale parameters differ from 1 ?"
294087,"it depends on the interpretation of those probabilities , which in turn depends on the structure of your data . can you describe in detail how the data to fit these models was collected , and the structure of the training data itself ?"
288200,"describe the problem mathematically . like : 52 cards are dealt to 4 people , what is the probability that any player got 13 cards of the same suit ?"
294112,"if you already know the wald test does not work , then the same source perhaps have some suggestions for a valid alternative ?"
294120,"to give you some intuition on why counts is necessary for any statistical test , here's an example : let's say i tell you in group a , 60 % of people are male and group b , 50 % of people are male . is group a systematically male biased ?"
294130,what data about the books is available to the classifier ?
294168,"what do you mean by "" normalize "" ?"
294194,so what ?
294298,"i'm really unclear on your setup . most critically , if you have a single variable measured pre- and post-treatment , how is it that your data are not paired in a manner appropriate for a paired t-test ?"
294332,whats output when weights are zero ?
294352,"let's assume that you discovered that $ b_1 , b_4 , b_5 , $ and $ b_7 $ all equaled zero . would you still want to omit $ b_2 , b_3 , $ and $ b_6 $ ?"
294360,"what do you mean by "" percentile "" ?"
294327,"since $ x_iy_i le x_i $ and $ mathbb { e } ( x_iy_i ) le sigma $ , isn't the sub-gaussianity immediate ?"
294387,"what you've written makes it sound like your dataset has 100k points , and you are randomly drawing from it to create one with 280k points . have i understood you correctly ?"
294391,"i think you need to better define what you're trying to accomplish by combining these metrics . as you have seen , there are an infinite number of ways to combine n1 and n2 to get a unified metric . none of them are intrinsically "" better "" than any other . do you want elements that do well in any score ?"
294398,is $ omega $ restricted to numbers of the form $ 2 pi n / n $ ?
294437,i now see where perhaps we may be talking past one another slightly . i saw the [ tag : sem ] tag and placed your question within the context of a structural equation model . perhaps you understood the tag to refer to simultaneous equation models ?
294450,can you perform a shapiro-wilk test for normality on the residuals and report the p-value ?
294483,"( 3 ) interestingly , it seems the median is never a sufficient statistic - see [ when if ever is a median statistic a sufficient statistic ?"
294455,"we'll need a lot more details about your networks' topologies ( type and number of layers , activation functions , etc . ) , your datasets ( size , type of images , differences between test and training sets ) to give you advices and tracks for improvement . additionally , have you tried to train the networks on one part of your first dataset ( 1 to 10 objects ) and test in on the other part . how do their results compare with the results on the test set ( with images with all numbers of objects and with images with 1 to 10 objects ) ?"
294323,i don't see a question here . does the accuracy stay the same if you increase the number of hidden units ?
294488,"for those of us unfamiliar with the abbreviation , can you expand on what gee is ?"
216222,"welcome to cv . as it stands , your question is quite sketchy and risks being deleted . please elaborate on factors related to your question : is there an analytic context for this query ?"
294548,"you say "" i want to estimate parameters of the distribution "" , which parameters specifically ?"
294565,"if you know the pattern you are looking for , then convolving with a template of the pattern can be used to detect its presence , this is how convolutional neural networks work . but how to detect any kind of general phenomena that exists a few times in a series of data is a difficult question to solidify . what is a pattern ?"
294567,why do you think boundedness will help you determine if you minimum is global instead of local ?
294606,* * hint * * : the lengths of ` qsim ` and ` qcon ` are $ 14 $ and $ 12 $ . have you noticed that $ 165 3 = 168 = 14 times 12 $ ?
294653,"what rule of probability , and what assumptions , justify taking the eighth power in your solution ?"
294663,are you familiar with gradient descent ?
294665,"did you try the standard encoding with dummy variables ( one per category , without reference category ) ?"
294682,"is that 30 per group , or 30 total ?"
288019,is ` time ` measured with the index of the series or with a separate series of values ?
294713,can you explain what your results are ( possibly include them here ) and why they are so unexpected ?
294502,"do you only have 5 days i . e . , monday thru friday in your data ?"
294738,how big is your data set ?
294740,"- are you asking for the probabilistic model / loss function that has this estimator as the optimal estimator , or are you asking for a common loss function used by statisticians in this-or similar-context ?"
294794,what do you mean by close-to-optimal ?
52103,would a random slope in the group indicator do the job ?
54882,what is the fixed interval at which measurements are taken ?
56422,"how do you get "" $ binom { 4 } { 2 } 3 $ "" ?"
61659,"isn't this essentially the [ same question ] ( url ) you asked earlier , apart from the mention of mixed models ?"
68607,"depending on your model , there is a logic to this in so far as the different subseries could be considered as realisations of the same generating process . depending on your data , i would guess wildly that this won't work well because of side-effects of the subseries not joining smoothly . aren't bull and bear both nonstationary any way ( not my field at all ; correct my ignorance ) ?"
294310,"it sounds like "" abstraction "" . are you asking if a human can abstract based on the matrix , or if another network can do that ?"
294907,why have you applied min / max rescaling instead of zscores ?
294957,do you mean your dependent ( output ) variable ?
294946,this is hard to follow . can you provide a small example dataset to illustrate your situation ?
294960,"it seems like this would just be regular linear regression , right ?"
294965,"a question like "" is there a way to get the list of split-thresholds for each feature ?"
295004,take a look at ` residuals ( usfaceavgarima ) ` . does it look seasonal ?
56682,what is ` to correlate data ` ?
295075,what is the domain of the random variable ?
295071,"wouldn't you need multiple copies of the n tuple $ x_1 $ , $ x_2 $ , $ x_3 $ , . . . , $ x_n $ to estimate each mean and variance and compare to see if they are the same ?"
295094,"this question is too broad . besides , it is potentially too tied with a specific program / software . have you read any texts ( books , articles ) about how to choose the number of factors ?"
295096,"exactly what kind of "" relation "" are you seeking ?"
294725,( 1 ) for the formula . do you also allow $ bar y $ to be a sample average plus $ mu_o $ ?
294929,"if your question is just , "" if ` lme4 ` can estimate the random-effects for new subjects given a fitted model "" , then it is about ` lme4 ` , not statistics . but , * how to * 'estimate the random-effects for new subjects given a fitted model' would be a perfectly on-topic & good question here . which are you really interested in ?"
295132,are you not concerned about multiple testing ?
295110,how are the two variables coded ?
99647,what is the cep ?
295169,at how many time points are they measured ?
295194,perhaps you should scale your data so that its area is 1 ?
295262,can you clarify the structure of your data ?
295271,what was wrong with benoit's answer ?
295274,"yes . but for your question we don't need to care about how to estimate the variances ; your question ( i . e . the quote in your question ) is i believe only about estimating the global mean $ mu $ and it seems obvious that the best estimator is given by the grand mean $ bar x $ of all $ n = nm $ points in the sample . the question then is : given $ mu $ , $ sigma ^ 2 $ , $ sigma ^ 2_a $ , $ n $ and $ m $ , what is the variance of $ bar x $ ?"
295286,could you post the results of your model & the post-hoc comparisons ?
295381,how much data on spending do you actually have ?
295336,"plot the data ! maybe the ones you suspect pipetting errors stand out , then maybe you should simply remove them ?"
246930,can you please link to the paper ?
295361,"it sounds that you are considering just the case with 2 classes , aren't you ?"
295441,"what do you mean by "" the standard deviation "" ?"
295448,i rarely see confidence intervals provided with weather reports . do you have an example of this ?
294948,this is hard to follow . can you provide a small example dataset to illustrate your situation ?
295509,i don't understand your output- are those coefficients for one of the predictors across the 10 groups ?
295405,"so you have 3 trees per treatment combination , i . e . in total 12 trees ?"
295573,what is the dimensionality of your densities ?
295571,any explanation for downvote ?
295313,what is zobs . . ?
295427,what is lda here ?
78024,"are you , in effect , trying to integrate out the categorical variable to get an estimate of the unconditional probability of the latent bernoulli variable ?"
295623,assuming damages is your response and family and k are your predictors then why not use glm ?
154294,what link function are you using in the negative binomial regression ?
35876,is $ c_0 $ the same for all functions in the $ mathscr { g } $ -class ?
295661,"have you tried having two regressions , one for men , one for women ?"
295048,"i can't understand the distinction / potential problem you are pointing out . of course a given product can only be sold w / or w / o the rebate , that's the way it always is . so what's the problem here ?"
295683,can you provide some example data ?
295690,are you wanting to have something of the form h ( t ) = a * f ( t ) error prior to t1 and h ( t ) = b * g ( t ) error after t1 ?
115812,why did you transform the predictor ?
245247,"what do * you * mean by "" truncated "" ?"
294699,"what does it mean to "" get "" species of setosa ?"
295770,"is this a problem of time series analysis or is the word "" forecast "" being misused here ?"
295789,"do you need the locations of the points in the new coordinate system , or are you asking how the new dimensions relate to the original variables ?"
295800,what kind of test are you wanting to do ?
295861,"rather that modifying your existing data , would it be possible for you to switch to a more difficult problem / dataset ?"
295875,"you asked "" is there anything . . . which can produce vectors of lda and generate the relation matrix between features and those vectors ?"
295881,"i assume that $ g_i $ is your target variable , and $ x_i , y_i $ are your right hand side variables ?"
174089,"this question ( especially the particular framing of the comparison ) reads like a question for a class , or a question from a textbook . is something like that the case ?"
295781,why categorise the counts ?
295953,"i don't understand option 1 ( specifically , the "" over the whole dataset "" part ) . could you elaborate ?"
296033,your expression for log loss appears to be incorrect . i think you mean that the second term should be $ $ ( 1-y ^ i ) log ( 1-h ( x ^ i ) ) . $ $ is this correct ?
296121,""" what's the deal about x "" is too vague / broad . please keep to specific questions . your third paragraph is unclear -- who uses such points for that purpose ?"
296014,"can you provide a reference for your statement , "" * i often read that the "" naive bayes "" classifier , is optimal for the 0-1 loss * "" ?"
296163,are you sure this is the posterior distribution ?
296213,are you interested in the covariance between a and b over your sample that gives the p ( x ) or over the population that gives you the sample ?
296237,is there any reason you can't combine all your samples into one big sample ?
296248,reduced row echelon form or pca ?
296257,"what is it you want to learn from , or do with , this model ?"
296230,can you explain your reasoning behind the expected cost for naive bayes ?
296283,you have introduced new tags pst and vlmc . can you please add tag wikis ?
296296,ctd . . see [ is normality testing essentially useless ?
296305,did you look at url ?
296356,that approach does not generalize from means to correlations . why not compute the 95 % confidence interval on the difference ?
296385,""" not k-th smallest value "" is not a random variable : what , then , is your question ?"
296391,can you say more about what's going on here ?
296390,what do you mean by fast ?
296377,"this : "" or should i do a two way anova without the interaction term , so i could control for the correlation between gender and musicianship , thus getting the gender unbiased estimate of musicianship effect on dv ?"
296415,"are you looking for intuitive insight on this particular problem ( e . g . whether it is the correlation $ gamma $ - $ delta $ or the correlations $ gamma $ - $ mu $ and $ delta $ - $ mu $ ) , or are you looking for intuitive insight on the general problem ( ie . the concept of hierarchical centering ) ?"
296440,could you provide a direct quote and reference for jaynes ?
291985,"i count as non-technical in this area : i have never used garch . what i see is that the methods both show low correlations and broadly agree . perhaps in your field the correlations seem interesting . in some areas a correlation around 0 . 1 is a discovery ; in others a correlation below 0 . 9 signals a failure . i would want to know how much data each was based on , why the differences are as credible as the similarities and why you want to tell me that one method is better . # 3 is bogus as a criterion : why not argue that a method that's been around for a century has proved its durability ?"
296471,possible duplicate of [ what is the reason why we use natural logarithm ( ln ) rather than log to base 10 in specifying function in econometrics ?
296470,"welcome to the site . this is rather unclear . what is the "" fitness "" of a variable ?"
296503,"by subtracting the right hand side from the left , you obtain the covariance . this is extensively discussed and interpreted at url are you looking for anything different than that ?"
296518,"your question is contradictory : on one hand you say that you don't care about the parameters , on another , you are interested in learning "" extra information "" about your model -- so what exactly do you want . . ?"
296273,"are you fixing the quantile ( i . e say , so that we have $ 0 . 25 $ probability to the right ) , or the corresponding value in the support of $ x $ ?"
296547,do you expect an individual supplier's inventory to be a linear function of time ?
296556,your premise is flawed . . . where did you hear that you must normalize variables in classification problems ?
294910,is your objective to forecast complaints or simply identify whether there has been a significant increase in complaints ?
296587,what's the parameterization of this burr ?
296601,"i suspect that you have a problem of unbalance data , could you provide more information about your results obtained by rf and nn ?"
296620,do you expect all of your correlations to be non-negative ?
296631,are you wondering about the actual writing part ( as in whether you should write this in your methodology ) or the statistics part ( should you follow those steps to conduct your anova ) ?
296636,why not to use the probabilities ?
296243,"a full factorial would be $ 3 times 5 times 6 = 90 $ total runs ( you say 180 , why ?"
296691,what loss function are you using for your network ?
296533,"michael please explain what meaning you ascribe to "" linear . "" as far as i can tell , this model is not linear in * any * of the parameters or its variable $ x $ in the standard mathematical or statistical meaning of the term . and why , exactly , would it be undefined at $ x = 0 $ ?"
296748,i can't access an english version of the reference you mention and my german is bad . could you expand a bit on where the standard normal distribution is accepted ?
296794,you are obviously a difficult person to please . why is the small difference you see important to your scientific question ?
296425,what are you trying to accomplish by this analysis ?
296803,friedman's anova is generally the basic method for more than two repeated measures on ordinal scale . how many confounders do you have ?
296802,"what do you mean by that the values are "" bad "" ?"
296842,what are the possible values that ` unique_bids_per_day ` can take on ?
296898,"could you explain what you mean by "" hours cancel "" ?"
160261,"if you have not taken any undergraduate analysis , might this be a problem if you want to go down the measure theory path ?"
294657,so what you mean is $ theta ( omega ) = g ( omega ) $ ?
296938,"welcome to cv . since you re new here , you may want to take our [ tour ] , which has information for new users . could you provide more information about the analysis ?"
296948,"if you are interested in * bounding * the sum $ s $ , then of course there are the trivial bounds $ kx_ { ( k ) } leq s leq kx_ { ( 1 ) } $ . and if your data are well-behaved under summation ( e . g . , normally or poisson distributed ) , then things might be easier , too . can you tell us anything about the underlying distribution of your data ?"
239496,what are you trying to do here ?
296749,` this seems to be documented nowhere ` really ?
296915,"do also read [ our policy on self-study questions ] ( url ) - can you tell us what you understand thus far , what you've tried & where you're stuck ?"
296981,the topic of the question seems to be neural networks yet the tool that you're using makes no sense outside time series analysis . function nnetar is a wrapper of nnet ( from package caret ) which adapts autoregressive neural networks to time series forecasting . are you sure this is what you want ?
296993,i think you are going to have to clarify this . when you say use the factor as a covariate what exactly do you mean ?
297084,url this your context ?
297088,what quantity are you plotting on the horizontal axis ?
297068,"comments : 1 . with 190 obs . only when you do 10-fold cross validation you end up with very unstable estimates . i would suggested bootstrapping ; if you are partial to $ k $ -fold validation , increasing the number of repeats by * a lot * . 2 . having said that , just look at the kde of your performance metrics . does it make sense to use a central tendency ?"
297110,"since you refer to "" data mining , "" do you conceive of these points as being measured with error or otherwise potentially varying a little around their "" true "" locations ?"
297113,haohanwang could you provide some motivation for considering this objective function ?
297105,have you noticed that all three variances are expressed in different units ?
297115,what do you mean that all calculations with lower n-grams don't have a sense ?
297165,"i lost you at "" we will find that such set of state values gives a loss of 1567 "" - are you comparing to some "" true "" v that you have not shared ?"
297159,"it is a good idea to report the p-value , but if you want to decide to reject $ h_0 $ or not , then you will need a threshold , so without threshold you don't have a decision ?"
297164,do you have a reference for the approach of applying arima then fitting a neural network on the residuals ?
297186,"if you truly have a population , then why is there any need to run the code more than once ?"
297163,""" consider a test which after $ n $ observations rejects $ h_0 : p = p_0 $ if $ log l_n b $ "" - where did you define $ l_n $ ?"
297190,if it does not change the parameters why would you want to remove them ?
294775,why does it seem counterintuitive ?
296766,"how many unknowns do you have , that is , dimension of $ x $ ?"
297328,converges when which quantity converges ?
297345,"do you have a mathematical definition of "" weakly identified "" , or is it qualitative ?"
297362,for a start is this really count data ?
296731,could you explain how you know your counterexample minimizer is a linear function of $ b $ ?
296784,can you provide atleast graph of your dependent variable ?
297454,you want $ p ( x_ { ( 2 ) } = a x_ { ( 1 ) } = b ) $ . assume for concreteness that your first order statistic = 3 ; what's the distribution of the second order statistic given that ?
297494,"i lost you at the phrase "" covariance between the two values of the dummy variable . "" i cannot make sense of it because by definition those values are * mutually exclusive * ; they cannot have a covariance . could you clarify what you are referring to ?"
297575,would this wording of you task sound ?
296824,"did you ran a ` cor . test ` , or a ` t . test ` ?"
297633,do you mean bootstrap t ?
297650,"when you say "" due to random chance alone "" do you mean specifically that the events across different letters are independent ?"
297441,"shouldn't ` data $ factor_a = "" a "" ` be ` data $ factor_a = = "" a "" ` ?"
297660,are these proportions count proportions ( a count divided by a total count ) ?
297702,welcome to this site . what is the intution that you have about the concept of degree of freedom ?
297690,"one natural way to address this would be to compute the correlations between all columns of matrix 1 and those of matrix 2 and attempt to create a bipartite matching . that reveals how much more information you ought to supply before you can hope for a good answer , such as ( 1 ) why might corresponding columns differ ?"
297744,how much noise do you have around the curve ?
297736,what are you trying to do ?
297818,could you highlight what it is * exactly * you need help with ?
297774,"what do you mean by "" binarize "" ?"
297862,"functions are implemented in many packages and in function libraries for many languages . these use approximate formulas that are highly accurate but they're complicated and typically come with many numerical constants that have to be accurately typed , and often with edge cases to deal with . the opportunities for mistakes are many -- frankly , unless there's some extremely compelling reason to do so , it's dumb to implement from scratch something that's already been implemented , debugged and very carefully tested and used for a long time ( even subtle errors show ) . what are you trying to do it in ?"
297863,"are $ x_1 , . . . , x_n $ independent ?"
297708,"could you give a reference or quote where you saw the term with more detail ( sutton and barto book is hundreds of pages , and the 2012 edition is not easily accessible , the most recent is june 2017 ) ?"
297909,"what is the matter with "" our estimate $ hat { v } $ is a function of the sample $ x $ and not $ v $ "" ?"
297916,` i can realize the fact that direction is not important ` - yes . so what is the problem ?
297957,"why do you say that using the same kind of metric to build and evaluate the model shoult "" of course , [ . . . ] not be the case "" ?"
297848,"can you include output of your code ( not just your code ) , as well as the output from the textbook you are trying to replicate ?"
297977,your code has some missing elements . where have you defined y [ i ] . are in the zs in the code same as the zs in the model ?
298014,possible duplicate of [ how to test whether subgroup mean differs from overall group that includes the subgroup ?
297924,is there a difference between a statistical and mathematical explanation ?
298043,"since $ p_ { x y } $ is * unknown * , there would seem to be little you can do apart from bounding $ pr ( x = 0 mid y = 0 ) $ . you certainly cannot use ml : you don't have a parameterized model . have you estimated the regression independently of your data , or did you already use your $ ( x , y ) $ data to make that estimate ?"
298017,"the "" empirical average "" is not estimated : it's a number that is calculated from the data . the calculation is either correct or not . are you sure "" empirical average "" is the term you mean to be using ?"
298161,are you suggesting that knowing how many invoices a customer has paid in the past should give you * no * information about how likely they might be to pay a new invoice ?
298190,"please add the ` [ self-study ] ` tag & read its [ wiki ] ( url ) . then tell us what you understand thus far , what you've tried & where you're stuck . we'll provide hints to help you get unstuck . will you actually analyze these data , or is this just a hypothetical scenario to probe your understanding of these issues ?"
298188,"the answers are no , no , and only when the source distributions are normal . however , i suspect you might intend your questions to include words like "" approximately "" : * e . g . * , "" when will $ mu_ { b delta , i } $ approximate a normal distribution for the purpose of . . . "" in that case positive answers are possible--but what would the intended purpose be ?"
298228,"i don't know what "" a / a "" means . you speak of both groups as "" control "" . do you mean to say that you have two control groups that receive the exact same treatment ?"
298255,"it's a good question , but i am baffled by the committee's recommendation for the simple reason that you have been explicit about your objectives : "" we are interested in how many of these people are under 65 . . . [ and ] we are also interested in the percentage per area . "" that is clear--so what is the problem with estimating these quantities ?"
298297,"you will need to tell us what a "" tolerable level "" of variance is . how would you measure it ?"
298294,would it be fair to interpret your question as asking how to find the smallest value that equals or exceeds 95 % of your data ?
298258,"you said at the top that you can't randomize within groups , but in bullet point 2 suggest that you can randomize at least something . back up and explain what can and can't be randomized ( in particular : what "" technological limitations "" are preventing randomization ?"
298344,what do you want to do with the model ?
298341,should the $ x_ { 1 : t } $ in the condition on the left hand side be $ mathbf { x } _ { 1 : t } $ ?
298365,can you please provide some relevant reference for the personalised page rank ?
298019,user8183921 : thanks ! it's clear * what * you've done but not * why * . how do you deduce the binomial distribution of the test statistic under the null hypothesis ?
298396,i do not see any strong evidence of a three-way interaction there . can you expand on why you think there might be one ?
298397,are you familiar with [ probability densities ] ( url ) ?
298409,what difference does it make between the two described splits ?
298121,"a question immediately arising : why are you speaking of columns of tables , not just of elements of sets ?"
298464,have you considered using a survival analysis model to deal with this ?
298479,what is the data ?
298309,"the very appearance of $ 1 / ( mu ( 1- mu ) ) $ , with its singularities at $ { 0 , 1 } $ , suggests a context in which strong assumptions are made about the variable . one would suppose its values are limited to the interval $ [ 0 , 1 ] $ , for instance . could you disclose all such assumptions and perhaps give us some context or motivation for looking at this particular combination of parameters ?"
298469,your edit * still * doesn't supply the requisite information . what can you tell us about the relative frequencies of events $ a $ and $ b $ ?
298534,"the [ documentation ] ( url ) for geom_density makes it clear it uses a kernel density estimate , so this boils down to "" what does a kernel density estimate do ?"
298538,"i don't understand your models , or the nuance you are referring to here . could you specify your two models in the question ?"
298562,but is it that all of the observations which have survived until t = 2 ( for example ) are included ?
298556,your questions needs clarification . do you mean the probability of all images to be in the same class or set of class ?
298588,what was your final answer to the question ?
298600,what is your question ?
298540,"your description is awfully vague : exactly what do you record when you "" write down some notes "" ?"
297990,do you want to know the true distribution of each of the 5000 variables ?
298738,"what do you mean by "" it cannot recover the true value of beta "" ?"
298732,"no , you haven't mixed it up , that's actually correct -- but it doesn't sound like what's in your post ; you should edit that . what size ( [ margin of error ] ( url ) ) do you want on your interval ?"
298632,"this doesn't make sense . what "" might be important "" about the number of treatment observations here , & why would downsampling help ?"
298813,"it can help to make the code look as much like the problem description as possible . at the head of the loop , then , subtract the cost of the bet from ` total_value ` ( you will want to create a constant ` cost_of_bet = 25 ` to do this clearly ) to model the cost of the bet . upon success , add ` win_value ` to ` total_value ` to model the gain from winning . you don't have to do anything when success does not occur ! btw , why do you use ` np . random . normal ` ?"
298828,getting better data ?
298357,are you familiar with the concepts of bias and variance ?
298871,the skew normal ( or skew gaussian ) is one kind of long tailed distribution . exponential decrease is another kind of long tailed distribution . the data are clearly long tail ; do you want to test one long-tail distribution vs . another ?
298938,"is there any specific reason you tagged "" causality "" ?"
298952,"it means exactly what it says . your training data had a given set of target values , and your testing data had additional target values that were not in the training data . is this a programming question or a statistical one ?"
298954,do you have time series data ?
298650,"unless you're in a situation where you know which summary of the posterior is most relevant , is there any reason to report only one aspect of the posterior distribution ?"
298816,can you provide a link or a better reference to the papers you cite ?
299030,"could you clarify what you mean by "" inferences of this type "" ?"
299044,"i think it really depends on the data and your purpose in categorizing it . if categorizing into two groups , does it make sense to divide data into greater than or less than the median ?"
299072,"it's not clear what you're asking , because normality and regression assumptions are covered multiple times and extensively here and elsewhere . can you explain what is your angle that is different from other discussions ?"
298332,"following [ this ] ( url ) , may you get what you observe ?"
299080,"the two models ( original and logged ) are * different * : they ( implicitly ) posit different ways in which $ y $ might depart from the predicted values . ` nls ` , for instance , could produce rather different parameter estimates for the two models , depending on the data . ( btw , ` nls ` is part of the base ` r ` distribution--it's not a package . ) could you tell us anything about the distribution of the errors ?"
69822,what kind of state-level data do you have ?
299135,maybe try a different ` ci . method ` ?
299191,"i think you might have an easier time if you code the variables as factors instead of variable indicators , i . e . treatment and prior take on value $ a $ , $ b $ , $ p $ ( placebo ) . then you'll have ` glm ( response ~ treatment prior treatment * prior , family = "" poisson "" , data = df ) ) ` also you have the same user getting multiple treatments ?"
299198,could you show us what your plots look like ?
299207,would you mind to refer that paper ?
299141,"you refer to "" the dependent variables $ x_i $ "" - is that what you intended to say or perhaps did you actually mean _independent_ there ?"
299219,could you describe your data a bit more ?
299242,what is your aim ?
299273,"your question is about estimating "" how much "" so * hypothesis tests * are immediately the wrong tool . your question is still somewhat unclear to me . are you positing some underlying "" true "" weight loss rate upon which there's some kind of observational noise ?"
299292,doesn't work for me either . perhaps dependent on features of the problem ?
298507,are you able to post the entire article as a link to a pdf instead ?
299303,"you explained well the circumstances about your animals being pooled and behave such that your measurements are not easy , but can you explain a bit more what your are measuring ?"
299304,how were the data generated ?
299354,what is your goal here ?
299111,have you checked this similar [ question ] ( url ) ?
299413,i'm not an expert on canonical ca so can't answer . but did you try to set the constraining data to a state where the constraint is no ?
299429,perhaps it would be better if you told us what the point of your experiment is . what is the scientific question you want your analysis to answer ?
298766,can you give any more details on your models ?
299458,"ttnphns the last question-- "" is there a better way "" --might be on topic here if it's asking for a statistical procedure rather than an spss command . beth , which one is it ?"
299462,"` the ordination was performed using 1000 separate ordinations ( i . e . , argument nits was set to 1000 ) ` what's that - for somebody not using same software as you do ?"
299447,"are you really assuming $ beta_0 , beta_1 $ are known ?"
299490,""" based on my reading it would appear the repeated goodness of fit test ( g test ) would be best suited over the chi-squared test "" . . . . what did you read , exactly ?"
299513,"glmms are notoriously hard to fit . added to that the negative binomial distribution is not an easy customer to fit either , especially when the overdispersions are large . serious lack of fit may also be an issue . does the fixed effects part of the model fit well ?"
299432,"it is harder to comment on your use of tobit models . the statement "" goodness-of-fit of the leisure model is about 6 times for shopping and 4 times for working purpose travels "" makes no sense to me . the reviewer seems to be asking for substantive comments on which predictors explain what , which seems fair to me , and beyond our scope here . but why did you use tobit regression at all ?"
299541,what does the variable ` cont ` represent ?
299548,have you considered using a sparse matrix format for your weights ?
299549,"wouldn't fisher's exact test be a better fit here , since your answers are categorical and sample size is small ?"
299559,what is your goal ?
299575,how do you define $ exp ( -x ^ 2 ) $ ?
299578,"i like the wilson binomial confidence interval indicator . jeffrey's also does it . tortoise vs hare also works for unfair coin . are you looking at "" if i get a series of wins that are "" n "" long , does it mean equal odds aren't in the 95 % ci ?"
299580,what is it the text says that you think is wrong ?
298147,that first set of plots shows nb dominating out of sample prediction . . . do you mean green ?
297294,"irt is already utilized by many , i'm not quite sure what you are asking ?"
299622,"do you have a parameter that has a truncated normal distribution , or data that has a truncated normal distribution with several parameters ( e . g . , the truncation point , $ mu , sigma ^ 2 $ ) ?"
137960,"hint for # 2 : the likelihood ratio $ displaystyle lambda ( x ) = frac { f_1 ( x ) } { f_0 ( x ) } $ is a _function_ of the random variable $ x $ . _conditioned_ on $ h_0 $ being the true hypothesis , $ x $ has density $ f_0 ( x ) $ . do you know how to find the _expected value_ of a _function_ $ lambda ( x ) $ of $ x $ directly _without first determining the density of_ $ lambda ( x ) $ , that is , just from knowledge of the density function $ f_0 ( x ) $ ?"
299645,"could you repost the plot , excluding the training lines ?"
299662,"since $ e ( y mid y 0 , x ) neq e ( y mid y 0 , x ) $ , isn't it to be expected that the regressions give different results ?"
299683,why use cdf in the first place ?
299687,why do you think there should be any bias ?
299697,excel will fit multiple regression using more efficient approaches than solver . i notice you have used the measurement error tag -- do your independent variables ( ie the second set ) have substantial measurement error ?
299229,the number of observation in the table adds up to 1410 . where did the extra 120 observations go ?
299738,"did you measure each subject on one hand only , or on both ?"
299756,won't a simple group by clause in sql make this series equally spaced ?
298616,are you trying to use z-score to describe homogeneity or uniqueness ?
299806,how about a gamma distribution ( url ) ?
299834,is your sequence something that would be easy for the model to predict ?
299877,"what do you mean by "" an inverse f-test "" ?"
299883,please clarify the circumstances ; it's not clear from what you wrote . * what * comes out nonsignificant ?
299856,are you referring to overdispersion in glms or something else ?
299942,"so e . g . it is randomly chosen every minute which event happens and it can also be an event , that you don't see ?"
235442,can you say anything more about your situation and your data ?
237176,what are the independent variables in your model ?
300056,"what makes you think using the raw event data causes you to "" lose some of the aggregated data "" ?"
300078,"there is missing information , as you say . but let me ask you this . what is the * exact * phrasing of the question she's having trouble with ?"
300087,are the two smaller values because of saturday and sunday ?
300090,how are you creating these roc curves ?
300124,why not read gosset's original paper ?
300147,"by "" data normalization "" do you mean "" transforming to normality "" ?"
300105,""" for example , only the first feature is duplicated . "" do you mean rather , the dimension is duplicated ?"
300174,this is quite hard to grasp . perhaps you could edit in a small subset of the data-set to clarify what checks and controls are and how they relate to trials and blocks ?
300148,"exactly what theorem are you quoting where you write "" this is enough to ensure . . . independent "" ?"
300119,how this is bad ?
300300,what happens as $ y_1 $ approaches arbitrarily close to $ y_2 $ ?
300306,what do you mean by asymptotic ?
300334,what is wrong with the standard procedures for survival analysis ( such as a cox survival model ) ?
300333,"your sampling variance for par2 may be too * high * , not too low . . . do things improve if you reduce it to 0 . 05 or 0 . 005 ?"
300350,"richardhardy , what are the examples of simple methods ?"
300391,"what does "" 1 lac "" mean ?"
300405,"what is your objective behind "" more than just eyeball the distribution "" ?"
300431,"maybe just add some noise to $ i , c $ ?"
300437,"we need more context , do you think $ x $ itself affects $ y $ or is it only * knowing * or being informed about $ x $ that affects $ y $ ?"
300409,"1 . what do you mean by "" standard distribution "" in the title ?"
300134,""" two different feature vectors but using the same model coefficients are different . "" -- yes , that's what i was discussing . in relation to your formula , whuber already told you why the answer is no -- why do you need to be told twice ?"
300487,i am not fully sure i understand your question . you have 10-12 independent variables that represent some metals ( the presence or absence ?
300526,"i am puzzled by this question , because any model building procedure ( which is what appears to be the function of your "" optimal regularization strategy "" ) always involves building multiple models--sometimes a very great number . indeed , creating multiple models is one of the keys to getting a robust result . there is no aspect of the situation you have described that would suggest using one technique instead of another , so why not apply methods you are familiar with and can employ well ?"
300528,"could you provide a sufficiently clear definition of "" categorical "" and "" continuous "" that would distinguish them * as implemented in a digital computing system * ?"
48577,[ ot ] is it a problem from statistical mechanics ?
300541,could you please clarify if your dependent variable is a count ( number of completed tasks ) or a binary feature ( completed / not completed ) ?
300547,what on earth are you trying to * achieve * with this ?
300555,what do you mean by sequential ?
300544,what do m1 to m4 stand for ?
300561,"am i correct in interpreting the x-axis as "" price ( $ ) "" from $ 0 . 00 to $ 1000 . 00 ?"
65895,"i think the standard approach would be to bootstrap the parameter and effect size estimates , so you get parameter estimation confidence intervals . for that , you can for example calculate the point estimates ( for parameters and effect sizes ) on a few thousand bootstrapped samples and take the 2 . 5th and 97 . 5th percentiles of all resulting values . also , truly random samples drawn from the same population should not result in arbitrarily smaller p values as a function of sample size ?"
300578,did you try to google for jacobian random variabele transform ?
300581,what are you trying to ask ?
300408,"there is nothing in your question that would rule out using all the data , which obviously is optimal in terms of obtaining an accurate estimate of the mean . can you provide further information that would clarify your objectives and the nature of the data ?"
300611,"this question sounds like "" i have bad data , and i know they're bad , and i know why they're bad ; how do i use these bad data ?"
300625,"can you share some of your descriptive normality-related statistics for your items , so that we can better gauge the severity of your situation ?"
300676,why do you think that ?
218299,"better is a very loaded word . more trees takes longer to compute so it is not better for compute . what is your items per leaf , and max depth ?"
300708,why only worry about genes ?
300758,"i think some time series textbooks or lecture notes should have pseudo-codes for estimation of arch and garch models , or at least explicit likelihood expressions . it could be easier to find them than to write them from scratch ( or explain here ) . have you tried looking them up yet ?"
300768,"rajeshdachiraju nowhere i disrespected you , i'm trying to give you constructive inputs . if you don't want people to give you ideas * * then why post the question at all * * ?"
300809,you didn't tell ` xts ( ) ` that the data were periodic . the ` frequency ` argument allows you to do this . you need to tell it how many observations correspond to the unit time interval . if you had monthly data this would be 1 / 12 say . do read ?
300826,"are you saying $ x , u $ are conditionally independent ?"
300145,"yes it is , but what is your question . . ?"
108374,would it be ok if i provide you solution using sas software ?
300890,i'm still not 100 % clear on the point of * acceptance intervals * here . is newman simply defining the complement of a rejection region for use in a hypothesis test or is he creating a * consonance interval * ( an interval for a parameter based on the region in which some test would not reject ) ?
300843,you might need to edit the question ; do you draw 2ml or 5ml ?
300885,what is the definition of an all-pass model ?
299353,statsplease - do you want the distribution $ f_a ( y ) $ to be continuous ?
300759,"with the differing variances , is the spread related to the mean ?"
300883,"this claim is expected : given less information , the entropy is larger . what is $ f $ in your counter-example ?"
300887,does it make sense that you get the following ?
300607,what about the coefficient for the endogenous variable in the second-stage model ?
218717,"could you explain more specifically what you mean by "" correlate . . . non-square matrices "" ?"
300980,"you should detail better your question , _e . g . _ what kind of resampling ( if any ) are you using to obtain that auc ?"
301017,are you dealing with missing x's or missing y's or both ?
301014,"what do the "" rep "" columns represent ?"
301028,"i'm not sure i understand this . what do you mean by , "" the higher values are distributed to the lower values "" , eg ?"
301034,what's the gradient of $ opt_a ( lambda ) $ ?
301040,i believe you mean whether $ x_1 $ and $ x_2 $ are correlated ?
301065,what exactly minimization or maximization is on you mind ?
301069,can you clarify more the hypothesss you want to test ?
301043,can you link to the article ?
301077,why do you think chi-squared test is too liberal ?
300864,"can you give an example or explanation of what "" number of samples "" means ?"
155213,what is your questions exactly besides that it doesn't feel right ?
301120,"both the relationships you mention are still * functional * ; what about relationships like the last three ( i . e . the ones on the far right ) in the bottom row [ here ] ( url ) , where there can be two or more typical values of $ y $ for a given $ x $ ?"
301144,"unfortunately , your simulation experiment - despite it is commented a bit - isn't comprehensible enough to someone not using r . what were you doing ?"
301267,did you read chris olah's post ?
301291,what classifier do you use ?
301302,how is this related to regression ?
301208,how would you get ssrc if the models have different predictors ?
301319,"there is a large although often repetitive and dismaying literature on diversity in ecology , as you should know , and if one authority claims that one single measure is best , others will disagree or argue that the claim is at least contentious , if not meaningless . but positively i'd commend exp ( $ h $ ) not because of this implausible claim ( what is "" true diversity "" any way ?"
301355,what would you imagine the null hypothesis could be ?
301374,"if my understanding is correct , empty cc header simply means that email has not cc'ed anyone . so it should definitely not be considered as missing . could you provide more details on the format of the cc header field and how you would like to use it in your data mining model ?"
301397,look carefully at the values you've assigned to ` newdata ` . ( try printing out ` newdata ` . ) does it look right ?
301408,are the features scaled ?
301428,"i see no clear evidence for that , it looks pretty flat to me ; if there's clear changes it's probably going on in the lower portion of sample size . do you have the data , or only the image of the plot ?"
301445,what is your understanding of the c parameter ?
301329,"i think it is an indication that you are fitting the wrong model , indeed the saturated one . could you provide us with output of the software ?"
301424,"what meaning do you put in "" covariates "" here ?"
300722,what is the fault precisely ?
301480,are the reported confidence intervals for the slope estimate ?
301483,what about the answers i gave to several of your earlier questions ?
301497,is there any specific reason why you cannot do an f test on the variables of interest ?
301357,i still didnt get the second part . you are splitting your data into 2 sets to do a k-fold cv on each ?
301507,"i answered a similar question at url i would hesitate to offer that answer here without knowing what statistics you will compute and how you plan to interpret them , because their meaning can change dramatically when the bins are computed from the data themselves . perhaps you could tell us more about what you would like to accomplish ?"
301532,"i would refer you to any definition of "" convex "" that you are familiar with . don't they all involve a concept of points in the domain of a function lying "" between "" other points ?"
301533,"what is "" $ w $ "" originally and what operations do you wish to perform on it to "" normalize "" it ?"
301545,what is it you want to learn from these data ?
301557,"this does not sound like a machine learning problem to me , but maybe i didn't quite get it . could you explain how a point / cell in the grid is mapped to 0 , 1 or 2 ?"
301562,"it depends on ( a ) how those people were selected and ( b ) your quality criteria for the database . for instance , if you need the dates to be correct you might draw one conclusion but if you only need them to be approximately right you might draw the opposite conclusion . what can you tell us about ( a ) and ( b ) ?"
301558,"offset the overall mean ( the log odds of the mean if you're in logistic regression land ) , and then estimate a model without an intercept ?"
301625,1 . what are the relative costs to being a little under vs a little over ?
301549,"i don't understand the question . covariance already has a definition . see url do you mean what if $ s $ were not a covariance matrix , but a scatter matrix ( url ) ?"
301666,"for me it is quite difficult to asses whether log-transformation of the independent / predictor variables is necessary without some information about your data ( sample size , maybe a few rows of data and some descriptives ?"
217696,you have just 8 possible combinations of features - does a simple table of frequencies of those combinations not give you the desired information ?
241233,"i cannot reproduce your calculations of "" probability . "" ( 1 ) did you remember to include the constant in your calculations ?"
301741,"is this the same receptor being used in each of the assays , or do the assays involve different receptors or different forms of the receptor ?"
301766,first things first : do you know the * true * value of the signal ?
82020,"i have a similar problem , did you find a way to do it ?"
301858,how is the data you have cross sectional ?
301862,there are several unclear or confusing points in your question . one ia about toeplitz . why not just diagonal cov . matrix ?
301865,how are you obtaining all the moments ?
215765,can you clarify what you mean by the intersection of af and sofa ?
301879,"* overall_satisfaction * is probably discrete , how many values do it take ?"
203111,"what exactly is involved in your "" multiple regression , "" given you have assumed these variables are * independent * ?"
249603,"when you say "" fraction of beta "" do you mean updating only parts of beta or do you mean updating all of beta but only sometimes ?"
302016,the first warning seems fairly clear . what happens when you deal with the problem it identified ?
302064,what assumptions are you making about $ tau $ ?
211094,"what might "" keep it maximal "" actually mean ?"
302082,"i do not understand what you are asking because the covariance matrices are not random variables . what , then , could possibly be the meaning of taking expectations of norms of their differences ?"
228312,how would such an observational study eliminate the alternative explanation that the deer are not using some other cue than antler size ( which might nevertheless be correlated with it ) ?
301878,"could you provide the exact text of the puzzle , and cite its source ?"
302145,would your model be used ( by a decision-maker ) * conditional on * these categorical choices ?
302072,"good questions ( 1 ) - but bundling several questions together isn't usually a good idea . the first three are quite closely related ; but the last , at least should be split out into a separate cv question , & probably amplified a little . ( the third could also do with some clarification - what's "" eta "" ?"
203193,"you can run separate regressions , of course . my preference would be to stack them ( the strategies ) up as separate cross-sections and run one model . also , are you using dcf , cico ( cash in-cash out ) or irr ?"
302182,what do you have in mind when you are talking about $ bar y $ . . . ?
302262,what do you mean that $ k = x $ and then $ k = x x ^ t $ ?
302278,[ what are you trying to ultimately accomplish ?
202973,"what about looking at prediction interval coverage or bias of predictions ( or mse as you already did ) . if you were doing independent simulations , then you could assume the bias for each simulation as approximately independent normals ( and coverage as indpedenet bernoulli trials ) . if we are talking about real data series over time , then the predictions are presumably not entirely independent , but perhaps they are still approximately ?"
299184,are you sure you have $ x $ and $ y $ the right way round ?
302336,"can you clarify the data that you have , & the structure of your study ?"
250636,"arguably , not so . poisson regression is not at all the same as , or reducible to , fitting a poisson distribution to your response any more than linear regression is the same as fitting a normal distribution to your response . i'd say the main idea is just $ y = exp ( x beta ) $ without even an assumption that the response is counted . that doesn't rule out other models being better ( how could it ?"
302435,have you tried replicating your net and training with e . g . mxnet ?
302441,could you try making your question more focused ?
302490,are t ( l ) and t ( r ) definitive limits of age or just upper and lower ends of a prediction error ?
302464,"i'm not quite sure what you did . did you do one wilcoxon test for assignments 10 vs 9 , then another for 9 vs 8 etc , or did you somehow combine all the comparisons into one test ?"
302505,"did you read "" bayesian reasoning and machine learning "" ?"
302506,why would a statement in a textbook be authoritative ?
302529,what about programing bootstrapping and permutation test ?
302542,what do the numbers 10 and 6 refer to ?
302551,"an anova looks at the relationship between a categorical predictor ( or multiple of those perhaps with interaction terms ) and a continuous outcome . there is a normality assumption , but i don't see a linearity assumption . are you talking about some very specific variant of anova ?"
302550,"is this counted percentages , that is , do you know numerator and denominator separately ?"
302558,can you give a link to where andrew ng is stating his recommendation ?
302502,i wouldn't expect a random walk on a simplex to be uniform ; what's the basis on which you say that there's too many near the boundary ?
302562,"since $ nh ^ { * } / h = ( n / h ) h ^ { * } $ is just a constant times $ h ^ { * } $ , it would seem there is no difficulty at all in relating the bias and variance of $ n ^ { * } $ to those of $ h ^ { * } $ . are you sure you have described your notation as intended ?"
302609,"your example seems unrelated to your description , which indicates the data could be represented as a table with one column for each design , one row for each subject and question , and values of just "" 1 "" , "" 2 "" , or "" 3 "" in each row . what do the numbers you have shown mean ?"
302078,"i think that the discussion of the statistical concepts here is absolutely on-topic for this site , but i think the process of successive editing effectively in reply to answers may tend towards questions becoming too broad to fit neatly into our q & a format . it may have been a better idea to ask follow-up questions ( e . g . what's the rationale for choosing number of factors for one construct ?"
302615,"is there a specific reason you're asking sampling from a large finite population that is itself drawn from $ ( x , y ) $ , instead of sampling from $ ( x , y ) $ directly ?"
302610,"if you set aside the code related issues , is your question answered by [ how to plot roc curves in multiclass classification ?"
302632,can you please elaborate what the labels ` 0 ` to ` 4 ` mean ?
302653,the * survey * doesn't have a [ standard error ] ( url ) . what statistic from the survey are you trying to compute the standard error of ?
302713,"i would call a time series a "" crow "" and therefore a related group of them that hang out together ought to be called a [ murder of crows ] ( url ) . all facetiousness aside , could you tell us what your * statistical * question might be ?"
302118,do you really mean you have 6 manifest variables from which you are trying to derive 5 latent variables ?
302763,i do not understand what you mean by feature engineering . could you elaborate ?
302451,i am not in a position to understand what exactly you want me to respond ?
302706,"floudc , why do you say "" but it doesn't work with 2 factors using factoran "" ?"
302768,"as i understand , $ y $ is "" observed sex "" ( noisy measure ) and $ g $ is actual sex . so what is $ x $ ?"
302633,"stata is also using a small sample adjustment to the variance of n / ( n-k ) , which r typically does not use . that is probably not enough to explain the difference . if you run the code with the same bandwidth and do this correction , how close are the standard errors then ?"
302817,why do you call gender a treatment rather then a factor ?
302828,"the thing you are interested in ( changes in power ) is rooted in the lack of stationarity , so unless you want to pretend that it's stationary as some sort of null hypothesis , then no . you might be able to treat the differenced timeseries ( where $ t'_i = t_i - t_ { i-1 } $ ) as stationary , although i'm not sure if that's what you want . . . what exactly are you trying to do here ?"
302830,what leads you to believe that the features you see in the plots etc . are not real features of the data and are in fact due to ` gam ` fit problems ?
302831,could that be a duplicate ?
302850,"this seems like a reasonable question , but be aware that the request for code may not be provided--that isn't what we do here . can you clarify what you mean by , "" forecasts y at time t = 5 "" ?"
302851,""" continuous "" and "" categorical "" are * modeling decisions * and , sometimes , are characterizations of levels of measurement . as such these are not properties that can be deduced from any amount of data . that makes it difficult to understand what you are trying to accomplish : what is your objective in conducting this analysis of patterns of duplication ?"
302875,first thought -- is it possible that you are getting fewer lambdas evaluated because some didn't converge ?
302896,"since ecdf is defined in terms of individual datapoints , each having same 1 / n weight , you cannot get "" the same "" ecdf . what exactly are your requirements ?"
302899,do you have only two variables ?
302917,1 ) could you explain a bit more what you do with your mc ( and why ) . the way i understand it now is that you wish to estimate the parameters of a distribution to match some observed quantities . you do this by some gradient descent process and optimize the parameters to minimize a $ chi ^ 2 $ measure . but why ( and how ) do you calculate this $ chi ^ 2 $ by the use of a mc ( don't the estimated values result directly from your distribution ) ?
302909,can you add some more detail about your problem ?
302933,"i did not quite understand the question . what is "" row "" here ?"
302965,"have you tried if with different random_state parameters , and if so did you observe the same result ?"
302967,is your issue that you are surprised that the number can be as small / large as 12 ?
302987,"the decision thresholds involved in roc analysis need not be probabilities . which do you want , a roc curve or probabilities ?"
302926,what exactly are you trying to estimate ?
303032,"[ wikipedia ] ( url ) is very clear that it considers $ x $ to be a "" k-dimensional column vector . "" you seem to be using "" x "" both for the model matrix "" $ x $ "" and for such individual observations $ x $ . case matters ! doesn't that settle the issue ?"
303039,"you definitely * * should * * include both eyes , and hierarchical regression modeling would be a natural technique to accomplish this . is it at all possible * not * to categorize the clinical assessment of retinal health ?"
303040,"cool question . how exactly do you calculate "" combined uptime availability "" ?"
303051,"clarification : do you want to to use mds coordinates as "" response variables "" or as predictors ?"
303057,did you try to search ` cronbach alpha factor analysis ` on the site ?
303063,why are you taking square root of average score ?
303068,can you provide any context for this ?
303104,have you considered bootstrapping or cross-validation ?
303007,"could you add some tables showing the amount of data broken down by period , income band , and family composition ?"
303127,"not a direct answer to your question , but if you're going the bayesian route anyway , wouldn't credible intervals be a better fit than confidence intervals ?"
303172,is $ p ( x = 0 ) 0 $ ?
303221,your image is training set error ?
303231,are the two responses related or independent ?
303239,what do you hope to learn from this experiment ?
303258,how are you calculating manually ?
303290,what do you want to test ?
303292,"what are var1 , 2 and 3 ?"
303311,a related question / answer this site with an excellent explanation of cca is [ how to visualize what canonical correlation analysis does ( in comparison to what principal component analysis does ) ?
303322,would you not be better of on a more technology oriented site in case they do not use statistical methods at all ?
303232,"question is unclear -- what's this "" variance of the residuals "" you mention ?"
303328,can you write the table and explain the interpretation of the margins ?
303346,user177357 it depends on what you want to do with this bit of information called correlation . are you going to fit a model ?
303413,"by impact you probably mean "" important in cluster partition "" , that is , associated with clusters ?"
237006,"this seems to be an unreproducible example and a not very clear question . residuals are extracted for an "" object for which the extraction of model residuals is meaningful "" , what choices do you have , related to the question you ask ?"
205467,"the mean size of standardized residuals is $ 1 $ , by construction . with that for the context , by what conceivable measure do you believe that a discrepancy of less than two parts in 10 , 000 , 000 , 000 , 000 , 000 is "" rather different "" ?"
303482,"what do you mean "" unstable "" in relation to fully bayesian posterior sampling via ` jagam ( ) ` ?"
190386,what is the purpose of your modelling ?
303578,"correlation coefficients measure correlation , regardless of the distributions . in your title do you mean "" non-normal "" rather than "" non-bivariate "" ?"
302236,"are you sure you mean "" sample size "" ?"
303599,can you define your notation ?
303615,do you mean that $ mu = 10 $ as an effect sufficiently far from your null $ mu = 5 $ so that you base you power analysis on this effect size ?
303660,"can't you model the counts and include "" before "" and "" after "" as a predictor ?"
303729,"perhaps the quickest and simplest way to assess multivariate linear relationships among all the variables is to regress any variable ( pick a constant or choose random numbers ) against them : the software automatically performs this evaluation and can emit diagnostics to help you understand it . if you literally want to assess * correlation , * in the sense of any bivariate correlation coefficient , then why not just compute and review the correlation matrix ?"
264071,do you understand _statistically_ what a weighted linear regression is ?
303467,"so you have $ n_g n_r , p sim text { binomial } ( n_r , p ) $ , and you put priors on $ n_r $ and $ p $ . you mention that $ p sim text { uniform } ( 0 , p_ { text { max } } ) $ , but i'm not getting as clear of a sense what priors you want for $ n_r $ . also , how often are you shouting ?"
303766,"in what sense , exactly , would removing * any * of the larger image sizes make these data more "" reasonable "" ?"
303776,possible duplicate of [ how to fit a mixed model with response variable between 0 and 1 ?
303785,the counter example appears valid . can you be more specific about what isnt clear to you ?
303799,"as you are still with a large $ n $ , you still have the clt and can compute confidence intervals for $ mu $ the usual way for any distribution . any particular reason that is not sufficient ?"
303814,i wonder if this ( and the comments ) does not answer your question ?
303835,""" quantify it's increasing nature "" is incredibly vague . what do you mean by that ?"
303841,are you interested in trends specifically in the context of unit root testing ?
303851,"what do you mean by "" getting the probability smooth curve from the data "" ?"
303791,"hint : draw a picture . divide the $ ( x , y ) $ plane into eight equiprobable sectors along the lines $ x = 0 $ , $ y = 0 $ , $ x y = 0 $ , and $ x-y = 0 $ . how many of those correspond to $ x y gt 0 $ ?"
303896,have you had any luck with this ?
303902,do you have any labeled data ?
303893,"it's all good . still a little confused though--should the first equation involve $ bar { x } $ or $ x_i $ for $ i = 1 , 2 , 3 , 4 , 5 $ ?"
303911,so there is not only $ text { salary } $ and $ text { salary_group } $ but also the interaction ?
303923,"rewrite the whole thing , please justlife . what is $ c $ , what is $ n $ ?"
303193,"providing access to spreadsheets is fine , and your attention to that detail is appreciated--but your question needs to be understandable without requiring readers to open them . could you therefore describe what you mean by "" compute a z score in this way "" ?"
303753,"this is more than "" something outside "" of the events . * you have changed the probabilities of $ a $ , $ b $ , and $ a cap b $ . * this could be done even without introducing $ x_5 $ . why wouldn't that have a potential effect on independence ?"
303787,"personally , i would inspect the heteroskedasticity and my assumptions regarding the model error term a bit more . what is the reason for it ?"
303997,are you asking whether this could ameliorate the bias discussed in the linked paper ?
303846,user321627 where did you encounter $ v_j $ ?
304042,"what do you mean by "" usually "" ?"
304060,why do you think the likelihood ratio test is telling you the quartic is better and not that the quadratic is better ?
304065,what do you mean by monthly trends ?
226869,so each person appears in both rows of your table and was classified as 0 or 1 on songmatching ?
304082,"maybe sas here uses some strange , deviant definition of residual ?"
303991,can you please write a tag wiki for the new ` rstan ` tag you introduced ?
304132,does it work if you do glmer ( scale ( lat ) ~ cond 1 trial . . . . ) ?
304113,"while this is an interesting result , it doesn't bother me as ml theory states their results only asysmptotically and one has to expect that in some occasions finite sample performance might be pretty bad . however , can you give a more specific example of such a family of distribution $ p_ theta $ ?"
304211,"if the estimator of $ beta $ was consistent , what would it imply about $ u $ ?"
303004,"are you using experience replay ( learning from random sample of earlier transitions ) , or working purely online ?"
304270,have you read the documentation ?
304277,"if you expect that each your construct is based on latent factor , why not do cfa instead of efa ?"
304166,"can you explain what you mean by "" my svm . . . contains 3 classes "" ?"
304313,"gung , is it really a duplicate ?"
304352,"it's not exactly clear what "" random "" means here . for example if you have a training set of images , how are you defining a random image ?"
303572,what do w and r represent ?
304426,can you explain why the pre-test scores are not comparable among the groups ?
303888,""" i don't want to find the ( nearly ) optimal solution by solving the tsp , but the solution the human would have chosen like he did before . therefore i have to learn from previous data instead of optimizing it . "" i have a background in operations research and machine learning so i can probably somewhat help with both approaches . but why are you so convinced that classification and not constrained mixed integer optimization ( or heuristic approximations of it ) is the way to go ?"
304459,what is $ j $ in your equation ?
304466,"when you say "" ranges for each parameter "" : is that the confidence interval or the min-max for each * variable * ?"
304483,you said your network is predicting a scalar 1x1 but you also mentioned that the output size is 1x400 . which is it ?
304514,"exactly in what sense do you find this a "" little bit strange "" and what kind of advice are you seeking ?"
304530,why can't u assume it ?
304561,"i don't know what you mean by "" different "" . if you have two functions , $ f ( x ) $ and $ g ( x ) $ which are different ( i . e . $ f ( x ) ne g ( x ) $ ) then is the process of calculating $ frac { d } { dx } f ( x ) $ * different * than calculating $ frac { d } { dx } g ( x ) ?"
304621,"from the way the question is phrased , i'm guessing this is self study . so , instead of an answer , hints : 1 ) how often , in an infinite sequence of $ x_n $ , will $ x_n-0 epsilon $ for some arbitrary $ epsilon in ( 0 , 1 ) $ ?"
304685,"sorry , but i don't understand the question . you've done it , so "" can you do it ?"
304374,"i think this is almost literally the definition of compound symmetry . is there some specific definition of compound symmetry that an answer should use , and then prove that that definition implies the equivalence of the models m1 and m2 ?"
304706,"do you have interest in meta-analysis of effect-sizes or "" sample means "" ?"
304716,"in your last line , what happens if $ s = t $ ?"
304735,"you would make some progress by fixing the ( many ) typographical errors in this account . in particular , why are you referencing just a single variable $ u $ rather than a collection of such variables ?"
304744,"can you give some context , why do you need an approximate normal distribution ?"
304749,what do the columns of the table mean ?
304747,"what exactly do you mean by "" dichotomy "" ?"
304768,typo ?
304758,thousands have played aournd the cifar10 dataset and nns . you may have messed up in your code . can you show it ?
304834,"what do you mean by a "" reliable correlation "" ?"
304871,"are you trying to suggest that specifying an error distribution ( where "" error "" is the difference between the observed response and the true value ) and specifying a response distribution are somehow different things ?"
304713,what techniques / methods / models are you using ?
304250,possible duplicate of [ intuitive explanation for inverse probability of treatment weights ( iptws ) in propensity score weighting ?
304765,"this question lacks important information : what is this "" single number "" intended to tell you ?"
228983,"when $ delta = b ^ 2-4ac geq 0 $ ( with probability about 0 . 6272 ) the imaginary part is 0 , otherwise it is non-zero , and when it is nonzero the average magnitude of the imaginary part will be correspondingly about 2 . 68 times as large as you'd get by averaging across both sets of cases . are you sure you intend to average over both cases ?"
304529,i don't get this : you start out by asking us to ignore the problems--which include issues with predictive power--and then you ask whether there are such problems ! why not [ search our site for the answers ?
302835,"it's not clear to me why you doubt the validity . note that it's not * frequency * below 5 that's the issue , but expected frequency . what proportion of categories have expected frequency below 5 ?"
304979,"could you please clarify what you mean by "" derive "" and "" define "" ?"
304982,why not just restore the seed after calling ` cv . glm ` to what it was before ?
305003,"welcome to cross validated ! any second maximum in the probability density function of the population implies a bimodal distribution , by definition . whether the second mode is in some sense unimportant is a subject-matter rather than a statistical question . is that all you're asking ?"
305025,i got a couple of questions : is the revenue value continous or binary ( yes / no ) ?
305070,"1 you might consider re-interpreting your task as one of identifying and applying an appropriate measure of agreement between predicted and measured soil moisture to various twi procedures as applied to data from the site . aic , even if it could be interpreted in this context , would not necessarily be hydrologically relevant . after all , what does anybody care about the number of parameters used ( at least within reasonable limits ) when the objective is to make reliable predictions ?"
304796,please elaborate what do we understand understand by double log model ?
206135,"the distribution of $ max ( x , y ) $ ( for $ x $ and $ y $ with equal variances and equal means ) is given at url from that you can compute the expectation ( it looks like numerical methods have to be used ) . the general problem ( for arbitrary variances and means ) looks difficult : do you need a solution in that case ?"
243599,"neither . would it be a little clearer to write the ( conditional constant ) vector $ x / x ^ 2 $ as , say , $ u $ ?"
207793,"i'm unsure , because i still don't have a good grasp of where you're going with this question . is there perhaps a specific problem or setting that has motivated it ?"
305108,what is uncorrelated variable ?
305127,can you please add a tag wiki for the new tag ` satterthwaite ` that you introduced ?
305148,however the $ sigma $ may be in meters . do we have something like $ log $ square meters ?
305181,so you have something like $ y_ { ij } = beta_0 beta_ { 1i } x_i beta_ { 2j } z_j $ where $ i $ indexes the country and $ j $ the company ?
305224,what is $ delta $ ?
305221,could you give us an example of your data ?
305229,some additional context for the formula would be helpful . . . what does it describe ?
305243,do you have an example of this use of $ x $ ?
212990,"if you are interested in better ways to model your data , you should direct questions about statistical model fitting over to [ stats . se ] . this doesn't seem like a very specific programming question . how exactly do you know that the coefficients from other models are incorrect ?"
305284,can you specifically identify the variables that were actually used to fit the model and show your code ?
305292,what possible mechanism could cause an ace to have any more or less probability of being selected for the second card than any other denomination ?
305180,?
305333,why do you want to do that ?
305349,what is your question ?
305391,could you elaborate a little bit more ?
305412,"it sounds like you might be confusing the term "" variable "" with "" group "" , "" level "" , or "" value "" . you have one independent variable , namely school type , which has four levels , namely public-urban , private-urban , public-rural , and private-rural . your concern is that you have different numbers of subjects of each school type . is that correct ?"
305459,""" doesn't apply "" means "" doesn't add or subtract anything from the prediction . "" sounds like a zero , doesn't it ?"
305361,"one might be inclined to interpret "" do not differ "" as asking whether * after some kind of calibration is performed * the two methods yield the same information about the subjects being sampled . for instance , it's possible you could find a function $ g $ such that with $ ( x , y ) $ being the two scores , $ g ( x ) = y $ in every case . arguably then the methods would merely be different ways of expressing * identical * results . one would expect the match not to be that perfect , so there remain questions of ( a ) how to estimate $ g $ and ( b ) how to assess any * remaining * discrepancies $ y-g ( x ) $ . is this what you need ?"
230951,"did your source ( where you read these two problems ) give any definition of "" generalized variance "" ?"
244076,could it be because they are factors ?
305571,"how many observations , roughly , do you have ?"
305577,what motivated your choice of models ?
305614,"people use the term "" grid "" in many quite different ways . because of that , it's impossible to determine with certainty what graph you are trying to describe . ( i suspect i know , but i can think of many variations depending on how the data are ordered and what coordinate system is used . for instance , will you plot the prices from smallest to largest , or just in some arbitrary order ?"
305606,is there enough information given here to make this a reasonable question ?
231771,are you sure ` difficulty ` should be the response here ?
305590,tomka have you used a non-informative prior for your bayesian model ?
222085,hi maha and welcome to the site . could you maybe include a picture of the spss-output in your question ?
305641,"for why "" how do i interpret this ?"
242419,"can you say more about your situation , your data , your models , & your goals here ?"
305718,why are you computing the probability of 12 arrivals in an hour ?
305704,at all costs ?
305713,"please note that your last example violates the condition $ x gt 0 $ . as such , your question has become unintelligible , because it asks how to construct "" such an example "" that does not conform to your assumptions . what are trying to ask ?"
305722,"thank you . the improved chart is intriguing by providing context . but as far as your question goes , it sounds like a matter of business practice , not statistics . many executives might be horrified at the prospect of disappointing 66 customers , on the principle that for each disappointed one there will be ten times as many who feel negatively about the company , and 660 customers is such a sizable proportion of all customers that in a low-margin business they could represent the difference between profitability and ruin . who are we to contend that's a "" small "" difference ?"
305726,how do you compute potential correlation under point 1 ?
305131,could you combine the two data files and fit a single model ?
305766,"what do you mean by "" help to derive "" ?"
305440,"is it correct to assume that your "" id "" is the dependent variable and that $ ( v_1 , . . . , v_10 ) $ are the independent variables ?"
305490,"if you have only one observation , then where did the estimate of the population variance come from ?"
305863,did you figure this out ?
261704,are the images on top examples of your actual samples ?
305931,could you explain what ( 2 ) might actually mean ?
305879,"this is utter mathematical nonsense : it begins with an expression that you acknowledge makes no sense , so what else is to be said ?"
305962,"do you mean "" intra-week seasonality pattern "" or "" inter-week seasonality pattern "" ?"
305993,couldn't you just set $ x_i = 0 $ and sample the remaining variables from an $ n - 1 $ dimensional dirichlet distribution ?
306001,you have 631 observations but how many subjects do you have ?
306029,all that depend on your suppositions . do you admit that factor structure in your case should change over time ?
306030,your notation confuses me a bit . what is $ x ^ { [ i ] } $ ?
306051,"it's hard to consider y not autocorrelated . sales data is very persistent and almost always autocorrelated . you may wont to look at differences both in y and x , and lag dy on dx . do you have marketing expense budget variable ?"
306042,what is svar ?
306093,"since it's mathematically impossible for the distribution to be exactly normal , the solution actually is a little tricky : perhaps it has to be a * truncated * normal , cut off at the endpoints $ 0 $ and $ 100 $ ?"
306097,"you went astray the moment you categorized your trait variable in an effort to cope with its * censoring * at both ends : you both complicated the analysis and lost information , which will make the results worse than you might otherwise achieve . there are better ways . would you like to change your question to ask how to accomplish your original aim , or do you still want to pursue the path you have taken ?"
240102,"just to be sure i understood , you want to build a classifier ( response is binary ) where the predictors are the 13 drug-use values , the subject id and time ?"
306131,"why are you doing "" x . astype ( float ) = = x . astype ( int ) "" ?"
306160,when to prefer a univariate forecast to a bivariate one ?
306172,"sorry i apparently come from a different subfield -- what are "" loadings ?"
306162,let's leave that aside for the moment ; i'll come at it from another direction . can you say something about the 20 different samples - do you expect there could be variation in the proportion of infected controls across samples ?
305876,"just to see if i get your question * ( especially regarding the non-stationary variable i am not sure what kind of model you have in mind and why shifting the mean would be problematic , a contrast , why ols would work , as comparison would be helpful . why is this non-stationary specifically a problem for regularization ) * : 1 ) how about not penalizing the intercept to solve your first concern ?"
304853,it looks like your pre and post measurements are perfectly correlated . is that true ?
306278,i don't actually see a question here . what are you asking ?
306286,"i suspect you will only get educated guesses concerning what "" drawing probability "" could possibly mean . ( your [ tag : gaussian-mixture ] tag is a hint , but it strongly suggests you haven't supplied enough information . ) have you consulted the person who set you this problem to ask for clarification ?"
306309,"when you refer to "" models "" $ f_i $ , are these conditional distributions or are they only notional means ( or similar measures of location ) ?"
306310,what tells you these events are independent ?
306262,"what are "" nonlinear data "" ?"
306254,"lucasfariaslf , * they're actually gonna reflect the relation between the deterministic / stochastic trend than the actual the data * ?"
306324,"i don't understand what you mean by "" simple "" and "" complicated "" . after all , if you merely define $ x_0 = sin ( x_2 ^ 2 ) $ , then $ f ( x_0 , x_1 ) = x_0 x_1 $ treats both variables equally . could you define these concepts--preferably quantitatively--or at least provide a more detailed description ?"
306407,"i concur with your approach . have you carefully checked , the question is exactlyi the one you gave us ?"
306460,"i think it would be helpful to describe in what way your design is unbalanced . by cell , do you mean a unique combination of rows and columns ?"
306491,"there are two issues here . first , $ f $ is not a distribution function . do you perhaps mean to use it as a * density * function ?"
306477,have you left any useful details out ?
306510,"i don't know keras , so asking this - is back-propagation enabled ?"
306518,would you like to have a good chance to reject the null hypothesis when it's false ?
306531,expected winnings look correct ( except you've got the signs mixed up when you've multiplied out ) . the values of $ a $ you're looking for will depend on $ p $ . does that help ?
306541,do you have experience applying pca to data sets ?
305763,what is ` distance [ i ] ` ?
304659,"it seems like you're set on using a discrete-valued response distribution rather than a continuous approximation . assuming that's the approach you want to use , then the two options you've listed ( binomial and poisson / related ) might be fairly limiting . the binomial only has one parameter ( n is set to 24 ) and the poisson assumes infinite support . have you considered a beta-binomial response to increase the number of parameters while fixing the support on { 0 , . . . , 24 } ?"
306554,is the author perhaps implying a multiple testing correction has been applied ( e . g . bonferroni ) ?
306267,what's wrong with his definition ?
306613,"two comments . with binary predictors , you might just use a regression model . second , it sounds like you have experimental data and are interested in the effect of binary treatment . the right model will depend on the details of the experiment . do you have multiple observations on an outcome for people who are always treated or untreated , or do you have observations on people before and after treatment . do these people interact with each other ?"
306632,it's not fully clear to me what your goals are . what will you do with your summary statistics ?
306638,maybe you should tag this as self-study ?
306584,"what exactly do you mean with "" level "" ?"
306655,"i don't understand ( a ) why you are doing all these calculations and ( b ) how it's possible you could propose them , perform them , and then claim you don't understand what they mean ! as to ( a ) , since your question asks "" to what extent participants chose , e . g . , 5 as compared to the other options , "" what is the matter with reporting the relative frequencies of each of the five options ?"
306663,"what does "" fwl "" mean ?"
306640,can you show some of the scatter plots ?
306526,lda has several meanings . what does it mean here ?
306739,what makes you say that you need to detect outliers and what do you propose to do with them ?
306728,"this information is not enough . do you have a vector of drug therapy outcome , for example , so that you can tell which dosage led to which outcome ?"
306755,i do not understand why you have multiple z-scores per subgroup . the z-score of a subgroup should consist of the mean of its observations ( possibly subtracted by the population mean under $ h_0 $ ) divided by the standard deviation in that subgroup . can you elaborate on your z-score calculation ?
306567,is the incoming data affected by the previous incoming data and your previous suggestion ?
306737,"i am afraid you have some notational difficulties . for example , what does your equation 2 mean ?"
306817,1 . is this work for some subject ?
306821,perhaps not all emotions occurred with the same frequency and this is a weighted average ?
306829,can you provide an example of these debates ?
306831,what is the role of 'times' ?
306871,do you have a statistical contwxt for the q ?
306877,what are you comparing to justify a t test ?
306758,"you haven't described anything in your circumstance that might be related to time , so that makes it impossible to understand what "" long term relation "" might possibly mean . do you perhaps intend "" $ t $ "" to represent time ?"
306919,"steps 4 , 5 , 6 : you can use cv in order to select optimal iteration number without guessing . look for minimized mean error on cv validation folds and on variance of the cv fold error values . the lower both measures the better the hyper parameter value associated with them . you can also grid search through other parameters in your function , like * * max . depth * * or * * eta * * . use caret package for this purpose . the overall stream looks logical . as for the resulting auc , if it is good or not is up to you to decide . how well does your model solve the task ?"
306993,i guess it might be easier to obtain data if you timebox the returning probqbility ?
306934,"my guess is that it's because your question is quite unclear . you seem to have "" cases "" changing colours for example . it's hard to follow what you mean . how is case 1 sometimes black and sometimes white ?"
307060,do you have a reference for this being called bernoulli ?
307070,"it does not seem possible to answer your questions with such data : the apples offered you are not random samples ; there may be differences among the farms ; and you have no controls to compare what you receive to what is typical of those farms . suppose some test were to declare there is a "" significant "" difference in the data : what then ?"
307085,"if you mean to use more data by avoiding a large split in train / validate set , why not try cross-validation ?"
302004,can you write a little bit about how you actually found the covariance matrix ?
307123,how can you know anything about x $ _t $ ?
307127,then i suggest using search over crossvalidated supplying available traincontrol methods . different cv types may result in different model quality . did you just try several other options in traincontrol ?
307167,what is the basis of this guess ?
307171,"can you be more specific about what you mean by "" the "" discrete version of the student t distribution ?"
211516,a couple of questions for verification . what is the maximum lag length that you've entertained for testing lag length by information criteria ?
307012,can you elaborate a bit more on what you mean by multiple kearnel learning ?
307188,1 . is this an exercise for a class ?
307210,"to clarify , your training data is from around -1 . 5 to 1 . 5 , so the network has learned that accurately ?"
307259,what have you tried . what are you unsure of ?
307250,"what are $ m $ , $ k $ , $ u_j $ and $ x ^ { ( i ) } $ ?"
307262,"while classification can be a special case of regression most of the time , i would not call it a regression problem . i think its a classification problem . why not google multivariate classification ?"
307369,"you certainly had a reason to use the offset , what was that ?"
307079,"what exactly is "" relative abundance "" ?"
307361,"do you meant a model of $ y_ { t } -y_ { t-12 } $ ( i . e . , change from the same month last year ) ?"
307422,have you had a look at [ this ] ( url ) koenker article ?
307497,it is not becoming clearer to me now that you have presented the data : is rv response variable ?
247850,this is too unclear a question to be understandable by most readers of the forum . could you try to make it more precise or more focussed ?
307586,what are these mutually exclusive variables ?
307598,"you probably meant to say "" logistic regression "" not logical regression ?"
307611,"welcome to cv . since you re new here , you may want to take our [ tour ] , which has information for new users . out of curiosity , do you know why the teacher gave such an advice ?"
307648,do you know the expression for the probability that n students accept if m are offered ( based on independent decisions with an 80 % acceptance rate ) ?
307739,"i am not so sure whether i get your question right . but if you are mainly interested in finding a function that maps from x and z to y you should probably think about a nonparametric approach . a possible solution would be a tensor-product smooth that fits a model like y = f ( x , z ) u ( see url ) . is this helpful for you ?"
307753,can you provide us more information such as the whole question description in the book ?
307780,since the site has a tag for propensity scores with 199 threads i wonder what steps you have taken to find out about the ones you asterisk ?
307784,is there a rationale behind the hyperparameter choices of your model ?
307831,what's the rationale for doing individual comparisons ?
307877,"if you * didn't receive helpfulness votes * , then that sounds more like missing data . why would all these missing votes be zero ?"
307675,there are some nice tricks if all diagonal entries of d are equal . any chance that's the case ?
303229,"would you be able to provide us some example code , and the value you expected to see ?"
307953,can you please add the self-study tag ?
308031,what exactly do you ask ?
307770,"soft max would be a solution , but given you are doing a binary classification , why are you doing a regression tree ?"
307909,what do you mean by * using student's $ t $ -statistic to define the estimators * ?
308077,"please be more specific , because you haven't asked an answerable question : you have only expressed a state of mind . exactly what don't you understand about this page ?"
308040,to invert $ f $ you are going to have to solve $ y = exp ( - beta x ^ alpha ) / ( 1 x ^ m ) $ numerically because that is a transcendental equation . maybe some clever acceptance / rejection scheme is in order here ?
308030,is your outcome variable bounded below at zero ?
308090,what does srl mean ?
308120,"logical fallacy : false either-or . you might look at the geometric mean , the harmonic mean , any number of windowed running , smoothed , windowed , or truncated means . there are , several infinities worth of possible measures of central tendency . you are asking "" what is the best mean "" . this is an optimization problem , so what is your rubric for "" bestness "" of the mean ?"
307991,"there isn't anywhere near enough information to answer this question , assuming the usual meanings of the notation : that is , that the $ x_i $ are independent identically distributed random variables . what does the unusual expression "" $ r ^ { [ 1 , n ] } $ "" mean ?"
308083,what is acc ?
308129,the dataframe has only ` cbsa_code ` and ` emp_app ` . what is the ` est ` in the regression ?
307552,is everything all correct with your centering / scaling of the data ?
308192,if you want to compare two measurement systems have you considered using bland and altman plots ?
308216,what do you mean when you say your first attempt at creating a time variable was incorrect ?
308130,how does your script model drawing * without replacement * from the deck of cards ?
307777,"if you standardise each to n ( 0 , 1 ) then surely they will be normal ?"
308023,"do you know how to find the covariance matrix of $ ( b_0 , b_1 ) $ ?"
308403,"1 . likert items are plainly not normal url -- there would be no point in testing something you already know for sure . . . however 2 . ivs * are not assumed to be normal * in regression . 3 . your dv is not normal either ( though it's not the raw / marginal dv that is assumed to be normal ) , not even close . you don't state what the 1 , 2 , 3 values represent -- is that categorical ?"
308414,"the final ( unfinished ) statement is unclear because one cannot tell what "" it's "" refers to . apart from that , the only statement with any substance is the original claim that convexity of $ s $ implies the expectation of an $ s $ -valued random variable lies in $ s $ . that follows immediately from one particular definition of convexity--namely , weighted averages of elements of a convex set are in the convex set--and the definition of expectation ( which is a weighted average ) . there's much less going on here than you might suppose ! what , then , are you specifically trying to ask ?"
308436,have you looked into using influence functions to detect multivariate outlier ?
308450,what is the cdf of a set $ b $ ?
308460,is there any uncertainty here ?
308486,how does the missingness arise ?
308497,* * problem is that evaluation over a single test set gives an estimator that has high variance . * * why do you think so ?
308521,"what is your definition of "" can be classified "" ?"
308565,maybe i'm being ignorant here but never heard anything like wilcoxon-mantel-haenszel . are you perhaps referring to wilcoxon-mann-whitney ?
308559,"hi , and welcome to cv . i'm afraid your question is not very clear to me . how do $ n $ , $ k $ , the three sets you propose and the formula hang together ?"
308604,"do you have any idea what the distribution looks like , and if you could make it look more 'normal' through a transform like a logarithm ?"
308621,"why do you think the class imbalance is a problem , and what problem is the oversampling addressing ?"
308627,are you sure you don't want to estimate the actual probability of fraud ?
308657,i think it depends . is there an evidence that the team's performance depends on past games ?
308680,"are these actually curves , or was this plot generated by plotting points and then connecting them with line segments ?"
308684,"since each pc is ( by definition ) a linear combination of the original variables , by merely expanding each pc out in the second model , you will have written a model that is * exactly * in the first form you present . could you explain what you mean by an "" actual risk factor "" ?"
308694,welcome to the site . can you edit your question grammatically to enhance its readability ?
308750,is this a homework / exercise / test question ?
308752,your taylor series $ ( 4 . 7 . 1 ) $ seems missing $ ( f- hat { f } ) $ . shoud it be $ l ( f ) = l ( hat { f } ) frac { l' ( hat { f } ) } { 1 ! } ( f- hat { f } ) ?
308781,"notice that "" $ beta $ "" has different meanings in the two models you are asked to compare . maybe it would be clearer if the question asked you to evaluate a regression model of the form $ y = x ^ prime gamma e $ . given that the poisson model applies , can you work out the distribution the random variable $ e $ must have , conditional on $ x $ ?"
308806,do you know the parameters of the two dirichlet distributions ?
308782,are row number 5 in blackbirds and row number 5 in song thrushes paired data or unpaired data ?
308835,why is sgd ( stochastic gradient descent ) listed with these other things ?
307837,have you considered multivariate regressions or a seemingly unrelated regression with a cross-equation hypothesis test ?
308873,can you clarify what you mean by unique and why dummies are a problem ?
308890,i am a bit confused . will you have individual-level data from untreated towns ?
308859,is c the eight level factor formed from the interaction ?
308906,could you back those mean values into * total * values ?
308912,what's your goal with the analysis ?
308922,"what is preventing you from taking the ( piecewise ) derivative of $ c_x ( y ) $ , which immediately gives you the pdf ?"
308932,"could you explain what "" pairwise exponential "" means in the title ?"
309035,"so , just to clarify- $ hat theta_n = min_i x_i $ is the mle for a parameter $ theta $ in a model with density ( proportional to ) $ e ^ { theta-x } $ ( $ x 0 $ ) ?"
308925,why are they redundant ?
309077,not so obvious to me . could you add some context ?
309112,"if age were uniformly distributed between 25 & 75 , & income were an exact linear function of age , what distribution would income have ?"
309126,"i can't see that imputation will add any information on outliers to what you have already . in this kind of data there are outliers -- china and india have very big populations , etc . -- but their main implication is to work with some variables on log or another transformed scale . why worry about marginal normality or its lack ?"
285697,"what is "" intersection "" ?"
309186,so you want to assume the conditional mean is changing as well as the conditional variance ?
309216,are the estimates also restricted to be integers ?
309210,why not just fit the arelano-bond estimator treating the fixed effects as just a set of dummies ?
309232,why sample from the posterior at all when you have already calculated it exactly ?
309143,` and filtered out insignificantly correlated variables ` why did you do that ?
309251,i need more information about your network architecture . how many layers are there ?
306410,is this an exercise for some class ?
309281,is this work for some subject ?
309182,you do have a statistical question here in the first part but the later request for code is liable to get this closed . perhaps edit your question to avoid that happening ?
309337,"no . when was the last time you saw the "" matrix solution "" for $ hat { beta } $ written out using the qr decomposition as actually implemented on a computer with nested for-loops ?"
309362,1 . is this for some course / subject ?
309342,""" if . . identically distributed variables . . . does this mean they are also identically distributed ?"
309352,"your code is unreadable . please clean it up , using proper indentation , data structures , and documentation . if you do not , it is not likely that anyone will bother to read it . moreover , you have not even described what the code is supposed to do , so what understanding are we supposed to check against ?"
309037,what language is that ?
309399,you need to clarify this by editing . which of x or y is n ( ) ?
309418,[ please tell us ] ( url ) what have you tried yet and where are you stuck ?
309421,"are you , or would anybody , really be in any doubt about the clustering ?"
309332,how big is your data set ?
307340,what do you mean by 'delayed inputs' ?
309467,"obviously $ y $ and $ y ^ 2 $ cannot be independent unless $ y $ is a constant . could you explain how the posts you referenced , or even url do not fully answer your question ?"
309485,"( 1 ) what is the source of this "" high bias "" to which you refer ?"
309494,my own question [ should we account for the intercept term when kernelizing algorithms ?
309524,so did you try ` lmertest ` ?
309526,"( 1 ) i hope you have somehow misquoted or incorrectly summarized the answer key , because it's a little mind-boggling to see precision confused with statistical significance ! ( 2 ) unless your $ b_ { ij } $ are coefficients of * standardized * variables , what sense does it make to compare the standard error of one to the standard error of another ?"
309545,is $ x_i $ going to be the midpoint of the window ?
309268,could you clarify what you meany by the first statement of your post ?
309559,"welcome to cv ! since you are new here , you may want to take a [ tour ] ( url ) , which has information for new users . is your question from a textbook ?"
309560,1 . what are you quoting there ?
309586,are you looking for a theoretically calculated deviation $ sigma $ of the distribution or an expectation value for the estimated variance $ s $ of the sample ?
309621,"let's say you have no missing values , what would be your plan for establishing predictive power ?"
309580,does it mean that each checkerboard has a different size ( in terms of number of squares ) ?
309683,"( i ) your ` r ` expression is incorrect : you need to subtract ` ppois ( 2 , . . . , lower . tail = true ) ` rather than ` ppois ( 3 , . . . , lower . tail = false ) ` . ( ii ) why not just compute the observed proportion of values between 3 and 6 ?"
308669,"interesting question but i cannot see how an answer can be motivated without a specific use-case . do you have * "" grossly corrupted observations "" * ?"
309698,would one of the bayesain packages mentioned in the cran task view help ?
309703,could you explain how you think having a balanced dataset would be helpful ?
309519,what's unsatisfactory about the wikipedia definition ?
309776,did the researchers have honest confidence about the order based on a-priori knowledge such as experience or theory ?
309778,"i'm not sure i'm following the question . yes there's a reference category if you're using dummy codes . you're looking for the value of the regression coefficients associated with these dummy variables , or the correlation between variables ?"
306041,a reproducible example ( including the one that produces an error ) would help . for the benefit of me . . . since nobody looked at your question for a month ; ) . . . can you explain the advice regarding both the fixed and random effect approaches to meta-analysis ?
309838,"how do you multiply a "" bag "" $ y_t $ by a scalar $ alpha $ ?"
309850,seems more like an economics question . should it be moved to that site ?
309862,"it's not quite clear what you're fishing for , because the motivation for this definition of heavy-tailed is explicit : it greatly reduces the utility of the mgf . are you perhaps trying to ask what value it might have for the mgf to be defined in a real neighborhood of zero ?"
309880,"the output of the network should be the value returned by the sigmoid function , which is used in the loss function directly ( typically binary cross entropy ) . so , it should be pretty easy to lower the threshold as you please . which library are you using ?"
309916,"and to follow on whuber comments , there is nothing bayesian or non-bayesian in the question as stated , since the model is not precisely specified . what is there to estimate there ?"
309917,"you talk about a series first and about residuals thereafter . are you dealing with residuals from some model throughout or first with some original series and then residuals , or with an original series throughout ?"
309935,"what are you referring to : negative coefficient estimates , negative predicted log odds , or negative predicted probabilities ?"
309901,spearman's rho and kendall's tau are calculated in different ways . why do you believe that something is going wrong with the kendall tau calculation ( and not the spearman one ) ?
309977,can you be a bit more specific ?
310005,"i'm curious about that statement -- "" once objects in the real world are projected . . . they may have the same coordinates . "" did you have a specific example in mind ?"
310021,possible duplicate of [ how to know that your machine learning problem is hopeless ?
309867,i am not following . could you present an idea in the original question with some supplementary data ?
310071,i've seen a variety of different intercepts used with the theil slope . how are you calculating the intercept ?
310073,tomque why would making the * data * appear normal be required for regression ?
310121,"you say your response variable is a "" proportion of total counts "" , do you know the constituent counts ( hits , & totals ) ?"
310167,mickey if the data is random then how do you want to learn any kind of relationship between the two ?
310168,how can you say that the $ r ^ 2 $ is low without a point of comparison ?
309930,what is $ alpha $ ?
308730,"examine the functions in this carefully : ` n = 5 ; plot ( stepfun ( cumsum ( rexp ( n , . 1 ) ) , 0 : n ) ) ` . . . is there a statistical question here or is this just about the r implementation ?"
310242,"it sounds like you want to simply predict some labels for your data based on learning on the sample of it , isn't it . . ?"
310278,"the straightforward thing to do would be to just cast aside the bad observations . unless there are aspects of the bad observations that aren't bad , that you're perhaps not picturing ?"
310290,what do you mean with a deficit ?
310328,"there are two ideas . first , the test is going be a one-sample test since you compare smaller groups' mean to a population ( supposed ) mean . second , why would you want to do this given that hypothesis check on a sample statistic is about where the sample is from the specified distribution ?"
310336,how about a sample size of $ n $ / 2 so you can maximise the total number of unique draws ?
310351,first of all : why would you use a suboptimal method where there are * lots * of better ways of doing this ?
285594,"first you say that $ x_1 , . . . , x_t $ may be dependent and then you assume they are i . i . d . -- could you clarify on that ?"
310387,"the package ` marss ` fits linear gaussian state-space models with a kalman filter , which easily accommodates missing values . have you tried just sticking ` na ` values in your series for the middle part ?"
310232,"generally , you may do that . why so many attributes ?"
310416,your original problem seems to indeed only have been a problem of too few iterations . regarding zero-inflated versus stand negative binomial : how badly off is the number of zeros from what your model predicts ?
310423,what's the exact problem statement ?
310285,can you be more specific about what you've tried so far ?
310437,could you show your model's summary : 3rd and 4th cases ?
310494,"for fitting likelihoods , there's nothing special about this problem . nothing differs in the least from fitting curves in cartesian coordinates : as always , you write down the likelihood function and find its maxima . what , then , are you trying to ask ?"
310508,could you explain the meaning of an expected proportion of zero and why you are carrying it along in your calculations ?
310563,could you include the results / printout of the fitted garch model ?
310575,"i don't understand your simulation code . inside your for-loop you do 'y [ , i ] = a ^ ( i-1 ) % * % y [ , i-1 ] ' . why do you raise all elements of a to the $ ( i-1 ) $ power ?"
310610,with that sample size is it reasonable to expect it to fit any distribution you choose ?
310650,""" i need 1000 pcs to capture 75 % of the variance . "" could you elaborate on why you interpret 0 . 75 as 75 % but 1 . 00 as 1 % ?"
310660,"have you considered simply displaying what you know , rather than trying to distill this information into a single score ?"
234085,1 ) your formula d = d1-d2 should be d = z1-z2 ?
310722,are you familiar with method of moments estimators ?
310750,"you want to "" distinguish the classes / categories apart "" but you are "" not trying any classification "" ?"
310804,"( 1 ) yes it will , but thid doesn't have to be "" bad "" . ( 2 ) why would you do that ?"
310779,how exactly did you get those values ?
310820,are you looking for finite mixtures ?
310809,this sounds a lot like the general issue of [ omitted-variable bias ] ( url ) . what exactly are you trying to accomplish that goes beyond documenting that phenomenon ?
310831,"i cannot really real eviews code well , so let me ask : does eviews set the mean to zero , or does it estimate it ?"
306972,"can you define the events $ l_i $ and $ a , b , c , d , e $ ?"
309240,you need to tell us about your data & your study . what are your variables ?
309832,can you explain symbolically the assumption you're referring to ( made by the t-test for pearson correlation ) ?
310892,"* "" null hypothesis : there is no difference between the 5 curves . "" * if there is no difference among any of the curves , there will be no significant individual difference , especially after multiple testing correction . non-parametric statistics are less powerful than parametric statistics if the assumptions of parametric statistics hold . can you include a bit more about the type of data and the research question ?"
310849,"i don't see any percentages here at all , nor can i see numbers like 21 . 7 % or 89 . 1 % anywhere . have you noticed that the four gray bars all have identical lengths ?"
310975,is it essential that you process each image in one go and are you strongly tied to this architecture ?
311020,` the best latent factors ` for fitting this dataset . but who will test how it is reasonably good for the population ?
311021,"* "" notice that [ variance ] is constant for a given set y , "" * could you please explain this a bit more . what is this set y you are talking about ?"
307544,"ok , i will rewrite the code for your data . which one of the column in your data is res ?"
311017,can you give an example where the rule _does not hold_ for _dependent_ random variables ?
310962,"did you look at the "" disasters "" example in pymc3 example ?"
311042,could you explain just how those plots suggest non-stationarity ?
311051,what is the purpose of having two explicit training data sets ?
311044,transaction * data * or * date * ?
311025,what formulas for correlation do you know ?
311005,can you edit this post to use simpler language and clearly state a single question ?
181589,"i am not sure , but maybe [ dempster-shafer theory ] ( url ) is something to ponder in this line of thought ?"
311073,is there a typo here ?
311136,how large are the datasets you are trying to model ; why do you assume non-linear relationships to be present ?
311146,do i understand correctly that you calculated the required sample size after obtaining the sample ?
311112,"yes , you are right . and of course we * want * this dependence . if your time series were independent , there would not be a point to time series modeling . does this answer your question , or could you clarify if something is still unclear to you ?"
122673,one serious difficulty with the alleged cdf reported in the question is that it is not monotonic : it jumps * down * from 0 . 539 to 0 . 469 at $ x = 166 $ . there must be some mistake in reporting it . what connection do ` ag ` and ` bg ` have to ` as ` and ` bs ` in the second half of the equation ?
310062,"ben : for a couple of serial numbers , check the scatter plot of response versus voltage . are the functional relationships looking like a polynomial of degree 3 ( big doubts here ! ) ?"
310989,"what do you mean with "" the data is not balanced "" ?"
311326,"try taking the log of the likelihood . which term now appears to be a constant , i . e . , one whose value can change without affecting which value of $ theta $ will maximize the log likelihood ?"
311349,"does your textbook say anything about confidence intervals , z tests , or t tests ?"
311371,and what makes you want to do 'model selection' instead of just 'model specification' ?
311377,"in my experience , box-behnken is used when you can't access design points at the vertices of a design . depending on the factors , can they be redefined numerically or the highs and lows adjusted around the centre point value ?"
311427,is your output variable ( or some derivative thereof ) included in your input variables ?
311428,is it necessary to use problem 2 as a 'substep' in the solution ?
311421,a monte carlo resolution is obvious . what is the question ?
311446,question : why do you need percentages ?
311451,have you included a time covariate in the autocorrelation structure ?
311460,what hypothesis test did they use ?
311467,"what do you mean by "" returned log likelihood function "" ?"
311430,what are your variables ?
311482,"would "" cyclicality "" mean "" seasonality "" ?"
311360,"perhaps you have a different understanding of "" multivariate "" : that refers to a vector * response * , not multiple regressors . which situation are you trying to describe ?"
311521,what do you want to do with the model ?
311479,a few questions before an answer : ( 1 ) are individuals only at one site ?
311556,regarding the convergence warning - you said in ( 1 ) that you tried ` bobyqa ` optimizer and it did not produce any warning . what's the problem then ?
311614,is your noise really constant as the mean changes ?
311639,"there should be a way to obtain the scores of your new variables ( factors ) via the factor analysis command . as an example see this : ` dt = mtcars ; f = factanal ( dt , factors = 5 , scores = "" regression "" ) ; dt = cbind ( dt , f $ scores ) ` . it creates 5 new variables and uses a given method to calculate the scores of those new variables . for more info see ` ?"
311486,"further : how do you derive $ frac { log ( p ( x , z ) ) } { p ( z x ) } = log p ( x ) $ ?"
311718,i think people are going to need more detail to be able to point you in the right direction . what are these variables ?
132830,how many categories are there in the rank ?
311683,""" bell curve "" is not a well-defined mathematical constraint . what do you mean ?"
311751,"i have voted to close as a duplicate . if you don't think the earlier question addresses your concerns , perhaps you could edit your question to be more specific ?"
311771,is there some context for this question ?
311764,"i should think , however , that a sum running from $ j = 1 $ to $ i $ would describe the likelihood corresponding to $ i $ observed patients ( not $ i-1 $ , as you indicate ) . are all your $ i $ 's and $ i-1 $ 's verbatim from cheung ?"
311678,is there some difference between ( 2 ) and the alternative expressed in the final equation ?
311872,what kind of autoencoder do you use ?
311882,why don't you look at the data ?
311865,could you tell us more what exactly does it show ?
311906,"could you please tell us what you mean by a "" cramer statistic "" ?"
133690,the poisson * process * seems to be a good idea . do you know what is it ?
312003,"could you tell us what you mean by "" unrelated to "" ?"
180451,"i don't know robust regression , but how do you want to use the aic or bic ?"
312030,why are you omitting the last observation in your definition of the sample mean ?
310731,it's quite straightforward . is this an exercise for some class ?
121425,can you double check your last equation ` ( -1 ) ^ 1 143c1 * ( 1 - 0 . 0044598585072423936 ) ^ 142 = -75 . 802 ` ?
311915,"this may be stated too generally to permit any effective answers : based on what you have given , your objective function could be literally any function of $ alpha $ that takes on values between $ 0 $ and $ 1 $ . perhaps you could make it more specific by providing more information about the multivariate distribution of $ x $ ?"
311920,"what do you mean by "" $ k $ "" ?"
311774,"these are not distributions but relationships between your observed quantity and time ( which we might metaphorically refer to as * trajectories * ) . when you call it a parabola , do you mean that you intend to fit an actual parabola or is it intended more to mean something like "" a somewhat-near-to-parabolic more-or-less-smooth function that increases and then decreases "" ?"
311949,any particular reason why the response and e . g . count are left untransformed ?
312117,"the derivative is not the kind of functional for which the bootstrap will work . if you try it , you will be making deductions about your method of estimating densities from data--but they won't tell you anything at all about the derivatives of the true underlying density . one has to wonder why you are focused on this : just what information would the derivative of the density hold that is of interest ?"
312147,"if your categorical variable has few different levels , e . g . , "" red "" , "" green "" , "" blue "" , "" purple "" , then it would be quite feasible to put everything "" red "" in the left branch , then try all $ 2 ^ 3 = 8 $ possible ways of adding everything of zero , one , two or three specific colors to that left branch , and finally evaluate the purity gain . are you sure no implementation tries something like this ?"
312150,how often did you run the training ?
235111,do the real values vary ?
312153,can you elaborate on why simple methods do not seem a good choice ?
312164,"what does the "" 3 / 5 days "" signify ?"
252780,is this a homework problem ?
169864,would you have asked this question if fisher's test would have given a p value below your significance level ?
312213,is there any reason to believe that trials # 1 in condition a and # 1 in condition b could be more similar to each other ( for any given subject ) than trials # 2 ?
312262,"you seem to be asking how to estimate parameters , or improve a previous estimate , given that you have no relevant data . how do you hope to accomplish that ?"
312281,"benzamin the paper's expression for the posterior ( 3 ) is different than yours . i also notice that your expression places normal priors on variance components , that you have different means for your $ gamma $ terms , and that there are some discrepancies with your subscripts . have you tried a problem like this with a simplified model ?"
312326,can you provide a link to your online source ?
312268,can you explain how exactly your personalized pagerank algorithm works ( or give a reference ) ?
312306,"a bayesian interval won't give you an interval with the properties of a confidence interval ( won't give you a selected level of coverage for example ) . if you're contemplating both [ credible intervals ] ( url ) and [ confidence intervals ] ( url ) at the same time , what properties are you looking for in an interval ?"
312374,"by a single layer , you mean no hidden layers ?"
312128,"any poisson or negative binomial routine that rejects data with zeros is incompetent ! restriction to * * zero or positive * * values is common , but not universal , as arguably the key assumption is that * * means are strictly positive * * , not the data . the problem with negative values is knowing how low they can go . is the range from -5 to 5 empirical or a matter of principle ?"
312307,"it's not clear what sort of explanation you're seeking for "" the concept behind the z-test "" . what is it you want to know ?"
312398,"with this low number of observations you can practically get increasing or misleading rmsep . actually , as the number of components increases , the chances of overfitting increases which may be somewhat evident from a rmsep vs ncomp plot obtained by loocv . another possibility is that plsr fails to model this data . how about obtaining a test set to evaluate the success of the model ?"
312496,how did you obtain a sample of data in dimension $ 3 10 ^ 9 $ ?
312512,"in many practical situations there isn't any finite "" population , "" nor would it even make sense to pretend there is one . how many samples of seawater are there , or possible observations of a star , or adult human beings ( who ever will live ) ?"
312527,"a tiny bit . entire books have been written on ways to interpolate geographic data . "" associated physical measurement value "" is so vague that it doesn't narrow the scope much . what kind of measurements--yes / no values , counts , differences of counts , angles , positive quantities , any quantity , etc ?"
312518,"the result isn't necessarily true , because it depends on how $ x $ changes with $ n $ . could you tell us what you are proposing ?"
312558,"how to define "" better "" ?"
312582,are you assuming independence ?
312605,"could you tell us more on your actual problem ( what is your data , what are you trying to achieve ) ?"
312610,do you assume anything of the ( non observed ) value being measured . is it known to be constant across measurements ?
127337,have you looked at the help page ` ?
48464,"apart from the description of the hessian , i cannot find any definitions of anything in or near the second paragraph . exactly what definition are you referring to ?"
310676,wouldn't that be a mixture of gammas with scale parameter $ - log p $ ?
168766,"aksakal is correct , kristof ( and happens to be one of the "" more experienced people "" whose help you might be looking for ) . although you * likely * intended to include words like "" two-sided confidence limits "" in your description , their absence leaves us wondering what you're actually trying to do and what exactly you mean by "" the metric changes . "" could you please edit this post to clear up these ambiguities ?"
312671,what are your response data ?
312692,"it may help to underline that pca has no idea of response versus predictor variables . also , although you mention several variables , it's not clear which would be used in each method . what is habitat cover ?"
312704,what is the _joint_ distribution of $ x $ and $ y $ ?
312710,"can you clarify what a "" complete posterior "" distribution is ?"
312723,the [ ` caret ` ] ( url ) package has a function called ` expotrans ` that estimates the exponential transformation of manly ( 1976 ) by maximum likelihood . does this function satisfy your needs ?
312642,would you mind to define all symbols that you are using ?
312743,loadings and weights are useful when interpreting individual components . is it really your purpose ?
312745,"iseliget , it appears you're using both $ ^ t $ and $ ' $ in the same equations to mean transpose ; it would be clearer to use $ ^ t $ throughout . also , i'm not clear what the "" 1 "" following each $ bar { y } $ is meant to represent , is that just a typo ?"
312766,could you perhaps share links to at least two specific papers ?
312770,should the p-values not be uniformly distributed under the null hypothesis ?
312763,"where is $ f ( x , y ) $ in the integral ?"
243975,"first , is this an independent samples comparison or a paired comparison ?"
312797,"could you edit to tell us what do you mean by "" imputing the same data over time "" ?"
312817,what is vif in coefficients table ?
312835,` as . list ( coef ( model ) ) ` will not give you a list with the right format ( see ` ?
312836,what is your aim in modeling ?
312846,what is the goal of information coefficient ?
116753,"when you say there are 3 outcomes , do you mean that there is actually 1 outcome with 3 ordered levels ( low , medium , high ) ?"
312857,i think we are going to need more detail here . do you have a family of distributions to select from ?
155464,it is going to be hard to say without more information . can you paste in the code & output from the 3 tests ?
33758,"no problem , could you edit your question to use a different phrasing than "" punctuation "" ?"
312790,"i have tried replicating your problem but i could not get past the first line . after i run it , i get the following error message : ` error in download . file ( paste ( yahoo . url , "" s = "" , symbols . name , "" & a = "" , from . m , : cannot open url 'url is it supposed to work right away , or have you omitted some code that precedes your code that is necessary to make it work ?"
312886,"con , it seems to me quite likely that the most useful answer to your question is an explanation of why you shouldn't , or can't , or shouldn't want to do what you're asking for . can you give more details ?"
309380,what is this curve attempting to display ?
312875,can your huge differences be demonstrated in a simple overview of the data ?
313000,have you tried subtracting the mean from the time-series ?
312894,does this help url ?
237922,"annie i'm confused by ( c ) as well . what is "" the unit of measurement "" of a distribution ?"
310069,"the condition number of a ( positive-definite ) matrix , when otherwise unqualified , is usually understood as the [ ratio of the extreme eigenvalues . ] ( url ) this is inconsistent with any of the statistics you report : in ( 1 ) , 10 / 0 . 01 = 100 but you report a value of 34 . 21 ; in ( 3 ) , 2 . 30 / 0 . 44 = 5 . 23 is not equal to 2 . 28 . ( since 2 . 28 * 2 . 28 = 5 . 20 is close to 5 . 23 , maybe you are reporting the square roots of the condition numbers ?"
313065,"yes , by inspection it's quite clear how to get an essentially perfect fit . . . is this an exercise for a class ?"
313076,"have you identified which measurements belong to which product ( e . g . by time ) , or is that part of the question ?"
313089,this looks like it's exactly the same question . could you elaborate on how you think it differs ?
312498,why didn't you add a garch tag to a question about a garch model ?
312341,aren't nw-type hac estimators superseded by the fixed smoothing hac estimators of [ kiefer & vogelsang ( 2002 ) ] ( url ) & the subsequent literature ?
313167,can you please add an example ?
313183,"by "" explanatory variable "" , i assume you mean the * dependent variable * ?"
313216,i your question about speed or mathematical model ?
313170,"what do you mean by "" handling "" multiple values ?"
105320,is your response actually a count ?
313300,there's a 60 % probability that it is a an a and 70 % that is a b ?
144239,here is what you seem to be overlooking : how do you obtain $ e $ ( which you need to use on your step # 2 ) ?
49700,i agree w / cardinal . are you referring to the scale parameter for a specific distribution ( which ?
22118,"don't you have access to x1 , . . . , x5 ?"
313394,1 . cook's distance is a function of the residual . 2 . what does it mean for something to be an outlier without reference to the dv ?
313363,how many terms do you have in the sum ?
313432,do you believe the model is wrong because you do not like the result or are there other reasons ?
158426,"the fact that your measurements are paired might also play a role on how you compute this ratio . as you work with paired measurement , don't you want to compute the mean ratios ( each individual has a ratio , and you mean it ) instead of the ratio of the means ?"
313452,isn't there some physics here that can inform analysis ?
313344,"some edits of language , but it's not totally clear what your situation is . observed versus measured : what's the distinction there ?"
313535,worth interpreting in what sense ?
313542,can you work you the density of $ u ^ 2 $ ?
313557,is there some reason why you don't see values above 15 ?
313576,why would you need to check normality ?
313608,"this may be a valid question but it sounds too broad at this form , since you seem to ask us to translate any possible frequentist method into bayesian form -- one could write a book on this topic ! most introductory bayesian handbooks ( e . g . kruschke ) discuss those topics as they are aimed at frequentists . moreover , you probably already use a lot of frequentist tools ( e . g . for diagnosing your mcmc chains ) . some of the topics you mention are not purely bayesian ( loss function ) . could you try editing your question to make it more specific ?"
313643,q1 : do you have a clean validation concept ( like cross-validation etc . ) ?
313617,possible duplicate of [ invariance property of maximum likelihood estimator ?
313671,"[ apa style ] ( url ) guide seems to be clear about it ( ` r ( df ) = value , p threshold ` ) , so i wonder what is your question in here ?"
313706,what * action * is taken when an observation falls outside the control limits ?
313730,which issue exactly do you want to solve ?
313869,"what do you mean by "" either my ar term or my ma term is pretty high "" ?"
313783,"is this actual data , or simulated ?"
313887,because nobody's calculating the likelihoods ?
313890,it looks like you have a circadian cycle . have you considered a cosinor model ?
313941,"btw , why do you need orthogonal weights ?"
313966,96th percentile of * what * ?
313968,it sounds like you are asking a lean / economics question and not a statistics question . are you sure this is stats related ?
314009,have you considered a fft to determine periodicity of the amplitude ( electric potential ) ?
314017,"two possible reasons for the downvote are that the question is very broad ( there are all manner of similarities one might discuss ) and that the question relies on an external link that you give no context for ; if the pdf were removed it would be difficult for anyone to find out what you were asking about . . can you give the an outline of the sorts of things it says are differences in your question ( or perhaps a couple of pertinent quotes ) , for some context ?"
313670,describe your data - is it percentage of users - complaints or index for efficiecy of different machines / users . total sample and subsamples- number for each group ?
314056,what exactly is unclear for you ?
314059,"you have two objectives , and how you combine them matters . are you trying to ensure that # 2 holds for 100 % of your predictions , and that # 1 is the best ( let us say least squares ) solution that can be found given # 2 ?"
314070,what * simple formula * ?
314074,what about the macroeconomic environment ?
66715,"is there censoring ( dropout , other disease ) ?"
83510,"the data is univariate . when you plot it , does the histogram looks unimodal ?"
57257,i assume that you want the answer to assume a flat prior ?
314109,"i'm a bit confused by your choice of setup . you have output functions $ f_i ( x ) $ for $ i = 1 , 2 , . . . , 12 $ and 28 input features . instead of outputting each function at each sample , why not train your network to output $ f_i ( x ) $ ?"
314156,"second question : are $ a $ and $ b $ independent of one another , or is $ b $ simply $ a $ with an additional variable on each observation ?"
314157,"the various paragraphs don't seem to have much to do with each other . the title and the first paragraph are ambiguous : what does "" single trial of an event "" mean ?"
314190,what does the original series look like ?
314080,"what is the benefit of adding $ hat { y } _1 $ and $ hat { y } _2 $ after estimation , rather than regressing $ y = y_1 y_2 $ on the $ x $ s ?"
314207,"firstly , i don't get why you define distance between two points as $ e [ u_ { ( m k ) } ] - e [ u_ { ( k ) } ] $ . why do you need to invoke ordering at all - is that some shortcut i don't notice ?"
314231,what exactly is your goal ?
314217,could you describe your procedure in greater detail ?
314266,"if you did not estimate $ rho $ , what value would you use when actually implementing the gls ( * some * particular value is needed ) ?"
314268,that fact that you don't know what hypothesis to formulate suggests you don't need a test . why not just summarize the data ?
314124,"first , why do clusters , if they exist , have to be about "" balanced "" groups ?"
314169,it shouldn't matter if the cross-over is staggered . can you clarify the subscripts in your model ?
314358,please explain what you mean by the variance and covariance of a series . several possibilities are natural . are these series of numbers or series of data values ?
314381,what exactly is your question ?
314208,what is the goal of your analysis ?
314450,[ kruskal wallis ] ( url ) ?
314454,is your question about * methods * of fitting polynomials via gradient descent ( that you may be able to implement in python ) or are you specifically seeking python code / functions to call ?
314490,"once you take logs , your response is not in seconds . in effect it's unit free . are you calculating mean absolute error on the log scale ?"
314528,how long has it been running ?
314536,possible duplicate of [ auto . arima with daily data : how to capture seasonality / periodicity ?
314287,for homework assignments add the [ tag : self-study ] tag and review the site criteria on such questions . mainly : explain what you've tried and where are you confused ?
314538,"there is obviously no _generic_ r function that "" computes "" $ y x $ . in the problem , the conditional distributions are well defined for each possible value of $ x $ and easy to generate . however the question as reproduced is weird since the question provides the distribution of y given x . as exponential . why would one want to re-check this ?"
314558,"are these "" observations "" assumptions explicitly made in the question or are they equalities you believe to hold in general ?"
242084,better for what ?
314562,interesting question . can you provide links to the papers or articles you are referring to ?
137469,what source are you quoting ?
314632,"i find the phrase "" compress both ends of outliers "" confusing ( you seem to be using the first and last words in two different senses each there , for example ) , and it's also not clear exactly what you mean by "" preserve proportionality "" in the title and near the end when you say "" this proportionality is simply removed "" . proportional to * what * exactly ?"
314642,have you considered poisson regression ?
314629,"welcome to cv . since you re new here , you may want to take our [ tour ] , which has information for new users . could you give us more information about your analysis , for example , sample size and ranking scale ?"
314658,"sorry i don't know that network , could you specify the number of layers and parameters ?"
314689,what is the purpose of a 3 legged stool ?
314245,how big is $ l $ ?
314705,do you have a particular dnn architecture in mind ?
314746,what do you mean by the estimation process ?
314752,did you mean to say cv accuracy is low rather than high ?
314770,"you get different p-values , so there must be a difference . can you clarify what your question is ?"
285014,"melih different writers can sometimes mean different things when they say long tail or short tail ( for some long means heavier than gaussian , for some it means heavier than exponential , for some it means asymptotically power-law , and so on ) . can you give some context which might narrow down what definition might be intended ?"
311165,"it seems you are trying to estimate a ( causal ) bayesian network ( you want to know how each variable affects each other as a system , you do not want only one "" outcome regression "" ) , is that it ?"
314833,"you appear to state you have computed $ $ int_b ^ infty x frac { 1 } { theta } e ^ { -x / theta } dx . $ $ that suggests you believe the probability density of $ x $ , conditioned on $ x ge b $ , is $ f ( x ) = ( 1 / theta ) e ^ { -x / theta } $ . as a check , what is the integral of $ f ( x ) $ from $ b $ to $ infty $ ?"
314862,"you ask whether the two sample k-s test is the "" best "" test but haven't identified what it is you want to be best * at * . you haven't even clearly identified what it is you actually want to find out from the data . what do you really want to be able to find out about the two populations your samples are drawn from ?"
314778,"your notation is obscure and ambiguous . what kind of object is "" $ z_i $ "" and how is it related to $ x , y , z , v $ ?"
314886,what are these values ?
314884,"either a "" $ $ "" or a "" $ - $ "" is missing in your process . can you please edit it ?"
314893,"clarification request : what is your number of trees , and learning parameter ?"
314896,"1 . the poission $ lambda $ parameter is required to be positive , so some care is needed if you want to assume that $ lambda $ is normal , to ensure the normail tails do not practically become negative . _______ 2 . one can solve the parameter-mix distribution for your desired poisson-normal as a closed form , but it is a bit messy with hypergeometric1f1 functions . ___3 . what is the meaning of your title : tl : dr ?"
314915,"do you really , really , trust any one device to be dead accurate ?"
314930,"since you do not want a madian , maybe a trimmed mean . maybe you can find ( possibly unequal ) trimming fractions $ alpha_1 , alpha_2 $ so that there is about equal "" contribution to mean "" trimmed from each tail ?"
314955,"this is probably not an adequate representation of the structure of the information in the data . for instance , having separate main effects for fy , month and day of the week would be more useful than testing for any interactions with case_control . next , are there mean differences in gross margin between plants ?"
314957,you have levels model on log vs . difference model . why should the coefficients be similar ?
314428,possible duplicate of [ how to interpret garch parameters ?
314994,can you edit your question to include your data ?
314999,"could you expand on what you mean by "" not clearly possible "" ?"
315025,what kind of data do you have ?
315038,from your explanation it seems the problems are caused by bad fit when t islarge . thos m8ght be becaus3 of nonlinearities . maybe investigate that rather than adhoc modify the model ?
315041,which textbook are you using ?
314954,1 . your calculation compares medians . why should that be related to the chance of picking the most-biased coin ?
315072,do you mean after you have fit the model ?
315076,different authors may have different definitions--should the relation be continuous ?
19792,are the constraints linear ?
315087,"if i understand you correctly , there is only a problem if two matrices have nonzero entries at * all * the same places , correct ?"
315099,"note that you replaced $ p $ by $ n $ in the formula . now , are you asking about why there called the case of $ p le 3 $ "" two dependence "" , or just on how to generate such data ?"
314130,"i've never heard of 'parametric' qr . qr is always discussed as a robust , distribution-free , nonparametric modeling method . would you supply a reference ?"
315128,"can you specify what ci , mi and se stand for ?"
315120,do i understand correctly ?
315194,"you probably refer to the draws from the posterior generated by , e . g . , some mcmc scheme ?"
315199,are you using r ?
315262,"there's no $ theta $ in your distribution . did you want to mean $ b ( 1 , theta ) $ ?"
303269,is spearman rank correlation really a linear model ?
315176,"this language , lesion , driver , gene , makes it difficult to understand for simple statisticians . but any way . . . is the following logical ?"
315369,"without knowing what your model / data are , it's really hard to answer this question . could you expand on this a little ?"
315414,"what do you mean here by "" conditional distributions "" , cagdas ?"
315418,"thanks for edit , could you also tall us what do you mean by "" better "" ?"
315440,does this url or this url help ?
315453,can you explain your graphs more ?
203605,"could you explain what you mean by "" is not univariate "" ?"
315445,please [ read about our policy ] ( url ) and tell us more what have you tried and where are you stuck ?
315492,why do loadings lambdas have to come specifically from uniform distribution for you ?
315512,interesting question . can you edit your post to include some simulated data ?
183206,"hard to tell , because we dont know what ` alphare , ere , ure ` from stata or gretl are . do the coefficents match ?"
315502,"1 . i like the version where the urn begins with $ 2 $ balls ( and one is removed ) , then another $ 4 $ are added ( and one is removed ) , then another $ 8 $ are added , etc . : - ) neil what is that argument , exactly ?"
315577,"in an individual case anything can happen , true . what happens on average in the long run ?"
315561,what is the meaning of the ltv in this context ?
315575,"it would help a lot to describe the setting more . what is d , for example ?"
315600,"if $ theta ^ { ast } $ is the mode of $ p ( theta y ) $ , then i think what you are doing on the right hand side of the equation is some form of type-ii maximum likelihood . i . e . , you take $ theta $ as some hyperparameter influencing both $ x $ and $ y $ , and rather than integrating out the parameter uncertainty about $ theta $ encoded in a potential prior distribution , you use the ml estimate . that being said , i find the approximation itself a little strange , since it basically says $ p ( x , theta y ) approx p ( x theta = theta ^ { ast } , y ) $ . are you sure that is reasonable to assume ?"
315618,"what do you mean to prove that it "" works "" ?"
315472,"i don't understand what you want to do . given the data in your r code , you want to divide up the observations into groups ?"
315629,when you say existent do you mean exists ?
315646,1 . you probably shouldn't do anything until your goals are clear ?
257294,"if $ g $ is a function of $ x $ , it has just changed dramatically from a constant to a random variable , i . e . a non-constant function . then , how could it remain equal to the ratio of two constant quantities ( mean / variance ) ?"
108578,"coolserdash's point is on-target here , but be aware that the standard statement of chebyshev's inequality pertains to the true sd known a-priori , not an sd estimated from your sample . it may help to read this excellent cv thread : [ does a sample version of the one-sided chebeshev inequality exist ?"
315452,what is _your_ definition of independent random variables ?
304451,can you give some context where this problem arises ?
315684,why are you sure there's no separation ?
315780,"ridge regression can be calculated via ordinary least squares extended with some quasi-data , representing ridge via a bayesian prior . that gives an extended $ x $ matrix ( extended with one new row per parameter ) . just use the usual formula with this extended $ x $ matrix ?"
315782,"the kde is unlikely to be an appropriate method to smooth these data . your dataset doesn't even appear to be that large : the plot looks like two "" curves , "" each formed by fewer than 300 points . why not just apply a standard robust smoother , like loess ?"
315790,"what do you model 4 does include "" such effects "" ?"
191065,"do you have the given failure probability or only observed failures , i . e . is your response variable binary or continuous ?"
178614,why do you want to successively reduce the list rather than just going through the list once and keeping track of the maximum observed value along the way ?
315837,"you are asking about using * permutation test * , is this the term you're looking for ?"
315842,"what do you mean by "" taming "" it ?"
315865,"thanks for editing , jake . i think your question is on topic now . it isn't quite clear to me , however . what constitutes an analysis in your situation ?"
315858,is your question how to run a nonlinear regression i . e . are you stumped by something conceptual or the implementation ?
315917,could you clarify what is surprising here ?
315860,do you have repeated measures ?
315983,can you solve this problem in the case $ n = 1 $ ?
316057,"nickcox suggestions are helpful . my view is that you need to explore your proposed model structure a bit more widely to understand the relationships rather than imposing a kind of a priori , deterministic , hierarchical or sequential functional form . in other words , why not use the same approach with octane number that was done with absorbance ?"
153333,what is your dependent variable ?
316097,do you have groups with one member ?
316104,"i am not sure what the problem is here , but if the effects are indeed proportional you should count your blessings ! ( i . e . having to model time-varying effects can be very difficult ) usually , interactions are not related to the time variable unless they are specifically made for a time-varying effect . non-time related interactions are used to allow the effect of covariate $ x_1 $ on survival time to depends on covariate $ x_2 $ . might you mean to ask what to do when a ph test is not significant , but the corresponding interaction between a covariate and time is ?"
316163,"i think this is a decent question , but it is also very broad at present . what is it you are trying to do ?"
316157,it could definitely be appropriate ! but we need to see your data to answer . can you share them ?
316199,are you using catpca ?
316203,it's hopeless to calculate the properties of one sample from those of another that is independent of it ! what exactly are you trying to accomplish ?
315958,"you should look at diagnostic plots , such as the "" cook's distance "" and "" residuals vs leverage "" plots provided by ` plot . lm ` . the easiest solution to the uneven spacing is a simple transformation of your predictor , but of course this changes the model and should be based on science . you could also do weighted regression . there are other issues to consider too : you are not including the subjects in your model ( i suggest a mixed effects model ) . also , how are the "" naturalnessoftimbre "" values created ?"
315986,are your derivations assuming the $ x $ is centered ?
316272,how do you get a negative ratio of prices ?
316340,"is your question about * this particular process of weighting * the models ( there are better ones that have theoretical justification , btw ) or is it really concerned about * whether and how * to combine regression results ?"
316296,is this a question from a course or textbook ?
316354,it seems like the network is still decreasing until epoch 5 . does the cross-entropy loss stay flat after epoch 6 ?
316259,do you track the embryos individually or do you just have summary counts at each hour ?
316360,have you tried having separate sparsity parameters for the two penalty terms ?
316299,"when you say "" fitted values of y "" , what do you mean ?"
316442,"the question seems strange to me , the [ pearson's correlation ] [ 1 ] is a bivariate correlation . it is a measure of the linear correlation between two random variables $ x $ and $ y $ or $ x_1 $ , $ x_2 $ . but for your right hand side equation , there are four random variables $ x_1 $ , $ x_2 $ , $ y_1 $ , $ y_2 $ , how can you calculate the pearson's $ rho $ ?"
316453,"just to be clear , membership in one of these four possible groupings is mutually exclusive for each participant , correct ?"
316455,why do you think a cross-validation procedure might lead to overfitting ?
316462,i don't think the choice between validation metrics is the problem here since both models are clearly very bad . these results are expected since you're choosing low-order nonseasonal models to forecast a seasonal time series . how did you come up with these models and what does auto . arima give you ?
316468,kfold what ?
316470,why start with neural nets ?
315308,what is panel data investment ?
316458,you have two things here . are you looking for correct code or a correct / appropriate model ?
316507,"what does "" r "" stand for ?"
316523,what's the purpose of this academic exercise ?
316544,would you know at the time of prediction who long has the machine ` x ` been up and running ?
316558,"that "" $ / $ "" may be ambiguous . could you define what you intend by $ theta_i / pmb { x } $ ?"
316573,what is between panel variance ?
316616,"correlation is not defined if either variable is constant . alternatively , what you think the correlation should be in that circumstance ?"
315668,what is the purpose of the edit replacing $ y $ s by $ t $ s ?
316630,is there a reason you are excluding the use of random effects ?
316638,why not look at the three components of the score first . are they correlated ?
316379,how do the measures differ ?
316659,"do you really want to be using a tool that was created by someone who obviously is unfamiliar with what it is intended to do , especially when there are thousands of alternatives to choose from ?"
316662,could you please provide the output of your regression ?
316627,why are you running two different sets of post-hoc tests ?
316708,"furthermore you are writing arima ( 0 , 0 , 0 ) in the heading and arima ( 1 , 0 , 0 ) in the body . is one of those models a typo ?"
316707,"since a skew normal has three parameters and you have three constraints , where is the issue ?"
316717,"chi-square tests are highly sensitive to sample size , big * n * 's produce big stats , a finding that dates back to the earliest literature on discrete analysis and models . that said , your question is a bit unclear or lacking in details . for instance , why ( and how ) did you collapse the ~ 2 . 5m rows down to 10 , 000 unique ids ?"
316396,could you use ` bam ( ) ` to fit the model you want ?
316796,why do this transformation at all ?
316818,i don't understand this question . what is r ?
316814,"ok thanks . now i read the question till the end and it * almost * makes sense . another clarification : the set of events $ e_b $ is countable whereas the whole set $ s $ is uncountable . do you consider other points in $ s $ also to be events , or is the set of all $ e_b $ the whole event space that you are considering , and the remaining part of $ s $ is irrelevant ?"
298197,when you say central line what exactly are you referring to ?
316636,please clarify what regression you imply . one dependent variable ?
316857,"instead of comparing means at each time point , it seems like you have two time series and want to compare , perhaps , trajectories ?"
316644,"according to favid's list of "" first ( ?"
316589,what do you mean by 'break down' ?
316904,"this is a variation on the usual theme of stepwise regression , which is often unreliable for inference , but it can sometimes work well for prediction . however , as it is , the question doesn't give us enough details for a good response . can you 1 ) describe the actual problem you're trying to solve , so that we can understand if there are physical reasons which can motivate the transformations , 2 ) show us your data and 3 ) repeat the same exercise you did , but using cross-validation or traning-validation-test set , and see if the approach with the transformed variables still comes out winning ?"
316913,"multivariate regression * * is * * regression with multiple outputs . regression with multiple inputs is called multiple regression . see url but the multiple outputs is the least of your troubles : you can use the softmax function ( or look on this site for "" multivariate logistic regression "" ) . the real issue here is the temporary component , which makes this look like time series modeling more than multivariate regression . can you please show some examples of your data ?"
316916,have you tried reading the documentation by doing ` ?
316937,would you clarify your acronyms ?
316975,"what do you mean by * "" i want to make a comparison "" * ?"
317009,"( 1 ) what do you mean by "" correctly scaled counterparts "" ?"
317030,why are you counting $ e [ x_t ] $ as the mean of all previous observations ?
317027,"please explain the acronym * gp * , is that 'generalized pareto ?"
317115,"a simple histogram of negative birth outcomes per capita ( per 1 , 000 women of childbearing age ) is a good start . what else have you considered ?"
317130,why is the probability of observing one head and one tail $ frac 12 $ ?
314155,"now add your definitions of tnrate , tprate , * use * the "" given . . . = . . . "" part , and the proof should be trivial . what did you try ?"
317150,"i am sorry , i am not able to comment on the post , but i need to ask- will not a simple average of the range corresponding to your upper and lower bound should do the trick ?"
317167,"could you clarify what you mean by "" the reward function "" ?"
317192,is that all you have 6 weeks and 42 values ?
317195,can $ x_i $ and $ y_i $ be negative ?
317216,the answer to your question is simple : it is a rejection ( you have rejected the proposed sample and stuck with the current one ) . i'm not sure this helps your understanding though - perhaps you could explain why you were in doubt about this ?
317219,"i understand that in your case , a and b are large , but are they in the same side ?"
317256,"could you describe in more detail what a "" birth outcome "" might be , in what sense it is measured with a * continuous * variable , and how that might be related to proportion of a total ( as in "" 65 % of nyc births "" ) ?"
315893,"176 variables ! how can your lda work with n * 19 = 176 cases , n being the number of cases per class ?"
317264,why are you assuming $ x_i $ are uniform ?
317269,"in the phrase , "" click through rate "" , what is meant by the word "" rate "" ?"
317288,"in the title , what is baci ?"
317294,can't you just take the standard error of the mean of the maximum ?
317255,"by "" how these probability are derived "" do you mean how to derive the fact that the number of events in an interval is poisson , starting from the assumption in the first paragraph ?"
317124,can you please revise your question and elaborate your problem more ?
317297,let $ x_1 $ be the number of winning pulls on machine 1 before a losing pull . so $ x_1 - 1 $ is your payoff if you were to play machine 1 . what is the expectation of $ x_1 $ ?
317322,"what does 'edf "" stand for ?"
316962,"this is interesting , but i don't think it will attract a lot of interest because it's 50 % code . could you intersperse the code with written explanations , formulas , etc ?"
317348,"can you explain the two sigma rule , how are you able to say that ?"
317349,how is your age variable coded ?
317355,are you asking for code to create dummy variables ?
317333,"both "" age band "" and "" persona "" are categorical variables / factors ?"
73498,have you tried to work out the algebra involved ?
317404,"do you have any replicates , or is what you posted the full dataset ?"
317419,"if you know what objective you have in mind , why do you need a package to do it ?"
317425,""" i know for each person his day at work and his day sick "" does that include the bosses ?"
317400,i am suspect whether a closed form solution is necessary or possible . you allude to hermite quadrature as a numerical solution . is that not a desired workaround ?
317458,why logistic regression does not catch the variability ?
317476,"this seems to hinge on why some origin / destination pairs are not "" useful "" . why aren't they useful ?"
317450,"are these 15 different enzymes , 15 different "" doses "" of the same enzyme , or some combination of different enzymes and doses ?"
317489,"i am not sure this question can be answered without more information about the overlap between the samples . e . g . , are perhaps 50 % of the people in the first sample also in the second ?"
317508,"what do you mean by "" evenly distributed "" , that they have the same mean and variance ?"
317496,should the $ x-hz $ be $ x-hz ^ 2 $ ?
317497,did you mean 'bimodal' or 'multimodal' ?
317564,"what do you mean by "" topics which are perceived either positive or negative "" ?"
317573,how many observations do you have and what is the dimension of the process you want to model as a vector autoregression ?
317589,what's wrong with the mean squared error ( mse ) for this purpose ?
317590,"how did you measure "" community composition "" ?"
317574,"without knowing the stimulus it's hard to say too much . was the lack of reaction a deliberate suppression , or is it possible the reaction is below the limit of ( your ) detection , such as a muted gasp , or other subtle quickening ?"
317572,"it's a bit odd to see $ r ( s ) $ independent of any decisions or transitions like that in your first equation , could you link your source , so i can check the assumptions of that source ?"
317626,have you tried analyzing the weight data on a log scale ?
317658,why not fit two models with univariate outcomes ?
317665,so you want a multivariate distribution where the marginal distributions are beta ?
317697,any outliers that might have been effectively trimmed by the binning ?
317165,what exactly is truncated in your data ?
317775,you need to tell us more about $ text { price } ( i ) $ and $ text { # cups } ( i ) $ . are these random variables ?
317777,why not a linear spline ( for the seemingly linear data ) ?
316319,"you have a hidden categorical factor that causes the "" real "" data to follow the two colored lines , but without knowledge of it the data appears to follow the dotted line . consider driving accidents by age as your target and x-axis variables - not categorical . they appear to go down with age , right ?"
317818,"what does "" clubbing "" mean here ?"
317839,what is your analytical goal ?
317841,check the final model coefficients . are they the same in spss as in r ?
317229,"evidently $ a = ( a_1 , a_2 , ldots , a_n ) $ and $ phi = ( phi_1 , phi_2 , ldots , phi_n ) $ are * vector-valued * random variables . what can we assume about their joint distribution ?"
317827,i'm a bit lost here . what is the point of multiple biases ?
317857,can you post figures showing the non-normality and heteroscedasticity ?
317925,what type of data you want to analyse ?
316965,what is the procedure you adopted for sd ( store ) ?
317933,"if n = 1 , is there always a "" closed "" form ?"
317935,mean and covariance of what ?
8511,"a somewhat related question was asked here , [ logistic regression : which pseudo r-squared measure is the one to report ( cox & snell or nagelkerke ) ?"
317978,the question requires how you interpret the standard deviation and whether there is dependence between the peptides of interest . are the observations for one peptide statistically independent of the others ?
317363,$ eta $ ?
317995,why not use a more suitable * parametric * assumption than normality ?
318030,what exactly you have in mind when saying - low significant coefficient ?
318050,"one problem you have : many spending patterns show an annual cycle , but with data from only one year , identifying this is a challenge . perhaps you could extract something if you had a strong prior expectation that this annual cycle should follow a specific pattern ( e . g . sinusoidal ) ?"
317699,did you wait for more epochs ?
318086,"why did you include the [ tag : prediction ] , [ tag : garch ] and [ tag : cointegratoin ] tags ?"
318087,is it possible you have some co-linear variables ?
318089,can you please explain why it has to be $ theta_2 geq 3 $ in the calculation of $ f ( theta ) $ ?
318115,"monte-carlo tree search and reinforcement learning still require some kind of outcome / reward in order to work , so if you can't get well-labeled data to use with supervised methods i'm not sure . ( actually , it sounds like you have been a handful of true positives as well . ) you're looking for true periodic signals ( say planets orbiting a star ) , not semi-periodic signals ?"
317161,most surprising things can happen when you sum or average raw ( not centered ) variables in one scale . did you do centering or not before averaging ?
318070,all possible combinations by what number of communities ?
295017,"cross validation is not a variable selection algorithm , what do you mean here ?"
318144,"what is interesting is that all your correlations are positive . the fourth and fifth less so ( light sky , darker foreground ) but the first and second more so . what would happen if you calculated the correlation between an image and its negative ?"
312336,are there multiple rows with the same account number ?
318174,what is your $ n $ ?
318220,"there is much more freedom here than in your former question , which only depended on $ n $ . here there are $ n $ eigenvalues , which might be all equal ( easy case ) , or all different , or something in between . if you could indicate something about how $ n $ tends to infinity ( how do $ sigma $ look like ?"
318243,are you familiar with properties of expectation ?
318270,i don't see this type of regression as anything other than a fixed effects model . why use an improper flat prior and speculate at the posterior's density ?
318290,what does your $ boldsymbol sigma = sigma_j ^ 2 i $ formula mean ?
318028,"when is the study analyzed , at 12m ?"
318312,""" i have another variable representing the first variable "" is awfully obscure . could you describe your data more clearly or precisely ?"
318361,"do you have a belief ( say , probability ) that given some range of ages , the example would end up in cluster # 1 instead of # 2 ?"
318360,how can something have a probability $ frac { 1- pi } { 4 } ?
318376,would you please post a link to the data ?
318272,why not follow the advice in the thread you link to and see what happens ?
318419,""" correct technically "" in what sense ?"
318298,could you do ` ` ` model . summary ( ) ` ` ` and post it in the body of the question ?
318479,surely the desirability of various possible loss functions depend on the intended use of the analytical results . is this question a generic one or specific for an actual purpose ?
318534,do you need it to be of the form $ y = a be ^ { cx } $ necessarily ?
318556,you have not indicated the population size or any other relevant characteristics of localities ?
318565,what is the purpose of stating p = 0 . 14 ?
316944,"this might be a kind of abuse of hypothesis testing . instead of _testing for a difference in performance_ , you should perhaps be _modeling the probability that b performs better_ . also , to clarify : c1 means "" a performs better "" , and c2 means "" b performs better "" . is that correct ?"
318609,"what is "" unsatisfactory "" about your forecast ?"
318625,hi supreeth . did you have a chance to look at the answers ?
318645,i think that is supposed to be the bellman optimality equation for the state value function ( turned into an update rule for value iteration ) ?
318656,"what do you mean by "" predictors ` var1 var2 var3 ` "" ?"
262233,z_i = x_1i - x_2i is a sequence of iid rv of finite mean and variance . hence it satisfies the levy-linderberg central limit theorem from which your results follow . or are you asking for a proof of the clt itself ?
318705,"thanks . what does "" fn x1 "" mean ?"
318698,your description implies $ r $ is an integer between $ 0 $ and $ 500 $ . are you seeking an * integral * value for a discrete analog of an inflection point ?
318725,"how bad is the goodness of fit , really ?"
318737,what is the answer from your professor ?
318754,"if your probablity include zero , what will do with log ?"
318567,did you perhaps omit some powers of $ v_1 $ and $ v_2 $ in your definition of $ theta_s $ ?
318780,couldn't infants be male & female ?
318806,have you checked the variance is finite ?
318792,have you tried to use the function ` fixef ` form the package * * plm * * ?
318837,why would you want to do this ?
318870,"sorry for removing my comment , i though you were moving : ) i can't see the image , is it a full approximate ellipse ( if so this is about the most common shape there is ) or an empty ellipse ?"
318879,this sounds like a restatement of your previous question at url how is it different ?
318898,to what would this threshold apply ?
318903,between nominal data ?
317512,"forgive my ignorance , but what does blup stand for ?"
318928,have you considered survival type analysis ?
318989,is this homework ?
318916,"this is a sign the model is inappropriate ( or , possibly , that the procedure used to fit it has failed ) . how to cure that problem depends on the model . perhaps you could provide more details about it ?"
319000,"which methods will be appropriate will depend upon the nature of your dependent variable . in your sample data , the dv has values of either 0 , 1 , or 2 . is this variable a continuous measured variable , an ordinal variable , or a categorical variable ?"
319030,"are you defining "" predictions "" for a binary outcome to be the sampling average , like a proportion or percentage ?"
319072,"[ i removed my very confusing previous comment ] . your interesting question could be made more general and maybe also more precise , here is an attempt . let $ x $ and $ y $ be two r . vs with the same distribution and let $ xi ( x ) $ denote the tail index ; can we prove that $ e [ xi ( y x ) ] leq xi ( y ) $ ?"
318678,"could you explain how you would interpret a "" probability "" of $ 1 . 429 $ ?"
319076,"1 . you say you have continuous variables -- in which case you should have no ties to worry about . 2 . it's not generally finding the total number of possible permutations that is the hard part it's the number "" as or more extreme "" that go in the numerator of your p-value . what's your sample size ?"
319088,is there a typo here ?
319095,"i'm not really seeing how metric / length is appropriately modeled by a poisson model . . . especially where you can get values on the order of 1e-6 . usually this sort of model is used for count data , not continuous data . or do you have a reason to believe the variance of the error term is proportional to the value of metric / length , which would be another reason to use a poisson regression ?"
318947,"the description in question 1 in unclear and perhaps incomplete . could you perhaps supplement it with a short , simple illustration of such a sequence of variables ?"
318777,to be a valid comparison you need to specify all the null and alternative hypotheses . researcher 2 can only test 1 hypothesis while researcher 1 probably wants to control thee probability of not make 1 type 1 error out of 1000 . if that is the simultaneous inference that you want to make then you have to make do the p-value adjustment . researcher 2 has one test and no need for adjustment . for researcher 1 are you fitting different models to the same data or one model fit for each of 1000 data sets ?
319115,"saying that $ y $ is i . i . d and then wondering about autocorrelation , doesn't make sense - they are mutually exclusive . i am further confused because the model you propose is not indexed over time , so where would the autocorrelation come from ?"
318865,"why do you say this : "" also , for the same data , there should be one vc dimension characterising the problem . "" ?"
319187,can you explain what is gpl ?
319117,is $ y_1 neq y_3 $ ?
318232,how do you reach at 15 p values ?
319232,( 1 ) why do you want to use correlation ?
319228,what is your hypothesis ?
319247,are there repeated measures in this design ?
319297,what is the probability of getting 14 given that $ a = 3 $ and the expected value is 5 ?
319320,given $ mu = 0 $ and known $ sigma $ you want $ x $ such that $ p ( x leq x ) = 0 . 1 $ ?
319335,can you share the data in question ?
319360,"you seem to be hinting that there's a special ( even unique ) way of minimizing the negative log-likelihood ( "" they are both numerical procedures "" ) . what particular optimization method did you have in mind ?"
319376,"i guess your last formula implies the rejection of "" true "" null hypothesis , doesn't it ?"
319012,would presenting both help ?
319101,"there have been almost 18 years since the start of 2000 . or do you mean "" since today's date 17 years ago "" ?"
319408,what was the sample size for the original 3pl model ?
318724,"when you say * cauchy variate * , do you mean a regressor $ x_ { j , i } $ in the regression equation $ y_i = sum_ { j = 1 } ^ jx_ { j , i } beta_j varepsilon_i $ , and are you looking for the confidence interval of the ols estimate for $ beta_j $ ?"
319455,do sample units appear in the data more than once ?
134447,"i know what i would do , provided there is enough data . i would make a histogram . i would look at the histogram . if there was a clear bound at 99 making a one-sided truncated histogram at that point , i would be suspect that it was truncated . i would also look at data known not to be truncated and inspect their curve shapes , and see if i can get a probability model to fit that , e . g . , a gamma distribution , or what not . i would then go back to the truncated data ( by assumption ) and see if the rest of it is also gamma distributed ( or whatever ) . then i need to explain , "" why gamma ?"
319606,"just to be clear , is $ f ( k ) $ expected to be universal , i . e . independent of $ x $ ?"
319612,"have you tried , or considered , any other approach ?"
319616,did you notice that one bullet concerns a * product * while the other concerns a * sum * ?
319631,what are your independent variables and response variable ?
319567,is there no reason to include only the candidate covariates of $ x $ in the calculation of the $ mathcal { l } _1 $ penalty of the lasso ?
319609,does your design involve repeated measures ?
319700,"what do you mean by "" features that consist in logic operations "" ?"
319717,1 ) please add the self-study tag to self-study or homework questions . 2 ) what are the differences between the three observed probabilities ( for a starting hint ) ?
319721,what is your data ?
319820,have you tried the constrained crf model as in url ?
319828,for what analysis is 75 000 rows of data not enough ?
319837,this remains unclear . exactly what is the process by which $ a $ and $ b $ select balls ?
319794,"if the columns are indeed genes , why are there 36k of them ?"
319857,why do you want to do this ?
319862,"it does not seem to be a trivial problem , because the numerator and the denominator are not independent - they have a negative correlation - when one is higher the other tends to be lower ( because you repeat the experiment a limited number of n times ) . the main question here is - what exactly is your problem ?"
319750,"i guess wildly that perhaps 1 in 30 people here use matlab , so that cuts your readership way down . is your question adequately summarized by the first paragraph ?"
319876,it is not clear to me : around the 40th iteration ( of your first chart ) one sees a jump : what if another jump occurs at the 90th iteration ?
319853,"your ols estimate in the second curve seems to be a far better fit that your ensemble mean , so i do not think the problem is with the former . could you edit your question to explain your resampling / emsemble method in more detail ?"
319933,1 . why would you want to give $ x_3 $ a higher coefficient ( in effect ) if it's large ?
319938,are your constraints linear ?
319987,i'm curious as to what situation would prompt such a model . is it simply a mathematical curiosity ?
320007,"you get a p value of 0 . 001035 , so the output does say something . the real questions are : what are you looking to compare ?"
320034,"your notation is a bit unclear . what do you mean by the , $ x $ , $ y $ , $ bar { x } $ and $ bar { y } $ ?"
320047,how long of a time series do you have ?
320074,"if indeed the control stores were "" very similar "" to the test stores , then why are their total weekly sales almost the same despite having ten times as many control stores ?"
320068,what is the question ?
320054,there are many ways to normalize variables before combining in one index . we don't know your specific data and situation . i would recommend to lie on a sofa and meditate over variants and their implications for you . two topics i might point to as especially important : ( i ) do you really nead standardization based on subtraction of the mean ?
320110,"at its original form , clt is for the sum of a sequence of random variables ( or more generally , a triangular array ) . it is a pure probabilistic result which could have nothing to do with parameters . therefore , do you actually want to ask except sample mean , does clt establish normal convergence result for other sample statistics , such as proportion ?"
320102,what are fwe and mst ?
320186,can you express the code mathematically ?
319880,"are the residuals and fitted vs predicted you're plotting from out of sample data , or from the same data on which you fit the model ?"
320222,do you have a theoretical reason to test the ivs separately or all together ?
320154,"what does "" parity "" mean here ?"
320237,sma . d : does the text give an explanation what they consider a failure of the validation plan ?
320042,"maybe . but before you even get to that , two things worry me about this data set . first , why do you take the subset of days when only one file is created ?"
319637,gordon smyth did o . p . really get : -1 . 861246e-04 for p-value ?
320264,how is hierarchical bayes related to your question ?
320271,identifying the optimal or even a fairly good arima model in a non-random way is a complex task . i find that your method is very naive since p = 36 and q = 34 sounds massive for the time series in question . i'm not familiar with matlab's time series toolboxes but have you tried the 'forecast' package in r ?
320253,hint : the sum of gammas with common scale parameter is also gamma ( with what parameters ?
320262,"could you edit your question with a full citation to the paper , in case the link goes dead ?"
171610,"if these are different tests of different populations , is there reason to believe that they ought to be similar ?"
320342,is this innovations algorithm some standard thing ?
320397,could you clarify if you want to determine the most likely time when a user will create their first new file of the day or the probability distribution for when a user will create their first new file of the day ?
320415,"in what sense is "" $ a_0 cdots a_ { d-1 } t ^ d $ "" a time series ?"
320348,"do your "" shoulders "" contain * both * "" broken "" and "" unbroken "" data points ?"
320446,must you choose a threshold $ n $ at all ?
320451,is your question about the computational accuracy of using the laplace approximation vs say mcmc to estimate the posterior for latent variables in a multivariate normal setting ?
320408,"could you elaborate on what a "" transition of 'physics' in the tail "" might mean ?"
320347,is there a reason you need to hard assign each case to cancer or not cancer ?
320523,why do you think that $ p ( a g ) $ is a random variable ?
320524,why not remove the closed stores from the dataset ?
320624,what are you trying to predict ?
320636,i work with a similar problem . can the integers be thought of as ratios or as something similar to a count of times x exceeds y ?
320643,"a gamma distribution makes no sense for times within 24 hours . the chart is almost useless because its coordinates are unexplained and appear to have little or nothing to do with a sequence of times . what , then , is the point of this exercise ?"
49113,is this a homework problem ?
320647,how many experimental conditions does the athlete perform on a single day ?
320427,"i'm not sure what exactly you're asking but i _think_ you might be able to answer your question if you work at the level of probability measures rather than densities . it seems like a lot of the confusion here is because of manipulations of differentials and if you just worked with events it might be easier ( unless i'm missing what you're trying to do ) . have you tried to formulate your question that way , without any densities ?"
320537,what are possible values for e ?
320619,where is the missing link between the weak law of large numbers and the result ?
188869,"1 , i've wondered about this myself . such indices are used in demography as well . question is pretty straight forward , but can you describe your data snippet ?"
320727,why pool the results as a sample when you aim to delineate effects for each trial ?
320778,you may need to give us more detail but surely poisson regression would be more appropriate for a count outcome ?
320746,"by the phrasing "" family of a distribution "" , do you mean something else "" a family of distributions "" ?"
320753,"these plots aren't really that helpful . assuming that the green s with corresponding numbers are instances , can you please only plot a subsample of them in order to have the actual clusters visible ?"
320912,john meighan is this something as a toy example or to study m-h algorithm ?
320916,why exactly are you surprised ?
320966,why are ypu down sampling ?
320991,"shenflow , could you include the link to the other question ?"
320999,how many unknown photos are there ?
321016,does it matter that quantum computing is still in it's infancy ?
321000,i think at least one of the figures will make that clear . must everything that is plain be written ?
321066,perhaps change the cost function to value the 3rd and 6th more ?
321106,in doing this aren't you assuming the series are essentially the same ?
321123,"this question is not yet well formulated : you need to specify the distribution of the number of marbles that are grabbed from the bag . you also need to specify how many of each type of marble is in the bag . and what does "" grabbing exactly k unique marbles after the x number of selections "" mean ?"
268820,the link to the paper is broken . do you remember the name of the paper ?
321181,"i haven't much to add beside frank-harrell 's answer , but would be curious why you want to calculate power . maybe there is some ( mis ) conception about power or maybe there is another statistic which is more useful to what you are trying to accomplish . op , could you elaborate ?"
321165,what is alpha ?
321219,"michaelchirico , that is probably a good idea . i am pretty new to stack so i'm not quite sure how to move it - do you know how to ?"
321223,"if you have criteria here for "" will not do "" , what are your criteria for "" will do "" ?"
311077,"the modified binomial test is more interesting . it's unclear where the $ 0 . 5 $ in "" probability mass of $ 0 . 5 ^ n $ "" comes from--that number appears to have no relation to $ h_0 $ --nor is your change "" minute "" or only "" slightly modified "" in case $ p $ is close to zero , which is included in $ h_0 $ . regardless , the modified test is * inadmissible * with respect to any reasonable loss function ( including the 0-1 loss used by nhsts ) : it's provably worse than the usual test in some cases and never better . if you're unfamiliar with admissibility , then perhaps this is the concept you're after ?"
321247,"it's fixed in that when you're actually implementing variational inference ( or any other method of approximate inference ) for some model , you're working with an actual data set . this data set is fixed , and when you calculate $ p ( x ) $ for this data set , it will spit out some scalar . $ p ( z x ) $ is indeed the posterior probability of $ z $ , the unknowns , given your data $ x $ . how much have you studied bayesian statistics before ?"
321137,"gung one can outline a book . many of the questions here deal with infinite sets , and some questions are worthy of being answered not so much because they are broad but because even broad questions can have short answers . for example , if one asked , "" what is statistics ?"
321375,"if the data are sequential , would it not make more sense to interpolate the missing values ?"
321255,unfortunately i am not aware of a quicker solution . but again i have an idea for a different formulation of the problem . what about using a graph database like neo4j and standard graph algorithms to solve the problem ?
321380,"1 for validating math against code . however , it is unclear how the code computes what you described . could you clean it up ?"
321451,i don't understand your design . how / why did you set the parameters of a control condition to produce unanalyzable data ?
321204,what is the _definition_ of strictly stationary process that you are using ?
321478,quick comment : what do you mean by saying $ mu_i = { a_ib_j } zeta_i $ ?
321523,add a link to the lecture video ?
321544,"is it essential that you use "" nonlinear least squares "" ?"
321109,"yes , they , are , but why do * you * then delete $ ( x_i- bar { x } ) ^ 2 $ in the above expression for $ se ( hat { beta_1 } ) $ ?"
12605,have you looked at ` ?
321587,are you saying you are trying to predict crop yield using a variety of features ?
321592,""" and almost all of them use a fixed step size "" - are you sure ?"
321539,what are you trying to estimate ?
321597,"you say "" none were better than chance "" . how are you measuring _better_ ?"
321613,were you checking each day / interval with some idea of ending the test early ?
321633,"it sounds like you're interested in similarity from a geometric perspective , but what would it mean to "" also take accuracy into account "" ?"
321635,can you describe what you mean by output features and an example of a problem you are solving ?
321561,can you provide a citation for the paper ?
321508,"what does "" $ y $ "" represent ?"
320895,could you update your question with the corresponding output ?
321720,related : [ how to know that your machine learning problem is hopeless ?
321762,"what do you mean by "" full bayesian inference "" ?"
321593,i see no evidence in the ` lm ` output for such alarming messages . where does ` gvlma ` come from ( it's not a standard part of ` r ` ) and how is it supposed to work ?
321841,"ok , i can assume you re familiar with autoencoders , then , right ?"
321844,"i agree with user86895's answer . by the way when you say real-time , what delay are you allowing for the decision ?"
321851,"i do think this is too broad . i'm not sure whether or not being cw should 'save' it from closure--i could go either way . how should we interpret the scope of "" machine learning "" here ?"
321859,what search did you run to answer question ( b ) ?
321913,what's your sample size ?
321887,"have you first tried a much simpler approach , e . g . , representing the input as a fixed number of features and applying ( penalized ) linear regression ?"
321927,could you clarify what you mean by $ ( 1 ) $ ?
321829,could you give some indications as to when this distribution occurs ?
321970,which notion of classifier performance are you trying to optimize ?
321972,"what kind of "" functionals "" are you referring to ?"
322023,"could you please elaborate on how "" $ g_i $ s add information "" ?"
322037,is there a bound on their sum ?
322110,"if you are aware of $ z $ is cauchy , can you determine the distribution of $ frac { 1 } { 1 z } $ by applying the transformation formula ?"
322114,where do you get this information ?
322126,how do you define the information of a prior $ pi ( p ) $ ?
322169,"this is a broad question . could you refine it , perhaps by disclosing the specific information you have about the relationship and the form in which you have it ?"
322183,"i assume they were trying to fit a model with a level-2 random intercept for each student , and they wanted to add a level-3 random intercept of some sort . when you say "" cluster by school feeder patterns "" , what's the nature of the random intercept ?"
322199,do you mean * residual * instead of * bias * ?
322153,"if i understand your question correctly , the package you link to does this as you can see url here . however it needs some data to get started , hence the two random points . could you clarify your question ?"
322224,you have mentioned k-means . how is k-means used to dimension reduction ?
321568,"what is "" ` cfu . g ` "" ?"
322280,"i assume that you've tried actual cross-validation , besides the pseudo-cv methods employed in smoothness selection in gams ?"
322292,"hint : can you find a matrix $ a $ such that $ am $ is a vector of $ k $ independent , standard normal random variables ?"
322315,what happens if the player loses at steps 2 or 3 ?
322306,"can you please explain a bit more about user id , is it akin to say roll number of a student in a class ?"
322175,"this isn't really a meaningful question , unless you include context about what you're trying to do . there are many different nlp features , but not all are useful for a given task . so what are you trying to do exactly ?"
310460,are you referring to mean squared error ( mse ) ?
322376,"let's say you have random variables $ a $ and $ b $ and you know variance of $ a $ , variance of $ b $ , and correlation between $ a $ and $ b $ . you want to compute correlation between $ a $ and $ a b $ . is that the correct description of your problem ?"
314979,"1 . for mgcv , your graphs are not consistent with the equation you wrote in . there is a ` s ( month ) ` term in the plots but not in the equation . 2 . is there a reason you are using negative binomial instead of poisson ?"
322420,use the median of the original dataset . how else would you apply your model in a sample of size 1 ?
322437,have you checked the documentation ?
322354,in what sense ` counterpart to the mann whitney u ` ?
322448,why not just subtract new york from the world and treat them as independent ?
322462,"try working it out conditional upon $ y = 0 $ . once you've figured that out , the rest should be easier . what values can $ x $ take when $ y = 0 $ ?"
322504,"i would choose "" none of the above . "" the stated "" correct "" answer is only an approximation ( albeit a pretty good one ) . how can i be so sure ?"
322517,how do you know an r-squared of about 0 . 2 isn't useful ?
322607,how many observations / responses do you have ?
322613,"neither term "" kamb "" or "" 1 % area "" is common in statistics . it's possible , by searching the peer-reviewed literature , to determine what a "" kamb contour "" is ( while , at the same time , establishing that many people who describe these haven't any clear or accurate idea of what they are ! ) , but it's harder to find an adequate definition of "" 1 % area contours . "" would you happen to be able to give us such a definition or a reference to one ?"
322663,have you missed some formatting ?
322679,how can you use either ?
322548,many questions are given here but few details on * * precisely * * what you're doing . but as far as i can gather you are winsorizing one ( or more ?
322793,is percent cover the response here ?
322816,so are you saying that your outcome is the total number of coronary events experienced by an individual ?
322806,why don't you fit the linear model and estimate those slopes along with their 95 % confidence intervals instead of conducting all these tests ?
322821,"those numbers need further explanation . could you edit this post to explain , for example , just what the value "" 0 . 8 "" refers to ?"
322837,could you explain what the values in the columns mean and how they relate to the information in the map ?
322847,"could you explain what you mean by "" nonsignificant , "" given that every p-value you report is "" 0 . 01 "" ?"
322843,why use a family ?
322065,based on your image does your data include 4 subjects with a total of 6 observations or is that just illustrative ?
319838,picklerick - give two demo pictures . don't make me half-baked invent your problem . i can show what i mean . how do you feel about python and opencv ?
322920,"you can t derive functional form of the underlying distribution from empirical distribution . empirical distribution approximates it , that s all . could you be more precise what do you mean ?"
322953,why do you have an arbitrary null hypothesis about the mean height ?
322960,clearly you have to use the poisson distribution . why didn't it work for you ?
322926,how about using var models ?
322974,have you considered a simulation approach ?
323000,it's not clear what the hypothesis is here . you describe your variables but not what specific question you're trying to answer in terms of those variables . what does it mean to compare things measured in different ways ?
322692,could you please write the two equations you are estimating out in math ?
322800,can you clarify your question by editing ?
322987,* where * did your duplicates come from ?
323069,"can you please state , and provide references / links as available , for the interpretations you've seen of kl-divergence which are based on an upper bound of 1 ?"
323092,yes . . . would that do the job for you ?
323112,do you mean generalized linear models ( glms ) or generalized additive models ( gams ) ?
323122,what can you tell me about the nature of your data ?
319911,as for the order of the predictors this may help : url regarding the difference of ` na . pass ` and ` na . omit ` look in the r help file : ` ?
323108,1 . please add the self-study tag for self-study or homework questions ; we'll typically guide you to an answer rather than simply posting one ourselves . 2 . what is $ z $ ?
323030,"1 for the thorough results you quote . when you look at the unscaled distributions of secom manufacturing data , are there orders of magnitude differences between features without scaling ?"
323179,"the title says p ( a , b1 , b2 , b3 ) the text says p ( a b1 , b2 , b3 ) . which one is it ?"
323248,"one problem leaps out immediately : you might have a hard time using any procedure that is based on expected loss . you could end up comparing a lot of values of $ - infty $ to each other . more pragmatically , since an infinite loss is unrealistic , why would one want to tackle the technical complications of allowing for it in the first place ?"
323257,general questions : do you know in what way the data should be changed by the correction factor ?
322733,"do you also know the value at that percentile , or do you just know that it's larger than the largest value in your sample ?"
323278,how do you calculate the importance of features ?
323288,are you familiar with completing the square ?
323294,"i think the random intercept could be fitted for id ( 1 id ) and any variables could be considered as variability of slopes ( random slope ) . in addition , ( item id ) and ( test id ) were considered as random slopes . i recommend this code : ` result = glmer ( score_group ~ factor ( sex ) age item test ( 1 item test id ) , data , family = "" binomial "" ) ` ( variable sex is a cateogorical variable , andthen you should use r function 'factor' . ) . your model depends on the strategy of analysis . which variables are considered as random or fixed effect and random intercept or random slope ?"
323308,"consider you have two fair six sided dice numbered 1 to 6 ( one red and one green ) . if you roll them the outcomes have the same distribution , but if the probability that they're equal is 1 / 6 . now imagine you rolled a 60 sided die of each colour . these results also have the same distribution but the probability they they're equal is only 1 / 60 . now imagine you have two independent continuous uniformly distributed values ( clearly they have the same distribution ) . now consider the distribution of their difference , d ( it's symmetric triangular ) . what's p ( d = 0 ) ?"
323388,what do you mean by uncertainty ?
323444,so this is an image labeling problem ?
323479,"sean , i am not sure i understand the meaning of the sentence "" days since last call causes a call . "" can you say a tad more ?"
323490,the standard recommendation is not to use random effect like ( 1 b ) when the grouping factor b has below 5 ( or even 10 ) levels . how many levels of b do you actually have ?
323445,what are you actually trying to test or find out from your data ?
323532,"please clarify what you mean by "" $ y $ "" in your question . if it's a ( scalar ) random variable , then how is it associated with the data that produced the estimate $ hat beta_1 $ ?"
323545,have you tried optimization ?
323410,what's the log mean ?
323589,"[ this answer ] ( url ) is closely related , but i am not sure if it adds much extra intuition to what you have already said yourself . depending on normalization , a positive loading might make perfect sense . so perhaps your understanding is fine , and it is actually your professor who might need to rethink this ?"
323591,"i am trying to understand * what * you are trying to calculate the variance of . for one day , you have a 48-long time series . there you could use the [ newey-west estimator ] ( url ) that takes into account that the series might be autocorrelated . but i cannot understand what happens beyond one day . do you need separate estimators for each day ?"
323595,what are you trying to do ?
323596,your data has a striking pattern . what question are you trying to address with your regression ?
323643,"item response theory was specifically developed for these kinds of problems . why not fit a rasch model to individual student performance , and then examining differential item functioning by group ?"
323686,"predicting stock market prices , in general , is extremely hard problem . unlikely to get you 70 % -80 % accuracy by tuning the network on such small data , no matter what you do . recheck the objective too . do you want to predict direction or exact value ?"
323696,"on the contrary , passing in a vector of start values * does * help--provided you use suitable ones . try ` start = c ( 1 , 0 , 0 , 0 ) ` . btw , why did you post all this code when your question focuses on ` glm ` ?"
323727,it is not clear how you want to define variable b ?
323759,it might depend on how you identified $ t $ : is this a sample independent of the other proteins ?
323752,why would that be the case ?
323766,"yes , can do that , but i would like to have the mean relative error because i need to compare it with some other results . do you know if it is possible to set in tf to re scale so i can get mre ?"
323776,normally when i see interaction models they would be of the form total . fruits ~ reg amd gen amd * gen . . . . is there a reason you didn't go this route ?
323755,"what is the problem , exactly ?"
323783,how can you fit to unseen data points if they are unseen ?
323840,"when running your code , i get this error ` fit - lm ( sepal . length ~ factor ( species ) : factor ( var ) -1 , data = iris ) error in unique . default ( x , nmax = nmax ) : unique ( ) applies only to vectors ` are you sure these results are not due to an issue with the model ?"
323911,a [ contingency table ] ( url ) ?
323782,any chance you could include an example image ?
323930,have considered using simulated annealing ?
324011,"could you explain more specifically what a "" sanity check "" is intended to reveal ?"
317453,i think your question would be improved if you could make clear * * * what question ( s ) are you trying to answer using these methods ?
324050,is there any reason why interval regression doesn't work here ?
324056,did you do any dna analysis to identify which scat belongs to which fox ?
324074,do you know how the propensity scores were generated originally ?
324113,why do you want to estimate with one observation ?
313685,are you training the map on both datasets ?
324117,can you give a [ mcve ] ( url ) ?
324158,"i understand what you are doing , but i don't understand your goal . do you want to generate 4 correlated bernulli or 1 binomial with 4 trials ?"
324161,"it would help to give an example . do you mean , for example , finding gold nuggets in space and time ?"
324162,"could you tell us what you intend "" country "" in equation ( 1 ) to mean ?"
324164,"i'm afraid i cannot understand what you're trying to ask . your question seems to say "" if i decide i have lognormal variables , . . . how can i know whether they are lognormally distributed ?"
323957,do you get the same output if you rerun the * same * model several times ?
324078,"an interesting first question ! but note that those links are going to change over time , and possibly go dead ( we have a serious problem with link-rot in our older questions unfortunately ) . to keep this self-contained and more relevant for future readers , do you think you could extract the key quotes ?"
324133,"what do you mean by "" assume $ x_i $ "" in the last sentence ?"
323797,have you considered survival analysis ( aka reliability analysis in engineering ) ?
320405,"in what way do you think , intend , plan or hope ( whatever your objective ) that the result of your above expectation / integration of the closest order statistic to $ alpha $ will be materially different than $ alpha $ itself ?"
51844,"judging from this quotation , the paper is written at a very abstract level and is intended for people who are ( a ) knowledgeable about statistical problems in the first place and ( b ) conversant with the theory of hilbert and banach spaces and functional analysis . it sounds like this does not match your background--your questions have to do with linear operators , not statistics--and so you would be better off reading a different introduction to statistics . might i suggest [ searching our site ] ( url ) for recommendations ?"
324315,you don't think proofs help with understanding the underlying ideas ?
324348,how are you fitting the mixture model . . is it em ?
324138,can you clarify that the first and second set of samples are independent based on separate sets of observations ?
324409,is ` var1 ` categorical ?
324457,"also , what is chf , and who are you referring to when you say * they * ?"
324475,the parent sets are the smaller sets from which a larger set is created ?
324474,do you mean that the probability of 'success' ( y = 1 ) decreases as the continuous variable moves away from 0 in both directions ( positive & negative ) ?
324497,for the 2015 data you know the outcome ( labeled ) . is the 2016 data labeled as well or do you want to predict instances in that data set ?
324512,"as a thought experiment , imagine $ x sim text { u } ( 0 , 1 ) $ , and you find out that $ x 0 . 5 $ . what do you suppose the conditional distribution of $ x : x in ( 0 , 0 . 5 ) $ is ?"
324517,can you get the aic for the ols model ( ` aic ( mod ) ` ) ?
324516,this seems like folklore . there are several papers that argue there is not too much difference between classifiers performance . can you explain how you believe feature engineering contradicts no free lunch ?
324686,are you sure you have correctly formulated the equations ?
324709,"i do not really get up your idea . however , are you looking for how many possible joint distribution function that can be constructed from those margins ?"
29580,maybe regularized regression is just not enough ?
324750,"you seem to be rather interested in anomaly detection then hypothesis testing , aren t you ?"
324595,please give more information on a . can one person have mot then one event a ?
324862,"what do you mean by "" $ x $ "" ?"
324888,is treatment a between-pair or within-pair factor ?
324915,is the current output necessarily a problem ?
324930,do you mean besides the [ nine methods offered in ` r ` ?
278881,consider working on the log-scale with differences ( differences of logs = logs of ratios ) . . . . i should check -- the controls are not the same creatures as the treated right ( i . e . this is not pre-treatment / post-treatment right ?
324964,you lost me at the outset : what would be the point of a code that expands 10-bit sequences into 12 . 1-bit sequences on average ?
323694,"well , they are all known to be more wrong than right , so why care about arguing against something that one does not expect to work ?"
325095,"when describing your power relationship , do you mean $ mu_i ^ 2 = text { var } ( y_i ) $ ?"
325124,"stackexchangehouseninja did you read jbowman's comments , especially the first one ?"
325156,why should regularizing the wrong model be useful ?
325109,is one mile performance your dependant variable y ?
325173,can you provide the reference for the statements ?
325184,it's probably spectral clustering with a kernel function as similarity . doesn't sound too different though . is it published on any major conference / journal or low quality ?
325060,"what do you mean by "" rational and non-arbitrary ?"
325194,"in the question near the end of your post , i assume you mean $ delta ^ d ( s_ { t-1 } , a_ { t-1 } , s_t ) $ ?"
324643,"you say nothing of how r relates to your mixture model . if they're independent the "" probabilities "" factor . ( note : $ lambda_i $ is not an event thus does not have a probability ) . also what is the event "" observing r "" ?"
36116,"can you give a more detailed reference to the book by including author ( s ) , publisher and year of publication ?"
325208,"1 . although you make it clear that this is homework / self-study , still best to add the self-study tag , just for clarity for people who look at tags . 2 . although your deduction is a good one , depending on the level of the class and what you've learned already you may not actually be being asked for a test . have you learned about bootstrapping yet ?"
325008,why would you expect any algorithm to converge at first iteration . . ?
325133,"at least to me , the question isn't clear . when you say , "" then the p-value for all scores are estimated "" , the p-value for what hypothesis ?"
324518,"this question is starting to look too open-ended . to see why , consider that the distribution that assigns probability $ 9 / 10 $ to $ 0 $ and probability $ 1 / 10 $ to $ 10 $ has a mean * exactly * $ 1 $ and * exactly * satisfies your constraint--but otherwise looks almost nothing like your plots . could you focus this question to include ( a ) what you really mean by "" long-tail "" or "" fat tail "" and ( b ) what additional criteria you are thinking of that would narrow the scope of possible answers to something reasonable ?"
325302,"please don't cross-post to ` r-sig-mixed-models r-project . org ` and here , unless you've waited for a while ( say a day or two ) for an answer without receiving a response - although thank you for including the link in your cross-posting . where would you rather have your answer ?"
325327,you didn't specify the key parameter - number of epochs . also did you try network with only one lstm layer ?
325333,is this a question about extracting statistics from ` r ` objects or is it about what model to choose ?
301290,how does this question arise ?
325326,i'm afraid i don't understand . what model is p_1 a parameter in ?
325393,"actually it looks like your points 1 and 2 are closely related since the point 2 is the reason why your error term may not be normally distrubuted : the assumption of exogeneity of your explanatory variables would not be respected if one of those is explained by the outcome variable . that being said , why not use $ wx_ { t * } $ as ( spatially and temporaly lagged ) predictor ?"
325444,your proposed steps for hlm model building doesn't fit with my intuition about them . what literature about this class of models have you read that suggests such a structure ?
325448,what is the fundamental output of the new test . is it truly all-or-nothing ?
325445,"the point is that the integrated fmm framework accounts for dependencies that can be lost using two different algorithms . * lg * is not free but at about $ 1k for a license , it's not expensive either . i think they have a free trial period and a reduced price for students . again , check out the papers referenced on their site ( url ) . another excellent book is frhwirth-schnatter's * finite mixture and markov switching models * . as a student , do you have access to your university's proprietary statistical software , e . g . , sas ?"
325461,is this in turn an assignment ?
297550,wikipedia on [ moment generating functions ] ( url ) gives a slightly more general result in an obvious place to look ( what were you searching for ?
325506,what about permutation testing ?
304471,how big is the validation and test set ?
117154,are you saying that the feature vector is sparse but there are clusters of non-zero elements ?
325510,"you haven't yet explained what "" resolved "" actually means . does it mean a failure is * impossible * ?"
325435,could you add the numeric results into the question ?
325545,what is the actual question you and your colleague are trying to answer ?
325616,is this question about calculating a $ p $ value for the coefficients returned by your model ?
325221,have you considered root mean squared error ( rmse ) ?
325687,how did you fit the parameters ?
325717,the two expressions of $ f $ describe exactly the same thing . why not graph them both to compare ?
325720,should that delta be a lambda ?
325775,"surely if you know the distribution / are willing to assume one , then estimating the distribution parameters e . g . by maximum likelihood and calculating the quantity of interest on that basis must be a serious option ?"
325332,please add some information regarding fixed effects and which question you plan to answer with this model . i could imagine scenarios where leg and muscle group would be fixed effects / random slopes and subject and time grouping variables of crossed random effects . time could also be a fixed effect / random slope ( maybe even use a mgcv gam ?
324473,"at the moment this question is a bit unclear . you have a "" gridded dataset "" of estimated se values of an effect . what are the variables that define the grid ?"
325799,did you check some of the other similar posts ?
325740,what do you mean by * identification granger causality * ?
325800,"what does "" $ mathcal n $ "" refer to ?"
325820,yes exactly . but what i don't understand is why you regression exports on gdp ?
325821,thanks . are you sure that the position of $ k $ and $ m $ is not the wrong way round ?
147619,do you have multiple time series ?
325864,0 . 08 is also between 0 . 05 and 0 . 15 . . . would $ a = 0 . 5 $ if the mean were 0 . 08 instead ?
325838,"thank you . could you clarify what you mean by "" true parameter distributions "" and "" small-medium distributions "" ?"
325884,"did you consider using embeddings for categories , like in [ this paper ] ( url ) ?"
323873,"i'm a bit surprised that you haven't found any treatments , because it is a fundamental concept in statistics that is covered in most sufficiently advanced math stat textbooks . have you tried starting with the wikipedia page ?"
325902,i see no contradiction . what do you take to be contradictory ?
325904,do you mean something like [ equating ] ( url ) . . ?
325912,how do you get p ( evidence not guilty ) = 1 / 5 ?
325822,you are welcome . when you visit that material--or any related material on random variables--i think you might get a great deal of insight by focusing on one issue : * how can we talk about the * joint * distribution of $ x_t $ and $ x_s $ ( for $ t ne s $ ) ?
325992,"have you directly observed x , y1 , y2 , and z ?"
326022,"may we presume that $ x $ and $ y $ are not really "" variables , "" as claimed , but are intended to be * sequences of random variables ?"
326096,what exactly do you mean by lambda * w ?
326124,"consider them literally as a double act . they act together . there is no sense in which one can be held constant without the other changing . in any case , why resort to a qualitative verbal summary when you can show the curve ?"
326077,are the cv folds exactly the same in each experiment ?
326012,what kind of difference are you asking for ?
326148,i presume you can you link the two datasets ie you know which employee works to which manager ?
326142,"could you explain how the "" likelihood of occurrence "" is estimated or computed ?"
326165,i don't understand your third paragraph . you have one of two conditions in 6 participants ( ?
326214,"if different metrics gave same results , there wouldn't be need to duplicate them , don't you think . . . ?"
326220,"the "" total probability theorem "" amounts to asserting that the limiting value of $ f ( x ) $ as $ x to infty $ is $ 1 $ . since this limit does not depend on $ c $ , how do you hope that will help you ?"
326069,what properties do you want the noise to have ?
326262,"how are we supposed to answer when we do not know , which role a season plays in your model ?"
326287,"could you elaborate on what you mean by "" impact "" or "" importance "" ?"
326307,"multilevel models are used for clustered data ; like students in a school , or teeth in a mouth . how would you generate a set of predictions for a newly adopted cluster ?"
276623,"how is "" state of the art "" defined here ?"
326325,"your question is unclear : please edit it to include an explanation of what "" appearing each of the x records in the sample "" means . does it mean * all * of the x records are in the sample or * at least one * is ?"
325240,can you clarify your notation for the likelihood expressions ?
326357,do you have labels assigned to the assay results so you know from which specimen they originate ?
324975,"for the second question , what do you actually want to do ?"
323433,"you're asking six questions which all seem reasonably technical or broad , so it's hard to answer . can you break this question up into a couple of smaller questions ?"
326406,have you read this ?
326404,"i , for one , do not know the rules of the bridge game . neither what honor cards are nor how many cards are used at all nor your notation of potential cases . maybe you could braoden the number of potentially answering people if you explained a bit about bridge . that being said : do your one 10 and two 10 cases overlap ?"
326438,what does the second column 'cover ( % ) ' mean ?
326427,"since in the glment paper , the goal is to fit the entire regularization path , possibly the idea is that the rescaling would just be a monotonic transformation of the path ?"
326470,how long is that vector you can't fit into memory ?
326473,how do you find the _ [ a ] mean decrease in accuracy for trees the top three predictors set have values of 30-50 % . in the isolated data set 9-15 % . _ ?
326065,does url answer your questions ?
326484,do you have a prior belief that there are some amounts and that they have some distribution between envelopes ?
326512,"you have constructed a model in which there are 22 effects . in what sense , then , do you intend us to interpret "" effect of each variable "" ?"
326306,what is mse ?
326595,why did some students take the test more often than others ?
326599,would you please post a link to the data ?
326351,"why can't you sample by just using the absolute value of $ a_i $ , and then negating your $ x sim f_i $ sample ?"
326630,"what are "" es "" and "" ma "" ?"
326640,"you'll need to write a little more about the dp model you're reviewing , as your notation is unclear . for example , what is $ a_i $ ?"
326643,your proposed architecture is definitely not the standard one . so the question 'why ?
326644,would you use lags of fitted or realized volatility as features ( just like in a var model ) ?
326320,"maybe i'm misunderstanding , but if you know the ( large ) vector of means and ( larger ) matrix of covariances , then a gaussian distribution is perfectly characterized . you mention higher order moments , however . are these data * not * gaussian ?"
326742,can you please format the text of the question somehow ?
326755,do you have a reference for that inequality ?
326823,"that said , i don't read python very well . can you highlight how you are setting ` eps ` & ` min_values ` in your ` debscan ( ) ` call ?"
326859,which part of the referenced thread are you following ?
326905,"the process by which you calculated the weights is not that clear , nor why you wanted to do that . can you edit your question to expand on that part ?"
326927,it would be helpful if you articulate the research question more clearly . . . are you trying to ask about the reliability of the assessments ?
326453,since this problem is hugely underdetermined--there are more ways to solve it than anybody could possibly describe comprehensively--could you edit this post to provide more information about why you need this and what you're trying ultimately to achieve ?
326816,what $ sum_ { i = 1 } ^ theta x_i $ stnd for ?
326963,"how do you want to treat "" three occurrences in a row "" . is that "" twice two "" , "" one "" , or "" none "" ?"
326989,"as a broad strategy , maybe estimate the seasonality first , add that as a ( more informative ) explanatory variable , then do your anomaly / change detection on each time series individually ?"
326970,how are you going to construct a second data set ?
327090,how did you find out that they are not changing ?
327105,ancova is a form of regression . the regression coefficient would give you the change in estimated reaction time for unit change in score . is that what you are looking for ?
327134,doesn't property have a cost regardless of who owns it ?
327145,have you already looked up multinomial and ordinal regression ?
327154,notations for a normal distribution vary . are 50 and 100 variances or standard deviations ?
327158,"since the * only * potential problem in working with the random variable $ ( x , y ) $ with a singular distribution concerns how it is represented mathematically , any failure to perform "" statistical work "" would merely represent a failure on the analyst's part to describe the situation in an effective way . it could not possibly preclude the use of any statistical procedures . what would an "" effective way "" mean ?"
327005,1 . how is the detector identifier created ?
327195,"you cannot prove this with the information given . are you also assuming the $ ( mathbf { x } _n ) $ are independent where $ mathbf { x } _n = ( x_ { n , 1 } , ldots , x_ { n , r } ) $ ?"
326160,"you say the $ p $ -values are proportions . so just to be clear , these $ p $ -values aren't the typical sort of $ p $ -value from a statistical test ?"
327233,"do you specify in advance which variable the row has to be on the high end and which at the low end , or are you just looking in general for rows that are high on one or more unspecified columns and low in one or more other unspecified columns ?"
327242,"` plm ` is not part of ` r ` : it's an add-on package . your best bet is to read the source code . if you would like to get comparable estimates , why not manually drop the same variables in ` r ` that stata has dropped ( or * vice versa * ) ?"
327245,"one percentile per hospital , or one per patient ?"
327191,"what do you mean "" you have complete data on 50 % of the population "" ( you mean sample not population ) . do you mean only 50 % were actually diagnosed with hypertension or . . . ?"
327221,"i would say this is equivalent to the following problem : "" suppose you flipped a coin $ n $ times and only ever observed heads on every flip . given this information , what is the probability that the next flip will be tails ?"
327340,"why not just decide that the corners are clusters a-priori , & automatically assign patterns to those categories ?"
327342,have you considered using a poisson model with [ a logarithmic offset ] ( url ) ?
326920,"this is not a multinomial distribution , which is discrete and on the integers . it most resembles a dirichlet distribution . i don't see how , if you have the measurements of $ x_1 $ etc . , there is a standard deviation involved ; if $ x_1 = 4 , x_2 = 6 , t = 15 $ , where is there any variability in $ x_1 $ ?"
327372,how do you know this fit can be improved ?
327406,"the formula , as you already note , would have to depend on the distribution : there is no universal formula , just as there isn't even a universal formula for the ci of a mean . would you like to provide some specific distributional assumptions ?"
327387,how many zeros and ones does your data set have ?
327464,have your read the [ wikipedia article on mape ] ( url ) 's list of disadvantages with the metric ?
327331,"re "" the interpretation is difficult : "" since in either case the variance of $ c $ easily can be less than either those of $ a $ or $ b $ , you would conclude that each of $ a $ and $ b $ "" explain "" more than 100 % of the variance of $ c $ . what could this possibly mean ?"
327496,i would like to respond but i really have no idea what are you asking about . could you rephrase the question to make it more clear ?
327514,so you want to compare a set of survey responses on two large independent samples ?
327548,"is there a reason you don't want to go the route of just modeling sd directly , as you do with the equation you present for sigma ?"
327552,"just for clarity : the problem is that you ( for concreteness ) have two coins ( a and b ) with different probabilities of generating a head , and you don't know how many flips come from each coin . your objective is to estimate the probability of generating a head from coin a ?"
327568,"firstly , you are asking for the sampling distribution of the mean of the ols estimator , correct ?"
327626,"welcome to the site . unfortunately , it is difficult to spot how and where to help you . your approach to data analysis is unveiling the internal contradictions of over-testing : it sounds like you have a large dataset . to the extent that big data increases the power of these "" assumption checking "" tests , the central limit theorem makes those assumptions irrelevant . but the bigger question is : if gaussian clustering is designed to differentiate groups by mean differences , what are you expecting to find that is of any interest by performing anova ?"
327532,"are trying to do model validation by plotting residuals and inspecting their shape / pattern , or do you want to have a final graphical representation of your model fit with confidence intervals etc . ?"
327655,it would help to have some more context here . what are the tests ?
327666,your question is rather unclear to people who don't already know what you're asking about . . . what is an or ?
327727,maybe check out bumphunting ?
327732,are you talking about fixing parameters of the logistic regression or the neural network ?
327719,what does the 2nd graph represent and how do you know to have faith in it ?
327729,what are the standard deviations for these groups ?
327755,see ` ?
327427,( 1 ) you haven't made any assumptions about the regressor . what if it takes on only two values ?
327687,"your calculations are erroneous because you are working with nine-digit numbers and have lost the fourth significant digit : the correct normalized value is 0 . 1038271 , not 0 . 1037 . what , then , is the problem ?"
327792,( 1 ) why would it not make sense to include all categories ?
327806,"please explain what you mean by "" apparent limits "" and "" true limits . "" of what quantity are they the "" rounded "" and "" non-rounded "" forms ?"
327820,are you asking what will be likelihood function in case of k-means cluster analysis ?
327835,how long is the period from $ t $ to $ t ^ * t $ ?
327843,what are the ivs and dvs of your model ?
327750,". . . therefore , i think that the p-values are based on different null hypotheses and hence not comparable ( although they might be close ) . see also ` ?"
327892,"your notation is vague : could you explain what a set of "" birth results "" might refer to in your definitions of $ a , b , c $ ?"
327940,"based on the information you have supplied , a ouija board would do fine . to improve on that , consider analyzing relevant data . do you have any ?"
326562,are you implicitly trying to tell us the columns of $ w $ are independent ?
327288,"your description is overly vague : the details matter . in particular , ( 1 ) do you know the sizes of $ a $ and $ b $ ?"
328041,how is abundance measured ?
328059,"if the standard deviation of the data is 170 , the standard error of the mean is $ 170 / sqrt { 500 } = 7 . 6 $ , which would lead to a t-statistic p-value of somewhere around machine precision ; $ 2 . 9e-32 $ wouldn't be far off . did you leave out that $ sqrt { 500 } $ term by any chance ?"
328061,"let us assume you have these predictors from prior research . if that is the case , and you testing it on new data , are you looking for model selection using a frequentist methodology such as aic or bic , or are you seeking to use your data to update the quality of the predictors and do model selection afterward , in which case you would need to do a bayesian method ?"
328152,have you learned anything about this topic through the usual searches ?
328167,"honestly , who gave you the advice , to use a number of univariate analyses for multivariate data ?"
327899,""" i should mention that the predictor in question is extremely positively skewed and discrete . "" please provide more details . is this an ordinal variable ?"
328189,why do you feel you need to test for normality ?
328194,"can you say more about what the "" x "" and "" y "" axes are for these lines ?"
328205,what is on your other axis ?
328249,how limiting the information available for your model ( throwing away data ) could make it more powerful ?
328275,also : what do you mean by some patients had already exceeded . . . ?
328276,i don't understand why you include ` state ` and ` site ` as fixed effects . wouldn't a nested random effect be more appropriate ?
328332,can you summarise what your question is please ?
328329,what does this have to do with belief propagation ?
328369,can you specify the pdf with the range of values that $ x $ can take ?
328403,"why would you want aic on test data , where the penalty loses its meaning ?"
328453,how are the knockout columns paired to the wild type columns ?
328485,is it possible model your problem as a binary classification problem instead ?
328577,exactly what form does this truncation take ?
328616,adding a variable w on the pathway doesn't sound like moderation to me . perhaps post your code ?
328785,are you sure you mean linear regression when you refer to euclidean distance ?
328797,"try to ask the same question for linear regression : do we gain anything by using the model $ y_i = alpha beta x_i epsilon_i $ , rather than simply model $ x_i $ and $ y_i $ separately ?"
328795,maybe it is obvious but . . . what does oa stand for ?
328630,"you're kidding , right ?"
328826,have you looked into strategies for cross validation ?
328851,why do you want to force $ x_t x_ { t-1 } $ ?
328855,how many cycles you have in your training sample ?
328859,"if you have two algorithms for estimating the parameters , and both are guaranteed to converge , and your problem is convex ( i . e . , has only one minimum ) , they should both give the same answer , give or take a tiny amount due to stopping criteria , roundoff errors , etc . why do you think you might get very different results ?"
328854,"is this "" before and after "" data ?"
328875,"yes , such models have been formulated . what are you willing to assume about $ x $ ?"
328891,"does this variable measure all violence ( as reported to the authorities , say ) or does it estimate it from data ?"
328952,"when you say you can sample from the marginal posteriors , does it mean you can _only_ do that ?"
328940,"i do not understand , pdf and cdf are two faces of the same coin , i . e . , they both characterise the probability distribution . or are you worried about the histogram being a poor estimate of the density , when compared with the empirical cdf as an estimator of the cdf ?"
328974,"a "" 2-dimensional space "" * a fortiori * has two dimensions . evidently then the $ d_i $ refer to "" dimension "" in a different sense . are you trying to say you have samples located within some rectangle of size $ d_1 times d_2 $ ?"
329038,"you appear to contradict yourself : if indeed the metric is "" lower than a threshold for a sustained period of time , "" then there can be no such thing as a "" false positive "" : it either was lower or it wasn't . could you be more precise about the purpose of this "" alarm system "" ?"
329025,"what , then , is your understanding of a standard error of the mean ?"
329069,"how reproducible is the 50 % increase in "" mean performance "" for a or the 10 % increase in "" mean performance "" for b ?"
329080,why not use gradient boosting ?
329062,""" grid search validation to nearest centroid "" is not clear to me , are you talking about using cross validation to find the optimal $ k $ for k neighbors ?"
329114,"your dataset size seems okay for such a small network . are you sure there is no problem with your data , i . e . some of the features is very highly correlated with the output ?"
329089,"have you considered using more then one cluster to model , but only keeping the largest ?"
329208,"could you elaborate on what you mean by "" include these two variables as they are "" ?"
329214,"is the length of the route important , or might they all be approximately the same length ?"
329217,how did you determine that the comparison was unnecessary ?
329259,can you elaborate on this any ?
329285,have you tried searching the site for [ interpreting poisson ] ( url ) ?
329236,what is the function $ psi $ in your first displayed equation ?
329046,you need to come up with a similarity measure here . in case of facial recognition it's relatively easy if not laborious : anyone can be asked to tag the same people on pictures . in case of proteins how are you going to judge the quality of the algorithm ?
329329,why do you think this will be interesting or useful ?
329382,instead of $ p ( x y ) = p ( y x ) p ( x ) $ did you intended to write $ p ( x y ) propto p ( y x ) p ( x ) $ ?
137902,"what is "" churn "" ?"
329410,you say you had to scale your predictors . why was that ?
327774,why are there double logs ?
329490,what's your statistical background ?
329517,could you explain what the second formula is trying to say ?
329551,"this is pretty messy , if you could clean up the mathjax that would help a lot . furthermore , what is $ w $ ?"
329560,"please explain what you mean by a "" trend "" and an "" overall "" trend . would these be slopes ( or rates ) ?"
329568,what do the variables ` pp ` and ` pp_pos ` represent ?
329573,"while this is not a forum for debugging code , could you perhaps share the r-code to make it clear what you are doing , and what results you are seeing ?"
264698,why not try cross-validation ?
329635,"what do you mean by "" changing the units of parameters "" ?"
329641,"why not call the "" a "" x and the "" b "" and "" c "" y and just proceed ?"
328417,it is very important to know the reason why two samples from the same location can have such different values . is it the inaccuracy of the testing method or the sampling variance ?
329683,i don't see why any symbolic software such as mathematica wouldn't work ?
329691,what are the other covariances--the ones you haven't specified ?
133361,could you tell us something about the practical context where this arises ?
329713,are you familiar at all with the time reversible equations ?
329559,"lastly , i think most ( all ?"
329366,"the model you are describing seems to be missing an 'm' . including random effects requires a generalized linear mixed model ( glmm ) . you could use the function ` glmer ( y ~ x ( 1 tank ) ` in the package ` lme4 ` to model a random effect for tank . that being said , how and why did you rescale the counts ?"
329665,could you provide a link to the paper your mention ?
329793,what exactly doesn't make sense . . ?
329832,why do you think that $ r ^ 2 $ can be used to decide whether imputation model is reasonable or not ?
329405,"yes , probably . which package are you using ?"
329482,"can you tell us more about this "" average abundance "" ?"
321981,1 . is this for some subject ?
329796,teodorageorgieva you should specify much better what you are actually doing . this error can occur due to many different steps and depending on the situation you could try different strategies . did you search for other examples on problems with glmnet and memory ?
260468,""" these cis "" is a bit vague . can you provide some context ?"
275526,bias in what sense ?
329976,"what exactly are you asking to "" recompute "" ?"
329992,do you never hope to acquire new customers ?
329663,what's the dimension of $ theta $ ?
329963,why do you want to code it by hand rather then using software like jags or stan ?
330036,"first , why do you want to carry the state ?"
325306,is there maybe a reference where you have read this ?
330064,""" brick "" ?"
330076,"for starters , could you explain what it might mean for a "" dataset "" to be "" non-linear in . . . [ a ] variable "" ?"
330089,"we can't have any idea what test to apply without knowing what your study objectives are . also , unless you have very large counts , a normal distribution is an unlikely model for them , so what's the point of testing for normality ?"
330161,why would you expect that the coordinates and distances would be normally distributed ?
330213,"also , what sort of trends does this package monitor for you ?"
330245,do you want to know the percentiles for the predicted value $ hat { y } $ or for the coefficient itself $ beta $ ?
330209,"it's not even clear that the question is well formulated . i can imagine english words , like "" fardel "" or "" yclept , "" that would not be identified as english by a large majority of native english speakers--or possibly by * all * english speakers within a particular community . the lone person out of a million who does identify such a word as english might be the sole knowledgeable scholar in the group . how does that make her a "" cheater "" ?"
330270,does url or url nswer your question ?
330291,"just to be clear , your model is synonymous with $ y = beta_ { 0 } beta_ { t } t beta_ { x } x beta_ { tx } tx varepsilon $ , yes ?"
330286,what have you tried so far ?
330345,what is elementary and what is advanced ?
330350,exposure is not clear . may define . whar is confounding here ?
330364,"it was a comment , not an answer ! but you haven't addressed any of my points ( e . g . about negative means ) . how does the question arise ?"
330376,how is the progress ?
330346,are you looking for an explanation what a levy flight is ?
329204,"can you define how you are using "" objectively justified ?"
330463,"yes , you basic understanding is correct , but maybe you should not be picking the random-effects structure to begin with ?"
330488,"as you've described it the variance of the samples is $ sigma ^ 2 sigma_ epsilon ^ 2 $ . so if you know $ sigma_ epsilon ^ 2 $ , you can subtract that from the variance of the samples . ( estimating the precision of that estimate of $ sigma ^ 2 $ is another matter . ) if you don't know $ sigma_ epsilon ^ 2 $ , then you can only estimate the sum of the two variances . one way that allows you to get separate estimates is to take 2 or more estimates / measurements for each sample . then you can use a mixed model to get the separate estimates . if you know $ sigma_ epsilon ^ 2 $ , why not consider a bootstrap approach ?"
330498,is their dataset public ?
330596,"just to be clear - in your sample , each row is a case , the ` ` ` tx ` ` ` column indicates assignment to treatment and the ` ` ` prenbr ` ` ` and ` ` ` postnbr ` ` ` are the sums of occurences of the outcome pre and post treatment respectively . in the full data set , each row expands to 48 observations where the outcome is 0 or 1 for each . is that correct ?"
318380,"in what sense is "" accuracy "" implied here ?"
330621,are you asking about a statistical question ( how to cluster them ) or a programming one ( how to move them ) ?
330626,where do the dependent variables come from ?
330610,could you give more details on what your discrete variables look like ?
330660,"if your loss is defined per observation ( e . q . squared error for a particular observation ) , then average loss will be the same either way . i wonder then in which situations is loss not defined per observation but rather is a function of a whole chunk of observations at once . perhaps median error per chunk ?"
330616,"what do you mean , then , by your request "" to see how much do they actually vary "" ?"
330680,"for a given day , you have a dichotomous variable being number of occurrences vs number of non-occurrences . what is the other variable ?"
330700,isn't $ a $ independent of $ c $ and therefore $ p ( a ) = p ( a c ) $ ?
330710,"what meaning is this "" weight "" intended to have in the model ?"
330760,do you have values that are zero in the dataset ?
330199,what exactly do you mean by drift ?
330811,if you add one to log ( x1 ) what does that correspond to for x1 ?
330823,"so if i flip the signs of pc 1 score because signs do not matter , do the interpretation also change . in the explanation given by other question answers , it just tells you that signs can be flipped if you flip the loadings too . but does it mean that the intterpretations change too ?"
330833,"regarding unbiasedness , does the concept refer to a sample size ?"
330834,the original gans are notoriously unstable to train . have you tried instead doing e . g . a wgan-gp ?
330669,"if the sum of the probabilities is often greater than 1 , then you aren't measuring the probabilities of each team winning very accurately , are you ?"
330871,"are you sure the third formula doesn't actually have terms of the form "" $ pm t_ { alpha / 2 } , frac { s } { sqrt { n } } $ "" ?"
330589,did you manage to control for the manufacturing main effect in the interaction model ?
330889,could you give us more details ?
330894,"wat exactly is the problem with "" contamination "" ?"
330924,"it depends on what you mean by "" basic linear model "" at the end . are you referring to a * least squares fit * of the model to the data ?"
330925,i see only * one * simulation . what happens when you repeat for new independent values of ` x ` ?
330976,"moreover , the splits are sequential , where subsets are further splited in subsequent iterations . also "" value according to subset "" does not sound nice . the value is some statistic of the subset - the mean ( always ?"
330865,what's wrong with the book that the instructor assigned ?
330997,"if there is any , what's the distribution you assumed when running regression ?"
331007,does the order within the bucket matter ?
331022,your question does not seem to tell us why you want to reduce the number of variables . if you goal is prediction would it not be better to include as much information as possible ?
331052,"what does it mean to "" rip "" a country ?"
331090,you mean if agent 1 chooses option 3 that no other agent may choose option 3 ?
331104,( 3 . 4 . 9 ) contains $ tilde mu $ while ( 3 . 4 . 10 ) contains $ tilde mu ^ * $ . aren't they different ?
331107,"the verbal description following "" normally "" does not appear to match the formula for the mle . could you therefore explain what "" $ n $ "" and the "" $ x_i $ "" in the formula mean and how they correspond to your description ?"
331124,what is the function $ f_ * $ here ?
331154,is it possible to include a histogram or a qq-plot to the question ?
331048,what are these data ?
329287,"question says "" in econometrics "" . clearly your examples are economic , but in what sense are you imagining or implying that the stipulation "" in econometrics "" might affect possible answers ?"
331179,"well , deep learning is still machine learning , just sounds "" cooler "" nowadays . can you be more specific what are you actually asking for ?"
331295,"do you care about things like "" performance at time 1 "" vs "" performance at time 2 "" ?"
330273,"think about whether the fact that the data is missing is significant or independent from the true ( unreported ) value of $ x $ . the fact that the data is missing might be an informative feature . also : is the distribution of $ y $ over those vectors with missing $ x $ equal to the distribution of $ y $ over vectors with other values of $ x $ , or over all vectors with non-missing values of $ x $ ?"
331310,"please explain what you men by the "" derivative . "" evidently you don't mean the usual calculus sense , but what could it be ?"
331338,"at the outset , are you interested only in comparisons to treatment 4 ?"
331399,"welcome to our site ! your last plot is confusing because it suggests you are clustering on the y-coordinate , whereas the question concerns clustering on the x-coordinate . have you considered representing your data in more than one dimension at a time ?"
326350,perhaps the random starting value is a poor one . why not select a better one ?
330877,"if $ p ( x y ) = p ( x ) $ , then $ h ( x y ) = h ( x ) $ , no ?"
331423,could you expand a little on what $ t $ represents ?
331491,wondering about your notation $ x mid d' $ . . . are you trying to sample from a 'truncated' version of the distribution of $ x $ ( where the density at all points outside $ d' $ is forced to zero ) ?
331497,"since the item was sold on day $ n $ , can we just assume the fair price is $ p = p_n $ ?"
331414,"maybe a scatterplot of the two continuous variables , and the categorical variable to encode color ?"
331543,if you have a theory which leads to five factors then why would you want to do a preliminary efa ?
331482,"as a first cut at the problem , how about using the intersection point for the two dotted lines on your graph ?"
331559,"what do you mean by "" lm ( x ) "" ?"
331591,"your axes are labeled x and y , but you say x and y are the data points and centroids . what do the plots represent ; is it energy vs . k ?"
331610,are your actions still discrete and entirely different at the scale you are interested in ?
331636,from the quoted excerpt i take away that for binary outcomes you can compute the treatment effect estimates from sample proportions . for dose response you clearly wouldn't look at proportions . where do you take the att vs ate argument from ?
331580,if these are proportions then they will both be skewed . i am not clear what you mean by your imputation not what your scientific question is . can you edit to clarify further ?
331671,"to clarify , by "" a , b "" do you mean that state could be a or b , you can't tell which , or do you mean you actually have examples where it was a and examples where it was b ?"
331408,"if you can determine a distance measure that is appropriate for your data , you can use any clustering method that can operate over a distance matrix instead of the raw data . you need to think about the issue of sparsity ( what would it mean to have clusters in sparse data , what would you want to detect ?"
331728,jbowman this is exactly what i did . i copied it from the meta answer to [ how best to use the review queue ?
331748,""" i need to control for day of the month "" why ?"
331804,"suppose you have 4 numbers : $ x_i in ( 1 , 2 , 8 , 9 ) $ . your distance is the $ d ( i , j ) = x_i-x_j $ . how do you want your two anti-clusters look ?"
331810,"is it possible to apply robust , sandwich based standard errors to the gls model ?"
331799,you gave almost no background data . is shopping $ the outcome ?
156660,you have your simulated training set of 12 observations . why not just use 12-fold cross validation ?
331936,"achim zeileis thank you for the response . that makes sense . just to clarify , if i use the "" total count "" as my response variable and i use an offset ( like you suggested ) , is there anything special i have to do to interpret my models ?"
331943,why not just bootstrap confidence intervals and see if that of the random effect's variance includes zero ( non-significant ) or not ( significant ) ?
331978,is there a reason that 'regression coefficient' is insufficient for your purposes ?
331992,"how many predictors are you trying to select among , and how many of the patients had events versus having been censored ?"
332017,"by "" $ sigma_ { a , b } $ "" * etc * do you mean covariances between random variables ?"
332018,"you refer explicitly to a "" multivariate uniform distribution . "" a uniform distribution is * defined * by its support . for instance , there's little you could say about the univariate uniform distribution i presently have in mind . does it assign any probability to positive numbers ?"
332039,what do you mean by $ x_i $ in the equation ?
183277,"please give more information , e . g . , how do you know the two effects are power relationships ?"
332077,can you provide a reproducible example ?
331930,is this a question from a course or textbook ?
332081,"the standardized ( unobserved ) innovations are normal , but the nonstandardized ( observed ) innovations are leptokurtic . does that help ?"
307946,"what do you mean by "" results are not so good "" ?"
332096,what exactly are you stuck on ?
332128,would you please post a link to the data ?
332026,""" in the bayesian view , . . . the data is fixed "" surprised me . i believe bayesians adopt the nearly universal statistical viewpoint that data are analyzed using a probability model for them . therefore their models consist of * joint distributions * of parameters and data . to the extent your questions are predicated on this ( mis ?"
332093,the chi-square test of independence would not give same results for the two tables . why should the fisher test ?
332010,1 for the question . can it be assumed that you have relatively low number of possible events and rather big dataset ?
332192,what about [ this ] ( url ) ?
332201,from the equation you wrote down it does not look that the distribution of $ z_n $ would vary with time . doesn't that answer the question ?
332221,do you wish to detect outlier datapoints or outlier time-series ?
332113,"are you asking about the product of * distributions * or of * random variables * or of something else , such as a cartesian product ?"
332237,i think we need more details here . do you mean to test each of the proportions against a theoretical value ( 0 . 5 ) or do you mean to see if they differ ?
332267,what fixed linear model do you have in mind and why do you think you need it ?
332303,i don't think the $ lambda / 2x $ term is ancillary . is it ?
332023,"whuber isn t the domain of $ x $ different , though ?"
332336,"the most common problem with "" sklearn logistic regression vs something "" is in regularization . are you sure that in esl they also use quadratic penalty with c = 1 ?"
332178,what activation function are you using on your output layer ?
332375,why should they agree ?
332383,can you specify what you mean by ` n ` ?
332370,what is the sample size here ?
332384,"i read your post a few times and for me the most unclear part is about this introduction of "" unpredictability "" . for example the probability in roulette that a ball will land on 0 is a long-run frequency of it landing on 0 . how can it be subjective in this framework ?"
332392,i cannot reproduce your problem ( using r 3 . 4 . 3 and ` forecast ` 8 . 2 ; what versions are you using ?
332415,welcome to cross validated . do you know how to type equation in latex ?
332433,why do you care ?
332473,"what are "" null "" data points ?"
332333,"have you tried sarima ( 1 , 0 , 0 ) x ( 1 , 0 , 0 ) ?"
325334,can you add your data as described here : url ?
332574,could you be more specific about your question ?
332600,"do you mean given an unfair coin 98 % to 2 % chance of heads to tails and that you flip it 100 times in a row , there will be a run of exactly 17 consecutive heads but a run of 18 , 19 , etc . would not count ?"
332627,can you provide more detail about your data ?
332448,"i don't follow . "" these data "" include your assertion that you downloaded 40 episodes . presumably you downloaded distinct ones . how does this differ from k , then ?"
331505,"isn't it simply ` glmer ( choice ~ 1 ( 1 subject ) , family = binomial ) ` ?"
332630,"with 95 examples and 15 features each , there is perhaps a chance to build a classifier . have you tried a linear classifier as your baseline ?"
332645,you seem to have too few data points to be testing for normality . maybe use some robust method ?
332648,why would you use a model that you don't understand ?
332653,how do you know the sample isn't random ?
332562,"do you provide a * definition * of "" mean-preserving spread "" or do you just quote one of its properties ?"
332685,did you look at the pacf plot stratified by ` trial ` ?
332698,let's tumble that multimodal distribution and view it as an optimisation problem where we want to find the global minimum of function with multiple local minima . what would be the solution there ?
331972,"please elaborate on the meaning you attach to "" strong "" in your question . if this is intended as a synonym for "" statistically significant , "" then what do you view as a population or process and what do you view as a sample ?"
332736,"i'm not sure if you have enough information to get to the resolution you are looking for , at least no without more prior knowledge . for example , would it be reasonable to assume that in the cases you have complete information this is in proportional to the durability of a part across different car models ?"
332745,"i gather you are referring to 'table 1' . are you asking about rcts per se , or also observational studies ?"
332766,"your network can fit a nonlinear function because the output of each unit ( or at least the hidden units ) is a nonlinear function of its input . unfortunately , it's impossible to say more than this unless you tell us the details of your network ( and at that point , the answer to your question would be self evident ) . have you tried looking at the documentation for the package you're using ?"
332770,why are you fitting the model ?
332710,what are proportions of the classes ?
332788,i assume x is an observed value of the random variable x . to be unbiased the estimator $ mu $ ( hat ) must have expected value equal to 5 $ mu $ / 9 . so see if ( 4e ( x ) / 7 ) -1 equals 5 $ mu $ / 9 . does it appear to be biased ?
332820,"the others also are p-values , as indicated by the heading over the rightmost column . what , then , remains to be clarified ?"
332780,"are you sure * interference level * is categorical , and not ordinal ?"
332768,do you have to use linear regression ?
332828,"it's not clear to me why you would try to "" verify "" it in the first place . do you think you may have mis-derived it ?"
332854,what do you want the output to look like ?
332879,heh ?
332905,why do you think that the answer should be close to 0 . 5 ?
332969,prices are discrete in principle but approximately continuous in practice unless the step between possible prices is large enough to bite . sale success is on the face of it entirely binary : there was or was not a sale . otherwise i am not clear what you're asking . why is 18 . 95 more random than 9 . 99 ?
332962,"what are "" breaks in data "" ?"
332948,how did you decide on alpha = 0 . 1 ?
332967,"the confidence interval for $ y ( x ) $ is a function of the sample . as such , it "" includes variation in "" every conceivable statistic computed from the sample . in light of this could you clarify your question ?"
332632,what method do you use to compare your results to a geometric distribution ?
332995,"in your currently last paragraph i notice a discrepancy between two different way to look at it . 1 ) if you have a pdf f ( x ) , defined by 8 parameters ( the 3x2 parameters for the gaussian distributions and 2 for the mixing ratios ) then 8 points from f ( x ) will suffice to define the entire f ( x ) . 2 ) in your question you seem to focus more on samples . but how do you 'choose' the ( random ) sample ?"
332713,""" has a certain property "" is a bit blurry , everything in the world has some property . convergence in probability is $ lim_ { n to infty } pr big ( x_n-x varepsilon big ) = 0 $ , could you please tell us what exactly are you referring to in the definition ?"
332747,what are you trying to accomplish here ?
333036,"batching will not work if batches are not homegenous , e . g . you take one batch men , another batch women and the output is gender sensitive . what are you trying to accomplish ?"
333052,could you explain why you need to perform this procrustean feat of shoehorning a five-point response into a four-point scale ?
333081,what do the rows of your matrix correspond to ?
333087,why does a small sample size justify the bootstrap ?
333080,"if it's not to be randomly generated , there are a huge number of possible ( and simple ) solutions , which makes your problem undeterdetermined . indeed , almost surely a matrix with independent random normal values will satisfy your criteria , so what not generate it once and for all and store it ?"
245681,""" multivariate "" means multiple response variables while "" multivariable "" indicates multiple predictors . do you have multiple groups which people are members of ?"
332838,"what is "" score "" , which metric do you measure ?"
332805,how do you * * know * * that $ e [ ( x-e [ x ] ) ^ 2 ] $ _does not equal_ $ e [ ( x-e [ x ] ) ( x e [ x ] ) ] $ ?
333183,the tiny p values and your degenerate boxplots suggests that you have a huge amount of data - so much that * any * departure from equality will be statistically significant . how much data do you have ?
333196,"may i ask , why are you asking this ?"
333190,wouldn't it be better to use data to figure out what a good planting index is ?
333199,oops ! sorry then ! how did you do the grid-search if not while using an 10-fold cv then ?
333256,have you figured out whether the reported likelihood is actually the negative of the actual likelihood or not ?
333280,"just to clarify , you re looking for a confidence interval for $ p $ based on a _single sample_ ?"
333283,are you saying that you are trying to detect a trend in inventory as the time stamp increases ?
333205,"1 . is "" experiment id "" actually a "" disc id "" ?"
333180,what was the nature of your error in the preprocessing ?
333383,does the order of selected_genes play a role ?
333421,"by "" probability theory "" do you intend to include alternative theories of probability , such as bayesian ( and dempster-shafer and the transferable belief model and dezert-smarandache theory ) , imprecise probabilities , plausibility theory , etc . ?"
333412,i don't understand it as well . in a one-sided t-test $ h_0 $ could be that some parameter ist less or equal $ 0 $ . maybe some context might help . maybe we are in a situation where we only want to do two . sided testing ?
333427,adjust the x-axis ?
332517,is defining an estimator as the max of bayes estimators still a bayes estimator ?
333470,since the random variables are independent can we just multiply p ( x1 = x2 ) times p ( x1 = x3 ) ?
333533,"would it be fair to say you have something of the form $ y = x beta varepsilon $ where $ varepsilon sim mathcal n ( 0 , omega ) $ with $ omega $ known but not diagonal ?"
333562,"pc1 and pc2 are orthogonal within the combined data set , by construction . however , within separate datasets , they are correlated . what does this mean to you ?"
333558,can you clarify if you have repeated observations on the same individuals over time ( panel data ) or just a time series data without timestamps ?
333568,is it necessary to use two different notations for derivatives ?
322321,this is a conditional distribution . actuarial exams ?
312988,actuarial exams ?
333603,"is the goal is to predict only product # 6 , based on data from all products ?"
333639,could you please include a full citation for the paper ?
333721,is it that you want to cluster points but add the restriction that points of the same group must fall in the same cluster ?
333588,"there are some differences of opinion about how to interpret your question . i , for one , am not sure about the rules of the game because i don't know what is being "" ordered "" at the outset . what exactly is the "" result of the throw "" : all nine values , sums of three values , subsets of three values ?"
333734,"hint : add another row to your table giving the values of $ log ( 2x 3 ) = log ( 5 ) , log ( 9 ) , log ( 13 ) . $ what do you mean by "" portability "" in the title ?"
333593,"after the update : i am not sure this is answerable without a reproducible example . as you say , this should always be positive definite . btw , what exactly do you mean by "" not always positive definite "" ?"
333599,that's trivial when you look at it the right way : what happens to the optimal value of the objective function ( sum of squares of residuals ) when you impose constraints on the possible solutions ?
333842,"what does "" eqaul group sas mine "" mean ?"
333694,will a recursive formula do ?
333806,"thank you for providing reproducible code . could you please edit your question by changing ` lm . 1a ` etc . to ` model . 1 ` etc , so we can match the example to your question ?"
333804,can you write out the likelihood function for the observed data ?
333931,are you doing pca with or without centering ?
333932,fwiw for multiple independent variables you'd have to have $ beta_1 $ be a vector as well ( transposed / oriented so that $ beta_1 x_ { ist } $ is a dot product ) . afaict eq . ( 2 ) and ` model 3 ` are indeed the same . is that your entire question . . . ?
334007,my guess is that the two libraries are finding slightly different optima that are effectively the same . what happens if you plot the coefficients against one another ?
331995,"you say that you have a certain "" purpose "" . what is it ?"
335096,"just to be clear by precision you refer to the ratio : $ frac { tp } { tp fp } $ , correct ?"
335116,in the first model was b4 statistically significant ?
335143,what question are you trying to answer ?
335164,why do you want to estimate a mean and standard deviation ?
335204,what about it confuses you ?
335233,"how can you hope to "" test "" the model in any meaningful way when you don't yet have the outcomes ?"
335254,to clarify when you say implement do you mean in terms of the model formulation or how to actually code it up and implement it in software ( or both ) ?
335277,what kind of outcome variable do you have ?
335310,why are you using these specific priors ?
335344,that does look very puzzling . what meteorology is it that implies that raw autocorrelations are negative at lag 1 hour and strongly negative at lag 24 hours ( but negligible at 48 ( 24 ) whatever hours ) ?
335360,heard about stan ?
335399,"detecting elements like dates or weight in your example seem more like a problem to be tackled with regular expressions rather than statistical methods . while your 'location' category could be matched against a dictionairy of locations , i find your definition of 'name' somewhat vague . can you elaborate a bit more on that ?"
335417,what's your question ?
335451,are you missing another summand expression in the denominator for the ssxx term ?
335464,"it may just be that i have not yet caffeinated this morning , but if p ( odd ) = 1 / 9 , and p ( even ) = 2 / 9 , what do the other 6 / 9ths of the sample space represent ?"
333139,are the hours at $ t_1 - t_6 $ randomized per subject ?
333556,what we really want is p [ die is unbiased observed rolls ] . doesn't the hypothesis testing as you describe give us p [ observed rolls die is unbiased ] ?
335569,"both are possible , but they are obviously different models . whether you should include the interaction in the random effect depends on your specific problem and your specific data ( is there sufficient data to justify and estimate an additional parameter ?"
335393,"do your objective functions typically return "" reasonable "" values for $ x $ outside of $ [ a , b ] $ , in which case the constraints are ones of plausibility or known physical relationships , or is there a computational failure that occurs ?"
87061,"just curious , why did you choose undirected graph model ?"
335596,does $ lambda_2 $ have a prior on it ?
335624,can you cite or link to the article where you read this ?
335662,is this really a graph or a tree ?
335719,i am a little confused . is this 128 consecutive weeks of data or is it 64 weeks of data for 2 different segs ?
335723,could you please clarify your last paragraph ?
335747,can you make clear what you mean with the symbol $ x $ after $ iid $ ?
335595,is this for self-study ?
335831,request for clarification : are you estimating the reliability from the model ?
335809,it ought to depend on the type of document and document length . why not examine a sample of the documents you intend to process ?
335836,accuracy isn't a measure that can be directly applied to regression problems . what do you mean when you say your accuracy is 30 % ?
335840,spell out rose / smote ?
335561,would you say y equals infinity if x = 0 ?
335908,is $ u $ a noise variable ?
335923,why should the interpretation depend on the procedure you used to fit the model ?
335921,could you at least post some details about what your cnn model is and what it was trained on ?
335938,"two clarification questions : first , do you wish to explore one single model for the two cell types ?"
335936,"two objections come immediately to mind . first , when you select the seed based on the results , the simulation no longer is random . the approach appears to be self-defeating . second , why keep only the 1 / 10000 part of the simulation results ?"
333933,"it depends on how you interpret them . the normal approximation is excellent with these counts , but the point of using a multinomial model is that the individual estimates are ( negatively ) correlated . this suggests you ought to be interested in a simultaneous confidence * region . * have you considered using a multivariate normal approximation that accounts for the correlation ?"
335781,"nicely written question . what do you mean by "" single category "" ?"
335578,""" how do i write this in r code "" will very likely be off topic , as would be "" what is wrong with my r code ?"
336093,try a simpler model first without interactions . your question is on-topic here as it is a statistical issues ( when should i use a random effect . . . ) so i see no particular reason to delete it as your statalist question will be different - why do i get r ( 1400 ) ?
336127,the bayes factor compares the fits of both models for the _same_ observed dataset . it is not relevant to compute _one realisation_ of the posterior by simulating a dataset under each model ( and with which value of the parameter ?
336145,did you try looking at this question url which seems essentially identical ?
336166,"welcome to the site . please have a look at r's documentation , either by typing ` ?"
336171,why do you divide stage by total when deriving your outcome variable and also including total in the weights = option of your model ?
335438,can you please elaborate a bit more on your problem / dataset ?
336180,clarification : what are the frequency sizes in the 2x2 table ?
336191,could you tell us what the axes represent ?
336202,i think some clarification may be needed : is this both a treatment / control group design and a pre- / post-test design ?
336225,why would a reduction to a dimension of 120 be pointless ?
336261,could you clarify if i have understood correctly that you want to distinguish between int used as an ordinal variable and used as arbitrary categorical coding ?
335830,could you please use $ tex $ formatting ?
336349,are you assuming that $ x $ and $ y $ are continuous r . v . s ?
336424,i don't know how you're able to see separation in those plots - the points overlap too much to distinguish filled from empty circles in every case . are you sure the zero / one probabilities aren't just predictions for the observations with extreme predictor values ?
336442,"what was the area of application , and how much data did the groups have in general ?"
336487,is the majority class covering 66 % of all cases ?
331341,what are you criteria for statistical versus computational performance ?
336629,""" would i have to recode the variable responses so that they have the same interval levels in order to have valid regression results ?"
336637,"i think the issue is a question of power . we can do a t-test with 2 points , would we trust it though ?"
334010,what is your question ?
336682,are both of your variables skewed or just one ?
336502,"testing each sample separately for normality does not assess whether the samples come from the same population . what question , then , do you really need to address : that of normality or that of a common distribution ?"
336693,please add the self-study tag and read its wiki : url what have you tried ?
336683,is is possible to examine the data based on the number of tweets per day ?
336677,"if $ x_i $ 's have different distributions , then do they form a 'sample' ?"
336553,possible duplicate of [ why is accuracy not the best measure for assessing classification models ?
94354,could you append a small piece of code showcasing how you got these numbers ?
336836,"could you tell us more on why exactly are you doing , what you're doing ?"
336284,"if you don't mind , leave the time table in . it adds interesting challenges to the question . do you know what years the tags were lost ?"
335763,"i don't understand your last question . to get an interval of a certain width use ` confint ( fit , level = mylevel ) ` . is that what you're asking ?"
336904,do you have the signal ?
336930,are you saying that the values are paired ?
336942,"when you say you have "" multivariate "" sales , do you mean that you have sales for multiple skus ?"
336954,"what is "" error "" in this case ?"
13822,"your test may be accomplished by something similar to a matched pair test , unbalanced randomized block design . but before i guess further , could you please elaborate on your data , what is it what is looks like etc . ?"
336528,which is upper limit of the risk weighted summation ?
337042,"how do you propose to calculate "" average distance to closest local mode "" without clustering or some other previous step to identify local modes ?"
336911,""" i want to make sure that my response variable y is normally distributed . "" --- * why are you trying to do that ?"
337082,"it's not clear to me what you're actually asking , could you clarify ?"
254254,jwimberley could you expand on the consequences of ignoring these correlations in an answer ?
336946,"for those of us who do not use your software , could you please explain what "" rlabel "" does ?"
337223,"two observations . a ) i can't understand what the phrase "" model of the first differenced for 35 observations including 3 variables "" means , so it might be ambiguous to other people as well . b ) what do you mean by "" is my model correct or wrong to test granger-causality ?"
337222,"you mean $ x_n $ and not $ x_n $ , right ?"
172485,are you asking how to achieve this with r2jags ?
337132,it is interesting to see that the sas model uses somehow 4 degrees of freedom for the estimate of the standard error / deviation . why not 27 or 28 ?
337288,"i am afraid that your question was ignored as not very clear . no source for the equation , no details of the reference , not very well written . i don't understand it either : if a particular report is not clear on what was done , we can't add detail unless ( minute chance ) one or more of us were the authors . why not ask them ?"
337295,if we show the people that gave you this a statement of the [ central limit theorem ] ( url ) and ask what they actually mean for us to do with that theorem ( where in this question do we have $ n to infty $ ?
337117,"what is a "" beta "" if not a coefficient ?"
337309,is this a statistics question or is this about economics ?
335643,what is your question ?
336892,"clarification : the 122 items are the same as in the stems are the same , but 5 have different response options , correct ?"
337353,have you seen this answer ?
337354,have you considered looking at classification and regression tree ( cart ) analysis ?
337389,"what does "" i do not want a test that answers what i want , but one that considers this natural variance . "" even mean ?"
337089,"you seem to have used $ n $ as an index and as a limit variable ( also the sum upper range is suspicious ) . also , where does this come from ?"
337393,are you told to choose an instrument only from the variables presented ?
337441,what does your actual raw data look like ?
49225,i glanced thru the attached document and could not see obvious mistakes . are you really checking that the _observed_ likelihood is increasing ?
336931,what is the hypothesis that you want to test ?
337482,"in one group you give stimulus at different distances , and in the control you do what . . . ?"
337492,should you split your question into at least to distinct questions on cbow and skip gram ?
337596,i think it's the goal that is an issue - why would you want to eliminate the randomness ?
337083,"out of curiosity , could you post pca results as well ?"
337636,what does stable mean ?
337721,can you say something about what you are using the dimensionality reduction for ?
337722,"given the naming convention , do your 4 groups reflect two distinct variables , each with two levels ?"
337723,can you compute a prediction interval for $ log ( p / ( 1-p ) ) $ instead perhaps ?
337133,there are many possible reasons ! could you tell us more about your data and your use case ?
337786,"say that you build it , initially it predicts two classes and marks one case as anomaly--if you train your classifier on single example it would badly overfit . . . what if on next iteration another case would be marked as anomaly--would you train for another single-observation class ?"
337794,""" customers should not wait more than 10 minutes . this maximum waiting time varies from day to day . "" this is a strange set up . you're trying to make sure that there's a worst case scenario for wait time , but that worst case scenario depends on the day of the week ?"
337798,did you completely randomize the order of those 48 observations ?
337829,"welcome to cv . since you re new here , you may want to take our tour , which has information for new users . the question is not clear . what do you mean by "" does not capture the dependent variable "" ?"
331443,even for random samples the sample proportion of females will usually not be exactly 0 . 5 and it could be 0 . 55 for a small sample . if you don't know the population proportion how would you know what to adjust ?
337759,isn't the inverse of x the reciprocal namely 1 / x ?
337921,can you explain what you do not understand in that linked post ?
337927,could you please spell out your acronyms ?
337981,""" how can i put my regression results into the original data , and deseasonalize it , so that it fluctuates around the mean of data $ b again ?"
337994,what is the interpretation and value of this average adjusted $ r ^ 2 $ ?
327566,"suggestion 2 , if applied to results of two identical tests , would tell you there is a "" significant "" difference 10 % of the time . would you really trust the result of such a procedure ?"
337194,you need to clarify what data you are given in order to estimate the parameters . one sample path ?
338033,what is the question ?
337962,the fact that you applied dropout doesn't really tell much unless you specify dropout probability . did you try other dropout probabilities ?
338082,is there measurement error ?
337839,"that can't be right , and you can see that by noting that the minimum number of children is 2 . if the expected number of children = the minimum number of children , it must be that there is no possibility of having more children than the minimum number - otherwise the expected number of children would be greater than the minimum number . . . can you see the flaw in your argument ?"
338100,""" step-by-step guide "" sounds like something that could be too broad for this site , could you make it more specific ?"
337558,* * why * * do you wish to use a bayesian technique ?
337926,"with such a high ratio , it means you could lost acceleration , perhaps you are not even at point of local minima of a cost function , but for sure you are not touching global minima . are you sure gradient is applied correctly ?"
338016,"that's an interesting question that i think has not been discussed on this site before . to avoid confusion , why not eliminate the details and just start out by stating you have obtained a kl divergence of $ 10 $ ( or so ) between two gamma distributions , and then proceed to ask how to interpret that ?"
337766,did you check that ` exog_test . values ` has the correct numbers ?
338203,""" i don't have actual proportion of the data but assuming 50 % will there be any problem with the assumptions and analysis ?"
337334,why isn't this just an issue of p-value adjustment for multiple testing ?
337995,won't you lose almost all the information if you transform each month separately ?
338334,are you interested in [ partial correlation ] ( url ) ?
324046,what is your ultimate analytical goal ?
338078,"my first inclination is that there is a different default between the two ( maybe one is centering the other is not ) . second , have you tried different method / algorithm choices to see if others match up ?"
338426,and what is $ e ( u ^ 2 sigma ^ 2 ) $ when $ sigma ^ 2 $ is a constant ?
338391,why not just use the sample mean ?
338450,"to be able to assist , i will need a bit more information . in particular , if you could clarify what is meant by "" movement found across data sets "" . it seems to me that this is a situation where you have 6 ( comparable ?"
190107,what is your question ?
338495,did you calculate the variance of $ bar { x } $ in both cases ?
338574,"if they are in direct correlation with your target , why is there a preference on which one to choose as the root node ?"
338407,"you should start by defining what a "" tail "" might be . would you be referring to an extreme percentile ?"
338585,this sounds an interesting notion but could you make it more precise ?
338590,can you please add more details about what you're trying to predict ?
338635,"in poisson models , because of the mean-variance relationship , the standard errors are just a reflection of the sample size . you will find that $ text { se } ( text { rate } _i ) = sqrt { text { rate } _i / text { offset } _i } $ in a saturated model . does that answer your question ?"
338662,why do you have all the seemingly-unnecessary summation terms in your questions when you only have one element in each sum ?
338716,are you asking about unbiased estimation or about * asymptotically * unbiased estimation ?
338723,"i seem to recall that to obtain inference on mixed models , one should fit a null model and test nested models with anova ( see ` ?"
338725,do you want to analyze how ` arg / 16s ` varies depending on ` sample ` and ` gene ` ?
338729,do you have multiple observations per individual ?
338485,so you've determined that both independent variables have a significant effect on your response variable . can you be more specific about what additional tests you want to carry out ?
338823,"one reason we do multiple regression is precisely because the bivariate regressions between the response and the individual regressors tell us nothing whatsoever about how the other regressors might be related to ( or mediate or influence ) those regressions . if you aren't going to believe the multiple regression results because they differ from the bivariate regressions , then what's the point of doing them ?"
338827,how did you compute the accuracy for a logistic regression model ?
338772,why don't you want to form ` ratio_ab - int_a / int_b ` and analyze that variable as such ?
338923,how big is your data ?
338929,"welcome to cross validated ! i think you'll need to give a bit more information on what you're actually doing , & on your results , for this to be answerable . are you sure you're comparing the same models fitted on the same data ?"
338848,"( 1 ) this is an * arithmetic * progression , not a geometric one . ( 2 ) the distribution is continuous : it's not discrete . a more standard description would be that it is a * finite mixture distribution . * knowing what to call these elements of your problem may help in identifying related problems and searching for solutions . ( 3 ) do you perhaps mean that the gaussian sd is a tenth of $ b $ ?"
338992,"first , why is it missing ?"
339009,it depends on your experimental design . could you provide some information about how you went about selecting experimental subjects and measuring or observing their behaviors ?
339053,don't you mean p 0 . 001 ?
106176,"are you asking whether you can perform an * f * test of two nested linear models , one of which estimates predictive parameters for your two variables , and the other of which restricts those parameters to zero ( effectively excluding them ) in spss ?"
339228,"dummy variables are stand-ins for a single nominal ( or ordinal ) variable . those sound like binary variables , but not dummy variables . are the binaries the predictors or the outcomes ?"
27861,"do you need to account for scaling , rotation and / or translation ?"
339241,"this looks all wrong , you need the variables to represent ?"
339257,are your measurements linearly spaced or log spaced ?
339285,"as before i have to confess complete ignorance of how horses and riders are judged . i am familiar only with grading schemes in which ( a ) a judge can give whatever grade or mark seems merited ( out of a maximum ) ( b ) marks are independent , so that there is no quota or curve to be followed . i'd expect that principal component analysis or correspondence analysis might be helpful to you . are there example datasets you can post ?"
339163,in your formula there is an a not otherwise explained . why are you using common logs rather than natural logs ?
339321,"is the last "" pc1 "" supposed to be "" pc2 "" ?"
338978,are the 37 plots supposed to be from the same distribution ?
339357,are you asking about credibility intervals ?
339068,did all the regression coefficients have the same sign ?
322588,interesting post . you're interested in books dealing with the unexpected in areas beyond financial markets ?
339433,what is the purpose of doing this ?
339043,"my bad , i guess it is $ int_ { - infty } ^ x int_ { - infty } ^ y f ( u , v mu_1 ( z ) , mu_2 ( z ) , rho ) dv du $ ?"
339517,"no one's going to call the police on you , but one might wonder why this is better than just building one model . what problem are you trying to solve ?"
339443,are you having trouble deriving $ f $ ?
339551,can you say more about the $ y ^ j $ as you call it ?
339559,what ensembling technique are you using ?
339568,"welcome to cv . since you re new here , you may want to take our [ tour ] , which has information for new users . why do you think there is a paradox ?"
280092,"my first idea would be to simulate your null distributions many times and in each case calculate the test statistic $ ( m ( 1-c ) ) _i $ of box's m test . then you have this statistic's null distribution for the specific null distribution of your underlying data , no normality necessary , and you can compare whether your ` emp ` 's $ m ( 1-c ) $ falls in the tail of the $ ( m ( 1-c ) ) _i $ . would this work ?"
232402,are your variables defined on a 2d grid ?
338989,does this : url help ?
339634,n = 50 ( is 8 a typo ?
339278,"i don't see an explicit question here . in fact , the only "" ?"
339676,not yet . can you answer the rest of my questions ?
339695,have you just considered using a bayes factor instead ?
339696,is it a home work ?
339521,can you give an example of nonlinear arima you think of ?
153329,can you please check the correlation between ` elevator ` and ` floor number ` ?
93933,maybe this one helps ?
140845,"in a nutshell , advice to use far fewer than 40 explanatory variables with 400 observations seems very sensible , both statistically and scientifically . when you say there is little or no theory , what was it that led you to measure explanatory variables in the first place ?"
223995,what is your rationale for the ` myfun ` function ?
143932,what kind of model are you looking at ?
339692,"do you really mean b $ ( n , 0 ) $ ?"
339830,i thought sd is independent to regression methods ?
339837,"hint : for an exponential distribution and $ 0 lt p lt 1 , $ what is the formula for quantile $ p $ ?"
339873,"do you mean the * design effect * ( [ pdf ] ( url ) ) , $ de = 1 rho ( m-1 ) $ ?"
339880,"welcome to crossvalidated . have you heard the line "" the difference between significant and non-significant is itself not significant "" ?"
339896,"what does "" irrigation "" measure ?"
339913,may i ask why you need it for ?
339919,a source or reference where you see the term may help people dig into ?
339871,"the meaning of "" preferable "" depends on the objectives of your calculation : what is the purpose ?"
339283,which are your reasons to think that just entering the value is not the best way ?
339926,can you elaborate more on the model that generated this residual plot ?
339956,it wouldn't be unreasonable to think of the coefficients themselves as covariate weights in a model . could that be what they mean ?
340041,are you working in any particular programming language ?
139349,does your dataset include the date / time of the sales ?
340065,"are you splitting train / test / validation data , for instance using cross-validation ?"
340120,define what you mean by pseudoreplication ?
340181,are you looking at out-of-bag performance estimates for the training set ?
340184,a result can be too good to be true . does your science tend to produce near perfect explanations ( e . g . highly controlled experiments with minimal measurement error ) ?
340213,your plot is not relevant to the ks test because it uses the percents corresponding to the quantiles . could you redraw it as such and show that to us ?
340349,how much data do you have ?
340216,"welcome to cv ! can you define "" churn "" for us ?"
340262,context would probably help . what are these sequences ?
340392,have you noticed that $ 0 . 367 lt e ^ { -1 } lt 0 . 368 $ ?
338222,does $ omega $ represent the indices where the matrix elements are observed ?
340486,"i gather you mean $ left lvert vec { beta ^ { ( l ) } } right rvert_1 $ and not $ left lvert vec { beta ^ { ( l ) } } right rvert_2 $ in the latter sum , right ?"
112251,this is conditional on the $ w $ 's ?
340512,"perhaps the most critical aspect of the solution concerns whether the measurement errors in the angular frequency are independent . ( associated with this issue is consideration of the possibility of a systematic error in the angular frequency measurement . ) the reason i focus on this is that the data appear to have been very well chosen for the purpose of identifying the peak , leaving little possibility of much estimation error . would it be reasonable to adopt a standard model of peak shape , such as $ a re ( ( omega- omega_0 ) ^ { -1 } ) $ for unknown complex $ omega_0 $ and real $ a $ ?"
338348,can you say more about your study & your data ?
340534,"although the formula in the wikipedia article you quote is correct , the text is plainly wrong . trust the formula : can you express a $ chi ^ 2 ( k ) $ distribution function in the form $ f ( x-k ) $ ?"
340394,how was customer satisfaction measured ?
340306,"are you asking how to estimate the parameters of a poisson or negative binomial distribution , or . . . ?"
340555,could you provide a hyperlink for the port algorithm ?
340544,"how is the scaling done , standardization ?"
338626,"do you mean that the sample observations of $ f_0 ( t ) $ are uncorrelated with those of $ f_n ( t ) $ for all $ n $ , in the sense that the sample correlation coefficients are all equal to $ 0 $ , or that the underlying factor is uncorrelated , or both ?"
340696,see url for multiple approaches . does it answer your question ?
340720,do you care about the magnitude of the squared errors or the pattern of the square errors ?
340742,( -1 ) it seems hard to believe that you want to understand the concept of a posterior distribution from a single slide . have you considered opening a standard textbook ?
340830,"it's grubbs' test , not grubb's test , but more interestingly ( 1 ) why remove outliers ?"
340892,why would you like to use machine learning here ?
340899,there doesn't seem much information here in most parts of the graph . have you considered smoothing on some transformed scale ?
340961,what is the question ?
340921,perhaps the paper is only interested in finding the zeros of the gradient ?
340980,wouldn't it be better to store the data in a dataframe with two columns : datetime ( or date and time separately ) and the temperature value in another one ?
340551,"nicso , i see that you use anova test but are you sure that your data is normally distributed ?"
341019,could you give us more details ?
341022,"knarpie indeed . it's not my choice ; it's the op's to make . he can assume it . he can check whether it's true . if you can't change your model in the light of results , what is science about ?"
337953,could you provide a concrete reference that an answer can address ?
341061,are you measuring performance on a per-parameter basis ?
340990,what is your goal ?
341095,"elegant or not--that will be in the eye of the beholder--the most salient aspects or this proposal are that ( 1 ) it is univariate , not multivariate ( it doesn't account for simultaneous changes in parameters ) and ( 2 ) it is * ad hoc , * * vague , * and * non-quantitative * insofar as it does not determine how much to change the parameters nor does it provide any principles or criteria for doing so . as such it's difficult to conceive of this as being a form of regularization . is it possible you have left out some important details in your description ?"
341094,is the data dense or sparse ?
341122,* predication * or prediction ?
341135,are you sure that you want to 'correct' at all ?
341200,"welcome to cv , j . con . this is an interesting question . why not simply go completely nonparametric ?"
340259,"area under curve $ ll $ 1 , so what are the units on the $ y $ axis ?"
341282,you mean graphs like in graph theory or plots ?
341306,"when you say that "" member of these datasets are not identified "" , do you mean only from year to year , or from 1 dataset w / i a given year ( employment ) to another dataset ( education ) w / i the same year , or both ?"
341326,"even with just finite additivity , what probability would a uniform distribution * necessarily * assign to each natural number ?"
341359,"which "" results "" are you quoting , given that there are three tests reported in this output ?"
341430,"i suspect the down vote is for the code , as cross validated likes to have questions closer to stats and maths theory . you may find this sort of practical "" how do i address code issue in machine learning "" question works better in data science or stack overflow . regarding the code , it would be a good idea to explain what actually goes wrong - does the code run but give incorrect results , or is there an error ?"
341473,what is fdi ?
341450,"what do you mean by "" common "" ?"
341483,what is ` lm . beta ` ?
341501,possible duplicate of [ how to use gibbs sampling when target function is known only up to normalising constant ?
340498,how is $ b_1 cos ( b_2 x ) $ a probability density ?
341040,"what guarantees that $ f ( boldsymbol { x } _i ) $ is positive semidefinite , and therefore a valid covariance matrix ?"
341552,"why don't you just do classic knn , without hoping that the centroids are a good approximation ?"
341491,why would you use a vae to find mean and variance of a sample of data ?
340898,"it looks like you're using a single-unit rnn in both cases . have you tried making it bigger , say 10 or 100 ?"
341583,"maybe some form of multilevel discriminant analysis , separately for a / b and w / x / y / z ?"
341573,this question is confusing because it isn't clear what $ mathbf { a } $ might be . is it a finite set of vectors of interest to you ?
341649,under what conditions do you think transformation is appropriate / justified ?
303074,i'm away from my office and don't have access to wooldrige's book . would you mind developing the equation you are talking about ?
341567,do you have other datasets ?
341702,what kind of constraint ?
341713,why do you think that the fact that they are latent is a problem ?
341720,it is not clear whether you want to examine ( test ) the relationship or just ascertain the magnitude of the relationship ?
341814,why ?
341821,can you please add more details to your question ?
341900,is there something you don't understand in the reference ?
341920,"three queries : what is the sample size ( total , and for each group ) ?"
341819,i am the one who first down-voted your question ( i don't know about the second down-vote ) . the reason why i downvoted it was that i found your post factually wrong . htf approach * but * without millions of transactions . a hugely competitive and extensively researched field * but * with the main modelling vehicle being an htf reference that hopefully ( ?
341977,what makes you think there is any shrinkage going on in the glm fitted on page 156 ?
258472,could you be more specific about what gradient you propose ?
341971,can you explain in more detail what you're measuring & what you want to investigate ?
342001,"the covariance question at the end is asked and answered at url it's not clear what you mean by "" make sense "" or even by "" df "" : what context do you have in mind and how is your "" df "" computed ?"
341973,would give a few more details ?
342057,"back-transforming makes no sense here . you threw away the sign , so the transformation is not reversible . it's not like the logarithm or any other one-to-one transformation for which there is a unique inverse . either your response is on an interesting and useful scale in which case there is no need to transform ; or it's impossible . i am really surprised at the idea that this transformation would improve anything for a linear model . can you post the data or tell us a public source for ` mp2017 . dat ` ?"
342069,"neither method reads like a valid way to compute a p-value , but it's hard to determine that because you haven't explained how you "" got the result , "" you haven't clearly stipulated the distribution ( s ) you have used to obtain "" monte carlo generated random points , "" and you haven't even exhibited a testable hypothesis . instead of asking us to decide between two potentially illegitimate methods , why don't you describe your problem and your data and then ask what would be an appropriate procedure ?"
341927,"could you explain the distinction between finding a "" strategy to win "" and evaluating the payoff of the game ?"
342058,"can you evaluate e without error ( noise ) , or only a noisy estimate , and if so , can you control the level of noise ?"
342013,"could you explain your last observation about a "" big difference in sd "" ?"
342173,"also , what is the acceptance rate for your chain ?"
342175,is this unsupervised learning ?
342184,how about the cross product of the two vectors divided by the sum of lengths ?
342125,could you fit an anova and show us a plot of the residuals ?
342103,what makes you think that 10 epochs is particularly early ?
342187,"the question is whether you really want euclidean distance , why not manhattan ?"
342203,the nudging thing wont work efficiently for high cardinality categorical features right ?
341704,what's the distribution of the components ?
342214,how exactly would someone get the estimates of covariance of the data after having estimated a var ?
342235,why calculate a ratio that you can't interpret ?
342285,what is the chance that your sample contains * no * interesting elements ?
342292,"azim that being said , the post is very complicated to follow . perhaps you could simplify the question , op ?"
342321,"eg , for # 3 , you seem to be referring to [ tag : overfitting ] , for # 2 [ this ] ( url ) might be helpful , [ here's a related search ] ( url ) . re # 1 , if people here already say this , what are you hoping for from the answer to this thread ?"
342343,your question is unclear . are you asking about a single number that measures the jumpiness of your whole time series ?
342388,"please check the title of your question . further , does ordering the x-axis make sense ?"
342396,do you have specific models in mind ?
342372,"please confirm , in the 2nd model , the enjoyment effect is n . s . also , what do you get for a p-value for the slope if you do flow ~ enjoyment ?"
342496,* i had to apply a transformation ( abs ( * * x * * -mean ( * * x * * ) ) ) to the * * response variable * * * can you clarify this point ?
342501,"if the confidence bounds are adjusted appropriately for the fact that these are residuals , not raw data , then it looks like ms-garch fits the data less well than garch . wouldn't that be what you would have deduced had you not asked this question ?"
341316,are you fitting different models on the same train set ?
340675,does $ mathcal { c } mathcal { n } $ just mean the usual multivariate normal distribution ?
342558,how do you define a significant difference between forecasts ?
342615,what are you planning to do with the data ?
342339,"please clarify what the "" statistical mean and standard deviation "" apply to : would it be $ y $ , $ x $ , or $ both $ ?"
342666,what is shown on the x-axis ?
342671,how exactly are the two balls being drawn ?
342689,"can you state the problem in * mathematica * notation , rather than the notation of your specialty ?"
342710,is $ x_0 $ random ?
339769,different people have different reasons for returning . different people also have different ways of getting sick . does that mean there's no underlying process behind sickness ?
342790,"it depends on what you mean by "" valid "" . what are you trying to achieve by doing this ?"
341509,"for any $ p gt 0 , $ there exist distributions with $ 1-f ( x ) = x ^ { -p } $ when $ x $ is sufficiently large . what happens to $ a ( x ) $ for these distributions ?"
342843,1 ) this table that you present in the image is very specialistic . without further information about how you obtain it ( there are multiple ways to calculate these p-values ) it is difficult to say anything about it . 2 ) * who * is considering the regression equation that you mention ?
342883,is it possible for you to provide similar simulated data ?
342757,would you please post a link to the data ?
342968,what is the probability that $ u leq 1 / 4 $ ?
343000,"what you are observing is the effect of dichotomizing a continuous variable . in this case , it is inflating the relationship . what do you obtain for a prediction if you return to the logistic model and predict the probability of being in top half for the first and third quartiles for the training milage values ?"
343095,"if you are using different dependent variables for each sub-model , i do not understand how they can be compared or aggregated . they are estimating different things . what are you interested in estimating ?"
342987,possibly url will help ?
343187,"however , i am not sure why you calculated the derivative with respect to $  ^ 2 $ rather than  , because your parametr is  , isn't it ?"
343056,"you should * not * use ` total . parasites ` as a fixed effect ; you have correctly specified it as "" weight "" . why do you put it in as a fixed effect too ?"
342818,how is the expression defined if $ u ( t ) beta x ( t ) $ is negative ?
343250,how do outliers enter into this question ?
343258,what you mean when you say your regression gives you info on standard deviation ?
343177,""" i would still be in the same situation . so the question remains : what is the bayesian justification for privileging the study that came first ?"
343323,how can you explain the huge coefficients in the first model ?
326480,"just for curiosity , why don't you want to see the bayesian answer ?"
343310,"what i mean is that you'd need to specify a distribution for the inliers . any distribution whose support lies within the boundaries is valid . but , for any choice of boundary , there are infinitely many such distributions , and you'd have to pick one to sample from . for example , do you want the uniform distribution on the interior of the the hypersphere / cube / etc . ?"
343375,"you still have $ p ( h y ) $ as your ultimate goal . do you mean $ p ( y h , x ) $ ?"
343415,"if x2 and x5 are highly collinear , you should only include one of the two in your model ( e . g . , x2 ) . i don't understand why you would still include x2 : x5 in a model which includes x2 ?"
343421,"if you're going to put $ mu $ and $ sigma $ as * states * , then no , this is not a linear system . typically you would estimate those as * parameters * , by maximum likelihood . the mle is even available in closed form here . is there some reason you're not doing that instead ?"
342950,auc should be similar unless your dropped variable is quite significant . have you thought of drop in say accuracy ?
342779,"in addition to amoeba 's correct comment ( 1 ) , can you please set the seed of this code demonstration ?"
343473,first of all ( x y ) $ ^ 2 $ = x $ ^ 2 $ 2xy y $ ^ 2 $ . so what is e ( xy ) ?
343515,what are you predicting and with what type of model ?
343532,is part of the problem that you are modeling a strictly positive quantity using a normal distribution ?
343558,"it's hard to see anything to answer here , since the relationship you describe is immediately implied by $ cos ( 0 ) = 1 . $ what kind of "" intuition "" do you seek about that ?"
343560,"why do you think , that student t is a 2-parameter pdf ?"
343597,you're welcome . why not register your account in the interim ?
343563,are you sure you want that form ?
343630,"( 1 ) are all waiting times are independent of each other , ie , the positive inputs and negative inputs form two independent renewal processes ?"
343640,whats the purpose of the model ?
343632,possible duplicate of [ how is empirical bayes valid ?
343628,"are the model parameters the same in arima ( 0 , 1 , 2 ) and reintegrated arima ( 0 , 0 , 2 ) ?"
343670,is group supposed to be the time dependent covariate ?
343681,how do we count it twice ?
343647,what exactly is your question ?
343697,"buckets = groups of products , right ?"
343719,"this question is loaded with ambiguities . could you clarify what it means for "" a / b total people showed up "" at a particular time ?"
343726,have you seen the answer ?
343609,"please tell us the sense in which you mean "" covariance . "" as an example , a random permutation of the rows will exhibit each row as the realization of a random variable in which , by design , the covariances of these rows * qua * random vectors is zero . if you mean some empirical measure of covariance , then exactly what is it ?"
343811,"is it really true that it is * impossible * for a polyp to be found on the first procedure , but no polyps were found on the second procedure ?"
343861,do you require that $ mathcal { s } $ be a partition of $ mathcal { x } $ ?
343844,"holiday effects and seasonality are not generally thought of as "" outliers "" ; they are usually explicitly modeled . do you have "" spikes "" for which you have absolutely no pattern / explanation ?"
343890,what is your question ?
343894,"is "" eyes "" your dependent variable ?"
343917,why do you think you need a dummy variable for a continuous iv ?
343929,can you provide some info as to what the axes mean in this case ?
343961,"the upper whisker always stops at a data point . it is never at upper quartile 1 . 5 iqr unless that coincides with a data point . rather that is as high as the upper whisker can possibly extend , but the data often ( i'd say usually ) imply otherwise . it's easy to think up examples where upper quartile 1 . 5 iqr could be higher than the maximum in the data , but you wouldn't expect the upper whisker to extend beyond the range of the data , would you ?"
343967,"i imagine that some rounding has occurred - the weight for your best model is very close to 1 , and the weights for the other models are all very close to zero . can you access the weights directly from the mod . avg dataframe to check ?"
343972,"maybe it is my ignorance , but how taking observation id as a random effect would account for the over-dispersion ?"
343976,"do you only have 3 observations , or does $ x_i $ represent a mean number of interactions from year $ i $ ?"
343998,what is the reason that some observed variables were measured in one group and not the other ?
344012,"well here's a familiar face . . . : ) i think the question i marked as duplicate is close to the best answer you'll get . the big question is really "" which confidence intervals are you really talking about ?"
344046,what do you want to learn about them ?
344094,what are you trying to model ?
344126,` do i need to include time in the fixed effects ` -- what does that mean ?
344133,are you aware of this link : url ?
344134,how were you able to * not * do the maximization jointly and yet calculate the aic of the arima-garch model ?
344074,have you reviewed the answers on this thread ?
10370,is the categorical variable unordered ?
344188,can you say something about the categories ?
344205,"please explain what you mean by "" optimal separation "" : what criterion are you optimizing ?"
344214,how does the tag meta-analysis mathes the content in body of your question . re-draft it along wth your part of data you are working with ?
344116,"actually , as noticed by sycorax , the documentation says it all . i cannot think of better answer then copying and pasting it . it gives you the formulas and explanation . what exactly is unclear for you ?"
344286,possible duplicate of [ is the w statistic output by wilcox . test ( ) in r the same as the u statistic ?
344291,does [ how to interpret coefficients in a poisson regression ?
344386,how are you estimating probabilities without data ?
344418,hello . * 1 ) * please explain in words what the code does . * 2 ) * what are your own thoughts ?
344412,could you state precisely what the question is ?
344424,clarification : are you looking to visualize the model ?
344456,"by editing your post , could you explain the purpose of your analysis ?"
344506,"well . . which "" regression model "" are you using ?"
344542,how are your validation and test sets constructed ?
344549,what do you get when $ a $ is the $ 2 times 2 $ identity matrix and $ d = pmatrix { 2 / 3 & 1 / 3 1 / 3 & 2 / 3 } $ ?
344636,why would you expect the conditional mean parameters * not * to change when you change the conditional variance parameters ?
344695,there's a diagram in that slide . i think it's very clear . what is exactly confusing ?
344699,"ctd . . . 3 . it's not at all clear what you intend by "" whether the distribution is significant "" . what are you trying to find out about the distribution ?"
343306,"thanks , i voted to reopen . if you want the answer specifically in the context of neural nets , perhaps add that tag and maybe include it in the title to the question ?"
344706,could you post the data ?
344761,"often these would be called "" inliers . "" regardless , your question seems to specify exactly how you would detect them : they have "" low occurrence rates . "" could you clarify what , beyond this trivial observation , you might be looking for in an answer ?"
292682,"for a standard normal and $ c = 1 $ , the value is 1 . for $ c 1 $ , it is undefined with high probability and for $ c 1 $ it converges to infinity as $ n $ grows . maybe $ x_i $ should be positive ?"
344825,welcome to the site . do you want to test the difference between two sample means ?
344836,where did you get that formula for $ lambda $ ?
344856,"have you tried standardizing the "" large "" variables ( such as ` gross ` and ` budget ` ) ?"
344853,why it holds that $ x_i = f ^ { -1 } ( g ( z_i ) ) $ ?
344880,"please write out your tlas and explain your terminology . what , in particular , is a "" line "" and how exactly is it related to data ?"
344498,"the bold question in the body and the question in your title are very different . it looks like all of the answers , including mine , are addressing the question in the title . perhaps you could ask the narrower question about nodes and features in its own thread ?"
344475,"i'm confused by your question . the expectation reduces to $ ( e ( lambda_1 ) , cdots , e ( lambda_n ) ) $ . are you interested in the expectation of a single eigenvalue then ?"
344924,"to be clear : you want a prediction interval , rather than a confidence interval for the mean of $ hat { y } $ ?"
344829,how many observations are there . what is the frequency of measurement ?
344931,"they are solving different problems , what's your question , you want to comparing what ?"
344935,your pca will always return at most 37 features for 100 % of the variance because you're in a high dimensional setting so at most 37 columns could be linearly independent . with so few observations i think it's extremely dangerous to do such a high variance feature selection process and you're almost inevitably overfitting . do you really need to do feature selection ?
344939,it is not clear to me what you show in the picture . can you write the model so we can understand your problem ?
344958,"all is fine with your explanation . what 2x2 matrix are you interested in , the one with $ delta $ and $ rho $ term ?"
344917,"please clarify your question . what do you mean by "" clustering "" , what is your expectation on "" better execution time "" and for the result ?"
344984,did you construct that table ?
344069,these are some big questions - perhaps break your question down to ask one at a time ?
344573,"is your hypothesis that for a given image , will there be predominantly 1 tree species ?"
345015,what is your goal in using hypothesis testing ?
344676,if every letter is randomly how could you predict with any degree of accuracy ?
345036,a suggestion in a different direction : why don't you use a package like xgboost ?
345045,( upvoting just for fancy impressive pictures ) why didn't you consider 3-cluster solution ?
344923,"query : are a1 , b1 , c1 , . . . the same thing measured at different times ?"
345038,is this a homework question ?
345090,do you have a reference to your definition of sufficiency ?
345126,what is your true loss function ?
345114,"it sounds like you're not using a softmax , i . e . your two output neurons aren't linked to eachother via $ p q = 1 $ . is this true ?"
344769,where did the data came from ?
345150,can you post more about where you see this repeated testing happen ?
344561,so you know a and you need to find b ?
345205,would adding ( or subtracting ) 45 degrees to that angle get you an appropriate rotation angle with the cloud of points rotated about the means ?
345224,"the next question is what do you do with an exponential sample $ ( x_1 , ldots , x_n ) $ ?"
345174,can you try ` str ( data_animal $ year ) ` ?
345294,differences in variances of * what * ?
345296,"hi charlie ! unfortunately , since this is really a programming question and not a statistical one , it's not really on-topic for this site . if you're asking elsewhere , it'll be helpful to clarify what you want here : do you want to sklearn to help with the cross-validation training / fitting loop ?"
345300,"in my experience , the way to make theory come alive and engage more deeply is through application to real problems . are you currently at university ?"
345301,what is your question ?
341725,are the zeros true zeros or do they represent below limit of detection ?
345132,"there is a block bootstrap that is used in time series analysis , but what kind of block bootstrap is being used in this situation . how does it differ from the ordinary bootstrap ?"
345352,would simplifying this to line fitting still be relevant ?
344937,"it's not clear what you don't understand , please clarify the question . what is the purpose and what kind of research have you done ?"
345375,can you explain how / if this is any different than the newton raphson method to finding the root of the score function ?
345200,how can you adjust the probabilities if you don't even know if $ h $ and $ e $ are related in the first place ?
345398,"the way your question is worded , it's not amenable to a stats test . you want to compare each pair of items ?"
309495,"there are dozens of things that could easily be checked for . there's a time when i think a set of more comprehensive consistency checks would be useful -- before publication . where the original data is not provided in the paper , it would be a simple matter for an editor to get someone to run the information in the paper through a collection of consistency checks and flag anything sufficiently weird to query the author about ( "" with this summary , how do you have a mean equal to the lowest reported value in the group when the standard deviation isn't 0 ?"
345422,what is the purpose of your study ?
345459,what does this have to do with statistics ?
345269,"it's very well explained in the picture caption : "" visualisations of learned data manifold for generative models with two-dimensional latent space , learned with aevb . since the prior of the latent space is gaussian , linearly spaced coordinates on the unit square were transformed through the inverse cdf of the gaussian to produce values of the latent variables $ mathbf { z } $ . for each of these values $ mathbf { z } $ , we plotted the corresponding generative $ p_ { boldsymbol { theta } } ( mathbf { x } vert mathbf { z } ) $ with the learned parameters $ boldsymbol { theta } $ "" . which part you don't understand ?"
345357,what exactly is your scientific question and hypothesis about change ?
345499,ace high or ace low ?
345474,could you provide a bit more information on your original dependent and independent variables ?
345520,"the question was asked and answered , especially about 2-class case , a few times on this site . did you try to search ?"
345530,"which specific "" stupid idea "" are you referring to ?"
345537,the expected value of poisson distributed random variable is not equal to it s standard deviation . it s equal to it s variance . so what does your calculations show if you correct this ?
345651,what is there to explain ?
345550,what do you want to do with $ y $ ?
345689,"i won't have a reference for you . but to clarify , are you asking specifically about risk assessment , as mentioned in the quote ?"
343815,is tuning the elastic net and all that caret stuff really part of the problem or could you reproduce it with a single model fit using made up $ alpha $ and $ lambda $ ?
345717,what hardware are you running on ?
345737,""" then why don't the network weights converge in such a way that one neuron simulates the linear regression and all the others converge to zeros ?"
345781,"as you've written it , the errors have non-zero mean ( zero mean only if variance = 0 , i . e . , zero error ) . is that what you mean ?"
345801,do you have any additional information ?
344485,"most of what you deduce is incorrect because the $ delta_i $ are functions of the data . it's hard to believe that is "" not relevant . "" among other things , this implies expressions for variances and covariances are wrong . in effect , by not telling us what the $ delta_i $ are , you are stating that $ chi $ could be practically any function of the data--and that makes this question far too broad to be answerable . perhaps you could , therefore , edit this post to explain what the $ delta_i $ are ?"
345817,"$ log ( x_1 ^ 2 ) = 2 log ( x_1 ) $ so as written this does not make a lot of sense - are you sure this formulation is what appears in the textbook ( and in "" the real world "" ) ?"
345868,"interesting question . i'm not sure those are all appropriate levels , particularly party , since there are likely only n = 2 or 3 at that level . candidate , as well , could be problematic , if there aren't many candidates . could you describe the data a bit more ?"
345903,is this a homework question ?
345908,you can conclude that the observed frequency is significantly different than . . . what ?
345950,` if it were the same people that ticked off fewer boxes for certain elements ` i'm sorry for not understanding this enough . can you explain more clearly what you want to test or to measure ?
159800,"this question looks strange for several reasons . first , "" independence "" only makes sense with paired data $ ( x , y ) $ , so it is a surprise to see the possibility that you have $ m ne n $ values of each . are your data paired or not ?"
345998,"$ p_ { attach } = 1 , 1 . 25 , 1 . 5 $ . what , the scale-free attachers are so good that they have up to 150 % chance of successfully attaching ?"
345926,are these variables necessarily positive ?
346051,why do you believe it's not log uniform ?
345990,"what about introducing properly your problem ( what is the research question you're trying to answer , describe your data , show your model , etc . ) ?"
345902,"re the edit : did you perhaps write "" dependent "" for "" independent "" ?"
346111,can you print the output of ` summary ( a1 ) ` as well as the value you calculated for ` h2 ` ?
346139,` ?
346151,"any reason , not to use a mann-whitney u or wilcoxon test ?"
346166,"if the model is correct then the kalman filter computes the sequence of filtering distributions exactly , no matter how many observations are missing . however , doing so when the data is sampled very sparsely over time may not be the fastest way to compute them . you may be able to modify your model to have observations at every "" time "" but with time-varying dynamics , and still use the kalman filter but with one update per actual observation , not per second . what is it that you are worried about exactly when you say "" unsuitable "" ?"
345604,can you provide any more context for this ?
346173,"not sure , but i think the point of kde resampling is to obscure ( become asymptotically independent of ) the original data in order to improve privacy . if there is no need to obscure the original data , then i think kde resampling may not have any merit . have you seen otherwise ?"
346197,robust in what sense ?
346202,this cannot possibly be generally true . instead of the sum would you perhaps mean an * average * ?
346208,i may be missing something -- but isn't your interval just dependent on the number of random drawings ?
346223,is this question a version of what you were trying to ask at url ?
346136,is this school work or you're managing a pension fund ?
346084,"note that a random normal variable might get negative values . a * rectified * normal variable might be better to model the problem . but anyway , are you asking your question for a specific distribution , or for any kind of distribution ?"
346299,which optimizer was used ?
346431,but it doesn't look like it's converged yet ?
346433,are you asking about the interpretation of ` sma1 ` ?
346503,"control = coxph . control ( iter . max = 100 ) is present in m2 and not m1 , could you explain why this difference exists ?"
346512,what is reghdfe ?
346545,would mass spectrometry results be available for providing isotopic analysis data ?
346551,is it fair to say that you're basically asking why people typically choose $ theta $ by maximum marginal likelihood rather than just maximizing the regular likelihood ?
342727,"what do you mean by a "" continuous factor "" ?"
346561,are you conflating conducting a group of pairwise tests of the same kind with control of the fdr ?
346583,automatic variable selection is [ almost ?
346614,"so to be clear , both coins have unknown weight ?"
346653,""" i find this a bit misleading due to the nature of the task "" -- there is little information on the nature of the task and the matter and the goals of your work . without any knowledge of what question the test is supposed to answer , there really is no good answer . now for variant one ( if-both-predictions-available ) i could think of possible questions to be answered . for the second ?"
346675,do you really need to select features ?
346643,"to be precise , are you asking about ( i ) adding a constant 2 to every entry of matrix $ x $ , ( ii ) appending a row to $ x $ where every entry in the new row is 2 , or ( iii ) appending a column to $ x $ where every entry in the new column is 2 ?"
346511,is this homework ?
346702,why should you add uniform weight value to a glmm ?
346707,does [ this ] ( url ) help ?
346755,security of what ?
346774,why do you want to detect extreme values ?
346775,"could you tell us more explicitly the form in which you "" have "" this distribution ?"
346784,just for curiosity : why to test for correlation between residuals and regressors ?
346790,why would you think a normal q-q plot would be appropriate for residuals based on data that is almost entirely integers less than three ?
346814,why are you interested in a linear neural network ?
346823,are you sure $ t ( x ) = x_1x_2 $ is unbiased and that the average is biased ?
346794,thank you for the effort to clean up . what are you hoping to get out of making a ci ?
346798,"are you interested in showing multiple , bootstrapped calibration plots or the calibration statistic adjusted for the bootstrap ?"
346838,have you tried url ?
345758,"i'm unable to understand this question because i cannot obtain a clear idea of how you compute your "" z scores "" : what sets of data are they based on ?"
346891,p . windridge why not post that as an answer ?
346906,was there an active intervention in your study ?
346931,please check that my edits did not change your meaning . i wasn't clear when _questionnaires_ meant questionnaires ( number of people ) and when it meant questions . how many people did you study ?
346499,it probably won't make much difference . why not try both ?
346947,can you explain what is * left and right trials * ?
346953,"if the sum is constant , then what is it that is normally distributed ?"
346978,have you checked whether these high outliers all correspond to the same customer month after month ?
346988,is it possible that the marginal effects in your second plot are expressed on the log odds scale ?
347019,"before i respond , what sort of outcome are you trying to forecast ?"
346573,"when you say "" reduced its accuracy when predicting only the original inputs "" , do you mean the uncorrupted training data or the uncorrupted validation data ?"
346651,"your data is numerical and finite , so why the interest in solving the integral in closed form . once you've create via splines a function , you can do numerical integration . in addition , are you familiar with the kolmogorov-smirnov test / theorem ?"
347093,""" is it possible to discuss this further ?"
347105,"i recommend that rather than asking "" will this be a good approach ?"
347119,i assume each model predicts the disease status or severity on the same data ?
347123,"how can these points be "" known "" for a cdf and yet tend to decrease with increasing values of $ x $ ?"
346818,"hint : we know that $ k_1 ( x , y ) = phi_1 ( x ) cdot phi_1 ( y ) $ and $ k_2 ( x , y ) = phi_2 ( x ) cdot phi_2 ( y ) $ . given that $ k ( x , y ) = phi ( x ) cdot phi ( y ) $ and that $ k = k_1 k_2 $ , what could $ phi $ look like in terms of $ phi_1 $ and $ phi_2 $ ?"
347110,you aren't very clear about what the difficulty is . did you work out the cdf of $ hat { theta } $ ?
347133,what is the intended difference between ` h ` and the default ` ytrafo ` used by ` ctree ( ) ` ?
346577,can you write out what you think q learning does ?
347165,did you mean $ frac { 13-10 } { 5 } $ ?
347009,i don't understand why you are testing for the significance of s using your current model2 . can you elaborate ?
347221,""" is this used as some sort of baseline for making the others relative to that ?"
347174,"well , for a start , there is no $ beta $ , only $ beta_a $ and $ beta_b $ . so what is this $ hat { beta } $ supposed to be estimating ?"
347231,"it's really difficult to answer the question in your comments , without a reproducible example and results . . . . p . s . for friedman test , what was your blocking variable ?"
347257,"by l1 regression , are you referring to regression problems where a solution is sought to minimize l1 loss , i . e . $ min_ beta x beta - y $ the absolute differences ?"
347258,does the exercise assume that cat either scratches or purrs ( i . e . they are exclusive events ) ?
347240,what are $ phi1 $ and $ phi2 $ ?
346249,in another question of yours ( url ) and through a chat ( url ) i've tried to convince you that you don't have random samples from a weibull distribution and that fitting using maximum likelihood in inappropriate . what you do have is a regression where the form of the curve is ( or might be ) in the shape of a weibull . that's a very different situation . but no response from you . how am i mistaken ?
347308,how do $ n $ and $ r $ relate to each other ?
347323,we can infer that the predictive model is fairly useless but almost nothing else . it could even be that the model can't be improved on . or it could be that the robust model is missing some structure in the data . why not show the original data ?
347336,can't you just take the aggregate across the cases ?
347199,"the distinction , though , is critical , isn't it ?"
347416,"are you confusing "" bridge "" and "" ridge "" ?"
275100,are you aware that this is not a classification problem ?
348262,are you sure you've chosen a title / headline that reflects your question ?
349343,possible duplicate of [ bag-of-words for text classification : why not just use word frequencies instead of tfidf ?
215945,how are $ h $ and $ x $ related ?
215996,"all the methods applied to sample medians at url also apply to other percentiles . in effect , your question is identical to that one but merely replaces the 50th percentile with the 1st ( or 0 . 01 perhaps ?"
217396,"aren't you asking for [ bands ] ( url ) rather than intervals , since ( if i understand correctly ) even given a fixed $ y_i $ , you want a different interval for every age ?"
217637,welcome to cross validated ! can you add references to where you've seen these formulae & explain the notation ?
217756,what is it that you want to compare between the conditions ?
215961,"since you're interested in the means rather than variances , why not just cluster the means ?"
217924,forgive me ; where does 2n-1 come from ?
218020,aren't they just the same thing ?
218019,what's ctl ?
218055,"` here c , a and b are independent variables with a normal distribution ` . . . the same normal distribution ( e . g . standard normal ) , or with differing means and variances ?"
218443,"if you are only asking how this can be done in spss , that would be off topic here ( see our [ help / on-topic ] ) . however , if you are looking for suggestions for how to display these results ( irrespective of software ) , that could be on topic . we would need to know more about your model , data & results , though . can you provide more detail ?"
218488,"please edit your question to provide context . for example , where does the data come from , how many variables are available , what is the sample size , and what is the overall goal of the analysis ?"
218526,"please edit your question to describe the context of this problem . for example , what is the goal of this project , what sorts of text are you trying to classify , and what performance have you been able to achieve with the training data you already have ?"
218811,how do you get 4 as a possible value of a ?
219097,could you be more specific about what is being compared to what ?
219462,why are you running anova on count data ?
220215,did you tune ` nu ` and ` c ` ?
220216,"can you post a snapshot of what your data looks like , preferably with a few examples from each class ?"
220296,not quite sure what you're asking . there seem to be two questions here : ( 1 ) how do you find the maximum allowable value of $ lambda $ - well you just solve $ r ( t ) = e ^ { - lambda t } $ for given values of $ r $ & $ t $ . ( 2 ) how do you calculate a lower confidence bound for the true value $ lambda $ from a sample ?
220539,"what do you mean by "" distribution over their belief about each of the three color hypothesis ?"
220546,"pls explain "" percentage of negative elements in the training set is 49 % "" . is this a binary classification problem where you're trying to predict class 0 and 1 ?"
221500,"i don't know what you mean by "" unique "" . ( besides , something can't be "" the most unique "" ; something is either unique or it isn't . ) can you be more specific ?"
222155,"as it stands you're being overly vague and the problem seems to lack a little context . what's "" the augmented error minimization "" ?"
222274,"did you really mean to write "" conjugate "" ?"
222284,what is it you want to be able to say from these data ?
222478,"what do you mean by "" only "" information ?"
222709,"whatever that syntax is , it is not stata syntax ! ! ! spss ?"
222716,"it is the first time i've heard of "" bifactor rotation "" ( shame on me ) . can explain it or give a source where it is explained ?"
222901,"1 . when you say "" gets values from 900 to 999 "" this implies that the values are integer ( because otherwise values between 999 and 1000 would not go into either bin 9 nor into bin 10 ) . if the values are integer they are not normally distributed and if they are not integer you have incorrectly ( / misleadingly ) described what happens to the values . please fix your description so that it is consistent with the actual situation . $ : $ 2 . many algorithms are named after knuth . what algorithm is this ?"
222940,"you still haven't described in sufficient detail what a "" margin of error "" might mean . min and max pairs are not usually called "" margin of error "" but rather are referred to as ranges . what domain of interest would this data be developed in . the statistical issus might get difficult because there would be no natural ordering of the ranges . is an instance of 350-550 larger or smaller than an instance of 370-490 ?"
222970,could you elaborate on the minimization problem ?
223093,you will need to be clearer about what information you want to extract from the corpus . what is the distribution you expect ?
223188,is this possibly a preprint : url ?
223313,how many levels do i and d have ?
223435,"you need some notion of covariance , and i don't see a way around that . are the estimates of $ p $ and $ q $ independent ?"
224493,"if $ z $ is normally distributed , what's the distribution of $ z a $ ?"
224508,could you possibly go into more details ?
224521,perhaps a more radical rethinking would be useful : why do you need to estimate an expectation of $ a / b $ in the first place ?
224914,( 1 ) who has the time and budget to take arbitrarily large samples ?
224933,"what do you mean by "" confidence "" ?"
225145,grad_student i think this would depend on the type of treatment . is there any reason why you could not include a $ during $ dummy and a $ during times treatment $ interaction ?
225266,1 . but are you sure you need to do this derivation ?
225313,"what do you mean by the "" weight for each cluster "" ?"
225356,what is your question ?
225389,have you seen [ my answer ] ( url ) to xi'an question ?
225426,1 . do you have a particular book or something that says this ?
225299,"i'm surprised by your question since you have sufficient points to suggest that you are familiar with cv . this means that you should know that this site is not intended to be a resource for software specific questions . so , you risk having your question deleted . there are jags user groups and support forums . why not try posting your question there ?"
225107,can you get an answer by including the group factor in the model to check whether the function $ p ( y = 1 x ) $ is the same for all groups ?
225970,"can you fill in a little what you mean by "" interpreted in the same way as logistic regression "" ?"
226321,are you saying that the correlation between the actual values and the fitted values is zero ?
226714,"could you elaborate on what you mean by "" overlap "" ?"
226768,"* i can see how this works when $ x $ and $ y $ are different physical quantities ( i . e . bmi vs . sugar consumption ) , but i don't know how to make $ a_ { 1 } $ and $ a_ { 2 } $ independent for temporal data ( i . e . the number of humans over time ) . * this aspect of your question is unclear to me - surely $ x $ and $ y $ * are * "" different physical quantities "" if one is time and one is the population ?"
226878,` but the implementation i've tried returns me an empty strings ` did you try to study the trouble ?
226902,"could you please say some more about the data , in particular how many events ( recurrences , deaths , or whatever ) there are ?"
226918,"i think it is important to clarify the levels of your education . what is the difference between "" college "" and "" bachelor ?"
227079,"what do you intend by "" non-parametric distribution "" here ?"
227116,"what exactly did you measure ( what is the response ) , what is each ` subject ` and how many subjects are there ?"
228224,what are the $ lambda_i $ ?
228348,could you edit the title to highlight the actual problem ?
228717,do the flat files follow a common structure among the reports ?
229309,your two expressions for the bias differ : you seem to be assuming $ theta $ will be close to unity . how did you estimate bias with training data only ?
229653,what is $ m $ ?
230010,what's the size of a standard deviation of your policy variable ?
230252,could you describe your notation in greater detail ?
230296,` why does the sums of squares not change when changing the coding ?
230462,what do you mean by distance to the avg . . ?
230539,have you tried a smaller learning rate ?
230772,"it is strange that the line plotting "" expected number "" of messages received is usually greater than any moving average would suggest . are the blue and cyan features perhaps plotted on two different axes ?"
230851,have you studied generalized linear models ?
230877,see [ here ] ( url ) for some suggestions . also look at some of the linked questions . what about a median with bootstrap cis ?
230994,"unfortunately , i don't read japanese , & google translate doesn't seem to work on the page for some reason . can you translate & paste in the explanation ?"
231048,what is the actual question here ?
231066,"what does "" perfect "" mean in "" gives standard errors which are almost perfect "" ?"
231170,"since the ` r ` output very specifically states ` 2 and 53 df ` on the last line , which looks very clear indeed , could you explain what * you * mean by "" dfs for $ x $ and $ x ^ 2 $ "" ?"
231165,"this doesn't make sense . "" heteroskedastic "" * means * that the variances are different . can you clarify what you have in mind here ?"
231586,i'd like some clarification after your edit . you have samples for two users u1 and u2 where some features are hashtag co-occurrence counts ?
232218,"the "" vice versa "" and your comment to xi'ans answer seem to indicate that you consider it possible to draw the outer variable more times than the inner variable , but how could that make sense -- aren't all outers for which $ 0 $ inners are drawn wasted ?"
230053,"also , please clarify "" separation "" of what with what you are talking about . are your 90 samples split into classes ?"
232359,"there is not enough detail in your question for me to understand its nature confidently , and there are typographical issues that obscure the data . are any of the numbers you have given negative ?"
232607,but you want to use em for what kind of models and what kind of data ?
233366,how about transforming the probabilities first ?
233585,"i agree broadly with hadi's answer . you should be concerned with whether the overall functional form of the model makes sense . a residual versus fitted plot and added variable plots would be higher up my list of diagnostics than checking normality of residuals . in stata , which you are using , those are ` rvfplot ` and ` avplots ` . zeros in the response are no problem to generalised linear models with logarithmic link . does your model ever predict negative values for the response in the range of the data ?"
233596,is the gamma distribution the true one ?
233625,how about a numeric tool ?
233692,could you elaborate a little more ?
234099,"ha ! i saw your title and was like "" but what is a tdnn ?"
234129,"ctd . . . and that spread increases with mean . 3 . when you say "" making 10 jumps first "" are you now comparing * times * ( time to complete the tenth jump ) rather than counts ?"
233862,"your notation is nonstandard , so please explain what you mean by "" convolution "" . normally a convolution of two functions is another function , which therefore would have a single argument , but your convolution operator involves two functions * that have already been evaluated * . your uses of $ p $ also suggest it might be a * density * function rather than a distribution function . could you clarify that ?"
234483,"you have quite a few inter-linked questions ! to start , i would suggest re-considering your first two bullets : trend & seasonality . the term "" trend "" is not necessarily limited to a persistent linear trend over the entire time series . and the term "" seasonality "" refers to any * cyclical * variation , so the period does not have to be yearly ( i just learned this term recently myself ) . so in the big picture : would you say the time series has a longer timescale smooth variation ( trend ) with a super-imposed oscillatory variation ( posssibly "" seasonality "" ) ?"
234606,"to give you a sense of why your general question isn't likely to be productive , consider that one of the best tools for assessing randomness ( or lack thereof ) is just to compress the database as much as possible . the ratio of the original length to the compressed length measures the "" nonrandomness . "" but so what ?"
234479,can you give the book name ?
234695,"( 1 ) what do you mean by the "" maximum entropy "" if a sample ?"
234738,trying to understand what the reduced dcc model is : do you want to set the garch parameters ` alpha1 ` and ` beta1 ` for each equation to zero but retain the dcc parameters in both cases ?
235096,"you seem to be conflating sample and population formulas and mangling them as a result , leading to your present confusion . for example your initial formula for variance doesn't seem to be generally correct . where did you see it ?"
235138,do you know both the true number of sales and the google number for all months ?
234663,logistic regressions tend to be well-calibrated . have you checked your model's calibration ?
235189,is it common that people refer to linear regressions as ols ?
235253,i cannot figure out what you want to accomplish . what should this algorithm do ?
235310,"if you could know just by looking at it , there wouldn't be much point to stats , would there ?"
235522,do the data points you keep have to come from the origional data set ?
235514,"it isn't clear to me what you mean by "" cannot derive to cost function "" - is it just that you do not know to convert the equation into python code ?"
235613,could you give us more information about variables ?
236129,your descriptions ( at the end ) are vague : could you provide a simple example to illustrate what you are trying to describe ?
236153,"a lot of important information seems lacking . what is the point of "" selecting a random coin "" when its behavior is completely determined by its "" known bias "" ?"
236238,"that looks like a "" bastardized "" cross of the kronecker and dirac deltas . perhaps this should be more like $ mathrm { cov } [ w ( x ) , w ( y ) ] = delta ( x-y ) $ ?"
236311,"if you say ` a ` and ` b ` are factors , does that mean they are r factors , i . e . , categorical variables ?"
236371,"is this "" pattern "" given as input or does it need to be determined from the string itself ?"
236606,"can you provide more information about your study , your data , your analyses & your goals ?"
237244,"please explain what you mean by "" stdev . "" for instance , would it be the standard deviation of the data or maybe the standard error of the mean ?"
237253,are the three trials different in any way ?
237527,it's not clear whether you are testing pre- and post- combined or separately for normality . in your last paragraph you don't define $ r $ . using a t-test some of the time and not all the time depending on some arbitrary threshold for a normality test strikes me as a bit messy . a significant result at some conventional level for s-wilk may just mean that your sample size is large enough to detect minor non-normality that doesn't matter . when you are in doubt why not use both t-tests and wilcoxon and flag if and when they give very different results ?
237940,"what do you mean by "" normalizing "" in respect of the exponential ( and how does it differ from sampling a geometric ?"
238544,"beta * can * be easily parametrized by mean and precision , see url unfortunately i do not understand what you are doing so it is not clear for me what is your question . could you describe your model in greater details ?"
238736,"because the question is lengthy and manifold i just focus currently on its "" gateway "" dilemma . ` a dataset of 59 observations described by 36 variables ` fa is a modeling technique which needs considerably more cases than variables . with 36 variables , i might recommend not less than 120-150 sample size . but think , do you really need _factor analysis_ ?"
238905,"it's hard to answer this or comment without more clearly defined terms . ( 1 ) when you say "" investment in $ x $ "" , what precisely is $ x $ ?"
238963,"so the matrices $ v $ and $ vd $ aren't going to be either lower- , or upper- triangular matrices , so its not 100 % clear to me what you mean . cholesky and svd are both two ways to take a matrix and decompose it in a way that might be useful , and will be used in different circumstances . for example , svd is commonly used in principal component analysis while cholesky is often used for solving numerical systems . you're right that the cholesky decomposition has upper-triangular and lower-triangular versions , but there is only one version of svd . maybe a little more about what you're trying to do ?"
239065,"do you know if the sequence is "" stationary "" or not ?"
239164,what are your variables ?
239539,are you looking for an informative prior ( one in which you can easily encode prior information ) or something more-or-less noninformative like a reference or jeffreys prior ?
239462,have you looked at the lme4 documentation ?
239722,does this mean 15 people each rated all three products ?
239747,is there any reason not to share the results with us ?
239804,if you have an estimate of the effect size ( difference in proportions ) and its standard error then you would use rubin's rules to combine them . is there any particular reason which leads you to prefer combining the $ p $ -values ?
239828,"first i would refit using ` method = "" reml "" , select = true ` and remove the ` bs = "" cs "" ` bits . ( unless you have a real desire for shrinkage cubic regression splines ?"
239888,"your question is not very clear . in the context of fourier analysis , the fine and coarse scale functions are orthogonal , so you cannot really represent one in terms of the other by superposition . if you are stretching / scaling the functions , then that is more like wavelets . are you perhaps asking about something more like [ super-resolution ] ( url ) ?"
239940,"why not choose $ m in [ 0 , 1 ] $ to minimize the loss ?"
240039,"what do you mean "" contains clustered observations "" ?"
240211,can you provide some context ?
240600,where did you get the formulas ?
240609,can you show the output from the regression as well ?
240717,"reject if you observe any successes , otherwise don't ?"
240837,what sort of data is it on ?
240438,huh ?
241400,"it seems like you've already answered the question , no ?"
241289,"how are you "" finding the best fit amplitude "" without using a degree of freedom ?"
241670,"could you clarify what you mean by "" similar "" ?"
241933,is this [ tag : self-study ] ?
241991,are all your ivs factors ?
242019,"it looks like some of the time the variable ( which is right skew ) is nearly independent from one time period to the next and at other times is highly dependent from one period to the next . to let us see what is going on , could you do a time series plot of the data ( and if the data are always strictly 0 , also the log data ) ?"
242280,why is it tobit ?
242515,"the answer is simply ` dnorm ( x , m , s ) / dnorm ( m , m , s ) ` , but * why * do you want it to be 1 . . ?"
243143,do you have any distributional assumptions at all ?
243673,"would you kindly adopt proper grammar with capital "" i "" , capital letters at the start of the sentence , etc . ?"
244037,"your reference to "" jumps "" suggests you are thinking in terms of the * first differences * of the data rather than the data themselves . the use of "" more "" suggests you are indifferent to the order , but are merely considering frequencies of differences . why not then describe the distribution of first differences ?"
244173,you mean that you get 1 precision for each document ?
244450,possible duplicate of [ dummy coding for regression ?
244449,"could you edit the question , further clarifying what exactly you are trying to achieve ?"
244621,my suggestion would be to use some-kind of machine learning algorithm on the second label . then you can deduce the first label from the results you got for the second label . why do you want to use a clustering algorithm ?
244711,i am having difficulty understanding this version of the law you are using . could you work out a tiny example for us ?
245116,"it's hard to figure out what you are trying to do . if the $ theta_i $ are parameters , the maximum likelihood solution is $ hat theta_i = y_i $ and $ hat sigma ^ 2 = 0 $ . shall we presume you know the $ theta_i $ then ?"
245221,why shouldn't it ?
245867,"i'm having trouble following this . what is the "" thermosensible part "" of the data ?"
246226,are you asking about how to do that with r ?
246464,the question is unclear . you're stating that you have a large ( countable ?
246586,"this isn't terribly clear . also , be aware that asking for r code / help w / code is off topic here . if you are just asking how to conduct tests of simple effects given an interaction , that has nothing to do w / r necessarily , although you may happen to have conducted your analysis in r . what is mass here ?"
247538,did you make up these numbers ?
247855,i have edited the formulas in from the images you linked to so that the question is self-contained . please check them for accuracy . more importantly are you absolutely sure you have the model and the formula correctly matched up ?
247971,i am not sure about what you are asking . do you want to know whether or not age is related to prevalence of uti ?
248069,. . . reading where ?
248250,can you paste in an example dataset ?
248256,"this doesn't quite seem like a good fit for the site to me . i think i would call this * primarily opinion-based * , which is a reason for closing . as our [ tour ] states , "" avoid questions that . . . are likely to generate discussion . . . "" . ( to be fair , we have sometimes let questions like this slide as cw . ) could you edit this to make it fit better w / the nature of this site ?"
248266,could you describe the data you're plotting here a bit more ?
248433,can you get nicer residuals if you specify the ` frequency ` of your time series to be 23 or 22 in place of 24 ?
248715,"why freeze the embeddings , and why add start / end tokens ?"
249053,what is the 95 % ci of b ?
249080,"i'm confused , do you have data on how many people in each group read the next issue ?"
249147,"could you please explain how "" chi squared values of paired values of the parameters "" are computed ?"
249249,what is ` e ` ?
249310,"actually there about as many variations on the bootstrap as you can possible imagine . . . typically you bootstrap the t statistic , and use the distribution instead of the theoretical t distribution . i would like to add that the bootstrapping itself does not save you from small sample problems , as the reviewer appears to think . can you provide more context ?"
249618,"in the anova , which are the levels of the two factors ?"
249822,a truncated normal distribution for spherical or polar coordinates is unnatural . you won't find any analytic formulas . have you considered using a [ von mises distribution ] ( url ) instead ?
250372,what are you trying to do with the daily data ?
250451,what does psd stand for ?
250500,"the formula for variance is difficult to interpret . if it refers to a * parameter * of the model , it makes no sense , because it involves the $ u_i $ themselves ( which evidently are the data ) . that would suggest it's some kind of * sample * variance--but then it doesn't seem correct . please explain what these $ u_i $ actually are and what you really mean by "" variance . "" what do you mean by "" the variance is not matching with the mwu test "" ?"
250624,would you like to clarify if url answers your question ?
250656,""" what is the best way to cluster those models ?"
251051,what is the difference between 2 ) and 3 ) ?
251058,"what * is * "" density "" in genomic data ?"
251206,according to wikipedia frank benford was the second person to observe this phenomena . but it was named for him anyway . in my example divide by 210 and you get a discrete distribution for the lead digit of this data . the point noted was that 1 has by far the highest proportion . the distribution is not unique . it depends on the collection of numbers . did you pick a set of data and compare to the distribution benford used ?
251839,"when you say "" * . . . implies that we have n m independent and identically distributed random variables * "" are you saying that that the $ a_i $ variables are mutually independent ?"
252049,"will you be using openblas , or a parallelized matrix library ?"
252234,why do you want to use fisher's exact test for this ?
253060,what do the indices $ i $ and $ j $ refer to ?
253088,what do these plots represent ?
253149,why would you expect it to take a smaller number of iterations to converge ?
253347,"not related to the question ( i had a go at a brief answer ) , but for readability , howaboutsomespacesinyourcode ?"
253418,"when you say "" dynamically increases or decreases the difficulty between levels each day , "" how is this done ?"
253427,if i were in your place i would first try to get a single model to produce acceptable results . do your predictors have workable distributions ?
253604,what variables are in the regression ?
253791,can you explain a bit further what your scientific hypothesis is ?
253821,have you considered cohen 1969 ?
253825,where's the plot ?
253949,what are your estimates for the mean and variance ( assuming zero-inflated poisson ) ?
253955,jan can you provide your plots with equal scales i . e . where each plot has the same range of values for each axis ?
254155,do you mean this url ?
254273,"i noticed that you are using the regression tag . are you wanting to use regression specifically or does your question apply more broadly to all "" machine learning "" methods as your title implies ?"
254358,why not ?
254666,do you know why you were told that the chi-square test cannot be applied ?
254990,do you know the special properties of the multivariate normal such as the fact that every linear combination of the coordinate variables is a univariate normal ?
255061,"also , are you examining one-step-ahead forecasts only ?"
255096,have you tried simulated annealing or genetic algorithm ?
255456,"can you say a little more about the study , their data , & there analyses ?"
256331,can you share your working for the autocorrelation of order two ?
256335,perhaps you could edit your post to show us the output ?
256516,what is your question ?
256591,i am not sure that i understand your post . can you please explain what testing generalization viability of the clustering method means ?
256890,why do you want to fit the interaction between a continuous variable and a categorised form of it ?
256877,why is one test agecategory3 and the other agecategory ?
257098,it is not clear to me what the varying abbreviations you used stand for . could you write them down in full ?
257110,are you saying you want to compute the standard error of a mean of a mixture distribution from the statistics of the component distributions ?
257227,1 . please correct the count in your first sentence . presumably you mean four things . 2 . you should make explicit whether the time variable is the time at which it occurs or how long it occurs for . for convenience it would help to give units ( seconds after the start of the observation period ?
257258,"the reference you quote talks about * clipping * the weight vectors of * individual * hidden units versus * penalizing * based on the * whole * weight vector , which then apparently includes the weights of * all * hidden units . so the weight vector $ w $ is not the same in both cases , as you seem to think from the way your question is formulated . maybe you can try to edit your post and formulate your question concretely ?"
257672,which is it then ?
257946,"gaussian models minimize quadratic losses while laplace models minimize linear losses . the latter increase much more rapidly near their optima . they result in predictions of * medians * rather than * means * . especially when response distributions are skewed , the two can be very different . for instance , if you're analyzing risk to human beings , do you want to protect the largest * number * of people or do you want to minimize the * total harm * ?"
258567,i'm a little confused by the notation ; are the $ z_ { ij } $ iid ?
258853,i guess maybe it depends on how the original data set was collected . is it a random sample ?
258855,can you explain more about why you want to exclude zeros ?
258999,have you considered other types of analysis that might be better suited to a 1-5 scale ?
259240,at this point you haven't described the within-group heteroscedasticity structure in your model yet . check ` ?
259376,"i can't make much sense of this , because i cannot see how an $ n $ -variate distribution could in any meaningful sense be "" proportional to "" a $ k $ -variate distribution . could you please clarify what you mean ?"
260104,"i'm still confused about what you are trying to ask , even after the edits . what exactly are you trying to do inference on ?"
260425,do you mean your model is $ y_i = b x_i ^ a epsilon_i $ ?
260884,"can you filter out the spikes with some sort of lowpass filter , and use the filtered version to compute mean & standard deviation that you need for normalization ?"
260909,"to clarify : you have 20 patients , and for each patient you have 500k 10-dimensional measurements ?"
260914,can you say a little more about the situation you are modeling ?
261177,"what you ask is unclear , because $ operatorname { var } ( x ) $ is a * number * : it does not have a distribution . are you perhaps referring to an estimator of $ operatorname { var } ( x ) $ from a * sample * ?"
261188,"i think i understand what you are asking for , but i'm not at all sure that you really want to analyse the ratios . what is the question that you would like your analysis to help you answer ?"
261493,"it is unclear what you mean by "" these types of exercises . "" apart from that , you ask * five * separate questions : the one in the title , questions ( a ) , ( b ) , and ( c ) , and your "" doubts . "" which one do you want us to address ?"
261646,what is your code so far ?
261676,now in terms of your question : could you spell out more of what you mean by categories ?
219937,is there an established gold standard for these studies ?
262658,instead of probability of what ?
262801,can you tell us more about the contest ?
263015,"could you describe what "" fme "" actually does ?"
263604,is it meaningful to include a centerpoint ?
263652,is the area of interest fixed in all images ?
263670,"if you could find an objective reason to propose $ -999 $ rather than , say , $ -0 . 009 $ or $ -9 times 10 ^ { 30 } $ , then maybe you could free your proposal from the impression of producing completely arbitrary data ( with concomitant analyses that would be equally arbitrarily and therefore useless at best ) . what reason ( s ) do you have in mind ?"
263679,can you provide the output from the summary ?
263778,can you give the whole code in r ?
264111,can you also add code showcasing how the estimator fails ?
264319,maybe you could show us your code ?
264974,factor analysis give you latent factors . is that what u want ?
265048,maybe he used some other method ?
265079,"welcome to stats . se ! please take a moment to view our [ tour ] . the sort answer is , yes you * can * ( i am also not entirely sure if the idea is statistically sound ) . will it convey the information in a meaningful and impactful way ?"
265202,do you know the max no of borrowers possible ?
265217,"yes it is the model that is closest in kl-divergence . i'm not exactly sure what you mean by "" predictive metrics "" , but bayes factors simply report the ratio of the density ( or mass ) of the data under the prior predictive distribution , so perhaps it is not surprising that it is identical to "" predictive metrics "" ?"
265662,what about zero inflated negative poisson ?
265878,"michael presumably you mean [ grace * wahba * ] ( url ) , but given the broad extent of her work you should probably narrow the scope of your comment down a bit ( across all the decades she's been publishing , she'd have to have published over 150 papers , i'd think ) . did you perhaps mean to refer to the book * spline models for observational data * or did you have some particular papers in mind ?"
266208,have you looked at the book by bradley efron and rob tibshirani on the bootstrap ?
266487,in order to choose the correct statistical test can you give us some more specifics for the entropy data . when not under attack do you know what type of distribution the entropy values have ?
266720,"can you provide a little more context , or an example to illustrate this ?"
267217,hint : what is the posterior predictive distribution of the poisson-gamma model ?
267300,ratios are not automatically between 0 and 1 ( e . g . the ratio of male births to female births is above 1 ) . do you mean to say that your observations are proportions between 0 and 1 ?
267405,how do you use the one-vs-all predictions in order to predict the concept ?
267474,shouldn't the output have the result of likelihood ratio test ?
267749,is your unit of analysis the person or the country ?
267750,i don't think you should call this [ logistic regression ] ( url ) . can't you use ` nlme ` with a logistic function ?
267759,two things . . . can you post ( giving credit to the authors ) the plots or charts you are referring to ?
268053,have you looked into url ?
268024,what are you asking about ?
268181,"what is the tolerance please , that is , is it 5 % , like a 95 % confidence interval , or something else ?"
267848,but what kind of outputs did you receive ?
268352,i think you ought to be able to do it with a messy numerical integration . or just use simulation . do you need a closed-form solution ?
268365,is this an assignment for school ?
268669,rmse is only a measure of model performance insofar as the model's utility in predicting an outcome . but models may be used for inference as well . is your question about prediction or inference ?
268894,have you tried using chi-square ?
267327,can you provide a [ reproducible example ] ( url ) ?
269104,should this be in math overflow ?
269282,"* * yes , there are several tests you can use . * * for an introduction into why this might be the case , please see url which deals with a simple ( but illustrative ) case of your situation . moreover , repeating the composite measurement * is * relevant : that would enable you to perform a routine anova to test whether the * means * in each group differ significantly--and isn't that exactly what you want to find out ?"
268993,the total value of all your items is fixed . do you mean that you're allocating every item to a group and the total value of every group must be close to 50 ?
269784,"what could it mean to be "" a discrete rv that follows a normal distribution "" ?"
270167,are the intercepts estimated from two independent datasets or not ?
270382,it's not really clear what you're asking for . there are infinitely many such parametrizations . what's your end goal ?
270992,"could you add the intercept and coefficients of the model to your question , or even better : the code required for others to replicate the problem ?"
271051,"what would you mean by "" parameter space "" ?"
271404,what do you mean by sample product moment ?
271449,"the collinearity represents the fact that x1x3 is partly interaction and partly x3 . it follows that it will correlate with x3 . centering your variables helped but unless they are perfectly symmetric there will be a correlation ( i think , but haven't considered it carefully ) . that's why you should control for x3 if you are interested in the interaction . what about collinearity in your specific analysis concerns you ?"
271511,i don't why it's so hard to understand . what about you just move the log to the other side of the equation ?
271613,"the terminology in this question is confusing . it sounds like you are using the term "" probability space "" to refer to the sets of values that can be attained by random variables--that is , their * ranges . * and how could either of these discrete variables possibly have probability "" density "" functions ?"
271667,provide some link or reference to give more context of what you're looking for ?
272426,can you draw a graph for you network like your question ?
272416,i do not think symmetry is the issue here . can you edit your post to let us have more details about what you understand and what is puzzling you ?
272468,are you just trying to find if there is a difference in the ctr or cr between two different types of kpi's ?
272530,what are we looking at ?
272761,a large number of factors have a play here . what are the locations and shapes of the areas ?
272811,"please explain what you mean by "" data set "" : could you perhaps mean the same thing as * observation * or * data point * ?"
272949,"sorry to bump this , but did you ever find out or does anyone know ?"
134247,"in the first inequality of the actual question ( involving the max ) it appears as if the two terms are identical . based on the next inequality , shouldn't the second term of the max have kl ( p , q ) in the denominator ?"
273446,what do you think you should do ?
273779,please explain how you managed to estimate a ccdf down to $ 10 ^ { -13 } $ when you have only $ 10 ^ 6 $ ( or maybe $ 10 ^ 5 $ ?
273788,what does 90 % markovian property mean ?
274250,"you seem to be asking for two completely different things : ( 1 ) "" it is not important what happens for values between $ 10 ^ { 3 } $ and $ 10 ^ { 5 } $ "" yet ( 2 ) "" i would like the model to be also precise for small values . "" could you clarify what you need , preferably a little more quantitatively and less abstractly ?"
274565,what is the question ?
274762,histograms are for continuous data so this is still rather confusing . it makes me wonder whether your data are at least ordinal . is there a reason you want to avoid chi squared ?
274962,what exactly are you asking ?
275070,"please explain how you propose to measure "" smaller "" : would it be * contained within * ?"
275105,"you lost me at the outset with your notation and i really don't want to try to infer what it means by reading everything else : in the sequence "" $ ( theta_ { n } ^ { i } ) $ "" what do the * two * indices $ i $ and $ n $ refer to ?"
275314,weighted least squares ?
275580,how does the rayleigh distribution enter into this problem ?
273370,"1 . a sum of marginally normal random variables is not necessarily normal ; if that's what your question is , it's [ a duplicate ] ( url ) . a sum of * jointly * normal random variables will be normal , however . . . . 2 . what is the basis on which you assert that your * data * arise from a normal distribution ?"
275876,what is fp a false positive rate ?
276046,hint : do you want a one-sided or two-sided test ?
276461,what do you mean by increasing number of classes ?
276515,perhaps [ mutual information ] ( url ) is what you are looking for ?
276475,this could be an interesting question but you need to tell us ( much ) more about the data . maybe you can show us a small excerpt ?
277110,does the iman conover method have to come into what you're asking for ?
277044,"so , what is the difference between the one explanatory variable and all the others which are also explanatory ?"
277350,"you say that the target distribution is normal , but one of the components is a variance parameter . how is the target distribution normal then ?"
277498,"you already removed a3 and b2 , why do you want to remove even more ?"
277531,design of experiences---do you mean design of experiments ?
277795,"it's not clear precisely how one should ignore it . should we erase all subscripts and superscripts involving $ n $ 's or just the slash superscripts , for instance ?"
278196,"there is very little information , can you augment ?"
278415,how much data do you have ?
278818,"what you mean give it "" meaning "" and "" standard error relation "" ?"
279539,could you post some code and results ?
279805,can you link to the book you are referring to ?
279630,how did you do the feature selection ?
279956,what is your goal ?
280035,the question is asking about using a * working origin * ( and scale ) - it is in effect asking about going back to the original tabulated data . the text will have already explained what a working origin is ( and then it should be clear why you get negative values ) . so what did the text say about a working origin ( and scale ) ?
280480,"yes , thank you . but i do not understand why you write "" it has no $ y $ in it . "" isn't it the case that $ hat beta $ is a linear function of $ y $ ?"
280811,ok . let's say 200 ?
281319,could you simplify the program codes into math equations ?
281541,"are you using p to represent 1 / variance then you have given the formula for a n ( 0 , $ sigma ^ 2 $ ) density ?"
281758,what are the axis of these graphs ?
281783,"is $ k $ continuous or does it take discrete values like - 2 , 3 , 4 , etc ?"
281867,"but i also don't quite understand what "" accession "" is . you said you want to test it -- so it should be a fixed factor probably , not a random one ?"
282306,"the rank-sum , at least , is not a test of equality of medians . it seems to be fairly accurately described at your link . from my reading of how it implements mood's test , you should have no counts in either sample below the grand median , so it should not be giving significance ( if it gives a p-value at all , it should be 1 ) . can you give a table of how many 0's and 1's you have in each sample and show the results you got ?"
282311,what are the parameters you want to estimate ?
282332,maybe you can tell us a bit more about your study and give us context ?
282194,what exactly is not appropriate for you in the second question ?
282553,"there is no such thing as a "" normal distribution with unequal variances . "" could you be more specific and accurate about the model for your data ?"
282567,"can you say something more of the data , what variables do you have , how many ?"
282711,"m4 uses the data "" area . no . al . tx "" and m2 uses the data "" area . no . alaska "" . how are these data sets different ?"
283225,"could you please explain what it means to "" have arbitrary distributions over the state space "" ?"
283524,"why are you using ` classifier . fit ( x , y_train ) ` in the first example and ` classifier . fit ( x_train , y_train ) ` in the second ?"
283566,"crossvalidated is not a code review nor a "" what's wrong with my code ?"
283628,is higher better for each metric or is lower better for each metric ?
284124,"are the values * truncated * , meaning if a true value is greater than 1250 it * is never seen by the analyst * , or * censored * , meaning if a true value is greater than 1250 , the analyst only sees a 1250 ( hopefully with an indicator that the true value is greater than 1250 ) ?"
284423,"remark : the property on $ x $ you are referring to is known as [ exchangeability ] ( url ) . the assumption $ p ( y vert x ) = p ( y vert x_ ) $ is automatically true if $ x $ and $ x_ pi $ have the same law , which is what you want to express with the second part of the assumption : $ p ( x ) = p ( x_ ) $ , am i right ?"
284512,can you please add a plot of your data ?
284522,"if you can elaborate on your objective ( "" make a statement about race and fire risk "" ?"
284960,could you please * describe * the test that this software is performing ?
285762,what does this question have to do with $ y $ or $ epsilon $ ?
286132,"could you clarify what you mean by "" covers "" ?"
286142,"just a note about functional form here . a normal distribution implies that learning is happening , that is prior errors will vanish . it doesn't appear that prior errors are really vanishing . differencing isn't going to matter because your model has an incredible amount of path dependence . is there a natural explanation for this ?"
286212,interesting . the second result is also very different in quality . have you verified it is the initialization ?
286433,"how exactly do you "" call up the best model's beta coefficients "" ?"
286443,""" found "" or "" find "" ( in a few places ) ?"
286737,could you edit your post to include the output you are looking at ?
286754,can one safely assume that you've created a training data set ?
287563,why does everything interact with id ?
287852,kolmogorov-smirnov test could be what you're looking for ?
288183,this looks like the posterior predictive distribution for the conjugate bayesian model of the multivariate gaussian distribution . is it that ?
288321,is $ u_i $ indeed dependent on $ i $ ?
288362,why does a low pseudo- $ r ^ 2 $ make you think the model is poor ?
288552,` is it correct to assume that any binary classifier will not generalize well ?
288602,you need to say a lot more about your situation & your data . what are your variables ?
288653,why is day a factor ?
288718,"you state at the beginning that your goal is to test the effects of a and b , but your questions are all based on analyses that say that a & b have no detectable effect . could you clarify what you are trying to achieve ?"
288939,"could you provide a more detailed explanation of what "" multi response probabilities "" might be and why the transformation you seek isn't exactly the same as the one you write down for $ pi_ { i , j } $ ?"
289110,"in "" direct "" model you check if measures change with time ( time is your independent variable ) . what do you want to check in "" indirect "" model ( what is your independent variable ) ?"
289308,do you expect some specific properties of $ f ( v ) $ ?
289457,where did the parameter $ mu $ come from ?
290567,"note that the "" top "" of the band of residuals is parallel to the line at the bottom . the line at the bottom is cause by the "" 0 "" values . is there a hard maximum on the response ( "" vehicle miles travelled "" ) in your data set ?"
290804,"one immediate comment might arrive : why are you speaking of , say , tetrachoric correlation , which is a crutch to "" revive "" former unbinned variables when you , of a sort , have those unbinned variables at hand ?"
290844,the question might appear interesting if it were not so much r-oriented . can you edit it - at least add commenting to your code - in order make less software-specific ?
290955,"if the dots are cumulative arrivals , why do they decrease sometimes from one timepoint to the next ?"
291197,possible duplicate of [ are there any models that can handle out of sample features ?
291269,"it's not clear to me the distinction you're drawing in the last sentence . "" more variable in its sequence "" is clear enough , i think ( you seem to mean that $ sum_t ( y_t-y_ { t-1 } ) ^ 2 $ is larger , which it clearly is ) , but it's then not at all clear what "" qualitatively more variable "" means if it's intended to mean something other than that . do you just mean $ text { var } ( y ) $ - ignoring order , as with an ordinary sample variance - is larger ( due to the more equal proportion of 1's and 0's , as you suggest ) ?"
291566,"dbscan explicitly computes outliers clusterwise . therefore ( 1 ) treat noise as a new partition is not a good idea . further if you ( 3 ) reassign the noise into the existing ( nearest ) cluster , you can directly use clustering algorithms which do not detect / consider outliers . finally ( 2 ) remove outliers before evaluation sounds most reasonable . who does not recommend it and why ?"
291642,questions that are only about how to use software are generally off topic here . can you edit this to make it software-neutral & more about the statistical issues involved ?
291653,"can you assume a , b are independent , do you know there correlation , or can you estimate the correlation from the same data used to estimate a , b ?"
291736,do you have the original kernel and bandwidth ?
291859,can you provide any extra information on what your task is and what the data set is composed of ?
292008,""" the data is categorized into six classes . "" do you mean there are six classes of subject , or six classes of observation ?"
292098,usually we refer to pade * approximations * . in this case are you saying the pade solution is exact ?
292184,what specifically do you want to know ?
292273,"if you have the survival function $ s ( t theta , x ) $ or the cumulative distribution function $ f ( t theta , x ) = 1-s $ in closed form , then you can use those instead of the $ exp ( -h ldots ) $ term . but i assume you do not have those , either ?"
292497,this is in danger of being closed if you appear to be asking for code in spss or amos . can you rephrase it to emphasise the statistical question about whether you can use the variable ?
292505,is this for some class ?
294527,( 1 ) how do you decide what each $ n_i $ should be ?
294550,"note that a cnn without relu but with max-pooling is still nonlinear because max is a nonlinear function . when you changed max to avg pool , was that before or after you removed relus ?"
295016,"( 1 ) you've used capitals to write "" hyper-parameter optimization "" and deep learning . does this indicate that you have a specific algorithm or method in mind , or do you mean to speak generally about hyperparameter search ?"
295230,"could please you edit to fix the spelling of "" dependent "" ?"
295363,"just to clarify , are you asking whether any distribution can be written in this form , or whether any family of distributions can be written in this form ?"
295458,"at present , this id probably * too broad * to be answerable . can you provide an example situation ( a small dataset , & some results ) ?"
295512,could you provide a few rows of sample data ( with headers ) to give an idea of what the data looks like and what it means ?
296087,do you mean 38 tables of size 9 and one table of size 8 ?
296038,have you trained your instrument to recognize dogs ?
296611,"i feel this might be an interesting topic , but i cannot really make clear what the problem is ( please provide some context and define all parts , even if they are a random variable ) . additionally i am not sure what your exact * question * is . you want to have some replacement 'e' where ( ex / by ) = ( cx / w ) / ( dy / w ) , but further down you talk about some kind of performance as well . where must the focus of a good answer lie : the mathematical formula or a kind of performance statistic ( which one then ) ?"
297027,is this the extent of your data in terms of attributes ?
297304,"if one indeed needs to operate on so widely dispersed numbers , log-transform might actually be the best starting step , purely because of computational reasons - i . e . precision loss when adding floating-point numbers . maybe it could be avoided by assuming some distribution for $ x $ , i . e . lognormal or exponential ?"
297399,"you need to tell us more about your data . you say that you don't have data , but aren't the parameters some kind of data ?"
296990,"there may be novel and interesting scientific results lurking in the upper end of your data distributions . suppressing them in the analysis , either by transformation or--far worse--outright removal as "" outliers , "" would seem counterproductive and contrary to the scientific impulse towards discovery . instead of working to process your data in some procrustean manner so that they will fit an intended formal analytical procedure ( * i . e . * , anova ) , why not * explore * them to find out what might actually be going on ?"
297444,( 1 ) why would you want to use gls for this in the first place ?
297486,"this is such an abstract question that one is led to wonder , why would your description differ from any other description of a probability ?"
297872,"i'm not entirely sure of the answer but a few thoughts that come to mind . how correlated are tv_spend and sem_send , if the variables are highly correlated it might be that the model is having a hard time distinguishing between the two variables . also although the interaction maybe "" significant "" is it meaningful ?"
298138,should this have the self-study tag ?
298177,"1 . re first sentence . no , for two reasons : ( i ) we assume they're equal for poisson regression , not proportional ; and ( ii ) it's the * conditional * variance that's proportional to the conditional mean . 2 . why are you transforming rather than fitting the poisson regression ?"
298407,your question is unclear to me . what do you mean by * the intersection represents the differences associated with having condition a * ?
298669,should this have the self-study tag ?
298687,"welcome to cv . since you re new here , you may want to take our [ tour ] , which has information for new users . what does gwr stand for ?"
298905,could you provide examples of the conflicting results you have obtained ?
299034,"just to clarify - if $ s_i ( t_1 ) $ is random , then one or both of $ a_i $ and $ b $ are random . which is it , or is there something else going on ?"
299235,[ back up . ] ( url ) what do the samples and vectors represent in the first place ?
299590,i think you are going to have to edit your question with more detail to get any help with this . what stages did you go through to get to this point ?
300102,"in your text , you must be mistaken : you have both ivs as between subject factors , don't you ?"
300444,"1 . "" kindly share your thoughts "" is too broad an invitation . please stick to specifics . 2 . did you read the help ?"
300539,do you know the 'true' value of the samples ?
300609,"doesn't work well in terms of predicting held-out data , interpretability of the topics , or something else ?"
300900,"what do you mean with "" different format of model ?"
300919,what are you trying to compare ?
301727,"i take it you have these data for all possible $ t $ , not just a specific $ t $ . ( if you do not , it looks like your question would be unanswerable . ) put a little more abstractly it asks , "" how can i calculate a probability given that i have three ways to find its value from historical data ?"
301995,did you recognize this as exponential family ?
302556,please be more specific what you mean with weighed cross entropy . are you asking if it is equivalent only with regard to this specific metric ?
302557,so that we don't have to decipher your code ( which seems almost irrelevant--isn't it just graphing stuff ?
302674,what does your formula mean when $ x gt y $ ?
302701,could you add your country ?
302924,how do you get the ` plm . gmm ` object ?
302976,"what exactly do you mean by , "" check if the squared residuals are independent "" ?"
304301,can you be more concrete about what your dependent and independent variables are and how you computed the average ?
304452,weren't this topic already considered ?
304608,"do i understand correctly that $ y' $ is a ( known ) constant , so that the aswer to ( a ) would depend on $ alpha , beta , y' $ ?"
304634,"what is "" score "" ?"
304719,there's no specific question here . could you clarify what help you need ?
305930,"i've upvoted your question as i'd like to see a detailed answer to it as well . however , i would like to note that confidence intervals are not always calculated the same way , and in some situations , some ways might even be considered better than others . consider the agresti-coull adjusted wald confidence intervals ( compared to the regular wald cis ) for proportions , or likelihood profile cis compared to regular confidence intervals from regression models . as such , it is the context and goal of the ( desired ) statistic which are required to decide on 'suitability' . could you elaborate on this ?"
306075,what is a losing coin ?
306204,scaling to zero variance ?
306301,"how did you find any data to train on , given that 100k test samples must exhaust all 100k records that you have ?"
306581,that doesn't like something that can be solved with 30 data points . you're trying to infer a particular graph structure out of 2 ^ { n choose 2 } possible graphs given 30 examples ?
306764,what form will the new data coming in have ?
306778,"1 ) huber loss is not differentiable at the hinges , 2 ) why do you think absolute loss is sensitive to noise but the other two are not ?"
306900,"at the outset you seem to say two contradictory things : you have a "" sample probability distribution "" but "" not an actual data sample . "" could you please explain , then , what a "" sample probability distribution "" might be and how you arrived at it ?"
306924,is there any particular step you cannot justify ?
307066,"you just want people to see that these combinations exist , or you want to show them something about each combination ( such as a fit metric for a model w / that combination of hyperparameters ) , or want them to compare fit metrics w / different combinations , etc ?"
307160,"i think we need more detail here as , on the face of it , you do not have the information you would need to generate a survival curve from each study . can you expand your question with more information ?"
307216,can you explain a little more what are the unnormalized values ?
307644,"without the 2 there , $ sigma ^ 2 $ would be "" twice-the-variance "" , which is an awkward name , isn't it ?"
308287,what is the regular method ?
308672,"please type your question as text , do not just post a photograph ( see [ here ] ( url ) ) . what exactly do you want the sd of ?"
308897,"as written this doesn't make much sense to me . correlation by definition assumes that there is a paired ordering between your variables . so if $ x $ increases , then $ y $ tends to increase too , * when considered simultaneously * . in your example , i don't see any indication of such a pairing : you just have a list of categorical variables along with their values . so what do you mean by correlation here ?"
308870,a neural network with all 0's would give you $ nn ( x_ { new } ) = 0 $ . so are you sure you want that to be your metric ?
308953,is your confusion around how to plan a study around desired precision ( or error margin ) or why that type of study is used rather than a classical inferential study ( using power calculations ) ?
309125,"the question is under-specified . to talk about root-n consistency you have to be talking about an infinite * sequence * of lassos as n increases , but you haven't given any details about how this sequence is behaving . for example , what's $ lambda $ doing as $ n $ is changing ?"
309267,"the vagueness of phrases like "" starts and stops at particular times "" and "" another different threshold "" might make this question difficult or impossible to answer . could you be more specific about what you mean by this and , indeed , what kind of "" random walk "" you are talking about ?"
309419,"really $ x_k $ depends on $ n $ and should be written $ x_ { k , n } $ . shall we presume you want to demonstrate that for any * fixed * $ k $ , the limiting distribution of the standardized version of $ x_ { k , n } $ is standard normal as $ n to infty $ ?"
309456,"could you describe in greater detail : ( a ) your data , ( b ) the "" complications "" you mention , ( c ) your exact procedure ( e . g . how did you update your prior ?"
309507,you are using only one training example . how do you expect the network to learn ?
309547,what's the relationship between $ a_1 $ and $ a_2 $ ?
309848,what does the plot show ?
309854,could you please explain what is being plotted on these graphs ?
309920,"btw , why are you using ` glm ` function to fit a linear model ?"
309939,"should the predictors in the first equation be $ x_i $ instead of $ x_i , _j $ ?"
309625,i think you might do better on a programming site ?
310223,"are you interested in a specific supplier , or are you just wondering if there is any supplier that is preferred to the others ?"
310243,"sorry for the silly question , but did you try to contact the package owner ( first ) and david spiegelhalter ( second ) ?"
310325,ricardoc url maybe you're thinking of the half-normal ?
310370,to what formula do you refer ?
310393,is accuracy a reasonable metric for your application ?
310434,did you read the help pages for qqplot ?
310374,"what is the goal of your analysis , and why does it necessitate removing correlated variables ?"
310632,what is your question ?
310668,could you please explain the variables in your graphic ?
310861,"where exactly did the values in your "" table of chi-squareds "" come from ?"
310981,"if you have answers already for 1 ) and 2 ) , they most likely are based on an _unstated_ assumption about the _joint distribution_ of $ x $ and $ y $ . could you _edit_ your question to make this assumption explicit ?"
311045,how could you look at whether events 1 and 2 are correlated within each year ( rather than over years ) if both are only observed once ?
311227,"i just don't understand what distinction you are making with the phrase "" mathematically related "" : * all * models posit some such mathematical relationship ! could you tell us more about $ beta $ ?"
311542,where is the intercept in your output summary ?
311616,"there is no question , i assume you want ton know whether you can include such features ?"
311869,"could you say some more about how many cases there are with 'occupation' for each species ( or , if 'occupation' is more frequent , how many lack 'occupation' ) ?"
311917,"1 . it would sure help to know what are $ s $ and $ d $ and where the problem comes from . 2 . you want to visualize $ { mu_p p in s ^ d } $ , right ?"
312079,there is nsuch thing as zero component in plsr . can you check it again ?
312190,why are you trying to discretize a continuous variable ?
312339,"i will not be checking your code , but will note that traditionally bic is computed as "" lower is better "" form , so why did you select the highest value ?"
312449,please double-check the question you quote . is the alternative supposed to be $ p 0 . 40 $ rather than $ p 40 $ ?
312473,can you explain in more detail what you mean by mixing and why you are interested in using these combinations of kernel methods ?
312526,"sounds like you are after a hierarchical bayesian model . could you tell us more about your data ( e . g . give a small example ) , so that we can understand it better ?"
312992,is this a real homework ?
313504,"quick question : is it true the the $ x $ 's and the $ y $ 's are coming from the same "" generators "" ( i . e : $ x_ { ik } $ ~ $ x $ for every $ i $ and $ k $ and $ y_ { ik } $ ~ $ y $ for every $ i $ and $ j $ ) ?"
314517,"if you're finding esa too tricky ( and it can be quite dense ) , can i recommend maybe having a look at "" an introduction to statistical learning "" by robert tibshirani and trevor hastie instead ?"
315297,so how did you compute the correlation matrix given that you have missing values in the data ?
315713,"would there be any utility or usefulness in fitting the sum of 1 / 2 of each , that is , fitting y = ( a1 b1x1 ) / 2 ( a2 b2x2 ) / 2 ?"
316248,"how do you define "" belonging to the same distribution "" ?"
316884,and what is $ y_t $ ?
316898,did you actually read the answers ?
318674,"do you intend that "" / "" means a conditional probability and "" bc "" refers to the conjunction of events "" b "" and "" c "" ?"
319512,how do you guarantee this is a true statement ?
319954,"if you take a random sample from the vector , it follows a gaussian mixture distribution ?"
320808,related : [ can we find a distribution of the conditional expectation ?
321089,could you please edit this question to clarify what you are talking about ?
321630,"can you show how you egened this variable "" did "" ?"
321748,"are twins in the same group , or different groups ?"
322095,does $ x $ refers to $ x $ in your equation $ ( 1 ) $ ?
322102,what does your data represent ?
322343,"multivariate regression is probably not appropriate for count data . when it comes to that , check out poisson regression . because it is impossible to get something like "" 2 . 57 orders . "" it is hard to say without looking at some code / results / diagnostic plots . is the decision tree working out alright ?"
322618,why would you want to guarantee that $ s ( b ) $ is positive or negative ?
322768,"numbers in "" null error "" column are larger than 1 , therefore not probabilities . how did you create that table ?"
323406,"welcome to the site ! this site can provide useful tips on selecting the models and interpreting their output . other reasons will provide specific instructions on implementing the models , such as in r . can you say a bit more about how birds are "" counted "" ?"
323530,"there is no naive bayes theorem , there are naive bayes algorithm and bayes theorem . what exactly is unclear for you ?"
324489,can you give more details about the variables and the research design ?
324539,"the original question was closed as unclear but i don't think the most recent edit has helped clarify things - "" why fitted probabilities occur "" should probably say "" why fitted probabilities of 0 or 1 occur "" ?"
325046,could explain why do you sum over i in you attempt ?
325116,what is meant by $ alpha_i in mathbb r ^ { 1 times 1 } $ ?
325139,isn't this just normal clustering ?
325157,"i assume you have the same sample size for all your comparisons , is that true ?"
325047,"setting ` n_estimators = 3 ` means you're only training 3 trees . this is a very small number , and should be something more like 100 . given the randomness of each tree , the measured accuracy of the overall model could fluctuate wildly from run to run . so , it seems hard to read too much into the accuracy here . "" the saved model trained on 2 million samples is 50 % larger "" what exactly are you measuring that's larger ?"
325284,"can you clarify what the observations are - do you observe $ s $ in discrete times , both $ s $ and $ r $ , something else ?"
325355,please explain the purpose of comparing likelihoods : what meaning does this have ?
325458,"this seems to require expertise in psychology to answer well , but nothing in your title or tags is flagging that to attract attention from experts ( not me ) . 27 % seems utterly arbitrary as a cut-off . if you can't give a reference or an argument for that , it's hard to know what to say , except crucially why do you need to group here at all ?"
325523,"* which * "" 2 aforementioned vectors "" are you asking about ?"
325728,"this is a pretty problem-specific issue , and generally bandit papers are devoted to how to pick these terms in order to minimize regret given a certain prior . do you have a particular problem / algorithm in mind ?"
325751,what use or interpretation do you want to put on any single-number summary ?
325718,"if you don't know the original units , how could you possibly interpret the coefficient ?"
325787,do you still see feature a dominate after the unit scaling ?
326934,could you post some examples of such integrals and what you have done sofar ?
326940,how do you explain the output from your calculation of power using ` qt ` ?
327149,"the likelihood is based solely on the data and therefore is not affected by the prior . perhaps you mean the "" posterior is more peaked "" when the uninformative prior is used ?"
327296,could you give us more details ?
327363,your problem is not well defined : is the output of each machine a random variable ?
327524,what do you mean . . ?
327599,"at the moment there is nothing in your question that appear to be a random variable . you seem to have defined a deterministic series , which would allow you to obtain the parameters exactly . perhaps you meant to add some randomness in your recursive equation ?"
328037,can you be more explicit in your question ?
328109,why do you need to remove outliers ?
328947,are the annotators working on the same work items ?
329017,do you have sources for all these definitions / claims in your question ?
329173,what are the formal assumptions of the poisson distribution ?
329224,"how many subjects have you examined in each ( diet , substrate ) group ?"
329369,"you haven't explicitly included in your question whether the difference between ` ( c ) ` and ` ( i ) ` is insignificant after 3 months , but i'll assume it was . this can happen for example if the control group has higher variance than the intervention group , rendering the comparison between them insignificant , while the before / after difference is significant for the intervention group . is the difference still significant after correcting for 4 hypothesis tests ?"
329509,that $ mu $ is not a constant value right ?
329677,"your terminology is vague to the point it is difficult to determine what you're trying to ask . could you explain how $ sigma_a $ differs from the "" the errors of the individual measurements "" of a ?"
330085,by using the gaussian cdf you can immediately reduce this to a one-dimensional integral ( is there any reason you did not do that ?
330121,"what do you mean by "" paired "" ?"
330153,are you including $ z $ in your model ?
330355,you imply that you only have summary data and the the detailed responses . is that correct ?
330633,"would you please edit your question to define terms such as "" credit spread "" and "" market beta "" ?"
330637,perhaps you could edit your question to tell us what the two methods you are using are ?
330390,why is the fact that the decision tree skews in the same way as the data a problem ?
330792,"as it stands there is no way this question can be answered , as a bias needs to be assessed relative to some process having generated the data , which you do not state . is it $ y_i = alpha beta x_i u_i $ where something is assumed about the relationship between $ u_i $ and $ x_i $ ?"
330567,"can you say a little more about the context ( what you're trying to do ) , how the samples were generated , and what you want this value to measure ?"
330931,"can you say more specifically what you mean by the classifier "" performing better than chance "" ?"
330980,"what is you query of interest , the causal effect of a joint intervention of treatments say $ x_1 = 1 $ , $ x_2 = 1 $ and $ x_3 = 1 $ versus $ x_1 = 0 $ , $ x_2 = 0 $ and $ x_3 = 0 $ ?"
330837,i think the selection of a good method crucially depends on the assumptions you can make about your data . could you provide more detail on how the data is generated ?
331166,what specific application do you have in mind ?
331330,"you mention mackay , are you referencing a paper or book ?"
331561,"what is hindering you from using the "" _new variable , ` gpa . diff ` , in my cox regression as a time varying predictor . _ "" ?"
331842,do you mean that $ y $ is a concave function of $ x $ ?
332002,"what does the "" acc . "" in your title stand for ?"
332266,"not sure i understand the question . it sounded like you were asking about $ n $ -ary splits rather than binary splits , but then you mentioned splitting the target variable . is that right--do you mean somehow splitting the target ( i . e . output ) rather than ( or jointly with ) the input ?"
332640,can you show the model call or explain the structure of the model ?
332777,"i have no idea what the plot is , sorry . what are you sliding ?"
332814,can you tell us the possible choices ?
333285,how is the function you are trying to fit related to the score ?
333433,"in other words , your pre-trained model fails to converge ( reach small training error ) on the new , small dataset ?"
333652,it would be useful to see a simple working example with the brms code . i'm also not clear on what you mean by the difference between models being less than 2se's . . . do you mean the difference in some quantity you are estimating ?
333658,"this is presumably an error in the organization of the book . is there an index in which you could look for "" normality tests "" or similar ?"
333818,"i might be missing the point , but wouldn't $ y_i = x_i ^ 2 epsilon_i $ where $ epsilon_i $ is normal with mean 0 , do the job ?"
333870,could you explain the context of the covariate ?
333892,""" too strict "" in itself does not mean anything . "" too strict "" to achieve what ?"
335184,"instead of all the gobbledygook of the theorem , why not just apply the simple result that for $ y geq 0 $ , $ f_y ( y ) $ equals the probability of the event $ x in [ - sqrt y , sqrt y ] $ and differentiate to find $ f_y ( y ) $ in terms of $ f_x ( x ) $ ?"
335322,"you will need to give more details . for example , what are the proportions , how many are there , why are you averaging them ?"
331860,"no , i have misread a part of the question . what if you simply start by using only common choices ?"
335699,"you need to shed more background on the problem . what is the "" treatment "" in this case ?"
336071,can you edit your question to include the output produced by r ?
336112,can you show the output ?
336329,"i think contingency table chisq or fisher's exact is the way to go for simplicity . you could do a logistic glm paired with anodev , but like why ?"
336368,"i really don't follow this question at all -- neither the basis for the statements nor what is being sought . perhaps you could try to explain in more detail what you need to achieve in plain words ( avoiding statistical terms as much as possible ) . could you also explain what it is that you see as conventional and why is it a convention ( i . e . what the reasoning is for it ) , preferably with some references ?"
336538,this does not look like standard time series analysis . what are you trying to achieve ?
336818,"it's not entirely clear what your end-goal is , whether it is image similarity in vgg's feature space or in word2vec's context space ( images co-occuring ) . could you clarify this by explaining the problem you are trying to solve ?"
336843,"at a minimum , you define a metric and use appropriate predictive methods to evaluate the reliability of the predictions ( or are they forecasts ?"
336968,do you have links to the references where you saw each method ?
336488,could you give us more details about your data ?
337235,"what do you mean by "" performs as well as "" ?"
337536,"your input is 8x3xwxh and you want to reconstruct this from just wxh , is this your goal ?"
337537,what question are you trying to ask of your data ?
337613,this sounds odd . are you saying that you just want the histograms shape to be similar ?
338499,your terminology is unclear here . what do you mean by 'control' and 'test' ?
338679,check your adjusted formula ?
338808,"you're saying both "" i was wondering if it is possible [ . . . ] "" and then in the next sentence "" [ . . . ] they can be compared in terms of roc auc "" . what are you actually asking ?"
338868,do you mind sharing the data ?
338887,"you mean "" iv 3 : interaction between iv 1 and iv 2 "" , right ?"
339035,is this an exercise from a textbook ?
339402,could you add your architecture code to the description ?
339546,could you please explain your second equation in pt number 3 ?
339959,"a truncated uniform distribution is uniform . it's unclear what the "" value weighting "" means , because the formula you gave does not necessarily produce a cdf ( and usually does not ) , thereby making nonsense of your title . thus , the intelligible part of your question is already answered in the closely related thread and the other part really needs clarification to be answerable . do you think you could edit this post to address these issues ?"
340055,there does not appear to be any special feature or difficulty in computing the power of a permutation test : it works the same as computing the power of any other test . could you articulate some aspect of this situation that you think merits a special discussion ?
340112,"copying and pasting the 27 values into your question would let people experiment . it's harder to copy from an image except the tedious way . in any case what does "" not working "" mean ?"
340144,what do you understand the coefficient for 'female' to represent ?
340318,do you find ssd to work better in practice than faster r-cnn ?
340878,could you tell us more specifically what ` ordsample ` is trying to do ?
341023,this is a different question . why do you want to obtain the quantiles from kde ?
341281,is this self-study ?
341458,"how do you define "" well shaped "" ?"
341767,what are you trying to accomplish by using a k-m based scaling of time to model a time-dependent coefficient for ` stage . n ` ?
342669,is this e . g . 20 users with a bad experience out of 2000 ?
342816,"is the only correct sequence [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ] ?"
342902,"first , here should be * * t1 : boxcox . lambda ( t ) * * ?"
343339,"you mention variance of the forecast error , variance of the forecasting equation and variance of the forecasted value . could you check once again if what you have written is what you actually mean ?"
343449,"do you mean $ $ p [ underset { n to infty } { liminf } l ( delta_ { 1 } ( mathbf { x } _ { n } ) , theta ) leq underset { n to infty } { liminf } l ( delta_ { 2 } ( mathbf { x } _ { n } ) , theta ) ] = 1 $ $ ?"
344108,does your data have a spatial or temporal element that's potentially causing autocorrelation in the residuals ?
344173,what do you mean by * stochastically bigger * ?
344315,"could you please provide the code you use to fit your model and an example of the output . you really should also provide either a sample of your data , a simulation of what it looks like , or ( at bare minimum ) a description of it ?"
344459,is this home work ?
344816,"how do you define "" belonging to distribution "" ?"
345063,"could you elaborate on what you mean by "" get from the last equality "" ?"
345097,can you give a better example for us to consider ?
345403,can you clarify how many levels a has and what they are called ?
345687,accuracy on what ?
346301,is there a reason to expect it has any meaningful interpretation ?
346324,( 1 ) please quote enough of the question so that we can understand your post . ( 2 ) what does the title ( about the inverse cumulative f distribution ) have to do with the contents of your post ( which focuses on sums of squares ) ?
346380,"stochastic gradient descent is one of many algorithms for finding the max / min of a function ; the function shouldn't depend on the optimization algorithm , but on the problem you are facing . given that , i'm not sure what you mean by "" . . . $ f $ is better or worse than some other estimator $ g $ for stochastic gradient descent ?"
347313,best for what ?
348175,i don't understand . what did you use mi for and why are there multiple datasets ?
347383,"well , how do the bots in your data set behave ?"
347387,does this help you : url ?
346608,"typically this fp result would invalidate the estimation strategy . if you are finding effects where theory predicts there should be none , what makes you think that this won't carry over to the intervention period , particularly if the periods are contiguous ?"
347502,what's the reason for combining the models / depts ?
347524,try multiplying the predictor by 100 ?
347526,posterior * is * a conditional probability . could you try making your question more clear ?
347515,what is your goal ?
347528,""" each vector is basically a ruler with 750 intervals "" - are these intervals each a pair of an upper and lower bound ?"
347550,"have you only got this data ( the table as you show it ) , or have you got the detail of responses per participant , i . e . for each response a gender and a goal ( or many goals if participants were allowed to select multiple goals ) ?"
347538,i'm not sure i believe any of these formulas are generally true . are you perhaps implicitly assuming all variables have been centered ?
347520,"could you explain how you know this system of linear equations "" has infinite solutions "" ?"
347583,of course they shouldn't give you the same answer ( as hinted by the fact that the two fits return different scale but same shape ) . why do you think they should ?
347624,"note also that tau is similarity , not dissimilarity . does your program automatically revert similarity into dissimilarity ?"
347627,don't you think the calculation will differ depending on which procedure is in question ?
345152,"so your question is just on how to convert $ s ( a , b ) $ into $ d ( a , b ) = f ( s ( a , b ) ) $ such that $ d $ satisfies the triangle inequality ?"
127597,what is the goal of this analysis ?
347728,could you write down the integral you have to evaluate ?
347768,how many obsevations do you have in your model ?
347801,what is the goal of this project ?
347267,first we're imagining data and then you seem to be implying that you have $ r ^ 2 $ to hand from real data . which is it ?
346901,"you've read about linear regression because it's the simplest model , so it's nice for introductory example . what exactly is that your need ?"
347868,"try to ask your question in more general terms . i don't want to run the script to see the data ( because i "" m lazy ) . but if you said "" i've got data that look like . . . . and i did this test . . . . and got this result . . . . is that appropriate ?"
347918,"it sounds strange to me the basic concept of using your present data to set a prior . i always thought prior should come from some previous knowledge ( i . e . you decide them before seeing your data ) , like from literature or 'prejudice' . what do you hope to gain with your procedure in comparison to setting a flat prior and use all your data for inference ( in case you have no prejudice / idea how to set the priors ) ?"
347941,it looks like you need to run a logistic regression . you seem to be aware of this based on your tags even though the question title doesn't reflect this . what exactly do you need help with ?
347935,"ok , i'm starting to understand your confusion . maybe you could edit your question to add some of the things you said into the question body for clarity ?"
347977,why do you not want to use the full dataset / much larger ( e . g . 60 % ) for training ?
347994,"you have done 3 post-hoc tests , and none were significant . but there are many other possible post-hoc tests . the anova tests for variance among the set of groups . what is your result for testing group 1 vs ( group2 and group 3 ) ?"
347998,tl ; dr : principal component analysis or pls regression ?
348006,"your question is not clear , and example even less so . could you reformulate it ?"
347907,"im not following what you're doing here . what's a "" query point "" ?"
347923,"hint : for _starters_ , check whether your claimed joint density for $ x $ and $ y $ is a valid joint density . after fixing the error , re-do your work and check if the corrected joint density that you find for $ z $ and $ w $ is a valid joint density . for example , where do make a note of the fact that if $ y = w = 0 . 5 $ , ( say ) , then $ z $ cannot possibly exceed $ 0 . 25 $ , and so your expression for $ f_ { z , w } $ cannot be valid for * * all * * $ z , w in ( 0 , 1 ) $ ?"
348062,how about an indicator variable for each event ?
348065,"maybe you could explain your example a bit more clear . i think you can just use regression . with enough training data the effect of the "" density "" should be taken care of . unless you have weird distributions . am i missing something ?"
347735,you are correct that gelman and hill do not discuss qr * per se * but is that a barrier to leveraging their insights into bayesian approaches to panel data models ?
347780,[ better for what ?
348136,"that's presumably correlation coefficient across all entries of $ d $ matrices , i . e . these $ n times n $ matrices are "" vectorized "" as $ n ^ 2 $ datapoints , right ?"
348144,what is the distribution of the data like ?
348156,""" rate of growth "" is per some unit of time . . . so your estimated rates are relative to * what time units * in each case ?"
348160,"using a normal distribution here will never make sense , because you will always have a positive probability of * losing * rupees by cutting bushes ( no matter the mean or standard deviation ) , which to my knowledge is not possible . do you know for a fact that the drops are independent between bushes ?"
348181,antoniojunior : do you have predefined categories ?
348212,not sure what you mean ?
348200,there seems to be too little information on the problem -- or for the problem to be solved . is this all you have on the data and its weights ?
348218,""" can i consider the $ dx $ as a quantity which describes the changes in $ x $ due to a deterministic function $ mu $ plus white noise with $ sigma $ as variance ?"
348220,"the symbol "" $ sigma_u ^ { 1 / 2 } $ "" has no definite meaning in general , but given the first equation , most people would understand it to represent one possible meaning , by analogy with the corresponding relationship between $ sigma = p times p $ and $ p = sqrt { sigma } $ for positive numbers $ sigma . $ therefore there doesn't seem to be any content to this question . what are you trying to ask ?"
348252,""" this is beyond my level of stats prowess "" - 2 observations : 1 . use logarithmic scaling to compress the range . 2 . are you concerned about "" income "" , "" wealth "" , or both ?"
348002,"please clarify what you mean by a "" cone "" : are you discussing * one * lobe or * two * ?"
348279,is t ( gamma ) 1 ?
348264,1 ) what do the confounder do ?
348031,"please give us more details , rather then the reference alone . what exactly is your question ?"
348371,"well , obviously there is a mistake somewhere . but if you don't show us what you did , no one will be able to diagnose it . calculating probability of 0 . 77 doesn't even make sense for a continuous variable . perhaps you used a function to calculate the probability density function at 0 . 77 ?"
253320,think about whether you have the data to calculate time to events and whether such a quantity is something you would want to model ?
348387,"the last expression is wrong , where did you find the squares ?"
348402,possible duplicate of [ what exactly is a hypothesis space in the context of machine learning ?
348475,"it's mutual . who would call them selves "" data scientist "" ?"
348443,can you clarify whether these are variograms of the residuals associated with each model ?
348483,what action ?
348489,"what is an "" ssw "" ?"
348462,can you edit your question to clarify how many studies you have in your meta-analysis ?
348495,"curse of dimensionality is not a synonym to overfitting . moreover , your procedure is not perfectly clear . somehow i can't believe you're not overfitting . do i understand correctly that you use feature selection ?"
348410,the length of the series is only 37 ?
348530,"given that the dimension of your proposed minimally sufficient statistic is ( fill in the blank ) ___ , can it be reduced to another sufficient statistic , i . e . , to one with smaller dimension ?"
348497,"well , if you assume that * continuously compounded rates * $ r_t $ are normally distributed , then the growth factor $ e ^ { r_t } $ is lognormal , and products of independent lognormals are also lognormal , sure . but if the continuously compounded rates are normal , the annually compounded rates are not . so , which assumption are you making ?"
348573,what do the graphs show ?
348598,this formula looks misquoted to me . $ ( q_ { 90 } - q_ { 50 } ) - ( q_ { 50 } - q_ { 10 } ) $ compares the length of right and left tails and simplifies to $ q_ { 90 } - 2 q_ { 50 } q_ { 10 } $ so the last sign looks wrong . it is easy to imagine that you might then want to scale by $ q_ { 90 } - q_ { 10 } $ but i can't see that adding a factor $ q_ { 10 } / q_ { 90 } $ makes sense either dimensionally or statistically . kelly is probably also a common mutation on kelley . can you give a source for this formula ?
348488,what is the blue line in the bottom graph ?
348608,"what do you consider "" the best way "" ?"
348597,"all marginal distributions are univariate . perhaps you meant to write "" uniform "" ?"
348636,"if you know the proportions already , why run a trial ?"
348638,i'm not clear on the question . are you asking about analyzing the differences in retention or depicting it ?
348494,"jeza , could you explain what's missing in my answer ?"
348644,"if you only measure the patients' severity score at the first consultation , i can't see how you can measure progression of disease . it must be that you have subsequent measurements of severity available after the first consultation - if yes , can you edit your question to clarify this aspect ?"
348665,"if you are not allowed to use a , then looking for b that is a proxy for a is probably * * equally unethical * * , isn't it ?"
348587,"where exactly in those two sources did you encounter the mention of "" one-standard-error rule "" ?"
348696,why do you think the ar ( 1 ) residuals follow a white noise ?
348733,recode your classes ?
348735,are you treating your outcome variable as ordered ?
348765,"you don't optimize models , you optimize an objective ( cost ) function . what is your objective function ?"
348768,what is $ a $ and $ b $ ?
348777,what is the difficulty in replacing $ p_1 ( y ) $ and $ p_2 ( y ) $ with the normal pdfs ?
348506,"could you supply some context and / or references to help us understand where these ( generic ) phrases "" one-vs-one "" and "" one-vs-rest "" come from and what they might mean ?"
348863,i'm afraid i can't read stata . is ` deteriorate ` the response variable ?
348882,what is the form of the equilibrium distribution from which you derived the moments ?
348889,what's a negative price ?
83626,"perhaps a better title for this post is "" how to best bin a continuous variable to estimate its mutual information with a categorical variable ?"
348783,"i don't know very much about bootstrap methods , but are there problems caused by mgcv doing model selection inside the simulation ?"
348977,are you asking about a mathematical derivation or for steps to simply calculate ?
348728,do you have an object or variable in your workspace called 'weight' ?
349063,could you give more details about your sample and model ?
349093,"can you post your data , or at least plot it ?"
349106,are you committed to a bonferroni-like adjustment ?
343036,what would be the purpose of such modifications ?
349140,"why don't you simply calculate the c-statistics ( also known as the area under the roc curve ) for each model ( only a , a b and a b c ) ?"
349154,"are you looking for the limit of $ a_n = 1 1 / 2 ^ n $ or are you looking for the limit of the product $ a_n = prod_ { k = 1 } ^ n ( 1 1 / 2 ^ k ) $ . the way you have written your mathematics is asking for the latter , but can you confirm that this is your intended question ?"
349162,"it seems like your $ pr ( y theta ) $ is a density , not a probability , so some of your confusion may be because of a poor notation that calls a density a probability ?"
349190,"usually you have random variables , from which you calculate the correlation . maybe i know too little about pathway analysis . to me it seems that you have 100 2d random variables . if you want to determine the correlation between the individual components ( a and b ) , then you'd take these . in a scatter plot , plotting a vs b you'd directly see the covariance . am i missing something ?"
349198,"so much going on here . . . why do you believe the "" * arch coefficient * "" cannot be negative ?"
349218,it's possible . how many data do you have ?
349241,is your learning rate decaying ?
349245,perhaps consider [ false discovery rate ] ( url ) ?
349259,"when you say "" based on a weibull distribution "" - what is it the distribution of ?"
349273,"your question would be improved by making explicit your precise question . for example , what is the null hypothesis you are interested in testing ?"
349279,what would it mean to make the variable more important ?
348030,this does not seem to belong to cv -- maybe math ?
349305,"it looks to me like you've derived the solution for when there is a singe variable in the model ( with a single coefficient $ beta $ ) . how would this generalize to a case with multiple variables , where all the coefficients need to be 0 ?"
348904,why can't you do ( 1 ) ?
231062,what are you trying to * do * with those statistical tests ?
349353,because your data was different ?
349377,what happens if you try the command coefficients ( summary ( final ) ) ?
349384,does this come from any source ?
349034,what are lambda and gamma here ?
349418,is it usually defined that way ?
349431,"ah , so it did . was reading on my phone and didn't see it . any luck ?"
349433,can you give an example where someone says this ?
349461,it is a bit unclear what you are asking . is it 'how to use a test without a norm-reference based on a ( different ) population of interest ?
349460,how do $ bar { x } $ and $ bar { u } $ make the regressors and error term ( or residual ?
349499,are the items marked 4 . - 7 . your answers to the questions 1 . - 3 . ?
1469,you need to compute the fisher matrix ?
5023,"'non-independent' is a bit vague ; there are many causes and models for dependence ( clustered data , hierarchical / multilevel models , time series , . . . ) . could you be a bit more specific on your area of interest ?"
5197,"i may be completely wrong here , but all the example outputs seems like simple counting operations ( additionally the word "" assumptions "" confuses me ) . do you want to extract statistical measures or do you want to e . g . extract the combination of variable values which "" cause "" certain injuries and hence allow prediction ?"
71984,"re "" don't have a clue "" : are you asking for an explanation of what a uniform distribution is or what a logarithm is ( or both ) ?"
2661,is your question related to some extent to assessing model goodness of fit or the comparison of two nested models ?
4010,you say this sequence 'may represent the correlation between a couple of measurements' . do you have the data for the measurements ?
6320,"the answer will depend on what kind of distribution is estimated . is your goal only to estimate the distribution , or you intend to estimate something else using this distribution ?"
8137,"yuriy by horizontal line , you mean arrow-like whiskers or add e . g . , the mean together with the median inside the box ?"
10953,"are you saying that , say , f1-m2 was observed in condition "" a "" but not in condition "" b "" and that perhaps f1-m3 was observed in condition "" b "" ?"
14161,are the discrete values ordinal or just categorical with no ordering ?
14831,any specific reason you want to use clustering ?
17377,"you seem to be saying "" i have this procedure that inputs a $ k $ and a $ d $ and outputs a number ( the mean of $ mathbf { v } $ ) . how can i maximize the output ?"
6247,"can you construct a simple , reproducible example of your problem ?"
6580,"hey tomek , do you mean parameter $ b_p $ or parameter estimate $ hat { b_p } $ ?"
7166,what exactly are you trying to model / predict here ?
7278,what's wrong with the formula given by url ?
7676,"assuming you've got a valid rationale for comparing the same people in the two conditions without a true control group , i'm not sure the correlation across bootstrap iterations is really something to be worried about in itself . it seems like you are , in effect , calculating cis for the average treatment effect on the treated ( no wikipedia entry yet , sorry ) and interpreting that as a meaningful outcome of interest . that said , i'm having a hard time following exactly what steps you took to estimate the differences between conditions . is it a simple difference of means ?"
8808,"this question needs more information : what exactly do you mean by "" working with "" a distribution ?"
9604,"formally you can do , but from practical point of view are the discrete choice variables endogenously related in your model ?"
10078,why do you have c ( 2 ) and not just c ?
10562,"what does it mean "" most sensitive to finding natural clusters "" ?"
11370,"i tweaked the question title to make it a little more specific on the assumption that "" order "" is a between subjects factor . feel free to change back if i've misconstrued ?"
12762,"as such , the spread of multivariate gaussian doesn't make sense . however , depending on your needs , there might exists approaches to answer your question . trace of the matrix is one of the many ways , but you would be ignoring correlations , which may make a huge difference . eigen values , pca , etc . might be much better . therefore , could you please elaborate on your needs ?"
13106,could you pls paste the output of dput ( your_data ) ?
13799,are you wanting to calculate some * empirical estimate * of the entropy of a source ?
14402,do you think it is fair to say that your ordinal data is also * interval * data ?
14671,i don't understand your reluctance to characterize each store ( in part ) by its mean on the continuous variables . what else would you try to do with those variables in a cluster analysis ?
14999,"good question ! i put a reference to the paper of donoho in my answer , but what are your written references about reproducible research ?"
15211,are you sure it is applicable for the time series data ?
83855,a question is too broad . how do you know that $ a $ is the cause of $ b $ ?
187564,can you specify the form of the sde ?
206071,"the title does not quite match the body . also , did you mean * central tendency * ?"
280956,do you mean how do i program it ?
325033,"could you clarify what you mean by "" sample space of $ epsilon $ "" ?"
17116,what do you mean by categories ?
18692,did you consult the wiki article [ on estimation of parameters for the von mises distribution ] ( url ) ?
19179,"the median is the data point which is greater than 50 % of all data points . as soon as you have one or more data points , you always have a median . what does the phrase "" doesn't reach 0 . 5 "" mean ?"
20052,first off : is this a supervised or an unsupervised learning problem ?
20106,"are you aware of the ` ` ltable ` ` command and the survival analysis capacities , the so-called ` ` st ` ` commands ?"
20820,"the question seems too vague to answer . could you explain what a "" connection "" is , what an "" r matrix "" is , what a "" value "" of a matrix might be , and what "" relation "" you seek ?"
20868,"what is the expected horizon for your projections ( 1 month , 1 quarter ) ?"
21623,( 1 ) this is a very interesting problem . i am curious : which domain ?
24535,please precise . what is the r package you use ?
18586,"ok , that's good . to be precise , you appear to assume all battle outcomes are independent and that the chance of an $ a_i $ beating an $ a_j $ never changes . call these chances $ p ( i , j ) $ . without any loss of generality we can assume $ a_i $ is the smaller of the two-- $ 1 le i lt j le 5 $ --and you are assuming $ p ( i , j ) lt 1 / 2 $ in all such cases . do you also assume there is some numerical attribute $ q ( i ) $ and some function $ f $ such that $ p ( i , j ) = f ( q ( j ) -q ( i ) ) $ ; in other words , that the battle probabilities can be determined by a single number associated with each character size ?"
27393,"two things : 1 ) a sum of regression trees is piecewise constant , so i don't think it has a gradient ( it's flat everywhere that it's continuous , so i don't think gradient methods are an option ) . 2 ) maybe if you clarified why you want the maxima we'd be able to help you better ?"
28369,is this homework ?
29637,macro don't you think your remark sounds a little harsh given that you are addressing a newcomer ?
29860,a confidence region for what ?
45589,?
139145,do you need software implementation ?
18718,i am afraid the question does not have a 'standard' answer as i suspect that the authors are using a term that may be domain / context specific . what is this paper ?
19525,is this a homework assignment ?
20525,what is the sample size ?
20574,"are you familiar with a good math programming language , like r ?"
20715,what is the purpose of the intended clustering ?
21161,"explain more about your data ! are you sure it is interval censored beyond the general level of resolution ( eg if all your variables have a yearly resolution , than event times do not really have to be more precise ) ?"
21224,"just out of curiosity , is your statement of the question taken verbatim from the assignment ?"
21850,"if $ x = ( x_1 , x_2 , ldots , x_n ) $ , does $ x $ equal $ ( x_1 , x_2 , ldots , x_n ) $ or $ sqrt { x_1 ^ 2 x_2 ^ 2 cdots x_n ^ 2 } $ ?"
21976,is the exposure dose going to be the same across your conditions ?
23066,are you asking about how trustworthy the automated procedure is ?
24059,got some references ?
24327,"you are asking "" what is the distribution of the variable $ y $ . . . "" but then saying "" . . and the density function $ f_y ( y ) $ . . . is known ( a shifted chi-square distribution ) "" so you know the density function of $ y $ already . what is the question that you really meant to ask ?"
25989,is that different from the reality check described by white in [ his 2000 * econometrica * paper ] ( url ) ?
26296,could you tell us what kind of data ( scientific field or measurement technique ) you are looking at ?
26588,is it the same phenotype in the three experiments ?
27276,could you please provide the definition of tomek links ?
27777,it's not totally clear what kind of model you're fitting - is this a linear regression model ?
27928,please add more information . are we talking about an exact weighted sum or is there an error term ?
29268,"chris , are these questions ( this and your previous binomial question ) homework ?"
30521,is your background in statistics or in computer science ?
31103,could you describe what do you mean by 'classification' ?
71615,can you write out svm ?
267708,"for small changes , log differences are close to percent changes : $ log x_t - log x_ { t-1 } approx frac { x_t - x_ { t-1 } } { x_ { t-1 } } $ . do you have a link to the paper ?"
283362,what is it you are bootstrapping and why ?
33616,could you please clarify in what sense the parameter estimation is poor ?
34570,"what do you mean under "" loadings "" in case of oblique rotation ?"
35386,for the linear model are you doing ordinary linear regression ?
38913,why really did you roughened your 4-point scale into 2-point ?
41604,why would that be too simple ?
43236,"hmm . . . all the cds return between $ 1 $ and $ 5 $ percent per year , so how do you come up with such an enormous rate ?"
44341,could you explain * why * you are carrying out this analysis ?
46651,"welcome to the site , ch3m . since you're new here , please read our [ faq ] ( url ) regarding site policies . for example , please don't post twice ; instead , edit your existing question to update it w / new info . this will also bump it to the top of the queue . i don't see your previous q , can you delete it ( assuming you prefer to keep this one ) ?"
47145,"it looks like the "" standard "" pearson correlation is out of the running , right ?"
47810,"very interested to hear others opinions . i don't think you'll necessarily end up with a great increase in the "" efficiency "" of the experiment in terms of participants recruited ( which would end up with a part-way number between a fully-between and a fully-within design ) to get the same amount of power / estimation accuracy -- factor a will have more estimation accuracy in half the group , factor b in the other half . the analysis for this might be excruciatingly complex , too -- perhaps some form of mixed ( linear ?"
48050,what amount of height difference would cause the console to move ?
51090,"what is meant by $ mu sim n ( mu ; 0 , xi ^ 2 ) $ ?"
51084,the question at url seems to be the same as this ( apart from the details of the process ) . does it provide an adequate answer ?
58596,this doesn't really deserve to be an answer but part of it is gonna be : what is ( in ) your data ?
96894,can you give more of the text ?
175645,could you please explain by what you mean with pasting together two distributions being sound ?
330913,are the similar observations similar enough to average thier values ?
3632,"did you really mean to include "" logistic "" in "" use logistic regression to estimate x "" ?"
31438,"i think that you may need to add more information in order to get a good answer to your question . for instance , are your sequences time series ?"
32223,are you sure that this is caused by sampling bias ?
32239,what do you want to do with the standard error ?
32716,this is awfully broad . can you say more about your situation & what you've done ?
33621,"it's not obvious to me that this would be possible . the model could be completely different without an intercept , and i'm not sure why there should be an easy path from one model to the other . can you explain why you think this is feasible ?"
34043,can you elaborate a little more on what your concerns are ?
34544,the * hitting time * of what set ?
35159,"because you have received answers that are based on two different interpretations of the question , clarification is needed . are you attempting to cluster * data * assumed to be drawn from a multivariate normal mixture or do you ( perhaps ) have a set of * distributions * ( already given in terms of their multivariate means and covariance matrices ) and you wish to cluster * them * ?"
35919,what do you expect us to be able to say without seeing the data ?
36151,"what is the reasoning behid your last sentence "" since $ epsilon $ is arbitrary , $ x_n to 0 $ a . s "" ?"
39187,i suppose nmf = non-negative matrix factorisation and lda = latent dirichlet allocation ?
40577,why the poisson ?
40629,how is what you're asking about different from assessing seasonality ( which i believe is standard in time-series analysis ) ?
43045,what definition / construction of a wiener process are you using ?
44946,"i suppose any discrete distribution with three or fewer parameters ( "" three "" since one of your four is redundant ) would be a candidate . . . what is your data ?"
45966,"this is expressible in terms of a [ jacobi theta function ] ( url ) , $ frac { 1 } { x } e ^ { frac { 3 pi ^ 2 } { 8 x ^ 2 } } left ( e ^ { - frac { pi ^ 2 } { 2 x ^ 2 } } right ) ^ { 3 / 4 } sqrt { frac { pi } { 2 } } vartheta_2 left ( 0 , e ^ { - frac { pi ^ 2 } { 2 x ^ 2 } } right ) $ . but what is your question ?"
46072,what are your values ?
46216,"interesting question . does professor ng give reasons why "" pca should only be performed on the training data and then the mapping is used to transform the cross validation and test sets "" ?"
46749,"this is a very open-ended question and seems to be based on your experience interacting with a specific text analysis package . can you narrow down what your question is , and tell us what software you're basing your example from ?"
46991,what have you tried so far ?
47049,what model ?
48375,have you heard about hierarchical hmms ?
49430,"are you referring to the st . dev of the data within each bar , or are you wanting the standard deviation of your measurement methods associated with that range of data ?"
49772,"first of all , are these 4 measures understood to be independent , or are they measures of similar constructs ?"
49814,why would you not just combine it all into one sample with size = 500 490 101 103 ?
50265,"hi dzungnguyen - i have made some edits to try to clarify your question , but you should check that i haven't changed your intent ( e . g . with the replacement of 'rigorous' - which really didn't seem to fit the context - with 'rough' ) . the use of the abbreviation 'ml' is ambiguous here ( it might mean one of several things ) . do you mean 'maximum likelihood' or 'machine learning' or something else ?"
51061,"( 1 ) it is clear there is no bias , because ` ( ( 1 : n ) -0 . 5 ) / n ` is reversed under the transformation $ x to 1-x $ and so is the inverse cdf of any symmetric distribution such as the normal . so , what evidence do you have about a biased "" intercept "" ?"
51218,ehh . . . can you work the term $ n $ into your answer ?
52293,"re the edit : the sw test result * * rejects * * the hypothesis that these data were independently drawn from a common normal distribution : the p-value is very small . ( this is apparent both in the qq plot , which exhibits a short left tail , and in the histogram , which exhibits positive skewness . ) this suggests you misinterpreted the test . when you interpret the test correctly , do you still have a question to ask ?"
135633,""" yes "" . the problem with asking questions to which the answer is simply yes or no is we can't actually give a single word as an answer , so the question may technically remain unanswered . please try to rephrase in a way that allows a more extensive answer , useful to later readers . one good choice would be "" marginals are mentioned a lot in copula literature , what does the term mean ?"
194543,could you tell us what mmse is ?
54713,my first question would be what sort of analysis you want to do on the dataset . why might the skewness be a problem ?
55494,have you drawn a venn diagram yet ?
55748,"for $ d = 2 $ this question is answered at url ( the statement is strangely stated . what it means is that if you divide each of the $ d $ sides of the cube into , say , $ m $ equal intervals of length $ h = 1 / m $ , then--by elementary geometry--the cube itself will be composed of $ n = m ^ d = ( 1 / h ) ^ d $ little cubelets . ( this will not be the case for arbitrary values of $ h $ , which is why the statement is so backwards . ) the definition of $ hat { pi_j } $ is bad because it refers to undefined symbols $ n $ and $ x_i $ : presumably $ n $ is the count of the data $ ( x_i ) $ , right ?"
62204,"and by guestimate i mean fit the model without the correlation term , fit the spherical model to the residuals , get those parameters and then refit with ` gls ( ) ` but state the parameter values rather than use the formula using argument ` value ` . without the nugget you'd only need to specify the range as a parameter but with the nugget you will need both the range and ` 1 - cor ( i , j ) ` when ` i ` and ` j ` are two observations close together in space . see ` ?"
58964,"excuse the possibility of my ignorance , but i've never heard of inarima . furthermore , my attempt to find documentation about inarima has resulted in failure . could you please confirm that you're not confusing an "" integer "" arima process with an "" integrated "" arima process ?"
64020,"hi davide , i'm curious to know whether you got anywhere with the solution i posted ?"
68494,configuration of your network ?
68973,"how is text "" continuous data "" ?"
69451,"think about the properties of $ f ^ { -1 } $ as applied to a * random sample * of uniforms , to start . does the ordering change ?"
69487,( 1 ) why do you think it makes sense to compare likelihood for different $ n $ ?
69380,the wilcoxon test is a permutation test already . it computes the permutation distribution of ( a monotonic function of ) a t-test on the ranks . your permutation test based off a t- is already nonparametric ; perhaps your concern is to make it more robust to outliers rather than to make it nonparametric . what are the response values measuring ?
70575,"maybe i missed something , but didn't you mean $ log prod_i f ( x_i ) $ rather than $ log sum_i f ( x_i ) $ ?"
71849,"do you have more information , like a model you are assuming or something ?"
72545,"could you please clarify whether you want to test equality of * eigenvalues * ( as stated in the first sentence ) , * eigenvectors * ( as in the penultimate paragraph ) , or the full * "" eigendecomposition "" * ( as in the title ) ?"
73043,"one explanation you don't seem to have ruled out is random variation . if you observed a new data set for each , might your decisions have gone the other way ?"
73433,i would start by defining the number of customers arriving at the shop in a given hour as $ x sim pois ( lambda ) $ and $ k ^ { -1 } x $ as the service time they require . can you then see how to answer the first two parts using the properties of expectations and variances ?
73853,"could you please explain what "" $ x $ "" might be and in what sense your notation--which conventionally refers to a * product * --is a "" noisy or "" ?"
74620,"normally people use programs which can supply p-values . note also that for small samples , those values in that table are only approximate . you may find this answer of some value : [ * how do i find values not given in ( / interpolate in ) statistical tables ?"
76177,"there are many different ways that data can have some specific correlation at lag 1 ; what is your model for the joint distribution , or at least for the joint distribution of two consecutive lags ?"
77071,"may we presume that "" ica "" refers to [ independent components analysis ] ( url ) and not one of a [ hundred other possible meanings of this acronym ] ( url ) ?"
77345,what do you want to use the result for / what kind of an answer do you need ?
77785,is this what you are looking for ?
286653,why can't you impute the missing values perhaps by multiple imputation ?
56032,what software are you using ?
56609,are you sure about equality of the dimension of $ y'y $ and $ hat { y } y' $ ?
58901,"i have used latent transition analysis with discretized continuous variables and other categoricals . not sure if r supports it , but you can do it in sas . in terms of unsupervised . . . i assume you want to use this for data mining or something ?"
59918,is your question on how to * technically * plot the lines and points in ` r ` ?
60278,"if there is no constraint on $ z $ , then what makes a certain $ sigma $ "" work or fail "" ?"
60962,is the variable categorical or ordinal ?
61761,"what do you mean by "" merging "" cdf's ?"
61876,could you be more specific and expand on your question ?
62604,you want to verify that your implementation is bug-free or you want to evaluate your model's performance ?
62617,what books did you read ?
62957,"i don't quite understand what you mean by "" go through x rounds of between y and z variables "" . are you talking about choosing y out of the 4e5 variables ?"
63236,"re the edit : your data are * multivariate * ; there is one variable per test . your two vectors are each samples of * one * observation of this multivariate process . although it's not impossible to establish whether two such vectors are "" significantly "" different , in practice the answer is almost worthless . you need to obtain several vectors representing "" a "" and several representing "" b "" so that you can assess their variability . almost all statistical tests proceed by comparing some measure of difference to the amount of variability . can you , then , replicate your tests in order to obtain such data ?"
63696,i have never seen an erlang-k application where k is not fixed . it will be hard to find references for what you are doing . are you running a hierarchical model ?
64534,how is the data coded ?
64724,"no sources given here . conservative relative to what precisely , in what circumstances ?"
65933,what does mle have to do with this ?
66257,"i like to get a distribution of aic's , not just 1 or 2 . i look at the distribution of them when i replicate the fit on the same data . if i have an outlier it means something about the connection between the data , the fit process , and the analytic form . now it looks like you are trying to come to terms with your parameters acting to counter-balance your accuracy . if you really don't care then use interpolation and get 100 % accurate , but likely terrible generalization . or trade away accuracy "" today "" for good generalization "" tomorrow "" . bic ?"
67247,welcome to the site . could you clarify your question a little ?
68766,this reads like a standard textbook question . in what context does this question arise ( i . e . what are you doing that it would lead you to ask this ?
68810,the second calculation should give you a random variable rather than a number . did you notice that the right hand side of the second formula depends on the unknown $ x $ ?
69120,not an answer to your question but why do you think the sufficient statistics has to have 4 dimensions ?
70017,shouldn't the -1 be a 1 / 2 ?
71177,have you looked at max flow algorithms ?
73437,"from $ f ( y ) = -y ^ t omega y k le p ( y ) $ , doesn't it follow that $ f ( 0 ) = k leq p ( 0 ) $ and so if you want $ p ( 0 ) = f ( 0 ) $ , then it muse be that $ k = p ( 0 ) $ ?"
74164,i don't know why this is tagged with bayesian - most research in nonparametric methods is frequentist . and isn't the success of the svm an argument that we can do nonparametric stuff with provable empirical risk bounds ?
74420,welcome to the site . 1 ) is this homework ?
76111,"you could add a constant to the coefficients , but that destroys the meaning of it as a correlation ; why do you need a negative exponential function ?"
76571,( 1 ) is this a homework question ?
76815,what is the substantive question you are trying to answer ?
80314,greater eigenvalues than * what * ?
80429,"when you say "" i'm looking at what percentage were discharged from the hospital at different time points after surgery "" you're asking a question about point estimation . when you say "" what is the most appropriate statistical test for this ?"
79131,what exactly would it mean to have a 95 % ci for a * range * ?
79521,"i can't follow your idea . do you want to test if the distribution of the proportion of your data less than the mean is normal via something like the shapiro-wilk test , & then again for the proportion above the mean ?"
79685,"confounding need not stay a "" belief "" . by definition , a confounding variable is associated with both the dependent variable and the main regressor of interest . have you checked pairwise covariance / correlation between each candidate confounder and the dependent variable , and also between the former and the regressor of interest ?"
80969,when you say 'for a stats question' -- do you mean a question like in a textbook or coursework ?
81154,"isn't the state [ customer in service , customer queued for second station ] for station 1 feasible ?"
81005,could you clarify what are the factors of the experiment you want to design ?
83066,( 1 ) how do the zeros arise ?
83232,what will you use the model for ?
87366,would i be correct in guessing that each row is a data point with x1 and x2 intended to be predictors ?
88175,the question is two broad . what exactly are you trying to compare ?
90715,"what kind of data is it , continuous , discrete , mixed ?"
90687,what are you basing your clustering on ?
91347,"as currently stated , this question is only answerable by re-stating bayes theorem : for some prior , you can compute a posterior on $ mu $ . $ $ p ( mu y ) = frac { p ( mu ) p ( y mu ) } { p ( y ) } $ $ where $ y = 0 $ , and $ p ( y mu ) sim text { poisson } ( mu ) $ . determining the posterior for an appropriate prior is left as an exercise for the reader , and the results are interpreted in the usual way . are you uncertain how to interpret bayesian inferences generally ?"
91638,could you please specify all the details of your regression ?
93573,"why do you "" need "" real-life examples ?"
93095,"when you say "" the same but with a time shift "" you mean $ y ( t ) = x ( t- tau ) $ ( where the shift is $ tau $ ) , with no error , no rescaling ?"
95860,what's your sample size ?
96965,how was the treatment subset selected ?
97246,models have more than one possible purpose . is the purpose of the model prediction ?
97457,"are you asking about how to do this in this particular package , or is your question about whether mediation of interactions is possible at all ?"
100191,do you have multiple data points on the same system at different points in time ?
103021,when you say 'polluted' do you mean a finite mixture ?
103661,could you clarify how you would construct a demand curve ?
104238,"please tell us what you are trying to do , in substantive terms . my blog post [ how to ask a statistics question ] ( url ) may help . also , how are you taking log of returns when returns can be negative ?"
107853,how unequal ?
109490,"are you looking for * * ( a ) * * a * confidence interval * for the difference in proportions , or * * ( b ) * * a formal hypothesis test of the null that the proportions are equal against one of the alternatives ( you pick ) * * ( i ) * * that underlying ( 'true' ) probability of 'yes' in a is $ $ the underlying probability of 'yes' in b ; or * * ( ii ) * * as in * ( i ) * but with $ neq $ rather than $ $ ?"
111648,"you seem to be applying some form of moving-average filtering to smooth data series , but your post is very unclear . please explain in more precise detail what exactly the numbers are at each stage . how did you get the coefficients in your terms , and why ( given your first set of coefficients add to 1 ) are you dividing by 7 ?"
111747,what is the difficulty ?
113023,"without some further diagnostics ( eg . $ beta $ 's conf . intervals , plots of observed vs fitted , residual vs fitted , $ r ^ 2 $ , etc . ) it is a bit hard to say . please provide some additional diagnostics first . in general , have you thought of a glm with gamma or inverse gaussian ?"
115616,"yes it's doable if you have a large enough sample size ( recall that each additional level essentially eats up a degree of freedom ) . interpretability will probably be an issue , however . can you give more information about your dataset ?"
100150,your question is quite incomplete . what is your ultimate goal ?
175610,"unless there's some chance the average and poor proposals would be funded , then why would you want to consider them any further ?"
211789,"what do you mean by "" cluster "" here ?"
268956,"since the student t test does not compare distributions--it only compares their means--it isn't clear what you're actually trying to do . it's essential to know that if we are to understand what you might mean by "" bias . "" are you interested only in means or are you interested in the entire distribution ?"
281097,"please explain what aspect ( s ) of this plot make it "" evident "" that the residuals have a non-normal distribution . have you looked at a qq plot of the residuals ?"
78989,"what is the dimension of your "" space "" ?"
79312,""" sine "" and "" sinusoid "" are the usual english words . it implies periodicity . in your case , the peaks at 9 , 18 , 27 , 36 , . . . imply a period of 9 . what does ar ( 1 ) have to do with your question ?"
79937,"should follow from the delta method , and also probably be part of the output of whatever statistical package you are using . can we see some code ?"
80125,why don t you add doithinkthisoneisrainier as regressor in the original logistic regression ?
80421,re the edit : are you now asking a statistical question about simulating data for a random effects model ?
81898,what could be 'best' might depend on a number of things ; what are you trying to do best at ?
82076,what do you mean by 'exactly the same characteristics' ?
86288,are you familiar with finite mixture models ?
87480,can you link the paper or give us the citation ?
87514,because this merely asks for a list of things it doesn't really fit within the se framework . * what actual problem are you trying to solve ?
87759,isn't this a standard result in [ principal component analysis ] ( url ) ?
88005,louvain method ?
92191,are you looking for code ?
92394,it's not clear from your quote what they're in fact testing for normality ( are you sure it's the residuals ?
93429,the paper is behind a pay wall . can you replicate the table ( or a simplified mock up of it ) ?
94030,your question seems to be based entirely on a typographical error : the quotation minimizes $ frac { 1 } { 2 } w ^ 2 $ while you write $ 1 / w ^ 2 $ . does that resolve the issue ?
94556,"the hard part of this question concerns how to cope with a * discrete * set of values of your dependent variable , the unit prices . could you please then tell us a little more about them ?"
95446,"are there only 2 values , or is there a series of values like the 2nd one or in between the two ?"
96057,this reads like regulation bookwork . is this work for some subject ?
96264,a p-value is computed given a null distribution for the data . what is the null distribution in this case ?
96582,what justifies drawing from the dirichlet distribution to simulate outcomes of the rolls of a die ?
97556,related : [ equivalence tests for non-normal data ?
99752,are you including a covariate in your ancova ?
100133,""" correlate to any given single date "" is unclear to me . wouldn't just tabulating the frequencies give you what you want ?"
100594,"could you please clarify what would constitute an "" explanation "" of a pdf ?"
100729,how much math do you want ?
100819,"the wlln , [ as usually stated ] ( url ) , concerns a sequence of independent * and identically distributed * variables . because these obviously do not have identical distributions , either there is nothing more to say--the wlln does not apply--or else you are referring to some generalization of the wlln . if so , what does that generalization state ?"
101058,"your "" derivation "" is puzzling because it begins with what you are attempting to show , whereas logically ( if not always narratively ) derivations always begin with what you * assume * and end with what you want to show . there also do not seem to be clear connections between successive statements in your work . what reasons justify each of the equalities you have written ?"
101117,"the properties of your data are a bit unclear . for each project there is a population of software modules , but inside each project , how could you compute the correlation between the modules if you only have one value per module ?"
101381,did you try ` ?
103151,you do know the distribution of the random variable that will follow given that you know the current value ; it's in the transition matrix . do you know the probabilities of the initial state ( $ x_1 $ ) ?
105204,"if you're asking about principal components regression , beta coefficients are effect size estimates . are they not the ones you want ?"
105624,what do you mean by range of errors ?
105687,"your question does not contain information about how $ p ( t mid alpha , beta ) $ depends on $ alpha , beta $ . do we even know that the integral converges ?"
107621,what would it mean for the coefficients to differ significantly ?
107756,you can have constant coefficient of variation while variance changes . you can even have constant variance while coefficient of variation changes . so looking at ( say ) levene's test won't directly tell you about coefficient of variation . are you asking instead whether those tests might be modified to deal with comparisons of coefficient of variation ?
108632,"what do you mean by "" if the two groupings differ significantly "" ?"
109263,do you have the sample size for the previous study too ?
109923,"when you tag this as self-study , are you answering a question like this ( e . g . from a textbook ) , or just interested in this question because of something that came up in the course of study ?"
110473,"i'm not sure the time is something i would ever look at to see if i thought something was being sent by a human . if i were , i would guess i would maybe be tipped off if it were a round number . have you considered just having the program wait a random number of minutes after it makes the relevant determination before firing off the e-mail ?"
111778,"this will depend on the distribution of the small-rectangle dimensions relative to the dimensions of the field , an the number of small rectangles . are the rectangles oriented to the axes of the field ?"
112878,could you tell us a little about your motivation for using $ x_1 / x_2 $ in this model ?
114427,to be clear ; are you fitting the same model to every subset ?
114901,"how did you deem them as "" not statistically significant "" ?"
115381,"you question would be improved by clicking the "" edit "" link in its lower left and expanding to describe : what is the distribution of number of trials ?"
115765,are the values of your variable always integers ?
115816,a plot of residuals vs what ?
116000,if you can say -- what does $ y $ represent ?
294809,do you know the underlying number of observations ?
116848,"unfortunately , this obvious rule for averaging is not always the correct one . the answer depends on the nature of the measurement errors . if on the machine scale they are homoscedastic then the arithmetic mean has a better justification than the geometric mean . a common example is a ph meter : the "" machine signal "" is the number on the meter ; the dispersion of its measurement errors will be fairly consistent across its range of applicability . one puzzling aspect of your question is the reference to "" raw machinesignal values "" : how do these differ from the left side of the equation ?"
117203,what are bl / fu ?
41913,what software are you using ?
117890,"interesting question . you might also ask if a player is scoring below his / her own historical average . in any case , how many data points do you have for each player ?"
119775,"perhaps you should include _what_ you have calculated thus far so that people will know exactly where you are stuck or made a wrong turn . also , you might want to start with something smaller . if $ y $ is the number of heads on the first toss of 2 fair coins , what is the _distribution_ of $ y $ and what is $ e [ y ] $ ?"
121107,[ law of total variance ] ( url ) ?
121643,why not compute an odds ratio of black / white victim vs . black / white reported ?
122559,are you familiar with the definition of a p-value ?
123098,"could you had the homework tag , please ?"
123638,not clear : do you mean whether / how visualization functions ( such as varimpplot ) in the randomforest * package * sort * variables * in the output ?
124822,have you tried logistic regression ?
125034,can you be more specific about what is given in part 1 ?
56511,"a more robust method would be to test for symmetry around the * median * : after all , when a distribution is symmetric about its mean , its median must coincide with its median . robustness is desirable because a single outlier would cause the empirical distribution to look highly asymmetric around the sample mean but would barely affect the symmetry around the sample median . but precisely how do you propose to apply the wilcoxon test here ?"
125275,what do you want to know ?
125420,"i don't completely understand your problem . basically when you estimate the parameter vector there is a covariance matrix associated to it ( based on your assumption about noise ( residuals ) ) . what do you mean by error bound , new sample and the optimal weight ?"
126175,is there some reason why you can't hand each of the multiple imputations to your downstream code and then combine the outputs from the multiple invocations of the downstream code ?
126813,"what exactly are you hoping to accomplish by the "" mean subtraction to avoid linear dependency "" ?"
43503,what sort of probability and calculus background are you assuming ?
113813,"it would really help if you were to describe what the "" custom tables feature "" in spss actually does . . . as it stands now , this question can't be answered unless we know by heart what the custom tables feature of spss does . what do you want to achieve exactly ?"
106075,"it's not evidence of bias that a model or procedure often predicts values that often occur . on the contrary , isn't that what you should want and expect ?"
132798,is this homework ?
132793,what is the purpose of the simulation ?
132833,do $ x_1 $ and $ x_2 $ enjoy a _bivariate_ normal distribution also ?
134924,could you do a test for normality on the log of the data ?
137055,how do you want to compare the data ?
136848,what are the reasons for the missing data ?
137654,how is defined $ lim a_n $ ?
136947,why not use multinomial logistic regression ?
139459,"if you could not find a specific answer , then you must be meaning to ask something different than what the question actually states : there is one , and only one , definition of a standard deviation for a population , period . what , then , do you mean by "" population "" and "" standard deviation "" ?"
139591,what are mlr and lda ?
140094,is this intended to be a [ pointwise interval or a simultaneous interval ] ( url ) ?
137507,i've used ctrl f to try and find these phrases but they don't appear . could you please include page numbers ?
140623,"what do you mean by * * * vectors * * * * that are by necessity zero , because they were never included * ?"
141600,is the variable normally distributed before the standardization ?
141587,what kinds of differences do you want to detect ?
142490,how much data do you have ?
143372,"are you looking for an explanation of the financial model , an explanation of how the moment conditions result from that model , or just how to code conditions and estimation into r ?"
143849,"if you considered cross-sectional i . i . d . observations ( rather than time series ) , would you regress d on a , b and c ( $ d = beta_0 beta_1 a beta_2 b beta_3 c varepsilon $ ) , obtain fitted values $ hat { d } $ and take $ corr ( d , hat { d } ) $ ?"
145158,"the [ law of the unconscious statistician ] ( url ) tells us that $ $ e [ c ( t x ) ] = int_0 ^ infty c ( t x ) cdot frac { 1 } { a } e ^ { -x / a } , mathrm dx . $ $ can you calculate the value of this integral for the given function $ c ( cdot ) $ ?"
144351,"this symmetry property is peculiar only to a few confidence interval procedures under very special circumstances . it is not part of the defining properties of confidence intervals , nor is it true of many common cis ( such as for odds ratios in logistic regression , to name just one common application ) . because "" proportion confidence interval "" does not have a definite meaning-- * what procedure is being used to compute the interval ?"
145435,have you already reassessed any patients ?
145959,"in theory yes , but what percentage accuracy you achieve will depend on the training set and the discriminative ability of the 5 features you've chosen . other algorithms may perform better , but you would have to empirically test them . do you know what accuracy level you are trying to achieve ?"
147257,related : [ how to simulate data that satisfy specific constraints such as having specific mean and standard deviation ?
148646,"based on your answers , i would guess you do not have that many observations and the interaction term absorbs some of the main effect ( are x1 and x1x2 correlated ?"
149079,"you might ask yourself 1 ) what is 'poi' , 2 ) how might you write the first line without the tilde sign , and 3 ) what would 'poi' look like if written out more explicitly ?"
149531,"a more general question : is there any statistical theory that would tell you how this * ought * to work , let alone how to convince r to do that ( whatever it is ) ?"
148197,"are each person given the three choices a-b , a-c and b-c ( for one set of three sentences ) , or are each person only given a ( random ?"
153695,how many variables your full dataset has ?
155845,"we use * mathematica * here , not maple . ( maybe our site logo is not that readable ?"
157650,"do you have the function that returns the "" quality "" of the selection , or are you estimating that too ?"
157662,` ?
158153,"the poisson distribution can be thought of as modeling a process both having a fixed average rate of events _per unit time_ and having independence between events . so as you pose the question , it seems that a poisson process would have more events if you examined longer intervals of time . did you mean something else by your question ?"
158601,"could you tell us why you do this , what you want to achieve ?"
158828,"have you tried to apply statistical tests for unit root like , e . g . , the dickey-fuller test ?"
159891,"the title appears to contradict the question , which asks about the trace of the * inverse * of the covariance matrix . which trace do you want to know about-- $ text { tr } ( s_0 ^ { -1 } sigma ) $ or $ text { tr } ( sigma ^ { -1 } s_0 ) $ ?"
161053,"it depends on how is your data , and which assumptions you're willing to make . . . do you have daily values of no-shows ?"
161950,what is the value of the chart ?
117660,"are you sure that you don't want your two level model to be ` y ~ a * b ( 1 a * b subject ) , d [ d $ c = = "" 1 "" , ] ` ?"
118573,"consider two categories with the labels 0 and 1 . you have four $ 0 $ 's and six $ 1 $ 's . whatever function you use to transform your data , all four $ 0 $ 's will become whatever you make $ 0 $ become when you transform it . so if you say "" $ 0 $ becomes $ 5 $ and $ 1 $ become $ 17 $ "" , you've specified a transformation . how does that help ?"
119805,""" * but does not involve a confidence interval that has only one continuous interval but not two separate intervals * "" . . . is confusing -- the first not combined with the second not suggests you * do * want two separate intervals . can you clarify your language so we're not trying to guess how you intend such double negations ( "" not . . . ( not . . . something ) "" ) ?"
120068,"1 . no , a poisson distribution generally has a _mode_ in the vicinity of its parameter , and so to match this up with a poisson distribution would mean a very small value for the parameter . 2 . yes and no . what would you want to do with a normal distribution ?"
120168,"what do you mean by "" nonparametric "" ?"
120576,"if i understand correctly , you are mixing distributions with random variables here . imagine you have a zero-mean gaussian rv p and your q = -p . then they have have the same distributions but e p - q = 2e p 0 . maybe give some details about what for you need the l_1 distance ?"
120885,""" better "" for what purpose and context ?"
121598,"if $ x $ is a vector , then $ bar x $ should be presented as a scalar , not as a vector . is this the case ?"
122056,what is the purpose of this glm ?
122425,"( 1 ) in ordinary regression $ beta_0 $ is a fixed but unknown quantity ; it has variance 0 . presumably you're asking about the variance of the * estimate * , $ hat { beta } _0 $ , which is a sample quantity , a function of the data ( and the observations , being a random variable , do have a variance ) . $ quad $ ( 2 ) your question is unclear . for example ( though this isn't the only issue ) , you talk about $ beta_0 $ and $ beta_1 $ ; were either of those meant to be the other there , or are you discussing an issue involving both ?"
122997,"why not just get a good , up to date regression textbook ?"
123423,did the judge explain his scepticism ?
123595,can you clarify your question in the body of the thread ?
124726,what do you know ?
125372,"as you have found , that's not a profitable avenue of investigation : you have enough data to discern potentially * nonlinear * relationships among the data . what do your scatterplot matrices suggest ?"
125393,please explain why this was not posted on crossvalidated . com ?
125711,"for better answers i suggest you say what classification procedure you're conducting . if it's predicting a binary outcome , how high is the incidence rate of that outcome ?"
126245,what is $ a $ ?
126714,could you provide more detailed description ?
127189,"you have to define them before we can comment . in general anything based on high powers is likely to be unstable . there are exceptions e . g . with values defined on $ [ 0 , 1 ] $ . note that l-moments are named by analogy with conventional moments ; they are not robust versions of the latter . ( what did 7 do that it is out of favour ?"
127415,your example code doesn't show logistic regression ?
128873,is this an assignment for a course ?
130769,"first and foremost , endogeneity should be supported by a strong logical argument . why do you think steel prices are endogenous in your model ?"
132874,who goes first ( it matters ! ) ?
133145,"are the categories ordered , or just numbered that way ?"
133750,welcome kris91 . you can do this many different ways . can you amplify your question to indicate more specifically what story you are trying to tell ?
133758,if you know there are two classes ( which seems to be what your first sentence says ) why are you varying the number of clusters ( or doing k-means ) ?
134434,"this isn't very clear to me . can you say more about your situation , your data , & your goals ?"
136190,1 . are you required to use method-of-moments estimators or are you looking for any good estimator ?
136497,"when you say 'discrete' are these counts , or some other kind of discrete data ?"
138433,` atan2 ` ?
138439,"i do not see any place where it is asserted that the error terms are the "" same . "" could you elaborate on your understanding of what "" the same "" means ?"
140050,"is there some reason why the "" m "" s were separate ?"
141156,did you just ask the same question a few days ago & delete it ?
141325,"do you mean you have a regression model and you'd like to perform this model to two different sub-groups separately , like males only and females only ?"
141229,is $ x $ a discrete random variable or a continuous random variable ?
141422,unfortunately it is quite difficult to estimate parameter values when you do not have data . . . perhaps you can gather more from nearby neighbourhoods ?
141477,"in what sense do you have "" additional data "" for those 10 samples ?"
142164,this is too broad to be answerable as stated . can you narrow your question ?
142457,"if you know the probabilities apriori , why would you make that argument ?"
142593,could you provide a reference for your quote for clarity ?
142822,what implementation of naive bayes are you using ?
143390,p-value is not likelihood . how were the p-values obtained ?
146175,what is the data-generating process ?
146349,"to clarify- do you "" bank "" points over the rounds ?"
147841,"i do not understand where this continuity correction comes from . why is "" $ x 1 / 2 $ "" to be preferred in the argument of $ phi $ instead of "" $ x $ "" ?"
147862,"when you say "" we know the distribution function that describes the nuisance parameter "" , i'm a little confused . in the lrt , parameters are fixed but unknown . if you're describing a parameter by a distribution it sounds like you're taking a bayesian approach instead , which would lead people to wonder , why discuss lrt at all ?"
148414,"okay , great . would you be so kind and post your finding as answer and accept it ?"
148916,"what does your "" score "" represent ?"
149220,"do the quotes in ` ' , data' ` matter in matlab syntax ?"
151769,exponential function is quite linear when close to zero : $ e ^ { delta x } = delta x o ( delta x ^ 2 ) $ . are you sure that's not the case ?
151994,are your effect variables properly coded ?
153563,thanks . could you elaborate on what kind of answers you are looking for ?
153997,"this is a question you likely can answer yourself in a minute or two . why not write down all three possibilities for $ mathbf { p } $ and $ f ( mathbf { x } , mathbf { p } ) $ when $ k = 3 $ ( or even just the two possibilities for $ k = 2 $ ) and compare them to what hogg's formula says ?"
154274,""" identifying principal components on the full model specifications , including interactions "" - what does this mean ?"
155653,"there is to little information here for any answer ! one dosnt simply "" do a visualization "" of a dataset , one does so as the response to some specific question about the dataset . so , what is your question ?"
155752,but why not look up the expected value for the gamma distribution directly ?
157070,it looks like the actual question was cut off ?
157944,what do you mean when you say that : i am running the trained network on the training data itself again ?
158368,do you actually mean that the model was accurate only 7 % of the time and then improved to being accurate only 23 % of the time ?
158759,how does the data look like ?
158957,so you have four data points ?
159057,the chi-square-test can also be used with larger tables than 2x2 . could you explain why the chi-square-test should not be appropriate for your problem ?
160023,"welcome to cv ! you may have more luck obtaining an answer if you give a bit more detail on what you're looking for , and how the common resources you've found are inadequate . e . g . , are you looking for examples of how to interpret rank-biserial correlation within a certain field ?"
160265,can you paste in your output ?
160494,"still no information ! do you mean something qualitative , counted , measured ?"
160691,"these graphs , which appear to be logging amplitudes continuously over time , do not seem to be consistent with your description , which suggests logging would consist of intermittent values followed by periods of nothing . could you clarify the connection between the graphs and your description ?"
160826,how is your rbf kernel dealing with 128 bit data ?
160932,"what do you mean by "" association between "" the variables ?"
161031,the variable you reference is not in the attached table ?
161204,how many possible actions & how many groups are there ?
163367,"your question , as currently written , is about * asymptotic * behavior , which is completely different than issues of normalization in a particular * finite * sample . what are you actually trying to ask here ?"
163725,"ponder this : when $ f $ is a one-to-one function defined on the range of the sufficient statistic $ t $ , then is $ f circ t $ ( defined by $ ( f circ t ) ( x ) = f ( t ( x ) ) $ ) sufficient ?"
164136,is it possible ?
164254,"the question in your title asks about determining first-order stationarity whereas in the text of your question , you ask only about the mean being constant which covers a much wider class of time series than the first-order-stationary time series . which property do you really want to test ?"
164366,"you must look for some indication of spread in each of your papers , be it confidence intervals , standard deviations or mean square errors . what do you find ?"
164629,could you explain what the matrix is composed of ?
164650,"i notice you are asking a series of "" proper name "" questions . could you please , then , explain what you mean by a "" proper name , "" state why you expect there might be a universally accepted such name , and indicate why knowing it might be of interest ?"
165022,oftentimes the first relationship you have written is taken as the definition of $ e [ x mid a ] $ . what conditional expectations have you defined ?
166359,are the same predictor variables included in the models for all of the imputed data sets ?
177007,check the literature of ` rank 1 updates ` . [ fast online svd revisions for lightweight recommender systems ] ( url ) by brand is an accessible first paper . i have not seen something for svd already implemented in r unfortunately . cholesky updates exists ( ` updown ` from ` matrix ` ) thanks to cholmod . the sparsity of your matrix $ a $ will really make a different to your final solution ; do you assume a dense or a sparse matrix ?
255495,unless i misunderstand you that is the usual interpretation . do you have some specific doubt which makes you ask ?
285501,i don't think this is often done . where did you find this ?
166860,"your random draw is equivalent to two independent operations : ( 1 ) pick three aces . ( 2 ) pick ten non-aces . since these operations are independent , their probabilities will multiply . that accounts for two of the terms in your product . where does the third one , $ binom { 13 } { 1 } $ , come from ?"
166869,would it be correct to infer that these are * two-sided * confidence intervals ?
167247,"the title does not exactly match the content . anyway , the model not being significant is an indication you might want to consider another model . i am not sure about the answer to your main question , though . if you rely on the model , you can surely report the association between x and y . however , should you rely on an insignificant model ?"
169312,"the question about ` r ` code is not on topic here . the issue that lurks beneath this request , though , concerns how to interpret the results of conducting all these t-tests : the p-values you want to display can no longer be interpreted as you might hope , because they are interdependent . might i suggest you would be better served by posing this question differently ?"
171726,do you have any negative examples ?
171735,"are the points labeled with an id ( analogous to 'patient 7' ) , such that you know a given point in one frame is the same as the point in another ?"
171843,adviced by whom ?
172669,"this one's hard to answer without additional information . what is this "" $ n $ -vector $ v $ "" ?"
172865,the last couple of sentences in whuber's comment is probably the most useful / to the point thing one might say . i expect that either one of your columns or ( more likely ) some of your rows have a small total . what are your two column totals ?
175498,it would depend on what you were trying to do with your regression . what is your purpose ?
175594,how many teachers and classrooms do you have ?
176326,and make it clear : are you speaking of selecting the model family or selecting terms to include in the model ?
177025,"i know you are using basketball as an analogy , but in your real situation , can we assume that the experimental trials are independent ?"
176892,"what do you consider "" advanced "" probability theory and stochastics ?"
177487,"that probably depends on your data . if the data is from a very limited range , it might we producing outputs only btw . 0 . 4 and 0 . 47 . how did you perform feature scaling ?"
174944,"to be clear , this prior is a pareto ( 1 , 1 ) distribution . the posterior form is known and has finite moments : pareto ( max ( 1 , data ) , 1 sample_size ) . the fact that the prior does not have a finite first moment shouldn't scare us as long as it is a distribution ( e . g . , using a cauchy distribution as a prior ) . so i'm a little confused as to what the problem is exactly ?"
180552,"droko , what software are you using ?"
181084,could you tell us specifically what the number $ a $ means ?
181481,"you seem confused about your response . you say that you have "" count data "" , which usually implies that your response variable consists of integer counts , ` 0 , 1 , 2 , 3 , . . . ` but then you talk about having three groups a , b , c and you say "" my response is categorical with three groups "" . so is your response counts , 0 , 1 , 2 , 3 , 4 , . . . or is it groups a , b , c ?"
182979,"it seems to me that the definition of empirical variogram ( url ) can accomodate arbitrary definitions of metric , or perhaps i'm missing something here ?"
184192,how does the accuracy of your forest compare against the best constant model ?
184694,"nick i believe the situation may be subtler than that . suppose i have $ m = 4 $ lists in which subsets of a fixed collection of $ n = 3 $ items are ranked ab , ac , cb , and abc , from first to last in each case . could we posit some reasonable probability model to handle the discrepancies among these lists and from that develop , say , estimates of the probabilities of the correct ranks of each of a , b , and c ?"
187449,can you provide some details about the mcmc generator ?
186167,this question is ambiguous : what are your quantifiers ?
188213,could you elaborate on how this is to happen more precisely ?
189185,in principle hypothesis tests about multiple interaction terms in the same model results in multiplicity . are these terms really of interest or just potential confounders ( in that case it may not really be a mulitplicity issue ) ?
190286,"it's going to be difficult to figure out on the information given . note that from the formula on the page you link to , to get a value bigger than 1 , $ sum d_i ^ 2 $ would have to be negative ( which is not possible ) . what value did you get for $ sum d_i ^ 2 $ ?"
190780,what is your definition of the non-central $ chi ^ 2 $ distribution ?
191372,"and what will happen if the prediction is : 0 . 33 for class 5 , 0 . 33 for class 4 and 0 . 33 for class 1 ?"
191635,do you have access to the original counts ?
191988,are you just asking for a ml algorithm that can predict categories from features ?
192013,'median' suggests there were originally multiple times . is that true ?
192124,100 observations aren't much for a multinomial probit model . how many variables w / how many levels do you have ?
192416,"a two-way anova is giving you a test of factor a while controlling for factor b ( & vice versa ) , if you use type iii sums of squares . was the extra test only given to one treatment group , or to some of all groups ?"
192366,"i'm probably misunderstanding something , but isn't this a basic sample mean problem ?"
195266,"out of curiosity , what data would you use to "" predict the optimal inventory level at [ your ] clothing store "" ?"
194233,how do you distinguish a local instead of a local optimum in this case ?
196672,have you considered a dynamic factor model ?
197551,"i think this is a great question , but you need to be more specific : ( 1 ) what do you want to do with the data in the end ?"
197875,peuhp is your parameter continuous ?
197748,"it would seem that "" contribution to dependent variable "" is another term for * estimated coefficient . * why wouldn't its absolute value be the basis for determining "" importance , "" then ?"
199053,are the outliers obviously corrupted data ?
199008,"when you say you have poisson distributions . . . do you have two poisson observations each thought to be drawn from a poisson distribution , or do you have a collection of poisson observations from each ?"
199267,"welcome to the site . could you provide some background on the circumstances that produced $ s ^ 2 = 0 $ ( which is unusual for real-life data ) , eg sample size , whether the variables are continuous or discrete and , if continuous , whether there was any rounding of values ?"
199704,what do you mean by ordinate ?
200742,"this is not very clear . so you have $ n $ respondents and 30 questions , you did pca , and you extracted 6 components . each component has $ n $ values . and now you want to run an anova to see if the components are different from each other ?"
202840,have you considered factor analysis ?
205226,"the example data contains some "" positive response "" which is a percentage , so it does not exactly match your description ( that there would be a yes / no dependent variable - can you clarify this detail ?"
205464,you might find the thread [ how to efficiently manage a statistical analysis project ?
206440,"you are basically telling us you can freely simulate $ ( x_1 , x_2 ) $ ( simply by ignoring the values of $ x_3 $ ) and are asking how to "" evaluate "" the cdf of $ ( x_1 , x_2 ) $ . could you please then tell us what you mean by "" evaluate "" ?"
208677,interesting questions . what is the distribution of counts for the patient visits ?
207806,yes there are in this context . having said that you appear to fit a simple linear regression model . in this case the standard ` regstats ` would do just fine and you could follow the example in the webpage directly . is there something caveat that enforces the use of ` glmfit ` ?
208854,"if you calculated the % s & ses for 15 / 300 & 10 / 150 , how would that not take into account the differing sample sizes ?"
209506,"the frequencies in the table are certainly different . 79 $ neq $ 0 , for example -- that's not really a statistical question , which generally relates to some form on inference about unobserved / unobservable things like population quantities . are you interested in making some inference about comparing population proportions in rows or in columns ?"
210448,can this be the result of simpson's paradox ?
211483,is y your input or output variable ?
211618,can you clarify your data set ?
212872,"if there is one peak , why would the median necessarily be the peak ?"
213229,what are the data ?
213127,"have you tried going back to read the [ clark 1973 "" language-as-fixed-effect fallacy "" paper ] ( url ) that loftus and palmer cite . . . ?"
214234,"could you elaborate on what needs "" improving "" ?"
215343,researchers might do it for any number of reasons . i could mention several reasons but none of them might apply to the particular bits of research you have seen . which ones were you looking at that used it ?
215639,1 ) is answered by looking at the documentation ` ?
216251,do you plan to set the gaussian prior restricted to the triangle ?
218991,do they have the same values of their parameters or not ?
220468,"you need to finish the calculation ! what is ` ( 1-ppois ( 9 , 5 ) ) dpois ( 9 , 5 ) / 2 ` equal to ?"
220848,the polynomial is alarming . how do it know to be flat for values of the argument less than about 0 . 4 ?
222193,"presumably r-squared does change , just by a value . 0005 ?"
222620,what measure are you integrating the likelihood against ?
149312,what if the minimum error is greater than zero ?
223441,"you just said "" trying to graph it "" but graph what ?"
223544,i do not use stata but i am surprised that a repeated measures design with nine observations per participant is unanalysable . perhaps you should try posting your code on a stata-specific site for help ?
226011,"anova makes * no * assumptions about the distributions of the explanatory variables ( the factors ) . in fact , you don't have an anova problem , you have a regression that you're trying to shoehorn into the anova framework by binning your variables . why not solve it using appropriate regression techniques ?"
227028,could you include model estimation output ?
229764,"expectation is a linear operator , so its ( order ) can be interchanged with summation and with the constant 1 / n . how on earth do you get $ e ( frac { 1 } { n } sum_ { i = 1 } ^ nx_i ) = frac { 1 } { n } sum_ { j = 1 } ^ n left ( frac { 1 } { n } sum_ { i = 1 } ^ nx_i right ) _j $ ?"
177955,do you have training data where expressions are labelled by true categories ?
158019,why are you performing these normality tests ?
166559,is it possible for a random * * variable * * with 0 mean to have a positive expectation after compounding many observations ?
166963,"could you clarify what you mean by "" calculate "" and "" value "" ?"
167539,"what do you mean by "" monthly score "" ?"
169128,"welcome to cv . 1 . what is "" * population churn rate * "" ?"
169407,are you asking what test to use ?
169663,"it would be helpful if you posted your data , but if not , tell us what the outcome measure is and what other variables you wish to include in the analysis . is the outcome measured twice for each patient ?"
171236,did you try a logistic regression with $ x_i $ and $ hat { pi } _i $ as independent variables ?
171429,are you asking about ml ( e . g . url ) . . ?
172516,"could you elaborate on these "" bounds "" , given that * all * correlation coefficients must lie in the bounded interval $ [ -1 , 1 ] $ ?"
173051,"lets say $ x $ is measured in seconds , the units of $ y $ are $ frac { 1 } { sec } $ , why would that make sense ?"
173352,is this a question from a course or textbook ?
173733,are you referring to a ( network ) graph ?
173815,"it is newton's binomial formula for $ n = 2 $ : $ ( a b ) ^ 2 = a ^ 2 2ab b ^ 2 $ : ) actually it is just simple matrix multiplication , which term do you have a problem with ?"
174572,did you see this ?
175344,there's no notation for bayesian stats that's standard enough that we can be completely sure what $ h $ is intended to be . what's $ h ( x ) $ in this context ?
175372,for which parameter would you like to compute a confidence interval ?
176096,"which variables are "" firm data "" ?"
176869,"what does ' * some kind of "" real "" thing * ' mean ?"
177828,"welcome to cv ! i think you ought to clarify whether your analysis is going to include both "" naturalness "" itself , as well as the individual items that it was constructed from , or just "" naturalness "" ?"
178814,is the number of observations ( 8 in your case ) for one user realistic ?
179193,conditional on what ?
179522,do you have a reference for the test ?
179654,"do you mean the model by pea & poncela [ "" forecasting with nonstationary dynamic factor models . "" ] ( url ) * journal of econometrics * 119 . 2 ( 2004 ) : 291-321 ?"
179508,"first , a remark : in any real ( non-artificial ) dataset eigenvectors will have non-zero elements for all features , so your $ alpha $ and $ beta $ should probably be linear combinations of all five $ x_i $ variables . apart from that , what you describe in the body of your question is called "" principal component regression "" ; in this framework the answer to the question in your last sentence is * * yes . * * but i am confused by your title , which has * nothing * to do with what is described in the question body ; could you please edit to make them correspond to each other ?"
180057,"if $ lambda_1 neq lambda_2 $ , they're not iid , and if $ lambda_1 = lambda_2 $ , why distinguish them ?"
180556,do you know what norm you are working with ?
180570,"can you say more about your situation , your data , & your goals ?"
181499,what purpose do you have in mind ?
183347,"you need to provide more information about this sequence of events . for instance , it must be a time series . what is the temporal unit or frequency ( e . g . , hourly , daily , weekly , etc . ) and how many periods are available ?"
184650,could you provide an example on how does the data look like since it is not clear from your question ?
184878,in multiple regression ?
184929,there's a huge variety of models ; presumably you're primarily interested in particular kinds of models ; what kinds of models are you dealing with ?
185132,do u have a state diagram ?
186121,""" cross-validation was used on the 12 remaining observations "" -- this is not clear , did you use 10-fold cross-validation ( ten times leaving out 12 observations our of 120 ) or simply computed the error on the fixed test set consisting of 12 observations ?"
187285,your notation is a little unusual . do you mean to say that $ bar { x } _n - bar { mu } _n $ converges to zero in probability ?
187655,how about setting a test on the pairwise distances between the domestically-owned firms and the foreign firms using monte-carlo simulation ?
188023,do you have grounds to believe that the apparent skewness is not just small-sample variability ?
188275,"please add some context & spell out your acronyms . by "" lda "" , do you mean linear discriminant analysis , latent dirichlet allocation , something else ?"
188370,do you need to know about the normal distribution ( e . g . the _title_ of your question ) or the _lognormal_ distribution ( in the text ) ?
189174,"in what sense are you using term "" dimensionality reduction "" ?"
190051,"you can easily calculate the sd even if all your values are negative . for example the sd of $ -1 , -2 , -3 , -4 , -5 $ is necessarily the same as that of $ 1 , 2 , 3 , 4 , 5 $ . what makes you think otherwise ?"
191969,"what does "" internally coherent "" mean , * positive definite * ?"
191980,"perhaps you could provide us with a few more details , just so we can understand the context / motivation behind your question ?"
192834,is this a question from a course or textbook ?
193167,i'm not quite sure i follow . is search costly or is there another reason you want to find the structural relationship ?
193170,"what's "" h0 "" and "" h1 "" in "" null hypothesis : h0 = h1 "" ?"
193889,what variable ( s ) are ordinal - dv or iv ?
194230,why do you want this ?
194317,"the link ( url ) doesn't work for me . can you fix it , please ?"
194747,"hint : if $ x $ were time in minutes and you wished instead to express the law in hours , then evidently $ x $ would be replaced by $ x / 60 $ . can you identify $ c $ in this expression ?"
196670,where is it exactly ?
197314,is this a home work ?
197341,perhaps you could clarify your concern about the t distribution ?
198506,1 ) ` and give poor internal reliability ?
198676,why did some people vote for this as being too broad ?
199092,could you first consider whether or not you can directly derive the distribution of $ y_1 y_2 $ ?
199151,what optimization algorithm are you using ?
199405,"what does "" cleaning "" this text mean to you ?"
199911,what exactly is the full model specification ?
201818,it would be helpful to know more about the circumstances which lead to time and budget stopping you prematurely . are they related to characteristics of the data already collected ?
202098,do you mean with the same variances and with all covariances between pairs of different variables the same ?
202724,could you add a link for the net surgery trick ?
202806,how do you decide tie breaks between nearest neighbors ?
203299,"by "" random matrices "" do you mean in the theoretical sense of matrix-valued random variables , or do you mean that each is an array of * realizations * of random variables ?"
203379,"you are looking for a difference in readings before and after a treatment ( i . e . watching a film ) , yes ?"
204152,"hi , using lasso and elastic net for regression is widely accepted . how do you use the omp , what's the dictionary for maching ?"
204991,could you elaborate on that comment about column sums ?
205330,so you just want to test if the sds for chemically bonded differ from permanent ?
205966,"if ( conditional on $ c $ ) you have continuous variates , how are you summing probabilities ?"
207647,i'm extremely curious : what course is this that they would like you to predict weather but provide you no statistical background ?
208104,what do you mean as linearity condition ?
209990,are you sure those numbers are correct ?
210438,what did you hear was wrong with its statistical soundness ?
210501,"because the differences among response rates may be informative , why not report them by district ?"
210510,"where does the "" 1 . 17 * 10 "" come from ?"
211289,"your tag suggests it's a logistic model . is it definitely a logit model , or something else ?"
211497,"this is rather sparse . can you say more about your situation , your data & your goals here ?"
211520,what does $ hat { pi } ( x_i ) $ denote in the last expression ?
212333,"what is the variance of the measurement error , and what are the mean and variance of the underlying temperature ?"
212942,what makes you say that there is small-study bias in these plots ?
213010,"could you clarify if your question is about how to conduct a power analysis ( i . e . , how many observations should i collect ?"
213171,"by "" different datasets "" , you probably mean that the two datasets have the same feature space , but may include different realizations . correct ?"
213250,i don't quite understand what you are trying to do . what are the dependent and independent variables and what is the goal of the analysis ?
214392,"it's not clear if you are asking about how to interpret regularized cca as opposed to normal cca , or about how to interpret cca at all . can you answer your last two questions ( two last sentences ) for the case of non-regularized cca ?"
214667,what's your sample size ?
215460,` reduce the initial item pool before completing the exploratory factor analysis ?
215559,"i think you need to provide many more details before this can be answered . the topology of the space is practically irrelevant and does not determine much of anything statistically . what * could * matter--although it's unclear how relevant it is to color spaces--is the * group * structure of the space . the sense in which you seek an "" analog "" of the normal distribution would still be unclear : is it the stable distribution of the central limit theorem or is it a distribution giving rise to linear solutions of maximum likelihood equations or is it merely a good description of measurement errors ?"
216036,what kind of generalization are you looking for ?
215980,where is the output for the coefficients ?
218608,how would you compute the distribution of * any * of these variances ?
219367,the wald estimator is equivalent to the 2sls ( with binary endogeneous and binary instrument ) . you could just use a 2sls and its standard errors ?
221942,you want some number of rolls in which the proportion of ` 1 ` s is * exactly * 10 % ?
222081,what parameters did you use on ` rpart ` ?
222520,is this a question from a course or textbook ?
222768,"this question seems to confuse the concepts of "" positive / negative "" * responses * with "" false positive "" and "" false negative "" * errors * . because the two are completely different , it is not reasonable to expect your approach to have any useful properties in general . but maybe you have some very special types of data and classification procedures in mind ?"
223362,i see no link here . can you clarify this ?
224318,"i haven't worked it out , but perhaps there is something useful at url , since it appears that the author is trying to use the inverse distribution method to generate random variates ?"
224485,why do you think that all the p-values should not be adjusted ?
224725,"i even do not know how to do it in r , can we add some constrains on the coefficient when we train the model , say linear regression ?"
225020,"you're familiar with the relationship between conditional and joint density $ f ( x , y ) = f ( y x ) f ( x ) $ ?"
225151,use linear regression ?
226084,what do these 2x22 numbers represent ?
226160,are you familiar with t-statistics and p-value ?
226169,""" . . . variance $ bar { x } ^ 2 / n $ "" ?"
226165,it is not clear to me how does the loops-code relate to your question ?
226661,"you cant have y on both sides of the equation , you are predicting something by itself ?"
226807,do you require $ x $ to be a continuous random variable ?
227104,""" reducing $ m $ via svd to 3 "" means that you take the first three terms from the [ dyadic expansion ] ( url ) of the matrix $ x = ( x_1 , x_2 , dotsc , x_m ) $ ?"
229082,more specifics ?
229224,stupid question : your objective is to normalise your $ x_i $ or do you have specific constraint on the problem formulation ?
229244,can you give us any information about how that variable fits within the science of your problem ?
229638,could you give an example with code and what you have tried so far ?
230605,which text is this ?
231102,are you trying to program this out yourself ?
231145,did you tune the parameters on the svm ?
231289,how is age factored into the calculation of the t score ?
232006,"if you are using ` xtmixed ` , or ` mixed ` , that can take a looooong time . if you are using ` gllamm ` , that takes even longer . hierarchical models are slow to run . how many levels do you have ?"
232028,"just to be clear , the noise variables are independent across time and from each other ?"
232392,"at the moment this question is rather broad and it isn't especially clear what you are asking . providing some context would be very helpful - e . g . can you give us a citation for the two articles you are talking about , and some key quotes from them ?"
232424,"this question is too broad to be answerable , because $ u_ theta $ could be almost any function at all . what can you say about how $ f $ depends on $ theta $ ?"
232555,"can you post an example of the problematic case , i . e . with multiple "" overlapping "" modes ?"
232591,"adf test is known to have low power . however , it is still confusing that it works for the original series but not its simulated copies . what test specification are you using , is it with drift ?"
240794,not necessarily . you need to give us a bit more information . which is you sample size ?
253290,"this may sound like splitting hairs , but i think you want margins of error not for "" each question "" but for the % of respondents who choose each option . right ?"
268521,"please clarify . suppose one of your categorical models is region { east , west , north , or south } . would you try to square "" east "" ?"
278035,are you talking about minimum sample size ?
279087,"did you fit data on the ( x , y ) pairs with a linear model ?"
282608,"i would understand consumption to be a variable that is necessarily non-negative . in what sense , then , do you think of it as being "" censored "" at zero ?"
287035,can you give us more details or an example ?
341432,"usually in statistics by * parameters * we mean something unknown to be learned from the data and by * variables * the "" columns "" in your dataset . so parameters cannot be extracted from the data . could you clarify on this ?"
234988,what is the average of three rolls of a die ?
235071,the question seems to me to imply that only two samples were used to obtain peaks . is that the case ?
237131,you should first start by stating your objective . are you trying to study differences in mean or variance ?
154526,"there is the "" * frankenstein * "" distribution that is known as the [ johnson s_u distribution ] ( url ) . you can probably fit it so it looks like a a flat-top gaussian but really . . . why ?"
238093,"it would seem there is little to answer here : if you convert categorical data to numbers in different ways--which is something you risk doing if you perform the conversion * after * splitting--then any comparison between the two datasets will be meaningless . but otherwise , what difference would it make ?"
238165,the standard error of what ?
238139,what's a triangle relation ?
239677,"your problem is not very specified , so there are many possibilities . given $ a 0 $ , $ b 0 $ , $ w = ab $ , and your desire for "" convenience "" , a simple possibility would be log-normal for all three . this would certainly be more appropriate than normal , for positive variables . what are your "" uninformative priors "" ?"
241795,what are you asking exactly ?
242080,"when $ j ge 2 $ , your probabilities in your solution to $ ( a ) $ are obviously greater than $ 1 $ . in $ ( b ) $ , pick any $ j $ : what happens to $ pr ( y_n = j ) $ as $ n $ increases ?"
242274,"what does "" the estimation given by pathologists "" look like ?"
243061,"are you asking , why * squared * residuals is more informative than some other measure such as absolute values or 4th powers ?"
243423,what's the practicality of this ?
244803,do you know anything about the distribution of the sample variance ?
244589,"are you referring to the sample correlations ( as i'd expect when referring to * data * , which you mention ) or population correlations ( as i'd expect when discussing variables , which you also mention , and use notation to suggest ) ?"
245418,"why not put the outcome on the y-axis , one of the predictors on the x-axis and plot separate symbols for the other predictor or different lines ?"
245771,what exactly is your goal ?
246025,is that an ` mgcv : : gam ` or a ` gam : : gam ` ?
246152,it seems surprising how narrow the precipitation graph is . have you averaged over time or location ?
247050,""" i understand that certroid-based classifiers are better than k-nns . "" - what do you mean with "" better "" ?"
247743,""" i know how to estimate population standard deviation using a chi square distribution "" exactly what procedure are you referring to ?"
248125,what is your research question and your variables ! how are they measured ?
252954,your question is a bit muddled and sort of runs on -- it reads like you're asking something after having run in from outside and you're out of breath and haven't quite gathered your thoughts yet . can you clarify what you want ?
181292,what's the question ?
255352,"do you mean something like "" smoking does not cause cancer "" ?"
255731,"what do you "" average "" over , i . e . what are the weights on individual paths ?"
87182,"based on [ your reaction ] ( url ) , i suppose what you mean is * * why * * shannon used logarithm in his formula , right ?"
257679,"what is the formula behind "" -7 matching 0 is more significant than ( ?"
258274,what do you intend to do with the model after you fit it to the data ?
258585,how do you compare to your colleagues to decide what is better ?
259121,"in your final confidence interval , do you want to include your uncertainty about the previous 0 . 95 estimate ?"
259118,what is your purpose ?
259410,doesn't ` validate ` in the ` rms ` package do what you need when applied to a ` cph ` object ?
259653,you want to make predictions based on a variable that has the same value for every observation ; is that correct ?
260116,what is ur data set and what is your exact problem ?
260314,""" what would be the best statistical test to show how likely my data is equal to the expected value . ( i hope that makes sense ) "" i'm afraid it doesn't . what are you actually trying to do ?"
262184,"the general answer would be "" [ regression ] ( url ) "" , but that may not be very helpful . the first step would be to gather some data of # letters vs . time for a collection of files . ( you may want to measure "" time "" as something like cpu time , for a more stable estimate independent of platform / load-balancing . ) do you have data already ?"
262738,"there doesn't appear to be any explicit information about hand-washing in your data , so how do you propose to identify "" hand-washing events "" ?"
263870,can you please clarify the nature of your response variable ?
264814,"welcome to stats . se ! please take a moment to view our [ tour ] . you will end up with a sample either way . with that in mind , what attributes are most important to * you * from your survey respondents ?"
265906,"google street view isn't real time . what good would it do to know what the prices were at some time in the past , possibly quite a long time ago ?"
266089,"why not just conduct a ` t . test ` between the original data of the two groups based upon gender ( that is , not just a ` t . test ` between male pre and post treatment and female pre and post treatment , but pre-treatment male and female and post-treatment male and female ) ?"
266976,did you use robust / huber white sandwich estimators for the standard errors in the lpm ?
267055,what do you want to ultimately show ?
268698,"is the claim that each fish has a single "" partner "" that it's consistently close to , or merely that the fish stay in groups of two , with the actual composition of those groups not being stable ?"
269007,"i don't follow your question . the se is the standard error , what does this have to do with the _ "" mean of means "" _ ?"
269783,"it has nothing to do with $ r ^ 2 $ . normally you would include an intercept , and this is not really specific to var models but rather any regression model ( you can search for question on including an intercept in a regression model ) . does the theory suggest anything about the intercept ?"
271673,some questions : how large are you train & test datasets ?
272449,""" precision and recall "" are two common words , but where did you encounter "" completeness and correctness "" words ?"
272884,"when you say that you * know * the mean and variance of $ log x $ do you actually know them , or do you mean that you have sample-based estimates of the mean and variance of the log ?"
274768,1 . a t-test is not a test of normality . 2 . why are you testing normality ?
44645,argh . by weight you mean the values of the estimated coefficients ( e . g . the $ beta_1 $ in the definition section of wiki article ) ?
278919,see [ interpretation of r's lm ( ) output ] ( url ) and [ how to interpret the output of the summary method for an lm object in r ?
280088,"two methods make sense to me , but it actually depends on what you are trying to achieve . what is the index going to to be used for ?"
280111,where did you see it ?
280958,"you are right that the wald test is preferable , particularly when you are using complex survey structures and weights that lead to you estimating a pseudo likelihood instead of a likelihood . in other occasions the likelihood ratio test for joint significance works well and is performed as you describe : fit constrained and unconstrained models and take the ratio . do you need insight on which commands to use ?"
282108,"is this from "" binomtools "" or something else ?"
284831,""" how about duration ?"
285082,i am afraid the results will depend in much extend on bandwidth selection and a number of other factors . what exactly do you want to learn from this data ?
285195,won't it be zero ?
286024,"this question has no unique answer , because the correlation coefficient and the marginal distributions do not ( in this case ) determine the bivariate distribution . could you explain the origin or motivation of this question so that we could help you frame a more useful inquiry ?"
287956,for one example . . . what about sums of squares of deviation from the mean of iid normal variates ?
277194,isn't the variance the 2nd cumulant ?
288636,"the title suggests you did not "" observe "" the order . if you don't have the order information , then you cannot use it as a covariate ; but if you do have the order information , then it's an observation--it's information available to you . what might be of greater concern is whether the order is meaningful and generalizable : for instance , if you intend to make inferences to future treatments where there won't be the same number or spacing of sessions , then perhaps you will be unable to use the "" order "" for this purpose . could you provide a little more information about your objectives ?"
288046,"could you be more specific about the sense in which a euclidean distance is "" required for pca "" ?"
289214,im not sure how a univariate analysis could ever provide more information that a multi-feature regression . what are you looking to learn about your data ?
289411,why would the interpretation be any different than that of the square of any variable in general ?
291049,you have described regression in a nutshell : to estimate properties of the distribution of $ y $ ( not $ hat y $ ! ) as it depends on the regressors / covariates / independent variables . the precise nature of that distribution depends on your model . which one are you using ?
291137,this cannot be answered unless you specify the conditions of the question / bet . does sequence matter or not ?
294104,"you'll need to fix the algorithm yourself because it's unclear exactly what you want to do just from the question . for example , you want to check "" different "" . different in what ?"
294270,welcome to cross validated ! see [ what happens if the explanatory and response variables are sorted independently before regression ?
294933,"the idea behind factor analysis is that , when two ( or more , i take two to keep it simple ) variables are strongly correlated , that this correlation has its cause in the fact that both depend on one same underlying variable . so it is correlation because of some common underlying 'factor' . but when you have no correlation its not worth looking for a 'factor' that causes that correlation ?"
295291,"there are various methods for tuning hyperparameters that might do what you need . but , i don't quite understand your specific requirements . can you say more about what you mean by 'robust' , and 'sensitivity value' ?"
296432,why do you think the ci should lie entirely between 0 and 1 ?
5826,what are the practical issues in using the gam fit ?
298571,"have you already posted with the obvious organizations ( e . g . the rss , industry specific ones such as psi if you are looking for biostatistics expertise etc . ) and at the larger statistics departments ( and other similar organizations such as mrcs ) ?"
298619,are the individual scores available to you ?
240594,"do you really mean "" dependent "" in the title , or do you possibly mean "" independent "" ?"
301721,"are you just asking about the r functions / how to do this in r , or are you asking about mxnet nns generally & a software-neutral answer would be just as good ?"
300439,there nothing special about the negative binomial as far as sample size is concerned . the principles are the same as for normal or gamma regression . why would you think that 161 cases isn't enough for 5 predictors ?
301973,"there is no simple answer even for the "" canonical "" case of normal random variables . for some ideas on how to proceed in some special cases of normal random variables , see my answer to _ [ "" which is the largest , of a bunch on normally distributed random variables ?"
302295,is $  $ a vector or a scalar ?
303627,"depending on your problem , it might work to treat this as a 2d regression problem ( i . e . predict continuous values for x and y ) . using the squared error would imply that nearby ( x , y ) outputs are similar . is this true for your problem ?"
302678,could you provide a link to the video or citation ?
165096,just out of curiosity : how does one obtain different annotations from a single algorithm to compute the pairwise correlations ?
304997,is this called left trucated ?
305382,"icedcoffee i don't agree with the other comments , and think you could still compute a confidence interval for the product . however , it could be useful to address the comments to my own answer to know if the confidence intervals from the original data were likely simmetrical and normally distributed , and the reference sample size . can you add these details ?"
304855,can you expand on the type of structural break you are looking for ?
305955,( 1 ) did you notice the transpose operator ?
306734,where did you come up with this idea that the intercept accounts for measurement error in $ x $ ?
307197,it is not expected i would say . is it still true if you keep the intercept term ?
306955,"$ sum_ { i = 1 } ^ k ( 1-x_i ) $ is not equal to $ 1 $ if $ k neq2 $ so $ ( 1-x_1 , ldots , 1-x_k ) $ cannot be dirichlet . is this the answer or were you thinking about some scaling ?"
307355,what is denoted as sd ?
324712,"if you have a linear model , the between / within subject effect is the same . for logistic regression , you can't project the conditional or , but you can place a lower bound on it by the marginal or . after that , other repeated measure power calculations apply . you need to know the icc to get at the intracluster variance . otherwise you must make some assumptions . are you using a gee or mixed model ?"
335567,"how could a * point estimate * ever "" contain the mean "" ?"
143704,"this would depend on your definition of your pseudo r ^ 2 . for example , are you using a count r ^ 2 ?"
155340,can you clarify how this is related to statistics ?
211999,"can you explain how $ hat { x } $ is not in the range of $ x $ . it is not clear to me how that is possible . are $ x_1 , dots , x_ { 10 } $ independent random variables ?"
234230,"sorry , can you add more context ?"
234519,can you add more information ?
234858,can you possibly provide context or summarize what he said here ?
235059,i doubt there is an all-purpose answer to this question . the details will matter . do you have calibration data to constrain the form of the temperature-dependent sensitivity of the probe ?
236034,could you give links to some of the strong opinions ?
236888,which paper ?
236931,the coefficient of the $ x $ term will be one smaller than it would be for the ordinary regression of $ y $ on $ x $ . are you trying to test if the original coefficient is $ 1 $ ?
237452,"i appreciate the concept expressed in the title is not quite right anyway , but to match the quote , shouldn't it say "" the probability of correctly classifying . . . "" rather than just "" the probability of classifying "" ?"
237497,re the first paper see here url does it help ?
237787,"there cannot possibly be any such method , because "" reliable "" ( as used here ) is a subjective , undefined term . not only that , but how meaningful do you think your scoring would be for estimates that are zero or negative ?"
238507,seems like this is a duplicate of those two combined . not sure how to mark that . maybe an answer referencing those two threads ?
238551,"this is very broad question , and the five coefficients are a deal different in their ideology . i would recommend you to narrow your question , and to make it reflect your specific problem in understanding a coefficient . what exactly you can't understand ?"
239097,are you seeking the joint pdf of $ z $ and $ y $ ?
239688,what are the points at the far right ?
240066,"that result is not possible unless you allow $ b to 0 $ as $ n $ increases . otherwise , $ f_n $ converges to a smoothed version of $ f $ rather than the correct version of $ f $ . assuming , then , that $ b $ does shrink to zero , * exactly how do you determine $ b $ in terms of $ n $ * ?"
243823,could you explain why you feel it would be useful to transform the independent variables ?
244101,"you wrote "" the dependent variables are both categorical and continuous "" , so are you fitting separate regression models for each dependent variable ?"
245564,"asking for libraries / code , etc . , is off topic here . i think your main question is probably on topic , but we'll need more information . how does the game work ?"
245800,* exactly * zero or very small and close to zero ?
245866,what are you trying to accomplish ?
247129,is your svm linear ?
247534,could you please pose your cost function ?
248420,what happens to the variance of $ u_i $ when you divide it through by any constant $ lambda $ ?
249210,can you explain a little the code ?
249787,did you look at minimum covariance determinant ?
250125,are trying to calculate / interpolate the missing values spatially ( e . g . how rain has fallen in the areas between the 104 stations ?
251553,"are users able to purchase more than one item or , alternatively , multiple unique items over some period of time , e . g . , six months or one year ?"
252201,""" my fish data "" ---can you give details ?"
253089,what do the individual numbers in ` group ` and ` temp ` mean ?
253228,"do you talk about response or predictor variables , or both ?"
254519,what is the reference of the paper ?
254558,i added a derivation of the issue you brought up in your comment . does it help ?
255655,"this has been flagged as ot , likely for its mention of r , but i gather that your interest is in how an arima model ( in r or any other tech ) forecasts without actuals . am i correct ?"
256270,"since $ beta $ is a vector of length p ( $ beta in mathbb { r } ^ p $ ) then necessarily $ x_i [ tilde t ] $ is a vector of length p as well , or their inner product could not be formed . could you clarify your question ?"
256488,is this a time series with just five or six values ?
257114,can you word your question more clearly ?
257195,are you asking about regular ols or penalized regression models such as lasso and ridge regression ?
257328,would you please provide the source ?
258474,"i'm not familiar w / that option , are you referring to the syntax of some specific software ?"
258553,you don't get the regression line from the table . where did this idea come from ?
258722,1 . is this for some subject ?
259308,when exactly would you like to stop ?
260845,can you plot the two roc curves ?
260899,could you provide some context ?
262454,welcome to stats . se ! please take a moment to view our [ tour ] . have you considered simply modeling the fact that the two hospitals are very different ?
262713,where is the picture ?
263199,"what do you mean when you say "" compare "" ?"
264377,"instead of controlling for it , why don't you test to see if it is an issue ?"
264490,why don't you include your output ?
265248,why do you think it needs transformation ?
266226,is your problem regarding the sum of the random variables or the sum of the likelihoods ?
266376,"can you be more precise what you mean by "" for sure "" ?"
269301,ordinary least squares regression ?
269309,why would you expect wind speeds to be stable across the years ?
270051,` ( x [ 1 ] x [ 2 ] x [ 3 ] ) / 3 ` . . . sorry but what exactly is the problem in here ?
270206,"by wn ( presumably "" white noise "" ) do you mean independent gaussian noise or something else ?"
270890,"you seem to be asking to throw out data that are relevant to the estimation of $ a $ . moreover , it's not possible to evaluate possible estimators without knowing how your data might deviate from the model . could you explain the first and elaborate on the second ?"
272330,"this seems unprincipled and i don't know any better , but i wonder if you can just augment each datapoint by its population weight ( so if your population weight is 2 , then you'll end up with 2 copies of your datapoint ) ?"
272404,"lots of things missing here . what are $ h_0 ( t ) $ , $ f ( theta ) $ ?"
273376,"if you have two ( or n ) specific seasonalities you want to adjust for , you could get each of them separately from statsmodels by calling sm . decompose ( ) twice with the two different frequency = parameters . then you could subtract both those seasonal components from your raw signal . does that get you what you want ?"
273530,"you could measure the ( dis ) similarity between the two sequences . however , we would need more information about the sequences to chose the dissimilarity measure : what are the states ?"
274251,$ / log 0 = - / infty $ isn't ignorable ?
274253,i believe the theory is outlined in great generality and detail at url is there any aspect of your situation that you think is not adequately covered in that thread ?
274337,is this [ tag : self-study ] ?
276313,"could you please clarify your objectives , the context , and the nature of your data ?"
277145,is this [ tag : self-study ] ?
277306,not sure why it was down-voted but it does seem a bit sparse . perhaps you could fill in some more background ?
277398,how can you tell for sure that it's the sum of an exponential and gaussian rather than ( say ) a gamma distribution or a weibull distribution or some other moderately right skew distribution ?
277886,what is the question ?
278540,could you please add the reference of the result ?
279652,are your variables all-positive ?
279874,"maybe you first should investigate the fit of the model with residual plots and so , to understand why you get negative predictions ?"
280711,"in general , all other things being equal , it is best to have a single all-inclusive model . do you have some doubts about the issues ?"
281695,why would such a requirement be necessary ?
282364,"do you know of some ways to characterize or identify minimal sufficient statistics , in addition to the definition ?"
282610,what are you predicting ?
282812,"1 . where did the "" $ 2 $ "" come from in $ hat tau $ ?"
282906,this reads like an assigned question . is it for a class ?
283427,if you have the pdf you can calculate the expectation if it exists by integrating x f ( x ) dx over the range of value for x with f as the pdf . but how did you get the density in the first place ?
284000,why would you care if the points have high leverage if they don't have high cook's distance ?
284642,"what is a "" backpropagation formula "" ?"
284909,"do you know when the anomalies occured ( both historically and in the future ) , or do you need to detect this in the historical data ?"
285033,"there isn't any "" regression model "" piece here as distinguished from a "" time series "" piece . perhaps you meant to write $ beta_1 x_t $ ?"
285340,"could you please elaborate on the distinction you make between "" best case . . . worst case "" and confidence intervals for the parameters ?"
285529,( -1 ) this question is so lacking detail it is unanswerable . what are these models for ?
285954,are the $ epsilon $ 's uncorrelated with the $ x $ 's ?
286775,"if the gp model is well-specified ( um , what's the opposite of misspecified ?"
286792,"it's hard to tell without looking at your data . that being said , you are probably better off performing a logistic regression . can you tell us more about what you are trying to accomplish though ?"
287504,perhaps use an error correction model and focus on the coefficient on the error correction term ?
288217,"possible duplicate of [ how can i group numerical data into naturally forming "" brackets "" ?"
289154,can you say more ?
289427,"working with eur / usd forex data myself , and i also see a huge crash during 2008 that messes with models . i don't really have a solution to your problem , but i was wondering if you could add a graph to your post of your forecasted trend line data ?"
291409,i don't understand why should it should matter if the lasso estimator is biased as long as a the confidence intervals have ( at least asymptotically ) correct coverage . is this the only reason why you want to fit ols estimates on the support recovered by the lasso ?
291940,"are you trying to extract 62 * factors * or do you have 62 * inputs * ( i . e . , items , questions ) ?"
294211,context would help . what are these quantiles of ?
294407,where does it say that ?
294951,it will help to know why you care which one is doing better or worse ?
295383,could you point us to an article / link stating this ?
296268,what is your question ?
296536,can you show your summary output ?
296895,what distribution do you want these matrices to have ?
297757,"please explain what it means to "" run the task during a system upgrade . "" would that include only situations where the task is * started * while a system upgrade is in progress , or would it also include situations where a system upgrade overlaps with the duration of the task ?"
300362,mse on a logit ?
300375,what's catpca ?
302025,have you considered using the differences in responses between t = 1 and t = 0 for the response variable ?
302521,"good luck , since nobody was able to achieve this before ! moreover i don't think that it is even possible without considering the clustering algorithm . however * * you didn't ask any question * * , so please edit it to be a question , e . g . * "" is it possible . . ?"
303138,there is no fallacy in observing different test results from different tests . it is somewhat surprising that clark-evans detects departure from csr which an envelope test based on g doesn't detect . what kind of envelope test do you perform ?
303504,can you clarify how your question differs from the linked thread ?
304061,could you give us more details ?
304108,does this question help ?
307327,"can you edit this question to explain what your acronyms , functions , and variables refer to ?"
307503,"you say you want to measure snr , but then that you're not sure whether this is the correct measurement . what's your actual goal--what do you want to know about the measured signal ?"
315799,do you understand why $ xi_i 1 $ if and only if the $ i ^ { th } $ training example is misclassified ?
47,"i don't see why you want to cluster your users without any subjective input ( i refer to a comment you made reed ) , you said you want "" the most appropriate number of clusters "" , but unfortunatly you don't have a clear objective , if you want to cluster your population to show something particular , you should tell us what you want to show ?"
2298,"at first blush this question seems purely mathematical : visualizing the function has nothing to do with the distribution of its arguments . however , the reference to "" heteroskedasticity "" suggests you're really trying to visualize an object that is more explicitly represented as $ f ( x_1 , . . . , x_k ) epsilon $ or more generally as $ g ( f ( x_1 , . . . , x_k ) , epsilon ) $ where $ epsilon $ is a zero-mean random variable and $ g ( z , 0 ) = z $ for all z . isn't this just a response-surface analysis ?"
3121,"i'm not sure what this means ; do you have the numbers 1-100 in a bag , and are going to pick them out one at a time without replacement ?"
4331,can you provide us with some context for your data ?
4441,are you interested in studying possible attrition effect or do you only want to assess the overall trend ?
5100,what do you expect ?
5703,"caracal there's nothing faulty about shabbychef's formulation . spearman's rho can be computed for so-called "" continuous "" data just fine . you have actually put your finger on the entire difficulty , which is characterizing the interaction between addition and ranking . one potential application is this : suppose $ y_1 $ is a response variable and $ -y_2 $ is a vector of unknown errors . what can we say about the spearman correlation between $ x $ and the * true * values $ y_1 - y_2 $ given a measured correlation with $ y_1 $ and an assumed correlation with $ -y_2 $ ?"
6492,do you have a truly * huge * amount of data ?
6715,"nice question , its a good example to expose to different procedures , because we basically know without any maths or formality , that environment 4 and 6 are different to the rest ( and environment 1 is a little different from 2 , 3 , and 5 ) . thus any good procedure should be able to produce the obvious result , only difference coming from quantifying * how different * in a mathematical sense . the obvious question is "" is there any other way the experiment could have actually produce these results , besides an error ?"
7141,"cardinal , we have the same amount of $ mu_i $ as there are data points . will this not pose a problem for estimation ?"
7695,"there is a problem with your first sentence , which probably is the cause of the further problems . is this your sentence , or is it citation ?"
8213,a simpler question : how would you go about detecting line segments in a two dimensional data ?
8470,why not work with logarithms of probabilities ?
8734,"chi fair . i did say almost always : ) . things like big n-way tables are impossible to ( completely ) reproduce graphically . it depends on the forum i'd say . tables have the benefit of being complete , sure , but does your reader actually * absorb * all that extra information ?"
8823,"i'm a little confused by the index on $ bar h_i $ ; is $ bar h_i = arg max_ { h subset h_i } p ( d_1 , dots d_m h ) $ ?"
9920,"( 1 ) this is a well formulated question . however , it now looks partly duplicated from your [ preceding question ] ( url ) ( that you've updated recently ) , though it's another question . would it be possible to balance the content of your two questions , with one target question in each ?"
10251,"maybe i'm missing something so please correct me if i'm wrong , but it should be possible ( at least in principle ) to construct what is done in pca using matrices as a ( complicated ) linear programming problem , but i don't know how you'd state all of the constraints required . also i'm not sure that'd be very simple to do compared to just using pca . why are you trying to avoid matrices ?"
10949,what would you like to do with your model ?
11960,does the order of choice matter this time ( cf . your recent question about [ testing the importance of an item among a finite set of items ] ( url ) ) ?
11970,"based on the wikipedia definition of a giant component , it merely need be connected a majority of the nodes in the network . is this the precise interpretation that you are considering , i . e . that the giant component is connected to . 5 of n where n is the number of nodes in the network ?"
12281,"gappy , did you consider using qr ( or cholesky ) decomposition for matrix $ omega ^ { -1 } bd ^ { -1 } b ^ t $ ( the middle term in woodburry formula ) ?"
10420,melon . your question is quite vague . what do you mean by parametric and non parametric ?
13671,"just a quick comment , it seems that the process is mean-reverting ( for a long period it went around zero , strange for the ratio though , and . . . hm negative values looks also strange , what the definition of ratio is ?"
13783,i gather using $ log x = alpha beta log y gamma log z $ was not apropriate ?
13927,"your axes don't have labels . i realize it's in meters , but is that something like distance from the start of the runway versus altitude ?"
13531,"this sounds like a survival / failure analysis kind of problem . however , i'm not quite clear on why this issue of windows arises . is there a choose of temporal scales ?"
14469,how many dimensions ?
14557,machine learning as opposed to what ?
14803,"what do you mean by "" fits "" ?"
15308,"this will depend heavily on the amount of data you have available . to get anything significant , you're going to need lots of games , and preferably with just about any combination of players in the two teams . do you have that ?"
15784,"i agree with whuber , and dasymetric mapping may be of interest to fmark given the subject material as well . unfortunately , it is largely separate from the ecological inference literature i cited in my answer ( i don't want to pile on more literature more ! ) what do you think fmark ?"
13148,"jeromy why not rephrase the question ( separately ) as a community wiki , requesting one post per rule ?"
17185,your problem definition needs more clarity . what are you testing for between your ( large list / ) variables ?
17366,"does "" discrete "" mean categorical or ordinal or integer or a mix ?"
17701,"correlation is something one computes between variables , not between users . are you looking to see how variables relate to one another , e . g . , whether smaller size tends to mean lower price ?"
17954,"does the radius only take integer values in $ { 0 , ldots , m } $ or is it a continuous random variable taking values in $ [ 0 , m ] $ ?"
18110,what's the matter with numerically inverting the cf ?
18232,have you had a look at 'scatterplot3d' ?
18247,"i think you need to clarify what you mean by the * mean is constant * . presumably there is a model that you have in mind in the background and it sounds roughly like it involves a function $ mu ( t ) $ that defines a systematic change as a function of time , and presumably , also an error term $ varepsilon ( t ) $ encapsulating the fluctuations around the local mean . then your question would seem to be : is $ mu ( t ) equiv mu $ ?"
18655,"ignoring issues about where the numbers came from and what they mean , would $ ( a-b ) / [ ( a b ) / 2 ] $ , the difference divided by the average , ( or $ a-b / [ ( a b ) / 2 ] $ , or even $ a-b / ( a b ) $ -- $ a $ and $ b $ are within $ x % $ of their average value ) be a better measure of the "" percentage difference "" ?"
18951,"the only usages of "" statistically equal "" i am aware of originate in non-statistical ( and usually informal ) contexts . do you have a specific quotation in mind , a source you can reference ?"
19518,you mention statistica . can you use it for your project ?
20021,what is the purpose of this exercise ?
20046,what are you trying to learn from your data ?
19165,"just for clarification , do the points at the 0 . 0 line really mean no observations within that category ( from -30 to -15 ) or a very small odds ratio ( same for the na category at the rightmost of the plot ) ?"
20079,"the logic is flawed . categorization would be a nonlinear transformation , tantamount to a wholesale change in the model . it potentially could cure a nonlinear relationship between the response and the independent variables , but would lose precision . a better reason for addressing skewness would be the presence of high-leverage data , but there are other solutions for that besides categorization ( and the leverage might not even be a problem and the categorization might not reduce the leverage , anyway ) . what evidence is there that the outliers have a "" detrimental effect "" on the fit ?"
20723,just to clarify - do you know the parameters of $ a $ and $ b $ ?
20802,"when you say "" i randomly resampled the dataset to balance it "" , does this relate to the stratified cv machinery ( which is the default in weka , as i seem to remember ) ?"
21221,can you tell us more about why you want an average ?
223,what's the significance of the fact that your friend is an md ?
22285,hint : there are $ binom { 30 } { 10 } $ different exams that the professor could set . how many of those will have all $ 10 $ questions selected from the $ 25 $ that the student knows how to solve ?
22356,"in writing "" 3d points "" were you contemplating an extension of this question to functions $ f ( x , y , z ) $ ?"
23005,-1 the op has also asked how to find the derivatives of $ ( 1-f ( v ) ) ^ n $ and $ 1 - ( 1-f ( v ) ) ^ n $ on math . se and accepted an answer there . this is not a question about the chain rule ( as whuber suggests ) but more basic : does $ frac { mathrm d } { mathrm dx } [ 1-g ( x ) ] $ equal $ - frac { mathrm d } { mathrm dx } g ( x ) $ or not ?
23281,can you say more about what you're trying to do ?
23554,so the $ omega_i $ 's are the weights ?
23830,my main issue would be how you avoid giving them just enough knowledge / tools / status to make them dangerous ?
23886,are all the changes of region either splitting ( like your twin cities example ) or merging ?
24521,so these are absolutely not ordinal data ?
24899,"depending upon the language / tool you're using to do the analysis , this might be very straightforward . what are you using ?"
24972,what's wrong with using a loess curve ?
25037,"the ci of a sample is intended to cover a parameter . in your case , you appear to want to construct some kind of interval ( of distributions ?"
17449,"maybe these lines of mine help to further clarify your question ( which i'm pretty sure i won't be able to answer then : ) but hopefully it helps some others to do so . . . ) one point where i get stuck while reading your question is this : "" the value of several actions "" . do you assign a value to an action ?"
26025,"conjugate prior you clearly know this field better than i do , but i'm not finding the answer on that page , nor any mention of "" normal "" or "" gaussian . "" i also don't recall seeing a time series text that addresses it . can you be more specific ?"
25228,"i think to make this question answerable , we need a model of some type . in particular , what does it mean to ask if "" there is a statistically significant difference over time between the two prices "" unless there is some noise in observing the prices ?"
26949,"what is the distribution of $ ( alpha , beta ) $ in your hierarchical model ?"
27085,"i'm not an image processing person , but perhaps you could try running a sobel or canny operator on the image to detect edges first ?"
27815,"this sounds like homework so i won't definitively answer the question but based on the phrasing , it doesn't matter whether the 'success' occurs on the first or second trial , so $ p ( { rm exactly one success } ) $ is the probability of having a success and then a failure or having a failure and then a success . given that , which of your options seems to be correct ?"
28187,what resources have you collected so far ?
28478,what can you tell us about the signal ?
28528,"so , you have this online / offline times for each user ?"
28602,have you tried other inital values when fitting your model with 'gaussian' ?
28618,are you looking for a mathematical characterization of such classes or are you inquiring about which of the generally known parametric families of distributions may have this property ?
28656,` one variable is redundant in the parameter estimates ` how did you know that ?
28692,"could you please elaborate on what it means to you to "" test "" a pair of tables ?"
28949,how do odds ratio relate to your problem of comparing amino acids ?
28974,"i don't feel it is right to call it repeated-measurements . your 6 read levels don't seem to differ in some systematic way ( e . g . condition ) . rather , you just performed 6 assessment attempts instead of 1 - for precision . right ?"
29168,is this homework ?
30270,"* writing * the likelihood is trivial--it's no different for one continuous distribution than for another ( it's just the product of the values of the pdf evaluated at the data , assuming they are iid ) . is your problem really one of * computing * the likelihood ?"
30256,"anna , this is potentially interesting here on the stats site--because as you know , many statistical procedures look for optima of functions like this--but can you draw an explicit connection with a statistical problem to convince the community not to vote to close your question as off-topic ?"
30406,"if you have more than 1 predictor , it could be tricky to do this without some kind of regression model . what did you have in mind ?"
30652,can't you just simulate data whose mean is a known smooth function and add random noise ?
30732,"macro , igor's definition makes sense even when the distributions have different shapes . his concern about using the wilcoxon test is valid : although it tests exactly this kind of ordering , it assumes the distributions are merely location-shifted . what i wonder is whether there is any issue here at all : the question says that the $ f_i $ are * population * distributions , not sample distributions , so it appears that no inference is necessary and all one has to do is compute the relevant probabilities . igor , is this the case , or do you actually have ( large ) * samples * of the populations ?"
29025,what's wrong with redundancy if it makes the plots easier to digest ?
31115,# 1 is answered at url but how did you determine that * geometric * variables are involved here ?
31739,whuber i read the article and saw the reference to approximately unbiased bootstraps referring to a figure . but i could not find any more details about it . did you get the rest of the information from the referenced online article ?
31768,"i think it is valid to use [ aic ] ( url ) for comparing these models . the wikipedia entry mentions "" there are , however , important distinctions . in particular , the likelihood-ratio test is valid only for nested models whereas aic ( and aicc ) has no such restriction "" . on the other hand , it is more intriguing why are you comparing such diferent models * * "" "" i would fit a normal , an exponential and a uniform distribution "" * * ?"
32436,are participants only required to press a button following an event and only required to press the button once ?
32475,are these curves stochastic or deterministic ?
32585,how is ` price ` coded in r ( ` numeric ` or ` factor ` ) ?
32641,"zach , with this improved information in hand , you have the basis to reopen your question : it now exhibits effective research , partial progress towards your goal , and a more definite focus . why don't you incorporate your last comment as an edit and re-open the question ?"
32770,"there are many papers available , including this review [ structural equation modeling of multitrait-multimethod data : different models for different types of methods ] ( url ) , or this paper [ analysing multitrait multimethod data with structural equation models for ordinal variables applying the wlsmv estimator ] ( url ) which shows the general idea . i can try to find a better reference for the context of your study , though . could you tell us : whether items are ordinal ( e . g . , likert-type ) or binary , sample size , and the number of facets you want to assess ?"
32839,"are you saying that you have a response variable with 500 categories , or a response variable with 2 categories and 500 predictor variables ?"
32822,doesn't that simply mean that points with score = 0 are not counted in the set of retrieved items ?
32945,i have written a home-exam about behrens-fisher problem when i taught statistics to mathematics students . it is written in french . do you want it ?
32994,"with the sas terminology ( but it is possibly a more common terminology ) , the g matrix is the variance matrix of the random effects and the r matrix is the variance matrix of the "" errors terms "" ( in your case perhaps it is the estimated residual variance $ sigma_ { 0e } ^ 2 $ ?"
33433,"i think you are asking about prediction intervals . note , however , that you use "" $ x_i $ "" , instead of "" $ y_i $ "" . is this a typo ?"
33850,can you give some more detail ?
33683,"just curious , why is that ?"
34170,"what is important to know is what you intend to do with factor scores . is this is convenient way to summarize individual differences as simple composite scores , or do you want to factor out scale and item scores because there's an underlying measurement model that would make sense in your context ?"
34396,"could you explain what you mean by eigenvector "" orientation "" ?"
33505,it is not m / s that has the student t distribution it is ( m- $ _x $ ) / s . why are you interested in the joint distribution of the components of the y vector ?
34740,"can you clarify what you mean by "" they are meant to be used on single ( gauian ) distributions "" ?"
28623,can you add just what the normality analysis you plan is going to be ?
35269,what is the meaning of the values in the first table ?
35280,"it is like saying , "" i don't have the money to buy a car . where can i find a self-contained 20-page guide to make my own car from scratch ?"
35465,"not surprisingly , a lot of people have looked at cheating detection in the past , including steven levitt , author of freakonomics . if you want to be able to tell whether someone cheated from the answers alone , don't give multiple choice tests , and proctor the exams yourself . you might be able to reject the hypothesis that the students' work was unrelated , but you will have a terrible time proving that they didn't simply study together . do you have a seating chart and did you verify the students' ids , that they were sitting according to the seating chart ?"
35640,"don't think in terms of p values , think in terms of effect size . did it change much ?"
36219,"i don't think nstor means to be harsh . in order to help you , we need to know more about your situation , your data , your goals , etc . would you mind providing more info ?"
37935,"not the worst question ever ( i . e . , 1 ) , but i somehow question that most post-hoc test report unadjusted means for the covariate . can you give an example for at least one software ?"
37947,"well , you can obviously use bayesian approaches for various things , so why would they not be usable for learning ?"
37649,can you help us understand the hypothesis you wish to test ?
38349,"how does a "" predicted scored rank a target variable "" ?"
7519,have you read the wikipedia article ?
39214,can you clarify your concern regarding the non-normality ?
39208,"some thoughts : 1 ) this sounds like a machine-learning classification problem ; is it supervised or unsupervised classification ( i . e . , do you know what the right answer is when you try to train the algorithm ) ?"
40549,please add to your question what you expect the listener to have for statistics knowledge . do they know a t-test ?
40584,"related topics on * poster * presentations ; i asked a question here , [ how should i organize my poster presentation ?"
38831,"by "" sometimes present "" , do you mean that you only know their value some of the time ?"
40955,"if there is no relationship between the $ ( a , c ) $ dataset and the $ ( b , d ) $ dataset--and you do not indicate there is-- , then why would you expect there to be any predictable relationship between the sizes of the "" errors "" ?"
41009,"what do you mean by "" significant high "" ?"
41386,is it the case that you have multiple dependent variables & you're checking all of them ?
43255,could you please explain what is special about computing with complex numbers ?
43315,"because your model says nothing whatsoever about the probability of the response variable ` hired ` , it won't be able to do what you are asking of it ( even presuming that "" hiring "" and "" hired "" are the same variable ) . do you think you could tell us something about the data and what you're really trying to find out ?"
43464,"welcome to the site . i attempted to clarify your first paragraph . if i messed up , please correct it . as to your question , why not just look at the parameter estimate for the covariate ?"
43465,can you provide more information on these criteria ?
43877,i guess that's extremely hard to interpret . how are the other p-values ?
44356,"because the relative increase of the means is * not * equal to the mean of the relative increases , i wonder whether your procedure is at all meaningful for your study . perhaps you could settle for determining whether the * net * increases are significantly different ?"
44508,"how can $ b_t $ be normally distributed if it is known to be larger than $ a_t $ , which we can choose any way we like ?"
44952,don't both of those cost a lot of money ?
45122,what is the objective of your modeling ?
45213,is this correct : your unit of observation is 'student' and for every student you measure which school he belongs to as well as how many hours he spends working ?
45248,[ any use ?
45546,"what does "" continuous on the positive integers "" mean ?"
45860,"what would it mean for the data to be "" abnormal "" ?"
45950,what are you using to perform the test ?
45974,"1 ) ability to find ( and * * introduce * * ) bugs is an individual trait , having little to do with the department . 2 ) code patches are supposed to * * fix * * bugs ( unless the qa process is not working in your organization ) . 3 ) why are your salesmen coding instead of selling products ?"
46080,luck ?
46897,"welcome to our site ! our [ faq ] does ask that "" you should only ask practical , answerable questions based on actual problems that you face . "" could you elaborate on what your actual problem is ?"
46908,"this is very akin to endless debate . you may want to refine your question , e . g . by looking at [ does julia have any hope of sticking in the statistical community ?"
47130,what is the assumed distribution of your errors ?
47697,why would you randomly divide the controls ?
47285,in what sense aren't your data normal ?
47752,"why would it matter , for this process of standardization , if the data is negative or positive ?"
47750,have your tried cross validation ?
47872,"so basically this is a study over two time periods . at time "" zero "" all units are $ 100 $ and at time "" one "" units could be any one of $ 8 $ different values $ ( 000 , 001 , 010 , 011 , 100 , 101 , 110 , 111 ) $ . you want to analyse and compare the distribution of your two populations across each of the $ 8 $ values at time "" one "" . the tricky part for you is that many transitions between the $ 8 $ values could potentially occur between times "" zero "" and "" one "" ( eg 100 to 101 to 111 to 110 to 100 ) , so you may see / miss differences just because of the timing of your sample . is this correct ?"
48903,"why not try the average of x2 & x4 , and the difference b / t x2 & x4 ?"
49340,do you repeat each trial only once ?
49335,"we need more information on why you are interested in this to be able to give any advice on what analysis to do . also it isn't clear what you mean by an "" event "" , and certainly not what might be meant by the probability distribution of the incident of event . and occurence of sessions - what do you need to know ?"
49555,"some * particular * kinds of combinations have names ( e . g . [ the skellam distribution ] ( url ) ) , but the general case its just compound poisson , i think . there will be no closed form expression that's simpler than the original sum in general , though i suppose you can just write it as a convolution . when you say 'generate' do you mean 'simulate random values from' , or something else ?"
49854,"whuber , i agree that interval censoring is a better framework . i should have been more careful about that . shouldn't the effect be the same , though : attenuation / sampling distributions of betas biased towards 0 ?"
49965,do you know the definition of an unbiased estimator ?
50201,i'm not getting this . could you maybe give an example of what the data look like ?
50516,do you mean 'into' groups or 'in two' groups ?
50646,prior for what parameter ( s ) in what model ?
50739,what is the overall loss function ?
50653,"just to check something i must be misunderstanding , let's look at a case with $ d = 1 $ . let the data be $ ( -1 , -1 , -1 , - alpha , 0 , alpha , 2 , 2 , 2 ) $ where $ alpha approx 0 $ is very small . evidently k-means for $ 2d 1 = 3 $ clusters will return three clusters with cluster means of $ -1 $ , $ 0 $ , and $ 2 $ . this set of means includes the zero vector . obviously neither the set of data nor the set of means is semi-symmetric . why is this not a counterexample ?"
51198,"* when i took my measure-theoretic probability we , for some reason i don't understand , never even touched conditional expectation . * whoa . i'm interested in this little snippet . what text did you use ?"
51383,"could you please be more specific about your "" shuffles "" ?"
51840,"although i believe most readers would have some idea of what "" bin-smoothing "" might be , it's a broad technique and conceivably could be applied in several distinct ways . could you please tell us more precisely what * you * mean by it in the context of regression analysis ?"
52187,linear regression with a binary dependent variable ?
52352,i'm not sure i understand the question . are you positing a separate response rate for each zip ?
52463,what is the purpose of your normality testing ?
52611,* * 100 % . * * that is a serious answer ( and one of the infinitely many correct ones ) intended to reveal the need for a clearer context for the question : ( objective ) probability statements are nonsensical without a description of what experiment is being performed and what constitutes an independent replication of it . would you care to clarify these things ?
52695,"you call your data ordinal , and appear to suggest it is discrete . this appears to conflict your statement on normality . can you clarify this ?"
52783,"are you using stata rather than "" state "" ?"
52856,"penguin_knight ( 1 ) which do you believe is "" correct "" : that the vif should be checked for interactions or not ?"
52857,"why is 333 days "" one and a half year ?"
53267,"( 1 ) could you please explain what you mean by "" input "" ?"
53357,what is the distribution of your observations ?
54898,"try the "" difficult "" option in stata ; it often brings convergence when the normal likelihood maximizer doesn't . apart from that , in a zero inflated model you jointly estimate a logit and a ( say ) poisson model . this might be difficult with few observations , especially when you have dummies as covariates . do you get "" xx predicts success perfectly "" messages ?"
54993,"yes , is the short answer . i'm not sure i understand the design though . factor a has two levels , and factor b has two levels means we have 4 measures for each unit ( person ) : a1 , a2 , b1 , b2 . what does each unit being measured 3 times refer to ?"
55037,can you please clarify what you actually want to do . . . what question are you trying to answer with these data ?
54995,are you sure there are * two * clusters ?
56377,"of course--but a good answer would reflect the reasons why $ y $ can become negative . presumably that's measurement error , but could you tell us more about its nature ?"
56444,can you describe further what you are trying to to and how you do it ?
56852,"i find two questions which , appropriately interpreted , appear to be duplicates ( and therefore already provide answers ) : url are these adequate ?"
57421,your mediational model implies that you are claiming that the ceo's education level causes the diversity of partners . did you intend this ?
57840,"i beg to differ , because i can't make sense of what you have said in your post . i can't tell from what you've written what the problem is , what you're expecting the code to do , or what it does . since the details of the code are in full view to you ( including the internal functions like ` . paramgh ` and ` . kappagh ` ) , why don't you read them and resolve for yourself whatever issue you are concerned with ?"
58270,"it's not clear to me what you know about the distribution of the data . you write "" it may be assumed that each invidual measurement has normal distribution "" . apparently these are different distributions for different measurements ; otherwise the overall distribution would be normal . what do you know about the parameters of these individual distributions ?"
58312,"what do you mean by "" . . . the point at which the distribution becomes 'long-tailed' . . . "" ?"
59020,"what would it mean , conceptually , to "" weight "" the predictors ?"
59241,i suspect this question can't be answered like this . perhaps you can refine it as laid out in the faq url ?
59275,"if you have three numbers , why use any measure of inequality ?"
59384,"i don't have access to spss . can you post the figure to something like [ imgr ] ( url ) , and describe your situation , your data & your model ?"
59965,"it would simplify things to throw out the rescaling by the gm . in practice this will be handled through the estimates of $ alpha $ , $ beta $ , and $ sigma $ anyway , so the fits will be identical , but for theoretical work the presence of that gm looks terribly complicating . it's rather bizarre that you multiply the $ log ( y_i ) $ by the gm , by the way . does that have an interpretation ?"
60470,"if , as seems to be the case , you're talking about constructing an independent ( predictor- , $ x $ - ) variable , there are no assumptions you need to satisfy for ols or glms . your question "" or in general "" is unanswerable . i'm not sure what you mean by "" sar "" ; seasonal autoregression ?"
60800,"you might try clustering , perhaps hierarchical clustering , but i'm not sure statistical testing really answers the question you're interested in . you presumably don't think that across the four and three groups within those divisions the employees are perfectly homogenous , only that the groups more alike within the two main groups than across them . presumably those levels ( grades ) are ordered categories on some measure ; is that right ?"
60867,what kind of changes are you looking for ?
61205,"have you considered transforming the data first , maybe taking the log of the data to make the data more 'normal' ?"
61498,"the problem is without knowing which orders eventually must be regarded as stopped for a training sample , how can you build a probability model for judging stopping * at all * ?"
61725,how exactly do you fit the logistic regression to get standard errors ?
62134,"excuse me , what are "" rigid "" points ?"
62754,please tell us this : why is the error important ?
62920,why do you want to use a neural net to do that ?
63321,what is it you want to justify in particular ?
64069,"how would the regression output change if you were , say , to add $ 10 ^ 6 $ to each ` pop ` value and add $ -0 . 0116584 times 10 ^ 6 $ to each ` fuel ` value ?"
64227,why are you talking about aic specifically ?
64618,are these states latent ?
65590,what's your goal with the transformed data ?
65669,"so for example , in component $ a $ you are measuring eda for each person ?"
51385,"now , out of curiosity , in your application , do $ f $ and $ g $ satisfy any ( nice ) properties , e . g . , related to boundedness or smoothness ?"
66677,` teaching statistics better ` is pretty broad - can you perhaps ask for more specific advice ?
66753,do you have a link / citation to those articles ?
66963,"isn't ` ( 1 strain ) ` only used in lmer ( from package lme4 ) formulas , but not in nlme ( from package nlme ) formulas ?"
67441,"also , in the model , what's outcome and what's predictor ?"
67572,huh ?
68137,violate in what way ?
68178,"could you clarify the sense in which you use "" likely "" here , given that you offer no probability model nor is there anything in this setting that can be interpreted naturally as a probability ?"
68170,precisely how does this book define $ w_i $ ?
68205,"it would be helpful to tell us what tau-squared & i-squared are , apart from greek & latin letters . and don't you mean "" calculating i-squared [ . . . ] given tau-squared "" in the title ?"
68444,"as you can presumably obtain half-year data from quarterly data but not vice versa , the quarterly data contain more information than the half-year data . whether the extra detail is interesting or effectively noise is a substantive question . what other kind of answer do you seek ?"
68678,"first : if this is not a purely r question but a statistical question , then please _show_ the data and interim results at every step . second : your example explicitly makes use of euclidean distance and adding a new point with coordinates ( x , y , z ) also seems implying the euclidean space . thence your last sentence is mystic so far . did you mean to say that you won't have ( x , y , z ) data at all but will have distances at the very beginning ?"
69862,how large is the sample ?
69996,are you only looking to compare two variables at a time ?
69921,"do you mean that the target variable was 1 for 90 cases and 0 for the other 69 , 930 ?"
70149,are you solely talking about ` predict ` using the default features ?
70165,maybe you should try a method based on false discovery rate control ?
70097,"your first sentence seems to imply that you have some data on the specific customers behind each transaction , and that you want to understand your customers buying habits in terms of customer traits . the last two sentences seem to be a time series question , which you might address with the theory of control limits . which part to you prefer to focus on ?"
70511,"there are no technical problems with obtaining the results of that regression , chris , but it sounds like you may be asking about how to interpret them and the extent to which they can be trusted . i can imagine situations where this would give me some misgivings and others where it would be perfectly fine . could you help us understand you better by disclosing a little more information about this predictor variable and how it might be related to the dv ?"
70539,"yes : it's called multiple linear regression : - ) . please forgive me for copying the comment i left with the duplicate of this question that you deleted , because it is just as apt as before : "" many readers will be wondering why you haven't just fit this ( routine ) model using ordinary least squares on your favorite statistical computing platform , so we suspect you must have tried that and run into some kind of trouble . what exactly was the problem ?"
70737,""" * some of the dependent variables are not normally distributed * "" -- good thing that's not an assumption of anova , then . there is a normality assumption , but it's not an assumption about the unconditional distribution of the dv . specifically , the errors are assumed to be normal . what do residual plots look like ?"
71065,there are lots of distributions with heavier tails than the normal - e . g . the t-distribution ( lower df has heavier tails ) . but what are you trying to do ?
71448,"as you are trying to estimate the number of users connected at a time , what is the relevance of the groups ?"
71585,"i find that "" definitely "" a little dogmatic . what do you think they are according to stevens ?"
71725,"could you provide a bit more information about your problem : what is the dependent variable , how is it generated ?"
72223,"cross-correlation may have some descriptive merit if it exposes a lag structure e . g . if your simulated values lead or lag the observed values , but that should be evident too from plotting the data . on arima : i am not sure that you understand what it does . it's a class of models ; so do you intend to model the structure of disagreement between your simulation model and the observed values ?"
72242,"good question : i can probably argue pro and against the removal of outliers . why not use medians if you worried about outliers and what you are looking for is just a "" central tendency "" ?"
72065,"regarding the relationship between eigenvectors & a regression line , it may help you to read this thread : [ making sense of principal component analysis , eigenvectors & eigenvalues ] ( url ) , & possibly my answer here : [ what is the difference between linear regression on y with x and x with y ?"
71112,does it makes sense to have a random slope in your model ?
73405,"this is closely related to a generalized [ birthday problem ] ( url ) : $ n $ would be days of the year , the $ d $ independent "" markings "" would be draws from a population of people , and the chance of $ c $ "" clean "" balls is the chance that among those $ d $ people there are $ n-c $ unique birthdays . as an answer , do you seek a closed formula , an efficient algorithm , or an asymptotic formula ( in $ n $ or $ d $ ) ?"
73775,"this seems indirect to me . you ( should ) want to know what the most dissatisfied customers are dissatisfied about . that's not really a regression or correlation issue . for example , i can be very happy with quality of website , friendliness of staff , promptness of delivery but as mad as anything because the product just _doesn't work_ . multiply me , say , because that's a widespread problem , but regressions and correlations are not optimal to find us . that's descriptive statistics and basic exploration first : these mad people , what are they mad about ?"
73690,"you want to forecast a variable which itself is an average over $ t $ variables . you surely have reason for this ; e . g . , maybe $ t $ covers the length of a seasonal cycle and hence the average covers seasonal information and period-to-period information . so why do you want to use the $ y_ { t-s } $ , $ s = 0 , 1 , 2 , ldots $ as a predictor and not the lagged averages $ overline { y } _ { t-s } $ , $ s = 0 , 1 , 2 , ldots $ ?"
73929,why do you have fixation on non-linear regression ?
73871,is this for some subject ?
74147,can you succeed in the case $ m = 1 $ ?
74458,"what do you mean by "" the same "" ?"
75030,"whuber's exemplary answer does mention "" making the distribution more _symmetric_ "" . not necessarily normal . but even if we did it in an attempt to induce normality , have you ever estimated a sample of infinite dimensions ?"
74798,can you provide a reproducible example ?
76513,why are you doing all this ?
76876,is there an apparent relationship between the variance of the residuals and the fitted values ?
76904,have you been through the examples in the associated [ vignette ] ( url ) ?
77580,what is the statistical model you are trying to fit ?
78028,"plot the geometric mean in one panel , and the ratios to the geometric mean in a second panel underneath ?"
74342,welcome ! would be easier if you could clarify : do you mean you have calculated coefficients for something like the * last * 30 days ?
78207,why do you think that downsampling would necessarily * reduce * noise ?
78256,"that's what i'm saying up there , yes . how are you doing it in r if not by least squares ?"
78284,your question is not very clear . are you looking for the ` predict . segmented ` function ?
78283,how are you assessing distributional shape ?
76962,are you able to write down a statistical model ?
76156,"the link is broken , can you fix that ?"
78536,"* normalization * usually means fixing the range of your data to the $ [ 0 , 1 ] $ interval . i think you mean * centering * , which is setting the mean to $ 0 $ ( see my answer here : [ how-to-verify-a-distribution-is-normalized ] ( url ) ) . what does "" sur "" stand for ?"
78810,"i fear you may be using "" significant "" in a non-standard way . let's focus on your actual needs : what are you trying to find out ?"
78905,""" * i could calculate the median but i want to exclude the outliers . * "" --- well , the median ignores the outliers ( except that it notices which side of the data they're on ) . if you actually want to * calculate * the average ( i . e . the mean ) arrival time ( which as worded is a sample quantity ) , you * can't * ignore the outliers . if you define it as the only the average of under normal behavior , how can we discern whether a large value is from 'normal' behavior or from abnormal behavior , unless you supply that information as well ?"
79180,what do you want the analysis to tell you ?
79684,i don't use r . i assume model2 = intercept through the origin . why would you do this ?
80877,"i am struggling to understand the question posed in the last line . it literally asks "" is a [ sufficient ] statistic really sufficient ?"
81057,"to answer your research question , it is all about interactions between group and the two items . so the model without any interaction wont help . maybe to not drown in parameters , you could try to represent the two items by a single parameter ( linear effects on log-odds ) each per group ?"
81430,what happens if you use just ` error ( subject ) ` in the call to ` aov ` ?
81477,what is your data like ?
82120,"hi balduz , do you use ols to fit each of the linear models ?"
82059,when you say 'the same mean' are you referring to the population mean or the sample mean ?
82402,"in other words , you are asking why $ 2 bar { x } sum_ { i = 1 } ^ n x_i $ = $ n ( bar { x } ) ^ 2 $ . factoring out the common factor of $ 2 bar { x } $ reduces that to either $ 2 bar { x } = 0 $ or $ sum_ { i = 1 } ^ n x_i $ = $ n bar { x } $ . now , * what is the definition of $ bar { x } $ ?"
82689,"you state you want a cdf . you're doing simulation , so it's a sample ( i . e . empirical ) cdf . what's the definition of the [ empirical cdf ] ( url ) ?"
82475,dominic - you've defined the * population mean * . a confidence interval would be based on some estimate of that mean . what sample statistic are you using ?
82723,""" to determine if results are statistically significant "" is too vague to be meaningful . what are your hypotheses and research questions ?"
83299,"do you need it to be a linear rescaling , or are nonlinear , but monotonic transformations okay ?"
83543,"your description seems unnecessarily complicated . if i follow correctly , you are describing sampling without replacement from $ { a , b , c , d } $ with the given probabilities . with this simpler characterization in mind , can you identify anything that would cause the chance of any outcome to vary with position ?"
83689,is b correct ?
85462,what is cfa ?
85788,"what insights does an roc curve give you , i . e . , what is your reason for drawing it ?"
85894,"just wondering , why not then put a uniform prior on the range ( 0 , infinity ) rather than on ( -infinity , infinity ) ?"
83612,are you looking to examine repeated measures ( distribution of values within person level clusters ) or panel results ( functions of response variable within person over time ) or are you just examining outcomes as a function of time ?
86124,"yes , generally speaking that's an n 2 dimensional distribution . what are the $ q $ 's - are they densities ?"
86403,you mean outcome without any explanatory variables ?
82612,"first of all , why do you want to do this on your own ?"
85488,"the very picture shows that the distribution is not uniform , it is more dense in the centre . in what sense is it uniform to you ?"
86664,putting in a different two cents : how often do aic and aicc give different advice ?
87083,"could you use the ( out-of-sample ) predicted likelihood or some function thereof ( e . g . , -2 loglik or proper scoring rules ) ?"
87443,"i don't know what you mean by "" valid "" here . a normal q-q plot shows an ( approximate ) linear configuration if data are sampled from a normal . it can be a good informal means of looking at data . but ( 1 ) something that looks like an outlier with respect to one distribution may be perfectly compatible with a different distribution ( 2 ) data fitting the description you give aren't remotely compatible with a normal , so i wouldn't expect such a plot to be useful here . some other distribution is surely more plausible , quite which depending partly on how your data were produced . poisson ?"
87431,"your first question implicitly assumes the two scales are commensurable . this seems like a dubious assumption . although a statistical test can show that two * numbers * differ , what would that possibly mean in this circumstance ?"
87453,"you should do several checks before going any further . first , if this is a small dataset ( "" small "" will depend on other characteristics , but less than a dozen or so points might qualify ) , then bootstrapping is unlikely to be reliable . second , have you tested your bootstrapping code ?"
87671,"your general references to "" machine learning , "" "" regressions , "" and states suggest you need to be more specific in order to be understood properly . what are you trying to do ?"
87793,"no , it looks fine . when you say 'why it looks like this' , which particular features are you concerned about ?"
87810,"what exactly is "" cross-reference ?"
87857,1 ) i'd have used the ` ecdf ` function . 2 ) the function doesn't have an actual inverse . what did you need it for ?
87774,"yep , for example , you could clarify , upon reading this post from david giles url why do you want to consider the third model : a linear probability model ?"
87955,"i believe there * is * a statistical question here . it may come down to this : what do you mean by "" all parameters "" ?"
88573,"i guess i am not exactly sure what you are asking . note that are no question marks in your question . my point was simply that pca does not rotate anything . maybe you already know that . do you do pca and then , in addition , rotate the components ?"
88062,"a conventional definition of an estimator is that it is a function from the set of possible data values to the set of possible parameter values . if by "" plausible "" you mean "" all , "" then according to this there is no such thing as an estimator with a larger range . do you perhaps have a broader definition of "" estimator "" or a narrower definition of "" plausible "" in mind ?"
88782,"glen_b : by bootstrapping "" simultaneously "" do you mean to take the differences $ theta_1 - theta_2 $ on each bootstrap iteration ?"
88396,"you can't generalize with certainty . if you show a plot from program a and think you're also getting an answer that relates to program b , * unless they both explicitly state what they're actually plotting * ( or you run a bunch of examples to check ) , there's a fair chance they're not actually the same thing . so you can say "" i don't care what minitab does "" -- well why link to an article that's explicitly discussing minitab ?"
63597,is there are any particular reason you're suppressing the intercept by including ` 0 ` in the formula ?
89392,"closely related threads can be found by searching [ constrained regression ] ( url ) . it looks like none of them answer this question because ( a ) most of the answers involve little tricks specific to their circumstances , rather than general solutions , and ( b ) all of them concern equality constraints rather than inequality constraints . however , * * this question is ambiguous : * * ( 1 ) why did you use different subscripts $ i $ and $ j $ to describe your data ?"
90047,this question isn't clear to me . are you asking for code that will let you add to a certain type of file ?
89929,"you talk about your ivs but not your dv ( though the title suggests it takes two values ) . this would suggest t-tests are not suitable , but why is it important to test for univariate differences before doing an anova ?"
90242,"uh , the spread of those residuals look okay to me . with that arrangement of x's what did you expect the spread should look like ?"
90207,"as it stands your question is unclear . if you arbitrarily increase the probability of selecting from the tails compared to the center , you're no longer sampling from a normal with variance $ sigma $ ( and if that's okay , it's easy - sample from something with higher probability in the tails -- like a normal with large variance ) . what are you trying to achieve , exactly ?"
90717,"if you * know * that there is dependence then i would suspect some problem with the lag plot . it seems odd that any time series data could show no autocorrelation , but i guess it's possible . what's your variable ?"
90758,"these are the * same * model , restated . can you please state what the two different pictures are that you're inferring from the two different views of the same model ?"
91158,"only by interpreting "" looks like "" very loosely , as if all the probability mass is already at a strain value of 2 , there's none left to go anywhere else - the probability over all values has to add up to exactly one . what is it you're really trying to do ?"
91715,"it depends fundamentally on * why * one is fitting or assuming a distribution and what it is intended to represent . we field many questions on this site where it appears people feel they have to fit a distribution to data or derived quantities ( like regression residuals ) when in fact the exercise is pointless ( or worse , deceptive ) as far as solving the statistical problems they * really * have is concerned . could you perhaps clarify the kinds of cases you have in mind ?"
92040,"there is an apparent inconsistency in this question : it appears to ask for families of unimodal distributions in which all possible modes can occur . that is true of the dirichlet , so "" doesn't really work "" seems to express some error of calculation on your part rather than an inherent limitation . are you therefore really just asking how to find a set of dirichlet parameters to realize any given mode ?"
91960,"what says this , and in what context ?"
92656,$ x_i $ is the random variable and the $ x_j $ 's are the possible values that it can take ?
92740,you will probably be interested in [ tag : equivalence ] testing and questions on the site detailing it . see [ how to test hypothesis of no group differences ?
92899,"there are many possible reasons for failing to achieve significance , including ( but not limited to ) : ( i ) small sample size ( leading to low power ) , ( ii ) a very small effect size / little difference in populations ( perhaps even one so small as to be of no practical importance ) , ( iii ) using a test with low power against alternatives of interest , ( iv ) test assumptions unsatisfied in a way that leads to low power . it looks to me like the last one may be part of the story - your distribution is somewhat discrete ( e . g . a big spike at 0 . 99 and a moderate one at 4 . 99 -- prices , right ?"
93029,"how do you define "" known "" or "" popular "" ?"
93374,"i think i follow : because you state the $ y_i $ are "" given "" ( and presumably measured without error ) then , in effect , the $ y_i $ play the roles of * parameters * rather than random variables . ( the notation "" $ x y_i $ "" suggests otherwise , unfortunately . ) several methods to deal with this situation come to mind , depending on exactly how the $ y_i $ control $ f $ . could you provide some details of that ?"
94396,are you reasonably certain that everyone's scoring the measure the same way ?
94604,"it seems that the table already gives the answer : because it says that $ 2 . 24 % $ of all filers with incomes of 50k or more are audited , that's the chance that a randomly chosen filer in that income group will be audited . because that is far from the answer provided you , i would guess the question differs in some important--but perhaps subtle--way from how you have phrased it here . could you tell us * exactly * what the question asks ?"
94863,is there anything that haven't been answered on [ quant . se ] ( url ) where you posted a closely related question ?
95261,doesn't the base depend on the kind of entropy ?
95588,"what does "" strength of schedule "" mean ?"
95658,there are [ discrete uniform ] ( url ) & [ categorical ] ( url ) distributions . can you say more about what you are looking for ?
95851,would a survival model work here ?
95996,"as far as i know , there is no exact analytical expression for communalities ; the formula that you provided is only an approximation used to initialize an iterative algorithm of factor analysis . is that what you mean ?"
96532,"what do you mean by "" a timecourse dataset "" ?"
105882,"wait , so are you saying they're available for purchase but that you just don't want to pay for them so you're looking to get them for free ?"
161218,"i would clarify what you mean by "" would you use [ techniques ] to estimated the nodes of a bayes net ?"
168029,"( 1 ) ripley's k is far better suited for analysis and insight rather than tests . no single test will capture everything that can be learned from a careful look at the graph of $ k $ ( or better , a suitably standardized version of $ l $ ) . ( 2 ) i have never seen software for ripley's k that did not also include a simulation-based confidence band . that can be very helpful to support visual assessments of differences . ( 3 ) ok , let's accept that you need a test . you must specify what behaviors you are comparing . * what is the alternative hypothesis . * ?"
225714,"you talk about needing smoothness , but how would you feel about ( possibly spurious ) oscillations in the fitted ( spline ) function ?"
309514,"why don't you just check for duplicates with distinct in sql , or just compare the id's or something ?"
309991,"you'll never get a definitive answer from cv statisticians wrt your question . why don't you simply try both metrics and see which one , if any , provides the more descriptive , intuitive and / or variance-explaining answer ?"
311797,it's unclear what you are looking for . would you be asking why the entropy depends only on the frequencies of values of the image and not on their locations ?
312678,in what way do you think that parameters are penalized in standard stepwise regression ?
313450,is this example enough for you ?
313624,"what do you mean by "" primary "" and "" secondary "" distributions ?"
313091,"this is basically a method of moments estimator , no ?"
315651,can you explain how you are going from a precision matrix to an edge list ?
315743,this depends on the network . can you show us details about the network ?
316729,"can you say more about your situation , your data , & your goals ?"
317656,how are you parametrizing the gaussian mixture so that there is ambiguity about the number of parameters ?
318422,"could you help us understand the implicit distinction you make between a ( presumably long term , hypothetical ) * rate * , as in "" false discovery rate , "" and a * probability * ?"
318959,your assumption of normality seems suspect . you should research weather and temperature literature . you will then need to look at a predictive interval or predictive distribution for temperature . are you only considering $ t_2 = f ( t_1 ) $ ?
320820,"on what units are these "" scores "" measured ?"
320993,"i like to think about microscale phenomena , on the level of diads and triads in a network . at the diad level you can think about mutuality of ties : if we condition on a- b does the edge b- a exist with higher or lower probability than if we don't condition ?"
322018,""" if the weibull model is a reasonable model for your data and you use proc lifereg and proc phreg to fit the data , then the regression coefficient estimates not only have opposite signs ( except possibly for the intercept ) but also have different magnitude "" which procedure are you using ?"
322841,"not all correlations are possible for all $ n $ , due to the fact that the variates have to sum to 1 . do you have any more information you could share ?"
323981,what can you tell us about the measurement errors in the $ x $ and $ y $ values ?
324440,are you assuming that the functional form of $ p ( x ) $ is known and that the only issue is parameter estimation for a finite-dimensional set of parameters ?
325214,"could you clarify what you mean by "" mutual computation "" ?"
324823,"welcome to this site . you are right in the interpretation of the ks test , although the sample size is pretty low and you could go for a shapiro-wilk . but why would you go for the wilcoxon signed-rank test ?"
326540,"do you know , or can you estimate , the distribution of doses overall before categorisation ?"
289062,"naive bayes , perhaps ?"
327530,"how do you define "" probability that two sets are correlated "" ?"
327570,"yes you can . but for a more specific question you should specify a bit better what your desires are regarding "" create a predictive model using any of algorithm's used "" . your question seems like 'we have data ( about incidents ) , what can we do with it ?"
328029,"what do you mean that your results are "" better "" ?"
328454,how are you computing the p vlaues ?
328633,why are you imputing zero values with medians when there is clearly non-ignorable missingness ?
329022,a lot of this will be clear automatically if you understand what an svm is & how it works . you may want to read this : [ how does a support vector machine ( svm ) work ?
189941,op : presumably you are aware of a pearson plot diagram which characterises distributions ( that are members of the pearson family ) in terms of skewness ( y-axis ) and kurtosis ( x-axis ) . is your question : how to add other distributions onto a pearson diagram ?
330054,"do you want to assess ni just for the final time point for both outcomes , or at the 4 post-baseline time points ( = 8 comparisons ?"
330045,what values of $ c $ are you examining ?
330248,"if you are to use the aic , estimate the model on the full series and get the aic for it . there is no place for prediction trials if you are going for aic rather than cross validation . but perhaps i am misunderstanding what you are doing ?"
332052,"1 . whether it has a name or not probably doesn't matter , just give it a name and describe it for your audience . 2 . i can't see what you'd be learning : someone listens to 3 songs , they subjectively identify 1 that "" feels "" discordant , no pun intended . what's the question ?"
332895,what is the relation between the title question and the text in the body ?
333445,"delta method does not estimate the variance of $ hat { gamma } $ , but is used to understand the form / structure of $ var ( gamma ) $ . the degrees of freedom of the $ t $ will be determined by the estimator of $ var ( gamma ) $ . so what is the estimator ?"
336447,clarification : what do you want to compare between the two models ?
264912,i would say this is quite a big matrix . even plain eigendecomposition will be problematic . mds is more than that . have you considered first to do a cluster analysis to reduce the cardinality of the data ?
337105,what is the purpose of your analysis ?
338260,what is the purpose of this scoring ?
329981,what is it you are asking ?
338036,"what do you mean by "" subtracting median values of different quartiles "" ?"
338335,what is your two way fixed efects model ?
329687,"do you mean : given training data , learn the class separation ( via a classifier ) and make predictions on future data , using the learned classifier ?"
340626,do you want to implement sann or just solve lr with sann ?
344002,if you need for some unstated reason to aggregate to months ( and do avoid that unless under compulsion ) then averaging the weeks that notionally fall in a given month may be adequate when averages are needed but splitting weeks between months is likely to be required when totals are needed . so you need to say that you have figures . what are they and what kind of aggregation is sought ?
345275,not sure what the question is . do you have trouble calculating the confidence interval or trouble with your definitions ?
344932,"what is the temporal frequency of which you collected the data at each site ( e . g . , every year , every month , etc . ) ?"
346030,"what is your question , actually ?"
346936,does url answer your question ?
347122,"it depends on what you might already know / understand about how this behaves , and kind of information you want to get out of it . one possibility might be to try to model it as a mixture ( is there a reason it looks like two separate but overlapping groups there ?"
284211,` to be normally distributed for each class ` - i don't understand this . the hidden units compute an activation for _every_ class in the output because they are fully connected . why would you want to control the hidden unit activation values anyways ?
347262,are the height and weight on different non-overlapping datasets ?
347048,what do you wish to accomplish in combining the data from the two studies ?
348775,is this for forecasting ?
349072,"welcome to cv , rforresearch ! this isn't an answer ( and hence i make a comment ) , but when thinking longitudinally , there may be lots of ways to think about differences . see my answer to the question [ which stats tests to use ?"
1753,"what was on the x , what was on the y , and what was the point of the graph ?"
3599,* in that values of b above a threshold will change c * do you know that threeshold in advance or does it need to be estimated as well ?
4214,what would be the purpose of ( or what would you conclude from ) a meta-analysis on studies involving the same outcome but different predictors or risk factors ?
4686,is anything known / can be assumed about the $ b_i $ 's ?
4689,"sorry , i don't understand what you mean by the second sentence . would you try and reword it ?"
5382,"what exactly do you mean by "" effective rating "" ?"
5757,"what do you call "" every experiment "" ?"
7314,""" . . . conditional probability tables used in this approach does not correspond to stochastic or deterministic relationships in winbugs "" : how not ?"
8065,what are those numbers ?
8349,lizzan are you interested in displaying each error type or just the overall error rate ?
8959,can you pls be bit more detailed ?
10961,prices are usually unit-root processes . did you check for that ?
11402,"are you saying that * practical nonparametric statistics * tells you to "" * throw out * "" data when they are tied ?"
11980,what is your goal on generating a probability model for your percentage ?
13078,$ n $ is not know ?
13141,this question is extremely vague and difficult / impossible to answer in the current form . can you hone in on a specific question that you need help on ?
13287,"can you be more precise about what you mean by "" the cointegration technique "" ?"
13500,thanks for the edit . just one more question . . . what would you do if you rejected this data ?
14910,"are you sure you really meant to change the title to include "" time series "" ?"
15463,"are you having a hard time with "" correlation coefficient "" and "" differ significantly "" or perhaps just one of those ?"
15467,can you give us some information on your design ?
15584,61 different correlation analyses between the same variables in the same dataset ?
15889,"i've tried your code with correlation matrix of random normals , and there were no marked increase in average correlation . so probably the problem is as jonathan explained , the eigenvalues you discard carry substantial information about your input matrix . i have few questions about your code though . why do you do the transformation in 4 line , i . e . inflate eigenvalues ?"
16094,did you delete the so version ?
17229,"i'm a little unsure of the notation , but i think $ prod_ { k = t } ^ { j } left ( 1-h ( k mathbf { x } ) right ) $ corresponds to $ s ( t ) / s ( u ) dt $ . notice how the former is automatically normalized to $ 1 $ for $ j lt t $ and , similarly , that $ s ( t ) / s ( u ) dt = dt $ at $ u = t $ . therefore the answer to your question must be lurking in the definition of $ h $ . could you provide that definition so that this pair of questions can stand on their own ?"
17527,"well , the log likelihood of many models are concave ( in particular , linear and certain formulations of generalized linear models ) . so maximizing them over a convex set becomes a convex program for which many fairly general computing packages exist . does that help ?"
18745,"what scientific sense would it make to retain some , but not all , levels of a factor ?"
19473,can you tell how the column looks in the source data file ?
19670,doesn't the function rcopula in the same package do that ?
19999,"could you explain how a single number , the rmse , can "" fit "" a distribution ?"
20399,"i find your example a little confusing , john . it refers to a situation with extremely strong distributional assumptions , but it immediately follows a remark about having "" absolutely no assumptions whatsoever on the prior distributions , "" which sounds like exactly the opposite situation . which is the situation you really have in mind ?"
20845,what kinds of analyses or decisions do you want to make about these relationships ?
20952,"in what sense is variance "" cumulative "" in a way that any other statistic , such as the mean , is not ?"
21530,it might be a feature of your data ; have you tried running other rf implementation on the same dataset to see if it reproduces this effect ?
21754,"just to check i understand . first , you say style 1 is a ratio scale , but in your text you talk about "" people with style 1 "" which makes it sound as though it is a categorical variable they can have . do you mean "" people with high scores on style 1 ?"
21971,could you update your question text and question with what you are trying to do ?
22053,"i would second whuber's comment which points to an important aspect when asking question : without some context , it is often too hard to provide a definitive and arguable answer , let alone some relevant pointers . in particular , what kind of questionnaire is it ( e . g . , when validating a questionnaire , i would first ask if this doesn't reflect a problem with * face validity * ) ; does the response rate ( rr ) depend on respondents' characteristics like gender , age , or geographical location ; what do you intend to do with the results ( 30 % rr on a 2-year follow-up with youth might be seen as acceptable ) ?"
22133,what does a scatterplot of the data look like ?
22214,"several questions appear to already answer this question , [ what if residuals are normally distributed , but y is not ?"
23057,so what is there to not understand ?
23108,"are you saying you have * stratified * the population by gender and selected 60 males and 95 females , or are these the actual counts of males and females observed in a random sample ?"
24604,what is a lhc scheme ?
25789,can you post your data ?
26316,where did you get this formula from ?
28087,"unless both $ x $ and $ y $ are random , either $ e ( x y ) $ or $ e ( y x ) $ is essentially meaningless , so i take it that both are supposed to be random . . . have you studied errors-in-variables models ?"
29594,why can't your answer of 4103 be right ?
29609,"roughly speaking there are two stages in a statistical experiment : before the experiment and after the experiment . in the binomial case , before the experiment we say : "" we will observe a realization of a binomial random variable with unknown proportion parameter $ theta $ "" , after the experiment we observe the realization and the question is "" what can we say about $ theta $ ?"
29614,do the models include other covariates besides the group effect ?
29636,what is your response variable ?
30928,what is the purpose of clustering in this case ( i . e . what are you trying to find from this data ) ?
31336,"just curious , what defines the trend line ?"
31550,what r function are you talking about ?
31648,what are $ x $ and $ mathbf { x } $ and how are they related to $ delta x_i $ ?
31929,can you say more about what you mean when you say the groups are not randomly selected ?
31948,"as fa might not necessarily be the best choice , depending on the question you are interested in , could you say more on the context of your study ?"
32586,i'm not convinced this is an appropriate model to begin with . are you familiar with the [ nyquist-johnson theory ] ( url ) of thermal circuit noise ?
32701,"it is unusual for boxplots to show confidence intervals . don't these show quartiles , fences , and any outliers ?"
32992,how did you obtain the trend estimates ?
33525,i think you mean ac and bd in the first case ?
34139,when you say update do you mean reestimate the parameters or revise the form of the model ?
35459,what sorts of problems are you having when you do this ?
35864,i probably don't understand your question . there is no uncertainty : which stocks fell first ?
35892,robinson could you provide more information about $ f $ ?
37594,"perhaps tell us a bit more about your situation . do you have just one measure per event or observation , or more than one ?"
38757,so $ theta = sigma $ ?
40592,"are you saying there's a strong * negative * autocorrelation , ie that if year t = 1 , year t 1 * must * equal 0 ?"
41798,"it looks as if you are supposed to assume this is a continuous variable , but in practice absentee records tend to be discrete : which group would someone absent for 6 days be in ?"
41846,"taking the average of the percentages is probably not a very good idea . do you know the numerator and the denominator counts of each of the percentages , or you just have the percentages , nothing else ?"
43120,what are you hoping the cronbach alpha to inform you on ?
43175,are you asking for an ` r ` package ?
43009,also of interest : [ what is the best way to identify outliers in multivariate data ?
44018,"when you say 'constant variance' , do you mean 'known variance' ?"
44023,can you expound this interesting idea in your question ?
44384,"cristina , could you please explain exactly how your model would differ from two independent regressions ` y1 ~ x ` and ` y2 ~ x ` ?"
44712,"what exactly do you mean by "" based on set a "" ?"
45345,"by "" bidirectional data "" do you mean data drawn from a bimodal distribution ?"
45799,"this question came up in comments to my answer - do all patients have revision times because revision is inevitable , or because only revision-needing patients are included ?"
46635,what is to prevent your algorithm--or indeed any algorithm--from producing identical pairings for every round ?
48060,"please observe that ( * caeteris paribus * ) ( 1 ) the widths of confidence intervals tend to shrink with increasing sample size and can be made arbitrarily small and ( 2 ) your question presents no constraints on sample size at all . thus , for instance , if group a were large , it could easily happen that the group b mean would not lie within the ci for a because that ci could be very narrow compared to the sampling variation of the mean of b . that answers your first question . for the second : what do you mean by "" associated "" ?"
48370,isn't that ( part of ) what the theorem asserts ?
48767,just an idea but perhaps it would be useful to have a look at hadley wickham's implementation of grammar of graphics for r for some pointers ?
48938,"90 % of statistics is knowing what answer you want . you need to decide what information you're hoping to get back ( like , was there any year where values were lower than we would expect ?"
49905,"hi aly , i added the term mahalanobis distance to your question as this is the what your distance is actually called . did you search for strategies to determine mahalanobis distance for small sample sizes ?"
50584,i vote to close this as a duplicate . did you read corone's [ edited answer ] ( url ) to your [ other question ] ( url ) ?
50586,"a good question that would be even better if you told more about your data . e . g . , how many variables are measured per user ?"
51115,is this related to some coursework ?
51590,"unless i'm mistaken , it sounds like you are greatly overcomplicating this . do you just want to see if the prediction rate is significantly higher than expected by random chance ?"
52209,um--don't you just subtract the minimum of the 1500 values from the maximum ?
52631,"what does "" $ c $ "" stand for in the definition of $ h $ ?"
53099,"can you assume any relationship between the mean of $ y $ and $ x $ , say linear ?"
54671,"what do you mean by "" statistical features "" ?"
55247,well you have to investigate the nature of your problem : is it linear or not ?
55572,"how is it possible to * observe * "" -inf "" ?"
56250,"these are probably the cluster centers , right ?"
56967,"could you please tell us a little more about your experiment : sample size , number of items in the scales ?"
57603,welcome to the site . do you have * samples * or * populations * . how many time periods do you have ?
59052,duplicate of [ this one ?
59302,what are you computing and how are you computing it ?
59715,"not really clear what you seek here , not least is this homework ?"
61898,"lots of unexplained jargon / abbreviations ( i fixed some but stuff like 'dev' - is that 'developer' , or some other thing ?"
62902,how many ways can $ x = y 17 $ ?
63402,it would be easier to answer the question with some more information . there are sixteen individuals but way more than sixteen boxes on the histogram . are there lots of sites per individual ?
64092,why do you think this would reduce noise ?
64166,could you maybe include 1 ) the plot and / or 2 ) a dataset so that we can reproduce your example ?
64856,"thanks for editing . you responded well to the first two comments , but not to mine : please tell us * what your investigation objectives are . * what are you trying to find out ?"
64893,where does your lrt ( ) function come from ?
64983,i really don't understand what you are trying to do . do the lists represent input vectors or labels or . . . ?
65497,does this make any sense ?
68358,"what power did the "" low sample size "" provide for assessing the hypothesis ( or hypotheses ) in the first study ?"
68684,why not say that this model only applies to the work week ( mon-fri ) as data were not available on sat and sun ?
69258,i find 'multivariate marginals' somewhat ambiguous here . could you be considerably more precise about what you're asking for ?
69383,can you show what integrals you are taking ?
69720,can you give a context to the quote ?
69761,"cochran q is is a repeated-measures "" anova "" for k dichotomous variables with the same two categories . then , what does a 2x2 table mean in your case ?"
69803,is there anyway for you to show us what the table looks like ?
69814,what do you mean by rate of the students ?
70183,you could be mis-applying the test : your description is vague . could you clarify it ?
70355,"could you please explain precisely what you mean by a "" partial correlation matrix "" ?"
71001,"it looks like your question got chopped off at the end . "" equal to "" what ?"
71301,is this homework ?
71466,"where have you been introduced to the hommel hochberg corrections , if you don't mind my asking ?"
72441,welcome to the site . what sort of model did you develop ?
72753,can you clarify : do we have a 1-d distribution $ d $ from which we get $ n_s $ examples $ { x_i } _ { i = 1 } ^ { n_s } $ ?
72986,would you mind linking to the paper ?
73181,are you speaking of * * median * * absolute deviation ?
73225,"welcome to the site , teddypicker . i have taken the liberty of formatting your question with the $ latex $ that the site affords . please ensure it still says what you want it to . also , could you edit your last paragraph ?"
73415,"i think that is not enough information . when you say , a proportion of a field is covered in water , is there any additional knowledge about the form of that proportion ?"
73637,"you might need to a bit more specific , gregorian funk . did you mean , say , the confidence interval of a variable that is the product of two variables whose confidence intervals are known ?"
73805,brownian correlation ?
73884,"just out of curiosity , how did you end up with an uncomputable prior that you can sample from ?"
74566,"what hypotheses and "" effects "" are you interested in ?"
76429,my current version of r does not have the ` ohio ` data ( 2 . 15 ) ( at least not as part of base ) . is it in a newer version or via some other library ?
76672,"as far as i know , accelerated failure time models take the log of failure time as the dependent variable . in your case ` exp ( 3 . 5288 ) ` is the mean time to failure and other coefficients act on this . risks are associated to hazard models . what distribution did you use ?"
76936,is there anything preventing you from simulating ?
77100,how many fish species and anemone species do you have in total ?
77283,if you set e . g . $ x_2 $ to 0 then $ b_1 $ is only the contribution of $ x_1 $ when $ x_2 = 0 $ . is that what you want ?
78025,what are the integration limits ?
78070,"what do you mean by "" valid "" ?"
78084,"this question appears to be based on a misreading of the [ second wikipedia article ] ( url ) . did you note the passage "" be careful when reading the expression : here supp $ x cup y $ means "" support for occurrences of transactions where $ x $ and $ y $ both appear "" , not "" support for occurrences of transactions where either $ x $ or $ y $ appears "" "" ?"
79352,how large are the four groups ?
79492,it depends on whether $ p $ was estimated from these data or was determined in some other way . perhaps you could clarify that point ?
80033,"assuming $ y $ is binary , $ y = b_0 b_1x_1 u $ is not a linear probability model ( lpm ) , just a usual linear regression model . $ p ( y = 1 mid x_1 ) = b_0 b_1x_1 u $ is the specification for the lpm . also $ y = phi ( b_0 b_1x_1 u ) $ is not a probit model - $ p ( y = 1 mid x_1 ) = phi_u ( b_0 b_1x_1 ) $ is . are these just typos of the question , or you actually estimated the specifications that you write ?"
80955,"it's also going to get hammered on so because it's just a "" how can i ?"
81750,"to be clear , you are classifying based on a single lab value ?"
81759,hint : what is your chance of * not * drawing that number after $ x $ attempts ?
82850,can you simply normalize your data first ?
82893,why is one vector longer than another ?
83002,"you can certainly calculate sd , interquartile range and range . ci are trickier . what will you do with the information ?"
83258,"gaussian distributions don't have two modes . if it has two modes it * cannot * 'seem to be gaussian' . i have no clear idea what you do mean , though . do you mean that you think it looks like a mixture of two gaussians , or do you mean something else ?"
83462,"not sure what you mean by the "" between estimator "" . do you mean you have two groups ?"
83760,"i'm having trouble understanding your scenario . do you mean $ n $ samples , or one sample of size $ n $ ?"
85730,i was wondering why you say you have data for minimum & maximum & maximum values ; then later that you have information on only expected minimum & maximum . which is it - observed or expected ?
86695,"the answer depends on the definition of "" white noise "" : by some definitions it is ( trivially ) ergodic whereas other broader definitions allow for it to be non-ergodic . * what is your definition * ?"
87090,"i'm not sure i can follow your question . what means "" policy weighted "" , "" policy level loss ratio "" ?"
87508,you must give more context . what else do you know about the data ?
87599,could you elaborate on your question ?
87749,what is the model that you are considering ?
87812,random initialization compared to _what_ initialization ?
87950,what are $ x ^ { ( i ) } $ and $ mu_ { c ^ { ( i ) } } $ ?
88392,"in line 2 , are you sure you want ` runif ( ) ` for your error term ?"
89012,not sure to understand why you can't . is that a question on how to do a pivot table in excel ?
89409,"if a predictor ( not only dummy one ) is very much skewed it is suspicious for possible outliers . for example , your dummy with 997 and 3 counts - who will bet that those 3 are not slip of a pen and are real ?"
89416,"since this is a routine book-work question , it should carry the ` self-study ` tag - and whose [ tag wiki info ] ( url ) you should read and follow the guidelines of ( i . e . edit your question ) . specifically , what have you tried and what problems did you have ?"
89939,draw superimposed graphs of $ exp ( - ( x- mu_i / epsilon ) ^ 2 ) $ for two different values of $ mu_i $ . what happens as $ epsilon $ shrinks towards $ 0 $ ?
89965,"welcome to cv ! what's "" manually identify "" mean ?"
90531,and how do you define the location of the distribution ?
90827,do you mean x = x1 . . . xn is univariate data ( of independent observations ) ?
90965,which two variables are independent you say ?
91222,why don't you write down the log likelihood and differentiate that with respect to $ mu $ ?
91529,"your fit models the spikes very well . i assume you fed it some kind of explanatory variable , e . g . , a boolean regressor coding a promotion . if these explanatory variables are constant in the forecast period ( and your model does not include trend , seasonality or arma terms ) , then the forecast will naturally be constant . does this help ?"
91621,"do you have a sign error in your $ w_i $ or did the image not reproduce the vertical line in a "" "" sign in the equivalent term in the image ?"
92300,what sort of result are you looking for ?
92868,"to what "" approximation "" do you refer ?"
93721,is this for a class assignment ?
94012,the sampling distribution of the standard error ( of the mean ) is * not * normally distributed . are you perhaps thinking of the sample distribution of the mean itself ?
94159,"the correct calculation is described in the question at url other closely related questions include url and url your question needs to be refined a little : to what does "" one standard deviation "" refer ?"
94623,"c45 can be tuned to build such kind of groups . however , before delving into details : what problem do you want to solve ?"
95244,is this a class assignment ?
95297,"in reading your first question , i gather that you wish to use $ x_1 . . . x_n $ to build a prior distribution to be used in the analysis of further observations . is that correct ?"
95965,"it's unclear what you mean by bmi categories , but it sounds like you want to correlate physical activity level with the discrepancy between body image perceptions and body image reality ( which may be fairly independent of bmi seems it would've been good to have data on body fat and muscle percentage ) . . . this would give you an effect size estimate for the relationship between activity and some operationalization of body image accuracy . how to perform that calculation depends on the levels of measurement , which it would be helpful to specify as well . are body image perceptions based on surveys ?"
113589,can you make this more concrete ?
130568,"your question is a little unclear . you'd be doing better to clarify what your variables are , describe how the quadratic coefficient fits into your model and reframe your question to more clearly ask about the statistical aspects of your problem before relating it to r . if you do want to also ask about implementing the model in r , a reproducible example as gung mentioned ( i . e . a small data set and code we can copy and paste to create it , as well as what you're currently trying to do ) would be important . how did this question arise ?"
144032,do you mean 22 variables and 6931 observations ?
144323,it is not really clear what you are asking . could you describe your problem in greater detail ?
144841,can't you just do matrix multiplication ?
177869,` coef ` returns coefficients and ` ranef ` returns modes of random effects - what i not clear in it for you ?
215008,"just to clarify a possible ambiguity : by "" spherical distribution "" do you mean a distribution on $ mathbb { r } ^ n $ that is invariant under rotations about the origin ?"
252267,are you talking about the mean or the variance or both simultaneously ?
256317,"please give more background . why do you want to compare , combine , think about . . . z scores rather than the actual data ?"
280764,"i assume $ d_1 , d_2 $ are some real random variables . when you say "" the relation between the two is not symmetric "" , what do you actually mean ?"
284651,it would be more useful to tell us the values of the autocorrelation . why don't you want autocorrelation ?
284811,"what level of granularity are you after , i . e . what are some examples of the common situations you want a quick reference for ?"
285197,your question is unclear . can you review it ?
294474,is m_y known ?
308647,what does * ltm * stand for ?
309657,"if you know the joint probability function , it is either a normal density or it is not . what is the question ?"
310319,"since you can make any ( not topologically wild ) non-simply connected region into a simply connected one by removing a set of measure zero ( with respect to both hypotheses ) , simple-connectivity is not a useful criterion . the problem of finding a critical region is relatively straightforward ; the key is to estimate $ h_0 $ and $ h_1 $ and then to assess how data variability affects that critical region . your knowledge of and assumptions about the hypotheses should help you identify suitable estimation procedures . can you provide more details ?"
310443,can you explain your question better or maybe give a little example of how is the data ?
312591,a higher value of what ?
313894,what do you mean by euclidian distance between matrices ?
315786,this is meaningless without a description or definition of $ b ^ { * } $ : what is it ?
315977,"this is a tough one to answer correctly even for people who are very good at math , because to apply any mathematics at all requires adding at least two pieces of information to the question : ( 1 ) how the survey was taken and ( 2 ) what your beliefs were * before * the survey results were revealed to you . could you include this information in your post ?"
316967,"what do you mean by "" performed better "" ?"
317680,"why are there four numbers after the "" x "" ?"
319302,what is $ a $ ?
319516,"i am not sure i understand the question . if you solve the dual of the primal , you are solving the same problem . so apart from efficiency , why would any other factor play a role here in deciding whether to optimize the primal or dual ?"
320104,could you explain what you mean for a distribution to be consistent ?
320459,"why do you think the variables follow a power law when they are the sums of three exponential variates , which do not follow a power law ?"
322995,can you explain what you want more clearly ?
323833,same ones as with every other kind of models . could you try being more specific ?
323933,why mention spss here ?
324867,"the terms "" portfolio effect "" , "" insurance effect "" and "" overyielding "" seem to be some disciplinary jargon . that could be fine , but think about your tags and title to make sure that you attract people in that discipline to your question . general tags ` correlation ` and ` variance ` seem unlikely to do that . is this ecology ( as the terms diversity and stability suggest to me ) ?"
325058,what values does your dummy variable take ?
325064,is the $ sigma $ a covariance matrix in your parametrization ?
325069,"do you have per-patient data available at the hospital level , or are you relying on aggregated data for each hospital ?"
327425,are you assuming the $ x_i $ are independent or not ?
328062,"welcome to cv , guillermo ivan pereira ! i think this is an important question . can you clarify whether those categories are * ordered * or * unordered * ?"
328791,"why don't you just do it the bayesian way and model each probability as , e . g . , a beta distributed belief , and then calculation the probability that one belief is greater than the other ?"
330790,can you describe what makes mass spectrometry data different from other datasets to narrow down your question ?
331174,your last paragraph is not clear to me . what is the obstacle you are facing ?
332432,"wouldn't you use causal impact on the treated population time series only , rather than on the whole population ?"
333299,can you rewrite the specific lemma you want a proof for ?
336101,"this has been addressed in many easily accessible places . have you done a basic search on this , and if so is there something particular that is giving you trouble ?"
336851,"what are $ a $ , $ d $ and $ p $ ?"
337271,is this a home work ?
338038,unclear question : what is the role of $ t $ ?
340088,"it's clearly not the case that the product of two independent gaussians is independent of either one : the variance of the product , conditional on one of its factors , obviously changes . your question is confusing because although you use the term "" independent , "" your formula expresses a condition of * zero correlation . * which one are you trying to ask about ?"
340643,the formula for $ g_t $ doesn't look familiar to me . why subtract $ r ( pi ) $ ?
340688,you probably mean clustering the transpose of a matrix ?
340762,"i don't fully understand this , but shouldn't that be 'adding a small value to a zero probability' ?"
341743,"can you expand on what you're trying to do , and why ?"
342249,"looks very difficult . perhaps as a first approximation for large $ n $ , you could say $ sum_ { j = 1 } ^ nf ( x_i ) approx mathrm { e } [ f ( x ) ] = mathrm { e } [ f ] $ ?"
342542,welcome to cv . is ethnicity your categorical iv ?
342800,"choosing the medium threshold seems strange , wouldn t that result in different false positive rates for the different classifiers ?"
343216,do you know how to determine quantiles for a standard normal distribution ?
343265,""" how do i judge if this model is good enough or not ?"
344790,"would you add some specifics as to what is meant by "" knowing their relations to the densities of interest "" ?"
345125,there are multiple possible interpretations of 'graph structure among the labels' . could you say more specifically what this means ?
345151,what do you mean by latency ?
345317,what do you mean by * stationary at i ( 0 ) * or * stationary at i ( 1 ) * ?
346532,i don't get it : is $ x $ a multinomial variable that takes 5 levels ?
348294,what are you asking ?
348758,is this homework or self-study ?
348772,what do you mean by evaluation ?
96885,"i think it is pretty straightforward . but i find the input values confusing . since "" high "" = 0 ; is "" low "" = -1 ?"
97304,wondering if there's a bit of context missing . sounds like a question after the introduction of an algorithm which takes those inputs as values and computes how to optimize revenue or risk . . ?
97656,"if i understand correctly , you now have independent observations and kw anova followed by any suitable nonparametric technique for pairwise comparisons should be ok . however , what is your classification factor ?"
97938,"in addition , do you mean that $ q ( x_i ) = 0 $ for all $ x_i $ ?"
99304,"could you clarify what a "" low frequency ( of events ?"
99266,"you are interested in some metric on the covariance matrix reflecting estimation errors , right ?"
99508,nothing is known about $ f $ ?
99638,are you asking about how to select a model or about how to use proc arima ?
100073,"as stated this is not a probability problem , but a straight mathematics / logic question . it's also so straightforward as to be routine bookwork - is this for some subject ?"
59228,"procrustes requires that points in the clouds are already matched , that is , any point _i_ in one cloud corresponds to point _i_ in another cloud . is that your case ?"
100780,"by the mixture property of the normal distribution , $ y_i theta_i $ is given by $ n ( mu , frac { 1 } { tau } frac { 1 } { tau_i } ) $ . is $ tau_i $ observed in each study , and assumed drawn from the same gamma distribution ?"
100635,why did you say of repeated measures ?
101306,you can't take the difference of categorical variables . please clarify . do you actually have 163 team pairs in your data ?
101510,"andy edited in the granger-causality tag , which shows that there are lots of questions on the topic on this site . have you looked at any of them ?"
101385,"like a ( two-tailed ) paired t-test , wilcoxon signed rank test or sign test , for example ?"
102678,"if possible you want to avoid throwing out the extra $ ( 21-15 ) ( 27-15 ) = 18 $ subjects ( $ 29 % $ of the total ) because that substantially reduces the power of the data . what statistical procedures , exactly , do you wish to perform that cannot be accomplished with unequal group sizes ?"
102925,"setting the new dependent variable to $ y-x_1 $ is just equivalent to having a regression for $ y $ and using all three predictors but forcing the coefficient / effect for $ x_1 $ to be $ 1 $ . further , perhaps it would be useful to know why you want to remove this predictor ?"
103220,"please add the ` self-study ` tag and read its [ tag wiki info ] ( url ) carefully , modifying your question if necessary to conform to the request there . i'd assume the intent is for you to invoke the clt . what information do you need to specify a normal distribution ?"
103453,what exactly troubles you in the expression $ $ e [ x_ { t-1 } x_ { t-2 } ] = e [ ( delta phi x_ { t-2 } eta_ { t-1 } ) x_ { t-2 } ] $ $ $ $ = delta e ( x_ { t-2 } ) phi e [ x_ { t-2 } ^ 2 ] e [ eta_ { t-1 } x_ { t-2 } ] $ $ ?
103911,did you notice that $ 0 . 66 ^ 2 = 0 . 44 $ ?
103857,does this question help at all : url ?
103847,how generalised ?
41394,"just curious - when you say "" frequentist analysis is more practical "" are you talking about the software - such as using ` lm ( ) ` in r being easier to use ?"
104399,i think your question is directing people to give you an introduction to poisson regression . why don't you revise your question and really tell us what you are trying to justify ( in the first sentence ?
104391,are you saying you want to know if there is a statistical relationship between any of the first 4 scales and any of the last 3 scales ?
104585,"yet , you do not have enought variability in the ligitation and layoff variables to estimate their effects . unless you provided only a subset of your data ?"
104749,where does it say p ( w ) = likelihoodfunction ?
104761,( i ) can you give some context ?
105186,"if i understand your question , it is something like this : i know how to conduct a paired * t * test on * a * . but i want to perform this test on * b * . but * b * is sometimes meaningless . * * what is the standard way to do this ?"
105192,"for * unweighted * correlations , the [ wikipedia article on kendall's tau ] ( url ) answers this question . the ` cor . fk ` function in package ` pcapp ` for ` r ` implements simcha's algorithm and takes a fraction of a second with a $ 100 times 1000 $ matrix . however , the link in ( 2 ) suggests a weighted version is sought . is that the case ?"
105114,could you clarify what you mean by regularised ?
105447,what kind of data do you have ?
105695,"can you cite a source for this : "" i would like to know why 1 / n * summation of ( y / x ) is a worse estimator than average of y divided by average of x "" ?"
105787,can you say a little about what you have tried / understand so far ?
105993,"it is curious that neither examples 2 nor 3 actually show ranges in the usual sense of the word . that raises the question of what you understand a "" range "" to be . does it differ from the conventional meaning of the interval from the least to the greatest value of a set of numbers ?"
106264,are you sure you want to ask a question about curves ?
108278,"calculate the cis for all 3 and look at them . though , is it possible you're interested more in something like a regression coefficient than the correlation coefficient ?"
108173,could you provide more specific information about the structure of the dataset and the purpose of the analysis ?
108586,"can you say more about your situation , your data , & your goals ?"
108761,"your approach appears to make two important implicit assumptions : ( 1 ) collisions are independent of each other and ( 2 ) multiple collisions cannot simultaneously happen . what i would like to know is ( a ) how do you determine the probability values you are using ( such as "" x1 "" ) and ( b ) how do you ensure that the probability of a colliding with b equals the probability of b colliding with a ?"
108430,do you know something about the dirichlet process ?
110224,could you provide us with a little more context ?
110608,"you say you are predicting ` status ` as the response variable , but this is * binary * . you would use an * ordinal * logit model if your response variable is * ordinal * . are you actually predicting severity ?"
110702,how sure are you that the claim is true ?
110688,"you don't need to know beforehand which have a great impact on the dependent variable - that's what the regression's for . how many "" yes "" s have you ?"
110133,"did you take a look at the [ task view for experimental design ] ( url ) . if so , can you specify how this does not provide the desired information ?"
111629,"these data wouldn't be poisson , if you have a known total who could be compliant . instead they would be binomial . are you wanting to compare a vs b , or t1 vs t2 , or both ?"
111819,i don't get anything like 0 . 0839 . what did you do ?
112216,"why do you want a "" wider "" distribution of the predicor variable ?"
112213,"this approach has some problems ; for example , only a few percent of observations at 100sd's from the mean of the 'good data' is enough to mask all the outliers . that said , i think that different circumstances may well call for different criteria . unfortunately , i can't quite follow what you're saying . when you say 'the measurement might be 15 magnitudes' it sounds ambiguous -- what exactly are you saying ?"
112441,maybe look into beta regression ?
112526,"the problem with this is that the sd and skewness coefficient are really sensitive to outliers ! accordingly , i think this is probably a conservative procedure in that outliers tend to inflate these statistics , making it harder to detect outliers . btw , in the 4th paragraph , you meant to say you flag all those * * more * * than 3 sds away -- right ?"
112567,can you show the code you do have ?
113750,can you amplify your question a little bit to motivate the research question you would like answered ?
114119,"your description is a bit sparse , can you add more detail ?"
113691,how do you use avg_neg ?
114356,are all of the categorical variables you are thinking about independent / predictor variables ?
114722,so the latter is nested w / i the former ?
114715,"a particular set of 30 categories , or at least 30 different unspecified categories ?"
114719,"i cannot figure out what you description means . what is the connection between the "" observed data , "" the linear regression , the "" distribution , "" and the "" estimated . . . data "" ?"
115187,are you provided with any form of sampling distribution ?
115335,how many objects will be in the set ?
115680,what exactly do you mean by * comparing them * ?
115911,"since $ x_1 $ and $ x_2 $ are referred to as * independent * variables , why are you inquiring about causal relationships among them ( as in "" get affected based on "" ) ?"
116084,"but that average no longer means anything because you have potentially missed the most important feature of the data . the proportional odds assumption _can_ be a useful simplification of reality , but if the deviations are too strong , then the model is essentially meaningless . consider the textbook example where a scatterplot shows an u shaped relationship and you plot a linear relationship which shows no effect . who cares about inference on the model with a linear relationship in that data ?"
116370,"as noted in several answers below , your model may be mis-specified . can you say more about what your data * are * ?"
116554,"from your description it comes that your instrument is one-scale ( one-construct ) with high homogeneity ( alpha 0 . 91 ) of items . if so , factor analysis - if at all needed - should be specified to extract just one factor . one factor solution cannot be rotated . so , how did you happen to get ` rotated [ loading ] matrix ` ?"
116670,it is instructive to find a maximum entropy distribution subject to a constraint only on its mean--or even subject to no constraints at all . what would it look like ?
116644,"just to check : when you say you know the mean and standard deviation of $ x $ and $ y $ , do you mean these are population parameters , or are these available sample quantities ?"
117431,"out of curiosity , how are you modeling the response variable ?"
115467,have you tought about consulting other psychologist about your design ?
117869,"does the phrase "" one single available observation "" mean a single * number * or a single * set of numbers * ( corresponding to your "" single set of observational data "" ) ?"
118026,"as i understand it there are about 100 years' worth of data over which the record has been lowered by about 1 s . do you think that's enough data to extrapolate to what is possible "" ever "" ?"
118336,say your model is based off of category a ( ie y ~ a ) . and say that a has 4 categories . your model should look like y ~ b0 ( a = = 1 ) b1 ( a = = 2 ) b2 ( a = = 3 ) b3 . where b # is the respective beta . the case when a is equal to the forth category is handled by the intercept . does this help clarify your questions wrt categorical regression ?
118430,in general it wouldn't seem sensible to model an average egg mass with a poisson distribution ( which only applies to a unitless count variable ) . perhaps you intended to use a log-normal ( ` lmer ( log ( avg_egg_mass ) ~ . . . ` ) or a gamma model ?
118541,"in your second sentence you call $ f $ a function ( so $ f ( x_i , x_j ) $ would be some kind of surface ) . then you was "" it's like we observe the "" relation "" between $ x_i $ and $ x_j $ "" , which makes it sound more like your title ( some kind of density , perhaps ) . then you say $ f $ is normal . . . so $ f $ is now a random variable ?"
119789,"i have no idea as to why the limits on the integral change from $ pm infty $ to $ pm pi $ just because the limsup of _something_ ( what's $ cf $ , anyway ?"
119874,"the question is really not clear . presumably , by "" this parameter "" you mean 'this * cluster * ' . what could "" parameter xy "" etc mean ?"
120199,"as it reads now , the question is impossible to answer . thereis no natural p-value for "" means by age "" . anova and regression are both linear models , but anova assumes a categorical predictor , regression a continuous predictor . how many data points do you have for each age group ( you need more than one for an anova to make even sense here ) ?"
120312,is this for a course ?
120803,"this question seems to confuse the roles of independent and dependent variables . in logistic regression , the response is a bernoulli variable with parameter $ p $ . the logit link is one way to model the limited range of $ p $ , which can extend only from $ 0 $ to $ 1 $ . * there are otherwise no restrictions on independent variables , * just as there are no restrictions on the ivs in ordinary regression . it would therefore appear that this question concerns a problem that just doesn't exist . have you perhaps mis-typed "" independent "" for "" dependent "" or * vice versa * ?"
120801,"a retrospective dataset like this might be useful for exploration and setting up an adequate study in the future , but with so much potential for confounding it seems too much to hope that any analysis could address the questions you are most concerned about . have you considered the possibility of making some random choices in the awarding of these programs ?"
121179,can you explain why you think they should be any different ?
121238,does it have to be exactly 2 out of 3 and 4 out of 6 or are you saying at least 2 out of 3 and at least 4 out of 6 ?
121360,"as far as i can tell , the demonstration amounts to dividing both sides of the penultimate equation by $ i omega ^ 2 $ . perhaps you could be a little clearer , then , about what part you don't understand ?"
121457,"i don't understand what you mean by splitting a class . do you mean introducing a new label , relabeling some of the training data to have that label , and re-training the classifier ?"
121708,"glms are linear * in the parameters * . in empirical modelling a non-linear relationship between the expected response ( transformed by the link function ) & a predictor is often allowed for by representing that predictor with a polynomial or spline basis : the model is still linear . are you using "" linear "" in the same sense ?"
121785,"presumably you miswrote "" $ n $ "" instead of "" $ p $ "" and you meant to say that "" $ p-k $ is much smaller than $ p $ "" ?"
121999,what exactly did you do ?
122095,"what makes a dataset "" imbalanced "" ?"
122127,what is the distribution of e ?
121518,"is your intent "" how will my analysis be affected if i treat all the data as independent ?"
122279,"you don't expect consistency with normality - in fact with such large samples , you expect to reject . rather than compare p-values ( which given you don't think the data are either normal or lognormal , aren't really useful ) why not compare the a-d statistics themselves ( which at least are a measure of discrepancy ) ?"
122426,"this questions seems to me to be not well suited to cv . it seems somewhat broad , fuzzy & potentially off-topic . can you focus it more & try to make it more clearly on-topic ?"
122772,"yes , what * is * the problem ?"
122927,"are you asking about how to get c3js to do this , or about how such data are best displayed generally ?"
123015,"2 / 2 as written , i think your question is too vague and may depend on subject-matter specific information . also , it's not clear what your goals are . are you looking for just outlier detection or also interested in predicting at what particular point in time an outlier will occur ?"
122838,if you have such a large uncertainty about the curve ( 20k sounds a lot ) why don't you go for a nonparametric model instead ?
122901,what is your desired result from the nn ?
123201,your model is pretty saturated . you can't really use this many variables ; you probably want to try something like the lasso . what are the predictor variables ?
123207,you need to form your condition indexes after dropping the intercept . did you do that ?
122316,"your procedure is equivalent to deciding that somebody likes something when they respond positively to it at least half the time . although that could be a useful * criterion , * it is not an admissible hypothesis test . moreover , it does not seem to have any way to cope with the complication that each article of clothing has * multiple * characteristics : type of clothing , color , style , etc . how do you propose to separate out the relationships between those different attributes and what people like ?"
123342,let's start by focusing your question : is your trouble over understanding how to arrange the three covariances into a matrix or is it in understanding covariance or is it in computing covariances of such ( linear ) combinations of normal variables ?
123239,can you share * visualization * of the effects you have been observing ?
123412,wouldn't it be possible to incorporate $ z $ into a single model and just test its coefficient within that model ?
123811,do you already know which items ( questions ) in your survey measure each construct ?
123915,are you familiar with $ r ^ 2 $ ?
124179,"could you please explain what you mean by "" model this scenario "" ?"
124316,"this [ link ] ( url ) may provide insight . also , offtopic but a simple searchable database may be useful because how can you cram characters , landmarks etc . in one legible representation ?"
124403,"please elaborate on what you mean by "" makes sense . "" what are you seeking beyond the "" biological meaning "" already ascribed to your thresholds ?"
57757,"do the estimates of a , b or ddref have a standard error associated with them in the studies ?"
124877,"what do you really mean by "" 95 % confidence . . . / -5 % "" ?"
125041,your response appears to be strictly positive . you might be better off with a glm perhaps . what does the response consist of ?
125295,as far as i am aware there is no single 'right way' to do this . an approach would be to use something like hierarchical clustering on the distance matrix $ 1 - rho $ where $ rho $ is the correlations . the other thing is whether your latter correlation matrix will capture meaningful relationships . what steps were taken to produce it ?
125431,"the question is not clear . it will be helpful if you can show a sample of your data in table format . will it be like this : ptid , x_modality1 , y_mod1 , z_mod1 , x_mod2 , y_mod2 , z_mod2 , x_mod3 , y_mod3 , z_mod3 . and you want to check if modality1 and modality2 are not inferior to modality3 , which is the gold standard ?"
125978,can you cite the source ?
126085,can you rephrase your question in such a way that they invite explanation of something rather than a yes or no answer ?
126206,"you cannot sample from an improper because it is not a probability distribution ! using a proper approximation is likely to produce something different . this has nothing to do with r , obviously , but with the very nature of improper priors . when this happens in abc algorithms , i use an alternative proper distribution that is an approximation to the posterior and then construct importance sampling weights to correct for this substitute . could you detail in the question what is your targeted distribution ?"
126226,the formula is indeed weird . can you add links / citation ?
126751,"the correct usage of "" semipartial correlation "" concept would be when there is one dv and 2 ivs . you say you have 1 iv and 2 dvs in this context , what does it mean to obtain residuals from predicting one dv from another dv ?"
127098,why do you think ` p1 - p2 ` will behave like that ?
127226,related : [ how to simulate artificial data for logistic regression ?
127536,"if you cluster observations , "" weighting "" of observations is simply changing frequencies among them ( whatever consideration led to compute the weights ) . is it so from your question's perspective ?"
127495,"what kind of "" transformation "" are you looking for ?"
128877,"usually "" pmf "" means "" probability mass function . "" a single number like $ 2 / 16 $ is not such a function , so what exactly do you mean by "" pmf "" ?"
129240,"i'm not sure that including a polynomial makes something parametric . i usually think of parametric as having parameters of a known distribution , such as the normal , and nonparametrics don't assume such a distribution , perhaps using ranks . what do you mean by "" non-parametric "" here ?"
129332,"i don't think this is really a statistics question . i think it's about "" what else can i do so that i get the result i want instead of the one i don't like ?"
129444,hint : a threshold is defined by giving a number . but what are you going to do with that number ?
129575,` lmer ` in ` lme4 ` supports using weights . what is wrong with it for you ?
67337,"there is no universal relationship ( although there are some bounds ) : that's why people don't use mad to compute confidence intervals ! incidentally , "" sigma "" usually refers to a sample standard deviation ( and so does your tag ) but you probably intended to refer to a standard * error * because that's what the width of a confidence interval depends on in the normal distribution situation . btw , what are "" mi "" , "" mj "" , "" xi "" , and "" xj "" ?"
130415,chi square goodness of fit or something along those lines ?
92020,"this question is not clear at all . what is tls ( yes , i can and in fact did look in the linked paper , but the question should be clear on its own ) ?"
130470,"some thoughts : ( 1 ) if you split your sample instead of including the interactions , you do not restrict the effect of interactions to be linear . ( 2 ) you could play with different splits to see how the effect varies . e . g . try a "" rolling split "" : rank the cases by the relevant variable and model the cases ranked 1st to 20th ; 2nd to 21st ; . . . 115th to 134th . plot you results . ( 3 ) is it honest to torture the data until it confesses ( i . e . until it gives you the answer you want ) ?"
71953,"what's "" moderately correlated data "" ?"
131006,"what do you mean by "" threshold points "" in the dependent variable ` y ` ?"
131310,do you mean other than reimplementing or parallelizing ?
131334,"some questions that may help pin down some characteristics of a model , which will hopefully help to identify the straight part : what is the response before you take logs - is it a count , a scaled count , a measured physical quantity that must be at least 0 , one that can be exactly 0 , or something else ?"
132842,"( ctd ) . . . however , you may also want to worry about dependence over time within subjects ; are you thinking of a mixed-effects model with the treatment of time as a numeric variable ?"
133000,"the tenses in your question are ambiguous . exactly what is the stage of the study at the present time : field work completed ; counties selected , but no field work done ; or something else ?"
133158,"can you clarify what you mean by "" we want to do this in constant time "" ?"
133329,i cannot find the claims you cite . could you identify where in the paper the 6 % / 2 % differential is discussed ?
133237,"you need to decide * on the basis of your psychological knowledge * how you would quantify a "" strong "" motivator . for instance , if all the respondents answer $ -1 $ , would that be the strongest possible motivator or the weakest possible ?"
133154,""" the 4 and 2 subjects in sections a and b are drawn without replacement from the n possible subjects . no subject appears in both sections simultaneously . "" -- hang on -- since the first sentence there precludes a subject being repeated within a section and the second sentence precludes a repeat across sections , isn't that just the same as saying "" the six subjects across the six questions on the exam are chosen without replacement "" ?"
133620,"could you elaborate on what you mean by the "" 2-d interaction case "" ?"
133764,"you will be , as they say , cursed by the dimensionality . in six dimensions you can cut each dimension into fewer than three classes on average ( because even $ 3 ^ 6 gt 300 $ ) --and , of course , with effectively just one class for any additional dimensions . for most applications this will be too crude . your only hope is that the data follow a multivariate functional form that has a very parsimonious description . is there any possibility of that ?"
133796,"what do you mean by "" r3 "" , "" r2 "" , "" r1 "" , "" r0 "" , "" j1 "" , and "" j0 "" ?"
133977,are you familiar with conditional probabilities ?
133703,no doubt you are aware of the pitfalls here . absence of evidence of difference is not evidence of absence of difference . not clear what anybody can add to this unless they have found any differences in results themselves ; the code is manifestly not public . have you asked microsoft ?
133356,"the decision on how to analyze your data will involve judgement about how the variables are operating : what relationships may be reasonably thought to be operating or not , and which may be ignored by the analysis . do you want to tell us more or do you want us to stick to your hypothetical example ?"
134379,is it at all possible that the variances are exactly equal ?
134727,""" * i would like to be able to test whether individuals were significantly more likely to turn in the direction of the speaker * "" -- individuals more likely . . . than what ?"
134888,"yes , a little more information would be helpful . do you plan to use both your pre and post scores in evaluating the impact of age , etc ?"
135209,"can you clarify what you mean by "" averaged each behaviour for a period of time before and after an event "" ?"
135343,how exactly are the elements of $ s_2 backslash s_1 $ sampled from $ s_3 backslash s_1 $ ?
68090,"what do you mean exactly by "" whitening "" ?"
136424,possible duplicate of [ why does the lasso provide variable selection ?
136744,are you seeking a conjugate prior or are you just after general advice about formulating your prior information into a prior distribution ?
136747,can you show the confusion matrix ?
136832,do you have any way of knowing how many data are represented by each box ?
137430,this is a really * really * basic question on the mathematics of pca . have you studied any textbooks or tutorials on pca ?
136831,a few weeks ago i took my shot at answering this question--or at least one remarkably like it--at url isn't that thread a duplicate of this one ?
137967,"hirek "" stationary . . . with a tiny trend "" ; would you talk about "" stationary with a large trend "" ?"
137975,we can't see the series . what is this plot supposed to tell you about nonstationarity ?
138069,what do you find to be _substandard_ about the problem ?
138429,why do you feel you need to transform the response based on its distribution ?
136384,"this is not a linear model , what you want is really a multiplicative model . you could perhaps use a glm ( generalized linear model ) with log link function . then your extra multiplicative parameyter will be an extra game / sports ( ?"
137935,"there are good ways to run this test . i can guarantee that if you are located near london , have any competitors , and have more than a tiny amount of data , then you will find there is "" significant "" variation--people will have a greater tendency to come from nearby locations and locations with no nearby competitor . the proper response to such an obvious conclusion should be "" so what ?"
17028,is $ pm 0 . 67448975 $ any more useful ?
139392,"if it has a max value then it isn't exponentially distributed . so you need to explain what you mean by "" random exponential distributed x data between zero and a max value "" . do you mean that a histogram of your data should resemble the exponential pdf but cut off ( truncated ) at the max value ?"
139673,"in addition to having data about the symptoms exhibited , do you have any data about the actual severity ?"
140017,"note that asking about how to use sas is off-topic here , but this may be a statistical ( not software ) question . in light of gavinsimpson's points , can you clarify what you are asking about & maybe paste in whatever context is required for the q to stand on its own ?"
139490,"andyw , given that the on-topic portion of this question is the name of the analysis & some references , why not develop your comment into an official answer ?"
140727,"hm , doesn't it follow immediately from the last paragraph that $ x_4 = 1 $ ?"
141375,why tag with ` non-independent ` rather than ` dependence ` ?
141512,"strongbad well , i'm not sure . i cast the vote , but i'm open to discussion ( that's also why i made the comment above ) . i also think it is a good question . and you certainly have a point that many people need it , but at the same time , the same is true for "" presenting any statistical analysis "" , so should we accept such questions ?"
141521,"there are many books entirely about introductions to forecasting , so your question would have to be ( a ) new to this forum ( have you looked for threads on forecasting ?"
138901,hazard ratios are ratios which apply to the hazard rate . hazard rate is a bit difficult to explain in a single comment but the wikipedia page for survival analysis will hopefully help . if the hazard ratio is less than 1 there is longer predicted survival . what is your typical followup ?
142157,so the differences between spss and stata are for when the negative binomial dispersion term is set to 1 ?
142931,well where do you get stuck ?
142902,it is * very * curious that the vast majority of responses are actually whole numbers and not half-integers . this suggests that the responses are favoring whole numbers . could you say more about what these responses are and help us understand this very strange behavior ?
142981,"re "" the signal processing community ignores subtracting mean and dividing by standard-deviation . "" could you provide a reference or two for this ?"
143003,it may be better to describe your data in some more detail . how many percentages are there from one hospital or is there only one ?
143361,could you elaborate a bit ?
143769,why are you testing normality ?
141704,the [ encyclopedia of statistical sciences ] ( url ) ?
144034,in what way are the results not satisfactory ?
144170,what do you mean by advanced ?
144268,df ( x ) = f' ( x ) dx = f ( x ) dx where f is cdf and f is the pdf . that's a calculus shorthand . does that make more sense now ?
144410,"could you explain the purpose of this "" noise "" and what it represents ?"
144968,"your question is unclear . if you're trying to compare two things , won't you need samples from both ?"
145026,can you clarify your question ?
145084,"what are the possible orderings of u1 , u2 , u3 ?"
145390,""" i am given 4 situations "" . from whom ?"
145622,on what basis would you give equal proportions to each of the original groups ?
145723,there are many ways to handle multicollinearity without having to sacrifice interpretability ( as you correctly stated in your post ) . what is your outcome variable of interest ?
145758,"this is a general comment ( and perhaps not helpful ) , but did you consider sampling from uniform ( 0 , 1 ) and using an inverse probability integral transform ( like [ here ] ( url ) ) ?"
146440,one mentioned [ here ] ( url ) or [ here ] ( url ) ?
146705,please provide more context . better is subjective . what are you trying to show ?
146860,"you should not normally dichotomize ( or otherwise group ) continuous data . when you say you binned it , did you also average $ x $ , or was it only the ages that were grouped ?"
147142,"this stupid app won't let me post a comment , so this will go in the answer section . could you be more specific ?"
147334,"that seems very strange , how long is it running ?"
142627,"this may just be due to randomness in the model-fitting process . if you run your experiment again with a different random seed , do you observe the same effect ?"
146212,"when you say your $ p_x $ were "" trained on the data with $ y $ marginalized out "" , do you mean $ p_x = left ( sum_ { y in y } s_ { x , y } right ) / left ( sum_ { y in y } t_ { x , y } right ) $ ?"
147830,"do you want to perform a hypothesis test / are you hoping for a p-value , or do you just want a meaningful way to compare how similar they are ?"
146969,"no one but you has your data and code , so we can't replicate your problem . you don't say what the error / problem is : "" model does not work "" is very vague . how can you expect anyone to diagnose what's going wrong from this limited information ?"
148636,"it is * not * true that your data has to be always and exactly normally distributed for parametric tests , see : url and if you really need to transform you data , box-cox is the simple and commonly used approach url but to provide the precise answer you have to tell what is your data and what do you want to do with it ?"
149017,"question : your measurement can only have 3 outcomes , but what about the variable you want to measure : is it continuous or discrete ?"
149816,"you must specify what you want us to help you with . questions like "" solve this for me "" will likely be closed , and you should also use the self-study tag . apart from that , it seems pretty straight-forward to me . in ( i ) you are given the equation to use , ( ii ) follows from ( i ) . ( iii ) may be tricky to parse , but once you get it it is also straight-forward ; is this the one you are having problems with ?"
149827,"i'm guessing ( but i don't know this package ) that the genes are supposed to be the columns and so are supposed to be measured on the same population , hence the same number of rows ?"
151083,"what should $ n $ be in your formula "" $ 2 ^ n $ "" ?"
151111,"what are "" normal "" variables ?"
149904,"i'm afraid i haven't completely answered your question . the chi-squared test will tell only you if there "" was a difference across items . "" do you know the total number of customers shown color a and color b ?"
151315,"there is no inherent connection between such matrices and entropy , so any answer would have to depend on what exactly $ a $ represents . could you edit your question to elaborate on this ?"
151837,i suspect $ s_n = sum_i ^ n x_i $ for some r . v . s $ x_i $ ?
152489,what exactly are you using em for ?
82466,that is a very good question . have you tried a few simulations to see how different the results would be from standard lasso if you one tried it your way ?
152598,"the term "" model error bars "" is ambiguous ; and further , when you say $ pm $ 1 standard deviation , it's not clear what standard deviation you're after ( standard deviation of what , exactly ?"
152735,for the continuous treatment you also have a observations that have zero treatment intensity or is everyone affected to some degree ?
153042,have you though about using already existing packages ?
153259,there are several theorems in this statement : ( 1 ) real symmetric matrices have eigenvalues ; ( 2 ) they are all real ; ( 3 ) the eigenspaces are orthogonal ; ( 4 ) $ x ^ prime bx / x ^ prime x $ is maximized with value $ lambda_1 $ when $ x = e_1 $ . which one are you asking about ?
153028,could you be even more specific as to what the two models are and what methods you use to estimate each of the models ?
154018,1 if initially zero and 0 otherwise : what's the problem ?
153368,can you clarify your research question and what you believe will happen ?
154650,"what an "" outlier "" means on this context . . . is this a time series ?"
155069,"for a given time period , do you know the number of potential hidden states ?"
155209,"could you explain why you must use some kind of regression procedure to perform a calculation that you can already do by other reasonably simple means , as you have shown ?"
155257,"* * what is "" $ n $ "" ?"
155392,"you might want to clarify this a bit , you first state that you know the parameters , and you don't have an estimate . since you know the parameters you already know if they are the same or not , so why are you doing a test ?"
155630,you would have to do a lot of digging into the ` rms ` package ` validate . * ` and ` calibrate . * ` functions and especially its ` predab . resample ` function . you would also have to write an ` rms ` wrapper for the main fitting function . do you feel that fractional polynomials have an advantage here and are you always analyzing variables that cannot be zero or negative ?
155790,"quite honestly and with all due respect , it's apparent that your questionnaire design skills aren't that technically strong . are you a student ?"
155939,did you try any examples ?
156566,1 . but i am wondering what is so bad about distributions without density functions ?
7049,"how do your empirical distributions differ from gamma variates , then ?"
156717,what is your your statistical background and area of study ?
155606,""" make sense "" seems to be an issue of logic or of the field of study , but in any event it doesn't seem to be very well defined . could you edit this post to provide a little more detail concerning what you mean by this phrase and its connection with statistics ?"
156941,"can you say more about your situation , your data , & your goals ?"
156965,"the dependence , if any , between a and b is crucially important . if you don't understand why , you need to learn the basics of 1st semester undergrad probability theory . do you even understand what joint distribution and joint pdf are ?"
157262,are you asking about using the existing algorithm for nmf or about developing your own algorithm ?
157376,why do these variables need to have normal distributions ?
157374,"this kind of problem indeed is of interest here . to address it , one needs data about actual matches and mismatches . if all you have is the database and no independent information about identity of individuals , then what would there be to distinguish any solution from pure guesswork ?"
157361,"are you trying to figure out the average distance between blocks , or the proportion of you file not taken up by blocks ?"
157380,"there are some standard ways to do this , including maximum likelihood and regression on order statistics . but if by "" left "" you mean the * lower * five percent , then you should be concerned about the potential for enormous standard errors . do you have a very large dataset ?"
157569,what statistical detecton methods do you have in mind ?
109550,"i don't understand . are you asking if we should be concerned if the model overfit in general , or if the estimate of the missing values "" overfit "" ?"
157494,what definition of a [ multivariate median ] ( url ) do you have in mind ?
157659,"i have never heard the expression "" cumulative density "" . can you show an example where it is used ?"
157872,"rmse is relative measure , i . e . it is expressed in the scale of your variable ( see e . g . [ here ] ( url ) ) . so there is no "" objectively small "" value for rmse , it depends on your data . so you have to tell us * why * do you consider this value to be "" too small "" ?"
158380,"can you provide more information , or a simple example ?"
157979,why would the existence of variance imply that the distribution ( by which i assume you actually mean density or pmf ) falls off exponentially ?
158280,"dear user80489 , i think it would help if you provided some specific detail about your problem . what kind of question are you trying to answer ?"
158959,what exactly do you have in mind ?
158705,"well , does it mean that for the first run , the random forest is used for a classification problem while for the second run for a regression problem ?"
159098,"your question mentions "" the four types of skew "" . . . but then gives a link and launches into a bunch of code ( which language you don't even mention ) . so people don't have to read a link to discover what you're asking , and for the benefit of the people who don't read r , and those who find reading code unhelpful in conveying understanding , it would help to define which four measures of skewness you mean before ( or preferably instead of ) a swathe of code . [ when you say "" the four "" , rather than say "" these four "" , why do you think there are exactly four rather than five or seven or some other number ?"
159796,"try the most basic thing . use a 1-nn , manhatten distance , and apply a 10 fold cross validation regarding both , the weighted and the regular nn . by the way which kind of weights are you applying on the features ?"
160180,"it seems to me your data have * all * the characteristics you mention : integers certainly are numeric ; they can be ordered ( making them ordinal ) , and they can be used as discrete attributes ( making them nominal ) . instead of a having a problem , it would seem you have the opposite : you could use practically any method you think might work . why , then , are you stuck ?"
160256,"i wonder what you mean by "" dispersion "" : is it a running estimate of a measure of dispersion , like standard deviation , or could it be the * actual data * ?"
161024,"if $ y_i $ is unknown ( as you state ) , how could you even compute $ y_i' $ ?"
78596,say i have 2 independent samples from the same population ( let's say we have a one sample t-test ) . imagine the sample mean and standard deviations are just about the same . so the p-value for the first sample is 0 . 0666 and for the second sample is 0 . 0668 . what should the overall p-value be ?
161624,"because these equations are nonlinear , it is unlikely the solutions form a vector space ( and in fact they do not ) . this kind of problem , as you have posed it , is beyond ` r ` and its full solution requires some knowledge of algebraic computation ( and some preliminary manipulation to put the equations in a more amenable form ) . however , your question hints that the problem was originally motivated by some kind of statistical analysis . could you say something about the data and your objectives ?"
160720,"could you please explain what you mean by "" both correlation coefficients are equal across subjects "" ?"
163017,why do you want to consider the interaction ?
162622,is the positive-definite matrix well-conditioned ?
163160,couldn't you simply split your observations into deciles and then add some noise to each iq by generating a normal random variable and add the value to the iq score or am i missing something here ?
163357,perhaps proportional change is not a good metric . could you tell us why you want to compute this and how you intend to interpret it ?
163404,are the $ y_i $ 's independent of the $ x_i $ 's ?
163560,"ssdecontrol it looks like the ` predict ` method takes an ` n . iter ` argument for how many weak classifiers to use in the scoring . could you not fit the model with a large number of iterations , but then use the ` n . iter ` argument to ` predict ` to evaluate the performance at various numbers of iterations ?"
163496,"any legitimate , objective answer to this question * must * be based on an understanding of how those "" relocations "" occurred and how the data were collected . could you explain what a relocation is and how the points in the datasets were obtained or measured ?"
163728,can you give us the density of the multivariate laplace distribution ?
163758,"1 the answer doesn't make sense to me , either . the conditions are impossible . are you sure you are quoting the question * verbatim * ?"
163748,"( 1 ) you mention an "" interaction "" : does this mean you have other independent variables ?"
163860,is it a homework ?
164256,"something isn't right here . you said that you have two ordinal values on a 5 point scale such as "" do you like chocolate . "" the answer to this question should be "" yes "" or "" no "" not an indication of agreement , so why are you having to recode data into yes / no ?"
164314,what do you mean by 'between performance means for the respective levels of performance' ?
164524,are you speaking of the anova type context or the context of information-losing binning of continuous variables ?
164600,we need to know more about your problem . what are you trying to do ?
164859,"what do you mean , precisely , when you say $ r ^ 2 $ is an * empirical * quantity ?"
164968,""" better "" depends on your objective . the meaning of "" average "" does , too , because there are many kinds of averages . what do you want this average to represent ?"
164976,do the four methods estimate a different parameter ?
164817,"hamed , would you mind taking a look at [ this question ] ( url ) ?"
165068,"google "" complete separation "" and "" hauck-donner effect "" ?"
165133,have you considered clustering ?
166279,could you please show how you arrive at it being chi-square ?
167094,the kruskal-wallis test is a fine choice if your data aren't normal ; the anova would be more suspect . can you say more about what your data actually are ?
167221,are the firms independent from each other . ie is there a state effect ?
167913,could you point out where you are manually computing a * weighted * $ r ^ 2 $ ?
168054,"it is hard to determine what your notation means , since "" $ * $ "" and "" $ pm $ "" are employed in unusual ways . could you explain the sense in which "" $ z = a * b * c $ "" is a "" model "" and what your formula for $ epsilon $ means ?"
168763,why is logit not a regression ?
169433,how frequent are the scans ?
169759,"this only off the top of my head , but i think you could essentially figure out what the raw data was from a given kaplan meier curve ?"
169694,"this question needs more context to be answerable . you might just as well ask "" how to know in advance that a variable $ y $ will be normal ?"
169784,optimal in what sense ?
170021,was there a particular reason you used bootstrapping for this ?
171538,"` i'm sure z-normalization is a bad idea , since it normalizes the variances to 1 for each feature , pca will be meaningless since it will randomly select the most varying features . right ?"
171655,what do you need to do with the data ?
172167,maybe a log scale instead of a sqrt using ` scale_y_log10 ( ) ` in ` ggplot ` ?
172152,are those really ranks ?
172244,"jona , i'm not trying to be rude , but terminology and notation are important in math , especially when conveying ideas to others . a sum is one number , therefore discussing the average of a sum does not make sense . dividing a sum by the number of elements being summed gives you the average of the terms in the sum . when i asked what the sum was over , i meant out of all of these indices , which ones are actually changing in the sum . is the first sum $ x_ { 1 , k } x_ { 2 , k } dots $ ?"
171932,did you compute the auc 'in sample' ( i . e on the same data you used for estimating the logistic regression ) of 'out-of-sample' ( on other data than the data you used for estimating ) ?
172442,it is usually the case that questions of growth concern * positive * variables $ y_i $ . is that true here ?
172202,why wouldn't you want to have a single quarterly change in 5 year treasury rate column and then a second indicator variable with 0 = pre-greenspan and 1 = greenspan ?
172396,"ar and ma orders of 24 look pretty high . perhaps you should reduce the ar and ma orders and use some seasonal dummies or fourier terms instead , or a seasonal arima model . how much data do you have ?"
172891,can you add more details about what you did and how you interpret the results ?
172944,"your accuracy seems to be . 999 , is that so terrible ?"
173210,rnyi divergence ?
173293,"do you mean that the data * are * paired , but that you don't have the id information needed to account for the pairing in the model , or that the data never were paired in the first place ?"
172853,your title refers to 'multiple regression' but your body text to 'multivariate regression' . when you say 'multivariate' ; are you talking about multiple responses ( dvs ) or multiple predictors ( ivs ) ?
173422,are you perhaps referring to a ( bayes ) * prior * distribution ?
32370,"the only possible correct answer to this question as * generally * posed is "" practically any distribution . "" this is because the diagram is a tool to compare two * arbitrary * distributions : "" observations "" and the "" model ensemble . "" they could differ in literally any fashion . by asking such a question , then , you appear to presuppose some kind of connection between the model and the observations . this is a fair assumption , but the nature of the connection depends on the kind of model and what it models . so : what kind of model and what kinds of observations do you have in mind ?"
173903,"most likely the answer is the student t distribution . however , details matter . could you explain what an "" alpha-interval "" is and describe the data you are using to compute them ?"
174732,""" confidence interval for a p-value "" is a contradiction in terms . confidence intervals apply to * parameter estimates * , but a p-value most decidedly does not estimate any parameter . one proof of this is to observe that a p-value depends on sample size , whereas a parameter's value does not . are you possibly asking for a confidence interval on the * monte carlo estimate * of a p-value ?"
175196,your title and question are confusing ! x is normal or x is log normal ?
175376,"uncertainty is in general not the same as error in measurement . i think you mean to ask which variables are random , right ?"
175708,"the question as framed is unsolvable , because the objective function is ( a ) a global function of the path and ( b ) potentially arbitrarily sensitive to any single value of any single cell at any time . i wonder whether this is even a useful formulation of your objective . why shouldn't the robot keep updating its weights as it goes along , * even for the cells through which it has already passed * ?"
175904,"can you please provide the ( or your ) definition of "" independence in the true sense of the word "" ?"
175983,"the question you were asked sounds like they're confused . but anyway , the documentation for ` lm ` directly tells you it fits linear models , right in the heading it says : "" fitting linear models "" . so linear , not "" nonlinear "" . the documentation for ` lm . fit ` tells you the algorithm it uses : . . . "" ` . lm . fit ( ) ` is bare bone wrapper to the innermost qr-based c code "" . so it uses qr decomposition to calculate the least squares fit ; it mentions the qr decomposition several times later in describing what's returned . what documentation did you read ?"
175962,you use missing data methods because you think they will give different results . you shouldn't be surprised you're getting different results - but you're not giving us much information . are the parameter estimates changing ?
176578,"what do you mean by "" the point where they are needed varies "" ?"
176353,"muhammad , please post your image on imgur . com and post a link here in a comment . if it is a pdf file , post in anywhere you want ( dropbox ?"
177052,"orthogonal point : does "" normalise "" mean scale in some way , e . g . ( value $ - $ location ) / scale , or does it mean make closer to normal ( gaussian ) ?"
177238,please post that in a form that can be copied and pasted into people's favourite software . are the rows and columns already in an order that makes substantive sense ?
178708,"one thing one can do is bag the variables a la rf . this is what i would call standard variable importance . this would certainly give one ( at least ) hints . secondly , i'm curious as to the why ?"
178662,"the question is a little vague at present . they certainly won't be independent in general ( of course ) ; if $ x $ is a continuous r . v . , the bivariate distribution of $ x , x ^ 2 $ will lie on a curve . you may want to consider $ x 0 $ separately from $ x geq 0 $ . can you say what the situtation is you're dealing with ?"
179088,em . . . are you consider doing a [ partial correlation analysis ] ( url ) first ?
179454,"unless you are careful about the meaning of "" $ s ^ 2 $ "" , or include more than a quantile of $ t_2 $ in "" some statistics , "" this formula could be terribly wrong . could you provide the specific formula you have in mind ?"
179527,it's not clear what the difficulty is here . are you concerned about calculating the distribution of the test statistic under the composite null or about some other issue ?
179435,"i do not understand where the problem lies and so i suspect i might be misreading the description of what you have done . if you're doing logistic regression , then the transformed data must be among the regressors , not the responses . because ( by definition ) a complex number is an ordered pair of real numbers , any complex regressor is just two real regressors . if a procedure ( such as ` glm ` ) doesn't like that , just feed it the real parts and imaginary parts separately . where is the difficulty ?"
179403,"do you know ahead of time which points "" belong "" to the red line ?"
179983,"how are you defining "" active ?"
179919,` 20 factors corresponding to 4 constructs ` what is that ?
180103,"i edited my comment ( again ) . maybe it's clearer now . also , how is error function related to all this ?"
180459,"the notations are unclear : is $ h $ a set of integers $ { 1 , 2 , . . , k } $ that label models under comparison ?"
180429,"this might be a stupid comment , but i'm a little bit confused by the notation . what does the $ e ^ { 1 / 2 } $ mean ?"
180584,i don't understand the question . how do you go from your 3 percentages to the two numbers between -1 and 1 ?
180457,what kind of data are you talking about ?
180979,"they are correct . each dog has a 40 % chance of being cured , and you've taken 12 samples . can you re-cast this as a coin flipping experiment ?"
181074,"actually , if it's just a function of two variables , why not just fit a gaussian process ?"
180413,"just to clarify "" i do not know which datapoints were recorded together "" : you have sequences of ( let's say ) $ x_i $ , $ y_i $ , and $ z_i $ which have been separately permuted , so you do not know which corresponds to which - for instance it is possible that $ x_ { 13 } $ , $ y_ { 224 } $ , and $ z_ { 129 } $ were all from the same data point originally ?"
181250,"this sounds like a question better directed to your thesis advisor . that said , do i imagine that changing the number of scale points used by a psychometric instrument would destroy the validity of the construct being measured ?"
182188,can you give an example of such a probability density function ?
182657,is this a question from a course or textbook ?
183245,"your "" price b "" series includes a lot of negative values . how are "" prices "" * negative * ?"
183339,i'm not sure what an analysis of the overall change in scores would tell you . how many likert items are there and how many subjects ?
183802,"is this the same question you were trying to ask before , or a different one ?"
184121,do you have any possible guesses as to the population variance ?
184361,hint : what happens when $ x $ can be less than $ - sqrt { a } $ ?
185502,how do you initialize the kmeans ?
186332,does mplus have a sem manual ?
186438,"what do you mean by , "" a p-value that is larger than the confidence interval "" ?"
26903,"mike , i think it would be very interesting to see the plot that you are looking at . would you mind editing your answer to include it ?"
187426,"so you didn't use the data from the ` c ` test , pre or post ?"
187688,"not a complete answer , but glancing through : it is * * not * * necessarily true that conditional variance is less than unconditional variance . perhaps this is where your mistake lies ?"
187965,"i think you need more information , and based on that to make a model of your problem . what are the "" experiments "" ?"
188022,what is $ n $ meant to stand for ?
185096,would you reveal which book this is from ?
188501,how are you defining accuracy ?
188493,could you quote or direct us to some source that claims correlograms are tools for detecting non-stationarity ?
188868,"what is the interval in your time series ( is it two observations measured each year , 24 measured monthly , 52 * 2 weekly etc . ) ?"
189309,could you add a simulated example ?
188683,"1 . what do you mean precisely by "" confidence level "" of a stratum ?"
189986,what is unclear for you ?
190277,"for count data it would seem logical to describe the data through some count distribution ( e . g . negative binomial or poisson ) and to have some regression model to take into account any known explanatory factors ( e . g . duration of observation as an offset , vegetation , cover , food sources etc . ) . are you interested in whether the count for species a is different between locations , separately whether the count for species b is different etc . or whether all species differ between locations in the same / similar manner ?"
189846,are you talking about sampling from an observed dataset - i . e . you have some sort of test scores for individual people and select n1 groups from the whole dataset and then n2 groups from a subset of the whole dataset ( your subpopulation ) where n1 = n2 . you then compute maybe the mean score for each group so you want to compare the distribution of the n1 whole population means to the n2 subpopulation means ?
190856,"could you explain the distinction between "" number of questionnaires "" and "" sample size "" ?"
191399,"$ y $ is just the argument of the function and there's no reason to give it another name midway through a calculation . if $ f_x ( x ) $ is just defined to equal $ y $ , haven't you concluded $ f_y ( y ) = y $ as desired ?"
186051,"this has no closed-form analytical expression . please , then , indicate more precisely * how * you would like to "" find "" the density function . btw , what is the reason for omitting $ v $ ( evidently some kind of a dispersion parameter ) from the arguments of $ f $ ?"
191734,"the allusion is to the _iris_ data ( e . g . url ) as far as i can see , the categorical distribution is that there are 50 values of each category , so frequencies are ( 50 , 50 , 50 ) and probabilities 1 / 3 each . any decent program will have ways to give you a table and / or to save the frequencies in a vector or variable . is that what you want ?"
191493,"that doesn't seem ideal . do you also have covariates you want to control for ( eg , the actual grade the child was in ) ?"
191827,what is the precise question that you're trying to ask ( mainly what is the predictor since i assume species abundance is the response variable ) ?
191375,some hints : word2vec is not a single algorithm . so is moody referring to the skip-gram or cbow model ?
192080,glen_b : i see your point with predicting the mean and i agree with you on that . but the op' s question was whether he could use ols and if you advise glm then implicitly you also say that ols is not ok in the first case or do i see it wrong ?
192411,what would it mean to test all the occupations from a single state ?
192404,"can you post your ( i guess ) ` lmer ` code lines , just out of curiosity ?"
192567,"a ` self-study ` tag seems in order , no ?"
192926,your question also seems to be somewhat unclear . is there missing context ?
161426,"do you mean taking a binary 0 , 1 indicator and passing it through the logit function $ log ( p / ( 1-p ) ) $ ?"
193374,"because the answer depends on what the coordinates mean and why you're doing this fit , could you edit this question to include that contextual information ?"
194601,how many levels are in ` w ` ?
194979,"the bradley-terry model is , perhaps , the most canonical one . there are whole texts written on models for "" paired comparisons "" . note the naivety of the properties you list . suppose a and b have played once and a beat b . is it sensible to then predict that a's probability of beating b is 100 % ?"
195193,how do you define 'chance' for gene interaction ?
196707,"you need to add the [ self-study ] tag ( as this sounds very much like a homework problem ) and indicate what you've tried . i also think you need to make the details clearer . are these individuals selected at the same time or do you select one draw , then a second , then a third ?"
85970,was that to rank the same 8 items with all the firms ?
195514,growth rate in what ?
197119,read your math carefully . it is not possible for $ sum_ { i = 1 } ^ infty phi ^ 2 $ to have _finite_ value unless $ phi = 0 $ . are you sure you didn't mean to write $ sum_ { i geq 1 } phi_i ^ 2 infty $ ?
197937,could you explain what fitting a burr distribution to your data has to do with a zero-inflated poisson distribution ?
198734,why not just interpolate the populations smartly ?
198821,can you clarify what you mean by test your model fit here ?
198655,"can you clarify what you mean by "" explain "" ?"
199418,"the truth of this statement depends on what you mean by "" left-skewed "" : please give us the definition you have in mind . when you do that , tell us how $ f $ is connected with $ x $ . are you perhaps assuming $ x $ is a * continuous * random variable with pdf $ f $ ?"
199415,have you at least checked the wikipedia sites for these tests ?
199443,"this might be an interesting and rather unusual question if you provide more detail . first , why cumulative , if what you are intersted in is the frequency and number of events per 'cluster' ( or else give more detail on the design ) . how many observations of response variable / yr / temporal cluster ?"
199661,"weighing is used to decrease the leverage of a certain point which would be having very high influence on the response curve / variable . unless the points you mentioned here are outliers , which they aren't , why do you think they should be weighed any differently ?"
199607,"kane , when you say that your data "" is 8 factors and 25 samples "" , you mean that there is 8 measured variables ?"
194993,"are ` alive ` , ` damaged ` , & ` dead ` ordered ?"
200281,"how can $ mu $ be a random variable , while $ theta $ is not , if they are both functions of $ a $ and $ b $ ?"
201027,"whuber then you would need to be more than usually careful about the arbitrary signs of the results , would you not ?"
201645,"i don't think we can meaningfully answer this without knowing what hypothesis you are testing . for many hypotheses , the multimodality would have no effect on the test . for example , $ h_0 : x-y = 0 $ vs . $ h_1 : x-y 0 $ . what difference does it make if x or y are multimodal ?"
202045,percentages have meaning only when components contribute * additively * to a whole . that is not the case for rmse . could you explain what you are hoping percentage-like numbers would accomplish ?
201976,"can you give more details , in the language of the application ?"
202314,without details about what explanatory variables you have and what you try to model it is not so easy to suggest something ?
22230,is this an homework ?
202727,""" mean and variance "" of what , exactly ?"
202896,does the ols estimator perhaps drop a * different * variable ?
202952,"how would you run $ k $ folds on the test split ( step 4 ) , given that there is only one such split and you already have a model trained on the full train split ( based on the current description ) ?"
202978,asking for help with code is off topic here . this presumably belongs on either [ so ] or the [ codereview . se ] site . ( you might decide which you prefer and flag this for migration . ) what language is this anyway ?
203063,have you read this one ?
203340,"what do you mean when you write "" bayesians only reply beliefs "" ?"
203322,what do you want to test ?
203474,why not just calculate the pairwise sample correlations directly ?
203749,"your description is a bit confusing . a [ distribution ] ( url ) doesn't have an $ n $ . are you using the word distribution to refer to a [ sample ] ( url ) , or to the length of a sequence of values where the density has been estimated , or something else ?"
203974,could you elaborate ?
203793,"comparing evaluations to neighborhood quality appears to be a form of * regression * model , not a clustering calculation . this makes one wonder what you are really trying to accomplish . could you clarify ?"
203747,what's the business objective here ?
204029,what is the confidence interval that you've learned ?
204578,"whuber naturally i agree . indeed , how does the gaussian arise ?"
204585,"what you are saying makes sense . you are using the central limit theorem to assume normality in the distribution of the sample means . also , you are using the t-test because you don't have the population variance , and you are estimating it based on the sample variance . but can you link or post any of these conflicting sources ?"
204837,"could you explain what you think your "" population "" is ?"
204911,"first , you need to decide what you are trying to minimize the variance of . once you do that , then any clustering algorithm ( e . g . , k-means ) should get you what you need . what clustering approach did you use and on what variable ?"
204930,but do you have spacial imagination that can take over the vision ?
203896,"i don't understand what you mean by "" the math part "" . what mathematical thing are you after ?"
205305,what sort of alternatives did you have in mind ?
205959,"if it's invertible , you can augment a with an identity matrix and then put a into row reduced echelon form though gaussian elimination applying each operation to the augmented matrix . once in reduced echelon form , the identity matrix will be the inverse . you can use lu decomposition too . your question is confusing . are you trying to find the inverse or the transpose or both ?"
206475,what is your actual goal ?
206192,""" how does r . . . "" is very software specific and not generally on-topic here ( see our [ help / on-topic ] ) , you are usually best to ask the people who make the software or in a software-specific forum . having said that , for r you can just look directly at the source code to see what it is doing . do you want to know specifically how the r functions work , or are you interested in ma fitting in general ?"
206649,what do you mean by correlated ?
206672,"i don't see that the correlation has to tend to 1 . if you were correlating the * total * score w / the other assignments , yes , but not if you are correlating the new score with the other assignments . do you want to include the weighting of the different assignments ( thus assuming it is correct ) , or check if the weighting is reasonable , or ignore it ?"
206706,can you explain these data a bit more ?
206146,"it might be wise to re-examine the calculation . its most problematic feature is that the cells represent radically varying amounts of the earth's surface : some are hundreds of times larger than others . this calls into question the scientific meaningfulness of these averages . if they aren't meaningful , then what good will standard deviations be ?"
206631,what is mean centred variable ?
206782,what code are you using to run the logistic regression ?
207069,why don't try to predict how much time each horse is going to take to complete the race instead of which is going to win ?
207296,i am not aware of a dedicated name . why do you think that you need one ?
207353,why not draw a graph of the pdf so you can * see * the area you are trying to compute ?
207686,what do you mean ?
207822,where did these models come from ?
208050,"can you give us a screenshot of a couple of lines of your dataset * * * sorted * * * to show what you mean by "" nested observations "" and "" repeat observations that are not nested ?"
207954,"sorry that's a little unclear . you have two populations , one of which you have all of and the other of which you have only a sample ?"
199923,"this is similar to a component-wise metropolis hastings , where one sweep of the algorithm updates each component independently . why not just do that ?"
209199,this is unclear . are you asking for code ( in what language ) ?
209266,"why don't you tell us something about the original model and data , why "" you need "" to use log-log regression , and how the results will be used ?"
209285,"this seems to be a question from a course or textbook , particularly your very specific examples you want to see classified ?"
209302,does the answer to [ this question ] ( url ) cover what you want to know ?
209762,please edit the information in the comment into the question . do you get the same results using ols ?
207400,"just an idea , but would it be worthwhile to consider undertaking [ change point analysis ] ( url ) ?"
210598,where is the formula from ?
210802,what is your structural model ?
210999,what is your goal in the analysis and what is your data like ?
211318,"gung i think there is a concrete question here : "" how do i choose a method for fitting a sde to time series data ?"
211523,"if you found everything you want , then perhaps this question should be closed as a duplicate ?"
111331,i don't understand your comment at all . are you asking now a different question ?
211179,"first of all , how do you define "" gram matix "" ?"
211233,"ok , i understand what you mean now . how about controlling in an lme each proofreading behaviour for subject and item effect first individually and then using the residuals for your biplots ?"
212373,"could you explain why you think these data create "" problems "" for your results ?"
211081,you have added the tag meta-analysis . usually in meta-analysis one would weight by the inverse of the sampling variances of the estimate ( the thing you call val ) . is that what you want to do or do you not have them ?
212619,how does one generically set the derivatives to 0 for a function ?
213117,can you show us some of the variances you are supplying to the ( unnamed ) package in r which you are using ?
213273,"it's the * same * clustering each time , right ?"
213523,are you trying to model the proportion of admissions that are readmissions ?
213697,why would you incorporate the cost in the model at all ?
213604,could you give us more details about the questions ?
212441,are impulse responses really based on svar ?
214124,"i think you have it the wrong way round , surely the difference within is greater , slightly , than between ?"
212730,"if your classes a , b , and c have e . g . 100 samples each , for the a-vs-all , b-vs-all , and c-vs-all svm you would be able to use 100 positive and 200 negative samples each , right ?"
214215,"what about $ f ^ { -1 } ( u ) $ , where $ u $ is uniform ?"
214839,""" nonparametric "" is an adjective applied to methods of inference or sometimes to models , but not to data . these appear to be counts , why would you not use a parametric model that should be suitable for count data ?"
212587,do i understand you correctly : you already know what you want ( t-test ) and are asking how to do a t-test in r ?
215048,"the trimmed mean is not a parameter of a distribution , so the question arises : what are you trying to estimate with it ?"
215261,"can you say more about your situation , the variables , & your goals here ?"
215040,"could you explain what you mean by "" stable "" ?"
87399,""" by means of quadratic programming . "" * why ?"
44261,i am not sure if i understand the question correctly . do you know the [ confusion matrix and derived measures ] ( url ) ?
215948,"( 1 ) could you explain what a "" percentual increase "" is intended to represent , since ( apparently ) the data are some kind of abstract scores ?"
216047,"are you asking how to combine the sample size , mean , and standard deviation from the individual files to calculate the overall sample size , mean , and standard deviation of all the records combined ?"
216008,"welcome to cv and congratulations with such a nicely written first post . 1 . one thing is not clear to me : lda computations require inverting within-class covariance matrix which in your $ n p $ case is singular and hence cannot be inverted . so applying lda "" as is "" without any tricks is simply not possible . there are some tricks , but you don't mention any . what program of function are you using to compute lda ?"
219055,"among the numerical values you have supplied , what are the estimated parameters and what ( if any ) are the assumed constants ?"
219090,pls describe your data . so your response is a count of some events ( ?
219220,is the mean just a given ?
219251,"what do you mean that you "" want to compare the effect of treatment "" , given that there is only one treatment & everyone got it ?"
219519,1 to both mark's comment but if you need to provides bounds but you do not have * any a priori knowledge * then why not just set the bounds to plus-minus ( numerical ) infinity ?
219976,"is it safe to consider that , for a given string , the pairs you are investigating ( . _ . ) ( no smiley intended ) are independent from each others ?"
220157,how identical ?
220270,"to me , for a large dataset , measuring effect size seems more important than hypothesis testing for the kind of reasons you provide . you could do a bootstrap procedure to estimate confidence interval around your x_bar . but i see an other problem here . don't you have non independent data points ?"
220742,how come the black lines are different ?
148500,"have you looked into other algorithms than neural networks , like svm , regression trees etc . ?"
221255,do we * know * that the $ x_i $ are normally distributed ?
221459,"for each user , do you have true / false probability values , or just true / false decisions ?"
221654,it is unclear what do you mean . . . bic is something that you calculate per model . * not * per subject . it is used to compare models . why do you want to calculate it per subject ?
221700,are you looking for exactly collinear points or approximately collinear points ?
221607,do you have repeated ` c ` values per subject ?
222139,"do you really mean to imply , as suggested in the first paragraph , that statistics is wholly--and only--about * point processes * ?"
222058,"a ) what do you mean with "" feature which has maximum occurrence "" ?"
222418,"i can't see that this displayed measure will ever become negative . it will vary between 0 and 1 . so , how you are measuring change , which is the central issue here ?"
222448,this is a strange post . why are you involving a prior probability distribution in your calculations when the two parts of the question stipulate that $ h_0 $ is true or $ h_1 $ is true ?
222384,"are these coefficients from different models run on the same dataset , different subsets of the same dataset or different datasets entirely ?"
222759,can bootstrap help ?
222973,"what do you mean when you say "" multiple regression restricted to a single variable "" ?"
223516,why do you want to remove values to improve the fit of the line ?
223449,"what does "" characterize "" mean in this context ?"
224575,"the normal linear model uses an identity link ( - additive model ) while poisson regression is usually done with log-link ( - multiplicative model ) . so maybe it is all about "" additive "" vs . "" multiplicative "" . the distributional assumption is often not that relevant as one would think . what i don't get : are you really trying to optimize a model without doing some form of ( cross- ) validation ?"
225131,"theorem 4 part b is a well-known result , of which i was well aware and have often used . but it's still not clear to me how it applies to your situation . is each observation in a lower dimensional space than $ r ^ n $ , maybe not all even in the same dimension ?"
225282,what conditional are you interested in computing ?
225570,"what do you mean by "" average predicted score "" ?"
226554,but it seems that you have build-in optimization algorithm that works ?
226840,"1 . "" recommend "" $ neq $ "" prove "" . which is it ?"
226946,"does , in your case , repeated measure mean that you have measured ` a ` at different time points ( say , every 6 months over a period of 2 years ) ?"
227115,"could you include a plot of your data , preferably arranged by seasons ?"
228452,what about sparse gps ?
228344,"after writing that previous comment i have been thinking through what the claim means and i confess i'm stuck . could you elaborate on exactly * how * linear regression will "" give "" a classification error ?"
228976,can you say a little more about what your survey / data looks like ?
229340,i suppose you mean to say 'linearly' separable ?
229291,"since the negative binomial is discrete , a hdi won't have those exact percentiles . do you know the exact percentiles ?"
229506,"it's not clear how you might try to go about assessing inter-rater reliability using a box plot . are you thinking of generating one plot per measure / person being rated , with the box and whiskers representing the range of scores raters give ?"
229626,do you have discrete or continuous time models ?
229729,why not just a grouped or a faceted bar chart ?
229775,do you have any repeated measurements in your setup ?
229821,can you elaborate ?
230278,didn't you find anything when searching our site ?
230366,is this your situation ?
230466,"this question is somewhat unclear , it would be helpful to see what your graph actually looks like - is it some form of histogram ?"
231252,"it's generally ( outside very specific cases ) [ not sensible ] ( url ) to exclude the intercept . if the client forces you to do something like this it doesn't make sense to care about further statistical issues . in fact , if they know best how to do the statistical analysis , what is your role there ?"
231311,"just make sure i understand what you're doing : you're using both the attributes of the individuals , and the fitted parameters of the distribution of the same group of individuals as input to your nn ?"
231325,"could you explain what a "" fake item "" might be ?"
231509,what happens when the robot serves more than one drink while the customer is in the bar ?
231745,"so , there's one row per event with each field or column capturing the sequential time of the event ?"
229443,if i understand icc correctly you could get a high value even if one was systematically higher than the other by a small amount compared to the differences between pairs . does that matter to you in your application as you say you want to use one as a surrogate for the other ?
232497,"i don't think the question title and title contents are well matched . if the question is "" is it a good idea just to use those data i think are relevant to my problem ?"
232527,one object from each class ?
232557,"if you already feel the distributions are different but don't believe the results of a test that indicates otherwise , it's not clear why you're performing the test . also if you run tests until one rejects then your testing procedure loses much of its validity . in any event , what are the sample sizes involved ?"
232893,user1471980 try to read a bit more about how to interpret coefficients of a linear model . that 1 . 134e-05 is the increase of cpubusy for 1 unit increase in variable timeperiod . so the interpretation depends on the units of that variable . is it seconds maybe ?
232721,what makes you think the mean and standard deviation * should * be the same here ?
233238,are you speaking of some 2-factor or blocking design ?
233605,i'm trying to get a sense of what your data looks like . for each point of interest do you only have two bits of information : 1 ) distance from motorway ; 2 ) whether or not it's been burgled ?
233581,"to the best of my knowledge , you can either choose a proposal distribution and do metropolis-hastings or sample from the prior and follow the method of the approximate bayesian computation ( abc ) . but if there is only one parameter that needs to be sample , why not just use rejection sampling or importance sampling method ?"
233878,"i second whuber's advice . in particular , what does "" arbitrary covariance "" really mean in your case ?"
234084,"take a look at my code here : url under the comment "" # multinomial propensity . "" my sense is that yours is a data issue , not an r issue . if your dependent variable is numeric , are you certain your model needs to be multinomial ?"
234207,"i am not sure what you are asking . it sounds like it may be more "" what alternative coordinate systems for $ mathbb { r } ^ n $ are bijective ?"
234229,"when you say "" examples and exercises "" , are you thinking of textbook / math syle exercises ?"
231624,are you interested in the time to cancellation or only whether cancellation occurs within one year by the customer ?
234427,"what do you mean by "" validity "" here ?"
234451,"this isn't really clear . are you trying to figure out if , eg , some people run faster on tuesday mornings & others on wednesday afternoons ?"
234545,"do you have just a single dimension , or are you asking about manhattan distance ?"
234773,what level is your data broken down to ?
234542,"you say you want to see if they "" correctly guess "" , are you trying to assess the classification performance of a fitted model ?"
234845,"i'm not sure i understand your intended model . it sounds like your dependent variable is number of medical issues . your independent variables aren't clear to me-- how are you defining "" intervention of the medical staff "" ?"
235064,"in response to your update : say you are using kriging . in the simplest case , let us assume that your variogram is known and fixed . then given some placement of $ n $ sensors , you could compute a map of the kriging variance , and place sensor $ n 1 $ at the location with maximum variance . in your case , you could calibrate the variogram based on the ground truth . ( in a real case , you might consider placement of sensors to ensure a confident asessment of the variogram , e . g . based on the distribution of inter-sensor lag vectors . ) btw if these comments are useful ( ?"
235134,"dsaxton is right . i would like to add another * caveat * : any metric of "" closeness "" also ought to account for the dimension of the distribution family . for instance , the normal family requires two parameters , but the poisson only one , so the normal family is a little more "" flexible "" and therefore should be penalized a bit in the comparison . btw , how you frame and pursue your question really ought to account for * why * you are writing this code : what decisions or actions will be taken as a consequence of its output ?"
235154,why would you need to retain the original data ?
234434,did you try to sum the unscaled posterior numerically ?
235381,could you provide a reference ?
235791,"i would say that it's appropriate to build separate models when you have separate questions you'd like to answer , which cannot be addressed by a single model . why have you chosen to build two models rather than one model that uses gender as a predictor ?"
235468,"it's a bit unclear what you are asking here . when you say your variable is "" categorical "" that would suggest you have five categories not measured along a scale ( e . g . "" blue "" , "" red "" , "" yellow "" , "" green "" , "" purple "" ) which you have just-so-happened to label as numbers . asking for a 95 % ci for the increase in likelihood for a change from "" red "" to "" green "" is a question that makes sense - but in that case you would need more than two regression coefficients ( you'd need a regression coefficient for each dummy variable ) . i wonder whether you mean "" discrete "" instead of "" categorical "" ?"
236277,"whuber yes , i was sloppy . the links i gave explain it better . in areas i run into , the term "" factor "" would usually not be used for something like taylor's example , which always holds for any $ p ( x , y ) $ . it would normally be associated with conditional independence relationships , i believe ?"
236181,the autocorrelation appears to be rather weak and i would probably neglect it . do you have a reason to believe a substantial negative autocorrelation for a lag of 4 years ?
236121,why do you want to use $ x_k = sum ^ k_ { i = 1 } x_i $ rather then individual $ x_i $ 's ?
236607,"shall we presume that "" error term "" means * in the model * and is not the * residual * with respect to the ols fit ?"
237002,two issues come to mind : 1 ) what determines the data sampling ?
237466,"you could use a [ balance scale ] ( url ) , and a bunch of pennies . then flip the pennies , and put all heads on one side , all tails on the other ?"
237540,"the second approach ( geometric average ) is likely more appropriate , as noted by mdewey . what is the goal of the analysis ?"
237652,why did you put pca and svm tags here ?
238065,"about question 1 : i think it is better to use "" not statistically significant "" in interpreting p-values , instead of saying "" weak "" . if the relationship between an outcome and a predictor is not statistically significant , assuming that the model assumptions are not violated , it can be explained only in the specific context of research and this is why we are doing statistical analysis in the first place . how can someone come up with a proper explanation without having more information , specifically about the model ?"
238288,"if you can compute the mean of your samples , then why can't you also compute their covariance ?"
238405,could you be more specific ?
238404,is this 2 known to be the smallest possible or is it just that you don't see values below 2 ?
239453,"yes , they will be significant : the large counts and even larger variations among them make this obvious . you might find it more useful to explore specifically * how * these three distributions differ . why not begin by plotting them ?"
239566,what are you using these features for ?
239696,"i do not do [ cca ] ( url ) but going by wikipedia , it seems like the input is a set of variables $ x $ and $ y $ , from which you get 3 covariance matrices ( self-cov for each variable a cross-cov ) . are your matrices $ a $ and $ b $ covariance matrices or [ data matrices ] ( url ) ) ?"
239813,"i do not use tensorflow or really do nns , but skimming your code , that looked like the part most likely to create nans . can you do debugging in tensorflow / tensorboard ?"
239844,"what do you mean "" high recall "" when discussing document clustering ?"
239595,what are you doing to do with discrete distributions ?
240892,"while i also voted to close as a duplicate , i wonder if this question might best be kept open if it could be distinguished in some way . might we add the fact that this was interval data to the title , and clarify that we are asking whether one can use a qq plot for interval data in the same manner as we do for continuous data ?"
241439,have seen url or similar ?
241512,"ok , i'm confused what you're asking now . are you asking how to write a function which gives you a value from cumulative distribution function ( cdf ) for the [ f-distribution ] ( url ) for a given $ x $ and degrees of freedom $ v_1 $ and $ v_2 $ ?"
242079,"the winner obviously is the one with the greatest return . what , then , do you mean by "" statistically "" ?"
242403,"in what sense are there even "" curves "" here ?"
235550,"in logistic regression as described , how do you find an unbiased estimator of $ a_0 $ or $ a_1 $ ?"
243001,it is really tough to give you good advice based on such scant characterization . what are the three groups ?
243583,did you search for cholesky factorization method already ?
243721,"i think this is hard to answer without reading the original paper ( since your question is specifically about the paper ) . also , what do you mean with "" levels of random effects ?"
243790,in what sense are the two rates dependent ?
244136,does split in your case mean taking a small sample from a larger set and running a tree on it ?
244284,it sounds like you're just counting which letters occur after b ?
244321,"ok . so if you want both check both x and y and they are independent then you do the same calculation for x and then again , but separately for y . yes , sorry for the confusion . you want to take x - 2 and then determine if the absolute value is greater than 0 , or equivalently , but more simply , you could just test if abs ( x ) 2 . i think the problem here is that your question is quite poor . we are all left guessing at what you are actually trying to do . what analytical problem are you trying to solve ?"
244611,"it depends , what do you want to use the results for ?"
244677,"since "" likely "" and "" influence "" are concepts entirely foreign to what pca does , could you elaborate a little on how you conceive of applying pca to this question ?"
244720,"could you help us understand what you mean by "" nomogram "" and its connection with the "" derived online score calculator "" ?"
245385,why don you want a confusion matrix for this ?
245472,what kind of distinction are you making between inner and outer cross validation ?
245831,can you show the calculations you performed for each column ?
245925,did you run logistic or simple linear regression ?
246301,"* "" are the inputs well selected ?"
246477,did you see [ this ] ( url ) page ?
246718,"yes , there was a visible shift around nov 15 . however , the new range is no different than observed in late october . what , then , do you mean by "" abnormal "" ?"
244245,what will you use your model for ?
246892,what is the type of your weight column ?
247373,"if the loss function is a function of g ( z , alpha ) and q is a function of the loss function , then q yet is a function of g ( z , alpha ) , right ?"
247175,"so would it be fair to say that you really just need a method to say if you can reasonably cut a graph into 2 pieces , and you're recursively applying that ?"
247573,"what do you mean by "" stepping immediately back again "" ?"
248186,"i haven't looked up all the definitions in a while ( which is why this is only a comment ) but does it hinge on the "" unique "" part ?"
248539,"ok , it seems more like a deconvolution to me , and you want to act on residuals . can i ask what is your input data ?"
248568,did you just post this a couple days ago ?
248346,"if your performance ratios / percentages measures are gaussian yes t-test is fine . in addition , with such a high sample size i guess the t-test won't have problems . you can also consider the mann-whitney test . what do you mean by "" the weighted averages of the ratios "" ?"
248445,are you looking to find the pairwise euclidean distances ?
248670,but why would you want this ?
249473,i can't follow this situation . can you clarify the situation you have in mind & your question ?
246398,"this seems like a pure coding issue . to make it relevant on this site , could you explain what the "" ed "" is and provide a quantitative definition ?"
249849,"this might be a stupid comment , but have you tried reducing this to the lowest fraction , i . e . 2 / 3 and 1 / 5 ?"
249956,are the events / non-events in the separate time windows independent of each other ?
249912,"i don't understand your question . what are x , y , z , b , and c ?"
250146,"without your definition of risk assessment and degree of uncertainty i doubt that technical people can understand the question fully either . at a guess "" affected "" is bad news , "" clear "" is good news and "" unknown "" is in between . you can report the fractions of each . are these litter sizes typical because statistically they look like very small samples ?"
250149,"you ask whether the two statements are equivalent . they differ in exactly one word : "" determine "" versus "" estimate "" . it is certainly possible to * estimate * the total , but not to * determine * it ( as in , without error ) without counting all individuals . so it seems like your two statements are not equivalent . but this does not seem to answer your final question , so i seem to be misunderstanding something . can you please edit your question to clarify what you mean ?"
250498,"if you have a matrix as the target , how do you compute the error that you will backpropagate ?"
250418,"what is your overall goal , and what is the full dataset available , eg do you have the pages viewed in each session ?"
250807,tic-tac-toe is a [ solved game ] ( url ) . why would one need ml to make a tic-tac-toe bot ?
250543,"sorry for being slow . . . i now see what you're getting at -- the issue arises because you have exhausted the population of subjects but you * don't * have the whole population of measurements you're interested in . sure , you can't use an ordinary t-test in that instance . you can proceed by setting up randomization to treatment ( as you have in your question ) , using some suitable test statistic ( even the t-statistic if you like ) and then using a permutation test . would you like an answer along these lines ?"
250685,do you have a reference for this claim ?
251552,how do you define ( inter and intra ) reliability ?
251253,"there is something not right in your question . perhaps you have $ hat y_ { 1 , i } $ and $ hat y_ { 2 , i } $ from the two models , not just a single $ hat y_i $ as in your question right now ?"
251855,"welcome to the site . if your question is referring to a problem or an assignment , please add the ` [ self-study ] ` tag and [ read its wiki ] ( url ) . can you give us the first few rows of your data--along with headers--so we can see what you have ?"
251891,it should be the case that the number of tasks should be a concave function of hours and a concave function of experience . do you have total hours per day or do you have lunch and break information ?
251896,that's a thing that you can do . what do you hope to learn from such a procedure ?
251665,you have 5 repeats in group 1 . does that mean that it represents a sample of 5 of the 15 individuals in group 1 ?
251907,why cite any at all ?
252100,"i am not sure how the variables line-up with the headings . if i read it right site 1 had a mean change of 5 . 2 , all subjects took drug a , there were 20 adverse events , and the number of subjects is 200 . if this is right for the first line what is the change of 5 . 2 a change from and what are you measuring ?"
252473,can you describe the study design better ?
252540,"just a thought : if you train any network with all data duplicated to reflect the commutativity , what would happen ?"
252709,have you read url ?
252570,do you have a sense if claims unmatched to a policy are more likely to come from certain types of policies ?
253127,i think the reference post answers your question . 50 is not large enough for some distributions . there are other choices . frank harrell points out that the wilcoxon test is relatively efficient . so that is one option and bootstrap is also available . if the population distribution is close to normal is it close enough to make the distribution of the test statistic close to the t distribution ?
253578,"as a thought experiment , consider the extreme example of a population with one member . what's the margin of error with a sample size of $ 1 $ ?"
193095,"what do you mean by "" expected value of getting a sum of points to be 10 or more "" ?"
253693,"well , one reason to not use ols parametric regression is due to violations of normality from the residuals . what do your residuals look like ?"
254044,you need to narrow this down to a manageable problem . what does chance to find a parking space even mean ?
254551,"how did you decide that the regression model "" doesn't fit "" ?"
254560,you seem to be saying that you intend to treat the answers a respondent gives for one product as independent of the answers that same respondent gives for the other product . is that really plausible ?
254847,this is very broad and has several question in it . can you narrow things down a bit ?
254824,"are you generating data from a bivariate distribution . you can't generate multicollinearity with i variable . you probably know that . the term outlier is not well defined especially for multivariate data . for univariate distributions an outlier is an observation that is far away either above or below the "" center "" ( possibly the median ) of the distribution . for the simulation you have to say how far away from the center above or below . i am curious as to why you want to do this . did you want to test diagnostics for multicollinearity and influential observations ?"
254783,"i was thinking there may be a less complex approach . what proportion of subjects in each group didn't reach 80 % and roughly what proportion didn't reach 70 % . more important , what is the main conclusion ( conceptually , not statistically ) you would like to draw ?"
254267,what is your hypothesis ?
255112,"how do you mean "" directly "" , unless it's with reference to the multivariate distribution you're sampling from ?"
255548,are you talking about correlations * between * random walks ( across series not within one series ) ?
255813,"the binomial theorem has involved infinite series for more than 300 years . see url alecos : what is a "" merlin transform "" ?"
256129,""" coefficients "" is plural . what , then , do you mean by a * single * "" confidence interval "" for them ?"
256132,those pictures are just as vague as your words . can you tell us how you * quantified * the correlations ?
256047,whether the * * data * * are from a normal distribution is not crucial at all . are you saying that you tested the * * residuals * * for normality ?
256046,tim can you provide one counter-example ?
256330,"because goodness-of-fit for glms is basic statistics . maybe there's someone here on ds that can answer it , but the evidence of the answers i've seen mean that's unlikely . machine learning , big data , yeah , but gof diagnostics ?"
256334,"excuse for a moment , your list of assumptions of efa "" test "" ( sic - ?"
256438,is it stated that $ x $ and $ y $ are independent ?
256390,"what is ` survey ` package , what language ?"
256577,finding the correlation is a technique--but it doesn't tell us much about * why * you want to apply the technique or how you are hoping to interpret the results . could you tell us something about this context ?
256040,are you sure about using mab in this particular case ?
70349,maybe 10000 is just not enough to establish a significant decision ?
256203,did you try to read wikipedia articles on entropy and differential entropy ?
257115,"even though i think the gist of this question is interesting , it is really hard to truly answer it . i can very easily 'guestimate' all four scenarios happen equally often , which may be correct in my field , and wrong in another or in the grand total of studies and data-collections . moreover , statistical methods aren't applied because of data-structure , but because of relevancy and applicability to the research question , i . e . reason for collecting the data in the first place . could you clarify what it is you are after ?"
257074,"an adequate treatment of these questions would come in the form of one or more books , courses , or tutorial sessions . not a couple of screens' worth of a webpage , i'm afraid . do you have a question about some specific aspect of the work ?"
257278,what * * * pattern * * * are to trying to predict using nn ?
257345,what are you trying to achieve that isn't already apparent in your matrix ?
257343,"what kind of "" problem "" do you have in mind ?"
257834,i am not certain that i understand your question . you have a dataset with many observations but when you use pca you end up with less components then that there are observations ?
257657,"yes , but in your question you asked for the kernel ?"
255326,why does your solution need to be 'clean' to be publishable ?
258261,your estimate of effect size should reflect the level of reliability of your measure ( s ) . do you have reason to think it does or does not ?
258328,"i assume that you are talking about a binary variable , with two values 0 and 1 , say , which in your applications you want to think as labelling non-defective and defective states . how does that relate to a hypergeometric at all ?"
258196,do the 100s arrive at regular intervals ?
258595,what do you mean by categorical time-series not being mark of chains ?
258845,"it would help to know the context of your apparent quotation . in particular , it isn't at all evident what someone might mean by a "" non-deterministic . . . borel-measurable function , "" so the intended meaning of "" deterministic "" is obscure . does this phrase come from some well-regarded paper or text or is it perhaps some throwaway passage from somebody's blog ?"
258986,""" more advisable "" for what purpose , exactly ?"
259231,"just to clarify what you mean from a functional perspective : do you mean that you have five functions , and $ y_1 = f_1 ( x ) epsilon_1 $ , $ y_2 = f_2 ( x ) epsilon_2 $ , etc . , or that you have a five "" measurements "" of the same function at the same locations , e . g . $ y_1 = f ( x ) epsilon_1 $ , $ y_2 = f ( x ) epsilon_2 $ etc . ?"
259654,"what do you mean by "" basis "" ?"
45803,why are you confident that separation isn't occurring ?
260391,or may be optimization perspective ?
260433,"i'm afraid my comment might not suit your situation and i deleted it while rethinking . anyway , i think it would be helpful to clarify what "" 10 hypothesis tests for the same 4 groups ( but different data ) "" means . do you perform your tests in different variables ?"
260981,possible duplicate of [ why is bayes classifier the ideal classifier ?
260860,welcome to stats . se ! please take a moment to view our [ tour ] . why are you trying to determine this type of mixed distribution ?
201933,are you asking us to clarify the actual question you have ( * is the answer to this question some general $ sigma ^ 2_h ( l ) $ ?
261672,why do you need to argue that the power of the test was insufficient ?
261652,"what do you mean by "" significantly higher than expected from the multinomial distribution "" ?"
261670,"as of now there is not enough information to tell what var specification is best . without any extra knowledge , the recommendation would be to run a regularized var model including the exogenous variables and their lags up to some sensible maximum lag order . but what do your variables represent in reality ?"
261803,"hint : fit the $ ( x , y ) $ data $ ( -2 , 4 ) , ( -1 , 1 ) , ( 1 , 1 ) , ( 2 , 4 ) $ with a quadratic function $ y = alpha x ^ 2 beta x gamma $ . what is its minimum on the interval $ [ -2 , 2 ] $ and how does it compare with the smallest value of $ y $ in the data ?"
262026,if i understand correctly you are performing a t-test to compare a group with 3 cases to a group with 11 cases ?
262199,what happens if you just take expectation on both sides of $ k hat { theta } _a ( 1-k ) hat { theta } _b = hat { theta } _c $ ?
262393,framed as a request for r code this is likely off topic ( though it's fine to ask if you focus on the statistical issues ; there's usually no problem with encouraging answers than incorporate r where possible ) . however i am not sure i clearly understand what you're seeking . are you after something like an empirical cdf ?
262820,please explain why you think it would be erroneous to assume equal variances in the two groups . do you have any evidence for that ?
262978,could you define parameter c ?
262845,have you considered using mixed-effects models ?
263472,"$ x_1 , x_2 , x_b $ are independent ?"
263248,"it depends on what you mean by the "" glm framework . "" your question seems to equate that with a particular software application that * by default * applies t tests . but there is nothing at all in the concept of a glm that precludes conducting z tests . is your question really about how to fool ` lm ` into producing the output of a z-test ?"
262252,does my comment answer the question ?
261837,"i don't understand the event whose ( conditional ) probability we are computing here . "" there is an occurrence "" does not specify a unique occurrence and thus it is unclear what "" it "" refers to in "" it is the first occurrence "" . in other words , when there are multiple occurrences , how is "" the one "" we are considering selected ?"
264455,"from the question it is unclear whether you are looking for three items which the user chooses one of , or whether you are looking for a set of three items the user chooses all of . this seems like more of an optimization problem where you are searching for the items which maximize the risk reduction given your model . the way you solve this optimization will depend on what you know of your function and its representation . a multi-armed bandit asks "" which sequence of actions will minimize my regret by balancing exploration and exploitation ?"
264552,do you know how to apply conditioning ?
264685,"to answer your question of what your states are , i think you need to think about what you mean by state in "" will still be in the same state "" ?"
264690,"if the values aren't independent , how do you calculate the standard error of the mean ?"
265115,see ` ?
264056,did you check the [ wiki ] ( url ) ?
265374,can you write it in mathematical notation and provide a source that states equivalence of fitted values ?
265760,it would help to know the context of your analysis . are you : a ) learning to code some stats ; or b ) doing actual applied research ?
265982,have you considered using two ( or more ) sequential models and then merging them ?
265742,wil you present data and statistical results ?
266732,"a multiple-regression model isn't going to help you find a correlation between two things . do you mean "" association "" ?"
267110,probably care more about the distance between two points than the actual numerical value ?
267355,"the p-value for a one-tailed test is given directly by the binomial distribution function : what's the probability of 100 or fewer "" successes "" in 210 bernoulli trials with a common "" success "" probability of one-half ?"
267460,"this question might be too broad to be answerable . * of course * you are * changing * the characteristics of the data when you transform them . this is always done with a purpose within the context of a particular analysis . an adequate account of all the possible purposes , contexts , and analyses would ( and has ) required entire books . could you explain what your actual statistical problem is ?"
267812,"are these relations ( * $ a = ( b ^ 3 ) c / 2 $ or $ d = ( a ^ 2 ) ( c ^ 3 ) / 4pi $ * ) you are talking about some kind of 'true' / known association , or something you've estimated from your data ?"
268235,how many observations for different temperatures and more details ?
268200,ok . what about it's references ?
268730,what are you testing the statistical significance of ?
268582,"can you clarify "" don't know what ranges of the blood test result could accurately predict their presence "" ?"
269434,time to conversion looks like survival modelling . in your situation is it possible that there are cases that can be seen that have not converted inside the time they were observed ?
269408,"please clarify what you mean by "" centering . "" if the variables are $ x_1 , ldots , x_n $ with means $ mu_1 , ldots , mu_n $ respectively , then is "" centering "" converting them to $ x_1- mu_1 , ldots , x_n- mu_n $ or is it converting them to $ x_1- bar { x } , ldots , x_n- bar { x } $ where $ bar x = ( x_1 cdots x_n ) / n $ ?"
269785,why would you want to put your data into bins rather than keep them in a more-or-less continuous form ?
213911,"what exactly do you mean by "" projecting data onto a model "" ?"
269274,2 . introduce a lag between input and output ?
269957,"i don't understand your question . what do you mean by "" the correct bin given the value "" ?"
270355,"you need to include the "" migrant "" indicator in the regression along with the interaction . otherwise , what you are doing is tantamount to asserting that natives all have zero time living in the area . see , * inter alia * , the analysis of a comparable situation at url and perhaps url is the same question as yours ?"
271005,which estimator of skewness are you using ?
271584,could you please explain what your notation means ?
271638,"the statement you quote makes little sense to me ; if they're known to be equally spaced you'd have an * interval scale * , not ordered categories . does it explain why it makes that statement ?"
271969,you can't draw it until you work out what its equation is . what did you get for the pdf ?
271745,why is * intensity * bucketed ?
272428,"since nns usually ( and in this case ) have no underlying statistical model , i'm afraid that calculating an aic / bic does not make sense here . i might be mistaken , tough . ( note that the aic mentioned in ` ?"
272801,sounds like an expert computer vision problem ?
273141,have you considered survival analysis with time-varying covariates ?
273341,what type of model are you considering ?
273521,do you know what are the standard deviations ?
273572,infinitely many . i suspect this answer--which is perfectly correct ( and i hope is perfectly obvious ) --is also of no use to you . what is the actual statistical problem you want to address ?
273632,what are your controls $ x_2 $ ?
273577,how are the subjects selected for each group ?
159479,presumably you have some definition for what a good clustering is ?
274162,what is the clinical purpose of your analysis ?
274260,"do i understand correctly that the sum of all $ x_i $ is always n , while you are asking for the distribution of s , which is also the sum of $ x_i $ and therefore n ( $ s = n $ ) ?"
274444,"if you only continue to collect data after the pilot if the pilot shows indications of some desired result , then your full sample would potentially be biased if you included the pilot data . there might be no true effect but the pilot showed apparent effects by chance . how do you think this would affect the kinds of samples you would see ?"
274341,maybe you could clarify what you want to do : define a new association coefficient ?
274610,"in general your description of the problem suggests that the binomial model is appropiate in this context ( being late is a yes / no event , right ?"
274675,"if w is n ( 0 , 1 ) then x can be any value . what is the point of having x ?"
255631,can you re-upload the image of the distribution ?
275808,what null or working hypothesis are you considering ?
275102,"given you already did some simulation , why do not try fit the model ( 3 ) only to see if you can get the unbiased estimate of that parameter ?"
275840,can you elaborate on the statement that their significance falls when entered together ?
275450,this is discussed in a lot of threads on this forum . have you searched for some ?
276412,"have you also tried non-linear associations ( transforming variables [ predictor or outcome ] to for example , log scale ; or fractional polynomials ; or [ restricted ] cubic splines ) ?"
276349,"that's a bizarre definition of conditional cdf , because you seem to be conditioning on $ y leq y $ , as opposed to $ y = y $ . the latter would correctly give you the pdf density after differentiating in $ x $ . could you double check your definition ?"
276096,"please tell us what function these additional variables are intended to serve . and could you explain what you mean by "" one case can have multiple variables and thus one case can have multiple outliers "" ?"
276694,"glen_b ok , in this case , what is the distribution of $ ( x p ne q ) $ ?"
277292,""" suppose your $ r ^ 2 $ is very low ( between 5 to 10 % ) for a price elasticity model "" * is not a question * . my response to "" suppose your $ r ^ 2 $ is very low ( between 5 to 10 % ) for a price elasticity model "" would be "" okay , done "" . i can suppose that no problem , so there's nothing further to do . if they were really not forthcoming , i'd have to ask what aspect of that they regarded as a problem to solve . in their absence , what do you see as the * problem * here ?"
277558,glen_b how about resampling methods designed for time series ?
277884,are you asking about ways to deal with multicollinearity ?
277278,1 . it's difficult to picture both the nature and the extent of what you're describing . are you able to show some plots of what you're talking about ?
277509,"i wonder if you've intending a more in-depth question than you've expressed here . the straightforward answer is , "" yes , absolutely . "" ( the first line of the wiki entry on lda reads , "" in natural language processing , latent dirichlet allocation ( lda ) is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar . "" ) and , the generative model for lda is fully covered in the paper introducing it . is this the full extent of your question , or is there something more to it ?"
278126,isn't it possible for the denominator to be 0 ?
278156,i hope you will be able to generalize from the simple example i gave : doesn't it show that adding a little bump on the distribution isn't going to change anything about the domain of attraction ?
278151,"you are using a language that will be unfamiliar to most readers and likely will be misunderstood by many . could you please explain to us what a "" large scale variable "" is ?"
278983,can you get the eigenvalues of the correlation matrix ?
279106,badmax where did you read this ?
279238,what is the output of the response variable ( the test output ) ?
278077,carefully define the baseline in this case . consider using * firm * as a random effect . plot your data and do some eda - do large differences appear plausible ?
279597,it's not exactly clear what you are asking here . are you asking how much effect each weight has on what the output of the lstm will be at a given time step ?
279896,i would need to know more about the data . what is the hierarchical structure ?
280182,how are you using the word interaction here ?
280289,"the short answer is yes of course you can . the long answer depends on just what properties you want your new variable , autonomy , to have so can you edit your question with more detail ?"
280343,have you tried the references provided by wikipedia url ?
280456,i would not expect a normal distribution ( if for no other reason : time cannot be negative ) . i would expect a clump around very short times ( a few minutes ) and then a long tail . maybe other clumps ?
280816,the title and the body of the question do not match ( variance of $ y_t $ or the variance of the limit specified in the last line of the question ?
280992,"in general , the choice of statistical method is strongly influenced by your question or hypothesis . why do you want to do this at all ?"
281512,how big is your data ?
281609,is there benefit in restating your required goal - what happens after one predicts the time at which a user logs in ?
281676,why don't you think $ - frac19 $ could be right ?
281739,"is it fair to say , that date is a feature ?"
281832,how do you expect pca will help you with adjusting for something that you cannot observe ?
281871,in what sense is $ a $ actually an adjacency matrix ( which typically has only zeros or ones for its components ) ?
281528,do you perhaps mean the [ assumption of homogeneity of regression coefficients ] ( url ) ?
282294,"normally i'd say this is duration modeling ( or , depending on your discipline , survival analysis ) , but since there are multiple occurrences of each item , that does not appear to be the straightforward case . what is ` lifetime ` in this context ?"
282129,could you explain what such a subsample would accomplish ?
282300,what do the grey bars represent ?
282591,"are you asking this question : url if not , could you explain how yours differs ?"
282897,in that case removing the outliers may be justified . do you know a range of values that flickers of light fall into ?
283204,advantages and disadvantages as compared to what exactly ?
283419,"why not just use the binomial probabilities directly , instead of approximating the binomial distribution with a normal ?"
283744,"[ this image ] ( url ) shows that you can get more than a binary split ( see the region variable ) , ( or equivalently , p22 of [ this ] ( url ) , see the outlook variable -- also see p7 [ here ] ( url ) ) . if you question is "" how do i make weka do this ?"
284033,why is assuming a normal distribution important to you ?
284262,can you add the self-study tag ?
284087,let's try this in reverse . my mean is 100 and my sd is 50 . what's my 90th percentile ?
284403,"please offer a complete reference . there's more than one paper with an author called greene published in 2004 . . . . do you mean greene , w . ( 2004 ) , "" fixed effects and bias due to the incidental parameters problem in the tobit model "" * econometric reviews * , vol . 23 , no . 2 , 125-147 . . . . ?"
284369,"a "" zero degree spline "" is ordinarily called a * step function . * could you clarify your question ?"
95797,which accuracy scoring rule are you using ?
284523,"your question is long and complex , and contains multiple questions - that might be why it hasn't had an answer yet . for q1 : how have you interpreted them ?"
281364,have you looked at [ this question ] ( url ) ?
285328,can you provide more detail about the comparisons ?
284919,are you talking about restricted boltzmann machine ?
285572,"it all depends on what you mean by "" best describes "" . as it stands , if we were to drop the term "" time series "" and just view your data as vectors , it would sound like a routine least squares fit . how does your problem differ from that ?"
285583,"this isn't real data , is it ?"
256867,does $ lvert hat theta- theta ^ * rvert = ( hat theta- theta ^ * ) ^ 2 $ ?
286007,it seems to me that there's little to gain by trying to create fake anomalies without having ever observed real anomalies first . what are the odds that you'll accurately anticipate their important characteristics ?
285469,` pca ( for binary data ) ` what do you mean ?
286820,"the definition is not the final equality : that's a calculation . ( it requires assuming $ u ( r_1 ) = 0 $ and $ u ( r_2 ) = 1 $ , which you only hint at . ) the definition is the * first * equality . what's the problem with that ?"
286831,"hint : when you perform the same deterministic arithmetic operation at every place in a stationary process , you must still have a stationary process . what do you get when you start with $ ( u_t ) $ and , for each $ t $ , construct $ u_t rho u_ { t-1 } rho ^ 2 u_ { t-2 } cdots rho ^ n u_ { t-n } cdots $ ?"
287065,have you considered multi-dimensional scaling or tsne ?
286987,are you sure it is zivot and andrews adf test ?
287141,hi ! welcome to cv . i feel your question can be significantly improved so as to attract attention and possibly good answers . what is your formal definition of hysteresis ?
287129,what kind of stop word list are you using ?
287280,""" but only an estimation is available "" - what do you mean by that ?"
287339,i don't understand why a model would be the basis for recommending a product . don't you just want a product that is better than others ?
287382,"if you want to use the difference between values corresponding to drug and placebo as dependent variable , you'd need to assume the order in which patients received placebo and therapy does not affect the difference . does that sound reasonable ?"
287138,"it looks from your plot like you're trying to detect changes in the mean , or perhaps a quantile ( like the median ) . why would kurtosis be relevant ?"
287458,"so you're trying to predict the positions at which the polymer breaks given some inputs , right ?"
287332,have you checked that the design matrix for the linear model you are fitting has full column rank ?
287461,"could you explain what the "" combined "" percentages are intended to mean ?"
286920,"this remains somewhat hard to follow without reading the code , which is itself hard to read b / c it's a picture . can you make it a little clearer & / or type your question as text , not just post a photograph ( see [ here ] ( url ) ) ?"
288365,"the first line makes it sound like $ a $ , $ b $ , and $ c $ are mutually exclusive , especially since the percentages add up to 100 % . and the second line seems to be saying that $ x_1 a $ , $ x_2 b $ , and $ x_1 x_2 c $ . since $ a $ and $ b $ are disjoint , so are $ x_1 $ and $ x_2 $ , so $ x_1 x_2 $ is empty . do i understand you correctly ?"
288617,"now that you have stated these are "" standard normally distributed "" rvs , you know a lot about the moments : "" standard "" tells us the means are zero and the variances are unity . "" normal "" tells us the third moments are zero and implies the fourth moments are $ 3 $ . moreover , if you also assume $ ( x , y , z , v ) $ is multivariate normal , then the three zero conditions on the covariances imply pairwise independence in each case . where , then , lies the problem in computing the variance of $ xy vz $ ?"
198061,"aksakal i can't tell whether or not you agree with alex r . do you agree that , as alex r . suggests , the word "" tensor "" is often misused and that "" multidimensional array "" would usually be a more appropriate term ( in machine learning papers ) ?"
288481,"is this primarily a question about statistics ( "" what is a way to approach this kind of problem ?"
288949,does this help ?
289095,"why not add subject as a random effect too , instead of using regularization ?"
288641,the direct issue of why the help says something is probably as answered as it will ever be ; the basic issue of what the difference is and why you'd prefer one or the other seems like a good question . what's the r function you're calling ?
287720,i think that ordered factors are what is needed here . from reading ` ?
289066,what is the scoring system you have used for liberton items that are being referrred . ?
128723,can you show the output of regression routine ?
290886,is your data really binary ?
146446,what happens here ?
292231,"i'm having trouble understanding the description of your setup . it sounds like an image $ x $ is mapped by some process to a real number $ y $ , which is then mapped to a binary value $ z $ by some threshold function . $ x $ and $ z $ are known , but you never observe $ y $ . you want to learn a function to predict $ y $ from $ x $ , based on known examples of $ ( x , z ) $ pairs . is that right ?"
292235,"consider some set of $ alpha $ and $ mu $ for $ theta_1 $ . now in $ theta_2 $ set its $ mu $ , ( $ mu_ { ( 2 ) } $ say ) to some particular value like $ 0 $ . can you find a set of $ alpha_ { ( 2 ) , i } $ values that leave $ e ( w_i ) $ unchanged ?"
292571,"the idea is correct but the algebra is belabored and wrong at times . for instance , the third line is both superfluous and incorrect , and the sixth and seventh lines are really overdoing the obvious . is this a problem ?"
292584,is this somehow related to interaction terms ?
294053,"instead of transforming the data to fit the model , why not use a model that doesn't make that assumption ?"
294260,"it's unclear what you're asking . if you are asking about transforming a response variable to have a normal distribution , there's no requirement that the marginal distribution of the response ( the thing you're looking at there ) be normal ; it's not an assumption of regression . what is the response measuring ?"
294473,"is the dependent variable really measured at the school level , or is it an aggregate of data from the individual level ?"
294614,why would your covariance matrix be a function of the data points ?
294515,what was your sample size in each case ?
295127,do you mean you continue until you have both pulled at least $ k $ blue balls from the first bag and at least $ k $ blue balls from the second bag ?
295258,"are we trying to satisfy the constraint with some probability $ p $ , or must it be always satisfied ?"
295743,"what are events $ a $ , $ b $ and $ c $ ?"
296022,two questions . 1 ) which value will be replacing the missing data points ?
296334,do you mean a notation like $ mathbf { hat { p } } $ ?
296437,1 . you're plotting the * negative * of the residuals against fitted ?
296107,why not find the exact matches and remove them before resorting to approximations ?
296672,"note that when you refer to "" rejection region "" , you are writing of a hypothesis test , but when you switch to "" bayesian estimation methods "" , you are writing of point estimation . these are not the same thing , and phrases like "" conservative leanings "" don't really apply . are you interested in a bayesian analogue to the classical hypothesis testing framework ?"
294936,what is actually your question ?
297480,are you trying to say the correlation matrix is $ 70 times 70 $ ?
297706,"i am really confused by this question . what do you mean by "" is the ordinal nature of the individual variables is preserved ?"
12002,"not an answer , just an intuitive observation . the ci for the pooled data mean ( all nine obs ) is $ ( 39 . 7 pm 2 . 13 ) $ , ci based on the means only is $ ( 39 . 7 pm 12 . 83 ) $ . not sure what your ci is doing ( typo ?"
297953,is it important to use regression ?
297734,"let p ( data x ) = p ( y1 x ) x p ( y2 x ) x . . . x p ( yn x ) , where p ( yi x ) is a * density * that integrates to 1 holding x fixed . i don't know what norm-cdf ( yi , x ) means in this context . ( at a minimum you need a mean and a variance to specify a normal distribution . ) you should be able to answer the following question : how would you generate observations if you know x ?"
298068,what is your definition of variance ?
298178,"lda is different from pca substantially , lda is "" supervised "" , pca is not . lda is close akin to canonical correlations ( [ see ] ( url ) comparison with pca ) . but what do you want specifically ?"
298163,is this for a class ?
298216,why do you need any of that ?
298115,"are you computing power * post hoc * , at the observed effect size ?"
298113,"certainly there are ways . it's even straightforward to do it with pencil , paper , and a table of random numbers . but could you be more specific about what you mean by "" randomly "" ?"
298265,i assume you're referring to [ lasso ] ( url ) ) regression ?
298693,"actually , i'll ask , what does it mean to draw from $ e [ x ] $ , unconditional expectation , in your situation ?"
295035,the simulations are very easy - is there a reason you don't want to run them ?
299014,the answer will likely to depend on the specific questions you want to answer . maybe you could add some information in this respect ?
299154,i wouldn't assume familiarity with the ames house pricing dataset . i would recommend stating what your goal is : is price a response or outcome you are trying to model or is it a predictor ?
298645,""" so the only thing it doesnt satisfy is that the relationship between m and y is not significant when controlling for y . "" do you mean "" when controlling for x "" ?"
299455,"welcome to cv . since you re new here , you may want to take our [ tour ] , which has information for new users . what is your question ?"
299471,how do you so confidently state that it's $ o ( n ) $ rather than say $ o ( n log n ) $ ?
282456,"i think simon you fully got the point : it is a high dimensional problem . all i know and tested so far shows that in such situation random mc is hard to beat . most methods fail if the number of dimensions goes beyond 10 or so . have you tried to strip down the problem to say n = 3 , and found a solution ?"
299820,"you stated "" a and b "" . does b happen without a ; or a without b ?"
300179,"correlation is proportional to the covariance $ $ operatorname { cov } ( xy , xz ) = e ( xyxz ) - e ( xy ) e ( xz ) = e ( x ^ 2 ) e ( y ) e ( z ) - e ( x ) e ( y ) e ( x ) e ( z ) . $ $ ( your independence assumptions justify the second equality . ) can you go on from there ?"
300075,what is edu_uni here ?
300305,"i heavily used random forests in r for a while , and i never heard the term ` auc ` . what does it mean ?"
300373,just a quick thought to add to the list of alternatives : what about a poisson model with an offset ?
301279,there are various approaches for feature selection . which statistical test are you thinking ?
301345,"welcome to cv . since you re new here , you may want to take our [ tour ] , which has information for new users . could you provide more information about the analysis ?"
301386,source for the claim ?
301398,"feature importance is a slippery concept , and borders on being non-statistical . the "" feature importance "" from a random forest is just a name someone gave to a diagnostic of a model , you shouldn't take the name too seriously . can you answer this question : if you knew what features were "" most important "" , what would you hope to do with that information ?"
301619,which kind of variance of you want ?
202060,your question is missing crucial information . what kind of model are you using ?
302134,do you any definition of likelihood ?
302190,as far as i can see that table does not report a meta-analysis at all so you just need to look at the means to see the direction of the difference . is that what you are doubting ?
302342,""" i later understood that "" neutral "" option should have been avoided in questionnaire scales . "" why do you think it should be avoided ?"
302626,"as i understand your problem , you have a bunch of widgets indexed by $ i = 1 , ldots , n $ . for each widget , you have some measurement $ x_i $ . it seems to me that it's imprecise to reject a widget simply if $ x_i notin ( -2 sigma , 2 sigma ) $ where $ sigma = sqrt { frac { 1 } { n } sum_i ( x_i - bar { x } ) } $ ?"
302760,likelihood makes no sense and cannot be determined until you specify a * probability model * for any discrepancies between observed values of $ y $ and those predicted from the associated values of $ x $ . what probability model would be appropriate in your application or might be suggested by the data ?
301587,"if you mouseover the ` [ normalization ] ` tag , you'll see it refers to making "" values lie within a specified range "" . i think you mean * [ tag : standardization ] * . at any rate , why would you do this ?"
303285,"sometimes the fine structure of a grade distribution is a hint at manipulation , as when there is heaping ( e . g . many students scrape a pass ) that can't be interpreted as a side-effect of a marking or grading scheme . i don't think there is any white magic to tell which originals may have been changed without more detail . the limiting case is clearly futile here : two grades are 66 , but i will tell you one was changed . which one ?"
303412,the qq plot is * fine * . why are you using a whole bunch of tests to test normality ?
303323,"i'm sure we're misunderstanding , because i am having trouble conceiving of how your assertions can be true when i apply standard concepts of "" correlated "" and "" mean . "" what exactly are the "" means "" of these binomial variables ( could they be sample means ?"
304534,"i think you need to explain how this plot was created . what is the data , and what does it measure / represent ?"
304698,"this formula is nonsense , because "" $ y $ "" appears on the right hand side as a free variable but not on the left and "" $ y $ "" appears on the left but not on the right . presumably these should both be the same symbol , but what do you intend them to represent--real numbers or random variables ?"
304859,can you tell us more about your data ?
304940,"i think your $ k $ usually should $ le p $ and the column of $ z $ will be less than $ x $ . i think we estimate fixed effect first then random effects . if there are only random and no fixed effect , why you estimate them then ?"
305006,what are the x-axis values where the function hits 0 and 1 ?
304367,what tests do you use to find the effect of c on the canonical variate or on $ d $ ?
305077,what's not clear ?
304922,"it's the [ pythagorean theorem ] ( url ) . among many explanations on this site , [ this one ] ( url ) has a picture . the thread at url seems to be a duplicate : does that answer your question ?"
304264,so to clarify : you also need to predict multiple output variables ?
305183,"it is not so clear what you ask , what do the column titles mean ?"
305608,how is that link relevant ?
305613,"why not do a regression of costs on a constant , a dummy for treated and condition , and a dummy for condition and untreated ?"
176883,um . . . why should the distribution of $ x_t $ depend on $ x_ { t 1 } $ ?
306116,why do you think that logistic regression wouldn't be appropriate ?
305994,what are the values of your response ?
305841,"first , your lif will be easier if you take ( wlog ) $ mu_1 = mu_2 = 0 $ , $ sigma_1 = sigma_2 = 1 $ and bother about the shift and the scaling once you are done . did you try taking an inverse wishart prior and then conditioning on $ sigma_1 , sigma_2 $ ?"
306356,"do you mean to say that you have four measurements per patient before and after ( e . g . $ t_ { 0 , 1 } , t_ { 0 , 2 } , t_ { 0 , 3 } , t_ { 0 , 4 } $ , $ t_ { 1 , 1 } , t_ { 1 , 2 } , t_ { 1 , 3 } , t_ { 1 , 4 } $ ) or four measurements in total ( e . g . $ t_ { 0 , 1 } , t_ { 0 , 2 } , t_ { 1 , 1 } , t_ { 1 , 2 } $ ) ?"
306463,are you asking what would happen if the variance of the white noise was something other than 1 ?
307821,if you are studying psychology in a german university ( are you ?
308006,have you tried a box-cox transformation ?
308057,i think question 3 is not well posed . $ delta_1 $ and $ delta_2 = delta_1 / n $ are random variables . what do you mean by a confidence interval of a random variable ?
308104,why are you doing this at 5 separate time points ?
308548,perhaps you could say why you abandoned logistic regression which many people would see as the default for a binary outcome ?
308440,do you want to know whether the cdf is a good representation of the data ?
309031,"cmf is not as well-known as cca or pca or factor analysis . can you add , to your question , links to sources explaining cmf theory and algorithm ?"
309319,"what do you mean by "" $ hat mu $ "" ?"
309535,the question is : why would you like to have a bayesian estimate to obtasin frequentist confidence intervals and p-values ?
309733,what is paradoxical about which conclusion ?
309873,what do you mean by a confidence interval for a chi-squared test over and above a ci for difference in proportions ?
309783,"hint : given than $ s = a $ where $ 0 leq a leq 1 $ , can you figure out why it must be that subject to this condition , $ x $ must be in $ [ 0 , a ] $ ?"
310474,"to what "" well known procedure "" do you refer ?"
310478,equivalent in what sense ?
310485,"it is counterproductive ( or worse , entirely misleading ) to generate lots of statistics and ask "" are these significant . "" instead , turn around and ask "" what can these data tell me about what i'm interested in and how reliable is the information they give me about that ?"
310693,"presumably "" variance "" in ( b ) means the sampling variance of $ hat beta $ . your first step therefore should be to obtain an expression for that sampling variance in terms of the $ w_i $ and the constant population variance . did you succeed with that ?"
310933,"multinomial regression with the type as outcome and the actions as predictors could give you some sense what the probability of being a certain type is . i do not know whether it is the most accurate compared to other techniques such as clustering . additionally , i'd wonder whether you have the 'true' distribution of actions defining the types . do you estimate these from your data or do you know that for example type a users perform have a 60 % probability to perform action 1 , 0 % to perform action 2 , and 10 % to perform action 3 ?"
311398,"if the outcome is invariant over time , why would you want to include multiple time points ; what is the goal here ?"
311415,"could you please elaborate on the procedure you followed by "" adding ( or subtracting ) a random value of the measurement based on the validation data of the instrument i used "" ?"
311417,do you want to do something about the trivial loss function $ l = 0 $ ?
277649,"it's adding ` w ` , ` y ` , and ` z ` . you can confirm this by creating a new column that's the sum of those columns , then seeing that the value of the test statistic is the same . what are you trying to do here ?"
312606,"this will depend on what you want to use the adjusted temperatures for . if you simply subtract the outside temperatures , then your adjusted data are the difference between the measured and the outside temperatures , and that may be exactly what you want . can you clarify what you want to do with the adjusted data ?"
312662,what is the domain of $ x $ ?
312601,"my first reaction is that by your use of the word influence , you are looking for a causal relationship . were these data generated in such a way that you can infer causality from either approach ?"
313241,are you saying the correlation between x and y is 0 . 3 ?
313043,your brackets are extremely difficult to read . can we simplify your term to the following ?
314148,"of course 4 . 33 and 8 . 55 differ--mathematics tells you that . could you please explain what these numbers * mean * or * measure * , how they might be related to your data , and what you mean by "" significant "" ?"
314153,"it is difficult to see how b was computed from a . could you give an example or two , or interpret some of the rows of b ?"
314256,"your analytic , clustering situation is unclear . you have 10 nominal ( with possible responses a b c ) variables v1 to v10 ( ten attempts ) . does it matters that two respondents make the same ( or not same ) choice in the _same_ variable ?"
314420,is that you want to create a ( zero mean ) variate whose correlation with another variate is precisely some nonzero specified value and correlation of its squares with that another variate is zero ( i . e . homoscedastic data cloud ) ?
314626,"mcmc is not an optimization method at all , it is a method for generating random numbers . given this , it is not at all clear to me how you could be using mcmc to train a model . are you sure that is what you are doing ?"
312933,what $ p $ -vector in your description means ?
314830,"do you know that derivatives of constant multiples , sums , and quotients of differentiable functions are differentiable everywhere the denominator is nonzero ?"
314937,could you add details about what kind of time series the $ a_i $ form ?
315010,how would scaling have any effect whatsoever on collinearity ?
315286,"the sw test does not test skewness . how , then , are you measuring this negative skew and what value does it have ?"
314414,can you please show some code of what you tried already ?
315861,which type of model / analysis you plan to work on ?
316020,what do you know about p ( x ) ?
316503,"haven't you simply got six different predictors then , each of which can be coded with a 0 / 1 indicator variable independently ?"
316960,there is not enough here to provide an answer . what is your treatment ?
317127,are you trying to control the family wise error rate or the false discovery rate ?
317131,what are you trying to predict / model ?
317148,most likely you are encountering some kind of singularity in your loss function . could you post the exact loss function here ?
316574,what is the definition of your characteristic function ?
317648,"what do you mean by "" step-by-step examples of machine learning without computer "" . . ?"
318044,"this question has been flagged as "" unclear what you' r asking "" , but isn't it clear it is about interrater agreement ?"
318071,this setup seems incomplete . what are you trying to infer ?
318263,have you tried reformulating your anova into a regression can controlling for the confounder ?
315545,"if my internet connection stays up , i should have time to get back to this over the next couple of days . which definition of more in the tails is that ?"
318322,why don't you just increase the penalty parameter ( $ lambda $ ) rather than possibly making the problem a non convex optimization problem ?
318762,do you want to ascertain extent of biasness or analyze the characteristics ( e . g . number of responses for taller etc . or what ?
318744,why are the summary stats changing for frequency and recency ?
318158,"it's not entirely clear to me what data you're working with . i quote : "" however , only the risky samples are actually being manually investigated , i . e . labelled . until now , a fixed model has been used for classifying samples into high risk and low risk "" . you write only the 'risky' samples are labeled - but what are the actual labels , 'risky' and 'not risky' ?"
318860,"the $ xz $ term is called an * interaction . * your question appears to be answered at url is that the thrust of your question , or are you trying to ask something different ?"
319303,in what sense are these predictions arbitrary ?
319427,"do you want the 4 categories as your outcome , or occupied yes / no ( in that case time would be a factor , if you model both party and present occupancy , or past occupancy could be a factor when modelling present occupancy ) ?"
319539,how much data do you have ?
319689,"are they mentioning "" one hot vector "" in google's word2vec paper ?"
319785,"another set of considerations you should add to your question , to get a more useful answer : what is the distribution of expression among different rna species , and how much do you care about detecting rna species with low levels of expression ?"
319629,two things i don't yet get : how did you define ( find ?
320546,"is your main hypothesis "" that $ p_1 $ is a better predictor for $ b_1 $ than $ p_2 $ is for $ b_2 $ "" ?"
321144,"hint : this is simpler than you think . if you determine there is ( say ) a 95 % chance that $ log ( y ) $ will lie between $ a $ and $ b $ , what does that tell you about where $ y $ is likely to lie ?"
321283,"it's impossible to answer this question unless you give us much more more information . we need to know 1 ) the actual problem you're working on ( you're doing regression instead than classification , but which kind of regression ?"
316254,"assuming you're conditioning on $ x $ , $ e ( x ) = x $ , but how are you inverting $ x $ ( or $ e ( x ) $ ) there ?"
228920,did you find out what was causing the problem ?
322791,"a couple questions . when you say you have 400 observations for each variable are you saying that you have , per university 400 observations per variable or per university , per year ?"
323428,"to help clarify your definition of "" direct "" - would generating a sample from a gaussian ( 1 , 2 ) distribution be considered "" indirect "" if the method was to generate a standard gaussian variate , multiply by 2 , and add 1 ?"
323598,"confidence intervals do not tell you how confident you could be about the results , neither they tell you about the chance of value being higher or lower ( see other questions tagged as [ tag : confidence-interval ] , e . g . url ) . what exactly do you want to achieve ?"
323398,welcome to the site . i don't quite understand how the data are structured . is your timeseries a single univariate series of length $ n $ and the rest of the $ m-1 $ columns of your matrix are the features ( $ m $ possibly greater than $ n $ ) ?
323520,can you clarify your question ?
323845,can you state clearly your biological question and provide a sample of your data ( or simulated data with the same structure ) ?
323208,have you investigated what ties are in a knn and how categorical variables might cause them ?
59089,what do you mean summing ?
303176,have you got any further with this ?
324960,"if you live in a condo or apartment in the city and like to compete in marathons and other mass races , then lawn mower statistics is irrelevant to you , while terrorist threat is relevant . also , following that logic we shouldn't worry about ebola . we're not going to get sick , some folks in remote places will , so who cares ?"
325345,do you know what the degrees of freedom for the $ chi ^ 2_ { nu } $ are ?
325371,"just to be clear , are you aware of [ scientific ( exponential ) notation ] ( url ) ?"
325357,why do you need these constraints ?
325432,"running a robust regression , both the coefficients as well as the p-values are even more significant . which other regression analysis you have conducted ?"
325505,haven't you assumed $ x_t $ and $ x_ { t-1 } $ are independent ?
325780,why did you use box-cox ?
325818,"never heard the second definition . and i don't see how retraining the algorithm is semantically connected to being parametric / nonparametric . however the statistics / machine learning / data science / ai communities are notorious for being inconsistent with names , sometimes using different words for the same concepts or the same names for very different concepts . . . so it's possible some sub-community uses "" nonparametric "" in a non-usual way . do you have any example of litterature where these researchers do so ?"
326194,how did you get that equation for detailed balance ?
326305,can you give the whole example that can be reproduced ?
326200,are you looking for $ det ( a ^ { -1 } ) = det ( a ) ^ { -1 } $ ?
326917,you assumption ( that the dataset is much larger ) is wrong . why wouldn't you use all instances if you have them ?
327108,"210 cases ( rows ) in not too low for a factor analysis of 75 variables ( columns ) . they are almost thrice , that's not bad . i don't understand why kmo and bartlett's test are not displayed - does spss issues a warning or error ?"
327146,"what do you mean by "" includes "" ?"
327350,how large are your samples ?
327449,"if the null hypothesis is true , do you have any reason to believe the outcome measures would have different distributions ?"
327620,are you asking why you should use dropout in that configuration or why you would ever use a dropout layer ?
327389,shouldn't it be $ var ( ax ) = a cdot var ( x ) cdot a ^ { t } $ ?
327888,is statistical significance really relevant to the problems of calibration ?
328405,what parts of this problem are known and what parts are estimated ?
328459,"to clarify , do you just know the minimum value , and not the time at which it occurred ?"
328505,""" simply speaking , i want to reproduce v1 , v2 and v3 in dat with larger sample sizes . "" why do you want this ?"
327487,are you using a single model to make predictions for all units ?
329662,are you referring to differences in the fixed effects ?
329778,there is not enough information to answer your question . but why don't you run an arch-lm test which is specifically suited for identifying presence of arch effects ?
330156,it is very unclear what you are asking . what equation do you want to improve ?
330169,is this with or without replacement ?
330773,a dataset with 5 samples and you are speaking about outliers ?
91114,"nice . for odd numbers , you could probably approximate it with the average of the result for bounding even numbers ?"
331539,how exactly would t-test tell you anything about performance ?
331822,"they look different , but bimodality usually refers to modes in a frequency distributions , not peaks in a ( seasonal ?"
332089,have you tried smaller values for $ epsilon $ ( e . g . $ 10 ^ { -8 } $ ) ?
332458,"since you just have four seasons , is there a reason you don't try incorporating a random factor by using ` lmer ` in the ` lme4 ` r package ?"
333227,"your use of the word "" risk "" seems a little non-standard . if i'm interpreting correctly , "" risk "" means "" relatively unlikely "" to you . ( ordinarily , it is related to the possibility of an adverse outcome weighted by its chance of occurring . ) so , to apply your sense of "" risk , "" why don't you just report the chance of a bracket relative to the most likely one ?"
333498,"assuming that the $ x_i $ all have the same distribution , it's $ 1 / n $ as above . do you mean for it to be generic normal distributions , with possibly differing means and variances ?"
333646,"the green line has pretty much the 0 . 42 slope you see in the acf . that seems too match actually quite well . maybe you expected this to be more clearly on a line , rather than a "" blob "" of seemingly independent data points ?"
333881,"to get the 75 % quantile , use ` qnorm ( 0 . 75 , 200 , 10 ) ` . to get the percentile for the value of 75 , use ` pnorm ( 75 , 200 , 10 ) ` . look at ` ?"
334071,"given the rewording of the question ( which is still not really a sharp question ) consider that calling ` rnorm ( 1 ) ` in ` r ` gives a normally distributed random variable using the box-muller transformation ( i consider generating by computer to be a natural phenomenon , but it is easy to do a physically experiment as well ) . it does not seem to me that this involves any kind of summing of small components ( although there may be an extremely pedantic way to characterize it as such ) , i . e . , the normal in the box-muller transform does not arise from the clt . does that answer your question ?"
335270,""" * we need to find a hypothesis function which will be close to the target function . * "" you lost me here . can you please provide a reference you are trying to follow ?"
333929,"fwiw , correlation between residual and value is not "" regression to the mean . "" such a correlation rarely occurs because most models are flexible enough that they * guarantee * its absence . are you sure this correlation exists ?"
335846,"think of the 1d case and extrapolate . if you had a single independent variable and a single output , how would you visualise trends in the output for similar input ?"
335906,"what is the goal of your research , i . e what are you trying to estimate ?"
336227,"just a question to clarify what you mean by "" attribution "" : the attribution of the store in this would be 10 % and the the attribution of social would be 5 % , is that correct ?"
336627,can you clarify the study design ?
337002,"perhaps not the right forum for programming language specific questions , but points is already assigned by the data block and the data parameter of the stanley call . you should assign values to the outcome array in the transformed data block ( seems like you are doing something like it in the model block ) . your data does not seem to tell you the outcome of the individual matches , would you not need them ( i guess depends on the game and your assumptions ) . you seem to assume that team a vs . b and team b vs . a are independent outcomes is that intentional ?"
337487,"this is too abstract and over summarized to answer . what are these variables , and what do they measure ?"
337973,what $ f ^ n $ stands for ?
337968,could you be more precise about what kind of help you're requesting ?
338092,do you want to compare a single train-validation-test split with nested ( aka double ) cross validation ?
337635,"clarification , are you looking for the proof of this formula ?"
313340,why do you need a pmf ( probability mass function ) for $ x / k $ ?
338129,care to show the plots and disclose the sampling frequency ?
337390,is it possible to have documents of equal importance ?
27640,can you give more context ?
232135,1 . why the demography tag ?
339730,why is this a statistical learning problem rather than a data provider problem ?
335648,""" this net performs pretty well "" - what does "" pretty well "" mean ?"
339705,i don't think the unbalance in the number of 'predictor variables' can cause a problem . why do you think it can be ?
339656,"is it a possibility to convert textual data to numeric by calculating product descriptions properties like length of description , number of words etc , what actually represent your concerns about the text ?"
338935,"you should look at scatter plots regardless of whether you wish to proceed further and regardless of sample size . you are more likely to make mistakes if you don't have a good feel for your data . that said , "" the relationship between soft tissue and hard tissue "" is not likely to be clear even to people in your field . are you e . g . measuring amounts of hard and soft issue ?"
340296,welcome to cv . it is difficult to guess what may be the issue without additional information ( what problems do you encounter ?
340199,"you are making * two * independence assumptions . ( 1 ) $ p ( a = 1 , b = 2 ) stackrel { ?"
340576,can you describe the ideas underlying the algorithm you're using to get the estimate of the coefficient ?
340984,normal distribution or standard normal distribution ?
96828,"can you solve this problem under the more restrictive assumption that $ b = ( 1 , 0 , ldots , 0 ) ^ prime $ ?"
341488,which experimental design did you use ?
341563,what exactly are you trying to obtain ?
341616,isn't this a question for the developers of the ` gbm3 ` package ?
341557,"1 even more to the point : unless this is a strange exam indeed , the responses to the questions will be strongly correlated . if $ x $ is the total score * for an individual , * this will preclude a binomial distribution . could it be possible the question is operating under a "" null hypothesis "" assumption in which all examinees are independently and randomly guessing all answers ?"
341722,"what is "" multiscale approximate entropy "" ?"
340738,"i saw your comment under peter's answer but the answer got deleted so i cannot reply there . if you want any advice , then please edit your q to specify : how many streams you have ?"
342568,"unconditionally they are independent , unless you only draw one $ lambda $ for all $ n_i $ , which is a special case . usually we assume that $ lambda $ varies from one $ i $ to another , though . is that the assumption you're making ?"
342795,"by "" which of the molecules went through the biggest change "" , could you please tell me its meaning ?"
342838,can you plot the scatter plot between pairs of variables ?
342728,hint : what happens when you drop one variable ?
343105,are $ t $ and $ q $ assumed to be independent ?
341107,are you set on using an sem-based framework to address this problem ?
9313,are you specifically looking for a review of algorithms or a more general look at the methods and design of studies ?
16611,"welcome to the site . the power may indeed be an issue . can you post your results , so that we could be more specific ?"
20939,"this will be difficult to interpret indeed unless you constrain the ratio of the third and second coefficients to equal the ratio of the fifth and fourth : otherwise the two harmonic terms are potentially out of phase . harmonic representations are not very good representations of seasonal temperature fluctuations , anyway : have you considered using a cubic spline instead ?"
32392,"you may need several books , depending on what you want to cover , & how far you want to go . so a list might be helpful . also , it would help to know something about the level of mathematical difficulty you want ; are you looking for mathematical statistics ( mainly proofs ) or applied statistics ( primarily conceptual understanding ) ?"
40775,its not clear to me why you want to scale your features ?
44181,"if i'm reading your second paragraph correctly : a random sample of raters will assess a random sample of emails , where raters do not rate the same set of emails ( conversely , emails are only rated by a subsample of the pool of raters ) . is that right ?"
69938,"when you say "" different datasets "" do you mean the same dataset ( ex : wine dataset ) which has been partitioned into different dataset or are trying to compare variable importance in the wine dataset with variable importance with iris dataset ?"
70293,"if you literally want such a probability ( which is eminently reasonable ) you need to supply additional information in the form of a * prior distribution * ( over a set of possible distributions ) . then bayes' theorem does the rest . there are other approaches to addressing needs similar to yours . for instance , a "" non-parametric prediction interval "" uses data drawn ( independently ) from a * totally * unknown distribution to erect an interval having a specified chance of including $ x $ . that doesn't involve computing $ p ( x ) $ , but perhaps it addresses your needs . which approach do you want to take ?"
78328,"by "" the jose and douglas book "" , do you mean pinheiro and bates' * mixed-effects models in s and s-plus * ?"
88451,is the difficulty just the relationship between raw and central sample moments ?
91346,"this could become very tricky depending on how you want to handle distance between non-identical observations . it's simple enough to say two users aged 22 and 23 are more similar to each other than to a 64-year-old user , but it's harder to say someone listing los angeles as a hometown or location is more similar to someone in hollywood vs . someone in long beach , and harder still to say that a seventh day adventist is more similar to a lutheran than to a catholic . how about two users who like several non-identical tv shows vs . a third who only likes books ?"
92251,gung what is it about this question that suggests it is routine or a standard textbook exercise ?
93924,"i see no controversy there at all . no hint of contradiction . the "" rule of thumb "" is apparently not doing what you seem to think it's doing . look it up . what's it * for * ?"
97119,what's the distinction between $ x_1 $ and $ x $ ?
97901,is this some kind of seasonal model where the season is 10 months / years or something like that ?
99139,"for this analysis to make sense , the scales for each of the 6 variables would have to be the same . ( recall that anova compares means . ) if you used the same scale for each variable , then some form of repeated measures anova may be appropriate . how many managers and facilities do you have ?"
99738,"what you want doesn't exist , and to be blunt , it doesn't make much sense . we can discuss alternatives but you need to state more thoroughly what are you trying to do . why do you want to fit a logistic model with an l1 loss ?"
100077,"if the constant variable x has a constant measurement error , and the errors are used only to weight the variables in a relative way , isn't this situation equivalent to not having errors in x ?"
100850,"sample kurtosis is given by closed-form expressions ; there are differing formulas , but i've never seen that which one to use depends on what distribution you think you have . perhaps you mean is there a closed-form expression for the probability density function of kurtosis when sampling from a gaussian ?"
101399,why would you want to ?
103030,can you post your path diagram ?
102949,you're predicting x from y or y from x ?
103843,"graduate-level textbooks are usually rather specialized , with titles like * negative binomial regression * , or * time series analysis by state-space methods * . can you be more specific about the area you're interested in , or * are * you looking for some kind of overview ?"
104148,"it is hard to tell whether you are asking about the effects of re-expressing "" predictors "" --independent or explanatory variables--or response ( dependent ) variables ( or perhaps both ?"
104357,"what do you mean with "" can require the knowledge of dispersion "" . do you have some measure ( like covariance ) precomputed ?"
104404,"could you augment your question to explain what you mean by being a "" necessary or sufficient condition "" ?"
105133,"andrej , are you interested only in the case where the components are iid standard normal ( as your figure depicts ) or are you interested in the more general case with an arbitrary covariance matrix $ sigma $ ?"
105565,"just asking for clarification : what exactly do you mean by "" unit-level dummy "" ?"
105838,what is your sample size ?
106121,"sebastianraschka : i am wondering if my answer here was useful , or do you have any further questions about these issues ?"
106298,"for each independent variable , do they have the same distribution ?"
108157,what is the purpose of this process ?
109304,have you checked out gaussian process regression ?
110262,well $ ( n-1 ) s ^ 2 / sigma ^ 2 $ is only $ chi ^ 2 ( n-1 ) $ if the sample is taken from a normal distribution . is that the case in your question ?
110715,you obviously mean a homogeneous poisson process right ?
110970,i've taken the liberty of adding the ` self-study ` tag since this seems to be unambiguously a textbook question . please see the [ tag wiki info ] ( url ) . is there any information / condition missing ?
111865,do you want a specified * population * correlation ( which the sample correlation would be close to ) or a specified * sample * correlation ?
112858,"did you mean $ s ( t ) $ and not $ f ( t ) $ , which is usually reserved for the density ?"
113308,"to what does "" that dataset "" refer ?"
113437,"* why * are you comparing "" samples "" ?"
113650,do we know how many heads each coin got ?
113824,"you will have to be more descriptive about what "" very non-stationary "" means . does the series exhibit seasonality-cycles ( non-stationary in the mean ) ?"
114001,are you sure this is the question you want answered ?
114231,i don't quite understand the data . can you put some column headings ?
114761,"what do you mean by "" stronger results "" ?"
115521,possible duplicate of [ does an unbalanced sample matter when doing logistic regression ?
116198,"regarding the second question , this "" particular variable "" is again an exogenous variable ?"
116524,are a and b the only two events that are possible ?
116737,how does a pareto distribution imply nonlinearity of y x ?
116789,"what does "" of course , this works , no problem . "" mean ?"
117000,what do you mean by 'missing the relevant columns of data' ?
117987,is this a problem for a course ?
118629,why do you think that wald's general equation applies in your case ?
119834,"the formula you link to can never be negative when supplied with valid input , so how are you obtaining $ -2 . 99 $ ?"
120507,is the dependent variable binary as well ?
120569,"i formatted the mathematical expressions in your question . please ensure they're correct . there seems to be a $ ( $ missing in the last expression . the included questions say that $ c4 $ "" is a function of $ n $ "" , is there any more information given about what it is ( perhaps in your lecture notes or somewhere ) ?"
120901,this question really isn't objectively answerable without some information about what the images represent and why you are comparing them . would you care to edit it to include such information ?
121285,could you give a more thorough description of data ?
122773,can you give some examples of these misclassified elements ?
123738,"i don't get it : if your models use only the data where there was nonzero effort , then what would be the reason to create such a superfluous matrix ?"
124372,and what does your model tell you ?
124791,"you need to clarify your question . for instance , do you mean the iv is relevant , but the second stage coefficient on the endogenous variable is insignificant ?"
124925,what does $ g_i $ represent ?
124951,what are y and n ?
125864,"you might be conflating a number of issues into one . * * first * * , a very low p-value of dickey-fuller test tells that the null hypothesis of the test is very unlikely to be correct . since the null hypothesis stands for the correctness of a particular ( integrated ) model , you will reject it . it does not straightforwardly lead to accepting that the series is stationary , though . but if heuristically you would say "" the series is stationary if $ p-value 0 . 05 $ "" , then that holds for $ p-value = 0 $ , too ; why wouldn't it ?"
126856,defining your slot ( ?
127029,"could you clarify what you mean by regressors being "" related "" ?"
127094,a critical point that needs clarifying : for how long after the first day can rolls be sold before being destroyed ?
127363,have you xtset your data ?
128813,is there any noise in this process ?
129259,"what did azzalini have to say about it , when he defined it ?"
129357,why would empty cells make you use fisher's exact test ?
129682,"i may be totally wrong , but should "" real state "" be "" real estate "" ?"
129843,do you have the formula to calculate the rating change after a game ( i guess not ) ?
131093,can you share the r code & output that prompted this question ?
131178,"this question is difficult to understand because ( 1 ) you do not distinguish between * experimental * and * model * variograms and ( 2 ) it is impossible to tell what you mean by "" unbounded . "" all exponential variogram models are bounded ; all experimental variograms are bounded ; everything in your graphs is clearly bounded . what exactly does "" unbounded "" mean then ?"
131339,"to what "" problem "" do you refer ?"
133410,"some of our threads , like [ what is the difference between a population and a sample ?"
134133,"do you mean "" probability that someone has * at least one * queen "" ?"
134550,kjetil could you explain further ?
135589,"ummm . . . the metric is the correlation . ( actually , you are far better off minimizing the * covariance * . ) another issue is that you can't just enumerate stocks to include in the portfolio : you have to choose * how much * of each one to buy ( even when the amounts are quantized into "" investable chunks "" ) . in light of this , it's hard to determine your question . what are you asking about ?"
137097,"could you provide references for those "" several papers "" or , if references are not freely accessible , direct quotations ?"
137582,how would you use loess to transform a variable [ n . b . not in statistical terms a parameter ! ] ?
137710,"this makes no sense , given that those logs often are * negative * : what would it mean to "" sample "" from a negative quantity ?"
138450,is there an algorithm to predict user's locations especially for new user ?
138601,what do you mean by ` data sets are different ` ?
139015,"you say ` not just put check-marks but rank ( 1 , 2 , 3 ) ` . or rate ?"
139632,"in practice , you * never * know population variance . so when you are asking if there are any benefits to presenting cis constructed using sample variance -- benefits * as compared to what * ?"
140513,"i don't see the contradiction here . if they are only suggesting the standard approaches , what is the relevance of that specific pdf ?"
141547,"tom , can you show your math ?"
141984,what's your task exactly ?
142109,what does $ y sim x $ mean ?
143072,"k ( x * , x ) should be a 0-vector if x * is actually far away from the training points x . have you checked its values when you get a prediction of -2 ?"
144354,are you interested in confidence intervals for parameters or in prediction intervals for individual predictions ?
145441,it appears that the variables ( 96 columns ) are not related to each other . what does the result of correlation matrix suggest ?
145985,you need to choose a distribution that models your measurement errors . gaussian obviously can't capture the asymmetry . can you put your measurement error data plotted so that we can recommend a likelihood ?
146959,"because the two expressions on the right hand side are identical , the relationship between ` ant pcp ` and ` thold ` is irrelevant , leaving a standard linear model for ` runoff ` in terms of ` pcp ` . most likely there is a typographical error : could you please fix it by editing the question ?"
149849,what do you mean by data loss ?
151208,what is your question ?
151467,"you mean you get less accuracy with the svm , correct ?"
151959,could you provide more information on the input variables of the model ?
152392,would you be able to elaborate on why you need to categorize your data and why exactly three categories ?
152741,do you know the actual times of the observations in question ?
152996,do you mean * linear * * ly * * * correlated ?
153397,""" groups "" of what ?"
154042,i don't understand your plot . what is bid ?
154862,"hint : if $ x $ has value $ 3 $ , $ y $ must have value $ 3 $ or more , no ?"
154996,is [ this ] ( url ) the article ?
155227,( 1 ) how are people who are within 1 sd of the mean assigned ?
155582,are the bits jointly independent ?
155667,"are you aware that as bandwidth , the variable $ h_n $ , or $ h $ in your notation , goes to zero as $ n $ goes to infinity ?"
156070,"you say in the first full paragraph "" all p . 05 "" . did you mean that all p values were less than . 05 ( i . e . "" all p . 05 "" ) ?"
157661,"it's not clear what you mean by your question 1 . question 3 seems too broad as it stands , since one could write a lot about each . could you review the wikipedia pages on the mean , median , standard deviation and mode , and then ask something more specific ?"
157747,"welcome to cross validated ! do the answers [ here ] ( url ) , [ here ] ( url ) , or [ here ] ( url ) help ?"
158167,"what is the "" naive frequentist method "" ?"
158319,you really have a nested model so you do need to have your r code alone the lines of ( 1 sample / participant ) to account for the nested structure . also can you give some more info about the response ?
158647,"this is a pretty broad request , clint , and so it might be considered too much to handle in one go . have you searched our site for threads about ar ( or arima ) models , [ tag : time-series ] , forecasting , and related terms ?"
158985,"you could just use the option ` sei ` in ` rma ` and provide the standard errors directly . otherwise , use se $ ^ { 2 } $ with ` vi ` . and do you have the standard errors on the log-scale ?"
159822,"i do not understand the remarks in ( 1 ) . how can $ c ( t ) $ be a correlation , given that the notation suggests it could be any function of $ t $ ?"
160446,you need to clarify what kind of data you have and the precise goal . it sounds as if you have data on variation within days ( hourly ?
160709,"by r2 do you mean $ r ^ 2 $ , the coefficient of determination ?"
162511,could you elaborate on what sense you think it treats ties incorrectly ?
162682,is this daily data ?
162723,what exactly was not covered in the answer you refer to ?
164200,what is your quantitative background ?
164534,"the a-d , correctly applied , works just fine when the parameters are estimated : see the wikipedia article at url it's difficult to see why this test would be terribly useful for quality control . what kinds of manufacturing processes have perfectly normal deviations ?"
164713,"so you want to calibrate ( = tune ) your raman spectral measurement set-up . you have some known chemicals with known spectra which you will use calibrate the set-up . after calibration , do you want to use your system to distinguish a few substances , or do you want to distinguish dozens of substances , using an raman spectral library ?"
164732,"can you share more , or perhaps a paper link or citation ?"
164801,what about kernel logistic regression with perhaps a polynomial kernel ?
165014,consider $ a = 0 $ . what's the correlation between $ z $ and $ y $ ?
166459,"could you please explain what you mean by "" b ( exp ) "" ?"
167238,"how big is the dataset , and what kinds of estimators will you be comparing between the sampling methods ?"
167491,are the $ x_i $ independent of the $ y_i $ ?
167909,can you provide more context ?
168138,how did you transform the dependent variable ?
168208,"( 1 ) there are good ideas here . you have overlooked one * really important * component of variability , though : the conditional distribution of $ y $ . your approach takes no account of it . thus , it could ( at best ) give intervals for the * conditional expectation * of $ y $ , but not for the values of $ y $ itself . in order to do that , you must either assume or deduce something about the shapes of those conditional distributions . ( would they be normal , for instance ?"
169634,"in your last expression ( "" before tidying "" ) there is dependence on $ y_t $ ( assuming that is the same as $ y ( t ) $ , which cannot be right , since this is the expectation of a function of $ y_t $ ?"
169785,so a point in another site ( even if the sites are neighboring ) wouldn't be expected to have any auto-correlation - only samples sharing the same site ?
172727,"presumably , you make some assumption that implies $ f_t $ and $ p_ { t 1 } $ are uncorrelated ?"
173572,could you give a little more detail on your data ?
173844,"this reminds me of the old joke , "" i always carry a bomb when i travel , because what are the odds of * two * people having a bomb on the same plane ?"
174252,maybe look at something like this with the caret packge ?
174636,are the number of categories fixed regardless of the number of subjects ?
175437,"what is your understanding of the "" expected values "" requested in ( a ) ?"
176103,do tickets come in more often during certain months ?
176386,"you are asking two different things . do you want the var ( $ { bf y } $ ) , which is the variance-covariance matrix of the responses ( and is , by model assumptions , equal to the n by n matrix $ { bf sigma ^ 2 i } $ ) . is it the variance of $ { it one } $ observation , so that it is , by definition , $ sigma ^ 2 $ ?"
177040,"possible duplicate of [ how to generate correlated random numbers ( given means , variances and degree of correlation ) ?"
178737,about which of these steps are you uncertain ?
178779,is your question about the alternative covariance formula ?
179612,( 3 ) doesn't state anything . did you leave something out ?
180533,welcome ! currently the question is very close to an excel operation question and will likely be flagged as off-topic and closed or moved . perhaps you can revise it to focus on how to treat the cells with missing data when applying anova ?
181331,what is your balanced accuracy of the no information model ?
181454,this paper may be useful * do we need hundreds of classifiers to solve real world classification problems ?
181649,can you provide a full citation for the article ?
182117,what happens when you solve $ 0 le z-t le t le 1 $ for $ t $ in terms of $ z $ ?
182326,you most likely have some form of an interaction between x1 and x2 . what is the correlation between them ?
182837,"which single approach would be best seems a very hard thing for someone to tell you if they can't see your data ! would you be content for someone to tell you what options you have rather than which is "" best "" ?"
184648,"looking at the answers , there appears to be some confusion regarding what you mean by "" kernel "" . what definition of "" kernel "" are you using ?"
184949,"could you clarify what you mean when you say "" x is the vector containing all of these points side by side ?"
185154,have you read white's papers on this ?
186054,sufficient for what goal ?
186433,"for this to have a definite answer , i think you had better make some assumptions about $ alpha $ : what happens to $ exp ( - alpha t ) $ for large $ t $ when $ alpha $ is negative ?"
186889,did you read this : url ?
187924,are you using mplus ?
188597,why you have used xreg = diff ( diff ( xreg ) this in your auto . arima model ?
188631,why are all factors added ?
189050,have you considered incorporating daily effects / holiday effects and / or level shifts / local time trends while adjusting for errant data ?
190121,could you write out the model ?
190278,"your question is a little ambiguous . when you say "" gradient with one derivative at a time "" do you mean co-ordinate descent , gradient descent or some other algorithm ?"
190536,"please include whatever information is necessary to understand & answer your question . few people will want to navigate elsewhere & read a bunch of material to answer your question for you . moreover , we want this thread to continue to have value for future readers after those links have gone dead . can you reframe this to stand alone ?"
191893,"i'm sure i'm misunderstanding this problem . are you sure you don't mean "" the number of people with a degree is less than 20 ?"
191917,"what do you mean by "" same distribution "" ?"
192316,"what do you mean by "" l1 and l2 come up in the same loss function "" ?"
193676,"we need more information . six metrics , got that , but measured at how many points in time ?"
193724,"how does "" productivty of tool "" have to do with the answers to the 10 questions ?"
195055,what do you mean by bespoke ?
196791,what kind of data do you have ?
196923,what's $ varepsilon $ ?
198327,do you need to sample from adjusted model ?
198829,what is $ y $ ?
199501,"vikramnath venkatasubramani : it looks close to canonical discriminant analysis , in concept . may i suggest you to reply and add some details on how to do it with a huge dataset ?"
199600,what is the purpose of ci for you ?
200127,"welcome to cross-validated , abdul . it's best not to assume that segments of your audience that can help answer your quest has discipline-specific knowledge . to that end , could you edit your question to spell out lstm before you start using the acronym ?"
200365,i'm having a tough time following the question . sounds like you are hinting at computing conditional probabilities like p ( aa c ) and are asking about controlling for cases like p ( b aa ) and p ( c b ) ?
200704,"1 . by "" twice "" , do you mean "" exactly twice "" or "" at least twice "" ?"
200898,"oh , that's the "" source "" , right ?"
201854,see the ` self-study ` [ tag wiki ] ( url ) which explains something about how these sorts of questions are asked and answered . what have you done so far ?
202007,"( 1 ) what does "" $ n_p $ "" stand for ?"
202233,where are you getting stuck ?
202778,have you tried the latest development version ?
203090,you know the distribution of the $ i $ -th order stat from a iid uniform sample ?
203359,"first of all , your notation is misleading . it should be something like $ y_i = f ( x_i , beta ) varepsilon_i , varepsilon_i sim mathcal { n } ( 0 , g ( x_i , theta ) cdot sigma ^ 2 ) , i = 1 , ldots , n $ . then , package nlme does not offer a polynomial variance structure . you can combine variance structures , but it's a multiplicative combination , not additive . why do you believe that this specific variance structure fits your data ?"
203726,can you clarify what model you fitted ?
204191,"please check that your code makes sense . in particular , ` 0 . 01 * n-1 ` is almost never an integer in your calculations . the manual states this value is "" the number of white balls drawn without replacement from an urn which contains both black and white balls , "" so how can it be non-integral ?"
204475,"why do you speak of "" confidence intervals "" in your title but don't mention them again in the question text ?"
206637,"is the intent of the question to indeed ask about somehow evaluating / approximating the density , i . e . , samples from the posterior predictive distribution are not enough ?"
207070,can you refrase your question ?
207613,"( c ) is easier than it might look because the substitution $ z = ( x y ) ^ 2 $ converts the expectation into an expression that is a multiple of $ gamma ( 2 ) = int_0 ^ infty z exp ( -z ) dz . $ for ( b ) , what can you say about $ operatorname { var } ( x y ) $ ?"
208901,it is unclear what you are asking . do you mean reporting mean and se of regression parameters ?
209651,it depends on what your research question is . what * is * your research question ?
210303,"in that case , wouldn't you use a simple squares-of-differences technique to see how each varies from the true underlying value ?"
210012,the lsmeans package supports betareg models . look at ?
210972,what questions would you seek to answer / what information would you seek to obtain using this model ?
212436,this seems to broad & tangentially connected to ml to me . can you make it more focused & concrete ?
213277,how do you obtain the second line ( the expression for $ p ( x pi ) $ ) ?
213672,"it isn't possible for a pearson correlation to be 1 . 2 , because pearson correlations are limited to [ -1 , 1 ] . did you make a typo ?"
214244,where the interventions assigned by randomization ?
214934,could you provide a minimal code example ?
215280,this is probably a jensen's inequality issue url . . . can we have a ( simple ) reproducible example please ?
217380,you say that you are going to use regression . are you aware that standard regression procedures do not give the same result as meta-analysis software ?
217451,some assumptions are necessary for there to exist solutions and for them to be unique . what can you tell us about the conditional distribution of $ y $ ?
217471,"tatami there may well be a good reason for it , but context will probably help locate it more quickly . what basis did field use to suggest it was a good idea ?"
217755,this is a deadly language / package specific question formulation . might you want to show your data and your results - so that more people could appreciate and answer ?
217926,"do you ask only about glm for gaussian family , or * any * glm model compared to lm ?"
220382,how can cases with $ k = m = 0 $ possibly be part of the likelihood ?
220420,yeap . . you need to read amoeba's answer [ on how to use svd to perform pca ] ( url ) carefully . you also need to pounder a bit if doing the eigendecomposition of the covariance matrix is really different from its singular value decomposition . ( i also suspect that you have centred that $ x $ beforehand right ?
221775,are the questions getting increasingly difficult as the test proceeds ?
222544,what do you mean results of a rf ?
222609,what sort of data are you looking to project ?
222623,"beginning this question with "" also "" suggests you intended to supply some ( much-needed ) contextual information , but that somehow it was lost in the post . could you restore that missing material ?"
223258,what kind of offset are you referring to ?
223768,"this is unanswerable at present . why are you "" struggling "" ?"
224444,could you provide the reference of the book you quote from ?
224967,possible to add data for reproducing the error ?
225148,r is open source so why do you not read the source code ?
225333,"1 . is the sample part of the "" general "" ?"
225642,what do you mean assign probability ?
226031,how do you transform ordinal variables into dummies keeping the ordinal relationship ?
228250,"if $ q ( x ) = 0 $ , why would you even include that term in the sum ?"
228489,"can you either provide an exact statement of the problem , or an accessible link to it ?"
228812,"an important issue concerns the extent to which those forecasts might be linked . for instance , the lower ends of each interval might be predicated on a gloomy economic outlook while the upper ends might depend on a rosy picture . what makes one forecast go up or down could affect the other in a similar way . if , on the other hand , the forecasts were for a product and its replacement , and the uncertainty was associated only with how much substitution might occur , then what makes one forecast go up would make the other go down . can you provide relevant information about the linkage ?"
228845,"i did not receive the notification of your comment . next time try writing "" richardhardy "" in front . sorry , but i am pretty busy these days . i would have helped already if i had been able to . your situation seems tricky . could you plot your data and include some test results ?"
231203,try not removing the index $ i $ when doing the calculcation . what does it mean when $ i = 1 $ ?
231832,how many features / samples / classes do you have ?
233984,what do you call ` regressors ` in that context ?
234136,"i think that given that you have data from one instrument thought to be a gold standard , this is clearly a question of concurrent validity . what's not entirely clear is what it is you don't know . do you not know how to establish concurrent validity , or do you know how to do it but you're not sure about the specific statistical test for your data ?"
235044,"are you checking a small number of fixed orderings chosen a-priori , or are you sampling at random from the $ 10 ! = 3 , 628 , 800 $ permutations ?"
235715,can you paste in the plot & the data ?
233931,"( 1 ) does "" whp "" mean "" with high probability "" ?"
237062,"it is incorrect to treat missing values as zeros--unless that's what you intended "" na "" to mean . so what does "" na "" actually indicate ?"
237689,what do you mean by seeing clusters by pca ?
238627,can you say more about the background of this scenario ?
239618,why do you specifically want an ensemble method ?
239666,"given that a cell of a matrix is a * single number , * could you explain what you mean by "" marginal row probability "" and "" marginal column distribution "" ?"
240167,"are there other independent variables you're interested in , or is it just code of conduct ranking and profitability ?"
241029,why can you not take a log ?
241159,are you referring to the predicted values of the logistic regression ?
241279,how is the sampling performed ?
241453,"i would rely on the definition of the data itself . for instance , postal code in the us is a 5 or 9 digit number , but treating it as "" continuous "" in a predictive model would be a mistake as it is really massively categorical . this analogy holds for your information as well . what does your categorical variable * mean * ?"
242326,this question appears to be one of speculative psychology : it invites us to guess the intentions of the author . is there any statistical content to your question ?
243359,this question seems perhaps more about the semantics of the test writer ?
244062,i think internally r makes the polynomials orthogonal by doing a qr decomposition ?
244399,"please elaborate on what you might mean by "" missing something . "" how are you thinking about this problem and what solutions have you attempted ?"
245541,what software are you using for the ` auto . arima ( ) ` function ?
245546,"it might help to be a little more specific about your problem . for instance , do you have a fully repeated-measures design , and if so , how many conditions , and are the conditions purely categorical ( i . e . , there is no implied order ) ?"
245659,what is the x-axis in your graph ?
246086,what do you mean clusters ?
246218,what will be the outcome of your investigation ?
246693,"it is not clear what do you mean . what "" negative binomial "" do you use ?"
247352,could you describe the data you have ?
248202,"can you explain what are your variables , e . g . categorical , counts , etc . ?"
249403,so you want a value that separates the two distributions the best ?
251520,what is unknown the power l ?
251780,do you think this model used time-varying predictors ?
252217,"what does "" right most of rvs $ x_1 $ and $ x_2 $ moves to the position of rv x "" mean ?"
252315,"do you mean that in models with each variable by itself , their coefficients are different than when all of them are used together ?"
252491,why not show us your data-set by editing in the result of head ( kripasdata ) or str ( kripasdata ) or summary ( kripasdata ) ?
252545,"if i had to do it , i would use a random forest . i use 'r' though , and some folks will take umbrage at the "" particular package "" . you might rephrase it as "" i prefer python , but i'm just looking for a general approach . is this a public dataset ?"
252904,i think you could remove all reference to software here and still have a valid question . perhaps you should try it ?
253605,"maybe a more answerable question would be , "" ( for any given predictor ) over many trials of such a procedure , how would that set of 10-fold-based averages compare to a set obtained using fewer than 10 folds each time ?"
253724,is the first image on the right or the left ?
254023,do people not normally take logs of reaction times ?
255920,what is your modeling goal ?
256715,what response ( outcome ) variables are you trying to explain or predict ?
256939,can you elaborate on the disutilities you are referring to ?
256819,"i am just reading your question again , did you measure ` brainvol ` for both hemispheres in each subject ?"
258470,could you edit your question to include a little more information about your more complex aggregation constraints ?
258522,"harvey motulsky , you changed the meaning of the question when you altered the title . the question clearly describes comparing two proportions . it's not about comparing a sample proportion to a specific value . did you even read the question , look at code to simulate this scenario , or notice the call to ` pwr . 2p . test ` ?"
260439,"what does it mean when your write : apples 10 / 12 / 2013 : mean = 1 . 8kg , s . d . = 0 . 5kg n = 20 ?"
261643,are they using the same cross validation loop to * both * choose algorithm hyperparameters * and * report an estimate of hold out error ?
261834,are you _summing_ up the 5 items' scores for each respondent ?
262542,"at present , this is too broad to be well answered here . can you narrow this down & make it more concrete ?"
263109,can you expand a bit ?
263392,i can't quite understand the question . are you asking about the pdf of the sampling distribution of the euclidean distance ( a scalar ) between two correlated variables ( realized in some sample size ` n ` ) with correlation $ phi $ ?
265099,"simon sheather and chris jones use the term "" plug in "" -- is that what you mean by "" solve-the-equation "" ?"
265740,is anomaly the same as an outlier ?
268451,"of course pca "" makes sense "" as a description of the data . evidently , then , you have something more in mind : but what is it ?"
268578,what exactly do you not understand in those threads ?
268609,"what's meant by _ "" small distribution "" _ ?"
269583,"could you explain what your term "" adjustment "" is referring to ?"
270337,you realize that we can't read this due to bad formatting ?
270587,it depends on how you are going to use the results and on the data available to you . why don't you explain the particular problem you are trying to address ?
270894,"if you run monte carlo to provide training samples , you must specify a model , so what is the point in learning this model later ?"
271164,"what if $ x in [ 0 , 2 ] $ and so is neither larger than 2 nor less than 0 , what is the distribution of $ y $ in this case ?"
270604,it depends on your data and your assumptions about them . could you provide specific information to help people formulate good answers ?
271258,"i am unable to reproduce these results . for instance , the mean of the sample is 4 . 132523 , which hardly differs from ` mu ` at all , so i cannot obtain anything like these statistics . what exactly is the distinction between ` mu ` and ` mean ` in your code ?"
271814,is it a homework ?
272314,what do you mean by computing it visually ?
273236,geomatt22 some of the singular values are numerically equivalent to zero . what are you supposed to do in this case ?
274685,have you tried drawing what power law relationships look like ?
275111,""" random function "" leaves too much unspecified . do you know the probabilities these functions assign to to each cell ?"
275552,"boxplot works for showing data distribution for any variable of interest , including variance , but have you considered showing how much the mean itself varies within each run , i . e . how much of the variability can be due to the "" random "" part of rf itself ?"
276130,what do you mean by robustness ?
276542,what do you want to do with the model ?
276657,can you tell us more ?
277627,"that helps a lot . however , could you be more specific about what this "" variance estimate "" is attempting to estimate ?"
278052,what is $ x_i $ ?
278496,does the denominator have a square root ?
279053,it is not clear how you get this histogram of prior percentages . how do you get the pairs ?
279712,"please tell us more about those "" error terms . "" unless you make some assumptions about them , too , how could you know what your model is saying ?"
280519,have you tried to implement dropout ?
280984,do you have the standard error of the difference between the means or just for each of the two means ?
281127,"i am no more enlightened . what do you mean by "" percentiles that are not exact "" ?"
281094,"1 . probably not ; most programs report two-sided p values by default ( if not , how would it guess which tail you want to test ?"
283392,"in what sense do you mean that a "" marble "" ( thought of metaphorically as some iterative procedure to seek a minimum ) could be a "" loss function "" ?"
283410,are these two different problems ?
283530,"if by "" overall "" you mean the pdf of a randomly chosen interarrival time ( choosing the $ w_j $ with probability $ 1 / ( n-1 ) $ , then yes , the pdf is just a mixture of each pdf . but perhaps you mean something else by "" overall "" ?"
283877,have you also plotted the true positive rate ?
283909,it's hard to say without reproducible code . did you normalize the training set ?
285825,"what do you imagine "" hebbian learning "" entails ?"
286190,"could you clarify what "" same distribution but with a larger variance "" might mean specifically ?"
286295,that seems very broad . can you expand a bit on what situations you think they might differ and which the same so someone can help you better ?
286743,"i can't tell if there is enough information here for this to be answered . from the numbers you post , you should almost certainly not be doing classification or feature selection . can you clarify your situation , your data , your analyses , & your goals ?"
287351,welcome to cross validated ! could you edit the question to explain what comparisons you're making between the results of the two tests ?
287483,"since the formula for the statistic works perfectly well when $ a_ { 11 } = 0 $ , and gives a finite value , what do you mean by "" not defined "" ?"
287666,how do you propose to deal with the nonzero probability that this expression will be undefined when all the $ x_i = 1 $ ?
288623,"could you tell us why you would belabor the explanation of a phenomenon you found to be "" insignificant "" ?"
291728,ryan tell us what have you tried so far ?
292119,"what do you mean by "" significance in respect of distribution "" ?"
293809,the red line is tilted -- can you explain how you're drawing it ?
294616,how are you calculating standard error ?
294633,it's unclear what you're trying to ask . could you give more precise specifications ?
296182,how do you compute . 4111 and . 2577 ?
296568,could you describe in words ( or in mathematical formulas ) what you are trying to achieve ?
297447,could you tell us more about your problem ?
299017,"the groups don't seem similar any way when the maxima vary over several orders of magnitude . again , we need more substantive information ( than zero ) . why blank out interesting detail ?"
299839,"could you explain the intended * meanings * of these weights and what you hope the "" multiply weighted "" average would reflect ?"
300051,"welcome to cross validated ! you'll need to edit your question to add some context & detail before this can be answered . what's are "" the databases "" ?"
302171,did you check how ` conv ` is handling the data at the edges of the range of ` x ` ?
303271,could you explain a bit more about what your data actually is ?
303852,"i have never seen any work on this , my guess would be no . what is the application / motivation for this ?"
304168,is $ p $ known ?
306701,1 . you should add the ` self-study ` tag ( as a signal to potential answerers ) and see the discussion on homework-style questions in the [ help / on-topic ] . 2 . do you understand the meaning of the indicator notation $ mathbf { 1 } _a $ ?
309075,"it is troubling that the angle is not well-defined . choosing the cut at $ pm pi $ , although conventional , is not adapted to the location $ ( mu_x , mu_y ) $ of the distribution . this lends an element of arbitrariness to the question ( and it will surely emerge in any good answer ) . could you explain the purpose of computing this variance ?"
309792,try to do an f-test ?
310300,"i think the question is really with what accuracy i can tell that i see 0 . 2 of total orders . otherwise , if you are sure you get exactly 0 . 2 , you are sure the order volume has grown 100 % . is this right ?"
310608,if these are per day why do you need to normalise them ?
311366,could you clarify the difference between the first set of n = 500 images and the second set of n = 1000 images ?
311689,best in terms of what ?
312248,"you're assuming too much and need to say more about the models , e . g . , what is "" its heckman counterpart ?"
312317,"there are relevant theorems here , but whether you need one depends on your definition of "" absolutely continuous "" : which one are you using ?"
312674,"what do you mean by "" correcting "" ?"
313896,"what do you mean by "" predicts "" ?"
316362,is this homework ?
316894,do you assume the other parameters are known : variances and mixture weights ?
318667,"the number of animals is measured once in survey 1 , correct ?"
318732,i don't see that n is well defined ?
319015,you seem rather confused about what you are trying to do . if the link which adamo provides does not sort out your problem can you edit your question to give us more details about what precisely your scientific problem is ?
319420,do you want us to debug your code ?
321187,unclear to me - if you dont have labeled data points how do you expect to estimate fpr and fnr ?
322360,perhaps you should edit in why you want to do this ?
322634,"what do the numbers in the "" a "" and "" b "" columns mean ?"
322684,"thank you . you seem to articulate two different questions . most of your post focuses on assessing whether a previous incident increases the chance of another incident of the same type . but at the very end , you are comparing recurrence rates between two types of incidents . what is the question you want to ask ?"
323480,why would you divide by $ n-1 $ when you assume the mean of each row is the zero vector ?
323734,"so , you would be happiest with a upper envelope to the data , e . g . the upward-pointing part of a convex hull ?"
323806,your question is unclear . you seem to start from two places : stationarity and the condition on the coefficient magnitude . what is your question about ?
324290,how do z and w relate to x and y ?
324434,"can you define what "" regular "" and "" dominated "" mean ?"
326129,are the tests independent and are they a representative sample of the population for which you want to express the confidence interval ?
327400,what model are you using ?
328096,what would you be inferring or testing ?
329619,what is the point of using a recurrent neural net if your desired output is independent of the previous observations ?
329630,what are you trying to do ?
330017,it's not a classification problem unless you discretize your continuous variable . have you tried other models than ols ?
330379,( 1 ) what definition of the square root of a matrix do you use ?
331973,to some extent this question may duplicate the existing [ why does convolution work ?
332778,moving average implies some sort of time series . was the first case a time series ?
336766,"you already mentioned some very good resources ( e . g . the hyvarinen et al . book and tutorial paper ) . these contain exact descriptions of both the principles and math involved , and also example cases . perhaps you could say more about what the remaining confusion is , or why these were unsatisfactory ?"
337136,it's hard to understand the problem you're trying to solve ( something about identifying geographic features from spatial points ) . could edit the question to describe this in more detail ?
340206,"i tried my best to parse this question into an understandable form . in the paper it looks the "" z "" is not fully unobserved but has a set of indicator variables for the population structure . . . something i don't totally understand . you refer to "" flexible nonlinear forms "" . . . but of what ?"
340557,value at risk has different ( but related ) definitions in banking and insurance . are you referring to the tail var common in insurance applications ?
340671,what norm did you use ?
342006,"in your first choice , if $ h $ is uniform , the there isn't a unique ml estimator . are you using of a posterior of some sort ?"
343003,can you explain the notation of your display at the bottom ?
344528,when you talk about adaptive selecting do you mean what i am suggesting ?
344658,"do you mean * * multivariate regression * * ( multiple * dependent * variables ) , or * * multiple regression * * ( multiple * independent * variables ) ?"
345061,"are you looking for [ hamming distance ] ( url ) , perhaps ?"
345870,"to clarify , what type of variable is your response ?"
346129,it belongs to infinitely many families . but how would identifying one of them be relevant to any meaningful statistical question ?
346425,"` stats : : decompose ` takes in the data as a parameter , not an arima model ( no arima models are involved in this seasonal adjustment at all , so the previous step is unnecessary ) . whether you should use additive or multiplicative seasonality depends on the data ( does the seasonality increase with the level ?"
346149,"log marginal likelihood scales linearly with the number of training examples . so if you want to compare those for different numbers of training examples , you need to normalize . furthermore , are you evaluating based on the training accuracy ?"
344945,can you specify whether or not you know the number of observations less than $ t $ ?
345117,you seem to be using leave-one-out-cv - in which case the loss for the ith fold should be the same as the absolute difference between y_i and the model's prediction . i think your formulas for the variance then just go through as normal ?
347432,"i don't see that trimmed means are any more problematic than anything else for moving windows . any way , what technique do you seek ?"
345184,yes i didn't explain well but added more detail for the gaussian case . what is the practical application of this ?
347523,"last comment : - ) your last model indicates that you are interested in a model with nested random effects but in the ` machines ` data it is actually _not_ the case that ` machine ` is nested in ` worker ` - rather , these variables are crossed . in fact the last model "" tricks "" ` lme ` to fit a model with a random main effect of ` worker ` and the random interaction for ` worker : machine ` . was that intentional ?"
347589,what is t ?
348095,isn't this a sort of object recognition problem ?
348502,"what do you mean by "" hold "" ?"
348862,"why cannot you combine your 200 matrices into one big matrix of 10 , 000 rows ?"
348753,"more on the constructive side - i think you should rephrase your question to explain on what grounds you base this argument , so that people can respond to something concrete . you make 2 assertions , do you have either references or a logical argument to support either of them ?"
349067,can you provide a bit more detail on what you're planning ?
349280,"what do you mean by "" double "" value ?"
349278,"this seems trivially false since ito diffusions are closed under "" nice "" functions ( like the conditions of ito's lemma , say ) . so if $ x_t $ is a brownian motion ( therefore an ito process ) , then $ y_t = e ^ { x_t } $ is also an ito process , and has lognormal distribution at a fixed time . was there a particular reason you expected this to be always normal ?"
348697,"ordinarily , "" mean "" and "" expected value "" mean the same thing for distributions and therefore require no comparison . why have you tagged your question with "" weighted-regression "" ?"
3,"maybe the focus shouldn't be on "" valuable "" but rather "" pros "" and "" cons "" of each project ?"
555,"if i am not mistaken , linear regression is the estimation of coefficients that define a good linear map from x to y . anova is a test to know if there is significant differences in x when y take two different values . can you explain us why you think they are the same ?"
1012,"what is "" not meaningful "" about the standard deviation of a uniform distribution ?"
1081,one remark -- expand nmds . is it just non-metric or something more exotic ?
1223,possible duplicate of [ simple algorithm for online outlier detection of a generic time series ] ( url ) this question is proposed to be closed as a duplicate . could you please let us know at the meta thread if and how your context is different from the question i linked ?
1521,duplicate ?
2066,do you want to know the mathematics or simply a code solution in r or some such ?
2326,many questions : 1 . is it an experiment or an observational study ?
2510,i may be missing something but i agree with whuber . i do not see why you need an approximation g ( x ) when you have h ( x ) ^ and in what sense will any other function g ( x ) be better than h ( x ) ^ ?
2613,"the mcnemar test is designed for paired data , isn't it ?"
3064,is your dependent variable continuous or discrete ?
2639,do you really mean you have 1 observation from a ?
3259,"i am not an expert but i found the sentence "" controlling for associated subscores when devising cut-off scores on each dimension of a measurement scale "" a bit esoteric . can you give me one more line of explanation ( otherwise i found it difficult to understand the question ) ?"
3425,"tal , could you show us some of the data ?"
4017,cw ?
4225,could you provide a link to the welch paradox ?
4288,"i don't understand what you're trying to do here . to estimate propensity scores you need to know whether each individual received the treatement or not , in which case you can simply count up how many received the treatment . why do you want to aggregate propensity scores ?"
4639,"this question has been downvoted . i didn't intend to give my 1 , but it seems to me now that voting it down is not very constructive : ( 1 ) the op makes clear this is homework and uses an r built-in data set for illustration , not his data , ( 2 ) a related question with ` step ( ) ` has been rated 2 at the time of this writing ( so why ?"
4884,what is an ab-test ?
4988,"i am curious : why did you specify the "" graphical-model "" tag for this question ?"
5114,in your question you have $ p ( x = 2 ) = 0 $ and $ p ( x = 8 ) = 0 $ . do you mean : $ p ( x 2 ) = 0 $ and $ p ( x 8 ) = 0 $ ?
5479,could you please add what are you trying to model ?
5746,what exactly is different about your problem ?
6079,could you explain where the 82 / 15 / 3 values come from ?
6400,"could you explain what are $ y $ , $ x $ , and $ z $ ?"
6838,this is a very interesting question . is it possible to play at least with a subset of anonymized data ?
6975,can you please be more specific about what kind of data set do you have ?
7040,comparison of region 1 and 2 on what metric ?
7156,"alexander , are you interested in the * change * in the level of corruption or are you interested in detecting a change in the * rate * of increase or decrease of corruption ?"
7246,i currently have exactly the same question . did you get any clue on this ?
7389,"levon9 ok , i reverted the title back to the original one . about general policy on title and question wording , please refer to meta , [ is there a style guide that provides guidelines for question title and question content ?"
7571,"i'm a bit confused , perhaps by the title . are you wanting to interpolate between two time points or are you asking about something like smoothing ( as opposed to filtering ) ?"
7790,how were the groups chosen ?
7791,also are you assuming that you'll always see him if you visit the dojo on the same day as him ?
7990,is there any motivation behind why the process is the way is is ?
8029,why would you be squaring the variances in the second code snippet ?
7996,can you really fix velocity and number of vehicles and vary the area ?
8157,how is that ` a_i ` follows distribution ` p_i ` and is also less that ` c ` ?
8236,"is this a raster dataset , such as a ( processed ) remotely sensed image , or is it an irregular dataset ?"
7903,this is a tough problem because you have very little information about the nature of the cheating . how do you differentiate a cheater from a student who studied extra hard ?
8606,"interesting question . you should add "" hats "" to your estimates , so that it is clear which quantities you are talking about ( hypothesis refers to true values - others places refer to estimates ) . also , are these upper and lower bounds "" plugged "" back into the optimization routine to get a new estimates of upper and lower bounds ?"
8639,"it takes only the most casual acquaintance with winbugs to answer this question as stated ( i . e . , does winbugs actually process data ?"
8702,do your boxplots take into account the fact that your repeated measures are within individuals ?
8784,how do you know one can't just look at the 'size' of the coefficient ?
8795,"clearly the data this graph is based on are not derived from tossing a coin and appear to be continuous , not binary . could you tell us what the substantive question is you're trying to answer ?"
8960,when you say you have the histogram - do you mean also have the information about the observations or do you only know the bin width and height ?
9104,is your ` size = 100 ` a typo ?
9266,"in brief , this question in its current form appears to ask "" how can i cluster a [ poset ] ( url ) "" . as your point # 1 indicates , this question is not answerable ( nor is it of any statistical interest ) until you can quantify similarity or dissimilarity of subsets . you have provided a nice example of what you're looking for but all you reveal about the basis of the clustering is that you "" imagined it "" ! so : can you specify what would constitute a "" cluster "" ?"
9385,"elizabeth , could you provide a data so we can test on other statistical packages to see whether the problem is in excel or in data or general applicability of exponential smoothing to this particular data set ?"
9533,"did you try to do pca , project into a lower-dimensional space and estimate the covariance there ?"
9629,"in the second case , are you assuming you know the total sample size ?"
9736,"can you clarify what you mean by "" predetermined correlation "" ?"
9749,"what were your "" unexpected results "" and did you do $ { 9 choose 2 } = 36 $ pairwise comparisons ?"
10096,did you look at the [ changepoint ] ( url ) tag ?
10111,"it looks like you're confused about f-test for testing two variances ( in the nrc 3rd ed . , i read ` prob = 2 . 0 * beta . betai ( 0 . 5 * df2 , 0 . 5 * df1 , df2 / ( df2 df1 * f ) ) ` , where ` f = var1 / var2 ` , in the section entitled "" 14 . 2 . 2 f-test for significantly different variances "" ) vs . one- or two-way anova . what you described suggests you're interested in a one-way model ( you have one response variable and one explanatory variable , or factor ) and want to conduct a statistical test about the effect of the factor with an f-test while providing a measure of effect-size with the eta-squared . could you confirm ?"
10322,"sounds silly , but how about choosing on the basis of colour ?"
10386,are the real data also sinusoidal ?
10424,"why not use robust , non-parametric summaries like median , iqr , mad , letter statistics , and so on ?"
10594,do you have any idea what probability distribution your variable follows ?
10855,"to get a useful answer , you'll need to provide more information . what does your experiment consist of ?"
10920,shameer i was curious about a few things in your problem : are data points the same as categorical attributes ?
11054,maybe you should just try regular boosting ?
11289,have you tried truncating the random variables ?
11459,has there been random assignment of cases to conditions ?
11436,you probably meant $ l_p $ metrics for the sequences rather than $ l_p $ for functions ?
11609,your assumtions that p ( e c ) = 1 and p ( e c' ) = 0 are unjustified . why do you state that if the actual interval does not contain the true parameter value this latter one is surely outside it ?
11945,"since it is not log-log regression , without constant you have not the elasticity interpretation as you wrote . why you believe that log transform is needed ?"
11957,"in order to get the most useful answers you may need to break down your question into more digestible parts . i , for one , could use clarification on : why do you need multiple groups ?"
12432,"dvs do not have to be normally distributed ( and almost never are ) , but for some tests it is helpful if the * residuals * do not depart too far from normality . for this purpose it is best to * plot * residuals rather than conduct formal testing ( such as ks ) , because the plots reveal much more and the tests tend to be * too * powerful . so , just to be clear : are you referring to the actual dvs or to their residuals in your characterizations of normality ( or lack thereof ) ?"
12453,"not without more information . what were the dialogue , women , color combinations ?"
12651,is bias in standard errors ( of parameters ?
12733,"clarification question : the scalar time series you talk about are the * column * vectors of the given matrix , and the states at any one time are in a * row * , right ?"
12888,i don't the first sentence in 2 . ?
13004,why did you stop at $ x ^ 3 $ ?
13014,"just to clarify : when you say you are looking for rigor , you don't mean "" statistical rigor "" , i . e . you don't necessarily need the combined test to give you accurate probabilities of type 1 and 2 errors , right ?"
13264,why not just tabulate them ?
12721,"the only awkward part seems to that you think product choices depend on products , their categories * and the choice in the other category * . perhaps you'd like to elaborate a bit on this last dependency ?"
13395,what's in the y axis ?
13887,does [ this ] ( url ) answer your question ?
13979,"hi ! you can't run a regression where dependent and indepedent varables ( one independent variable ) have different degree of integration . seems to me that there is a regime shift about t = 18 . according to the figure there is no overall deterministic trend , but change in indeterminstic trend can be modelled by using a dummy-variable . try a model where both variables are differenced . is it yearly data you are using ?"
13990,"this description sounds like either * spectral anomaly detection * or reduction of dimensions and clustering via [ tag : pca ] . given that your description and question are so vague , could you indicate specifically what kind of plot you are interested in the anomaly detection paper ?"
14061,shouldn't the integral value of a * proper * density estimate be $ 1 $ ?
14092,"you already have reasonably strong evidence of the logarithmic trend , even using only the data for s = 10 , 20 , 30 , 40 , 50 ( which avoids worries about high leverage with s = 40 or 50 ) and very strong evidence that there is * some * kind of trend . in addition to that , what more are you looking for ?"
14219,300k dimensions with how many rows ?
14241,seems like an interesting problem . could you pls elaborate on your model ?
14524,could you pls give the details of your data ?
14856,"first , regarding scaling benchmarks , this is pointless , as you will eventually discover . for example , every language stores an 8 byte double in 8 bytes , and every major language supports memory mapping , so your limit is only what you can afford in terms of ram or hds . does r scale beyond terabytes ?"
14946,are you looking for the _loadings_ of the pls rather than the regression coefficients ?
15032,"what non-linear model , specifically ?"
15064,could you provide additional criteria that would help narrow down the possible distributions ?
15319,the wilcoxon signed rank test you linked to is for paired data . you don't seem to have paired data . are you trying to see if the mean is different from 0 ?
15391,"i think that your pretend example doesn't match your real case . in the pretend example , if you want to show that people of a given age are about the same height , you can just report the variance of height for that age . but if you'd like to show that all the people of a given age are about the same height , i'd report the range of values . but then you start talking about measures that combine the variances or something across different groups . so apparently you want to say something not about people of a particular age , but about people of different ages . but what do you want to show ?"
15549,"i am puzzled because the sample sds you report are inconsistent with binomial observations . for instance , if fertilization is observed in 70 % of eggs , the sample sd * must * equal $ sqrt { 0 . 7 times 0 . 3 } $ = $ 0 . 46 $ , not $ 0 . 18 $ . could you explain how your sample sds were arrived at ?"
15550,have you seen [ diehard ] ( url ) ?
15692,what level of sophistication are you looking for ?
15818,"you posted some probabilities associated with 'title' and 'body' , each set of 10 probabilities is making reference to a document ?"
15839,"not everyone here uses r to read in your file format . please give your data in more convenient format ( plain text , excel ?"
16054,"could you post an image of a "" problem "" ?"
15947,i'm not sure why the ratios are important . are you trying to just determine if a change 'significantly' lowered system or real time ?
16270,are you doing one mixed within-between anova or are you trying to compare between two separate rm-anovas ?
16287,could [ procrustes analysis ] ( url ) help your point 1 ( comparing how close the model shape resembles the input shape ) ?
16835,"i fear this question may not be well-posed ( yet ) . for example , some order statistics may have well-defined means , even when the mean ( or variance ) of the distribution is undefined . second , the parameterization of a particular family of distributions may not be closely related to the variance . are you , perhaps , interested in some restricted class of distributions , such as * [ location-scale families ] ( url ) * or similar ?"
17123,"suppose you added or removed other balls ( not labeled in $ k , k 1 , ldots , n $ ) from the urn in such a way that the probability ratio of your two events stays constant . would this matter ?"
17231,aren't you really just asking for the first two moments of the sampling distribution of covariances of multivariate normal rvs ?
17367,"as an example , you could create a sample of points consistent with the observed ones and then simulate a random field of marks at those points conditioned on the observed values . variations of angle can be handled in various ways , such as by means of a bivariate distribution of ( cos , sin ) values . if there is a dependency between the point locations and the marked values , a more creative solution will be called for . but are you really in such a situation ?"
17451,could you please try to ask several shorter and more defined questions ?
17537,shouldn't we merge this question with [ the same one ] ( url ) asked last year ?
17654,"it is unclear what your * real * question is . it is obvious that no function can look like $ chi ^ 2 ( 1 ) $ ( which is an exponential distribution ) and still essentially be supported on $ [ 0 , 1 ] $ , so there's a question about your characterization . do you need to determine the null distribution of a test statistic ?"
18053,i must not being understanding something . you specified in the problem that $ sigma_ { y_2 } = sigma_ { y_1 } $ . so the relationship is just that they're the same ?
18231,dbr in that case you should edit the question to make it accurate / correct . you are not using all the information that has been given to you . what about the information on the earnings of someone who is 66 inches ?
16969,"if you know the correct answer , why do the analysis at all ?"
18389,could you provide some sample data ( preferably generated with just a few lines of code ) ?
18499,"what kind of "" dependence "" are you looking for specifically ?"
18538,"matt : glancing at your data , it looks like they are both upward trends . so are you essentially interested in the hypothesis that one cohort is increasing more quickly than the other ?"
18835,"it is difficult to understand what is being asked here . my guess is that you are considering uniform random permutations of an array $ ( x_i ) $ of $ n_f $ copies of $ f $ , $ n_m $ copies of $ m $ , and $ n_a $ copies of $ a $ ; your random variable $ y $ is the shortest distance between $ m $ and $ f $ ( * i . e * , $ min { i-j : x_i = m , x_j = f } $ ) ; and you want to compute the expectation of $ y $ . but your "" toy problem "" is confusing because the shortest distance can * only * equal $ 1 $ or $ 2 $ , but the probabilities you assign do not sum to unity ! in what respect ( s ) is my guess incorrect then ?"
18882,"you are kind of asking , "" i'm a dentist , and one of my patients has a brain tumor that i need to remove . what is the best way for me to operate ?"
18937,"do you mean "" latitude "" instead of "" tilt "" ( which is , for these purposes , essentially constant ) ?"
18969,are the data / time series whose discrete fourier transforms you are computing via the fft algorithm real-valued or complex-valued ?
19127,"what precisely do you mean by "" parameterize $ y $ "" ?"
19300,are you sure your code is correct ?
19326,"roughly how many elements , and how many mice ?"
19066,what is the basis of those calculations ?
19804,"to clarify , when $ x_i c $ do you observe a zero or a missing value ?"
19827,"i assume that "" without putting the first one back _after_ the second "" is a typographical error for "" without putting the first one back _before_ drawing the second "" . given that the first marble is green , how many marbles and of what colors remain ?"
19845,"the integral itself is always $ 1 $ for a continuous distribution , because the numerator equals $ e_ { i , j } $ almost everywhere ( and presumably $ e_ { i , j } $ is the pdf of the joint distribution ) . or perhaps it is intended in some special sense ?"
20114,* how * does the dependence manifest itself in your case ?
20157,tom isn't the ` gbm . fixed ( ) ` located in the [ dismo ] ( url ) package instead ?
20209,"mbaitoff : thanks for the further details , that is helpful . is you main interest actually in * sampling * from such a distribution ?"
20243,should this be community wiki ?
20366,"i agree that 0 . 5 looks smooth and yet shows a reasonable trend . it feels un-statistical to talk about "" looks "" , but i don't know enough to go beyond that . what does the detrended data ( i . e . residual after subtracting your loess trend ) look like ?"
20628,notice that the two forms of your question are not equivalent : it is not necessarily the case that minimizing the sum of squares of distances from the surface gives the best estimates unless a strong assumption is made about the nature of the perturbations . it would therefore help to know more about how the perturbations occur ( and how large they may be compared to the sphere's size ) . also : in how many dimensions is your sphere ?
20641,"the answer to ( 1 ) is well known and [ easy to find ] ( url ) . as for the rest of the question , even after reading the so version i cannot understand what is being asked here . perhaps you could present a small example ?"
20848,"well done ! please note that in the last graphic the plots are out of order ( evidently the software ordered them alphabetically rather than by x , which is strange ) . the graphics reveal fairly complex behavior . have you held out a sizable portion of your dataset to test predictions ?"
21119,"good question and you seem to be on a "" good track . "" why don't you post your factor loadings and inter-factor correlations after following the smart advice gung has given . that should help people size up the dimensionality of your set of items . ( but what do you mean by "" parallel explanatory factor analysis "" ?"
21415,can't these integrals be computed exactly ( symbolically ) ?
21503,sounds as if you have confirmed that the same device will produce very different sets of numbers . what else are you looking to find out ?
21590,"if you have a regression towards the mean , are you comfortable that the measured behaviour was a reliable indicator of overall behaviour at the time ?"
21768,cardinal posted a useful comment to the [ earlier version of this question ] ( url ) . what research have you done in following up on that comment ?
22015,what is your ultimate study objective ?
22073,"can you say what methods you've already looked into , what seems to work and what difficulties you're facing ?"
22417,"reyman , could you post your code and a sample of the way you calculate the pits ?"
22450,"i could be wrong , but isnt the answer you want basically the cdf of a multinomial distribution ?"
22627,"10 , 000 samples how big each ?"
22749,2 . computing $ h ( x_j ) $ means taking a simulated $ x_j $ and applying the function $ h $ to this value . . . what is the problem with this ?
22765,a lot of code to churn through in a few minutes . care to pinpoint out your problem where you think it goes wrong ?
23099,"question : you say "" i know how to interpret the above . "" but the title of the question states otherwise . what is correct here ?"
23154,"i would like to suggest that your thinking already is well beyond merely classifying images as nominal , categorical , etc . , and that such classification is far too limited and outmoded to be a useful framework for you . you may find it more productive to use your objectives as a point of departure : why are you analyzing images ?"
23582,"isn't the first term reflecting the best strategy , and therefore the best arm , over the period ?"
23833,"hi there , could you describe more about how group , condition , topic , and problem are related to each other in the design ?"
24214,"* * something's not quite right here : * * normally , people understand expressions like $ e [ x ^ p ] $ to be * expectations * of * powers , * but you state explicitly this is not a power . furthermore , $ e [ x_1 ^ p , x_2 ^ q ] $ does not have any conventional sense . do you seek the expectation of the * vector * -valued expression $ ( x_1 ^ p , x_2 ^ q ) $ or do you want the $ ( p , q ) $ moment , which is the expectation of the * product * $ x_1 ^ p x_2 ^ q $ ?"
24439,"mbq , shouldn't it look more like this : $ chi ^ 2 $ ?"
24464,"assuming you _do_ have multicollinearity , can you expand , as rolando2 suggests , on the intended purpose of the model ?"
24681,very nice . but are they the * only * loss functions justifying these procedures ?
24977,"out of curiosity , was the first response option to that education question "" my mother never finished elementary school "" ?"
25041,are you calculating cronbach's alpha outside and prior to the code snippet you've provided ?
25272,just for clarification : what's the category that is used as a reference ?
25343,1 . do you have your data anywhere so people can look at it ?
25440,"regarding your edit : you only need size and prob or size and mu . in the former case size is the parameter for target for number of successful trials , in the latter it is the dispersion parameter , namely theta ! both versions are related by prob = size / ( size mu ) . you can extract theta from the glmnbobject by object $ theta and the mean you get by exp ( coef ( object ) ) . see the example below . if you have a regression model , getting the mean is a bit trickier , you need to put in all the values for the x as well . is the latter where the problems lie ?"
25495,what exactly are you trying to chart and what are you trying to show ?
25552,do you mean $ ( 1-e ) n $ and $ ( 1 e ) n $ by chance ?
25756,two questions : 1 . why are you using fourier series to represent your data ?
25875,how do you have two different values for b per person when b was only taken on the third session ?
25946,do the points in b have a one-to-one relationship with the points in a ( eg each is a particular star ) or is it more abstract than that ?
26432,how much lag are you talking about ?
26520,"1 . by "" feature counts "" do you mean "" example counts "" ?"
26609,"starting by formulating a biologically meaningful measure of difference is a very good idea . the problem with "" area between the curves "" is that it is arbitrary and may be meaningless . "" arbitrary "" follows from the fact that area between the curves ( i presume * absolute * area is really meant ) is just their $ l ^ 1 $ distance , which is generalized by all the $ l ^ p $ distances for any $ 1 le p le infty $ . why should $ p = 1 $ be privileged ?"
26781,i'm not sure about your screenshots . could you add or link the full octave code ?
27050,how is it possible that your cost is not changing ?
27248,"i agree with the stackexchange suggestion . i hope someone there will tell you that with 3 data points , there's really extremely little point using fancy methods to compute confidence intervals . without making assumptions about the distribution , it will be almost impossible to nail down confidence intervals . what do you think the 95 % confidence intervals are of { 1 , 2 , 13 } . . . ?"
27346,just to clarify : which results are not consistent ?
27698,have you checked out our [ list of sas resources ] ( url ) ?
27773,i have couple of questions : 1 ) which standard error do you mean ?
27936,"your research question is not clear to me nor the theoretical interrelationships in the data . if you were to block on a variable ( i . e . , do a repeated measures analysis ) would you block on rows or patients or both ?"
27939,why don't you do principal component analysis since the first few compoents may explain most of the variation in the data ?
28018,"what do you mean by "" running the results through bayes rule "" ?"
28047,andy why not ?
28116,"a very frequently discussed misunderstanding , which might be operating here ( search for it ) , is to suppose that skewness in the responses is a problem . in general , it is not . what matters is the distribution of * residuals * . what can you say about that ?"
28437,possible duplicate of [ what are the differences between factor analysis and principal component analysis ?
28398,i think i understand the problem but i am not clear about what you mean by the algorithm converging . is it that the algorithm has a rule that depends on the past number of 1s and -1s chosen and that you want to show it becomes independent of the past as the number of cases gets large ?
28616,"if your code isn't too long , could you post it ?"
28642,"let's say you limit the possible relationships to linear , quadratic , and cubic ones . that increases the possibilities from 190 to 570 . i don't know of a program that will test all such possibilities for you . i think you're going to have to exercise some human judgment . however you approach it , i hope you'll use some sort of crossvalidation . how big is your sample ?"
28807,"with logistic regression with more than two classes , sometimes multinomial logistic makes sense but sometimes ordinal logistic regression makes more sense . if there is an inherent ordering to the classes then ordinal logistic regression might make sense . you mentioned four levels of income . . . is that your target variable or was that just an example ?"
28876,my first thought is to check whether or not you are comparing apples to apples . power depends on the alternative you look at . ar you matching alternative hypotheses in the simulation with the analytical ?
28776,"i tried to run you initial ` mlogit ` call , but got a singular matrix error . could you make the edit that allows me to run this ?"
30082,do the columns have to sum to one also ?
30380,are you talking about new subjects each year or the cumulative number over several years ?
30382,"i suspect you will get loads of tl ; dr reactions to this question , which doesn't bode well for the prospect of getting great answers . do you think you could highlight the key information and remove the less essential parts of this question ?"
30653,what about the distribution of the values ?
30930,what do you think would cause the change ?
30987,i've edited the equation so that it looks nicer . could you describe a bit more about your problem . is $ beta $ a vector or a scalar ?
30995,"it might help if you could list some of your data . also , what software are you likely to use ?"
31195,"how exactly is the "" intervention "" reflected in the data ?"
31400,"the statement "" r help says that the q argument is a ` vector of probabilities ` . . . "" is incorrect . the documentation under ?"
31440,"i think i do not grasp how "" clustering "" and the logistic regression model would interact or affect one another . could you explain the difference between "" clustering "" in this context and including a group identifier as an explanatory variable in the regression ?"
31527,"matt , i am no expert , but i understand that nns can work in difficult-to-characterize ways . if indeed an nn succeeds better than a regression model , doesn't that ( strongly ) suggest that regression methods to analyze the nn will be less than satisfactory ?"
23320,"a couple questions , not directly related to your question , but which may be helpful : i am not sure what you mean by "" splitted the data "" . why is calendar year categorical ?"
27512,"this is a great question and an instant favourite - but i agree it is too broad ( but only just ) . it can be made into an answerable , solvable problem by a ) explicitly stating the audience of the communication ( e . g . you imply an interested lay audience of press and general public ) , b ) explicitly targeting a problem ( e . g . "" how best to communicate uncertainty around a quoted figure ?"
31666,have you collected all of your data already ?
31795,( 1 ) but why do you expect to get exactly 95 % ?
31747,why don't you want to fit the zero inflated binomial model ?
32010,"thanks , josh : 1 . what questions are you asking about these interactions ?"
32040,"you need a year fixed effect if you're going to have a year : group interaction fixed effect . in general , you can't include an interaction term without also including the main effects . do you really think there's no fixed component to the year effect ?"
32620,you have sufficient reputation that you should be able to include the image yourself . are you encountering difficulties with that ?
32696,could you define $ text { vec } ( mathbf { x } ) $ ?
33038,what does the pattern look like ?
33036,are you using scipy 0 . 9 ?
33064,"i would like to run mod2 in order to see how much ram is actually needed . but if i define ` dectime = ( as . numeric ( date ) -min ( as . numeric ( date ) ) ) / 3600 ` there is a ` covariate must have unique values within groups for corar1 objects ` error . also , are you familiar with ` residuals ` and its method ` residuals . gam ` ?"
33348,"there seems to be some confusion in these comments , jason . you appear now to be referring to a collection of about 500 joint distributions , not a single distribution . your original question refers to "" correlation "" in the sense of a "" relationship between age and income "" : that is , the correlation * of a single distribution * ( for a single record ) . these relationships could change from one record to another . now , in the comments , you write of a * different * correlation , one that measures associations revealed by all 500 records . the two things are not the same ! which one are you really after ?"
33359,"can you expand briefly on what you mean by "" applied techniques "" ?"
33448,"first , if you try different models until you hit something that is better than $ x $ % ( in your case $ x = 85 $ ) , you can not in general expect this accuracy on your test set , due to [ over fitting ] ( url ) . second , if you only need a 85 % accuracy , and over 85 % of your data is "" stayer "" , then it will be sufficient to classify everyone as "" stayer "" . third , if your features ( demographics , i guess ?"
33405,can you explain what ` temp_w ` and ` temp_sept ` really are . you say mean but does this mean they are scalar ( same for each observation in same year ?
33566,"rachel : random button presses are just the most extreme form of unreliability . the tester needs to ensure -- to some reasonable extent -- that the measurements are actually measuring the same thing . if you ask a child , an average adult , and a basketball star "" is this fence tall or short ?"
33917,what is your reference on the bootstrap approach ?
34410,the newer versions of stata on 64 bit machines have no problem with datasets this size ( because 5gb easily fits in ram these days ) but have you any interest in commercial alternatives to sas or are you looking only at foss ?
34584,"no , this approach is not valid , because you have only 10 independent observations , not 400 , and there's nothing you can conclude from comparing just two numbers , either . however , you're not asking a question that will help you much . instead of asking about one invalid form of analysis , why don't you share your full dataset ( all 10 numbers won't be hard to post : - ) and ask for advice about how to analyze them ?"
35308,"your understanding seems accurate to me . anomaly detection is a bit too vague a term to answer the question accurately , could you give a concrete example of the data and the type of anomaly you want to detect ?"
35615,"hiberbear well , clustering 7 samples . . . but it is doable . but importance * certainly won't make any sense * here . let's say those are all human genes -- thus you'll get genes responsible for eye color , arthritis and alcohol tolerance mixed together . without decision , how the forest can tell which gene set to look for ?"
35719,how did you find the relationships weren't linear ?
36103,the problem with the last example is that a much better fit is obtained by a function of the form $ y = frac { beta_1 } { 1 - exp ( beta_2 beta_3 * x ) ) } $ ( notice the negative sign ) . is that an acceptable solution ?
36284,what does referent mean ?
36351,some individuals are belonging to more than one species . does this make any sense ?
37386,"the columns contains the series , and the rows the elements of the sequences ?"
37422,"please explain the definitions in the second paragraph more clearly , i . e . whats is $ mathbf { z } $ , $ mathbf { c } $ and $ mathbf { c } ' $ ?"
37564,"you say "" i1 are the variables included in regression 1 "" . is this a placeholder for multiple variables ?"
37584,some computational error has messed up the qq plot for the log prices--you should fix that first . but all this begs a more fundamental question : precisely * why * are you testing distributions ?
37955,"kiudee , if my interpretation of your q is right , what would you think about editing it to add the [ tag : loss-functions ] tag , & possibly revising the title to something like : "" how to design & implement an asymmetric loss function for regression "" ?"
38023,"i don't know the answer to this question , but , on a purely political basis , wouldn't it be better to do what the fda wants and show ( at least , presumably ) , that the results are similar ?"
38323,"what did you mean by "" proble selection "" ?"
38350,"so , you essentially want a mosaic plot with a different sort of fill ?"
38934,""" residuals "" is the normal english term , for future reference . has the comment by whuber on the two different uses of "" i "" cleared up the question ?"
38935,if you have missing cells you cannot use anova . unbalanced just means that the groups have a different size . are there really cells that are empty ?
40337,what analysis are you doing ?
40422,the double use of $ f ( x ) $ is confusing and should not have been used . do you have a link ?
39211,"so you cannot "" average "" the 60 regressions produced ?"
40421,what is your goal from this ?
40507,please could you post the outputs of str ( xx ) and head ( xx ) so that we see the essential of your data ?
40622,"not by much , actually . first question : did you select the "" units "" randomly ?"
40970,"a lot of essential detail is missing here--you would be better off explaining the real problem you're trying to solve . apart from specifying the nature of the random quantities indicated here , what precisely does it mean to award points "" equitably "" ?"
41352,are you sure there is no zero or negative value in y ?
41326,"are all the dimensions discrete , or are some continuous ?"
41362,"all models can be approximated by a taylor series , i . e . a polynom of sufficiently high order . however , if you know the model from the science , you should use it . in fact , the second fit shows that the ` dcl ~ i ( j ^ ( -0 . 5 ) ) ` relationship is significant . now you need to consider how re could factor into this . could it possibly modify the relationship between dcl and j ?"
41822,i am not sure but have you looked at functional data analysis ?
41835,i assume you have multiple 'var's and 'pop's per school ?
43128,how did you get from 39 questions to 13 variables ?
43157,"if the * only * thing you want to know here is how to use graphpad prism , this question is off-topic for cv ( please see our [ faq ] ( url ) ) . do you have a more general question about the nature of repeated measures experiments / analyses , or about the terminology ?"
44271,( 1 ) have you tried making some draws from a beta distribution whose second parameter is close to $ 0 $ and less than $ 1 $ ?
44717,i dont understand why la1 and la2 and lb1 and lb2 * may * be respectively equal . why don't you know ?
44647,"sorry i can't give you a better answer - i'm not that on top of my time series analysis . however , you may also be interested in this question i asked recently ( url ) which is also on climate time series and has a nice detailed analysis on temperature vs co2 from a time series pro . it might help others if you also had some data that you were able to post ?"
44769,of possible interest : [ is there an error in the one-sided binomial test in r ?
45206,"several interpretations of the objective are possible . for instance , do you want to maximize the * expected * number of correct answers ?"
45331,` left-handed individuals are more likely to be homosexual than right-handed individuals ?
45359,"something is missing : "" $ e ( u x ) $ "" is a * number * ( or perhaps a vector ) , not a logical criterion , so it is nonsensical to write that it "" holds . "" what did you intend ?"
45444,"i don't completely understand . are the "" outcomes "" finding something ?"
45686,"if the files are for "" completely different systems , "" then what exactly does it mean to talk about the "" probability of . . . an error "" ?"
45721,"i'm not familiar with this package , but it would seem that there is some problem with ` traindescr ` . can you give us the output for ` traindescr ` ?"
45738,i'm not quite following what it is that's confusing you . why are you worried that survival analysis might not be appropriate here ?
45731,"are you training this periodic function with the x axis as the input , and the y axis as the label for x = 245 , and then testing for x 245 ?"
45994,"one of the awkward features looks to be that not all ids are ranked in each time-specific ranking exercise , is that correct ?"
46010,"i understand that you want to develop a predictive model that estimates the probability that a given patient will be hospitalized , as a function of characteristics described in the patient's medical history as recorded in the cprd dataset . yes ?"
46094,"if you do that , then your posterior is conditional upon $ mu = bar { y } $ , not what you want . you want to integrate out $ mu $ instead . note that in the original paper it starts out with $ mu $ ( separated from $ x $ ) , but on p . 683 , column 2 , they refer to "" marginalizing over $ mu $ . . . "" and the $ n-1 $ appears shortly thereafter . for an analogous take on it , in classical statistics , how many degrees of freedom do you have left after you've subtracted off the sample mean ?"
46015,"if the assumptions are reasonable , you might use either a proportions test or a chi-square . ( this looks suggestive of the classic example of simpson's paradox ; where do the numbers come from ?"
46218,love = favorite ?
46482,this seems like an interesting issue but the length of your question is sure to discourage folks from reading it . is there no way to state your question more concisely ?
46777,how do you know that someone is a customer if they don't place an initial order ?
46925,is your $ h_1 $ that p 0 . 5 or that it is not equal to 0 . 5 ( as implied by your test statistic ) ?
47171,"sorry , i think i don't really understand your previous comment . could you clarify ?"
47179,could you post your data or a sample of it ?
47279,"you should add to your list of assumptions that the variances are equal . on another note , if your alpha is set at . 05 , & p = . 04 , then you * would * reject the null , & the question of the test being "" underpowered "" is a non-issue . lastly , you may find this question of interest : [ is there a minimum sample size required for the t-test to be valid ?"
47101,"can you please clarify what you mean by "" optimization technique "" ?"
47438,"i'm not sure you have a well-defined problem here . if the optimal solution assigns high weights to correlated features , well--that's the optimal solution . to obtain any other solution you either have to modify the objective function or further limit the domain of feasible solutions . what guidance can you give us concerning either of those options ?"
47789,are the points labelled ?
47828,"if you created a histogram of this % difference metric , what does it look like ?"
47849,"well , if removing part of the test set breaks the training , this is certainly a software bug ; have you tried asking the authors ?"
47989,is the actual ratio bounded in any way ?
48009,"can you please clarify what you mean by "" how can i cut some factors of my 22 factors by mean value "" ?"
48345,what definitions of independence do you know ?
48367,"the difference between the two distributions is indistinguishable because the variance of the series swamps any visible difference in the central tendency . a solution then is to approximate the plot the approximated distribution in the chart ( most likley via some running , smooth estimate of the series ) . examples can be found at [ preferred methods for graphing time-series data to present averages ?"
48441,"so if i'm interpreting this correctly , there are a number of series ( a , b , c . . ) , each of which is sampled at a number of points . however , the times at which a is sampled are not the same as the times at which b is sampled . is that right ?"
48455,"peterellis , is right . an analysis w / both categorical & continuous variables is often called ancova ( note the "" c "" ) . it may be that this is what you were advised , & you mis-heard or they accidentally mis-spoke . typically w / ancova you are primarily concerned with the categorical vars , & the continuous are considered nuisance vars ; also traditionally ancova means you don't have interactions b / t the continuous & categorical . but all of this is subsumed by multiple reg , so you can do as you like . what is the deal w / your 5 dvs ?"
48558,what regression tree algorithm are you using ?
48651,the package ` lars ` in r . i wondered why it wouldn't turn up on a google search of say 'least angle regression in r' . . . but for me it's the top result . did you not google ?
48678,"what are you doing when b is not available , so log ( x ) is undefined ?"
48688,are you getting very high variances for coefficient estimates when both ` month ` & ` effort ` are in the model - compared to what you see when you put each in separately ?
48989,"hi , cam . it would be helpful to see some output to potentially help diagnose things . note that what you've done is recoded things by creating two main effects and effectively removing an interaction ( though the model is equivalent ) . also , are you controlling for exposure or just modeling raw counts ?"
49052,is the 'x' dimension in the above graphs time related ?
49413,"can you please clarify your question . defining ( nonstandard ) initialisms like nts and cts would help . what are "" some of the gaussian properties "" you are hoping to retain ?"
49763,"just trying to understand the data , is "" hero combinations "" ( column a ) the name of hero 1 ?"
50262,"cardinal you're right , but it seems to me the underlying problem is not just about stata syntax : it's about how to make these comparisons in the first place . user20971 , could you expand on the first paragraph ?"
50681,i am also recently using the hhg measure for my research . and the output of the corresponding r package is confusing . have you solved this problem ?
50708,"i don't quite follow your terminology . when you say "" i and j are observations . . . "" do you mean you have two series $ x_ { 1 , t } $ and $ x_ { 2 , t } $ , in which case you would be better off dropping the i and j and going with $ x_ { 1 , t } $ and $ x_ { 2 , t } $ or even $ x_t $ and $ y_t $ . or does it mean something else ?"
50763,"are you already familiar with matrices , e . g . , through an applied linear algebra course , or is that part of what you are seeking to learn ?"
50765,can you be more specific about what issues your classifiers appear to be having ?
50929,dear max : is that _statistical_ or _r_ language question ?
51428,pardon my ignorance ; but what was the evidence for overfitting that you refer to ?
51470,"john , could you tell us what you hope to accomplish by this fitting procedure ?"
52147,"this is really no different than estimating confidence bounds for any other function of the parameters . the main difference , if any , may be that the * correlation * among the parameter estimates could play an enormous part in the estimates . do you at least have access to some information about this correlation ?"
52177,the odd thing about this seems to be that the correlation of -0 . 4 suggests that diamonds which are longer across the top are shorter from top to bottom . this seems counter-intuitive - are sure it's correct ?
52495,"for the benefit of non-matlab users--which would be the great majority of potential readers--please rephrase your equation in standard mathematical notation ( or at least describe what it means , in english ) . also , please be more specific about your question than just "" i didn't get it . "" what are you really asking ?"
52650,"can you give a reference , or at least some kind of direct quote so we can see what they actually say ?"
52651,"rob : i think this question will be closed virtually instantaneously on mathoverflow as off-topic ( not research-math level ) . one might debate whether it is better placed here or on [ math . se ] ( url ) , though . right now the question is unanswerable ( what is a . 2 and a . 3 ?"
52710,"can you elaborate on "" not seem right "" and "" more realistic "" ?"
52761,"it is possible that i am grossly mistaken , but i think your question requires a bit more information before someone can answer comprehensively . what do you mean by "" matched data match "" ?"
52794,is the dependent variable also on a 7-item likert scale ?
52840,"welcome to the site . you can read the [ faq here ] ( url ) . what do you mean exactly by "" redondant "" ?"
52865,what would be a good cluster ?
52992,how does your model differ from zero-inflated binomial regression ?
54508,"it is difficult to discern what you are asking . could you perhaps give an example of what the answer would be with , say , three names ?"
54541,"we maximize the log likelihood because statistical theory has proven this to be an optimum objective function in several senses , when there is no prior information about model parameters . to maximize something else implies that you have a special loss / cost / utility function . what is your utility function ?"
54570,what are the numbers on the vertical axes ?
54726,this could habe to do with local minima for the mixture likelihood . have you tried running the code with the same starting values every time ?
54893,"welcome to the site , ludovicofrate . it's not clear to me whether you need / want help with the statistical content of this situation , or just how to represent your ideas in r code . would you please edit this to clarify ?"
55301,"why not draw a man from the men and then a woman from the women , and * then randomly hand one of them the label 'first' * ?"
55302,you're talking about the smote * function * in the * r package * dmwr ?
55398,"what do you consider as a set of features in your dataset : measurement , property , or both ?"
55272,"by 'extra-' here are you referring to the use of a scale parameter , $ phi 1 $ , to model over-dispersion in similar fashion to say a quasi-poisson model ?"
55484,what are the error messages ?
55753,it would also be helpful to know what language you are using ( is it indeed r ?
55761,what does the prime ( ' ) mean here ?
55777,there's not nearly enough information to answer ( 2 ) . what are the conditions on non-uniformity ?
56089,"rotation is performed solely for the sake of interpretation of the components . interpretation is needed solely in the context of "" latent variable model "" , i . e . when you treat a component as a _factor_ , = you take pca as factor analysis [ a permissible albeit controversial decision ] . is that your case ?"
56322,what about a spineplot ?
56625,"what makes you want type iii ( "" u . s . senate "" ) tests as opposed to type ii ( "" u . s . house of representatives "" ) tests ?"
56869,"i'd like to see more detail in your first bullet point for "" repeat 25 times the following . . . "" section . which data is 5-folded and how is the data used for each set of meta-parameters ?"
57005,is this for some subject ?
57219,"hi , nick . are you familiar with the paper w . fu and k . knight ( 2000 ) , [ asymptotics for lasso-type estimators ] ( url ) , * ann . stat . * , vol 28 , no . 5 , 1356-1378 ?"
57162,"i think you are right , that does not make sense . what is the original text you are using ?"
57304,hi relena and welcome to cv . i have taken the liberty of using the formatting tools to make your post more readable . can you paste in the exact message you get ?
57331,"is your confusion alleviated if you recognize that , despite -1 being * smaller * than -0 . 5 , it is still * more * change than -0 . 5 ?"
57517,"just at a glance , it looks like you are assuming repeated measures in ` spss ` but not in ` r ` ; in ` r ` you've included the interaction between iv 1 and 2 , did you do that in ` spss ` . what data have you got , and what are your hypotheses and research questions ?"
57073,is this due to early termination ?
58525,note that the default ` boxplot ` call in r has the ` range ` parameter set to 1 . 5 . this means that the wiskers extend to 1 . 5 times the interquartile range ( see ` ?
58588,what commands did you use to fit the model ?
58594,"normally in statistical estimation problems a sharp distinction is made between variables with a hat and those without . subscripts matter , too . are you making such distinctions between $ theta $ , $ widehat { theta } $ , $ theta_p $ , $ theta_a $ , and $ widehat { theta } _p $ and , if so , what are they ?"
58595,can you test the same parts on multiple machines ?
58338,might you be misunderstanding the meaning of heteroskedasticity ?
58799,where exactly is the problem ?
59503,"it depends on the structure of the matrix $ s_ { ij } $ . considered as the adjacency matrix of an ( edge-weighted undirected ) graph , does the graph have a single component or not ?"
59678,"welcome to c . v . paul . let's start by 1 . what do you mean 'make a normal distribution on the interval [ 0 , 1 ] ' ?"
59733,"i haven't done any computing ( not able to , right now ) but looking at the formula for ll , how could it be negative ?"
59845,can you clarify your terminology ?
60174,"nstor raises a good point , but it may be hard to understand . if so , this thread : [ why does a 95 % ci not imply a 95 % chance of containing the mean ?"
60380,what's the matter with rewriting $ exp { ( ln { x } - ln { ic_ { 50 } } ) } $ as $ x exp { left ( - ln { ic_ { 50 } } right ) } $ ?
60410,""" * question 1 ) does the assumption refer to the values of y or the residuals of y ?"
61984,"i don't think this decision should only be based on the characteristics of the data set but also what you want to communicate , along with the expectations of your audience . error bars based on standard errors of the mean are very common , raw standard deviations less common , and ranges less common still ( if you're inclined toward ranges , you might consider boxplots ) . but with only 4-5 values , * why not simply indicate all four or five values ?"
62000,"as you press me , my personal view is that a good acceptable question will just cite the video as a reference and be focused on questions that other people might ask or difficulties others might express . this looks too much like "" here are some examples i have tried ; are they correct ?"
62052,have you set up the data using the ` mlogit . data ` command ?
62203,why ever would you want to do this ?
62209,"( 1 ) your basic problem is that you work too hard : almost all this code is repeated at least once . that leads to errors and makes them more difficult to debug . for instance , did you really intend to have two different formulas for ` c . stat ` ?"
63026,"i feel your social-science gruntwork pain , patrick , but i think your approach is wrong to begin with . if you want to use statistical tests , you will need to have humans code a portion of them to get classification error rates , have you ( personally ) done that ?"
63540,"it would help me to follow your description of your situation if you would actually describe what you are doing & what the letters stand for . i have no idea what it means that q is "" distorting "" something ; are you talking about q * moderating * an effect ?"
63566,"first of all : the new model is not a mixed model , it has no random intercept like the first model for ` subject_id ` ; is this intended ?"
63902,"if all your variables are the same kind of quantities and are expressed in the same units of measurement , then comparing sds as you do here is legitimate . but otherwise , this makes no sense . for instance , if the standard deviation of a mass is 0 . 001 kilograms and the sd of a length is 100 microns , who is to say which is "" large "" and which not ?"
63952,"you state that "" the outcome variable is not the * disease * status "" . what does $ y_i = 1 $ indicate ?"
63978,i have no idea what you're asking . you want to fit a non-monotonic function of $ x $ . . . what exactly is your problem with polynomial regression or sine regression again ?
64587,your expression for $ hat { beta } _ { mbox { cgm } } $ doesn't have a hat on the $ sigma ^ 2 $ . does that mean it assumes $ sigma ^ 2 $ is known ?
64715,i'm afraid i don't really understand what the dependent variables and the independent variables are in your data . is ` treatment ` the dependent variable ?
64754,another thought : are you using ` y1 ` as fixed effect or not ?
64766,without seeing them ?
64813,"frankharrell to be clear , by "" basic "" you are referring to the non-parametric bootstrap ?"
65211,"the output of the fourth example is almost the same as the second example . in particular , $ b = 8 . 542 $ again . are you absolutely sure that you ran the fourth example with ` y2 ` and not accidently with ` y1 ` ( for example , by re-naming the variable by mistake ?"
65484,"( 1 ) something is not quite right about the graphic . it has two vertical axes , but the right hand one cannot possibly be for counts or reciprocal counts ( it would show them as negative , which they cannot be ) . we must conclude it shows the values of the fits . however , with only the three parameters mentioned in the text the fits * necessarily * approach an asymptote of $ 0 $ at the left , whereas these both approach $ -2 $ . what's going on ?"
65411,"can you visualize the clustering result at 22 clusters , please ?"
65846,"by "" . . be estimated in the standard way "" do you mean that the covariance of $ n $ can be estimated * separately * from the data ?"
66037,"as you've written this , you * don't * need to include both $ x_1 $ & $ x_2 $ in the model - either one will do as it determines the other . are you sure that's what you meant ?"
66613,how large is your sample ?
66708,can you make the data available ?
66728,"a complete side-issue , and i don't use r , but isn't there an easier way to "" demean "" ( horrible word here ) ?"
66872,"why , specifically , are you not satisfied with the solutions you mention ?"
66890,"any chance you can provide a slimmed down data set , otherwise it is difficult for one to replicate your error and help you debug ?"
66940,so how exactly does iveware go about this ?
67044,why would you want to make your data seem normal ?
67228,"if the "" uncertainties "" are really larger than differences among the $ y_i $ --as illustrated here--then it may be better to fit a simple model to the data rather than interpolating linearly . the interpolation makes sense when the uncertainties are relatively small . however , please be aware that the uncertainties of the interpolated values will then be * autocorrelated * ; whether or not you have to deal with that depends on what follow-up calculations are done on the grid . might i suggest you tell us what you * ultimately * want to do with these data so we can provide advice that's suitable ?"
67990,have you checked the ` zelig : : sim ` documentation ?
68071,"i have some thoughts that i hope will help add context why you're making some decisions in about your research . keep in mind that your $ chi ^ 2 $ results will also be sensitive to how you transformed the continuous variables into categories . rebinning could change the kinds of results that you obtain . generally it's best practice to keep the data in the original units , so that the texture of the data is retained . also , it's unclear to me why you want to do a $ chi ^ 2 $ test when you have binary outcomes and continuous predictors -- isn't that what logistic and similar regressions are for ?"
68333,"please do a reasonable-sized plot . if it won't even fit on screen , it's far too big to be useful . the two sample ks test is for testing that two samples could have the same distribution , which isn't what you are doing here . what were the nature and extent of the ties ( i . e . what values were tied and how many of them were there ?"
68554,"talischen if the animals in a group don't survive or die all together , what is the sense in which they aren't independent . are you saying that within a group ( of 5 or 50 ) their chances of death are related ?"
68800,"i lost you at the first reference to $ y_n $ : how many trials are run in the experiment--two as you state ( "" a binomial trial "" and "" a second "" apparently corresponding to $ x ^ 1 $ and $ x ^ 2 $ ) or $ 1 k $ as you imply ?"
68859,"let's first establish the sense in which you mean "" subset "" : after all , the value 2 has been repeated in your 'set 2' and that is unusual--it suggests you might be looking for tuples or sequences rather than subsets . your notation "" ( . . . ) "" also is not a standard set-descriptor notation . could you clarify your meaning ?"
68966,why don't you post the data ?
69061,"colours are fine , but why not use different symbols as well or instead ?"
69408,should these weights sum up to unity ?
69524,"an alternative is to revisit the model . do you perhaps need another additive term , say $ ( a x_1 ^ c b x_2 ^ d ) x_3 ^ e f $ ?"
69563,"if you continue the iterations , do you achieve convergence ?"
69719,"it's not completely clear to me what you're trying to do , nor why 'binning' helps to 'parse' data , nor how "" using the conditional chi-squared dispersion test "" achieves whatever it is you are attempting . can you clarify ?"
69627,"please make it more * * clear and consistent * * which are "" classes "" and which are "" categories "" ( clusters ) . prof / amature or the genres ?"
69859,whuber why not make that an answer rather than a comment ?
69872,can you explain the first two lines of math a little more ?
69896,what exactly do you mean by your data are event times ?
69930,how about adding an image of the plot to the question ?
70050,it would rather be $ x to a $ but what is $ a $ ?
70123,"this is an interesting question , though i think it would help to clarify a few things , particularly which are the "" moving parts "" and which are not . it seems you want a bound that holds * uniformly * in $ p $ for each * fixed * $ r $ . but , what is the role of $ d $ here ?"
69982,"you haven't actually described a hypothesis test yet . what "" test "" are you referring to ?"
70221,"$ beta_ { 2a } $ and $ beta_ { 2b } $ represent the expected values of the estimators $ hat beta_ { 2a } $ and $ hat beta_ { 2b } $ , i . e . the means of the sampling distributions of those estimators . if a and b were sampled in a quite similar manner , we would have $ h_o : beta_ { 2a } - beta_ { 2b } le delta $ . if you can reject this $ h_o $ based on your data , you could be confident that the two samples were not sampled in a similar manner . does this make sense ?"
70442,"ordinarily we can guess what you might mean by a "" z-value "" but it is strange to see it applied to binary attributes and even stranger to see its use in the second question , which is difficult to interpret . so that we can be sure we understand what you're asking , could you please explain what * you * mean by this term ?"
70660,could you post the output from summary ( ) and anova ( ) that shows the exact problem ?
70784,"this would take a random sample of data . frame rows : ` test_data - real_data [ sample ( seq_len ( nrow ( real_data ) ) , random_count , replace = true ) , ] ` . is that what you need ?"
71260,is your question simply 'why isn't the mean of the conditional distribution = $ mu_1 $ ' ?
71003,"it is unclear what $ { s_m } $ is : what exactly is a "" $ p $ index "" ?"
71802,"just want to clarify the second point . by saying that change in response happens 2 % of the time , you mean that your time series which you want to forecast contains only 2 % non-zero values ?"
71783,tyler has pointed out a typo in the display equation ( right hand side should be division not multiplication ) . is this a typo in the book itself or just inadvertently introduced here ?
72091,can you give a more concrete example of what you mean by cv having multiple values ?
72165,are your data discrete ?
72369,"see advice at e . g . url on explaining abbreviations . for example , i stop at ml , thinking that means "" maximum likelihood "" , but is that meant here ?"
72484,"you need to know ( or assume ) more about what's going on . in some cases , the units within a packet might tend to have very similar weights ; in other cases , they might often be wildly different . would it be possible to destroy a small representative sample of the packets in order to assess this ?"
72533,"if you already have the population at hand , why would you use bootstrap samples to make inference about this population ?"
72519,"( 1 ) nicely written question . welcome to the site . just to clarify : in one instance you know the parameters and want to sample from the distribution , but in the other you have * data * and want to find the associated parameters ?"
72575,"yes , i think . adding a suppressor can reverse the sign of a coefficient . as well as not . so what is your question about - a suppressing phenomenon or a changing of a sign phenomenon ?"
72676,"what does "" do "" mean in your final formula ?"
72743,a couple of clarifications : 1 ) is indexing by $ i $ important to the question ?
73073,could you add some more context to your description ?
73151,so what conclusion did you reach based on your simulations ?
73179,i need to know more . . . did you use the ` categorical ` button to assign a variable to be categorical or did you make a series of dichotomous indicator by yourself and feed them into the model ?
73319,"in the current state this is sooner a discourse with highly uncommon terminology than a question . i'm , particularly , in difficulty to make head or tail of it . can you make the story clearer ?"
73165,"before asking what would be the flaws with this approach , maybe you should write why this approach should work , in your opinion . why do you think that the steps 2-4 improve the outcome ?"
73411,"there are many suitable distribution tests that apply here and are powerful ( most likely they are too powerful , but that's another issue altogether ) , including the chi-squared test and the kolmogorov-smirnov test . so what "" resource "" do you seek : a reference to some test that looks like yours or some test that will work well in the situations you describe ?"
73741,please tell us about your population : what kind of thing are you sampling ?
73807,"thanks for the feedback . regarding the "" conjecture "" , it only applies to square matrices -you provided a counter-example using a non-square matrix . there are general standard methods to measure distance between distributions like the kullback-leibler distance , hellinger distance etc ( instances of "" f-divergence "" ) . but in order to apply these , we need to have the joint distribution of the $ boldsymbol { v } $ . do we ?"
74306,"could you possibly add in all the data points that you used to construct the ideal line , or add in a little bit more information about how the dotted red line is computed to justify the blue bars being the "" deltas who are below the average of all the data points "" ?"
76279,"when you say 'related to this thread' at the start , which thread do you mean ?"
76525,the way you have described this problem is incredibly confusing . what are you trying to classify and how are the nodes / edges related to this classification ?
76533,( 1 ) is the normal distribution an assumption or do you have good evidence in support of it ?
77085,"do you want to say that you have q consisting of ranks ( positive integers 1 . . . n ) and you want to work out some form of standardized index assesing a degree to which an arbitrary subset of arbitrary size , from q , is far from being a collection of consecutive integers ?"
77099,"i think i follow you , despite some confusing and ambiguous statements in the question . perhaps the most important thing to clear up is the second bullet in the second set : $ np ( 1-p ) $ is constant ( equal to $ 5 / 4 $ ) as you have defined it and therefore the variance of these $ m $ values will always be $ 0 $ . i suspect you intended to mean $ n hat { p_i } ( 1- hat { p_i } ) $ where $ hat { p_i } $ is the estimated proportion * within window * $ i $ , $ i = 1 , 2 , ldots , m . $ is this the case ?"
77131,you appear to be asking to identify a [ tag : changepoint ] . do the threads with that tag help ?
74973,"you wrote "" for each anemonefish species ( $ i $ ) inhabiting an anemone species ( $ j $ ) , ssr was calculated as : $ ssr = frac { w_i } { sum { w_j } } $ "" . is it ssr ( i ) or ssr ( i , j ) ?"
77235,why do you throw out the interaction information ?
77211,can you please clarify how you are performing the replacement ?
77629,"both methods are concluding that the two means are significantly different . so , what is the issue ?"
77495,running tests without some goal is usually meaningless . what are you trying to achieve ?
78075,"there may be some critical typographical errors in this question , such as "" expenses pr production "" : what does this mean ?"
78169,"are the values of the $ c_i $ large in absolute value ( say , greater than $ 10 $ typically ) ?"
78236,i haven't worked with endogenous / exogenous variables . having said that : have you thought of using ` lme ` instead of ` lmer ` so that you can define an ar = 1 correlation structure for your errors and see if that takes care of your endogeneity ?
78339,are you sure it s a profile likelihood ?
80577,"as for the linearity , you cannot know whether the series is linear or not unless you tested it , and the types of non-linearity you can figure out are actually those that can easily be linearized . 1 ) why do you believe it be not linear ?"
80858,"you are having trouble because your description lacks critical information . first , * how * do you "" randomly draw "" values from a * function * ?"
80949,( 1 ) this doesn't look like a [ tag : self-study ] question to me : it looks like a genuine applied problem in probability . ( 2 ) how large might $ n $ be ?
81225,"( 1 ) in the second line , where $ f $ is defined , is there some reason why it would be given as $ _i $ rather than restricting it to the positive half-line ?"
81263,"i would like to suggest that making a consistent distinction between * estimates * of skewness / kurtosis and their * population values * would clarify this question ( and perhaps even answer it for you ) . it seems clear that this distinction completely resolves question ( 1 ) , because missingness has no effect on the population moments . what i cannot figure out from your text is whether you are specifying skewness / kurtosis / correlation for the * population * or for the * sample * . ( and if it's the sample , then * why * ?"
81247,"i find quite confusing the link between "" reach a certain point "" and "" avoid that stop "" and "" missed a stop or not "" . i don't think the problem is statistical jargon , could you maybe re-word the problem more precisely about what in the real world it is about ?"
81844,do we actually have any reason on the basis of the wording of the question to think that people choose their passwords randomly ?
81920,it sounds like your weighting scheme was somewhat arbitrary : that would make it difficult for anyone to assess your procedure objectively . have you done any testing of the accuracy of your classifier ?
81997,"your answer in each case is a sequence of a dozen or so assertions or manipulations . i'm sure you are not in doubt about most of them . since you are doubtful about the answer * overall * , that would seem to suggest there are a small number of steps that give you pause . which ones ?"
82291,what do you want your data to tell you ?
82356,"could you explain to us what you mean by "" tukey's line "" ?"
82532,"a confusing aspect of this question is that it refers to p-values for the coefficients and to residuals as if they were somehow the same thing , even though those are entirely different . could you clarify ?"
82557,are a1 and a2 meaningfully separate variables ?
82707,by whisker bar plot do you perhaps mean a boxplot ?
82951,"this doesn't answer your question , so i'll not put it in the answers . i have had similar problems before , and found that it was due to the scaling of the data . also , have you tried using the package plm ?"
83025,"what is your $ i_ { ( 0 , infty ) } $ function ?"
83082,this isn't at all clear . can you say more about your study & your data ?
83119,"could you please tell us what the "" hat matrix "" would be for logistic regression ?"
83296,"the two datasets , how many variables do they have ( are they each univariate ) ?"
83493,sounds like you're not fitting a mixed-effects model which you should do here to account for variation between the operators and ( nested within that ?
83682,can you be clearer about what you don't understand & need to know ?
83346,"sorry , it's more decades than i'd like to mention publicly since i did any queueing theory -- so i don't remember what the definition of traffic intensity is , and google wasn't much help . if you could define it , perhaps , or point to one , that might help . ( incidentally , questions such as these would normally carry the ` self-study ` tag ( [ * q . v . * ] ( url ) ) ; do you need all five of those tags ?"
83975,please include more information . what is not right for example ?
84274,what's the question ?
85506,""" i am not sure if this method is valid in my case for the following reason : each of these two data series , data1 and data2 , is itself a weighted-average of a bunch of standardized individual series . "" : can you explain why you think that is a problem for using order statistics ?"
85566,"have you considered using an independent samples test comparing the mean proportion of time flying in the two groups , and similarly for loafing and foraging ?"
86026,"not in the least . if someone hasn't seen python at all , why would they have guessed "" notebook "" means "" python notebook "" by reading your question ?"
86467,is $ a_i ge 0 $ another constraint or can you * go short * ?
86909,"yes , clearly this is a shifted and rescaled gamma-like density with parameter $ -3 / 4 . $ however , there is no such thing as a gamma variate with negative shape parameter , for exactly the reason i gave : the integral of the "" density "" diverges at $ 0 $ . it sounds like we're jumping into the middle of an analysis that has gone a little awry : would you mind telling us the context in which this problem arises and what you're really trying to achieve ?"
86853,please explain your notation : what do the values of the $ e_ { ij } $ * mean * ?
86980,"yes , i get that you have trouble : but what kind of trouble ?"
87389,"i see only two models and three variables . do you mean that you have 100 , 100 and 500 observations of the variables spdm , cc , and cty , respectively ?"
87438,are you using spss ?
87447,you have just implicitly introduced a key idea : that of * personal probability . * doesn't this immediately resolve your paradox ?
87858,"i know nothing about lasso , but assume that the slope should not equal one . you haven't just flipped the axis of your calibration plot and the slope is 1 ?"
87908,is coop a dummy variable ?
87832,"you refer to regression in the title & use that tag , however in the body of the question , you seem to be discussing a classifier . in machine learning , people often think of regression & classification as being somewhat distinct . can you clarify what topic you are thinking about ?"
88377,is this an exam you are taking ?
88423,are the $ alpha $ s the same in both equations or do they need a subscript ?
88461,"yes , your formula from matrix notation is correct . looking at the formula in question , $ 1- frac1 { n } , = , frac { n-1 } { n } $ so it rather looks as if you might used a sample standard deviation somewhere instead of a population standard deviation ?"
88588,you made more confusing now . can you show the example of the dependent variable observations ?
88630,it isn't clear where ` hitrate ` comes from . is it just the percentage of observations that is in the ` event ` column ?
89510,are you thinking of the 7 issues as related ?
89531,[ searches ] ( stats . stackexchange . com / search ?
89669,an * exact * answer will likely be extremely complicated : see url for an analysis of the distribution of just the sum of uniforms . perhaps an asymptotic approximation would be ok ?
93447,"this seems like an updated version of url if it is , please consider deleting the older version . as far as the present question goes , two million values is a ridiculously large data set which enables very precise examination of the relationships . why don't you start by plotting median ( or mean ) log against ` file [ , 4 ] ` and * look * at the relationship ?"
143517,"why did you decide upon a garch ( 1 , 1 ) ?"
154784,"this comparison seems to tell you that model1 isn't particularly good at predicting dataset 3 ( and probably vice versa ) , which makes sense since the coefficients for pcws and ref differ in signs . do these variables have different ranges in the three datasets , by any chance ?"
251612,"i just examined one of my recent quasipoisson models built with glmmpql and i definitely have different intercepts for each random effect . in eyeballing what you've presented above , it looks like you only have one level to your random effect in the glmmpql model . however , i can't confirm this is the case . could you recreate the problem in a dummy dataset ?"
277290,what inputs are these performance measures using ?
281243,"so you have a model $ x_ { t 1 } = r x_t exp ( -x_t ) $ , and you want to estimate $ x_0 $ and $ r $ from data $ y_t = x_t varepsilon_t $ , which has standard normal measurement errors ?"
281393,"just a shot in the dark , but : are those long intervals of 0 at the beginning and the end important ?"
320274,"without seeing dataset or code , i am a bit concerned with your use of "" accuracy "" as a metric for model assessment . does your training set consist of a balanced 1 / 0 categories ?"
325927,how many dice are you throwing ?
329829,"with the edit comes new potential for confusion . parsimony lies in the * model , * not in the data , rendering question ( 1 ) meaningless ( or trivial ) . in ( 2 ) , exactly which "" comparisons "" are you referring to ?"
347602,can you clarify what your research question is ?
89774,can you show your code ?
89783,can you clarify # 1 ?
89789,this looks like a homework question . would you like to revise it in the light of the guidelines [ here ] ( url ) ?
89952,"okay , can you actually write the mle function you're having trouble with in your question , please ?"
90080,how many zero observations are there ?
90228,"despite using $ beta_0 $ , you don't have any intercepts listed . you have * slope * coefficients in these models . in addition , you have the same slope coefficient for both variables in the first model . are you sure these represent what you are really after ?"
89948,i don't think i understand quite what's being asked here . can you explain in more detail what's going on ?
90619,"how did you simulate your data , i . e . what did you do to your ( pseudo- ) randomly generated normal distributions , whose parameters you know ?"
90871,hint : how many parameters are you trying to fit compared to the amount of data you have ?
91086,what is $ v $ ?
91013,i found the description a little hard to follow so i am not certain i am responding to the question you're actually asking . don't you just need to integrate out the variables ( dimensions ) that aren't of immediate interest ?
91243,"rly good to start with a question ( and , an interesting one at that ! ) . can you do a ` dput ( head ( ) ) ` of the ` data . frame ` in question ?"
91664,what are the variables ?
92919,""" results "" is too vague to be testable for significance . different in terms of what ?"
92808,""" interested in "" and "" what can be gained "" are rather vague . could you be more precise about what you want to learn about $ x $ ?"
93197,"the answer might depend on precisely how $ a $ was changed . if dramatic changes occurred ( especially if some values previously considered possible became impossible ) , it is difficult to imagine how the results could be salvaged , but if the new $ a $ could be expressed as a mixture of the old $ a $ and another distribution , then it is obvious how to augment the existing results . could you please therefore edit your question to give us this detail about $ a $ ?"
93413,"it seems that you are all after a reliable indicator of causality ( only this "" makes sense "" ) . correlation isn't necessarily causation , causation is always correlation . what if causation do not exist out there at all and is simply a way we verbalize / interpret some correlations some time ?"
93476,are you asking how to compare the proportion of people who use word processors given their os - as in a simple interaction with logistic regression ( or a chi square test ) ?
93502,can you post the code & / or the data ?
93881,"this is a good question , but note that 'how good are the clusters ?"
93915,how is $ s_t $ 3x1 ?
94121,did you include the main effect of lot1 in the final analysis you show ?
94280,are you saying you have summary statistics * but you don't even have the sample sizes * ?
94436,"what does the notation $ p ( x_1 , x_2 , ldots , x_ { 30 } leq 1 . 85 cdot 10 ^ { -5 } ) $ mean ?"
94882,as a start : age should most probably be a fixed effect . and a random patient effect is missing to account for the repeated measures structure . question : why not modelling absolute or relative changes in the dv ?
95103,"you haven't really told us what you would like to compare , except it seems to be in terms of * visitors , * not visits . thus performing an analysis of visits doesn't sound relevant , but that's a little unclear . would this analogy perhaps be apt ?"
95168,"within groups determined by entity , do most other variables simply stay constant or do they move around ?"
95278,"your formula has no $ b $ , so what's ` b ` ?"
95356,start by drawing a diagram ( have you included all relevant information in your question ) ?
95554,does $ sigma $ denotes the variance or the standard deviation ?
95559,"this question is very confusing because it asks about * * four * * distinctly different things : comparing "" trends , "" comparing means , comparing another measure of location ( implied by the wilcoxon test ) , and comparing distributions ( via the k-s test ) . please tell us a little more about what these "" paired histograms "" represent ( including how you obtained the original data and how you chose the histogram bins ) and as much as you can about how you really want to compare these data : what is your ultimate objective ?"
95622,"we still need a more precise sense of "" similarity . "" do you mean similarity in the euclidean sense that there exists some combination of a translation , rotation , and uniform scaling that sends $ m $ to $ n $ ?"
95676,how were the numbers of measurements chosen ?
95769,why don't you drop the difference operator and estimate the fractional response directly ?
95804,the question is not clear . do you know who the 1000 customers are which belong to class 1 ( don't accept offer anymore ) ?
95891,"can you recreate your first plot after regressing ` sex , region , age , supportscore1 , supportscore2 ` and ` county ` out of ` age ` ?"
95999,"the slope is a reasonable point of departure for this study but i believe there may be better measures of "" run a lot . "" the slope approximately measures the average speed * in the direction determined by the net motion during the entire period . * when an animal runs out and runs back , the slope will be grossly biased low . also , it does not seem that direction matters : you are interested in * speed * rather than * velocity . * thus , you actually have much more and better information than is captured in any slope : you have the ten distances between each successive pair of observations . why not use them ?"
96563,what does your fitted v / s y look like ?
96588,can you give the cite to the science paper you refer to ?
95916,i assume that when you say that your test had 95 % confidence after 15 days you mean that the p-value was less than . 05 ?
96788,"i would consider * posterior predictive simulation * for goodness of fit -- that is , simulate new data from your fitted model , compute some summary statistic you're interested in ( e . g . number of non-zero values , or mean of non-zero values , or something ) and see how well it does . ` glmmadmb ` doesn't have a ` simulate ` method , which makes things a little harder . can you say a little more about your model ?"
96941,"first , how is your $ x_ { ij } $ defined ( it's not in your list of notation ) ?"
97308,you say you include fitted model results . where are they ?
97338,"given what maarten says and what i understand from your question , it could be that the two methods are parameterizing the categorical variables differently - that is , which is the reference category for each independent variable ?"
97073,would it be possible for you to put more of your code in the question ?
98961,would url be the sort of thing you are looking for ?
99274,can you summarize what exactly you are attempted to do with such plots ?
99315,do you want multiple test sets ?
99497,"how did you determine that "" the value has a high probability between -1 and 1 "" in the first set ?"
99545,"when you mean that you do not have knowledge on its component , you mean you do not know its functional dependence or whether it depends on a component or not ?"
99591,"it is unclear ( a ) what you mean by "" unrolling "" the data , ( b ) what you mean by "" operating . . . directly , "" and ( c ) why you are concerned about memory usage with such a small dataset . could you please edit this question to clarify these things ?"
99600,how exactly was that geometric distribution generated ?
99626,"so , for each of 10 fungi don't you just have two variables - effect on plant and growth in dish ?"
99753,"why do you say "" please take probability distributions out of your mind for a moment "" ?"
100188,this may perhaps help ?
100297,how many classes do you think you have ?
100484,how is the background calculated ?
100688,"describe how the cross-validation was carried out , e . g . averaged over x repeats of k-fold cross validation - what are x and k for you ?"
100820,"if you appreciated it , why did you take the latex out again ?"
100914,"i'm having trouble figuring this out . surely "" round "" is the lowest level -- so the "" investment "" response is measured on each round . the levels are session - person - round . if that's the case , you don't need to include round in the model . but if not , then where do you take the outcome measurement ?"
101062,how does nmf acronym unwraps ?
101077,` 'princomp' can only be used with more units than variables ` pca can be used with p n . maybe you were using the wrong function or using it wrongly ?
101309,"you have described a lot of useful things--except for the most important , which is the purpose of your additional experiment . presumably it will be testing some hypothesis . what is it ?"
102864,"i'm stuck just trying to understand the data . what do you suppose those * negative * "" concentrations "" mean ?"
102907,"note that if you want to specify the interaction term separately , there's also the ` : ` operator in the formula interface . that is , ` a b a : b ` is the same as ` a * b ` . is the issue here simply that you're changing which category is the baseline ?"
102998,"need clarification , by 70 attributes do you mean 70 variables ?"
103016,your description is somewhat confusing . can you provide a 2 by 2 table illustration of your data ?
103891,"can you provide a sample of what trainx and trainy look like , as well as the problem ?"
103969,do you mean $ q = frac { x } { y } { boldsymbol 1 } _ { { x leq y } } $ ?
104441,"because there are myriad ways to express pdfs , a good solution should aim for a representation that is suitable for your purpose : what , then , is the objective of this exercise ?"
104468,"are you referring to the goodness of fit test , or one of the other chi-squared tests ?"
104473,"have you considered running a poisson model for sales with a robust variance-covariance matrix , with store size as an offset ?"
104540,are the variables dichotomous or polytomous ?
104666,there are some minor mistakes in your formulas to start with . note that the density of $ x_i $ is proportional to $ exp { -x ^ 2 / 2 } $ so the density of $ x_1x_2 $ should be . . . ?
104725,how likely are your poisson counts to be small ?
105016,"it's a good question , but in the interest of pursuing what might be an important issue , i would like to point out that the much simpler approximation $ f ( mathbb { e } ( y_n ^ { ( n ) } ) ) approx 1 / 2 $ already works pretty well : it is never off by more than $ 1 / 2 $ ! the point , of course , is that it would behoove us to * quantify * the accuracy of your approximation and to establish a threshold to distinguish good from poor accuracy for your application . do you have any thoughts about that ?"
105012,"apparently ` it ` is a pair of subscripts , but what does ` 2010 i ` mean ?"
103834,are you interested in evaluating the difficulty of particular questions ?
105130,do you know the form of $ p ( x y ) $ or do you just have samples drawn from that distribution ?
105162,this post may have received no responses because it is so vague . ci for what parameter ?
105347,"i would advise never fitting a model until you've taken a peek at the means . on average , do the questions that are answered have more upvotes than those which aren't answered ?"
105655,"it seems to me that you didn't use clustering . you used multidimensional scaling ( mds ) . so , was the whole question about mds , i . e . about plotting the distances between the 25 shapes in euclidean space ?"
105873,your lme command as provided has an apparent typo . does that typo exist in your original script ?
100919,the kde of dc reminds me a bit of a chessboard . what would the spatial autocorrelation plot from a chessboard look like ?
105951,may be auto . arima in forecast package with exogenous variables ?
105230,"did you also follow up on : "" the use of ipw to t an msm was described in detail , e . g . , in robins , hern an , and brumback ( 2000 ) , hern an and robins ( 2006 ) and cole and hern an ( 2008 ) . "" ?"
107599,"you lost me in the first sentence with "" maximal expected . "" if the $ x_i $ are a sample then its mean has an * expectation * which is a * number * : what is "" maximal "" about that ?"
108165,"do you really plan to look at over 22 , 000 of these plots after you have waited for them all to be computed ?"
108280,wait . . . are you sure clmm doesn't do random slopes ?
108383,are you * z * -scoring using the population standard deviation ?
108537,"the ` anova ( ) ` function in r behaves differently depending on what type of object you give it . in other words , what are ` fit1 ` , ` fit2 ` , and ` fit3 ` ?"
108637,your situation isn't terribly clear to me but your interpretation of p-value as goodness of fit is certainly one problem . don't use p-values to decide whether a fit is good or bad . what would made a model a 'good fit' or 'bad fit' for your purposes ?
108705,shouldn't the first term with exponent be $ e ^ { - left ( theta_1 theta_2 theta_0 right ) } $ instead of $ e ^ { theta_1 theta_2 theta_0 } $ ?
109248,"i don't understande the model . how can $ y_n $ can be present on the left and right part of the formula . what is $ w $ , $ lambda $ , etc . can you please explain it better ?"
109509,in the plot what is the y-axis ?
109527,is your normal equation right ?
109633,30 is pretty small . . . there's no way to gather more data ?
109697,do you know anything about the group sizes ?
109809,"welcome to the site . are you willing to ignore the time nature of the data , or is it important ?"
109949,does the murthagh and legendre paper say anything about this ?
110190,"your notation is mystifying because $ mathrm { e } ( y - hat { y } ) ^ 2 = mathrm { e } [ f ( x ) epsilon - hat { f } ( x ) ] ^ 2 $ literally means the square of the expectation . assuming $ mathrm { e } ( epsilon ) = 0 $ , this immediately reduces to $ ( f ( x ) - hat { f } ( x ) mathrm { e } ( epsilon ) ) ^ 2 $ = $ ( f ( x ) - hat { f } ( x ) ) ^ 2 $ . evidently , then , what you really want to compute is the expectation of the square , $ mathrm { e } [ ( f ( x ) - hat { f } ( x ) epsilon ) ^ 2 ] $ . but if so , the very first step in your derivation makes no sense . could you edit the question to clear this up ?"
110589,this sounds like a programming question rather than a statistics question per se . are you just asking how the function is working ?
110772,could you post the data ?
111108,"i would suggest that you include in your question 1 ) the regression equation , 2 ) the names of the regressors and 3 ) what you want to measure . for example , logistic regressions estimate the effect of the regressors on the _probability_ that the dependent variable will acquire a specific value -is this what you want to do ?"
111454,"can you edit your question ( use the "" edit "" link at lower left ) to say what kind of data you have ( i . e what kinds of values your data take ) ?"
111547,"i'm a little lost concerning the initial discussion because it seems to assume a contrast between a "" vector "" and "" ordered "" values . ordinarily , part of a vector's definition is that it is an * ordered * tuple and so there's no difference at all between the two . what distinction might i be missing ?"
111762,what's your question ?
112914,what kind of parameter is ` p ` ?
112944,have you looked at ` ` dataset ` ` ?
113006,what book is this ?
113178,"there seem to be several rather different questions here : are you asking how to ( a ) find a "" maximally uniform "" measure , ( b ) whether it has any connection with the length functional , or ( c ) how to minimize the length functional ?"
113232,welcome to cv karen . have you looked at the * * coxme * * package ?
113252,"from what i understand , ` 1 . extrovert , 2 . introvert ` are the two categories that your outcome ( dependent ) variable can take on . is that correct ?"
113311,"you seem to be throwing away the information needed to help solve your problem : by reducing each set of 35 replicates to a single score , you have eliminated all identifiable information about variation within the simulations . that leaves you powerless to attribute variations between the scores to anything but chance . as such , you cannot really conclude anything . have you considered analyzing all $ 60 times 35 $ values that you obtained , perhaps with an anova , in order to assess the differences ?"
113454,"you seem to have quite a high n , right ?"
113566,how do you know who is in the neighborhood ?
112385,it would help to clarify your question : what do you want to achieve with cross-validation ?
113462,they are two different methods so what makes you think they will return the same answers ?
113106,"what exactly do you mean by a "" variance measurement "" ?"
114399,"i'm assuming $ t $ is known , not to be estimated from data . is that right ?"
114411,"you assume that the variance of the $ p $ -dimensional vector $ b $ depends on the number $ n $ of $ p $ -dimensional realizations available from this vector , i . e . on the size of the sample . is this intended ?"
114895,i see that you are fitting both using laplace approximation for the log-likelihood . what are their respective log-likelihood scores ?
115253,"it's a good question , but "" recruited . . . randomly online "" seems like a contradiction in terms . could you share with us how you accomplished the randomization ?"
115428,"this would test whether those effects differ from each other , not whether the effects differ from 0 . is that really what you want ?"
115439,"just a guess , and i haven't run your code , but in ` exp ( gamma * mat_sq_dists ) ` , is the * sign * of ` gamma ` correct ?"
115661,"are you sure that you are calculating the definite integral ( 0 to infty ) , and not just the indefinite integral ?"
116342,"` "" why is the standard deviation defined as sqrt of variance and not as average of [ the root of ] sum of squares ?"
116330,are you perhaps re-asking [ this question ] ( url ) about computing the acf ?
113657,"if you plot them in colors that represent the direction , will you see patterns ?"
116954,this sounds like routine bookwork . is it for some subject ?
117474,can you post a link to the data ?
117605,is your problem that you don't know how to characterize re uncertainty after mi ?
117741,are you conflating population notation with samples ?
117778,can you paste your actual output into the question ?
118151,"something like a rank correlation , perhaps ?"
118080,certainly interesting . any chance we could see ` str ( in11c ) ` or ` summary ( in11c ) ` and / or relevant bits of ` summary ( all . 1 . null . rasch ) ` ?
118499,"what is the "" data within each group "" ?"
118521,"if the series are each "" converging "" to some value , that indicates that their means are going to be inadequate descriptions of each series . even worse , the means could be deceptive . t-tests are clearly inapplicable . to make progress it would be helpful to understand why and how these series converge . what do they measure ?"
118597,"the information in the table points to substantial variability in the correlation coefficients . that suggests it may be misleading , or even meaningless , to compare averages . but the problem is likely more fundamental than that : why should these cross-correlations tell you much about the subjects' responses ?"
118621,"please reread your question . where you said "" * i expect 0 and 2 to be different on each side of the breakpoint , and 2 to be the same * "" -- should one of those "" * 2 * "" values have been 1 ?"
119831,how many different characters are the 8 characters selected from ?
119866,how expensive is each function evaluation ?
119965,"welcome to our site ! your questions appear to probe a little more deeply into interpreting interactions than [ our other threads on the subject ] ( url ) . however , this site operates in english : could you please translate your post so that our readers can understand it ?"
120489,i have trouble extracting a clear problem statement from the question . can you elaborate more on what exactly is given ?
120526,"hello all . i edited the question , sorry if i wasn't clear the first time around . maybe have another look ?"
120749,i do not work with pgls but this problem type could be solved via canonical multivariate approaches or ordination followed by regression on the principal axes . have you considered that ?
121225,"assuming your prng is good , why would setting seeds with a pattern make any difference , isn't that the whole point of prngs ?"
121414,what is the x mentioned in the last paragraph ?
121517,aren't your models perfectly nested ?
121763,"here is a rough translation from software output language into english : how could a number like "" 29 . 9 "" or "" 10 . 2 "" possibly represent a "" number of observations "" of a person ?"
122284,"the initial distributional expressions are problematic , since they have zero variance . since you are deriving the asymptotic covariance , you need to examine $ $ { mathop { rm cov } } left [ sqrt n { left ( { hat mu - mu } right ) , sqrt n left ( { hat sigma - sigma } right ) } right ] $ $ . don't you think that the $ n $ in the denominator in your last line is problematic ?"
122832,i am unable to see how your question differs from the original one . could you point out where the difference lies ?
122990,why the $ hat { theta } _ { ml } $ ?
123026,when we can find the vc-dimension of logistic regression directly why do we need to bound it using rademacher sum ?
123807,could you show your derivation ?
123941,"your question seems muddled . you ask how to "" take the difference of two proportions "" ; but that's * literally * $ p_1-p_2 $ , not "" the difference of the logit "" . can you clarify what it is you need , and be more explicit about what the circumstances are , please ?"
123498,"i'm not sure i follow your scenario . what is your "" actual "" data ?"
124314,"for clarification : what do you mean by "" this group "" and also "" greater effect "" ?"
124388,not an answer to you question but . . . have you considered using aic ( or aicc ) to select the best arima model from the pool of all candidate models ?
124781,people may not want to read the paper to understand & answer your question . can you copy & paste the context in which the term is used ?
124855,can you add some of the necessary context into the question ?
124887,doesn't your top result only hold if x1 & x2 are perfectly uncorrelated ?
125154,a very simple idea : how about taking the time series of differences and looking at the auto correlation coefficient ( s ) ?
125485,"sensitivity analysis is a bit general , what in particular are you looking for ?"
125498,what are these data points measuring ?
125620,what is the possibility that the underlying intensity could vary appreciably among the three replications of the experiment ?
125701,is the level * * x2 * * supposed to be a regressor in addition to the squared * * x2 * * ( before you go for instrumental variables ) ?
125699,"unfortunately , i'm not ` r ` expert to help . can you give data , for people to try to reproduce your results ?"
125926,"i posted an answer to your question . did it help you . could you please reply , accept , or vote for it ?"
126003,"most aspects of your formulas have no clear connection with the data in the question . what does the "" $ sqrt { 9 } $ "" represent ?"
126196,"i'm a bit unclear on what you mean by "" my method of backtesting ( make a model only with data previous to that point ) "" . could you elaborate ?"
125552,why does it look weird for you ?
126510,what have you tried so far ?
126525,there's something unclear about your circumstances ; you may be aware of important details that we aren't . why is $ y_ { t 7 } $ needed ?
126673,this reads somewhat like bookwork . is this a question from some subject or course ?
126777,"this is much better , but i still do not understand the role of the beta distribition . is that based here on some physical theory ?"
127379,"i find the question incomprehensible : stripped of distracting phrases , it asks "" what are the advantages of modeling sampling distributions when you are able to model a sample distribution ?"
127584,in this situation it is plausible to suppose that ( a ) you could look up the salaries of all workers in the population and ( b ) you have access to data about all nine individual sales . would this be the case ?
127604,"i've tried to improve the formatting , but it wasn't 100 % clear what you meant by "" ~ ind ~ "" ( * independent * ?"
128677,what is the nature of the data ?
128763,"hint : given that all densities must represent a total probability of $ 1 $ , what are the possible constants of proportionality ?"
128868,"what do you mean "" linear data "" ?"
129179,have you seen [ this question ] ( url ) ?
129239,it really depends on * why * you are making this classification . different criteria emerge depending on how the tail influences the questions of importance to you . what is the reason you are evaluating distribution tails ?
129322,"it is not exactly about "" how to do mc "" , but are you familiar with this package : url ?"
129549,do you know the standard deviation ?
129592,and what is the problem with recreating results ?
129644,"it's impossible to tell what you are asking because you do not specify what numbers might be written on the balls in those buckets . in addition , your process is not completely defined , because even when $ sum c_i ge n $ , it will be possible to exhaust one of the buckets during the trials if it has fewer than $ n $ balls in it . did you perhaps mean to stipulate that * all * the $ c_i ge n $ ?"
129713,are you asking about the distinction between stratifying on some categorical variable versus including said categorical variable as a factor in a ( mixed-effects ) meta-regression model ?
129766,"welcome to the site , peter . can you clarify a few things ?"
129788,"science11 , do you mean max ?"
129801,"i have never encountered any application where a "" high standard error . . . is desired . "" what exactly do you mean by "" capture maximum variability "" and why is that a good thing ?"
129806,where are you getting this from ?
129792,but you want to calculate log-likelihood for what ?
129657,your most recent edit is intriguing--do you mean that you are just interested in a binomial probability of success in each group ( row of the contingency table ) and that you want to regularize this estimate ?
130069,are you willing to assume error normality ?
130064,""" is unbiased ( peaks at zero under null hypothesis ) "" : i may be missing something here , but relating this back to multiple regression , it's almost impossible for $ r ^ 2 = 0 $ even under $ h_0 $ . you'd have to get lucky with your $ x $ being orthogonal to observed $ y $ . demanding that $ mathbb { e } ( r ^ 2 ) = 0 $ under the null is obviously an unreasonable requirement because it is almost always going to be positive , but never negative ( similar but not identical considerations for $ r ^ 2_ { adj } $ ) . as $ rho ^ 2 $ is zero under the null , $ r ^ 2 $ is unsurprisingly biased . but perhaps you mean something else by "" biased "" ?"
131007,"depending on the kernel , feature space can be * very * large ; for example , for the gaussian kernel the feature space is infinite-dimensional . how would you want to "" compute "" $ v $ in such a case ?"
131130,"that edit is both different enough and long enough that you might be better posting a new question . also , what's a ` conference distribution ` ?"
131167,have you checked the optimization results ?
132609,"so you don't have "" rater id "" available ?"
132829,"how exactly does this book define "" estimator "" ?"
132925,"this is a little opaque . can you say more specifically what your situation is , perhaps in concrete terms ?"
133197,"i have edited the title so that it more closely matches your statement that "" my question is : how close is this to the true distribution of $ hat theta $ ?"
133392,is there a reason that you're trying to do a t-test with binary results instead of doing proportion test ?
133387,1 . could you show prediction $ hat y $ over true outcome $ y $ plots ?
133462,why doesn't it make sense to impute count data ?
133752,are you aware of this [ paper ] ( url ) that explains the difficulty with this setup ?
134276,"what do you mean by "" correlation within hospital ?"
134624,"the help is indeed abysmal . protect yourself by testing this function on simple arguments with known answers . for instance , ` inclusionprobabilities ( 1 : 2 , 2 ) ` returns the vector ` 1 1 ` . what does that tell you about the assumed form of sampling ?"
134905,"is your objective to "" perform mcmc "" or is it to learn something about the dice ?"
135429,"you need to specify in a little more detail what "" they play this game simultaneously , the first one to flip heads wins the game "" means - what if e . g . x and y both get a heads on their first toss ?"
135840,i'm a little confused . if you remove the random effect are you using ` glm ` rather than ` glmer ` ?
135962,i suggest that you are posing three very different questions . the first alone calls for a review paper . are new implementations needed ?
135255,in what sense were the values implausible ?
136828,i don't understand your situation . what are the original 6 data ?
136784,so are these * durations * ?
137089,"i guess you mean the systems * * control * * , not command . in statistics that would be disturbance term or noise term ( or input ) . can you edit also your title ?"
137143,"could you describe what the two things you're currently doing are in the question , rather than relying on links ?"
137152,"it will produce a fit that is the average of all $ 2 ^ { 10 } -1 = 1023 $ fits that can be made . this guarantees it will be worse than many possible fits , so why use it ?"
137322,i think this is fully explained at url is my answer there overlooking something you need ?
137626,fine--what is * your * definition ?
137683,"if possible , could you please add your output in this question as you got from software that you use ?"
137933,"i'd appreciate your naming the software , so that this bizarre practice can be outed . but much depends on what the "" banding "" consists of . if it's replacing a continuous predictor by a set of indicator variables , i see no guarantee that it will , as it were , point in the right direction for a later continuous fit . if it's using a discretised version , where is the computational advantage ?"
137931,"the second quoted statement appears to be nonsense . i don't think this medial , a variant on the median , has any effect on the standard fact that the median has nothing to do with totals . as explained in various ways in almost any text , there is no constraint on the median except that there so many smaller and so many larger values . using $ $ rather than $ le $ can't change that ; it's just a different way to cope with ties . or i am missing the point completely ?"
138434,what do you get when you try ?
135738,why stop the series defining $ g $ at $ n = n $ the number of states ?
138798,it's not clear to me -- how did your priors arise ?
139528,"i am somewhat doubtful in how far it even makes sense to apply a binomial model to proportions in the way done by the op . after all , ` family = binomial ` implies that the dependent variable represents binomial counts -- not proportions . and how would ` glm ` know that ` 0 . 1 ` is like "" one out of ten "" and not "" ten out of hundred "" ?"
140293,""" * the example should make use of at least 1000 samples * "" . . . so is this homework ?"
140842,have you tried different starting values for $ theta $ ?
140884,"a z-score is , * by definition * , a data value that has been recentered and scaled by the sample mean and sample standard deviation . doing anything else would not be a z-score . focusing on what a z-score is and how to compute it might be beside the point and perhaps even detrimental to your analysis . what comparison do you want to do and why ?"
140632,can you describe in more detail who you are going to get the names of the pis ?
140688,` multivariate dataset for which i have only a table including the cross-wise euclidean distances ` . is that you have the square matrix of distances between all the points ( instead of the original pointsxvariables data ) ?
141197,"you haven't given us any basis to answer this question . what exactly is this "" distance "" intended to represent ?"
141017,""" however , mahalanobis distance could be only applied to normally distributed features . "" actually , elliptical shaped . can you post the first few lines of your data set ( or some fake numbers but having the same features as the real thing ) ?"
141329,"if i understand correctly , this is a software question . what software are you using ( e . g . , r , python , spss , excel ) ?"
141870,can you focus your question a little more and perhaps ask followup questions separately ?
141933,"if you could provide some sample output that would be great . it's hard to understand what you mean by "" can't trust "" . what are you uncertain of exactly ?"
141766,did you try applying the hint ?
142300,what software are you using ?
142386,"i assume $ n $ = number of cases , $ k $ numer of folds in the cross valiation , $ i $ = number of iterations / repetitions of the cross validation ?"
142618,i wonder how is p_adjusted defined ?
143008,what exactly was the model that you fitted that is the basis for the lsmeans results ?
142917,why not simply assume u - $ tau $ - v and take $ p ( tau vec u ) p ( tau vec v ) $ ?
143091,it isn't clear what your question is . this seems rather open-ended & possibly not really statistical / about ml . can you clarify your question & its statistical aspect ?
143358,"it would be useful if you could clean up your code ( e . g . , there is an empty ` else ` branch ) and explain * what * your code does . in addition , it seems like there may be drops in your time series around the end of each year ( christmas ?"
144088,could you please clarify your question ?
144090,"is this something like , you have pass / fail data for each of 10 students in a class ( x ) , & 1 response variable for the class as a whole ( y ) ?"
144199,what is the purpose of creating the larger dataset ?
144245,not everybody has the book . can you show the picture ( or a similar one ) so others can understand the question ?
144349,why did you not post the spss syntax as well ?
144348,i have a similar question here url did you manage to solve it ?
143930,what is the definition of the fisher criterion weight ?
144597,"do you only have one row of data per species , as in the example data ?"
145083,"would love to * try * to help , but i don't know mcmcpack's syntax , so i cannot be certain what model you're fitting . is there any chance you could also show your model with mathematical expressions ?"
145127,some more detail would help - a grid of numbers without headers isn't easily interpretable . what's the value of -34 . 5598 you've put a box round ?
145379,"could you elaborate on what you mean by "" center in general "" ?"
145569,can you say more about your situation & your data here ?
145595,a faster computer ?
145875,"am i right that you're asking two questions : 1 -- can "" proper "" be re-defined in terms of the median score , rather than the expected score of a given forecast ?"
145796,can you add a plot of fitted values versus residuals ?
146118,1 . how big is your data ?
146185,doesn't the ps imply your question makes no sense ?
146461,is -110 . 824 a typo for -1 . 10824 ?
146657,""" so i might be random "" : what's i ?"
146677,"how about making a matrix , with a , b , c for rows and a , b , c for columns , and then some sort of symbol describing the "" impact "" measure between them ?"
146572,the answer might depend on how you are detecting fish . could you elaborate on the mechanism ?
146780,"in your previous version , $ z $ had cdf $ mathbb { p } ( z z ) = e ^ { zc } / ( 1 e ^ { zc } ) $ ( where $ c = 1 . 702 $ or whatever you had ) . it reminded me of url : ) is there some dodgy website somewhere that claims this is gaussian ?"
146796,"when numbers sum to more than unity , they simply cannot be interpreted as probabilities of disjoint events : that directly violates the most basic of axioms . good models parameterize the probabilities to * guarantee * they will sum to unity , so there might be the best place to investigate your situation : could you tell us more precisely how your models are managing to give such inconsistent numbers ?"
146843,""" others may have a stronger relationship between them and a lower correlation . "" can you give example for this ?"
146846,your real data has 6 observations too ?
147221,you seem to have left something off from your last sentence . can you edit your q to clarify ?
147301,it is not clear what exactly is your research question . is it that you want to determine difference in prevalence of diseases between 2 years or is it what disease change in persons between 2 years ?
147659,it sounds like your predictors are confounded with the conditions . do they vary between conditions ?
147673,can you please confirm whether the output that you show is what you get when the restriction on the coefficient for $ b ^ { 13 } $ is selected or is it the output from an ar model of order 13 with zeros for some of the coefficients ?
147810,spearman rank correlatipon ?
148282,confidence intervals are constructed for model parameters . do you mean prediction intervals ?
148416,you need explanation for correlation of equally valued data ?
148722,maybe you could use simulated data rather that file data to make your example reproducible ?
148982,what is the standard error of that prediction ?
149023,"silverfish , are we sure that he wants us to use continuous distributions ?"
149026,"could you explain what is the "" copula occurence probability "" ?"
149095,how many observations do you have ?
149227,"as a purely software question this would be on-topic on [ so ] once you edit it to provide a reproducible example and , most importantly , cite the "" memory error "" specifically . however , i think the most effective solutions are not going to be software related . they will have to involve reconsideration of this model , because the basic problem is that you are trying to estimate tens of thousands of coefficients , which borders on the ridiculous . would you consider editing the post to explain your * statistical * problem ?"
149545,why can't you work on the log scale ?
150936,"exactly what is this "" phenomenon "" to which you refer ?"
151228,just a suggestion : wouldn't it be far easier to prove that $ frac { ( n-1 ) s ^ 2 } { sigma ^ 2 } sim chi ^ 2_ { n-1 } $ and then work out the mgf for a gamma distribution ?
151386,what is the source reference ?
151588,"what do you mean by "" would this be problematic ?"
151807,"i cannot , nor can anyone else , because you don't supply enough information . have you applied the approaches and code offered in [ this answer to the duplicate ] ( url ) ?"
151827,is 9 % accuracy a typo ?
151967,the distribution of consumption is irrelevant to your problem . of concern is the distribution of the regression ( or anova ) * residuals . * what does that distribution look like ?
151840,"can you post sample data , so that people can play with different algorithms with a solution ?"
152033,are you just asking for help with the code here ?
152305,this is a complex problem . . . . . what do you expected in the asymetric case ?
152521,"it is a little surprising that skewness and kurtosis would provide adequate controls over any kind of influence in a regression situation . what is the reason you are performing your analysis in this particularly constrained way , especially since you otherwise haven't any preferences for the distributional shape ?"
152795,"if the data is binary , do you mean $ a_i in { 0 , 1 } $ at the end , rather than $ [ 0 , 1 ] $ ?"
152803,the most objective definition is already given by the formula . i suspect you are interested in interpretation of the parameters ?
152809,i think some more background could be helpful . it seems to be that what you actually want is to show that the way you split the data is helpful ?
152874,why would an empirical test be needed ?
152413,are you using filterpy ?
152958,"none of them is $ log ( x ) $ , they're all $ log ( x c ) $ , so any notion of 'correctness' there is nonsense . none of them are 'correct' for $ log ( x ) $ . to choose between them , you'd have to say more about what properties you want and what properties you're prepared to give up . what are you actually trying to achieve ?"
153044,why are you doing this in the 1st place ?
153013,"thinking about the kutosis comment . in ( my sketchy recollection of ) the proof of the central limit theorem you take the fourier transform of the distribution , then show that the non-second order terms die in the limit , which leaves you a distribution determined only by its first two frequencies . could something similar be happening ?"
153415,i still don't see a clear question in this post . what are you trying to ask ?
153547,why are you using a log-transformation for left-skewed data ?
153615,are your models nested ?
153619,would it be fair to assume both processes to come from either the same dgp or a different one ?
130025,"although the setting is interesting , you haven't yet asked an answerable question : the idea of np-completeness depends on having a * class * of problems , while you have described only one . exactly how do you want it to generalize ?"
154616,""" i have a covariance matrix and want to calculate an inverse covariance matrix . "" if you already know the covariance matrix , why are you trying to * estimate * the inverse ?"
154629,do you have individual response times for each request from each thread / user ?
155035,"the nature of this question is not apparent . is it about estimating the slope and nugget of the variogram , cross-validating the variogram , choosing appropriate search procedures , setting up the kriging equations , solving the kriging equations , or something else ?"
155206,"perhaps providing a quantitative definition of "" return rate "" might help clear things up . if you had a perfect crystal ball that could show you all details of your website usage throughout the future , so that there are no concerns about sampling or uncertainty , exactly how would you compute the return rate ?"
155408,what does it mean with respect to the models and the data if the p-value for a parametric model fit to 3 observations is similar to the p-value for a non-parametric model fit to 400 observations ?
155696,why are you missing the first four years of data ?
156330,you mean you have information on _realizations_ of $ y $ ?
156845,"greater clarity might be found if you considered that if $ beta $ is changing a bayesian wouldn't use a single symbol for it . e . g . changes over time would be indicated by writing $ beta_t $ for its value at time $ t $ , and then its behavior would be described by writing down some model for how $ beta_t $ behaves over time ( does it evolve over time , for example according to a random walk ?"
156857,"such patterns can occur when the dependent variable takes on only a discrete set of values . are the points in the lower , left of the plot all zeros ?"
157231,"many on this site don't know acronyms outside their own fields of interest . what is fdi , expressed as count data ?"
157234,"nickcox "" guessed ?"
157239,"might it be simpler to think of this as comparing 4 algorithms : vector / vl2 , vector / vlinf , histogram / hc , and histogram / hb ?"
157319,"are you willing to assume a parametric form of the trend ( e . g . linear , quadratic etc . with unknown coefficients ) or would you rather allow the trend to take whatever weird shape ?"
157775,is it possible to change the dag by adding a node for lung cell damage with arrows from tobacco and asbestos pointed in and an arrow to mesothelioma out ?
157816,are some values actually censored or are they just * missing * ?
157925,"as far as i can see , you are telling us that you have written some code ; it gets different answers than an old table ; and you want to know how to improve your code . i don't see how this question could be answered without having the details of what you are doing . am i mistaken in my interpretation ?"
158598,could you describe the data structure in a little more detail ?
158723,"having positive entries in a matrix is insufficient to ensure a positive determinant ; consider the 2 x 2 matrix with entries ( 1 , 2 ) on the first row and ( 2 , 1 ) on the second row . are there other constraints in your system that force $ a $ to be ` positive-definite ` , which would necessarily have a positive determinant ?"
158971,"you have given formulas , but those do not explain the meanings of those functions or their roles in this question . doing so is important for communicating your question to others and also for detecting errors . for example , you have written "" $ c ( alpha ) = - ( a 1 ) $ "" and "" $ a ( alpha ) = alpha beta ^ alpha $ . "" does that mean ( plugging the second into the first ) that $ c ( alpha ) = - ( alpha beta ^ alpha 1 ) $ ?"
158311,"when you run your parallel analysis , you are probably preserving variances of the original data . this means that random eigenvalues will depend on these variances ( as whuber has remarked in his last comment ) . can you assume anything about them ?"
159536,"doesn't biprobit usually do a likelihood ratio test that $ rho = 0 $ at the end , comparing the likelihood of the full bivariate model with the sum of the log likelihoods for the univariate probit models ?"
159752,"what are the reported $ pm $ numbers in the parentheses , are they standard errors ?"
160075,"it's possible i missed something , but i don't see anything in the paper that suggests the depicted curve is actually parabolic , nor that it specifically represents exactly the function you claim it does . you make a number of other assertions that are also not clear to me from the paper . in any case , you should justify each of your assertions of fact . how , for example do you know that the depicted figure specifically shows $ theta 2 ( lambda - theta ) i ( theta lambda ) $ , rather than it being intended more generally to represent any of a variety of possible $ theta p_ lambda' ( theta ) $ ?"
160258,are there more than one entries ( rows ) for each ( or many ) parks ?
160387,shouldn't we be dividing by $ p - 1 $ in the numerator and $ n - p $ in the denominator ?
160101,"the kind of model is determined by the response ( dv ) and by the kind of relationships you expect with the ivs . variables that would normally be dummies in a multiple regression model will generally remain dummies in other models . are the values taken by your dv ordered categories , or are they numeric values ?"
160613,whether things are appropriate rather depends on what you are trying to do . is this a potential poisson regression problem ?
160640,"this looks like two questions so it's broader than is usually desired here ( moreso than you realize ) . edit this so that it's just about how to solve your fitting problem . if , after you get an answer you still want to ask about p-values as measures of fit then do that after . and also edit the problem because there's lots of superfluous information that's in some ways a little misleading . all you need is the contingency table and the statement a b is good but it must have z 0 . that would satisfy the whole thing i think . could x be small ?"
161253,"we will need a clear idea of what question you're trying to answer . you write that you want to know which questions are the key factor , but "" key factor "" is entirely undefined . what do you want to know about your data ?"
161270,"do you mean you are interested in the posterior distribution of $ ( f_1 , f_2 ) $ ?"
161277,"good question , but i believe once you've said l2-loss is what you care about , $ hat mu_1 $ is right by definition . i'm hard pressed to say that i would ever use the midrange , because min & max are not very stable ; i might consider the midhinge ( mean of 1st & 3rd quartile ) , though . you might be interested in reading this : [ which mean to use and when ?"
161497,the crux of the matter concerns the possibility of dependence among the $ delta y $ . what can you tell us about the origin and nature of these errors ?
161623,"if the method in that paper fails you , then the measurement error must be very far from any kind of normal ( or even symmetric ) distribution . this leads me to suspect it will be important to explain your data in more detail and perhaps provide a small dataset that exemplifies the problems you have having . the title suggests there is something special about your measurements , too : exactly how do you obtain "" equally spaced angles "" ?"
161840,could you post your plots here ?
161777,"i am not sure i understand the question . your pc scores form a cloud of points in $ mathbb r ^ 5 $ . do you want to sample from this cloud such that the whole extent of the cloud is sampled uniformly ( as opposed to directly sampling the random points in this cloud , which would sample according to the density ) ?"
161770,what kind of space do the parameters belong to ?
162037,"pcs are just some derived variables , the axes / directions in the multidimensional space of the data . if i give you an arbitrary scatterplot of some data poins where all the points are labeled but the axes are not labeled - will you have difficulty inventing the missing labels ?"
162707,"what is a "" sum operand "" and how is it related to the weights $ w_i $ and the data $ x_i $ ?"
162638,any information on $ p $ or $ f $ ?
162647,"can i assume that by "" synthetic density graphs "" you mean you have a family of distributions with one or more parameters , and you want to find the parameter values such that the distribution fits your empirical data ?"
162919,be specific about your request : are you asking for the stata command for heckman / tobit or are you asking for the marginal effects from heckman / tobit ?
163377,are you sure you're looking at residuals that have been correctly standardized ?
163381,can you make your question explicit ?
163369,i can't follow your question . can you try rephrasing it ?
163652,have you considered using the twang package in r ?
163735,what groups do you compare exactly ?
163827,"did you take a look at the "" test / train-sets "" directory ?"
163836,"do you know the actual time between the timepoints , or only that , say , ` 2 ` is later than ` 1 ` but before ` 3 ` ?"
112769,1 for this well researched ( even if long ) question . it would help i think to perhaps continue to specify what exactly is confusing . is it enough to know that for fisher there doesnt exist an alternative hypothesis at all whereas for np the world of possibilities is exhausted with both null and alternative ?
164239,what is the treatment and when does it kick in ?
164323,"please be more specific . one does not simply "" model "" data without a particular goal in mind , that would not make any sense . what is it , specifically , that you aim to accomplish with a model ?"
164677,"could you elaborate on what you mean by "" wobbly "" pis ?"
165004,"if this is a time-series , have you considered using time-series methods ?"
165168,why would you do eq . 2 ?
165132,and what was the approach you used ?
166462,are your data * counts * ?
166913,do you know how many serves there were for each player ?
167266,how can you have data less than $ x_m $ when $ x_m $ is the lower bound of the support for the data ?
167628,could you clarify the formulation in the third paragraph ?
167646,which article ?
167907,"if you are predicting $ y $ from $ x $ , then it is not clear why you would want to use orthogonal regression . how does your situation differ from a standard regression of $ y $ against $ x $ ?"
169223,i think the traceback is cut off . can you paste the full one ?
169251,why are you trying to solve the problem in this convoluted way ?
169341,can you clarify what you are asking that is distinct from the linked thread ?
137995,"no this is not a dumb question , when you mean "" change seasonality "" , do you mean seasonality changes over time and is not constant ?"
171104,presumably your observations are given in a temporal sequence . but are all the time intervals the same ?
171295,could you define what you mean by * total cumulative effect * ?
171408,could you please describe your data in more detail ?
171521,"you need to give some more information . it seems you have many datasets . the data are describing similar situation , do they arrive continually with time , . . . ?"
171598,"note that $ bar { x } _1 $ and $ bar { x } _2 $ will be so near to normally distributed as makes no odds . further note that cohen's d is actually $ frac { bar { x_1 } - bar { x_2 } } { sigma } $ and you don't know $ sigma $ ( i . e . cohen's $ d $ as he defined it - see cohen ( 1992 ) , table 1 * * - is * not * a sample quantity ! ) . even if you ignore what cohen is actually doing and replace $ sigma $ by $ s $ , in what sense does "" cohen's d "" qualify being called a test rather than simply an estimate of the effect size ?"
171601,can you say more about your situation & your data ?
171535,"i would like to suggest that considerable insight into these questions can be had by replacing "" variance "" or "" standard deviation "" by some other ( more familiar ) quantity that plays an analogous role in quantitative description , such as length . when describing most physical objects , scientists will report a length . what does the length actually mean ?"
172405,what about nearest centroids ?
172573,is it conceivable that the app would give someone information that would lead to them for instance choosing a babstation instead of a nonbabstation ?
172589,what do you mean by the usual curricula ?
172606,"i have many bookcases of stats books dating back a half century . the number that are purely method-oriented is precisely * one * : gonick & smith's * cartoon guide to statistics * . even those that focus on methods emphasize understanding and suitable diagnostics . [ stat ed sites ] ( url ) focus on understanding , not methods . that suggests you and i may have different experiences of "" the way statistics , statistical learning and machine learning are taught today . "" could you briefly characterize this "" way "" and provide references to document the correctness of your characterization ?"
172617,please try to * visualize * your data . are you * sure * there * are * clusters in your data ?
172823,aren't you supposed to include the main effects also when using ` ti ( ) ` smooths ?
173636,"i did not quite understand your dataset . the variables ( attributes ) are ` count_red ` , ` count_blue ` and ` count_green ` and the data are counts . right ?"
174023,"i tried to clean it up a little . please let me know if this was what you were looking for . are you sure about $ eta $ vs . $ e $ in the second expression , the one referring to $ mu_ { t 1 } $ ?"
174546,how do the predictors in your data ( your $ x $ 's ) vary over the life of an individual ?
174741,"by the way , why is it $ frac { bt } { 2 } $ at the end ?"
174842,"how to use particular software is generally off-topic here . it's hard to see what your precise statistical question is . you want to run the correct tests and obtain the correct results . indeed , but that's advice for an entire data analysis project , a thesis or dissertation topic ?"
174871,what is $ k $ ?
174928,"just to make sure i understand the question , what are the approaches you are considering ?"
175064,i am utterly confused by this . what is the deal with the story ?
175115,"i din't use the library you mentioned , but i surprized the success of the structure ! what i see is you didn't use sparse connection but rather fully connected network with single hidden layer . how can that network learn features efficiently ?"
175141,"questions that request open-ended lists of things are not a good fit for this site , antoni . since you have already worked on an answer or two , why not reformulate this question to focus on that answer ?"
175242,could you provide more context on the specifics of the problem ?
175244,did you look at sax for ts ?
175503,"in what sense do you mean "" deeper "" ?"
175878,is your focus only on the design of the sampling grid or do you really want to optimize the final output ( the estimated number of animals ) ?
175976,"if you have a23 of spades , then the dealer cannot have 234 or 345 of spades , correct ?"
175834,can you share the data ?
176214,"if the feature is really not present on any chromosome ( i . e . p = 0 ) , do you ever get positive reads ?"
176918,wouldn't a tweedie distribution be a better idea ?
177045,"do you have data on gm volume for the hc group , or just the cognitive-performance scores ?"
177273,"( 1 ) for an excellent question . would it be fair to summarize your question as asking , "" are multiple comparisons corrections necessary when testing model stability ?"
177560,"ah . i'm not terribly familiar with exactly what stata is doing . i think there is a good chance that it is fitting a frailty model . this can be fit in r , see ` ?"
178109,any progress on this one ?
178174,"i'm not too sure i understand the diagram , could you generate a scatter plot showing the estimated error from nested and non-nested cross-validation on each axis ( presuming the 50 test-training splits were the same each time ) ?"
129769,do you mean there are a lot of distributions for which em applies or a lot of papers applying em to your distribution ?
178580,"it sounds double dipping - what do you mean by "" the functional form "" ?"
177426,"what information would you need to decide if it's "" balanced "" ?"
178792,what are the individual variances of your 27 predictors ?
179049,"could you edit your question to include a minimal self-contained example we could run , including $ y $ and $ x $ ?"
179430,how were the groups formed initially ?
180131,"point estimates ( e . g . posterior mean or median ) for $ sigma ^ 2 $ will not go to zero . the gamma prior is perfectly capable of "" dealing with "" the situation , where $ sigma ^ 2 $ is some positive value and the estimates should concentrate around the true value . or am i misunderstanding the question ?"
180208,"1 what do you mean by "" descending number "" there ?"
180248,what are the dimensions of this problem ?
180262,"whuber if i had to devise a method , then ( taking $ mu = 0 $ and $ sigma = 1 $ for simplicity ) i would do something like ` generate ` $ z sim u ( 0 , 1 ) $ . ` if ` $ ( 1- theta ) z 1 $ , ` return ` $ 0 $ , ` else return ` $ - ln frac { z } { 1- theta } $ which requires only one call to a random number generator . for other values of $ mu $ and $ sigma $ , all that is needed is to modify the $ - ln frac { z } { 1- theta } $ appropriately . of course , this _does_ use inverse transform sampling and so is not an answer to the_question_ asked here : "" is there any _other_ way than inverse transform sampling ?"
180344,well i'm not entirely sure but it seems to be the wrong syntax ( see ` ?
180450,what was your code to fit the spline ?
180854,could you repost the outputs and format them as code ( use the button with curvy brackets rather than the button with quotes ) ?
181304,"could you explain what the "" span "" $ h $ means ?"
181326,what information do you want your graph to convey ?
181377,"any time i see -ln ( p ) i tend to think information rate or entropy . in any case , i'm not sure what you mean by the a-ness of an event . is an event a large set of a or b outcomes ( simple events ) for which a single s is calculated ?"
181402,what about adding the previous ( lagged ) observation ( s ) to the current observation ?
181294,was there a performance drop ?
181605,"if you have no observation , how do you expect to estimate it ?"
182197,what's your goal ?
182488,do you seek intuitive or mathematical explanations ?
182798,"so , for region 1 , is the data saying that there are 5 countries that comprise it ?"
182718,"great progress . unfortunately i haven't read the paper closely and implemented it yet . your data is missing completely at random ( mcar ) , right ?"
183204,then why not start from random forest ?
183536,"yes it does , i didn't pay attention . otoh , when i run your code , changing sd = 1 to sd = 2 everywhere , i get almost exactly the same fraction of hits both times at the 0 . 975 quantile : 0 . 9683 and 0 . 9662 respectively . i wonder if you missed an sd = 1 somewhere in the $ sigma = 2 $ run ?"
184182,the quoted text--about using a line search--appears to have no relationship to choosing a step size . this makes it difficult to understand what you're asking . are you trying to understand what a line search is ?
184358,"but the formula you quote clearly produces a single number ! what , then , do you mean by "" single double "" ?"
184493,reduced variance maybe ?
184695,"your question--which asks to compute the inverse distribution function of a sum of squared t variables--does not seem to agree with the title , which asks to draw a sample . could you please edit one ( or both ) to make them consistent ?"
185183,"i've worked with sales trends for decades , but "" in trend "" is a new one to me ( although possibly quite common in your company ) . you seem to be saying that "" in trend "" means "" sales are good "" , whereas if it's not "" in trend "" sales are not good . is this what you mean ?"
185227,"surely you need to assume in addition that not only are the $ x_i $ and $ y_i $ iid , but also the $ x_i $ are independent of the $ y_j $ . given that , have you thought of working directly with the $ log ( z_i ) $ ?"
185525,"it appears as if you may be using the word "" cases "" in two different senses in your question , once to refer to the number of rows of the design matrix and once to refer to the number of '1's for an indicator variable . if that's not the case , could you clarify what you do mean by "" case "" in your question ?"
185550,"can you provide some actual values for the ( x_i , n_i ) pairs ?"
185634,how much linear algebra have you done ?
185787,"in general a linear mixed effects model is of the form $ y sim n ( x beta , z d_ gamma z ^ t sigma ^ 2 i ) $ you can re-express it as $ y gamma sim n ( x beta z gamma , sigma ^ 2 i ) $ . in your case this means that your conditional fitted values $ hat { y } = x hat { beta } z hat { gamma } $ . as such your residuals conditional to the estimated $ hat { gamma } $ are simply $ epsilon = y- hat { y } $ . do you use a particular piece of software for this analysis ?"
185937,this completely depends on what type of learning model you're using . which ones do you care about ?
186122,are you really fixing $ n $ ?
186236,why do you want this ?
186254,""" how to obtain measures of both errors after running my 'normal' and 'robust' models "" the standard errors are in the output , aren't they ?"
186324,have you perhaps omitted some information ?
186404,how are the lengths $ w_i $ chosen ?
186429,"don't use coefficients . use r-squared ( or adjusted r-squared ) . they tell you how well your data is explained by the model . since the only difference between my proposed two models is only whether you use hhincome or education , this also tells you which one of these two variables explains the data better , given the other variables you've included . but different question . why do you want to know which variable is "" better "" at explaining the satisfaction level ?"
186495,could you attempt to clarify your question ( by editing the text ) ?
186603,is there any relationship between the two martingales ?
186656,is it possible for the number of patents to go down ?
186708,"this is hard to follow . if you are asking how the clustering algorithm works , be aware that there are * very many * different clustering algorithms that work in very different ways . can you clarify your situation & what you're after here ?"
187074,could you clarify what $ m_1 $ is ?
187247,there are many threads here on outliers : did you read some before posting ?
187259,thank you for the fomulas : are you missing a $ z $ in $ p ( y_j theta ) $ in both formulas ?
187076,what kind of data set is this ?
187454,"what you've just described changes the situation a lot : many more rows , and independent as opposed to dependent observations . maybe you'd like to revise the 'original question' part of your post to fit that ?"
187503,have you looked at the [ glm source code ] ( url ) ?
188040,what is a relu network ?
188112,how does this address bias ?
188174,what are the sums over ?
188229,"do you mean because "" ` type4 : ca ` "" is listed in the output ?"
188413,you lost me early on : what are you predicting ?
188314,"a chi-square distribution exists for any positive degrees of freedom . do you mean "" i can't find tables for really large d . f . "" or "" some function i want to call won't take arguments that large "" or something else ?"
188777,could you clarify what you mean by your second bullet point ?
188925,"1 . "" to obtain unit variance i must multiply by the std . deviation "" --- umm , no . 2 . how skew are the problem features ?"
189002,"i don't quite follow this . what do you mean by "" min $ cdf $ "" ?"
189130,how do you want to deal with degenerate distributions ?
189266,"correct me if i am wrong , but isn't it a factorial with split-plots ?"
189215,"i don't see how $ p ( e x ) $ can possibly equal $ delta ( e - e ( x ) ) $ , as what happens if $ delta 0 $ and $ e e ( x ) $ or the reverse ?"
189385,"you're seeing the analogy between the sampling schemes clearly enough . if a quality engineer were interested in calculating a confidence interval of a given length for the proportion of defectives in a batch he might use cochran's formula to work out the required sample size , given the conditions were met that make it a decent approximation . but he'd more often be interested in specifying rules for accepting or rejecting the batch that guarantee batches with more than a given number of defects are rejected with no less than a given probability . what are you interested in ?"
189424,have you tried to specify the base level rather than last ?
189618,"however , on reflection , i suppose now that you're not after univariate data sets with the same boxplots , but instead seek bivariate data sets whose $ x $ 's and $ y $ 's all have the same set of two boxplots , * and * which have the same least squares line -- is that right ?"
189978,a couple comments : 1 . ) that dataset alone is insufficient : it does not include the current * age * of the components 2 . ) are implying you are interested in seeing how reliably changes over time ( another thought would be to see if it changes with number of active components ) ?
190698,"1st , be aware that asking for code help is off topic here ( i know that you aren't quite doing that--it's just a warning ) . 2nd , this is going to be hard to answer as given . can you paste in your output , some plots , etc ?"
190755,what is the probability to see [ two independent questions ] ( url ) on that topic on x validated within 10 hours ?
190825,"concerning asymmetry , are you perhaps asking the same thing addressed in the thread at url please note that the question of "" main peak . . . high and sharp "" is a completely different issue . it is rare that anyone would even care about that ; often sharpness of the peak is used as a visual proxy for how long the * tails * of the distribution are . could you perhaps tell us in more general , non-statistical terms what features of each image you are trying to describe or learn about ?"
190963,"are you asking for python code , or how such probabilities are calculated mathematically ?"
190944,this is a tough one to answer because you seem to be asking us how to ask the question ! could you please tell us what the actual statistical problem is that you are trying to solve ?
191131,so basically do you have just a pair of single-valued variables observed over time ?
191439,see edit to title for how to put a hat on $ beta $ . what should c9 be ?
191548,could you provide - possibly made-up - data sample of such data that can be used as example ?
191545,"could you give an example of the kind of covariance matrix you are interested in , say for $ n = 3 $ ?"
191685,why do you need to determine that ?
184064,what is wgn ?
192145,why have you decided the data have 3 clusters ?
192057,"just to be clear , the random variables are not necessarily identically distributed , right ?"
192428,""" both models predict some variable . "" do the predict the * same * variable ?"
192447,how much data do you have per person per song ?
192589,are you simply wanting to customize pictures ( graphs ) or are you wanting to do something with them ?
192649,"you might have better luck looking at the literature on kernel density estimation with gaussian kernels . since you have a mixture of gaussians with one per sample , as the number of samples goes up , do you get an asymptotically unbiased and consistent estimator of the distribution ?"
191810,can you include the output from your original model ?
193264,"by "" how many turns it will take to win "" are you assuming that you win ?"
193384,"you seem to know that it's useless to use future information to predict the future . consequently , it's difficult to determine what you are actually asking . could you clarify ?"
194248,nice question . is there a chance we see the models' output ?
194389,"you may be able to derive an anylitical solution with the conditional distribution of $ x_k $ . i . e . $ f ( x_k x_1 , . . . , x_ { k-1 } ) $ . can you tell us what that conditional distribution is ?"
194457,how do you know normality and equal variance are violated ?
194396,how stable would it be if you took the log of the values before calculating the parameters ?
195127,"1 . so you have some set of bins and then label the values in each bin by the left end of the bin , except that in the lowest bin you use $ 0 $ instead of $ - infty $ as the label ?"
195198,how big is your data ?
196613,could you clarify your last paragraph ?
196773,is epsilon a predefined constant ?
196689,""" most of the sources "" can you list them ?"
196997,statsstudent can you elaborate what it means by 'time-varying covariates' ?
197170,do you maybe have complete separation ?
197265,` i want to know the covariance . . . ` you want to know the covariance between two entries of the random scatter matrix s ?
197264,"possible duplicate of [ conjugated priors ( pareto and beta ) , name of the unconditional distribution ?"
197338,how are you measuring predictive power ?
197517,can you share a scree-plot from your pca ?
197825,""" the next sample will be higher "" - what does this mean exactly ?"
197853,"two questions . first , what is $ sigma_ { xy } $ ?"
197949,is you design matrix x well conditioned ?
198124,user2957945 can you edit your question to include the output from the model that used ` select = true ` ?
198154,could you please correct the title from its obvious typos ?
195350,"if you consider the speed as a scalar , it seems like a kriging problem in spatial statistics ?"
198694,( 1 ) what does $ phi $ have to do with the rest of the question ?
198726,it all depends on what you are willing to assume about the distribution of $ y $ . two characteristics are particularly important : is it a member of a parametric family or not ?
198781,why not reduce the scatter to the two medians ?
199185,"could you explain what a "" correlation difference "" is ?"
199256,is x measured in percentages or is it a proportion or some other unit of measurement ?
199294,"i really have a hard time understanding your second paragraph . in particular , can you try to reformulate the second sentence in that paragraph ?"
199726,we need more information . how are the 5000000 data constituted ?
199882,what do you mean by brute force over the coefficients ?
200245,it seems multilevel model may bt the answer . have you considered it ?
200272,"what does "" much more sufficient "" mean ?"
200319,closely related : [ is every covariance matrix positive definite ?
200459,"do you have 2 linear equations in 3 unknowns , and therefore , leaving aside the uncertainty , an under-determined system , not over-determined ?"
200595,url ?
201502,can you restate the riddle here so readers don't have to follow the link ( which also may break in the future ) and then watch a video ?
200252,is it correct that you have individual survival time ?
201919,an obvious one would be [ added variable plots ] ( url ) ?
202055,"in order to obtain an answer you would need to stipulate a quantitative criterion for what it means to "" work "" . could you expand your post to provide that information ?"
202182,"what do you mean by "" interesting aspects "" ?"
202326,"when this algorithm fails , could you try another algorithm ?"
202336,possible duplicate of [ how to calculate precision and recall for multiclass classification using confusion matrix ?
202627,greenparker the answer is simple : they are not . how would you imagine normal distribution centered at undefined mean ?
202617,"can you clarify this for people who don't read python , & make it more software-neutral ?"
203065,"do you mean "" effective "" or "" efficient "" ?"
203108,could you share the dataset ?
202878,"why are you trying to make the data more "" symmetrical "" ?"
203454,"you're trying to find a good penalty factor by searching over models : it might be an idea to start by seeing how long it takes to fit a single model with a given penalty factor . ( also , is the full model over-fitting in any case ?"
203423,"what's "" the book "" ?"
203574,"( whether in the database or one you construct via the various operations you apply to a database -- joins , projection , selection and so on ) ; you choose or generate the table and then apply the relevant ( to your particular question ) analysis to that table . as a result i find your question unclear -- if i understand it the answer is obvious ( r , for example , is heavily organized around applying statistical analysis to data frames ) ; if i didn't understand it you should be clearer about what exactly it is you want to achieve . specifically , what sort of a statistical question would you be answering ?"
204083,"what does this topic have to do with "" big data "" ?"
204110,what is the correlation ?
204181,"could you elaborate on what you mean by "" scalar information about the contents of $ hat a $ "" ?"
204186,"` housing health crime & transportation ` why wouldn't you perform pca on this subset of "" dimensions "" only ?"
203785,a fully bayesian model over which you want fine-grained control to tinker with the model specification ?
204234,could you explain what you are trying to accomplish ?
204634,"double checking , you want to minimize : $ $ h ( h , d , i_ { max } ) = frac { d } { 2 } sum_ { i = 1 } ^ { i_ { max } -1 } i ^ 2 [ h ( i 1 ) -h ( i ) ] ^ 2 d ^ 3 sum_ { i = 1 } ^ { i_ { max } } i ^ 2 v ( h ( i ) ) ?"
204753,can you trace where the nans are coming from ?
204921,what is unclear for you in this example ?
205475,"let me see if i get this straight . . . your "" event "" variable here is "" nonresponse "" which i hope to mean "" response "" , which you have measured time-to-event , e . g . time until responding . and each participant who swings from one season to the next is * censored * at the end of the season and * re-entered * into the next season at time 0 . my question to you is : what on earth is time zero anyway ?"
205494,"borrowing a page from computational linguistics , why wouldn't you also be interested in how the sound "" shapes "" of the words matter ?"
205090,"in addition to clarifying about what you mean by "" mad , "" "" flagged outlier , "" and "" on-call , "" and providing perhaps a small sample of data directly , it would help a lot if you could give a bit more background about the nature of the measurements ( are these 3 replicates under the same conditions , or evaluations under 3 different experimental conditions ?"
205481,such values are usually a sign of a data issue . what happens when you look at tabular analyses ?
206251,"can you say more about your situation , your data & your goals ?"
206188,can you provide all of your data ?
206237,"normal procedure is to calculate errors on the original scale , i . e . , after back-transforming your forecasts ( exponentiating and cumulating , the back-transformations of logging and differencing ) . could you explain in what sense you suspect that this might "" skew "" the results ?"
206973,sounds like you're using a wrong ( ?
207329,did you formulate this hypothesis before analyzing the data or in response to what you saw in the boxplots ?
207552,how did you obtain the bayesian posterior probabilities that each arm isthe best ( right before the last paragraph ) ?
207849,"how do you define "" unhealthy "" ?"
207965,"well , where does e . g . the wald test come from ?"
208039,"do you know the distribution of treatment onset times , at least ?"
208041,"( 1 ) how is "" conversion rate "" related to the abstract setup you initially describe ?"
208090,can you provide sample data and detail what questions you would like to answer with that data ?
208417,` ?
208014,"your language appears to confound the counts of certain things with the "" sample space . "" could you clear this up by editing your post to explain what * you * mean by "" sample space "" ?"
208578,bear in mind the negative binomial is a discrete distribution . why do you want to normalize it ?
208687,"out of curiosity , what text ( s ) or other sources are you working from ?"
208647,does the fd regression have an intercept ?
208814,can you elaborate on what exactly you're trying to accomplish here ?
208932,"( 1 ) because both $ u $ and $ v $ are positive , you can substantially simplify the "" strange underbraced term "" . ( 2 ) in question 3 , what do you mean by "" this equation "" ?"
208948,could you add a reference to the paper in question ?
209007,that's an unfortunately vague definition . [ wikipedia ] ( url ) to the rescue ?
209247,"more precisely , hodrick-prescott ( hp ) filter . djohnson , could hp filter be useful for forecasting ( which is the goal of the op ) ?"
209358,this is an interesting question . could you edit your question to include a representative sample of your data ( including timestamps for which there are readings for the towed ship as well as timestamps for which there aren't ) ?
209422,"just for curiosity , if your goal is to optimize a function , why don't you look at modern methods for global , nonconvex stochastic optimization as opposed to a mcmc paper from 1991 ?"
209614,"who is the "" author "" ?"
209256,does this have something to do with how sklearn centers the data before transforming it ?
209800,why can't you only compute the score for a and b when you are working in the lda-reduced space computed with a and b ?
209980,what do the results look like _without_ the log transformation ?
210296,what are the columns ?
210506,could you explain why values are missing ?
210229,"do the zeros in your response variables represent real values of 0 , or are they just below your measurement threshold ?"
210943,are $ s_n $ and $ y $ in the $ sup $ inequality the same as $ s_n ^ d $ and y ^ d $ ?
211463,"please add the ` [ self-study ] ` tag & read its [ wiki ] ( url ) . in addition , i'm not sure how well anyone will be able to answer this . are you expecting people to run your code ?"
211482,why don't you read the package documentation ?
211707,"while i haven't looked at this closely , my first guess would be that the parameterization that r uses in linear regression is different than scikit-learn's regression . how does scikit-learn handle the parameterization of categorical variables ?"
211361,"it seems your the link in the "" pre-answer "" answers the question about how you "" start considering as 'open' events like drawing a red ball from an urn ?"
211921,you need to clearly state your two ( apparently ( ?
212205,what is your question ?
212293,"the ccc is a comparison of how much better the clustering is than a uniform random . if you had a decent first estimator of kernel bandwidth , then you could use a kernel method to tell you "" where your data is "" . also called a "" nonparametric density "" . you could restrict your uniform sampling to those regions if you use a threshold . ( 0 . 001 aka 0 . 1 % ?"
212772,i think you are perhaps struggling with what you need to compute . have you looked at likelihood functions and mle ?
213192,i have edited your question a bit . perhaps you could also add your temperature data ( past and forecasted ) ?
214720,could you post your 10 data points ?
214963,"can you paste the actual numbers in , instead of a picture of them ?"
215041,how did you come up with the equation $ p ( a cap b ^ c ) = ( 0 . 1 ) ( 0 . 8 ) $ ?
217875,could you give some more information ?
246779,this all looks terminally weird to me . how do the significance levels change when the p-values are the same ?
272971,* specifically * what differs between the two results and by * exactly * how much ?
273630,have you looked into survival analysis ?
215839,can you state concisely the question that you hope the statistics will answer ?
215962,this is going to be difficult to answer as posted . can you paste in tour data and your model output ?
217751,"it's unclear what you mean by a "" volume metric . "" could you explain what that is intended to represent ?"
218189,"why not turn your comment into an answer , wolfgang ?"
218253,"could you please explain in more detail , what the "" cell-wise differences "" are , that are to be minimized ?"
218525,"neither the [ kpss ] ( url ) nor the [ adf ] ( url ) test test against nonstationarity * in variance * - the kpss tests for trend stationarity , the adf for integration . so it's little surprise that they don't tag your series as heteroskedastic . have you tried simply fitting ( g ) arch to your entire series ?"
218931,"` on the spss website i couldn't find any explanation ` explanations could be found on this site , url can it help ?"
219446,welcome to our site ! i think this is a near-duplicate of [ does the order of explanatory variables matter when calculating their regression coefficients ?
219619,are you asking about ml specifically or multivariate models in general ?
219832,"but it seems that you haven't disclosed statistically what sort of "" statistical power "" you suspect to be affected in the regression scenario . factor scores , albeit approximations , can be seen as better or fine-tuned approximations to what the _concept of latent factor_ implies than mere sum / average . then , what can be expected to be a more "" powerful "" predictor in most general sense - a fine measure or a crude measure ?"
220001,some points i think need clarifying : ( 1 ) what's the purpose of fitting the same model to progressively larger samples ?
220017,your diagnosis about no ` france ` samples being predicted as such is correct ( = zero true positives for this class ) . do you obtain the confusion matrix from the same data or different data as you trained your model on ?
220189,""" has the correlation of 0 . 9 "" ?"
221158,are you using support vector regression ?
221336,could you explain what the weights * mean * ?
221337,"gautier jacquemain two questions : are you comparing ` group = 1 ` to ` group = 2 ` and if so , why aren't you using the mann-whitney test ?"
221354,why not just choose 500 clusters ?
221814,"seems like it , yes . but why not cross validation ?"
222033,in general separation needn't be seen as a problem - see [ how to deal with perfect separation in logistic regression ?
221933,"i tried to clarify the question , feel free to rollback in case i misunderstood something . and please review the "" training ratio 75 % and 30 % validation and testing ratio "" part - those don't add up to 100 % percent . do i understand that you have 19 samples that you use to train and evaluate both your knn and ann model ?"
222111,is this a question from a course or textbook ?
221880,"( 1 ) in the python script you are generating some random data every time , right ?"
222821,$ epsilon $ measures the error of approximation . it is meant to be neglected in calculations . the rest of your question asks about how to calculate formulas that you have very clearly set forth--so what exactly is the problem ?
222832,do you actually * need * forecasts on minute level ?
223246,can you say more about step 3 ?
223050,have you tried finding the posterior distribution for this ?
223652,what is in your ctrl object ?
223643,it's not at all clear you have heteroscedastic residuals . are you asking about how to improve this model or about how to make your ` r ` code work ?
224145,( 1 ) by what mechanism could the two experiments possibly * not * be independent ?
224483,"welcome user8170 . can you elaborate and give additional details about your question ( including a link to the paper , ideally a non-paywalled version ) ?"
224762,it also has zero degrees of freedom . what does the summary of the model look like ?
224749,do you see this as a coding issue or a conceptual bayesian issue ?
225218,why do you need any of the variables to look normal ?
225595,what's your goal ?
225776,"you're using a library here that you don't import . where do ` filter ` and ` % % ` ( and , for completeness , ` ggplot ` ) come from ?"
225978,have you considered using the dbscan ( url ) clustering algorithm ?
226081,"are you just trying to prove a known result , or do you not actually know whether the result is true ?"
226152,"yes , but they provide a citation to williams original paper . perhaps it's worth looking into ?"
156791,do you generally want practical how-to-do answers or underlying statistical basis answers ?
226962,welcome to cv . where is your question ?
228931,"why do you need the area "" under the curve "" ?"
228981,what is your question ?
229282,what's q in your question ?
229165,"thanks ! - those graphs are much easier to read . what are "" copy number "" & "" sample "" ?"
229370,aside $ r ^ 2 $ you could consider [ rmse ] ( url ) and [ mad ] ( url ) as somewhat standard metrics to show . you should also look at relevant residual plots . you mention the use of ` glmer ` but you don't mention what kind of response variable ` richness ` is . can you please elaborate on this further ?
229499,would the probability not be : $ int_ { 0 } ^ { b } f ( x ) dx $ - $ int_ { 0 } ^ { a } f ( x ) dx $ ?
229195,"you have two various that correlate , x and y , but you think there's a spurious correlation , i . e . the correlation between x and y is actually due to a third variable , z . do you know what z is , and do you have data for it ?"
230022,can an you give the context of your point estimates ?
229487,why don't you try this url to check if it gives the same results ?
230167,"i don't understand your question . what do you mean by if it's "" really probability "" ?"
230057,"could you explain what you mean by "" the p-value calculated by random forest , "" especially in light of your prefatory remarks that rf doesn't compute p-values at all ?"
230374,"once users start interacting and providing you scores , would a straightforward re-training be sufficient in your case ?"
230530,?
231236,can you make this more specific than 'can i have some advice' ?
231255,can you clarify what you mean ?
231313,"the meaningfulness of applying pca to totally different kinds of objects , such as first differences of values and second differences of values , is doubtful . could you explain what you're hoping to accomplish with pca ?"
231345,"in the formula of $ s $ , why is it $ y_t - bar { y } $ and not $ y_t - y_t $ ?"
231329,shouldn't you be using the log likelihood ?
230983,"are you trying to analyze the effect of some group of factors on business failure rates among units changing cohort membership , as defined by rating , over time ?"
231738,"have you considered analyzing the data like a contingency table and using a chi-square or similar test to compare groups a and b in terms of the the distributions of cases among results 0 , 1 , 2 , and 3 ?"
232031,clarification questions about your experimental design : how are different factors nested inside each other ?
232408,can you expand on your context ?
232184,to op : why do you refer to your sample as being censored ?
232784,"i am not fully clear on your set up . in the general case , even without noise , you cannot necessarily assume the integration constant is zero . so the model seems to imply a purely oscillatory motion ?"
232593,i am not sure what graph have you plotted . are you using r ?
232876,"minimum chi-square is consistent . some of your assertions don't appear to be correct ; the asymptotics should be the same for minimum chi square and ml if you're using the same data for both -- if you are quoting sources for those statements you should indicate who said what where . i imagine you're reading things for two different situations . ( also , are your original data discrete or are you discretizing them after estimation ?"
233202,"also , there's a reason why recommender systems are not simply logistic regressions - how are you taking into account the fact that for some of the books you like there may be very few reviews ( or no review at all ) , while for others there may be many reviews ?"
233271,please post a reproducible example . without that it is hard to say what might be going on . certainly the variance of the random intercepts seems very high . have you looked at their conditional modes with ` ranef ( ) ` ?
233143,not a direct answer but if you have zero-inflation have you considered using the pscl package to fit it ?
234105,"have you looked at the conditional distributions ( e . g . data in a single "" x "" bin ) ?"
234452,""" unsurprisingly because statistical methods have developped since the 1960 "" . . . by that criterion , the mean and the median should be even more criticized ! at the very least they're * hundreds * of years old . can you offer a quote for exactly what criticism was given ?"
234495,"it would be helpful if you could describe the data and analysis-goal at the beginning of your question i think . if i understand correctly , you have a data matrix where each row is a site , and each column is a species , where the entries are counts of individuals ?"
234653,are you familiar with matrix equations ( systems of linear equations ) ?
234853,"did you try reproducing numerical results provided in the paper , so as to provide you an expectation of how well the authors think it works ?"
234574,your code is not reproducible . what libraries are you using ?
235476,"since you have used the [ self study tag ] ( url ) , can you tell us what you have tried so far ?"
236003,is there any particular reason why you want to remove non-significant variables ?
236135,is there any reason why can't you simply use linear regression ?
236130,this is hard to follow . can you provide a sample of your data ?
236256,what do the measurements $ z $ look like ?
236709,"first , try to get your concepts right . data is not "" significant "" or "" not significant "" , some hypothesis may be . i think your null hypothesis is that the probability of event in tose two series are the same , but you have time series dependence within the series . did yoy try to see at the autocorrelation function ?"
236752,you're going to need to give us more information . what is the study about ?
236815,"for an extremely large sample size the two should indeed conincide , but for any finite sample size a realization may deviate from the true curve . can you add the means at each of the doses to the plot ?"
236846,have actually visualised the fits ?
236889,can you upload a plot of the coefficients versus lambda ?
237033,"are the model data * snapshots * with a separation of 1 day , or * averages * over a day ?"
237280,you're going to need to say more about this . are these posterior distributions for some parameter after bayesian analysis ?
223230,is there a reason why the time-domain gets smaller in as the reps increase ?
238430,are you sure this is a confusion matrix ?
238514,which algorithm options did you use in lsqnonlin ?
238613,what is the example about ?
238655,"when you say , "" this method breaks down . "" is the basic problem you can't do a cholesky decomposition of a singular matrix ?"
239294,"i'm not sure what you mean by "" attribute "" . are you thinking of causation ?"
238549,"as you allude to , with these volumes of data significant results become the rule rather than the exception . would it not therefore make sense to stop thinking about statistical significance and instead think about whether the difference between the models have any practical consequence ( i . e . stop thinking about $ p $ -values , and begin thinking about [ effect sizes ] ( url ) ) . a meaningful question may not be "" do these models produce different results ?"
239504,does it make sense to use the switchpoint construction when defining your function ?
240498,just to better understand your situation and put glen_b's answer in context : how many predictors and observations do you have ?
239239,"could you give a reference / link to the "" book by hansen "" ?"
240171,significant in what sense ?
241291,( 1 ) that's not the cdf for rolling a fair die . ( 2 ) what are you asking ?
241383,the probabilities $ p_n $ and $ q_n $ are themselves changing with $ n $ ?
241450,"you have 4 parameters and 5 data points , which is not really enough data to reliably estimate the parameters . however your stated goal seems to be more about interpolating the $ ( x , y ) $ points than anything to do with the parameters . why not just fit a line ?"
241586,perhaps i am being a bit stupid here but how will you know your icc and hence de until you have done the analysis ?
241737,can you provide a simple example ?
241769,do you want to add the self-study tag ?
241948,if i understand correctly the population starts by being finite and then it is assumed that it becomes of infinite size ?
242103,"welcome to cross validated ! a "" level of confidence "" in what ?"
243114,is this not what is usually called [ partial correlation ] ( url ) ?
243789,"sample an unbiased sample and downsample the "" biased "" group ?"
243973,any chance you could post the data without me having to download that linked file ?
243766,did you use opticsxi ?
243878,"why binomial and no other distribution that is "" designed "" for continuous data ?"
240569,how are you using t-tests to compare classifier performance ?
244445,i don't follow what your question is here . are you just wondering why one model is less variable ?
244632,so since the crossvalidation is not working as expected you have to explain how the crossvalidation and data splitting is set up . it sounds like it is not random ( can you think of any reason why the data might change between chunks ?
244758,"could you please clarify the meaning of your "" lastentry "" column ?"
244917,have you problems with the wikipedia entry on [ this distribution ] ( url ) ?
244996,wouldn't the inequality have to be $ x_ { k-1 } ^ { alpha_ { k-1 } -1 } mathrm { x } x_k ^ { alpha_k-1 } neq ( x_ { k-1 } x_k ) ^ { alpha_ { k-1 } alpha_k - 2 } $ ?
245527,where does it have this ?
245414,as it stands your formula does not match your question which is not quite clear either . can you edit more details into your question ?
245816,does each patient have proximal and distal measurements ?
246236,can you provide a replicable example ?
245646,what about [ kendall rank correlation ] ( url ) ?
246623,"to be clear ; you want to flag a user if they're expected to purchase within the next 3 years . you're going to create a model to predict the "" flag "" column and you want to know if the "" purchased "" column can be of any benefit to making a prediction model . is that correct ?"
246736,"once you have finished that theoretical essay , would you be some kind as to link it here ?"
246971,"do the other studies also assume the same conditional mean and conditional variance dynamics , i . e . arma ( 1 , 1 ) -garch ( 1 , 1 ) ?"
247223,would you clarify the * experimental design * a bit ?
247311,you may want to have a look at the answer to this question : url is the network initialized ?
247691,"what do these 19 , 576 observations represent ?"
247701,why don't you post your data and i will try and follow up on chris . is the data set monthly ?
247648,why is this off-topic ?
248399,do you have an exaple dataset ?
249136,"1 . have you verified that these terms are not equivalent , or are you just assuming that they are not ?"
248003,"these formulas make no sense . in the first it looks like we must assume "" $ x $ "" means "" $ x $ "" , but in the second the left hand side refers only to $ y $ whereas the right hand side refers to "" $ x $ "" , which is * undefined . * surely a textbook would not get its notation so wrong ! are you sure you have transcribed correctly ?"
249298,"questions about software implementations ( like "" how to do x in r "" ) are off-topic here . your question , however , raises some important statistical issues that i will try to address over the weekend . in the meantime , could you please clarify the relations among samples and patients and "" phenotype condtions "" and disease status ?"
249620,"1 . please give a full reference to the book ( author , year , title publisher ) 2 . what answer do you get ?"
249632,did you hold out data ?
249553,"your title question seems potentially valid here , but the body is nothing but python code , which many people don't read . can you add some text to clarify your situation , & sufficient pseudo-code to be intelligible ?"
250053,"i am a little confused arma ( 5 , 3 ) has 5 autoregressive parameters and three moving average parameters . this is a stationary model . but you claim a trend and a seasonal component and your data suggests it . how did you fit the model ?"
250313,this is somewhat surprising . any chance of a reproducible example ?
250463,could you please restate your question ?
250662,since you are dealing with demographic variables the affect surviival why wouldn't you use a cox proportional hazards model or some generalizatio n of it . if you use kaplan-meier wouldn't you be comparing several curves ?
250728,i am sorry . you edited it twice but there is a lot i don't understand . i doubt that the problem is with the pseudo random number generator . are you transforming the uniform random numbers to some other distribution ?
250767,have you tried transforming the data ?
250761,"adding to what michaelchernick said , are $ x $ and $ y $ discrete or continuous ?"
251213,"[ in statistics ] ( url ) ) be deviance we rather understand the -2 times log-likelihood , are you * sure * you mean deviance . . ?"
251283,"please , explain your idea more precisely / detailed . what incremental updates in this case , etc . could your question be put in a simpler form ?"
251315,"just to clarify , you have fitted a trend line for each plot and then abstracted the slope which you are going to use in your definitive analysis as what you call "" trend "" in your list of variables ?"
251506,could you add some reference to literature that you find difficult ?
251640,"by "" sinus-like signal "" do you mean sinusoidal ?"
251683,( 1 ) is it intentional that $ beta_3 $ appears twice in the first regression ?
251652,have you considered running a nonparametric estimator ?
251861,an important factor is how many variables $ x_i $ there are ?
252106,"if c is a bijection with y , then c is y ?"
252398,various necessary bounds on the values of $ a $ and $ b $ arise . are we to assume that these hold ?
252616,1 . ` can we find a plane for lda instead of a line in this specific case ?
251957,how much missing do you have in the data ?
252965,can we say that ` no cancer ( 3 ) ` is ` cancer ( 2 ) ` ?
252828,can you please spell out lsd ?
253190,"1 . i don't know , but what happens if you specify a different solver , such as ` control = lmercontrol ( optimizer = "" bobyqa "" ) ` ?"
253608,counts can be 0 . how can you take the log of 0 ?
236699,"it might help if you write out the underlying "" correct "" model you believe is going on . ( you can use [ mathjax ] ( url ) . ) [ this ] ( url ) might be relevant for the "" noise "" distribution ?"
253650,what is c_n ?
253738,might be easier to answer if you gave clearer references . the first formula ( from where ?
254091,"it seems that you want to maximize some function of a convex combination of random variables . i . e . , find the optimal convex combination . but what that function is supposed to be is hardly obvious to me . you need to figure out what the 2nd ( additive ) term of the right-hand side is supposed to be . if n = 2 , can you write it out explicitly ?"
254669,then i do not understand your description . are you dealing with i . i . d . r . v . 's ?
255054,"what is an "" lme "" model ?"
255526,"presumably you do pca on snps without taking cancer type into account , whereas random forest aims to predict cancer type . why do you expect them to select same features ?"
255570,see [ what non-bayesian methods are there for predictive inference ?
255828,nobody can answer this question properly without asking for more information from you . most probable issue without any information : are the target classes equally distributed along both test and training data ?
256039,please provide more details and context . exactly how is the term used ?
256189,think about the range of the integral -should it go to infinity ?
256363,what then is your question ?
256505,the code's not transparent to all of us ! what's the role of ` ind ` ?
256843,"i don't know enough about this analysis to answer , but have you come across the paper "" have multilevel models been structural equation models all along "" by curran ?"
256916,ain't this just a random effects model . . ?
257079,"there are a ton more . from classic decomposition to transfer function methods , from kalman filters to dynamic regression . . . maybe show us your data so that we can help ?"
256864,"can you include your r code , please ?"
257118,"i am not sure whether i am misinterpreting the question , but would not a structural equation model also do the work ?"
257397,""" inverse bell curve "" is not a term whose meaning is clear . do you mean to refer to the inverse of a cdf of a normal ?"
257404,"what interval are you calculating when you use the linear model ( is it for example , an interval for the mean - the usual regression confidence interval instead of a regression prediction interval ?"
257692,i can't tell what you did . what are the axes of your plot ?
257835,your assumptions are about a 'model' . . . but you then ask what sort of random variable 'describes' reality ( the number of observed shooting stars ) . who knows ?
257899,"what would a "" scale invariant "" cross-correlation be ?"
258022,"it comes from referring the obtained value of $ t $ to the $ t $ distribution . can you clarify which part of that you do not understand , if any , by editing it into your post ?"
258245,first some questions : why do want to split your data ?
258307,did you bother to read the help for ` poly ` which specifies that these are orthogonal polyomials ?
258390,can you show the estimated model ( ` print ( model ) ` ) ?
258560,can you post your data ?
258762,could you show some numbers to show what you mean by * rolling averages * and * averages of averages * ?
259213,so the output variable you are trying to model can take on four possible levels ?
259370,could you include the results from r as comparison ?
259591,` if i will have different signs for a first component loadings everything will be easier ` - why ?
259727,can you give some more information about the model that you use ?
259871,what questions are you trying to answer by modeling this process ?
260081,can you please give a few more details about what you try to achieve ?
260232,depends what you want from your models . inference on coefficients / unbiased marginal effects ?
260552,"could you please show exactly what vector you did find , explain how you found it , and describe how you know it is incorrect ?"
261068,"your question appears to depend critically on the meaning of "" how each of the 'single' orders vary across different subjects . "" could you please explain that more fully ?"
261190,"what is the context , can you tell us ?"
261153,why do you want to dichotomise humidity ?
261504,can you explain your model ( esp . sp . norm . cdf part ) ?
261732,what is the question ?
261826,does this qualify as [ tag : self-study ] ?
262033,"i don't get your 2nd statement , where do you see recursion ?"
262109,have you searched the literature ?
262391,how does this relation for $ g $ differ from either of those you have used to express $ p $ ?
261980,are you asking what to do with a 3 by 2 by 7 contingency table ?
262590,"where did "" $ 7 2 $ "" come from in the denominator ?"
262941,how strongly does the mean vary over time ?
262968,"this is potentially a reasonable & non-software-specific question . however , i doubt anyone who doesn't use this software ( what ?"
262975,i'm having a hard time understanding your question . my understanding of it is that you're asking about whether confidence intervals overlapping determines significance in a linear mixed effect model . or are you asking about how variability is attributed to certain sources ?
263140,can you prove that you are using same data as the tutorial ?
263222,disclaimer : i don't know your specific subject matter at all . but my general experience of iterative methods is that you tend to have something like ` do { z1_new = f ( z2_old ) ; z2_new = f ( z1_old ) ; z1_old = z1_new ; z2_old = z2_new } } until ( end condition reached ) ` ?
263377,does your matrix of ivs include a column of 1s ( a global intercept ) or regressors that add up to such a column ?
263437,both your models seem rather obscure . can you explain how they relate to your scientific question ?
263483,might have something to do with your unbalanced dataset . in ` ?
263502,why is your first model just an intercept with a random effect ?
263721,"i do not understand . . . is the process you are modeling deterministic , or probabilistic ?"
263740,"is the response really a count , or is it , for example , a rating ?"
263931,can you explain the reasoning behind your guesses ?
264002,what do you mean by * feasible * ?
264066,why not try it and edit it into your question so people can comment on how your similar reasoning is working ?
264146,"you leave us guessing , because you write "" i want to standardize ` x ` "" but you don't explain the purpose . the only way we could provide objective opinions about which method ( if either ) is "" correct "" would be to know what you are attempting to accomplish . so what would that be ?"
264305,"you may have to define that more clearly , it is not clear to me . e . g . i am not at all sure what "" the model produces a sum "" means . do you mean the uncertainty around a predicted value that some how is a sum , do you mean the root mean squared error of the model on future predictions , do you mean something like r-squared on the present data you used to fit the model , do you mean the uncertainty around individual model coefficients , do you wish to compare how well different models fit the data relative to each other ( not quite sure why you mention the several models otherwise ) , etc . ?"
264429,i don't understand why you think alpha error inflation occurs here . can you explain that in more detail ?
264613,i want r to make the model so i think it's a coding question . how do you think i made the hyperbola ?
264798,"this is confusing . your original dataset is 10849 : 3166 , or ~ 3 . 4 : 1 , is that right ?"
264855,interesting issue . maybe you can add more concrete information ?
264914,try step = pm . metropolis ( ) or step = pm . nuts ( ) . which version of pymc3 are you running ?
265291,"the question is a bit unclear . first , how is mother education expressed ?"
265412,clarification : $ x $ is $ 1 times p $ and $ beta $ is $ p times 1 $ ?
265550,can you provide a small example dataset to illustrate what you're asking about ?
265630,"when you combine the observations from a single gun , you are assuming there is a single underlying accuracy for the gun for which you can compute an estimate and a confidence interval . you have observations from several guns . is there a single underlying accuracy they all share ?"
263872,"good question . have you heard of "" indirect inference "" ?"
266053,"surely the survival outcome is not the death of the country . is the event indicator an "" incidence "" of something in each country , like a case of hiv ?"
266291,"so , are you looking for the joint probability of the entire observation sequence ?"
266490,"you have an interaction in ` eq2 ` . so , are you asking how to interpret an interaction ?"
266549,"your output gives you a hint : "" 2 singularities "" . could you check whether malel and educl aren't all the same value , or if one of the other contains precisely the same information ?"
267047,"welcome to cv . since you're new here , you may want to take our [ tour ] , which has information for new users . your question is not clear . could you provide us more information about your problem ?"
267407,isn't the stark contrast in these empirical densities enough to draw the conclusion that the data are from different distributions ?
267936,"when you say "" withdrew from the trial "" in your question , it could matter whether the withdrawal simply represented the end of data collection for the trial or if it was due to unacceptable side effects , etc . also , in your dataset a , how many events are there ?"
266896,what kind of features do you use ?
220696,"it's very difficult to give a definitive answer to this question in its current form : "" how efficient is this approach ?"
268689,this looks like a standard regression problem unless i misunderstand you . have you considered that ?
268860,"are you assuming the bias $ theta $ is the same for all coins , i . e . , at all times ?"
269449,"because this question is abstract , it is crucial that it use its terms correctly . however , you characterize the $ gamma_i $ both as random [ diffeomorphisms ?"
269563,"imo it is actually recommended to enter some kind of baselinescore in your model in the case of repeated measurements . this way you 'correct' for baselinescore ( those who score high at t1 have more 'options' to go down / have a negative t2-t1 score than those who score low at t1 and vice versa ) . the big question however is , whether the online and telephone questionnaires are similar measurements ( is subtracting the two scores really feasible ?"
269604,what exactly do you not understand ?
269680,9 / 10 ratio of what to what ?
269761,can you give more information ?
269798,are the probabilities of each team winning given in column a and column b ?
269838,what is the link between normal distribution and heteroskedasticity ?
269847,are they actually * truncated * ?
269892,"i don't understand your survey instrument . for instance , how many "" events "" is each department asked to evaluate ?"
265572,my hunch is that zuur et al . 's suggestion is bad ( why would you ever use significance tests for model selection ?
269627,can you describe more carefully exactly how the data are collected and the nature of the interval censoring ?
270431,"i share the concerns voiced by matthew : could you explain what you mean by "" the ranking . . . in the population "" ?"
271077,possible duplicate of [ how to simulate data that satisfy specific constraints such as having specific mean and standard deviation ?
271184,why did you run the logistic regression after the lasso ?
271670,what result is the same ?
271394,"note that ( because of how order of operations works ) , the expression $ ln ( x 1 / y 1 ) $ actually means $ ln ( x y ^ { -1 } 1 ) $ not $ ln ( frac { x 1 } { y 1 } ) $ ( which i believe is what you want ) . can you say more about the failure of the taylor expansion ?"
271722,you have a right to be puzzled . without context the question is comparable with is this piece of string long enough ?
271758,"confidence intervals are intervals for unknowns ( parameters or functions of parameters ) , not for data . if you want an interval for * data * you'll have to be clearer about what kind of interval you mean ( tolerance interval ?"
271971,making random samples of 50 images per expert makes me wonder what would happen if one expert was given easier or more difficult images to group ?
272571,"can you rephrase the exprssion "" event number is recorded respective to the relationship "" ?"
272920,"if you had to think of one of your measurements as the "" outcome "" and the other as a "" predictor "" , which would be which ?"
273425,what about symmetric distributions with right and left tails that are equally heavy like the cauchy distribution ?
273149,i don't think i really understand your research question ?
273845,is the nonlinear regression still convex ?
273773,can you make some assumptions about the distributrion o the original data ?
273895,"are you interested in a measure of uncertainty , inference or a descriptive measure ?"
275470,i suppose if you simulated the combinations of input value ranges that could give you what you want . that could get messy with a lot in input values and a closed ui for the software . any more detail to share ?
276110,"please explain what you mean by a "" converging pattern . "" it seems like all you need to know is whether this "" least squares "" method , whatever it might be , is consistent . doesn't the paper examine that issue ?"
276070,"to appreciate the error , emulate your calculations with different numbers . suppose , for instance , there were $ 1000 $ packets and $ 501 $ of them were underweight . ( 1 ) intuitively , how strong is this evidence against the hypothesis that half or more of all packets meet the stated weight ?"
276487,"the ` s ( x ) . i ` terms are the penalised regression coefficients for the 4 basis functions in the model , they're not smoothness parameters . you code isn't working for me ; i get an error that the ` x ` and ` y ` lengths differ . can you run your code in a clean session and update as needed ?"
276496,"could you explain why you find this "" unusable "" to estimate $ alpha $ ?"
276478,` multiple component analysis ( mca ) . ` did you mean multiple correspondence analysis ?
276772,"rather than use a simulation , why not solve the problem directly ?"
276719,what does the double greater than sign mean ?
276689,"you said : "" ( y ) is the difference between the proportion of eggs found in a given nest and the expected value of eggs regarding the mean value of the sample "" . firstly : what is the point of subtracting sample mean from proportion ?"
277631,what is $ x $ ?
277643,derived from what ?
278088,any other information ?
278101,i don't think you have formulated your problem yet . could you please explain what your experiment is attempting to achieve ?
278012,"to be on topic on [ so ] , it will need a [ reproducible example ] ( url ) . can you provide one ?"
278320,this is rather broad & ambiguous . are you saying you want to test every item on your questionnaires individually ?
278375,"there can certainly a problem with simply calculating correlation or raw time series ( e . g . see the simulation [ here ] ( url ) ) . when you say you want to "" measure the relationship "" , what are you trying to achieve ?"
278531,"description of the setup is a bit unclear . but , it sounds like you have several cages . you have an ordinal dv . from each cage , you randomly assigned some animals ( ?"
278759,"i am confused by the "" double conditioning "" of the expectation . you write $ theta_0 = hat theta $ . this could be translated "" if it so happens that the obtained estimate equals the true value exactly "" . is this the intended meaning ?"
278552,"cagdasozgenc can you give some explanation of why you want to do this , and why you are not comfortable with the standard approach ?"
279057,can you please provide some additional information on what you want to achieve ?
279689,"one reason why an explanation in words is so important is to check that the code is doing what you think it is . the explanation you added is very helpful ( 1 ) . why do you suppose , though , that the log odds of at least one head ought to be a linear function of the number of tosses ?"
279966,"your question is far more general . for instance any normal distribution , as commonly used to model ( say ) measurement errors , assigns nonzero probability to ridiculously impossible values . the right question to ask yourself concerns whether this matters : provided those probabilities remain so small that they do not affect your analysis , why should you be concerned ?"
280248,maybe a stupid question but why not just build a different predictor for each of your 1000 possible medications ?
280545,what constitutes better performance ?
280665,"1 . what exactly is "" mean "" in your simulation results ?"
280832,"1 for very pretty figures . are you doing your pca on the covariance matrix or on the correlation matrix , i . e . are all the variables normalized or not ?"
281042,are the data single measurements taken from 39 different units ?
281232,lijiayu why do you concatenate ` ts ` in your vector of permuted means when calculating the p-value ?
281304,could you identify any scientific study anywhere that does not rely on a sample ?
281569,"your question is unclear in several ways , not least that you seem to conflate density with probability ( they're different ) . you seem to be observing densities . can you explain how they arise ?"
281511,"you seem to know the concept of potential outcomes . if your treatment and control groups are exchangeable , then you need not do any fancy math . your second estimator looks like an inverse probability weighted estimator , basically . say your two groups are balanced . i can't see any reason to use ipw . you would use ipw in an observational study , or if your randomization had failed . i also can't see any reason it should have lower variance than the first estimator . explain your simulation study a bit more ?"
282259,you reference two different models above . i'm wondering if this has something to do with it ?
283051,could you please include the output for ` model1 ` and ` model2 ` ?
284187,you only get 150 sample points in a 300ms interval ?
284067,related : [ what is the difference between linear regression on y with x and x with y ?
284561,do you have training data with user labels for events ?
285217,"can a pack contain both a ur and an sr , or only one of each ?"
285231,do you include subsampling ?
283954,can you clarify what the structure of the primary studies is ?
286112,do you not have the data per student ?
286134,the values are correct . have you read the documentation for the tbats ( ) and tbats . components ( ) functions ?
286352,"i'm a bit rusty on the particulars , but i believe you can only coherently represent a hierarchical bayesian model with a directed acyclic graphical model ( dag ) if that dag is an i-map for the bayesian model . your graphical model is not an i-map since it encodes independencies which don't exist in your bayesian model . your graphical model is , in effect , a relaxation of your bayesian model , which means you should sometimes expect it to result in the type of degeneracy which you've just observed . is there a reason you didn't set both your arrows to point in the opposite direction ?"
286359,how many observations are in your dataset ?
286357,"the last part - as a question about how to use spss : "" * how do we display the data in spss ?"
286624,what are your goals for the visualization ?
287304,` if i input the same data multiple times i will get different predictions each time . ` something seems wrong here . are you sure you haven't accidentaly used a recurrent network ?
287407,"dr . beeblebrox i'd like to edit my answer , but it would be helpful to define some terms . can you write the so-called sharp null hypothesis out and define the notation ?"
288012,could you explain why you want to divide ?
288018,"your stripped-down , abstract question is unanswerable because it does not supply enough information to determine significance . ratios usually don't come by themselves : they are derived from other data . what are your * original * data in this case ?"
288298,your data and analysis purposes are not clear ( to me ) . what is ` replication ` ?
288594,"when you view regression [ geometrically ] ( url ) , this question becomes "" why doesn't the pythagorean theorem apply to all triangles ?"
289300,"the nature of this question is obscure . much of it seems to focus on dealing with high-precision arithmetic . some of it refers to "" blocks , "" which meaning is undefined ; and none of it explains what properties these "" random numbers "" need to have : should they be independent ?"
290796,you're after an age-and-gender adjusted bmi that has about the same distribution as adult bmi ?
289075,are you sure we need [ tuning-parameter ] tag ?
290932,i think this boils down to the proportionality of the predictors' effects . i . e . do you expect the effect of some baseline predictor ( e . g . initial treatment of the infarction ) to be * constant during the entire period of follow-up * ?
290953,it does sound like overfitting . have you tried gradually increasing the number of trees in the forest ?
291183,what exactly is your question ?
291436,"i don't think i follow you . you refer to "" connected "" and "" smooth breakpoint "" and "" clipping "" and "" intersection . "" although they provide strong geometric images , they are still pretty vague when it comes to your statistical model . do you wish to fit a pair of line segments to your data that touch at the breakpoint but might have different slopes ?"
291681,frankharrell : you mean [ this ] ( url ) ?
291697,your model specification does not make any sense . do i understand correctly that each ` study ` contributes only 1 data point to your model ?
291776,can you please provide some references / papers so your question can be contextualised more accurately ?
292058,write sane loops ?
292067,"what is your definition of a "" good "" approximation ?"
292045,"the situation has not been clearly defined ; one might set up different sequences of tests that have different properties , and to talk about something having a distribution you must define a random variable or sequence of random variables that you're discussing the distribution of ( some statistic ?"
292248,"i'm struggling to understand your notation , because you have overloaded "" $ beta $ "" and the meaning of the expression "" $ langle beta ( bf { x } ) , bf { x } rangle $ "" is unclear : in what way might you be trying to distinguish this from matrix multiplication ?"
292283,"what do you mean by "" shifted to the right "" ?"
292333,"where you say "" is continuous "" in the second sentence of your second paragraph , do you mean to say "" is not continuous "" ?"
292588,"are you asking ( a ) how we determine if a statistical test is robust to an issue , ( b ) what are other metrics than p-values / alpha levels / type i errors / other nhst decisions we can use as measures of robustness , or ( c ) both ?"
292626,have you looked at weighted least squares ?
292628,"for those of us who aren't familiar with eye-tracking research , it would help if you could explain how to interpret the images . then , what exactly is the "" this "" that's supposed to be not a coincidence ?"
287920,are you sure the 1 / m is on the regularisation and not on the j ( theta ) afaik dikranmarsupial 's answer is making that assumption . . . . . . or does j ( theta ) itself have a 1 / m term ?
294050,"what loss function are you minimizing , log-loss ?"
294117,"instead of "" probability that the coin is unfair "" perhaps consider the probability that a fair coin produced the observed result . ( what exactly would the former mean anyway ?"
294244,"can you elaborate on "" when i took some sample values randomly from a population i did not find this statement true "" ?"
294297,could you also explain in your question what the remaining terms of the equation ( a's and s's ) represent ?
294412,""" as is always the case "" is a misconception propagated by efforts at elementary explanation on the web and in textbooks . furthermore , it's hard to see a hypothesis here at all : you seem to want instead to address the question of * calibration * : how accurate is the classifier ?"
294592,could you please explain how a sequential set of transitions through an ordered list corresponds to a markov chain on the set of permutations of the list elements ?
294591,"it's not clear to me what you're asking , especially your first question . if you condition on $ n $ , your random variable is going to be $ z $ , and if you condition on $ z $ , your random variable is either going to be $ n $ or $ n-z $ . why would you think the sampling distributions etc . would be the same when the r . vs themselves are clearly different ?"
294637,your question is a bit vague . i am not aware of a formally-correct test for what i * think * you are asking . but have you scatter-plotted the data with r1 on the x-axis and r2 on the y-axis ?
295012,"ok , then ` auto . arima ` should presumably try models with effects at lag 365 , but this may not be supported by the data . actually , i would perhaps expect more something like a combination of weekly and monthly seasonality . have you looked at ` forecast : : tbats ` ?"
295175,the first and the second plots are the same . could you also attach plots with transformed data ?
295561,why do you do this ?
295594,please give more details about your design / data . do you have longitudinal data ( ` dates ` ) ?
295704,ask yourself : is mean of the indices meaningful ?
295793,are you trying to make a recommendation based on the starting lat / lot point alone or do you also take into account metrics related to the driver id ( i . e . the history of that specific driver and not just the patterns of similar routes ) ?
295804,this can't be answered at present . what are the means ?
295843,i find it a bit difficult to understand the question . could you please try to clarify your first two paragraphs ?
295917,since negative values are not possible why do you say that the distribution is normal ?
296169,perhaps because your series has such constant variance . what does auto . arima ( ) give you ?
296217,are you only interested in the improvement over the baseline or also the improvement between protocols ?
296218,"1 . $ alpha $ is something you choose before you see any data . do you instead mean that the $ p $ -values are "" quite small "" ?"
296325,it is not clearly pronounced what is group and what is section . are the 8 groups are different samples of respondents ?
296375,"it might help to explain what the plots show . i think the points are the two sets of data that are used for training , and the line is the boundary between areas where a new point would be categorised into one or other group . is that right ?"
296505,what is the hypothesis that you want to test ?
296682,how are you proposing to estimate the posteriors ?
296788,"what do you mean that "" taking the log of yield messes up my linear model assumptions "" ?"
296890,"have you counted the numbers of increases in each of the vectors ` x ` , ` y ` , ` z ` ?"
296979,"you should be able to cast the model you have there into state space form and use the kalman filter to do mle . just put all your observations one after the other and change the state dynamics depending on the time ( constant within the day , ar ( 1 ) on the day boundary ) . there may be a simpler / faster method of estimating this specific model , but the state space approach is very general and will work the same for some slight variations on what you have there ( should you have within-day correlations ?"
297174,"could you explain what you mean by "" vectorial version "" ?"
297021,"obviously cca should be able to deal with all 18 variables . my feeling is that some of these variables are linearly dependent on the others , and get excluded by the cca algorithm . are your variables continuous ?"
296817,"re "" but this will neither be strictly increasing , nor continuous "" : a good reaction at this point ought to be "" so what ?"
297032,would you share your dataset ?
298485,can we get a reference for these quotes ?
298644,"do you just need to meta-analyze psychometric data , or do you need some particular method or family of methods called "" psychometric meta-analysis "" ?"
298757,did you read a detailed [ answer ] ( url ) about factor scores ?
298670,"in relation to "" 3 sigma "" - you would need to clarify what properties you're seeking . in the univariate gaussian case there's a particular connection between number of standard deviations from the mean and the chance of going beyond those limits , but it is different for different distributions . are you seeking the same chance of being outside the limits , the same number of standard deviations , or do you intend something else ?"
299091,did you include the original variables in the model when you estimated the coefficients of these interaction terms ?
299274,is it deliberate that ` x ` is confounded with ` k ` ?
299331,"it is unclear to me what you mean by "" and how can i apply k-fold cross validation over training set and test set with together ?"
299307,those terms are vague . can you provide the context where this word choice occurred ?
299481,could you post a citation / more detail on which bound and algorithm you use and maybe a figure showing the discrepancy ?
299909,"these are different coins , each of this has a separate heads probability ; and the beta distribution would be over heads probability ?"
300048,( 1 ) what does ` istrial ` mean ?
300166,are you implementing everything yourself ?
300404,have you studied the * actual * distribution of digits for the noon temperatures ?
300746,what exactly do you want to learn about the distribution ?
300762,what's your goal ?
300778,"this needs the same kind of clarifications requested of your previous question at url furthermore , these kinds of questions have little ( if any ) interest statistically ; they're too broad and don't have definite answers . could you explain * why * you want to simulate variables with these properties ?"
301052,"1 . your equation for $ p ( u = c ) $ doesn't seem to be consistent with your equation for $ p ( u geq c ) $ in particular it looks like that last power would need to be $ c d-c $ rather than $ c d-d $ . 2 . if you're doing a hypergeometric test , wouldn't your probabilities follow a hypergeometric rather than a binomial ?"
301205,"to help answer this , please add some details about your data set size , and the train / test split . also , what the training set accuracy is - perhaps you are over-fitting after epoch 4 ?"
301300,1 please give a complete reference for the book . 2 . was a distribution stated at any point ?
300580,"so , just to be explicit about dougal's question : do you want the * simulated data * to have these properties or do you want the * underlying random variable * to have them ?"
301396,are these counts ?
301448,"what is meant by "" time duration "" ?"
301696,. . exactly do you want to do ?
301781,"how do you define "" loading "" ?"
301946,can you show us the confusion matrix of predicted vs actual labels on the test set ?
301960,which version exactly of python are you using ?
302163,( 1 ) your immediate problem is that the expression scales like $ n ^ { -0 . 4 } $ and therefore depends on that arbitrary number $ n $ . the approach is nevertheless appealing : start with a simple assumption about the second-by-second decision-making process as a function of the entry point and the distance to the divergence . let that determine the distribution of the decision points . that suggests you still need to supply another piece of information : * exactly how should the instantaneous decision probability depend on where the driver enters ?
301243,why do you want such a constraint ?
302155,"to me iv means "" instrumental variable ; "" that doesn't seem to be what you mean . what do you mean ?"
302577,it's not clear to me what's going on in the last equation . what do the authors do with it after they've obtained it ?
303041,"please note that this is not what is usually meant by a time series , because data are not obtained at regular intervals . your question seems to imply that the true position changes after the string has been pulled , but is that really the case ?"
303468,"how does "" correlation "" relate to your situation ?"
303786,your problem will not be sufficiently well defined until you can provide a quantitative way to evaluate how well any approximation works . how are we supposed to measure the goodness of an approximation ?
304040,tell us more about the response variable ( is it a time ?
303983,"for reference , what are the $ xi_i $ produced for each plot ?"
304379,what does your variables represent ?
304363,"you use the ` glm ` function without a family argument , that is , you use the default gaussian family with identity link . so you could as well use the ` lm ` function ! but then later you use the hosmer-lemeshow test , which is for logistic regression ! so you seem confused , better tell us what your variables represent , and which question you want answered with help from the data ( without statistical jargon ) . that way , maybe we can propose something useful ?"
304633,what do you mean by 1d & 2d correlation ?
304660,"( 1 ) yes , it does make sense . it's fine . ( 2 ) this is hard to say . presumably if the variance of expert is non-zero then it's pretty small ?"
304730,"what do you mean by "" false "" objects ?"
304839,"it could be easier if the explanation is given using an example that you know , do you have a case where you would like to apply logistic regression ?"
304886,how many urls do you have ?
305091,this doesn't add up . what covariates are you including in the model ?
305273,"what do you mean by "" repeatable "" ?"
305406,i want to comment on the first question- you have 14 repeated annual measures of an industry sector in a country . the main question i have is : are these observations at the country level ?
305714,what do you mean that there is no noise ?
305830,"can you clarify what "" fox's statistical "" is ?"
305878,what exactly is amount of information in matrix ( or in product of matrixes ) ?
305884,"welcome to cv . since you re new here , you may want to take our [ tour ] , which has information for new users . could you give more information about the variables ?"
305813,where is your scale variable ?
306112,"i still think this is unclear - for example we are told at the start that "" sales_volume is corrupted after ranking process "" but then told that "" sales_ranking is reliable data "" . is the ranking column really just sales_volume put it ranking order , as the title of this question suggests ?"
306636,how many of those quadratics are you planning to compute ?
306780,what type of regression are you doing with this data ?
306928,might i suggest including that context and objective in the question itself ?
306937,"are you certain that in ( 3 . ) , $ z sim mathcal { n } ( 0 , i ) $ and not $ z sim mathcal { n } ( 0 , sigma ^ { -1 } ) $ ?"
307252,"not sure of what you mean by "" to suggest the same hypothesis as yours the first time "" ?"
307285,i don't understand what you're doing during your integration . $ int_0 ^ a be ^ { -bw } dw = 1-e ^ { -ba } $ . where are you getting $ x $ and where are you getting the second term ?
307387,what book are you talking about ?
307440,"suppose you have $ n $ independent , identically distributed bernoulli random variables each with probability of success $ p $ . how would you determine the chance that at most two of the $ n $ random variables is a success ?"
307543,fourier models are not recommended as they often misinterpret the data . what we have done in this kind of problem setting is to form a model at the daily level taking into account memory plus both known and unknown deterministic structure . we then incorporate the daily history and forecasts into 30 models ( one for each minute ) . subsequent forecasts can then be adjusted in either a top-down or bottom-up method . . . is this an academic exercise ?
307812,can you post an example of your data using ` dput ` ?
308066,can you write $ mu $ in terms of $ theta $ ?
308187,"i can't see why random search ( vs , for example , grid search ) would change anything in here ?"
308201,are there other distributional summaries of the groups aside from mean / median ?
308481,"user6376297 i agree with whuber ; as soon as i read as far as the word "" pharmacokinetic "" my first thought was "" this is going to be a difficulty with fitting linear combination of exponentials , right ?"
308757,""" we get a random output of either 0 or 1 , roughly following a normal distribution "" --- i'm sorry but what you mean is not clear -- if you have random numbers from a normal distribution , they won't be either 0 or 1 . can you explain what you mean in simple terms ?"
308785,what are you really after here ?
308910,"yes you can ! i guess , i mean you can always multiply $ ao ( x_i , x_n ) $ by $ text { sign } ( x_i- text { med } ( x_n ) ) $ . i'm not quiet so sure about the idea of summing these things though . what are you trying to accomplish is not all that clear to me quiet yet . see , the premise : ''i want to add / sum some variables having different units . '' and i wonder ''but why ?"
309047,the * * lsmeans * * ( just succeeded by * * emmeans * * ) package can do this for ` betareg ` objects . i guess that doesn't provide for zero inflation though . which part of the output you have has to do with zero inflation -- is it ` nu ` ?
309138,you don't appear to have a main effect of ` concorrencia ` . are you * sure * that's what you want ?
309245,do you have model fit indexes to accompany your 2-factor solution ( rmsea and tli ) ?
309605,are you talking about k-nn or k-means ?
309595,how confident are you in the linear relation you've assumed between each predictor & the logit response ?
309493,"thanks for the update . looking at the output of your updated lmer model , one can see that lots of random effects have 0 variance . this can either be due to some weird ( potentially convergence-related ?"
310798,could you clarify you question besides the one in the last paragraph ?
311507,"it appears that you have 6 distinct time series ( 1 , . . 6 ) and two characteristics ( measurements ) . which one are you trying to predict / analyze / cleanse ?"
307936,"it would be useful to know what the intent is here . you did these things , why ?"
311992,where is the question ?
312211,do you really have only one day's worth of data ?
312807,"why cannot you do pca on all the 12 features ( v1a , v1b , v2a , v2b . . . ) ?"
313022,are you sure about that last equality ?
313026,"you wrote "" however , since the treatment group is small , matching with a caliper distance will result in a completely different matched sample everytime and , thus , the randomness is results is huge ?"
313139,"these results are telling you the data don't come from a beta distribution . the software can figure that out because there is so much data . this raises more basic questions : why are you fitting your data , what do you hope that will achieve , and how accurate does the fit even need to be anyway ?"
313286,how do you see that there are _statistically significant interaction_ from the output you provide ?
313619,"in this question and your answer wherever you write "" $ 0 lt p lt 1 $ "" it seems you [ should be writing "" $ 1 lt p lt 2 $ . "" ] ( url ) is this a correct impression ?"
313703,"do you not want to use $ x $ itself as part of the the predictor , since you have measured it ?"
313771,what is the logic given by him for interaction effect ?
313784,i suspect arma models with unit roots might be fit poorly and might have some undesirable features . i would difference the data and only then supply them to ` rugarch ` . is there no mention of unit-root processes in the ` rugarch ` vignette ?
314151,"the sense of your question about "" interpretation "" is unclear , because you could always * define * the "" co-median "" ( the word absolutely needs a hyphen ! ) to be $ hat beta_1' $ times the mad . what kind of answer are you looking for ?"
314227,"i may have an answer but one point confuses me , and it depends on what your $ p ( m ) $ looks like . is it flat , by any chance ?"
314321,what is the response variable in your data ?
314673,can you please add additional information as an edit to the post ?
314947,does that mean that all the people who stayed for 40 days were in sunless conditions the whole time ?
315088,how many individuals are in this study exactly ?
315097,how did you specify deterministic terms in the test ?
315112,there is a risk this might be closed as off-topic as you seem to be asking for r help . there does seem to be a possible statistical issue here about fitting trees when you have competing risks - is it possible ?
315144,you ask us to estimate something that doesn't exist . the expectations are a set of $ m $ numbers . at least one of these numbers is largest . there's no probability associated with the associated index--it is whatever it is according to the laws of arithmetic . what are you really trying to ask ?
315207,what's your ultimate objective for this data ( i . e . the conclusions you want to make ?
315189,are you asking about ` ( x1 rand1 ) ( x2 rand1 ) ` ?
315224,if you normalize the data you may lose what look like very important aspects of it . are you certain that you want to use the same model for all of this data ?
315288,"i apologize for seeming dense , but the format of the data you have posted is not clear to me - for example , i do not see the response variable values . would you please clarify the data format ?"
315498,$ f_ theta $ is not a valid density . are you perhaps assuming the density is zero except for $ 0 lt x le 1 $ ?
315734,when you say your data is showing . . . do you mean your data or the residuals from your model or something else ?
315428,"could you explain , what are the replicates ?"
315909,could you include several rows of your data for more clarity ?
315973,"please tell us what data you are using . you say "" . . . for populations , "" suggesting you are using a complete census , but then the question about representativeness indicates you only have a * sample . * which is it ?"
316053,"so summarizing : instead of raw data you are given summary statistics ( mean , median , 5 % , 95 % quantiles ) and want to perform bayesian analysis of such data , do i understand you correctly ?"
316463,you do need to provide more information to us . 1 ) how is the r2 change ?
316489,that sounds about right but how would you know the correct number of principal components to use so that the data is still linearly separable to some degree ?
316536,"the first situation is routine : chi-squared tests address this situation , at least provided you roll the dice a few more times ( 180 rolls will suffice ) . in the second situation under a uniform distribution there are $ 20 ^ { 20 } approx 10 ^ { 26 } $ equally possible outcomes . your options are limited : how many rolls do you think it would take before even a * single * outcome were to show up twice ?"
317057,numerical issues ?
317110,"there seem to be two related but different questions here . the system ( 1 ) - ( 4 ) you have formulated indeed has a unique solution . however , it does not reflect the subsequent statements that the slopes are increasing on $ [ 1 / 2 , 1 ] $ . which of these is the question you really need to address ?"
317136,"how many "" commands "" are possible ?"
317502,"i must be having problems reading today , because despite scanning this question many times i cannot find a definition of "" $ kappa $ "" anywhere : exactly how is it determined by $ m , m , n , $ and $ mu $ alone ?"
317595,"i assume you mean a subset of observations , not variables ?"
318094,can we have a reproducible example please ?
318187,can you provide sample data ?
318601,what are method 1 and method 2 ?
318652,it may be inevitable if x and y are restricted to be positive . should i explore that case in my answer ?
318980,"so are there repeated measures for the same analyte ( i . e . , there is a single analyte a which is exposed to different events and measured each time ) or are different individual analytes from a class tested individually ( there are 10 analytes belonging to class a , and each is exposed to each event a single time ) ?"
318983,what is your question ?
319399,i find a vector with p-values containing some na's a bit strange . what does a missing value in the list mean ?
319994,what is the goal of this experiment ?
320375,the third sentence in the paragraph you quote is the key one . can you tell us more specifically what is unclear about it ?
320463,why change categorical data to numeric in the first place ?
320568,"my guess is that using "" monte carlo "" gives the informed readers that there was some statistical underneath the motivations of the speaker ?"
320661,"you go back and forth between alluding to your data as "" not well separated "" and "" separable "" : are you sure you have used these terms consistently ?"
321126,why do you think there could be a model that will get you mape of 20 % ?
321207,"to me , it looks like a categorical data , not continuous data . can you post a minimal hypothetical reproducible example / data ?"
321256,"what do you mean by "" all draws are good "" ?"
321527,how do you calculate ` sigma ` ?
321532,"you can apply an estimated quantile regression to a new dataset in exactly the same way as an ols regression . of course the regressors should be semantically the same and measured in the same way in the training and the test dataset - but this applies equally to quantile and "" normal "" regression . can you clarify what you are looking for ?"
321065,"are you asking for help with your matlab code , or about how to simulate diffusion using wavelet fractional brownian motion in general ?"
323071,oh . . . so the problem is that you don't know how to get the pointwise confidence intervals from the forecast object ?
323135,why do you need to exponentiate them ?
323246,"you need to first define what the random component of your model is . that is , what distribution are you assuming $ y $ follows ?"
323364,how correlated are review_count and stars in your data ?
323181,"i have a few ideas , but first a few clarification questions . you say that you have "" * up to * "" 100 observations . what does that mean ?"
323515,is this a homework problem ?
323571,"welcome to cross validated ! this seems an interesting question , but it's hard to understand what you want , exactly . on one hand , it looks like you're interested in time series classification . you have $ k $ classes , and $ m $ time series , and you would like to know to which of the $ k $ classes , each of the $ m $ time series belong . but then you cite also $ n $ time series , and this is where it becomes confusing . how many time series do you have ?"
323788,"no , eigenvalues are not enough ( unless your matrices are diagonal ) . you'll have to carry around the corresponding eigenvectors as well . i'm not sure why you want the inputs to be of the same length , but perhaps you can unroll all your inputs and just pad the smaller ones with zeros ?"
323827,"exactly what "" variance "" are you referring to ?"
323986,not a single course on probability theory while getting stat phys phd ?
324289,is this a homework question ?
324318,can you be more specific about the variance term you would like to calculate ?
324321,what is the function $ f $ in the denominator ?
324337,no simple distribution will be an exact match . do you particularly need a specific distribution for something ?
324590,what type of neural network are you using ?
324917,hint : can -314 . 49 % be a probability in the first place ?
325003,"just to check - you want the principle components of each of ( data , loadings and score ) calculated , but so that they are on the same scale as the original values ?"
325465,* itc * is new to me but similar older survey-based approaches to obtaining answers to sensitive questions have infinite variance . this may be the reason you can't find its calculation in the literature . what would have been nice is that the authors clearly stated that the variance was infinite . why not ask them directly about it ?
325689,"if i'm reading this correctly , you understand how a nonempty null space causes degeneracy in linear regression , but do not understand how a nonempty null space causes degeneracy in logistic regression ?"
325958,whats an roi ?
326099,can you be more clear ?
326449,"erm . . . don't you mean 'the more mass the probability distribution puts to the * * right * * , the better' ?"
326464,have you checked on wikipedia how m2 is supposed to be used ?
326656,"so you seem to have two conditions for gender and two conditions for context . on top of that you repeat the task three times per the 2x2 conditions you mention . that all makes sense so far . what is not clear is what your predicting in your response . i understand that they need to pick a word , but how large is the set of words to select from ?"
326658,"just to make sure , you are dealing with time series data ?"
327008,"when you run your regressions on the transformed $ y $ variable , are you simply running the predictions through the inverse transform , or are you accounting for the fact that , e . g . , $ text { e } exp ( y ) neq exp ( text { e } y ) $ ?"
327237,"the trick is the degrees of freedom , right ?"
327292,"is it possible to pare down this post into a single , focused question with a minimally reproducible example ?"
327371,how many unique values of path length are there ?
327646,"neither the word "" sink "" nor the code you quote appears in the linked paper . are you missing a reference ?"
327761,can you clarify how heritability relates to a logistic model relating a binary treat ?
328313,what is $ m ( y ) $ in the denominator ?
328331,"could you be more specific about what you mean by "" model "" these variables ?"
328395,"do you actually allow any $ t_n in [ 0 , 1 ] $ or do you mean $ t_n in { 0 , 1 } $ ?"
328604,"perhaps you could expand your question by editing it so that when you say "" higher "" we know higher than what ?"
328582,can you show any diagnostic plots ?
328712,"in the second set of models why would you have ` newsiteid ` ( i . e . , the factory ) as both a fixed effect and a random effect ?"
329521,whuber could you post an answer with some development ?
329625,"it is not clear what you are asking , or more specifically which point you are confused about . maybe you could extract two or three specific questions . right now the only real question i can see is , if you can argue with the box plots . but even there i don't really understand the question . do you mean in the sense you are trying to support a certain decision ?"
329810,well what're the median values for those covariates x1 . . . x6 ?
329972,"what specific features , in your view , distinguish this scatter plot from other scatter plots ?"
330025,"could you explain how exactly are you obtaining $ x_1 , x_2 , dots , x_n $ ?"
328242,why are you doing this ?
330414,if your sample size grows why would you do psudo inverse ?
331092,to my ( non-expert ) gut this looks like something that's difficult to do properly in frequentist setting . would sketching a bayesian solution for this class of problems be an acceptable answer or are you confined to the frequentist approach ?
331219,what is the minimum of your data ?
331899,is a an orthogonal matrix in these contexts ?
331716,""" does the fact that my response variable's values being between -1 and 1 part of the problem ?"
332008,"thank you . i must be confused by your notation . what could "" $ p ( y_1 y_2 mid y_1 ) $ "" possibly mean ?"
332287,how will your professor's reconstruction be evaluated ?
332450,it depends very much on the model . could you provide details of the two models ?
332695,how do you calculate $ r ^ 2 $ for the accuracy of judging ?
332819,"to be honest , i doubt that this is a question of deming regression vs . ols . looking at the very small absolute variability in $ x $ and $ y $ , i'd rather think this may be a numerical issue in excel . can you edit your question to include the data ?"
333040,"i don't understand the variable . a "" length "" describes the length of time for a "" tow "" : a single fishing trip . are you saying you are modeling the fraction of netted or trolled material that happens to be fish as opposed to other matter like debris . is that right ?"
332988,"couple of things : 1 ) could you expand [ on ] the abbreviations "" bp "" and "" tss "" . 2 ) why is ` min_dist ` allowed to be negative ?"
333239,"kurtosis is a matter of shape , not spread ( disperson , scale ) . so , clustering around the midpoint could be absolute ( spread ) and / or relative ( kurtosis ) . evidently your kurtosis is on a scale on which normal is 0 . people have been arguing for decades on what kurtosis measures ( apart from kurtosis ) : an intricate and often fraught debate aside , the best verbal summary i can offer is tail weight . i'd plot distributions as a quantile-quantile plot here . density estimates can be a little too sensitive to kernel width the marginal rugs give flavour rather than insight . can you post the data ?"
335713,would you please link to or post the data ?
336389,is this homework ?
336404,"i don't know python that well , but are you using the coefficient values to assess importance for logistic regression ?"
336842,is time increment a constant ?
336882,"your model does not have an activation at the output , how did you normalize the target coordinates ?"
337088,can you also post a plot of your actual time series ?
337813,whether this will be be useful almost certainly depends on what the variable importance measure is meant to indicate . what do you want to use it for ?
337856,so worst case scenario is that your samples are non-random and duplicated ?
338007,"did you tell it what the frequency of the data was , apparently 52 ?"
338169,why not just write a little preprocessing script that steps through the vector eliminating duplicates ?
338372,do you have multiple measurements per person * and * time point ?
338539,"not sure about matlab , but r has good documentation for its sample quantile functions ( under ?"
338832,why are you fixing the theta parameter of the negbin at 1 ?
339422,"* but non-statisticians are asking me "" how do you prove negative results ?"
339675,welcome to the site . i don't see an actual question here . how are you modeling times $ a $ and $ b $ as exposures ?
339660,we need to know something about how $ gamma_n $ goes to 0 . is it a sequence of constants ?
339869,have you heard of overfitting ?
340136,"i don't see a valid estimate of kl divergence in your code , but perhaps i misunderstand what it's doing . could you explain the algorithm you are using ?"
340175,do you mean classification or clustering ?
340214,"gaussian distributions have no limits , so it would behoove you to specify clearly what you mean by this assumption . also : is the thread taut ?"
340320,post-edit : have you tried specifically the approach in [ this ] ( url ) answer by glen_b ?
340531,"your question is confusing because a gaussian copula together with the marginal distributions determines the joint distribution , yet you state you don't know the joint distribution . do you mean that you don't know the parameters of the gaussian copula ?"
340614,"there is no answer independent of knowing what these data are . if columns are expressed in the same units and genuinely comparable , then it's not a problem that some values are high and some low . that is just what you are trying to summarize . conversely , you have not said one word on why you need to make the scales comparable . but if you do that , then the questions of which columns are higher or lower disappears or becomes meaningless . even if it's a good idea to scale , how can there be good advice on the best way to do it in total abstraction ?"
340713,i'd rather see the equation than some of the stuff you mention . an end user should presumably want to know what it means and can it be trusted does it match sensible limiting behaviour ?
340712,could you provide a table of your inputs and calculated results ( with appropriate variability measure ) ?
341036,how do you have missing data ?
340997,"surely that's just a way of cheating . if the goal is to generate significant p-values , why both with controlling for multiple testing , or doing work , at all ?"
341182,"i don't see a question mark here . assuming you're asking "" how can i make this model work ?"
341236,do you have any idea of the range of expected p-values for the individual tests ?
341673,does the challenge explicitly forbid you to ask for help on sites like cv ?
341712,"sorry i don't see this - . 35 coefficient in your output . also , why don't you use the option to get odds ratio directly instead of having to calculate them ?"
341736,"please defined completely the truncated normal distribution as i do not think there is a well-established definition . in particular , ( a ) what are the truncation points ?"
341862,can you work out the distribution of the number of sevens * unconditionally * ?
341990,"this sounds like a dummy variables situation , but a few questions first . is there any overlap in the groups ?"
341903,"does "" age-standardization "" involve something more than converting the ages to z-scores based on the sample ?"
342124,what does the notation $ t ( alpha ) $ mean ?
342190,1 . should $ x_i $ in the first equation be $ x_j $ ?
342246,is this homework ?
342512,do you mean adding new variables or increasing the sample size of the existing variables ?
342583,what kind of model are you fitting ?
342454,what is the exponent $ ( s ) $ ?
342713,what does $ x ^ { ( i ) } $ denote ?
342784,"please explain what it means for data to "" fit a function . "" could it be your data are 4-vectors and the fourth is given by applying the function to the first three , or would it mean your data are 3-vectors and applying the function to them all yields a constant value , or could it mean something else ?"
342810,have you looked at the wikipedia page for the negative binomial ?
343165,"it's not a linear optimization ( programming ) problem if the objective function is nonlinear . anyhow , among many other things , the performance of fmincon can be strongly affected by the starting values . are the 1e5 problems you want to solve closely related to each other , for instance by being minor perturbation from the previous problem ?"
343041,does each person have a score on each of the 5 dimensions ?
343372,""" general practice "" says who ?"
343268,we define p-value as 'the probability to obtain a result within a certain range ( often some value or more extreme for a calculated statistic such as used by pearson in 1900 ) given that a certain hypothesis is right' ?
343441,are all these novel machine learning applications instances of ( semi- ) supervised or unsupervised learning ( in the broadest sense ) ?
343802,do you have a gold standard score ?
343937,i don't understand - what is your main question ?
343794,could you add a [ * * tl ; dr * * ] ( url ) section to your question ?
344831,how did you actually compute changerate in each period ?
344788,can you please check that you get the same results as the one i added when i ran your code ?
344914,could you describe your models more clearly ?
344940,are you sure about the method you should use or is this assigned to you ?
345326,"1 . the distribution of the chi-square statistic does depend on n . have you seen the widely-used "" rule of thumb "" that the expected value in each cell should be greater than 5 ?"
346226,would you care to show the differences of series in addition to the levels ?
346752,what are these files and combinations you refer to ?
346782,can you explain what months and replicate stand for ?
346856,""" what i also observed is that this inequality gives a simple proof for $ mathbb { e } [ xy ] geq mathbb { e } [ x ] mathbb { e } [ y ] $ . "" huh ?"
346926,"looking at your plot provided as i was writing my original answer , it looks like the spearman correlation would be close to 0 . is it significantly different to 0 and is it significantly different between pearson and spearman ?"
347372,is biomass lost in the gr response attributable to sources other than mortality ?
347436,what happens if you log-transform leverage as well ?
347628,"in a linear regression you get the covariance matrix of all parameters , did you look at it ?"
347653,are you sure you're not confusing $ p ( x h_0 ) $ with $ p ( h_0 x ) $ ?
348034,"you do realize that would restrict your parameter estimates to be integers , not just positive , right ?"
348063,if the data is not collected randomly it may not be valid to do any statistical inference . how many frequency distributions are you comparing ?
348235,"ukaszgrad , could you write the explicit form ?"
348340,"i am fairly sure coefficients have a normal distribution ( under the model assumptions ) . is there a reason you are normalizing by the sum of coefficients , rather than in some more ordinary way ( e . g . by standardizing the ivs to have a sd of 1 ) ?"
348459,"as it stands , this is very broad . can you please give some more details about your particular data ?"
348649,"there are so many restrictions that calling a sequence of such numbers "" random "" would seem to be unjustified . could you explain the intended purpose of this sequence ?"
348828,"do you have the individual level exposure , count data , or has this been lost ?"
348912,do you mean $ hat { y } _ { t 1 } = alpha y ( 1- alpha ) hat { y } _t $ rather than $ hat { y } _t 1 = alpha y ( 1- alpha ) hat { y } _t $ ?
349030,optimal parameters in what sense ?
349044,the bottom right plot seems to have some information cut off . what are the colors ?
349137,"presuming $ c is symmetric positive semidefinite , this is a convex quadratic programming problem , for which any solution is a global optimum . if c is positive definite , the solution should be unique . do the various solutions you get all have the same objective value ?"
349295,"there are a few problems with this question in its current form . you seem to have two error series $ u $ and $ e $ and so your model is not an ma ( $ p $ ) model . you also have a parameter $ theta_p $ in your equation , which is not included in the corresponding parameter vector . ( and there is no purpose in transposing a scalar parameter . ) please check your question and make sure you're setting out your model correctly . ( also , if you are interested in the ma model , why mention the arima in the title of the question ?"
349217,"by "" how two quantities are equal "" , do you mean * why * they're equal ?"
349467,possible duplicate of [ how to choose the number of hidden layers and nodes in a feedforward neural network ?
